


# Sch√§tzen vs. Testen



## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.




### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen... 

- den Unterschied zwischen dem *Sch√§tzen* von Modellparametern und dem *Testen* von Hypothesen erl√§utern
- Vor- und Nachteile des Sch√§tzens und Testens diskutieren
- Das ROPE-Konzept erl√§utern und anwenden
- Die G√ºte von Regressionsmodellen einsch√§tzen und berechnen


### Begleitliteratur

Der Stoff dieses Kapitels orientiert sich an [@kruschke2018].


### Vorbereitung im Eigenstudium

- [Statistik1, Kap. "Geradenmodelle 2"](https://statistik1.netlify.app/090-regression2)




### R-Pakete

In diesem Kapitel werden folgende R-Pakete ben√∂tigt:

```{r}
#| message: false
#| results: "hide"
#| warning: false
library(rstanarm)   # Bayes-Modelle
library(tidyverse)
library(easystats)
```



```{r libs-hidden}
#| include: false
library(icons)
library(gt)
library(ggridges)
library(plotly)
library(patchwork)
library(plotly)
library(dagitty)

theme_set(theme_modern())
```



### Ben√∂tigte Daten: Pinguine


Wir ben√∂tigen in diesem Kapitel den Datensatz zu Pinguinen:  `penguins`.



Sie k√∂nnen den Datensatz `penguins` entweder via dem Pfad importieren:


```{r import-penguins}
#| results: "hide"
#| message: false
#| eval: false
penguins_url <- "https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv"

penguins <- read.csv(penguins_url)
```

{{< downloadthis data/penguins.csv dname="penguins" >}}


Oder via dem zugeh√∂rigen R-Paket:

```{r}
data("penguins", package = "palmerpenguins")
```

Beide M√∂glichkeit sind okay.


### Einstieg

Betrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:


1. "Lernen f√ºr die Klausur bringt etwas!"
2. "Wie viel bringt Lernen f√ºr die Klausur?"


:::{#exm-schaetzen-testen}
Diskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! $\square$
:::



## Sch√§tzen oder Testen?


Forschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:

1. *Hypothesen pr√ºfend*: "Die Daten widerlegen die Hypothese (nicht)"
2. *Parameter sch√§tzend*: "Der Effekt von X auf Y liegt zwischen A und B".

### Hypothesen pr√ºfen

Hypothesen pr√ºfende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.

:::{#exm-lernen-hyp}
### "Lernen erh√∂ht den Pr√ºfungserfolg"
Die Hypothese *Lernen erh√∂ht den Pr√ºfungserfolg* kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. $\square$
:::

Das Pr√ºfen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.

1. üü• Die Daten *widersprechen* der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.

2. üü¢ Die Daten *unterst√ºtzen* die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.

3. ‚ùì Die Datenlage ist *unklar*; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.


Hypothesen pr√ºfen ist *bin√§r* in dem Sinne, dass sie zu "Schwarz-Wei√ü-Ergebnissen" f√ºhren (sofern die Datenlage stark genug ist).

:::{.callout-important}
Eine g√§ngige Variante des Hypothesen testen^[vor allem in der Frequentistischen Statistik]  ist das Testen der Hypothese "kein Effekt" (Null Effekt), man spricht vom *Nullhypothesen testen*. $\square$
:::

:::{.exm-null}
### Beispiele f√ºr Nullhypothesen

- "Lernen bringt nichts"
- "Frauen und M√§nner parken gleich schnell ein"
- "Es gibt keinen Zusammenhang von Babies und St√∂rchen"
- "Fr√ºher war es auch nicht besser (sondern gleich gut)"
- "Bei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern" (Null Unterschied zwischen den Geschlechtern) $\square$
:::


*Vorteil* des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterst√ºtzen kann, da es die Komplexit√§t reduziert.


:::callout-note
### Man kann Hypothesen nicht best√§tigen
Karl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann, hat gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt [@popper2013].
Schlagend ist das Beispiel zur Hypothese "Alle Schw√§ne sind wei√ü". 
Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. Schlie√ülich ist es m√∂glich, 
dass wir den schwarzen Schwan einfach noch nicht gefunden haben.
^[Tats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan]
Umgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, 
um die Hypothese zu widerlegen (falsifizieren). $\square$
:::


:::{.callout-note}
### Wirklich nicht?
In der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. 
Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht.
Das bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist.
Auf dieser Basis und der Basis zuverl√§ssiger, repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als auch widerlegt werden k√∂nnen [@kruschke2018; @morey2011]. $\square$
:::

### Parameter sch√§tzen

Beim Parameter sch√§tzen untersucht man, *wie gro√ü* ein Effekt ist, etwa der Zusammenhang zwischen X und Y.
Es geht also um eine Skalierung, um ein *wieviel* und nicht um ein "ja/nein", was beim Hypothesen testen der Fall ist.

Beim Parameter sch√§tzen gibt es zwei Varianten:

a) ‚ö´Ô∏è Punktsch√§tzung: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein "Best Guess"

b) üìè Bereichssch√§tzung: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte

Allerdings kann man das Parameter sch√§tzen auch wie einen Hypothesentest nutzen:
Ist ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.


:::{#exm-param-hyptest}
### Parametersch√§tzen als Nullhypothesentest

>   Forschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?

@eq-muf-mum formalisiert diese Forschungsfrage als statistische Hypothese $H$.

$$H: \mu_M \ge \mu_F \rightarrow d = \mu_M - \mu_F \ge 0$${#eq-muf-mum}

Der Unterschied zwischen den Mittelwerten, $d$, ist genau dann Null, wenn $\beta_1$ in unserem Regressionsmodell `m1` gleich Null ist.
Entsprechend gilt $d \ge 0$ wenn $\beta_1 \ge 0$.


```{r}
m1 <- stan_glm(
  body_mass_g ~ sex, 
  data = penguins, 
  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
  seed = 42  # zur Reproduzierbarkeit
)
```

Dann z√§hlen wir einfach den Anteil der Stichproben in der Post-Verteilung f√ºr die UV `sexmale`, die einen Wert gr√∂√üer Null aufweisen:

```{r}
m1_post <-
  m1 |> 
  as_tibble()

m1_post |> 
  count(sexmale < 0)
```
100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr `sexmale`, dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind.
Entsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht (das weibliche Tiere schwerer w√§ren).
Damit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: $p_H = 1$. $\square$
:::



*Vorteil* der Parametersch√§tzung ist die Nuanciertheit des Ergebnisses, die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.





## ROPE: Bereich von "praktisch Null"  {#sec-rope}


üì∫ [Teil 2](https://youtu.be/k-CB0VGRENY)




Nullhypothesen sind fast immer falsch, s. @fig-nullmeme.


```{r meme-null}
#| echo: false
#| label: fig-nullmeme
#| fig-cap: "Du testest Nullhypothesen?"
knitr::include_graphics("img/5v5531.jpg")
```

[Quelle: Imgflip Meme Generator](https://imgflip.com/i/5v5531)







>   We do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have *some* effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. [@gelman2021]






### Alternativen zu Nullhypothesen


Nullhypothesen, $H_0$, sind z.B.: $\rho=0$, $\rho_1 = \rho_2$, $\mu_1 = \mu_2$, $\mu=0$, $\beta_1=0$.
Nullhypothesen zu testen, ist sehr verbreitet.
Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest m√∂glich ist.^[Mittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.]

Ein anderer Grund ist vermutlich, ... wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è

Alternativen zum Testen von Nullhypothesen sind: 
  
- Posteriori-Intervalle (PI oder HDI) berichten
- *Rope*-Konzept [@kruschke2018]
- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.
- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.






### "Praktisch" kein Unterschied: Das Rope-Konzept


üì∫ [ROPE-Video](https://www.youtube.com/watch?v=VweMjEBeQFg)


:::{#exm-rope}
### Beispiele f√ºr ROPE
Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens $d=100$‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als "praktisch gleich", "praktisch kein Unterschied" bzw. vernachl√§ssigbar.

Bei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g "vernachl√§ssigbar wenig" ist.

Eine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umssatzunterschied von 100k Euro "praktisch irrelevant" sei. $\square$
:::



Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer *Nullhypothese*: $H_0$.
Die Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte.
Diesen Bereich bezeichnen wir den *Indifferenzbereich* (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder *Region of practical equivalence*, Rope). 
Jetzt pr√ºfen wir, ob ein "Gro√üteil" der Posteriori-Stichproben im Rope liegt.
Unter "Gro√üteil" wird h√§ufig das *95%-HDI* verstanden (das ist auch der Standard der R-Funktion `rope()`, die wir hier nutzen).







*Entscheidungsregel* nach @kruschke2018:
  
- Gro√üteil liegt *innerhalb* von Rope  ‚û°Ô∏è *Annahme* der Nullhypothese "praktisch kein Effekt", $H_0$
- Gro√üteil liegt *au√üerhalb* von Rope  ‚û°Ô∏è *Ablehnung* der Nullhypothese "praktisch kein Effekt", $H_0$
- Ansonsten  ‚û°Ô∏è  keine Entscheidung 


Mit "Gro√üteil" meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).

### Vernachl√§ssigbarer Regressionseffekt

@kruschke2018 schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als "praktisch Null" zu bezeichnen:



Wenn eine Ver√§nderung √ºber "praktisch den ganzen Wertebereich" von $x$ nur einen vernachl√§ssigbaren Effekt auf $y$ hat.
Ein vernachl√§ssigbarer Effekt ist dabei $\hat{y}= \pm 0.1 sd_y$.
Der "praktisch ganze Wertebereich" von $x$ sei $\bar{x} \pm 2 sd_x$.
Resultiert der Vergleich von $\bar{x} -2 sd$ mit $\bar{x}+2sd$ nur eine Ver√§nderung in $\hat{y}$ von $\bar{y} - 0.1sd_y$ auf $\bar{y} + 0.1 sd_y$, so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar.
Das impliziert Rope-Grenzen von $\beta_x = \pm 0.05$ f√ºr z-standardisierte Variablen.

:::{.callout-note}
### ROPE-Defaults
Im der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±5% der SD der AV. $\square$
:::



### HDI-Rope-Entscheidungsregel visualisiert

```{r out.width="100%"}
#| echo: false
#| fig-align: "center"
#| fig-cap: "Die Entscheidungsregeln zum ROPE illustiert."
#| label: fig-kruschke-rope
knitr::include_graphics("img/Kruschke-2018-Fig1.png")
```

@fig-kruschke-rope illustriert die Entscheidungsregel zum ROPE 
f√ºr mehrere Situatioenen [@kruschke2018, Abbildung 1, S. 272]:
  
- Liegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.
- Liegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.
- Ansonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.



### Rope berechnen

Hier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (`m10.6`).

```{r}
m10.6 <- stan_glm(body_mass_g ~ species, 
                  data = penguins, 
                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
                  seed = 42  # zur Reproduzierbarkeit
                  )
```

Den Rope berechnet man mit `rope(model)`.

```{r}
rope(m10.6)
```

Die Faktorstufe `Chinstrap` von `species` hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. 
Wir k√∂nnen daher f√ºr diese Gruppe  das ROPE *nicht* verwerfen. 
Die Datenlage ist *unklar*. 
Es ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.

Aber: `Gentoo` liegt zu 0% im Rope. F√ºr Gentoo k√∂nnen wir das Rope *verwerfen*.



:::callout-note
Die angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. `help(rope)`.
:::
  

Das h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®


### Visualisierung unserer Rope-Werte, m10.6
  
Ein Gro√üteil der Posteriori-Masse von `m10.6` liegt  *nicht* innerhalb des Rope. 
Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. @fig-rope-penguins.

```{r}
#| eval: false
rope(m10.6) %>% plot()
```


```{r}
#| label: fig-rope-penguins
#| layout-ncol: 2
#| echo: false
#| fig-cap: "Rope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie."
#| fig-subcap: 
#|   - "Diagramm mit `rope(m10.6) %>% plot()`"
#|   - "Diagramm mit `parameters(m10.6) %>% plot()`"
plot(rope(m10.6)) + scale_fill_okabeito()

parameters(m10.6) %>% 
  plot() +
  geom_rect(aes(xmin = 0-80, xmax = 0+80, ymin = -Inf, ymax = Inf), 
              fill = "blue", alpha = 0.2, color = NA)
```


Das ROPE druchkreuzt die "Berge" der Posteriori-Verteilung f√ºr Chinstrap deutlich.
Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope.
Wir k√∂nnen das Nullhypothese f√ºr Chinstrap *nicht verwerfen*, aber auch *nicht best√§tigen*.

Gentoo hingegen wird vom vom Rope nicht durchkreuzt, 
es ist weit entfernt vom "blauen Fluss" des Rope: Gentoo liegt au√üerhalb des Rope. 
Es gibt einen "substanziellen" Unterschied, gr√∂√üer als das ROPE. 
Wir verwerfen die "Praktisch-Null-Hypothese" in diesem Fall.








### Finetuning des Rope

Wir k√∂nnen festlegen, was wir unter "praktischer √Ñquivalenz" verstehen,
also die Grenzen des Ropes ver√§ndern.
Sagen wir, 100 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. @fig-rope-range.


```{r echo = TRUE, results="hide"}
#| label: fig-rope-range
#| fig-cap: ROPE mit selber eingestellter Grenze von ¬±100 (Gramm)
rope(m10.6, range = c(-100, 100))
plot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()
```






Im Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:
  
```{r echo=TRUE, eval = FALSE}
rope(m10.6, range = c(-100,100), ci = .89, ci_method = "ETI")
```

`ETI` (equal tails interval) steht f√ºr ein PI.
Jetzt wird berichtet, welcher Teil eines 89%-CI^[89 ist die n√§chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. Damit ist 95 hier eine "magic number", ein Defacto-Standard ohne hinreichende Begr√ºndung. Um darauf hinzuweisen, benutzen einige Forschis mit √§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ] sich im Rope befindet.






### Beantwortung der Forschungsfrage


F√ºr die Spezeis *Gentoo* wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, *Adelie*, vom Modell entdeckt. F√ºr *Chinstrap* hingegen  ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.












## Modellg√ºte 













### Wozu Modellg√ºte?

Hat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, 
m√∂chte man wissen, wie belastbar diese Ergebnisse sind.
Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. 
Diese Kennwerte zielen z.B. darauf ab, wie *pr√§zise* die Aussagen des Modells sind. 
Je pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich.
Bei einer Parametersch√§tzung erh√§lt man  auch Informationen zur Pr√§zision der Sch√§tzung:
Ist der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa).
Allerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. 
Da kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.

Im Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, $R^2$.


### Modellg√ºte mit $R^2$ bestimmen



$R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt.
- H√∂here Wert von $R^2$ bedeuten, dass das Modell die Daten besser erkl√§rt.
$R^2$ wird normalerweise auf Basis eines Punktsch√§tzers definiert.
Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor.
Daher ist es w√ºnschenswert, diese Information in $R^2$ einflie√üen zu lassen: *Bayes-R-Quadrat*.





<!-- R^2_{Bayes} = \frac{\text{erkl√§rte Varianz}}{\text{erk√§rte Varianz + Residualvarianz}} = \frac{var_{fit}}{var_{fit}+var_{res}} -->
  
  <!-- - $var_{fit}$ ist die Varianz der vorhergesagten Sch√§tzwerte $\hat{y}_i$. -->
  


<!-- ```{r echo = TRUE} -->
<!-- r2(m10.6) -->
<!-- ``` -->


M√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen,
so kann man sich die Posteriori-Verteilung von $R2$ ausgeben lassen, s. @fig-m106-r2.

```{r}
#| fig.cap: "Die Verteilung von R-Quadrat im Modell m10.6"
#| label: fig-m106-r2
m10.6_r2 <-
  m10.6 %>% 
  r2_posterior() %>% 
  as_tibble()

hdi(m10.6_r2) %>% 
  plot()
```




### Definition vom "klassischen" $R^2$




Wie genau sind die Vorhersagen des Modells? $\sigma$ (Vorhersagefehler) quantifiziert die Streuung der Residuen $r_i = y_i - X_i\hat{\beta}$, mit $\hat{y}_i = X_i\hat{\beta}$. 
Anders gesagt: $\hat{y} = \beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots = X\hat{\beta}$.
Anders gesagt gibt $\sigma$ die "typische" Abweichung einer Beobachtung vom vorhergesagten Wert an.
Es ist n√ºtzlich, $\sigma$ in Bezug zu setzen zur Streuung der AV, $sd_y=s_y$:
  $R^2 = 1- (\hat{\sigma}^2/s^2_y)$.
$R2$ gibt damit den Anteil der vom Modell erkl√§rten Varianz, $V$, an.
Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck √§quivalent zu:
  $R^2=V_{i=1}^n \hat{y}_i/s_y^2$
  Die beiden obigen Ausdr√ºcke nehmen $\hat{y}_i$ als fix (sicher) an und vernachl√§ssigen Ungewissheit; sie sind √ºbergewiss aus Bayes-Sicht.




### Bayes' $R^2$

Besser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellg√ºte miteinzubeziehen:
  $\text{Bayes }R^2 = \frac{\text{erk√§rte Varianz}}{\text{Erkl√§rte Varianz + Residualvarianz}}= \frac{V_{mod}}{V_{mod} + V_{res}}$.

$V_{mod}$ ist die Varianz in der PPV mit $s = 1, \ldots, S$ simulierten Stichproben, $V(\hat{y}_i)$ und $V_{res}$ ist die Residualvarianz im Modell.
F√ºr jede Stichprobe $s$ berechnet man die vorhergesagten Werte, $\hat{y}_i^s$, die Residualvarianz $\sigma^2_s$ und den Anteil der erkl√§rten Varianz:
  $\text{Bayes }R^2_s = \frac{V(\hat{y}_i^s)}{V(\hat{y}_i^s+\sigma_s^2)}$, vgl. 
@gelman2019, @gelman2021, Kap. 11.7.






## Fazit

Obwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. 
M√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.


## Aufgaben


1. [Wskt-Schluckspecht](https://sebastiansauer.github.io/Datenwerk/posts/wskt-schluckspecht/wskt-schluckspecht)
2. [wskt-mtcars-1l](https://sebastiansauer.github.io/Datenwerk/posts/wskt-mtcars-1l/wskt-mtcars-1l.html)
2. [rope-regr](https://sebastiansauer.github.io/Datenwerk/posts/rope-regr/rope-regr.html)
3. [rope1](https://sebastiansauer.github.io/Datenwerk/posts/rope1/rope1.html)
3. [rope2](https://sebastiansauer.github.io/Datenwerk/posts/rope2/rope2.html)
3. [rope3](https://sebastiansauer.github.io/Datenwerk/posts/rope3/rope3.html)








