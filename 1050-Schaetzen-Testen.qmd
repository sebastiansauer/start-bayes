


# Sch√§tzen vs. Testen


<!-- TODO Dieses Kapitel ist sehr kurz. -->


## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.




### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen... 

- den Unterschied zwischen dem *Sch√§tzen* von Modellparametern und dem *Testen* von Hypothesen erl√§utern
- Vor- und Nachteile des Sch√§tzens und Testens diskutieren
- Das ROPE-Konzept erl√§utern und anwenden
- Die G√ºte von Regressionsmodellen einsch√§tzen und berechnen


### Begleitliteratur

Der Stoff dieses Kapitels orientiert sich an @kruschke2018.


### Vorbereitung im Eigenstudium

- [Statistik1, Kap. "Geradenmodelle 2"](https://statistik1.netlify.app/090-regression2)




### R-Pakete

In diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.

```{r}
#| message: false
#| results: "hide"
#| warning: false
library(rstanarm)   # Bayes-Modelle
library(tidyverse)
library(easystats)
library(palmerpenguins)  # Datensatz "penguins"
```



```{r libs-hidden}
#| include: false
library(icons)
library(gt)
library(ggridges)
library(plotly)
library(patchwork)
library(plotly)
library(dagitty)

theme_set(theme_modern())
```



### Ben√∂tigte Daten: Pinguine


![Possierlich: Die Pinguine [@horst_statistics_2024]](img/penguins.png){#fig-penguins width="50%"}

:::{#exr-peng-start}
### Machen Sie sich mit den Pinguinen vertraut

Machen Sie sich zun√§chst mit dem Pinguin-Datensatz vertraut. 
Sie finden den Datensatz `penguins` im R-Paket `palmerpenguins`, 
das Sie auf gewohnte Art installieren k√∂nnen.
im Internet findet man den Datensatz auch als CSV-Datei; s. unten.
Importieren Sie den Datensatz und verschaffen Sie sich einen √úberblick √ºber 
die Verteilungen jeder Variablen des Datensatzes.
:::



```{r import-penguins}
#| results: "hide"
#| message: false
#| eval: false
penguins_url <- "https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv"

penguins <- read.csv(penguins_url)
```

{{< downloadthis data/penguins.csv dname="penguins" >}}



```{r}
data("penguins", package = "palmerpenguins")
```

Beide M√∂glichkeit des Datenimports sind okay. $\square$


### Einstieg

Betrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:


1. "Lernen f√ºr die Klausur bringt etwas!"
2. "Wie viel bringt Lernen f√ºr die Klausur?"


:::{#exm-schaetzen-testen}
Diskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! Einmal Behauptung, einmal Frage -- was macht das f√ºr einen Unterschied? $\square$
:::



## Sch√§tzen oder Testen?


Forschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:

1. *Hypothesen testen*: "Die Daten widerlegen die Hypothese (nicht)"
2. *Parameter sch√§tzen*: "Der Effekt von X auf Y liegt zwischen A und B".

### Hypothesen testen

Hypothesen testende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. 
Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage.
Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, 
dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.

:::{#exm-lernen-hyp}
### "Lernen erh√∂ht den Pr√ºfungserfolg"
Die Hypothese *Lernen erh√∂ht den Pr√ºfungserfolg* kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden.
1) Die Daten widersprechen der Hypothese: 
Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 
2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg.
3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. $\square$
:::

Das Testen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. 
Die ersten beiden sind informationsreich, die dritte ist informationsarm.

1. üü• Die Daten *widersprechen* der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), 
also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.

2. üü¢ Die Daten *unterst√ºtzen* die Hypothese: 
Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). 
Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.

3. ‚ùì Die Datenlage ist *unklar*; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. 
Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. 
In diesem Fall gibt es keinen Erkenntnisgewinn.


Hypothesen pr√ºfen ist *bin√§r* in dem Sinne, dass sie zu "Schwarz-Wei√ü-Ergebnissen" f√ºhren (sofern die Datenlage stark genug ist).

:::{.callout-important}
Eine g√§ngige Variante des Hypothesen testen^[vor allem in der Frequentistischen Statistik] 
ist das Testen der Hypothese "Es liegt kein (null) Effekt vor" (Null Effekt).
Man geht also davon aus, dass es keinen Zusammenhang zwischen UV und AV gibt und
spricht vom *Nullhypothesen testen*, $H_0$. $\square$
:::

:::{.exm-null}
### Beispiele f√ºr Nullhypothesen

- "Lernen bringt nichts"
- "Frauen und M√§nner parken gleich schnell ein"
- "Es gibt keinen Zusammenhang von Babies und St√∂rchen"
- "Fr√ºher war es auch nicht besser (sondern gleich gut)"
- "Bei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern" (Null Unterschied zwischen den Geschlechtern) $\square$
:::


*Vorteil* des Hypothesen testen ist das klare, einfache Ergebnis --
die Hypothese ist abgelehnt, angenommen, oder die Datenlage ist unklar.
Das unterst√ºtzt die Entscheidungsfindung, da es die Komplexit√§t reduziert.


:::callout-note
### Man kann Hypothesen nicht best√§tigen
Karl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann, hat gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt [@popper2013].
Schlagend ist das Beispiel zur Hypothese "Alle Schw√§ne sind wei√ü". 
Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. Schlie√ülich ist es m√∂glich, 
dass wir den schwarzen Schwan einfach noch nicht gefunden haben.
^[Tats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: <https://en.wikipedia.org/wiki/Black_swan>]
Umgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, 
um die Hypothese zu widerlegen (falsifizieren). $\square$
:::


:::{.callout-note}
### Wirklich nicht?
In der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. 
Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht.
Das bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist.
Auf dieser Basis und der Basis zuverl√§ssiger, 
repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als auch widerlegt werden k√∂nnen [@kruschke2018; @morey2011]. $\square$
:::

### Parameter sch√§tzen

Beim Sch√§tzen von Parametern untersucht man, *wie gro√ü* ein Effekt ist, 
etwa der Zusammenhang zwischen X und Y.
Es geht also um eine Skalierung, um ein *wieviel* und nicht um ein "ja/nein", 
was beim Hypothesen testen der Fall ist.

Beim Parameter sch√§tzen gibt es zwei Varianten:

a) ‚ö´Ô∏è Punktsch√§tzung: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein "Best Guess"

b) üìè Bereichssch√§tzung: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte

Allerdings kann man das Sch√§tzen von Parameterns auch wie einen Hypothesentest verstehen:
Ist ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.


:::{#exm-pinguins}

Wie gro√ü ist der Sch√§tzbereich f√ºr den Effekt des Parameter "Geschlecht" auf das mittlere Gewicht von Pinguinen? 
Hat die UV *Geschlecht* einen gro√üen Einfluss auf das mittlere Gewicht dieser Tiere?
Anders gefragt: Um welchen Wert sind m√§nnliche Tiere im Schnitt schwerer als weibliche Tiere?

```{r}
#| results: hide
data(penguins, package = "palmerpenguins")
penguins_nona <-
  penguins |> drop_na(sex, body_mass_g)  # keine fehlenden Werte

m_penguins_sex <- 
  stan_glm(body_mass_g ~ sex, data = penguins_nona)
```

```{r}
#| echo: false
parameters(m_penguins_sex) |> print_md()
```

Grob gesagt sind m√§nnliche Tiere ca. 500 g bis 800 g schwerer als weibliche Tiere im Schnitt (95%-ETI), 
laut unserem Modell; der Punktsch√§tzer liegt bei einem Gewichtsunterschied von ca. `r round(as.numeric(coef(m_penguins_sex)[2]))` g $\square$
:::

:::{#exm-param-hyptest}
### Parametersch√§tzen als Nullhypothesentest

>   Forschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?

@thm-muf-mum formalisiert diese Forschungsfrage als statistische Hypothese $H$.

:::{#thm-muf-mum}

### Nullhypothesentest

$$H: \mu_M \ge \mu_F \leftrightarrow d = \mu_M - \mu_F \ge 0\quad \square$$
:::

Der Unterschied zwischen den Mittelwerten, $d$, ist genau dann Null, wenn $\beta_1$ in unserem Regressionsmodell `m1` gleich Null ist.
Entsprechend gilt $d \ne 0$ wenn $\beta_1 \ne 0$.


```{r}
m1 <- stan_glm(
  body_mass_g ~ sex, 
  data = penguins, 
  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
  seed = 42  # zur Reproduzierbarkeit
)
```

Um die Forschungsfrage zu beantworten z√§hlen wir wie gewohnt den Anteil der Stichproben 
in der Post-Verteilung f√ºr die UV `sexmale`, die einen Wert gr√∂√üer Null aufweisen:

```{r}
m1_post <-
  m1 |> 
  as_tibble()

m1_post |> 
  count(sexmale < 0)
```
100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr `sexmale`, 
dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind (im Durchschnitt).
Entsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht (das weibliche Tiere schwerer w√§ren).
Damit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: $p_H = 1$.
Achtung: Die 100%-ige Sicherheit f√ºr die Hypothese stammt aus der kleinen Welt,
nicht unbedingt aus der gro√üen welt.
$\square$
:::



*Vorteil* der Parametersch√§tzung (gegen√ºber dem Testen von Hypothesen) ist die Nuanciertheit des Ergebnisses, 
die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.





## ROPE: Bereich von "praktisch Null"  {#sec-rope}


üì∫ [Teil 2](https://youtu.be/k-CB0VGRENY)




Nullhypothesen sind fast immer falsch, s. @fig-nullmeme.


```{r meme-null}
#| echo: false
#| label: fig-nullmeme
#| fig-cap: "Du testest Nullhypothesen?"
knitr::include_graphics("img/5v5531.jpg")
```

[Quelle: Imgflip Meme Generator](https://imgflip.com/i/5v5531)







>   We do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have *some* effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. [@gelman2021]






### Alternativen zu Nullhypothesen


Nullhypothesen, $H_0$, sind z.B.: $\rho=0$, $\rho_1 = \rho_2$, $\mu_1 = \mu_2$, $\mu=0$, $\beta_1=0$.
Nullhypothesen zu testen, ist sehr verbreitet.
Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest (einfach) m√∂glich ist.^[Mittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.]
Ein anderer Grund ist vermutlich, ... wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è
Alternativen zum Testen von Nullhypothesen sind: 
  
- Posteriori-Intervalle (ETI oder HDI) berichten
- *Rope*-Konzept [@kruschke2018]
- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren (z.B. dass $\beta_1 > 0.42$)
- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat (*probability of direction, pd*)






### "Praktisch kein Unterschied": Das Rope-Konzept


üì∫ [ROPE-Video](https://www.youtube.com/watch?v=VweMjEBeQFg)


:::{#exm-rope}
### Beispiele f√ºr ROPE

- Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens $d=100$‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr einen Marketingmanager als "praktisch gleich", "praktisch kein Unterschied",
"nicht substanziell", "unbedeutend" bzw. "vernachl√§ssigbar gering"

- Bei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100 g K√∂rpergewicht "vernachl√§ssigbar wenig" ist.

- Eine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umsatzunterschied von 100k Euro "praktisch irrelevant" sei. $\square$
:::



Wie legt man den Grenzwert $d$ fest,
bis zu dem ein Unterschied (*D*ifferenz) gerade noch bzw. gerade nicht mehr
unbedeutend ist?
Die Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte.
Diesen Bereich bezeichnen wir den *Indifferenzbereich* (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder *Region of practical equivalence*, Rope). 


Jetzt pr√ºfen wir, ob ein "Gro√üteil" der Posteriori-Stichproben im Rope liegt.
Unter "Gro√üteil" wird h√§ufig das *95%-HDI* verstanden (das ist auch der Standard der R-Funktion `rope()`, die wir hier nutzen).







*Entscheidungsregel* nach @kruschke2018:
  
- Gro√üteil der Post-Verteilung liegt *innerhalb* von Rope $\rightarrow$ *Annahme* der Nullhypothese "praktisch kein Effekt", $H_0$
- Gro√üteil der Post-Verteilung liegt *au√üerhalb* von Rope $\rightarrow$ *Ablehnung* der Nullhypothese "praktisch kein Effekt", $H_0$
- Ansonsten $\rightarrow$ keine Entscheidung 


Mit "Gro√üteil" meinen wir (per Default) das 95%-KI (der Posteriori-Verteilung).

### Vernachl√§ssigbarer Regressionseffekt

@kruschke2018 schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als "praktisch Null" zu bezeichnen:



Wenn eine Ver√§nderung √ºber "praktisch den ganzen Wertebereich" von $x$ nur einen vernachl√§ssigbaren Effekt auf $y$ hat.
Ein vernachl√§ssigbarer Effekt ist dabei $\hat{y}= \pm 0.1 sd_y$.
Der "praktisch ganze Wertebereich" von $x$ sei $\bar{x} \pm 2 sd_x$.
Resultiert der Vergleich UV von $\bar{x} -2 sd$ mit $\bar{x}+2sd$ nur in einer Ver√§nderung von $\hat{y}$ (der AV) von $\bar{y} - 0.1sd_y$ auf $\bar{y} + 0.1 sd_y$, so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar.
Das impliziert Rope-Grenzen von $\beta_x = \pm 0.1$ f√ºr z-standardisierte UV und AV.
Einfach gesprochen: Eine vern√ºnftige Voreinstellung f√ºr die Rope-Grenzen sind $\pm 10 \%$ der SD der AV. 

:::{.callout-note}
### ROPE-Defaults
Im der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±10% der SD der AV. $\square$
:::



### HDI-Rope-Entscheidungsregel visualisiert

```{r out.width="100%"}
#| echo: false
#| fig-align: "center"
#| fig-cap: "Die Entscheidungsregeln zum ROPE illustiert [@kruschke2018]; A: Verwerfen der ROPE-Hypothese; B und C: Akzeptieren; D-F: Unklare Datenlage, keine Entscheidung zur ROPE-Hypothese"
#| label: fig-kruschke-rope
knitr::include_graphics("img/Kruschke-2018-Fig1.png")
```

@fig-kruschke-rope illustriert die Entscheidungsregel zum ROPE 
f√ºr mehrere Situationen [@kruschke2018, Abbildung 1, S. 272]:
  
- Liegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.
- Liegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.
- Ansonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.



### Rope berechnen

Hier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (`m_penguins_species`).

```{r}
m_penguins_species <- stan_glm(body_mass_g ~ species, 
                  data = penguins, 
                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
                  seed = 42  # zur Reproduzierbarkeit
                  )
```

Den Rope berechnet man mit `rope(model)`, s. @tbl-peng-species-rope.

```{r}
#| echo: false
#| label: tbl-peng-species-rope
#| tbl-cap: "Der Rope-Bereich f√ºr die Stufen der UV (Arten von Pinguinen)"
rope(m_penguins_species)
```

Die Faktorstufe `Chinstrap` von `species` hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. 
Wir k√∂nnen daher f√ºr diese Gruppe  das ROPE *nicht* verwerfen. 
Die Datenlage ist *unklar*. 
Es ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.

Aber: `Gentoo` liegt zu 0% im Rope. 
F√ºr die Gruppe *Gentoo* k√∂nnen wir die ROPE-Hypothese *verwerfen*.
Der Effekt von *Gentoo* ist gr√∂√üer als vernachl√§ssigbar.
Anders gesagt: Tiere der Art *Gentoo* sind im Schnett substanziell schwerer als Tiere der Referenzgruppe (*Adelie*).
Der ROPE-Grenzwert wurde hier per Voreinstellung auf 80 g Unterschied festgelegt (10% der SD der AV).



:::callout-note
Die angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. `help(rope)`.
:::
  

Das h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®


### Visualisierung unserer Rope-Werte, m_penguins_species
  
Ein Gro√üteil der Posteriori-Masse von `m_penguins_species` liegt  *nicht* innerhalb des Rope. 
Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. @fig-rope-penguins.

```{r}
#| eval: false
rope(m_penguins_species) %>% plot()
```


```{r}
#| label: fig-rope-penguins
#| layout-ncol: 2
#| echo: false
#| fig-cap: "Rope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie."
#| fig-subcap: 
#|   - "Diagramm mit `rope(m_penguins_species) %>% plot()`"
#|   - "Diagramm mit `parameters(m_penguins_species) %>% plot()`"
plot(rope(m_penguins_species)) + scale_fill_okabeito()

parameters(m_penguins_species) %>% 
  plot() +
  geom_rect(aes(xmin = 0-80, xmax = 0+80, ymin = -Inf, ymax = Inf), 
              fill = "blue", alpha = 0.2, color = NA)
```


Das ROPE druchkreuzt die "Berge" der Posteriori-Verteilung f√ºr *Chinstrap* deutlich.
Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope.
Wir k√∂nnen das Nullhypothese f√ºr Chinstrap *nicht verwerfen*, aber auch *nicht best√§tigen* --
eine unklare Datenlage.

*Gentoo* hingegen wird vom vom Rope nicht durchkreuzt, 
es ist weit entfernt vom "blauen vertikalen Band" des Rope: Gentoo liegt au√üerhalb des Rope. 
Es gibt einen "substanziellen" Unterschied
zwischen dem Mittelwert der AV in Gruppe Gentoo und in der Referenzgruppe Adelie.

Wir verwerfen die ROPE-Hypothese, die "Praktisch-Null-Hypothese", in diesem Fall.








### Finetuning des Rope

Wir k√∂nnen festlegen, was wir unter "praktischer √Ñquivalenz" verstehen,
also die Grenzen des Ropes ver√§ndern.
Sagen wir, 200 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. @fig-rope-range.


```{r echo = TRUE, results="hide"}
#| label: fig-rope-range
#| fig-cap: ROPE mit selber eingestellter Grenze von ¬±200 (Gramm)
rope(m_penguins_species, range = c(-200, 200))
plot(rope(m_penguins_species, range = c(-200, 200))) + 
  scale_fill_okabeito()  # sch√∂nes Farbschmea
```






In der Voreinstellung werden 95%-ETI berichtet, das kann man so √§ndern, wenn man m√∂chte:
  
```{r echo=TRUE, eval = FALSE}
rope(m_penguins_species, range = c(-100,100), ci = .89, ci_method = "HDI")
```

`ETI` (equal tails interval) steht f√ºr ein ETI.
Jetzt wird berichtet, welcher Teil eines 89%-CI^[89 ist die n√§chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. 
Damit ist 95 hier eine "magic number", ein Defacto-Standard ohne hinreichende Begr√ºndung. Um darauf hinzuweisen, benutzen einige Forscherinnen und Forscher mit √§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ] sich im Rope befindet.






### Beantwortung der Forschungsfrage


F√ºr die Spezeis *Gentoo* wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, *Adelie*, vom Modell entdeckt. F√ºr *Chinstrap* hingegen  ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.












## Modellg√ºte 













### Wozu Modellg√ºte?

Hat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, 
m√∂chte man wissen, wie belastbar diese Ergebnisse sind.
Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. 
Diese Kennwerte zielen z.B. darauf ab, wie *pr√§zise* die Aussagen des Modells sind. 
Je pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich.
Bei einer Parametersch√§tzung erh√§lt man  auch Informationen zur Pr√§zision der Sch√§tzung:
Ist der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa).
Allerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. 
Da kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.
Im Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, $R^2$.


### Modellg√ºte mit $R^2$ bestimmen



$R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt.
- H√∂here Wert von $R^2$ bedeuten, dass das Modell die Daten besser erkl√§rt.
$R^2$ wird normalerweise auf Basis eines Punktsch√§tzers definiert.
Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor.
Daher ist es w√ºnschenswert, diese Information in $R^2$ einflie√üen zu lassen: *Bayes-R-Quadrat*.






M√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen,
so kann man sich die Posteriori-Verteilung von $R^22$ ausgeben lassen, s. @fig-m106-r2.

```{r}
#| fig.cap: "Die Verteilung von R-Quadrat im Modell m_penguins_species"
#| label: fig-m106-r2
m_penguins_species_r2 <-
  m_penguins_species %>% 
  r2_posterior() %>% 
  as_tibble()

hdi(m_penguins_species_r2) %>%  # Intervallgrenzen der Post-Verteilung von R2
  plot()  # visualisieren
```

$R^2$ und $\sigma$ sind negativ assoziiert: 
In einem Datensatz mit mit hohem $R^2$ ist $\sigma$ gering und umgekehrt.
Beide Koeffizienten berechnen sich auf Basis von $\sigma$.
Im Unterschied zum Frequentistischen R-Quadrat erh√§lt man in der Bayes-Statistik
nicht nur einen Punktsch√§tzer f√ºr $R^ 2$, sondern wie auch sonst eine Post-Verteilung,
so dass man z.B. einen Sch√§tzbereich angeben kann.

Schneller bekommt man den Punkt- und den Intervallsch√§tzer f√ºr $R^2$ mit `r2(m_penguins_species)`.

```{r}
#| echo: false
r2(m_penguins_species)
```






## Fazit

Obwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. 
M√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.


## Aufgaben


### Papier-und-Bleistift-Aufgaben


1. [rope-luecke](https://datenwerk.netlify.app/posts/rope-luecke/index.html)
2. [penguins-rope](https://datenwerk.netlify.app/posts/penguins-rope/)
1. [Wskt-Schluckspecht2](https://datenwerk.netlify.app/posts/wskt-schluckspecht2/index.html)
2. [penguins-stan-01a](https://datenwerk.netlify.app/posts/penguins-stan-01a/index.html)
2. [rope-regr](https://datenwerk.netlify.app/posts/rope-regr/rope-regr.html)
3. [rope1](https://datenwerk.netlify.app/posts/rope1/rope1.html)
4. [rope2a](https://datenwerk.netlify.app/posts/rope2a/)
4. [rope3a](https://datenwerk.netlify.app/posts/rope3a/)
5. [penguins-stan-04a](https://datenwerk.netlify.app/posts/penguins-stan-04a/index.html)
6. [stan_glm01a](https://datenwerk.netlify.app/posts/stan_glm01a/)
7. [penguins-regr02a](https://datenwerk.netlify.app/posts/penguins-regr02a/)
8. [penguins-stan-02a](https://datenwerk.netlify.app/posts/penguins-stan-02a/)
9. [penguins-stan-05a](https://datenwerk.netlify.app/posts/penguins-stan-05a/penguins-stan-05a.html)

### Computer-Aufgaben

1. [Wskt-Schluckspecht](https://datenwerk.netlify.app/posts/wskt-schluckspecht/wskt-schluckspecht)
2. [wskt-mtcars-1l](https://datenwerk.netlify.app/posts/wskt-mtcars-1l/wskt-mtcars-1l.html)
3. [rope2](https://datenwerk.netlify.app/posts/rope2/rope2.html)
3. [rope3](https://datenwerk.netlify.app/posts/rope3/rope3.html)








