


# Sch√§tzen vs. Testen



## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.




### Lernziele

<!-- TODO hier keine √ºberschriftne der Ebene 3 -->

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen... 

- den Unterschied zwischen dem *Sch√§tzen* von Modellparametern und dem *Testen* von Hypothesen erl√§utern
- Vor- und Nachteile des Sch√§tzens und Testens diskutieren
- Das ROPE-Konzept erl√§utern und anwenden
- Die G√ºte von Regressionsmodellen einsch√§tzen und berechnen


### Begleitliteratur

Der Stoff dieses Kapitels orientiert sich an [@kruschke2018].


### Vorbereitung im Eigenstudium

- [Statistik1, Kap. "Geradenmodelle 2"](https://statistik1.netlify.app/090-regression2)




### R-Pakete

In diesem Kapitel werden folgende R-Pakete ben√∂tigt:

```{r}
#| message: false
#| results: "hide"
#| warning: false
library(rstanarm)   # Bayes-Modelle
library(tidyverse)
library(easystats)
library(palmerpenguins)  # Datensatz "penguins"
```



```{r libs-hidden}
#| include: false
library(icons)
library(gt)
library(ggridges)
library(plotly)
library(patchwork)
library(plotly)
library(dagitty)

theme_set(theme_modern())
```



### Ben√∂tigte Daten: Pinguine


![Possierlich: Die Pinguine [@horst_statistics_2024]](img/penguins.png){#fig-penguins width="50%"}

:::{#exr-peng-start}
Machen Sie sich zun√§chst mit dem Pinguin-Datensatz vertraut. 
Sie finden den Datensatz `penguins` im R-Paket `palmerpenguins`, 
das Sie auf gewohnte Art installieren k√∂nnen.
im Internet findet man den Datensatz auch als CSV-Datei; s. unten.
Importierne Sie den Datensatz und verschaffen Sie sich einen √úberblick √ºber 
die Verteilungen jeder Variablen des Datensatzes.


Sie k√∂nnen den Datensatz `penguins` entweder via dem Pfad importieren:



```{r import-penguins}
#| results: "hide"
#| message: false
#| eval: false
penguins_url <- "https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv"

penguins <- read.csv(penguins_url)
```

{{< downloadthis data/penguins.csv dname="penguins" >}}


Oder via dem zugeh√∂rigen R-Paket:

```{r}
data("penguins", package = "palmerpenguins")
```

Beide M√∂glichkeit des Datenimports sind okay. $\square$


### Einstieg

Betrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:


1. "Lernen f√ºr die Klausur bringt etwas!"
2. "Wie viel bringt Lernen f√ºr die Klausur?"


:::{#exm-schaetzen-testen}
Diskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! Einmal Behauptung, einmal Frage -- was macht das f√ºr einen Unterschied? $\square$
:::



## Was ist Sch√§tzen? Was ist Testen?


Forschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:

1. *Hypothesen testen*: "Die Daten widerlegen die Hypothese (nicht)"
2. *Parameter sch√§tzen*: "Der Effekt von X auf Y liegt zwischen A und B".

### Hypothesen testen

Hypothesen testende Analysen kommen zu einer Ja-Nein-Entscheidung bzgl. einer Hypothese. 
Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage.
Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, 
dass man ehrlicherweise zugeben muss, 
dass man sich nicht sicher ist oder sogar komplett im Dunkeln tappt.

:::{#exm-lernen-hyp}
### "Lernen erh√∂ht den Pr√ºfungserfolg!"
Die Hypothese *Lernen erh√∂ht den Pr√ºfungserfolg* kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden.
1) Die Daten widersprechen der Hypothese: 
Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 
2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg.
3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. $\square$
:::

Das Testen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. 
Die ersten beiden sind informationsreich, die dritte ist informationsarm.

1. üü• Die Daten *widersprechen* der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), 
also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.

2. üü¢ Die Daten *unterst√ºtzen* die Hypothese: 
Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). 
Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.

3. ‚ùì Die Datenlage ist *unklar*; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. 
Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. 
In diesem Fall gibt es keinen (nennenswerten) Erkenntnisgewinn.


Hypothesen pr√ºfen ist *bin√§r* in dem Sinne, dass sie zu "Schwarz-Wei√ü-Ergebnissen" f√ºhren (sofern die Datenlage stark genug ist).

:::{.callout-important}
Eine g√§ngige Variante des Hypothesen testen^[vor allem in der Frequentistischen Statistik] 
ist das Testen der Hypothese "Es liegt kein (null) Effekt vor" (Null Effekt).
Man geht also davon aus, dass es keinen Zusammenhang zwischen UV und AV gibt und
spricht vom *Nullhypothesen testen*, $H_0$. $\square$
:::

:::{.exm-null}
### Beispiele f√ºr Nullhypothesen

- "Lernen bringt nichts"
- "Frauen und M√§nner parken gleich schnell ein"
- "Es gibt keinen Zusammenhang von Babies und St√∂rchen"
- "Fr√ºher war es auch nicht besser (sondern gleich gut)"
- "Bei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern" (Null Unterschied zwischen den Geschlechtern) $\square$
:::


*Vorteil* des Hypothesen testen ist das klare, einfache Ergebnis --
die Hypothese ist abgelehnt, angenommen, oder die Datenlage ist unklar.
Das unterst√ºtzt die Entscheidungsfindung, da es die Komplexit√§t reduziert.


:::callout-note
### Man kann Hypothesen nicht best√§tigen
Karl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann,
hatte gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt [@popper2013].
Schlagend ist das Beispiel zur Hypothese $H$ "Alle Schw√§ne sind wei√ü". 
Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. 
Schlie√ülich ist es m√∂glich, 
dass wir den schwarzen Schwan einfach noch nicht gefunden haben.
^[Tats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan]
Umgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, 
um die Hypothese $H$ zu widerlegen (falsifizieren). $\square$
:::


:::{.callout-note}
### Wirklich nicht?
In der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. 
Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht.
Das bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne 
tendenziell (d.h.probabilistisch) zu betrachten ist.
Auf dieser Basis und der Basis zuverl√§ssiger, 
repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als 
auch widerlegt werden k√∂nnen [@kruschke2018; @morey2011]. $\square$
:::

### Parameter sch√§tzen

Beim Sch√§tzen von Parametern untersucht man, *wie gro√ü* ein Effekt ist, 
etwa der Zusammenhang zwischen X und Y.
Es geht also um eine Skalierung, um ein *wieviel* und nicht um ein "ja/nein", 
was beim Hypothesen testen der Fall ist.

Beim Parameter sch√§tzen gibt es zwei Varianten:

a) ‚ö´Ô∏è *Punktsch√§tzung*: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein "Best Guess"

b) üìè *Bereichssch√§tzung*: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte

Allerdings kann man das Parameter sch√§tzen auch wie einen Hypothesentest nutzen:
Ist ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, 
so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.
Das Hypothesen testen ist daher (implizit) im Parameter sch√§tzen enthalten.


:::{#exm-pinguins}

Wie gro√ü ist der Sch√§tzbereich f√ºr den Effekt des Parameter "Geschlecht" auf das mittlere Gewicht von Pinguinen? 
Hat die UV *Geschlecht* einen gro√üen Einfluss auf das mittlere Gewicht dieser Tiere?
Anders gefragt: Um welchen Wert sind m√§nnliche Tiere im Schnitt schwerer als weibliche Tiere?
@tbl-m-penguins-sex-params gibt uns die Antwort

```{r}
#| results: hide
data(penguins, package = "palmerpenguins")
penguins_nona <-
  penguins |> drop_na(sex, body_mass_g)  # keine fehlenden Werte

m_penguins_sex <- 
  stan_glm(body_mass_g ~ sex, data = penguins_nona)
```

```{r}
#| echo: false
#| label: tbl-m-penguins-sex-params
#| tbl-cap: "Parametersch√§tzung des Modells m_penguins; der Gewichtssnterschied zwischen den Mittelwerten der Geschlechter betr√§gt etwa 700 g."
parameters(m_penguins_sex) |> print_md()
```

Grob gesagt sind m√§nnliche Tiere ca. 500 g bis 800 g schwerer 
als weibliche Tiere im Schnitt (95%-ETI), 
laut unserem Modell; der Punktsch√§tzer liegt bei einem Gewichtsunterschied von ca. `r round(as.numeric(coef(m_penguins_sex)[2]))` g. $\square$
:::

:::{#exm-param-hyptest}
### Parametersch√§tzen als Nullhypothesentest

>   Forschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?

@eq-muf-mum formalisiert diese Forschungsfrage als statistische Hypothese $H$.

$$H: \mu_M \ge \mu_F \rightarrow d = \mu_M - \mu_F \ge 0$${#eq-muf-mum}



:::{#thm-muf-mum}
### Nullhypothesentest

$$H: \mu_M \ge \mu_F \leftrightarrow d = \mu_M - \mu_F \ge 0\quad \square$$
:::

Der Unterschied zwischen den Mittelwerten, $d$, 
ist genau dann Null, wenn $\beta_1 = 0$ in unserem Regressionsmodell `m1`.
Entsprechend gilt $d \ne 0$ wenn $\beta_1 \ne 0$.




Um die Forschungsfrage zu beantworten z√§hlen wir wie gewohnt den Anteil der Stichproben 
in der Post-Verteilung f√ºr die UV `sexmale`, die einen Wert gr√∂√üer Null aufweisen:

```{r}
m_penguins_sex_post <-
  m_penguins_sex |> 
  as_tibble()

m_penguins_sex_post |> 
  count(sexmale > 0)
```
100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr `sexmale`, 
dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind (im Durchschnitt).
Entsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht 
(das weibliche Tiere schwerer w√§ren).
Damit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: $p_H = 1$.
Achtung: Die 100%-ige Sicherheit f√ºr die Hypothese stammt aus der kleinen Welt,
nicht unbedingt aus der gro√üen welt. 

Einfach noch zeigt uns `parameters(m_penguins_sex)`, wie gro√ü die Wahrscheinlichkeit f√ºr $\beta_1 > 0$ ist,
n√§mlich anhand des Koeffizienten `pd`, s. tbl-m-penguins-sex-params.

Aber das Auslesen der Post-Verteilung erlaubt uns auch, andere Hypothesen zu pr√ºfen,
etwa die Wahrscheinlichkeit der Hypothese, dass der Gewichtsunterschied zwischen 
den Geschlechtern mehr als 500 g betr√§gt.



$\square$
:::



*Vorteil* der Parametersch√§tzung (gegen√ºber dem Testen von Hypothesen) ist die Nuanciertheit des Ergebnisses, 
die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.



:::{#exr-peer-Interpretation-Hyp-testen}
### Interpretation beim Hypothesen testen

Ein Forschungsteam untersucht die Hypothese,
dass hohe Bildschirmzeit mit verringerter Intelligenz bei Kindern einhergeht.
Dazu vergleichen Sie Kinder, die sehr viel Zeit am Tag am Bildschirm verbringen,
mit Kindern, die sehr wenig Zeit am Tag am Bildschirm verbringen (und die im √ºbrigen vergleichbar sind).
Sie finden in ihrer Studie einen Effekt von $95\% KI[-4;-2]$ IQ-Punkten,
zuungunsten der Kinder mit hoher Bildschirmzeit.

Welche Aussage dazu ist korrekt bzw. passt am besten?

A) Die $H_0$ ist als sicher falsch zu verwerfen.
B) Die $H_0$ ist als sicher richtig anzunehmen.
C) Die $H_0$ ist mit 95% Wahrscheinlichkeit richtig.
D) Die $H_0$ ist mit 95% Wahrscheinlichkeit falsch.
E) Die Datenlage ist unklar, es ist keine Entscheidung m√∂glich. $\square$
:::






## ROPE: Bereich von "praktisch Null"  {#sec-rope}


üì∫ [Teil 2](https://youtu.be/k-CB0VGRENY)




Nullhypothesen sind fast immer falsch, s. @fig-nullmeme.


```{r meme-null}
#| echo: false
#| label: fig-nullmeme
#| fig-cap: "Du testest EXAKTE Nullhypothesen?"
knitr::include_graphics("img/5v5531.jpg")
```

[Quelle: Imgflip Meme Generator](https://imgflip.com/i/5v5531)







>   We do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have *some* effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. [@gelman2021]






### Alternativen zu Nullhypothesen


Nullhypothesen, $H_0$, sind z.B.: $\rho=0$, $\rho_1 = \rho_2$, $\mu_1 = \mu_2$, $\mu=0$, $\beta_1=0$.
Nullhypothesen zu testen, ist sehr verbreitet.
Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest (einfach) m√∂glich ist.^[Mittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.]
Ein anderer Grund ist vermutlich, ... wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è
Alternativen zum Testen von Nullhypothesen sind: 
  
- Posteriori-Intervalle (ETI oder HDI) berichten
- *Rope*-Konzept [@kruschke2018]
- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren (z.B. dass $\beta_1 > 0.42$)
- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat (*probability of direction, pd*)






### "Praktisch kein Unterschied": Das Rope-Konzept


üì∫ [ROPE-Video](https://www.youtube.com/watch?v=VweMjEBeQFg)


:::{#exm-rope}
### Beispiele f√ºr ROPE

- Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens $d=100$‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr einen Marketingmanager als "praktisch gleich", "praktisch kein Unterschied",
"nicht substanziell", "unbedeutend" bzw. "vernachl√§ssigbar gering"

- Bei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100 g K√∂rpergewicht "vernachl√§ssigbar wenig" ist.

- Eine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umsatzunterschied von 100k Euro "praktisch irrelevant" sei. $\square$
:::


:::{#def-rope}
### ROPE

ROPE (Region of Practical Equivalence) ist ein Bereich um den Nullwert, 
der als praktisch √§quivalent zu Null angesehen wird. $\square$.
:::


Wie legt man den Grenzwert $d$ fest,
bis zu dem ein Unterschied (*D*ifferenz) gerade noch bzw. gerade nicht mehr
unbedeutend ist?
Die Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte.
Diesen Bereich bezeichnen wir den *Indifferenzbereich* (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder *Region of practical equivalence*, Rope). 


Jetzt pr√ºfen wir, ob ein "Gro√üteil" der Posteriori-Stichproben im Rope liegt.
Unter "Gro√üteil" wird h√§ufig das *95%-HDI* verstanden (das ist auch der Standard der R-Funktion `rope()`, die wir hier nutzen).







*Entscheidungsregel* nach @kruschke2018:
  
- Gro√üteil der Post-Verteilung liegt *innerhalb* von Rope $\rightarrow$ *Annahme* der ROPE-Nullhypothese "praktisch kein Effekt", $H_0$
- Gro√üteil der Post-Verteilung liegt *au√üerhalb* von Rope $\rightarrow$ *Ablehnung* der ROPE-Nullhypothese "praktisch kein Effekt", $H_0$
- Ansonsten $\rightarrow$ keine Entscheidung -- die Datenlage ist uneindeutig


  


Mit "Gro√üteil" meinen wir (per Default) das 95%-KI (der Posteriori-Verteilung).

### Vernachl√§ssigbarer Regressionseffekt

@kruschke2018 schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als "praktisch Null" zu bezeichnen:



Wenn eine Ver√§nderung √ºber "praktisch den ganzen Wertebereich" von $X$ (UV) 
nur einen vernachl√§ssigbaren Effekt auf $Y$ (AV) hat.
Ein vernachl√§ssigbarer Effekt ist dabei $\hat{y}= \pm 0.1 sd_y$.
<!-- Der "praktisch ganze Wertebereich" von $x$ sei $\bar{x} \pm 2 sd_x$. -->
<!-- Resultiert der Vergleich UV von $\bar{x} -2 sd$ mit $\bar{x}+2sd$ nur in einer Ver√§nderung von $\hat{y}$ (der AV) von $\bar{y} - 0.1sd_y$ auf $\bar{y} + 0.1 sd_y$, so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar. -->
Das impliziert Rope-Grenzen von $\beta_x = \pm 0.1$ f√ºr z-standardisierte UV und AV.
Einfach gesprochen: Eine vern√ºnftige Voreinstellung f√ºr die Rope-Grenzen 
bei Regressionskoeffizienten sind $\pm 10 \%$ der SD der AV. 

:::{.callout-note}
### ROPE-Defaults
Im der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±10% der SD der AV. $\square$
:::



### HDI-Rope-Entscheidungsregel visualisiert

```{r out.width="100%"}
#| echo: false
#| fig-align: "center"
#| fig-cap: "Die Entscheidungsregeln zum ROPE illustiert [@kruschke2018]; A: Verwerfen der ROPE-Hypothese; B und C: Akzeptieren; D-F: Unklare Datenlage, keine Entscheidung zur ROPE-Hypothese"
#| label: fig-kruschke-rope
knitr::include_graphics("img/Kruschke-2018-Fig1.png")
```

@fig-kruschke-rope illustriert die Entscheidungsregel zum ROPE 
f√ºr die drei Situationen *Verwerfen* der ROPE-Hypothese, *Beibehalten* und 
*unklare Datenlage* [@kruschke2018, Abbildung 1, S. 272],



### Rope berechnen

Hier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (`m_penguins_species`).

```{r}
m_penguins_species <- stan_glm(body_mass_g ~ species, 
                  data = penguins, 
                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
                  seed = 42  # zur Reproduzierbarkeit
                  )
```

Den Rope berechnet man mit `rope(model)`, s. @tbl-peng-species-rope.

```{r}
#| echo: false
#| label: tbl-peng-species-rope
#| tbl-cap: "Der Rope-Bereich f√ºr die Stufen der UV (Arten von Pinguinen)"
rope(m_penguins_species)
```

Die Faktorstufe `Chinstrap` der UV `species` hat 
doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. 
Wir k√∂nnen daher f√ºr diese Gruppe  das ROPE *nicht* verwerfen. 
Die Datenlage ist *unklar*. 
Es ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.

Aber: `Gentoo` liegt zu 0% im Rope. 
F√ºr die Gruppe *Gentoo* k√∂nnen wir die ROPE-Hypothese *verwerfen*.
Der Effekt von *Gentoo* ist gr√∂√üer als vernachl√§ssigbar.
Anders gesagt: Tiere der Art *Gentoo* sind im Schnitt substanziell schwerer 
als Tiere der Referenzgruppe (*Adelie*).
Der ROPE-Grenzwert wurde hier per Voreinstellung auf 80 g Unterschied festgelegt (10% der SD der AV).



:::callout-note
Die angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung,
sondern (in der Voreinstellung) auf das 95%-ETI. Dabei werden 10% der Streuung 
der AV als Intervallgrenzen des ROPE angenommen,
s. `help(rope)`.
:::
  

Das h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®


### Visualisierung unserer Rope-Werte, m_penguins_species
  
Ein Gro√üteil der Posteriori-Masse von `m_penguins_species` liegt  *nicht* innerhalb des Rope. 
Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. @fig-rope-penguins.



```{r}
#| label: fig-rope-penguins
#| layout-ncol: 2
#| echo: false
#| fig-cap: "Rope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie."
#| fig-subcap: 
#|   - "Diagramm mit `rope(m_penguins_species) %>% plot()`"
#|   - "Diagramm mit `parameters(m_penguins_species) %>% plot()`"
plot(rope(m_penguins_species)) + scale_fill_okabeito()

parameters(m_penguins_species) %>% 
  plot() +
  geom_rect(aes(xmin = 0-80, xmax = 0+80, ymin = -Inf, ymax = Inf), 
              fill = "blue", alpha = 0.2, color = NA)
```


Das ROPE druchkreuzt die "Berge" der Posteriori-Verteilung f√ºr *Chinstrap* deutlich.
Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope.
Wir k√∂nnen das Nullhypothese f√ºr Chinstrap *nicht verwerfen*, aber auch *nicht best√§tigen* --
eine unklare Datenlage.

*Gentoo* hingegen wird vom vom Rope nicht durchkreuzt, 
es ist weit entfernt vom "blauen vertikalen Band" des Rope: 
Gentoo liegt au√üerhalb des Rope. 
Es gibt einen "substanziellen" Unterschied
zwischen dem Mittelwert der AV in Gruppe Gentoo und in der Referenzgruppe Adelie.

Wir verwerfen die ROPE-Hypothese, die "Praktisch-Null-Hypothese", in diesem Fall.








### Finetuning des Rope

Wir k√∂nnen festlegen, was wir unter "praktischer √Ñquivalenz" verstehen,
also die Grenzen des Ropes ver√§ndern.
Sagen wir, 200 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. @fig-rope-range.


```{r echo = TRUE, results="hide"}
#| label: fig-rope-range
#| fig-cap: "ROPE mit selber eingestellter Grenze von ¬±200 (Gramm)"
plot(rope(m_penguins_species, range = c(-200, 200))) + 
  scale_fill_okabeito()  # sch√∂nes Farbschmea
```






In der Voreinstellung werden 95%-ETI berichtet, das kann man wie folgt √§ndern,
wenn man m√∂chte. Die ROPE-Grenzen sind in @ tbl-rope-species-rope-fine zu sehen.
  
```{r echo=TRUE}
#| label: tbl-rope-species-rope-fine
#| tbl-cap: "ROPE-Grenzen f√ºr das Modell `m_penguins_specie`s mit ROPE-Grenzen von 500 g."
rope(m_penguins_species, range = c(-500,500), ci = .89, ci_method = "HDI")
```


Jetzt wird berichtet, welcher Teil eines 89%-CI^[89 ist die n√§chst kleinste Primzahl unter 95; 
und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. 
Damit ist 95 hier eine "magic number", ein Defacto-Standard ohne hinreichende Begr√ºndung. 
Um darauf hinzuweisen, benutzen einige Forscherinnen und Forscher mit
√§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ] sich im Rope befindet.



:::{#exr-peer-rope}
### Peer-Instruction: Interpretation des ROPE-Anteils
In einer Hochschule wird der Effekt eines "Robo-Professors" auf die Lernleistung der Studierenden untersucht,
im Fach Statistik.
Der "Robo-Professor" ist ein Computerprogramm auf Basis k√ºnstlicher Intelligenz, 
das den Studierenden den Stoff vermittelt.
Dazu wird eine Gruppe von Studierenden von einem menschlichen Dozenten unterrichtet,
die andere Gruppe von einem "Robo-Professor".
Nach dem Kurs wird die Lernleistung der Studierenden in einer Pr√ºfung gemessen.
Das Regressionsmodell `m_robo` liefert einen Rope-Anteil von 10% f√ºr den Koeffizienten `robo_professor`.
Welche Aussage dazu ist korrekt?

A) Der Robo-Professor hat einen Einfluss von 10% auf die Lernleistung der Studierenden.
B) Der Einfluss des Robo-Professors auf die Lernleistung der Studierenden ist substanziell.
C) Es gib keinen Einfluss des Robo-Professors auf die Lernleistung der Studierenden.
D) Es ist nicht auszuschlie√üen, dass der Robo-Professor keinen substanziellen Einfluss auf die Lernleistung der Studierenden hat.
E)  Der Einfluss des Robo-Professors auf die Lernleistung der Studierenden ist vernachl√§ssigbar. $\square$
:::



### Beantwortung der Forschungsfrage


F√ºr die Spezeis *Gentoo* wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, *Adelie*, 
vom Modell entdeckt. F√ºr *Chinstrap* hingegen  ist keine klare inferenzstatistische 
Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, 
laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, 
aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.












## Modellg√ºte 













### Wozu Modellg√ºte?

Hat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, 
m√∂chte man wissen, wie belastbar diese Ergebnisse sind.
Eine Absch√§tzung zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. 
Diese Kennwerte zielen z.B. darauf ab, wie *pr√§zise* die Aussagen des Modells sind. 
Je pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich.
Bei einer Parametersch√§tzung erh√§lt man  auch Informationen zur Pr√§zision der Sch√§tzung:
Ist der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa).
Allerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. 
Da kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.
Im Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, $R^2$.


### Modellg√ºte mit $R^2$ bestimmen



$R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt.
- H√∂here Wert von $R^2$ bedeuten, dass das Modell die Daten besser erkl√§rt.
$R^2$ wird normalerweise auf Basis eines Punktsch√§tzers definiert.
Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor.
Daher ist es w√ºnschenswert, diese Information in $R^2$ einflie√üen zu lassen: *Bayes-R-Quadrat*.






Die Post-Verteilung von $R^2$ kann man sich wie folgt ausgeben lassen, s. @fig-m106-r2.

```{r}
#| fig.cap: "Die Verteilung von R-Quadrat im Modell m_penguins_species"
#| label: fig-m106-r2
m_penguins_species_r2 <-
  m_penguins_species %>% 
  r2_posterior() %>% 
  as_tibble()

hdi(m_penguins_species_r2) %>%  # Intervallgrenzen der Post-Verteilung von R2
  plot()  # visualisieren
```

`



$R^2$ und $\sigma$ sind negativ assoziiert: 
In einem Datensatz mit mit hohem $R^2$ ist $\sigma$ gering und umgekehrt.
Beide Koeffizienten berechnen sich auf Basis von $\sigma$ und haben den gleichen Zweck:
die Absch√§tzung der G√ºte eines Modells.
Im Unterschied zum Frequentistischen R-Quadrat erh√§lt man in der Bayes-Statistik
nicht nur einen Punktsch√§tzer f√ºr $R^ 2$, sondern wie auch sonst eine Post-Verteilung,
so dass man z.B. einen Sch√§tzbereich angeben kann.

Schneller bekommt man den Punkt- und den Intervallsch√§tzer f√ºr $R^2$ mit `r2(m_penguins_species)`.

```{r}
#| echo: false
r2(m_penguins_species)
```




## Fazit

Obwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. 
M√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, 
einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.


:::{#exr-fragjetzt-schaetzen}
### Zeit f√ºr einen R√ºckblick: Welche Fragen haben Sie im Moment?
Mittlerweile haben wir einen Gro√üteil des Stoffs absolviert.
Welche Punkte sind Ihnen offen geblieben? Wo haben Sie noch Fragen?

Die Lehrkraft stellt Ihnen eine (anonyme) Plattform f√ºr Ihre Fragen bereit,
so dass Sie in Ruhe Ihre offenen Fragen und diejenigen Ihrer Kommilitonninen und Kommilitonen 
√ºberdenken k√∂nnen. $\square$
:::



## Aufgaben


1. [Wskt-Schluckspecht](https://datenwerk.netlify.app/posts/wskt-schluckspecht/wskt-schluckspecht)
2. [wskt-mtcars-1l](https://datenwerk.netlify.app/posts/wskt-mtcars-1l/wskt-mtcars-1l.html)
2. [rope-regr](https://datenwerk.netlify.app/posts/rope-regr/rope-regr.html)
3. [rope1](https://datenwerk.netlify.app/posts/rope1/rope1.html)
3. [rope2](https://datenwerk.netlify.app/posts/rope2/rope2.html)
3. [rope3](https://datenwerk.netlify.app/posts/rope3/rope3.html)








