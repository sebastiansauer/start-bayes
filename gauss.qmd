
# Gauss-Modelle


![Bayes:Start!](img/Golem_hex.png){width=10%}


## Lernsteuerung


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ‚Ä¶

- ein Gau√ümodell spezifizieren und in R berechnen
- an Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt


### Ben√∂tigte R-Pakete






F√ºr `rstanarm` wird ggf. [weitere Software](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started) ben√∂tigt.

:::callout-note
Software, und das sind R-Pakete, m√ºssen Sie nur einmalig installieren. Aber bei jedem
Start von R bzw. RStudio m√ºssen Sie die (ben√∂tigten!) Pakete starten.
:::


```{r load-libs-hidden}
#| include: false
library(gt)
library(patchwork)
library(figpatch)
library(ggExtra)
library(tidyverse)
library(easystats)

theme_set(theme_modern())
```

```{r load-libs-non-hidden}
#| message: false
library(tidyverse)
library(rstanarm)
library(easystats)
```



### Begleitvideos

- [Teil 1](https://youtu.be/cYHArln1DkM)
- [Teil 2](https://youtu.be/qIuu-4qRT_0)




## Wie gro√ü sind die !Kung San?

Dieser Abschnitt basiert auf @mcelreath_statistical_2020, Kap. 4.3.

### !Kung San 

In diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. @fig-kungs.

The «ÉKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names «ÉKung («ÉXun) and Ju are variant words for 'people', preferred by different «ÉKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of «ÉKung people live in the villages of Bantu pastoralists and European ranchers.

[Quelle](https://en.wikipedia.org/wiki/%C7%83Kung_people)



:::{#fig-kungs layout-ncol=2}

![Kung People](img/kung.jpg){#fig-kung1}

![Verbreitung der Kung-Sprachen](img/kung-lang.png){#fig-kung2}

Die !Kung im s√ºdlichen Afrika
:::



[Quelle: Internet Archive Book Images, No restrictions, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/b/b5/Wandering_hunters_%28Masarwa_bushmen%29%2C_North_Kalahari_Desert.jpg) 


 [Quelle: By Andrewwik.0 - Own work, CC BY-SA 4.0,](https://commons.wikimedia.org/w/index.php?curid=79801340)]



### !Kung Data

Zuerst laden wir die Daten; Quelle der Daten ist @mcelreath_statistical_2020 mit Bezug auf Howell.

[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/2021-wise/main/Data/Howell1a.csv)


```{r Post-Regression-3}
Kung_path <-  
  "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv"  

d <- data_read(Kung_path)  # aus dem Paket `easystats`

head(d)
```


Wir interessieren uns f√ºr die Gr√∂√üe der erwachsenen !Kung,
also filtern wir die Daten entsprechend und speichern die neue Tabelle als `d2`.

```{r Kung-5}
d2 <- d %>% 
  filter(age >= 18)

nrow(d2)
```


$N=`r nrow(d2)`$.

Lassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben.
`{easystats`} macht das tats√§chlich recht easy.

```{r Kung-7, echo = TRUE, eval = FALSE}
#| eval: false
describe_distribution(d2)
```



```{r Kung-7a, eval = TRUE}
#| echo: false
describe_distribution(d2) %>% 
  gt() %>% 
  fmt_number(columns = c(3:last_col()-1)) %>% 
  fmt_integer(columns = last_col())
```



### Wir gehen apriori von normalverteilter Gr√∂√üe Der !Kung aus

*Forschungsfrage:* Wie gro√ü sind die erwachsenen !Kung im *Durchschnitt*?


Wir interessieren uns also f√ºr den Mittelwert der K√∂rpergr√∂√üe (erwachsener Kung beider Geschlechter), $\mu$.



![Mensch](img/human.png){width=5%}


[Quelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, via Wikimedia Commons 3.0](https://creativecommons.org/licenses/by-sa/3.0)


Wir sind uns √ºber diesen Mittelwert nicht sicher^[Darum machen wir hier ja die ganz Show!], und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178cm und Streuung von 20 cm:

$$\mu \sim \mathcal{N}(178, 20)$$


Warum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.^[Der Autor des zugrundeliegenden Fachbuchs, Richard McElreath gibt 178cm als seine K√∂rpergr√∂√üe an.]
In einer echten Untersuchung sollte man immer einen inhaltlichen Grund f√ºr einen Priori-Wert haben.
*Oder* man w√§hlt "schwach informative" Prioris, wie das `{rstanarm}` tut:
Damit l√§sst man kaum Vorab-Information in das Modell einflie√üen,
aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).


:::callout-note
Wir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der K√∂rpergr√∂√üen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. Dar√ºber hinaus ist eine Normalverteilung nicht unplausibel.
:::


```{r Kung-9, out.width="70%"}
#| echo: false
p1 <-
  tibble(x = seq(from = 100, to = 250, by = .1)) %>% 
  
  ggplot(aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +
  geom_line() +
  scale_x_continuous(breaks = seq(from = 100, to = 250, by = 75)) +
  labs(title = "mu ~ dnorm(178, 20)",
       y = "") +
  scale_y_continuous(breaks = NULL)

p2 <-
  tibble(x = seq(0, 50, by = .01)) %>%
  ggplot(aes(x = x, y = dexp(x, rate = .1))) +
  geom_line() +
  scale_x_continuous() +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("sigma ~ dexp(0.1)")
```



## Die Exponentialverteilung

### Die Apfel-f√§llt-nicht-weit-vom-Stamm-Verteilung

Darf ich vorstellen ...


Bevor wir unser Kung-Modell spezifizieren k√∂nnen,
sollten wir noch √ºberlegen, welches Vorab-Wissen wir zur Streuung um den Mittelwert herum haben.
Da wir uns nicht 100% sicher zur gesuchten Gr√∂√üe sind,
m√ºssen wir angeben, wie gro√ü die Streuung um den Mittelwert sein soll.
Hier werden wir eingestehen, dass wir uns auch nicht 100% sicher sind,
wie gro√ü die Streuung exakt ist.
Also geben wir eine Verteilung f√ºr die Streuung an.

Etwas Wissen √ºber diese Verteilung haben wir:

- Eine Streuung muss positiv sein (es gibt keine negative Streuung).
- Eine Gleichverteilung der Streuung ist vielleicht m√∂glich, aber nicht sehr plausibel.
- Wenn wir der Meinung sind, der Mittelwert betrage "ungef√§hr 178cm", so halten wir 180cm f√ºr plausibel, aber 18000 cm f√ºr unm√∂glich und schon 200 f√ºr sehr unplausibel. Also: Je gr√∂√üer die die Abweichung vom Mittelwert desto unplausibler.

Diese Anforderungen^["Desiderata"] spiegeln sich in @fig-exp wider.
Au√üerdem zeigt die Abbilung verschiedene Quantile, wie das 95%-Quantil,
das bei 3 liegt;
95% der Werte dieser Verteilung sind also nicht gr√∂√üer als 3.






```{r Post-Regression-18}
#| fig-asp: 0.5
#| label: fig-exp
#| fig-cap: Die Exponentialverteilung mit einigen ihrer Quantilen

d <-
  tibble(
    x = seq(0, 5,.1),
    y = dexp(x, rate = 1)
  )


d_qs <-
  tibble(
    prob = c(0.05, .25, .50, .75, .95),
    q = qexp(prob) 
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  geom_area(fill = "grey60") +
  geom_vline(data = d_qs,
             aes(xintercept = q)) +
  geom_label(data = d_qs,
             aes(x = q, 
                 label = prob,
                 y = prob)) +
  labs(
       caption = "Vertikale Striche zeigen die Quantile f√ºr 5%, 25%, 50%, 75%, 95%",
       y = "Dichte")
```

F√ºr eine exponentialverteilte Variable $X$ schreibt man auch:


$$X \sim \operatorname{Exp}(1)$$


Eine Verteilung dieser Form nennt man *Exponentialverteilung*.




- Eine *Exp*onentialverteilung ist nur f√ºr positive Werte, $x>0$, definiert.
- Steigt X um eine *Einheit*, so √§ndert sich Y um einen *konstanten Faktor*.
- Sie hat nur einen Parameter, genannt *Rate* oder $\lambda$ ("lambda").
- $\frac{1}{\lambda}$  gibt gleichzeitig Mittelwert und Streuung ("Gestrecktheit") der Verteilung an.
- Je gr√∂√üer die Rate $\lambda$, desto *kleiner* die Streuung und der Mittelwert der Verteilung.
- Je gr√∂√üer  $1/\lambda$, desto *gr√∂√üer* die Streuung und der Mittelwert der Verteilung.



Ohne auf die mathematischen Eigenschaften im Detail einzugehen,
halten wir fest, dass der Graph dieser Funktion gut zu unseren Pl√§nen passt.



### Visualisierung verschiedener Exponentialverteilungen

Schauen wir uns einige Beispiele von Exponentialverteilungen an.
Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in $\lambda$ (lambda) zur√ºckzuf√ºhren, s. @fig-exps.

```{r}
#| echo: false
gg_exp <- function(r, max_x = 50) {
  med_exp <- round(log(2) / r, 2)
  p <- 
    ggplot(NULL, aes(c(0, max_x))) +
    geom_area(stat = "function", fun = dexp, fill = "grey", args = list(rate = r))  +
    labs(title = paste0("Exp(", r, ")"),
         x = "sigma",
         caption = paste0("Median (Md): ", med_exp)) +
    geom_vline(xintercept = med_exp) +
    geom_label(aes(x = med_exp), y = 0, label = "Md", show.legend = FALSE)
 
}
```


```{r Kung-9-bis}
#| echo: false
#| label: fig-exps
#| fig-cap: Beispiele von Expnentialverteilungen mit unterschiedlichem lambda 
#| fig-width: 9

p_r1 <- gg_exp(r = 1)
 
p_r2 <-  gg_exp(r = 1/2)

p_r1_8 <- gg_exp(r = 1/4)

p_r1_25 <- gg_exp(r = 1/8)


plots(p_r1_25, p_r1_8, p_r2, p_r1)
```


Wie wir in @fig-exps sehen, k√∂nnte eine Exponentialverteilung mit $\lambda=1/8$ grob passen.

:::callout-note
Die "richtigen" Priori-Verteilung zu finden, bzw. die richtigen Parameter f√ºr die Priori-Verteilung zu w√§hlen, ist nicht m√∂glichn, denn es gibt nicht die eine, richtige Priori-Verteilung.
Eine "gut passende" Verteilung zu finden, ist h√§ufig nicht leicht.
Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu w√§hlen,
die einen breiteren Raum an m√∂glichen Werten zul√§sst. 
Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie mehrere Meter K√∂rpergr√∂√üe Streuung, erlauben.
:::

Man kann sich die Quantile der Exponentialverteilung mit `qexp` ausgeben lassen,
wobei mit man `p` den Wert der Verteilungsfunktion angibt,
f√ºr den man das Quantil haben m√∂chte. Mit `rate` wird $\lambda$ bezeichnet.

Dieser Aufruf zum Beispiel:

```{r}
qexp(p = .5, rate = 1/8)
```

Gibt uns die Verteilungsfunktion einer Exponentialverteilung mit Rate ($\lambda$) von 1/8 zur√ºck, ca. 5.5.

Die Grenzen der inneren 95% dieser Verteilung kann man sich so ausgeben lassen:

```{r}
qexp(p = c(0.025, .975), rate = 1/8)
```

Diese Grenzen scheinen hinreichend weit, das wir noch von den Daten √ºberrascht werden k√∂nnen, aber schmal genug, um unsinnige Werte auszuschlie√üen.
Ein guter Start! Weiter geht's!





## Unser Gauss-Modell der !Kung


### Modelldefinition

Wir nehmen an, dass $\mu$ und $h_i$ normalverteilt sind und $\sigma$ exponentialverteilt (da notwendig positiv) ist:



Likelihood: $h_i \sim \mathcal{N}(\mu, \sigma)$

Prior f√ºr $\mu$: $\mu \sim \mathcal{N}(178, 20)$

Prior f√ºr $\sigma$: $\sigma \sim \mathcal{E}(0, 0.1)$

Daher: $95\%KI( \mu): 178 \pm 40$


In @fig-kung-model1 sind unsere Priori-Verteilungen visualisiert.


```{r Kung-10}
#| echo: false
#| label: fig-kung-model1
#| fig-cap: Unser (erstes) Kung-Modell
plots(p1, p2)
```




### Priori gewichtet mit Likelihood ergibt Posteriori


Zu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.




Die *K√∂rpergr√∂√üen der einzelnen Personen* $h_i$ nehmen wir als normalverteilt an mit Mittelwert $\mu$ und Streuung $\sigma$:

$$h_i \sim \mathcal{N}(\color{blue}{\mu},\color{green}{\sigma})$$


### Prioris

Mittelwert der Gr√∂√üe ist normalverteilt mit $\mu=178$ und $\sigma=20$:

$$\color{blue}{\mu \sim \mathcal{N}(178, 20)}$$

Die Streuung $\sigma$ der Gr√∂√üen ist exponentialverteil mit $\lambda = 1/8$.

$$\color{green}{\sigma \sim \mathcal{E}(1/8)}$$

### Fertig!

Jetzt haben wir unser Modell definiert!

Weil es so sch√∂n ist, schreiben wir es hier noch einmal auf, @eq-mod-kung1.





$$
\begin{aligned}
h_i &\sim \mathcal{N}(\mu, \sigma) \\
\mu &\sim \mathcal{N}(178, 20) \\
\sigma &\sim \mathcal{E}(1/8)
\end{aligned}
$${#eq-mod-kung1}

Zur Berechnung nutzen wir jetzt dieses Mal aber *nicht* die Gittermethode (Bayes-Box),
sondern lassen R die Arbeit verrichten.

Da gibt es einen neuen Golem, ziemlich kr√§ftig der Bursche,
der soll die Arbeit f√ºr uns tun.
Der Golem h√∂rt auf den Namen `rstanarm`^[Hey, *ich* habe ihn diesne Namen nicht gegeben.].



## Zuf√§llige Motivationsseite


```{r}
#| echo: false
if (knitr:::is_html_output()) {
  knitr::include_graphics("img/pretty_good.gif")
}
```




## Posteriori-Verteilung des Gr√∂√üen-Modells, `m41`


Okay, Golem, an die Arbeit!
Berechne uns das Kung-Modell!
Nennen wir das Modell `m41`^[*m* wie Modell und 4, weil das Modell in Kapitel 4 von @mcelreath_statistical_2020 in √§hnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.].

```{r Kung-4, message=FALSE, results="hide"}
m41 <- stan_glm(height ~ 1, data = d2, refresh = 0)
m41_post <- as_tibble(m41)  # Modellergebnis in Tabelle umwandeln
names(m41_post) <- c("mu", "sigma")  # sch√∂nere Namen f√ºr die Spalten
```


Das Argument `refresh = 0` verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden.
Ich finde diese Ausgabe meist nicht informativ,
so dass ich sie lieber unterdr√ºcke.


`stan_glm` ist eine Funktion, mit der man Regressionsmodelle berechnen kann.
Nun haben wir in diesem Fall kein "richtiges" Regressionsmodell.
Man k√∂nnte sagen, wir haben eine AV (K√∂rpergr√∂√üe), aber keine UV (keine Pr√§diktoren).
Gl√ºcklicherweise k√∂nnen wir auch solche "armen" Regressionsmodelle formulieren:

`av ~ 1` bzw. in unserem Beispiel `height ~ 1` bedeutet,
dass man nur die Verteilung der AV berechnen m√∂chte, 
aber keine Pr√§diktoren hat (das soll die  `1` symbolisieren).


F√ºr das Modell `m41` haben wir *keine* Prioris spezifiziert.
Wir greifen damit auf die Voreinstellung der Prioris von `rstanarm` zur√ºck.
Das ist ok, aber wenn Sie Vorab-Wissen haben,
sollten Sie das an `rstanarm` weitergeben, weil es ja schade w√§re,
wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.

Plotten wir mal die Posteriori-Verteilung von `m41`, s. @fig-m42-post-joint.

```{r post-m41-plot}
#| echo: true
#| label: fig-m42-post-joint
#| fig-cap: "Die gemeinsame Verteilung von Mittelwert und Streuung."

m41_post %>% 
  ggplot() +
  aes(x = mu, y = sigma) %>% 
  geom_hex() +
  scale_fill_viridis_c() 
```

Da das Modell *zwei* Parameter hat, k√∂nnen wir auch beide gleichzeitig plotten.
Wie man sieht, sind die beiden Parameter unkorreliert.
In anderen Modellen k√∂nnen die Parameter korreliert sein.

@fig-m42-post-joint erlaubt uns, f√ºr jede Kombination von Mittelwert und Streuung zu fragen,
wie wahrscheinlich diese bestimmte Kombination ist.



Hier sind noch zwei andere Visualisierungen der Post-Verteilung von `m42`, s. @fig-m42-post-anders.



```{r Kung-5-bis}
#| echo: false
#| fig-cap: "Die Postverteilung in unterschiedlicher Darstellung"
#| label: fig-m42-post-anders


p_m41_post <- 
  m41_post %>% 
  ggplot() +
  aes(x = mu, y = sigma) +
  geom_point(alpha = .1) 

p10 <- ggExtra::ggMarginal(p_m41_post, type = "density")

p20 <- 
  m41_post %>% 
  ggplot(aes(x = mu)) + 
  geom_histogram()

plots(p10, p20,
      n_rows = 1,
      title = c("Die gemeinsame Verteilung von mu und Sigma als Punktediagramm",
                "Die Post-Verteilung von mu in m42; ein Balkendiagramm bietet sich an."))
```






Nat√ºrlich k√∂nnen wir auch nur einen Parameter plotten.


Fassen wir die Ergebnisse dieses Modells zusammen:


- Wir bekommen eine Wahrscheinlichkeitsverteilung f√ºr $\mu$ und eine f√ºr $\sigma$ (bzw. eine zweidimensionale Verteilung, f√ºr die $\mu,\sigma$-Paare).

- Trotz des eher vagen Priors ist die Streuung Posteriori-Werte f√ºr $\mu$ und $\sigma$ klein: Die gro√üe Stichprobe hat die Priori-Werte √ºberstimmt.

- Ziehen wir Stichproben aus der Posteriori-Verteilung, so k√∂nnen wir interessante Fragen stellen. 




### Hallo, Posteriori-Verteilung

... wir h√§tten da mal ein paar Fragen an Sie. üïµ


1. Mit welcher Wahrscheinlichkeit ist die *mittlere* !Kung-Person gr√∂√üer als 1,55m?
2. Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell?
3. In welchem 90%-PI liegt $\mu$ vermutlich?
4. Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?
5. Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der "Best Guess"?


Antworten folgen etwas weiter unten.





Abschlie√üend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von $\mu$ und von $\sigma$, @fig-kung3.

```{r Kung-22}
#| echo: false
#| label: fig-kung3
#| fig-cap: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen f√ºr mu und f√ºr sigma
#| fig-asp: 0.5
#
m41_post %>% 
  pivot_longer(mu:sigma) %>% 
  ggplot(aes(x = value)) + 
  geom_density(fill = "grey33") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ name, scales = "free", 
             labeller = label_parsed,
             ncol = 2)
```




### Posteriori-Stichproben mit `stan_glm()` berechnen 

Mit `stan_glm()` k√∂nnen wir komfortabel die Posteriori-Verteilung berechnen. 
Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - √§hnlich.
Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode).
Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zur√ºck.


Grob gesagt berechnen wir die Post-Verteilung mit `stan_glm` so:

```{r Kung-23, echo = TRUE, eval = FALSE}
#| eval: false
library(rstanarm)  # Paket muss gestartet sein.

# berechnet Post.-Vert.:
stan_glm(
  # modelldefinition:
  AV ~ UV,
  # Datensatz:
  data = meine_daten
)
```



Modelldefinition:

$h_i \sim \mathcal{N}(\mu, \sigma)$, Likelihood

$\mu \sim \mathcal{N}(155, 19)$, Prior zum Gr√∂√üenmittelwert

$\sigma \sim \mathcal{E}(0.125)$, Prior zur Streuung der Gr√∂√üen





### Ausgabe von `stan_glm()`

Wir k√∂nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.

Wir k√∂nnen es aber auch komfortabler haben ... 
Mit dem Befehl `parameters` kann man sich die gesch√§tzten Parameterwerte einfach ausgeben lassen.

```{r Kung-24, echo = TRUE, results="hide"}
m41 <- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm

parameters(m41)  # aus Paket `easystats`
```




```{r Kung-6}
#| echo: false
parameters(m41) %>% display()
```


Das Wesentliche: Unser Golem sch√§tzt den Gr√∂√üenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa `r parameters(m41)$CI_low` bis `r parameters(m41)$CI_high` sch√§tzt.

Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. 
Dazu sp√§ter mehr.


In dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie `pd`, `Rhat` und `ESS`. Kein Problem: Einfach ignorieren :-)

Wer N√§heres wissen will, findet [hier]() einen Anfang. Au√üerdem sei an @mcelreath_statistical_2020 und @gelman_regression_2021 verwiesen.

## Wie tickt `stan_glm()`?



```{r Kung-7-bis}
#| echo: false
#| out-width: "10%"
knitr::include_graphics("img/stanlogo.png")
```

[Quelle](https://mc-stan.org/)

Hier ein paar Kernimnfos zu `stan_glm`: 

- *Stan* ist eine Software zur Berechnung von Bayesmodellen; das Paket `rstanarm` stellt Stan f√ºr uns bereit.
- `stan_glm()` ist f√ºr die Berechnung von Regressionsmodellen ausgelegt.
- Will man nur die Verteilung einer Variablen (wie `heights`) sch√§tzen, so hat man man ... eine Regression ohne Pr√§diktor.
- Eine Regression ohne Pr√§diktor schreibt man auf Errisch so: `y ~ 1`. Die `1` steht also f√ºr die nicht vorhandene UV; `y` meint die AV (`height`).
- `(Intercept)` (Achsenabschnitt) gibt den Mittelwert an.



Mehr findet sich in der [Dokumentation von RstanArm](https://mc-stan.org/rstanarm/).


### Sch√§tzwerte zu den Modellparameter

Die Parameter eines Modells sind die Gr√∂√üen, f√ºr die wir eine Priori-Verteilung annehmen sowie einen Likelihood und dann aus den Daten sch√§tzen.
Ich sage sch√§tzen um hervorzuheben, dass wir die wahren Werte nicht kennen,
sondern nur eine Vermutung haben, 
unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln
und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren.

Wie gerade gesehen,
lassen sich die Modellparameter (bzw. genauer gesagt deren Sch√§tzungen) einfach mit `parameters(modellname)` auslesen.




### Stichproben aus der Posteriori-Verteilung ziehen

Wie wir es vom Globusversuch gewohnt sind,
k√∂nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.

Hier die ersten paar Zeilen von `post_m41`:



```{r Kung-26}
post_m41 <- as_tibble(m41)
head(post_m41)
```

In einer Regression ohne Pr√§diktoren entspricht der Achsenabschnitt dem Mittelwert der AV,
daher gibt uns die Spalte `(Intercept)` Aufschluss √ºber unsere Sch√§tzwerte zu $\mu$ (der K√∂rpergr√∂√üe).


:::{#exm-kung1}

## Mit welcher Wahrscheinlichkeit ist $\mu>155$? 

```{r Kung-28a, echo = TRUE}

names(post_m41) <- 
  c("mu", "sigma")  # den Namen "(Intercept)" durch "mu" ersetzen, ist pr√§gnanter

post_m41 %>% 
  count(mu > 155) %>% 
  mutate(prop = n/sum(n))
```

Die Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlie√üen,
dass die Kung im Schnitt gr√∂√üer als 155 cm sind.
Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind.

:::


:::{#exm-kung2}

## Mit welcher Wahrscheinlichkeit ist $\mu>165$? 

```{r Kung-28, echo = TRUE}
names(post_m41) <- 
  c("mu", "sigma")  # den Namen "(Intercept)" durch "mu" ersetzen, ist pr√§gnanter

post_m41 %>% 
  count(mu > 165) %>% 
  mutate(prop = n/sum(n))
```

Oh, diese Hypothese k√∂nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlie√üen.
Aber Achtung: Das war eine Kleine-Welt-Aussage! 
Die Wahrscheinlichkeit, die Hypothese $\mu > 165$ auszuschlie√üen ist *nur* dann hoch,
wenn das Modell gilt!
Wenn also der Golem keinen Mist gebaut hat. 
Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt.
Letztlich liegt es an uns, den Golem auf Spur zu kriegen.

:::

:::{#exm-kung3}

## Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell `m41`?

```{r Kung-29, echo = TRUE}
post_m41 %>% 
  summarise(q95 = quantile(mu, .95))
```

:::



:::{#exm-kung4}

## In welchem 90%-PI liegt $\mu$ vermutlich?

```{r Kung-30, echo = TRUE}
post_m41 %>% 
  eti()
```


Ein ETI ist synonym zu PI.

:::

:::{#exm-kung5}

## Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?



```{r eval = FALSE}
m41 %>% 
  parameters()
```



```{r}
#| echo: false
m41 %>% 
  parameters() |> 
  display()
```



Seeing is believing, @fig-m41-params-intercept.

```{r}
#| fig-cap: "Parameter von m41, nur einer: der Intercept"
#| label: fig-m41-params-intercept
m41 %>% 
  parameters() %>% 
  plot(show_intercept = TRUE)
```


Das Modell ist sich recht sicher: die Ungewissheit der mittleren K√∂rpergr√∂√üe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).

:::


:::{#exm-kung6}


## Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der "Best Guess"?


`parameters(m41)` hat uns die Antwort schon gegeben: Ca. 155 cm.

:::




üèãÔ∏è √Ñhnliche Fragen bleiben als √úbung f√ºr die Lesis ü§ì.



### Standard-Prioriwerte bei `stan_glm()`

`stan_glm()` nimmt f√ºr uns Priori-Wert an.
Welche das sind, kann man sich so anzeigen lassen:

```{r Kung-8-bis, echo = TRUE}
prior_summary(m41)
```





`stan_glm()` verwendet (in der Voreinstellung) *schwach informative* Priori-Werte, die nur wenig Vorabwissen in das Modell geben.
Es werden daf√ºr die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage f√ºr die Priori-Verteilungen herangezogen.
Strenggenommen ist das nicht "pures Bayes",
weil die Priori-Werte ja *vorab*, also vor Kenntnis der Daten bestimmt werden sollen.
Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.

Man sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden.
Die Voreinstellung ist nicht zwingend; andere Werte w√§ren auch denkbar.


- `Intercept`: $\mu$, der Mittelwert der Verteilung $Y$
    - $\mu \sim \mathcal{N}(\bar{Y}, sd(Y)\cdot 2.5)$
    - als Streuung von $\mu$ wird die 2.5-fache Streuung der Stichprobe (f√ºr $Y$) angenommen.

- `Auxiliary (sigma)`: $\sigma$, die Streuung der Verteilung $Y$
    - $\sigma \sim \mathcal{E}(\lambda=1/sd(Y))$
    - als "Streuung", d.h. $\lambda$ von $h_i$ wird $\frac{1}{sd(Y)}$ angenommen.
    
    



Eine sinnvolle Strategie ist, einen Prior so zu w√§hlen, dass man nicht √ºbergewiss ist,
also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert),
andererseits sollte man extreme, unplausible Werte ausschlie√üen.




:::callout-important
Bei der Wahl der Prioris gibt es nicht die eine, richtige Wahl.
Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflie√üen zu lassen und eigene Entscheidungen zu begr√ºnden. H√§ufig sind mehrere Entscheidungen m√∂glich.
M√∂chte man lieber vorsichtig sein, weil man wenig √ºber den Gegenstand wei√ü,
dann k√∂nnte man z.B. auf die Voreinstellung von `rstanarm` vertrauen,
die "schwachinformativ" ist, also nur wenig Priori-Information  in das Modell einflie√üen l√§sst.
:::



### Wenn es schnell gehen muss


`stan_glm()` ist deutlich langsamer als z.B. der befreundete Golem `lm()`.
Der Grund f√ºr Stans Langsamkeit ist, dass er viele Stichproben zieht,
also viel zu z√§hlen hat.
Au√üerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal,
damit sein Meister pr√ºfen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat.
Die Idee dabei ist, wenn alle vier Durchf√ºhrungen (auch "Ketten" engl., chains) genannt,
zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen
zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab,
so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist "dumm gelaufen".
An dieser Stelle schauen wir uns die Ketten nicht n√§her an,
aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument `chains` steuern kann.
M√∂chte man, dass Stan sich beeilt, so kann man `chains = 1` setzen,
das spart Zeit.


```{r m41a, echo = TRUE, results="hide"}
m41a <- stan_glm(height ~ 1, 
                 data = d2, 
                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit
                 refresh = 0) 

parameters(m41a)  
```



## Modell `m42`: unsere Priori-Werte 

Im Modell `m41` haben wir auf die Priori-Werte der Voreinstellung von `rstanarm` vertraut.
Jetzt lassen wir mal unsere eigenen Priori-Werte einflie√üen, in unserem zweiten Kung-Modell, `m42`.





### m42

Dann lassen wir `stan_glm()` (Stan) unser zweites Modell berechnen.^[Hey Stan, los, an die Arbeit!]
Dieses Mal geben wir die Priori-Werte explizit an, @tbl-m42-params.

```{r Kung-15-bis, echo = TRUE}
#| eval: false
m42 <- 
  stan_glm(height ~ 1, 
           prior_intercept = normal(178, 20),  # mu
           prior_aux = exponential(0.125),  # sigma
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = d2)
parameters(m42)
```


```{r Kung-15-bis-print}
#| echo: false
#| eval: true
#| label: tbl-m42-params
#| tbl-cap: "Parameter von m42 mit eigenen Prioriwerten"
m42 <- 
  stan_glm(height ~ 1, 
           prior_intercept = normal(178, 20),  # mu
           prior_aux = exponential(0.125),  # sigma
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = d2)
parameters(m42) |> display()
```




Wir haben noch nicht alle Informationen kennengelernt, die in @tbl-m42-params ausgegeben werden.
Im Zweifel: Einfach ignorieren. Wichtige F√§higkeit im Studium. ü§ì


:::callout-important
Vergleichen Sie die Parameterwerte von `m41` und `m42`! Was f√§llt Ihnen auf? Nichts?
Gut! Tats√§chlich liefern beide Modelle sehr √§hnliche Parameterwerte.
Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben.
Hat man einigerma√üen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht,
zumindest wenn sie moderat gew√§hlt waren.
:::



```{r Kung-16-bis, eval = FALSE}
#| echo: false
write_rds(m42, "objects/m42.rds")
```



### Posteriori-Verteilung und Parameter plotten




```{r}
m42 %>% 
  as_tibble() %>% 
  ggplot(aes(x = `(Intercept)`)) +
  geom_histogram()
```



Ein Vergleich mehrerer Priori-Werte w√§re auch n√ºtzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gew√§hlten Priori-Werte zu √ºberzeugen.



## Fazit

Wir haben die Posteriori-Verteilung f√ºr ein Gauss-Modell  berechnet.
Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Pr√§diktoren, betrachtet.
Die Zielvariable, K√∂rpergr√∂√üe (`height`), haben wir als normalverteilt mit den Parametern $\mu$ und $\sigma$ angenommen.
F√ºr $\mu$ und $\sigma$ haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung f√ºr $\mu$ bzw. $\sigma$ festgelegt ist.







![üß° Bleiben Sie dran!](img/chicken_standard_deviation.jpg)








## Wahl der Priori-Werte


üèéÔ∏è Dieser Abschnitt ist eine VERTIEFUNG und nicht pr√ºfungsrelevant. üèé




### Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?




```{r prior-pred, echo = TRUE}
n <- 1e4

sim <- tibble(sample_mu  = 
      rnorm(n, 
            mean = 178, 
            sd   = 20),
    sample_sigma = 
      rexp(n, 
            rate = 0.1)) %>% 
  mutate(height  = 
      rnorm(n, 
            mean = sample_mu, 
            sd   = sample_sigma))

height_sim_sd <- 
  sd(sim$height) %>% round()
height_sim_mean <- 
  mean(sim$height) %>% round()

```


üí≠ Was denkt der Golem (`m41`) *apriori* von der Gr√∂√üe der !Kung?

ü¶æ Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voil√†:


```{r Kung-12}
p3 <- 
  sim %>% 
  ggplot(aes(x = height)) +
  geom_density(fill = "grey33") +
  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "height ~ dnorm(mu, sigma)",
       caption = "X-Achse zeigt MW¬±3SD",
       x = "Gr√∂√üe") +
  theme(panel.grid = element_blank()) 

p3
```





[Quellcode](https://bookdown.org/content/4857/geocentric-models.html#a-gaussian-model-of-height)


### Priori-Werte pr√ºfen mit der Priori-Pr√§diktiv-Verteilung

- Die Priori-Pr√§diktiv-Verteilung (`sim`) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: 
$h_i \sim \mathcal{N}(\mu, \sigma),$
$\mu \sim \mathcal{N}(178, 20),$
$\sigma \sim \mathcal{E}(0.1)$
- So k√∂nnen wir pr√ºfen, ob die Priori-Werte vern√ºnftig sind.


Die Priori-Pr√§diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Gr√∂√üenwerten zulassen:

```{r Kung-13}
p3
```



Anteil $h_i > 200$:

```{r Kung-14, echo = TRUE}
anteil_gro√üer_kung <- 
sim %>% 
  count( height > 200) %>% 
  mutate(prop = n/sum(n))
anteil_gro√üer_kung
```


ü§î Sehr gro√üe Buschleute? `r round(anteil_gro√üer_kung$prop[2], 2)*100` Prozent sind gr√∂√üer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsl√§ufig ein schlechter Prior sein.






###  Vorhersagen der Priori-Werte


```{r Kung-15}
#| echo: false
sw_path <- paste0(here::here(),"/img/south_west_black_24dp2.png")
se_path <- paste0(here::here(),"/img/south_east_black_24dp2.png")


sw <- fig(sw_path)
se <- fig(se_path)



(p1 + p2) / (se + sw) / (plot_spacer() + p3 + plot_spacer()) 

```




### Extrem vage Priori-Verteilung f√ºr die Streuung?


$$\sigma \sim \mathcal{E}(\lambda=0.01)$$







```{r Kung-16}
#| echo: false
set.seed(4)


# simulate
sim2 <-
  tibble(sample_mu    = rnorm(n, mean = 178, sd = 100),
         sample_sigma = rexp(n, rate = .01)) %>% 
  mutate(height = rnorm(n, mean = sample_mu, sd = sample_sigma))

# compute the values we'll use to break on our x axis
breaks <-
  c(mean(sim2$height) - 3 * sd(sim2$height), 0, mean(sim2$height), mean(sim2$height) + 3 * sd(sim2$height)) %>% 
    round(digits = 0)

# this is just for aesthetics
text <-
  tibble(height = 272 - 25,
         y      = .0013,
         label  = "gr√∂√üter Mann",
         angle  = 90)

# plot
p4 <-
  sim2 %>% 
  ggplot(aes(x = height)) +
  geom_density(fill = "black") +
  geom_vline(xintercept = 0, color = "grey92") +
  geom_vline(xintercept = 272, color = "grey92", linetype = 3) +
  geom_text(data = text,
            aes(y = y, label = label, angle = angle),
            color = "grey92") +
  scale_x_continuous(breaks = breaks, 
                     limits = c(-400, 700)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "height ~ dnorm(mu, sigma)\nmu ~ dnorm(178, 100)\nsigma ~ E(0.01)",
       x = "Gr√∂√üe",
       caption = "X-Achse zeigt MW¬±3SD") +
  theme(panel.grid = element_blank()) 

p4
```





Die Streuung der Gr√∂√üen ist weit:

```{r Kung-3}
d <- 
  tibble(x = seq(0,75, by =.01),
         y = dexp(x, rate = .01))

d %>% 
  ggplot(aes(x,y)) +
  geom_line()
```


```{r Kung-17, echo = FALSE, eval = FALSE}
sim2 %>% 
  count(height < 0) %>% 
  mutate(prop = n()/n)
```




ü§î Das Modell geht apriori von ein paar Prozent Menschen mit *negativer* Gr√∂√üe aus. Ein Haufen Riesen üëπ werden auch erwartet. 

ü§Ø   Vage (flache, informationslose, "neutrale", "objektive") Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.



## Aufgaben

- [stan_glm01](https://datenwerk.netlify.app/posts/stan_glm01/stan_glm01.html)
- [ReThink4e1](https://datenwerk.netlify.app/posts/rethink4e1/rethink4e1)
- [ReThink4e2](https://datenwerk.netlify.app/posts/rethink4e2/rethink4e2)
- [ReThink4e3](https://datenwerk.netlify.app/posts/rethink4e3/rethink4e3)
- [Kung-height](https://datenwerk.netlify.app/posts/kung-height/kung-height)
- [Pupil-size](https://datenwerk.netlify.app/posts/pupil-size/pupil-size)
- [IQ-Studentis](https://datenwerk.netlify.app/posts/iq-studentis/iq-studentis)
- [Priori-Streuung](https://datenwerk.netlify.app/posts/priori-streuung/priori-streuung)
- [Priorwahl1](https://datenwerk.netlify.app/posts/priorwahl1/priorwahl1)









## ---



![](img/outro-08.jpg){width=100%}



