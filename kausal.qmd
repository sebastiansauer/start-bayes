# Kausalinferenz

## Lernsteuerung


### R-Pakete


F√ºr dieses Kapitel ben√∂tigen Sie folgende R-Pakete:

```{r}
#| warning: false
library(dagitty)
library(tidyverse)
library(rstanarm)
library(easystats)
```



```{r libs-hidden}
#| echo: false
library(gt)
library(DT)
library(ggdag)

theme_set(theme_modern())
```


### Lernziele


Nach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ... 

- rkl√§ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist
- die ‚ÄúAtome‚Äù der Kausalit√§t eines DAGs benennen
- ‚Äúkausale Hintert√ºren‚Äù schlie√üen




## Statistik, was soll ich tun?


### Studie A: √ñstrogen

Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?

</br>

```{r}
#| echo: false
studie_a <-
  tibble::tribble(
     ~ Gruppe,      ~`Mit Medikament`,         ~`Ohne Medikament`,
"M√§nner",    "81/87 √ºberlebt (93%)", "234/270 √ºberlebt (87%)",
"Frauen",  "192/263 √ºberlebt (73%)",   "55/80 √ºberlebt (69%)",
"Gesamt",  "273/350 √ºberlebt (78%)", "289/350 √ºberlebt (83%)"
  ) 

studie_a %>% 
  gt()
```

</br>


Die Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualit√§t (Beobachtungsstudie).
Bei M√§nnern scheint das Medikament zu helfen; bei Frauen auch.
Aber *insgesamt* (Summe von Frauen und M√§nnern) *nicht*?!
Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt?

@pearl_causal_2016





### Kausalmodell zur Studie A



Das Geschlecht (√ñstrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-).
Das Medikament hat einen Einfluss (+) auf Heilung.
Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (√ñstrogen) und Medikament *vermengt* (konfundiert, confounded).



```{r dag-studie-a}
#| echo: false
dag_studie_a <-
  dagitty("dag{
          gender -> drug
          drug -> recovery
          gender -> recovery
          }
      ")

coordinates(dag_studie_a) <-
  list(x = c(gender = 0, drug = 0, recovery  = 1),
       y = c(gender = 0, drug = 1, recovery = 0.5))


plot(dag_studie_a)
```


:::callout-important
Betrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. 
Stratifizieren ist also in diesem Fall der korrekte, richtige Weg.
:::


Betrachtung der Gesamtdaten zeigt in diesem Fall einen *konfundierten* Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.


:::callout-important
Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige L√∂sung:
:::




### Studie B: Blutdruck

Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?


```{r dag-studie-b-table}
#| echo: false
#| message: false
studie_b <- 
  tibble::tribble(
~ Gruppe,          ~`Ohne Medikament`,          ~`Mit Medikament`,
"geringer Blutdruck",    "81/87 √ºberlebt (93%)", "234/270 √ºberlebt (87%)",
"hoher Blutdruck",  "192/263 √ºberlebt (73%)",   "55/80 √ºberlebt (69%)",
"Gesamt",  "273/350 √ºberlebt (78%)", "289/350 √ºberlebt (83%)"
  )

studie_b %>% 
  gt()
```






Die Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualit√§t (Beobachtungsstudie).
Bei geringem Blutdruck scheint das Medikament zu schaden.
Bei hohem Blutdrck scheint das Medikamenet auch zu schaden.
Aber *insgesamt* (Summe √ºber beide Gruppe) *nicht*, da scheint es zu nutzen?!
Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt???


@pearl_causal_2016


### Kausalmodell zur Studie B





Das Medikament hat einen (absenkenden) Einfluss auf den Blutdruck.
Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung.
Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung.
Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament sch√§dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.





```{r dag-studie-b}
#| echo: false
dag_studie_b <-
  dagitty("dag{
          drug -> pressure
          drug -> toxic
          pressure -> recovery
          toxic -> recovery
          }
      ")

plot(dag_studie_b)
```

Betrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den n√ºtzlichen (Reduktion des Blutdrucks).




:::callout-important
Betrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. 
Stratifizieren w√§re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar w√§re.
:::






### Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell



Studie A
```{r plot-dag-a-plot}
#| echo: false
#| message: false
plot(dag_studie_a)
```






Studie B
```{r plot-dag-a}
#| echo: false
#| message: false
plot(dag_studie_b)
```



Kausale Interpretation - und damit Entscheidungen f√ºr Handlungen - war nur m√∂glich, wenn das Kausalmodell bekannt ist. 
Die Daten alleine reichen nicht.





### Sorry, Statistik: Du allein schaffst es nicht




Statistik alleine reicht nicht f√ºr Kausalschl√ºsse üßü





Statistik plus Theorie erlaubt Kausalschl√ºsse üìö+üìä=ü§©


:::callout-important
F√ºr Entscheidungen ("Was soll ich tun?") braucht man kausales Wissen.
Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.
:::




### Studie C: Nierensteine



Nehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. √Ñrzte tendieren zu Behandlung A bei gro√üen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die √Ñrzte zu Behandlung B. 


Sollte ein Patient, der nicht wei√ü, ob sein Nierenstein gro√ü oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratiÔ¨Åzierten Daten (Teildaten nach Steingr√∂√üe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) w√§hlt?






### Kausalmodell zur Studie C



Die Gr√∂√üe der Nierensteine hat einen Einfluss auf die Behandlungsmethode.
Die Behandlung hat eien Einfluss auf die Heilung.
Damit gibt es eine Mediation von Gr√∂√üe -> Behandlung -> Heilung.
Dar√ºberhinaus gibt es noch einen Einfluss von Gr√∂√üe der Nierensteine auf die Heilung.


```{r dag-studie-c}
#| echo: false
dag_studie_c <-
  dagitty("dag{
         size -> recovery
         size -> treatment
         treatment -> recovery
          }
      ")

coordinates(dag_studie_c) <-
  list(x = c(size = 0, treatment = 0, recovery  = 1),
       y = c(size = 0, treatment = 1, recovery = 0.5))

plot(dag_studie_c)
```



### Mehr Beispiele




>   Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erh√∂hen, wenn du heiratest.







>   Studien zeigen, dass Leute, die sich beeilen, zu sp√§t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu sp√§t zu deiner Besprechung.













## Konfundierung

\newcommand{\indep}{\perp \!\!\! \perp}




### Datensatz 'Hauspreise im Saratoga County'


[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv); 
[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SaratogaHouses.html)


```{r echo = TRUE}
d_path <- "https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv"
```



```{r read-data, echo = FALSE}
#| message: false
d <- read_csv(d_path)
```

```{r}
#| echo: false
d %>% 
  select(price, livingArea, bedrooms,waterfront) %>% 
  #slice_head(n=5) %>% 
  datatable(options = list(pageLength = 5))
```




### Immobilienpreise in einer schicken Wohngegend vorhersagen



>   Finden Sie den Wert meiner Immobilie heraus! </br>
Die muss viel wert sein!"

üßë Das ist Don, Immobilienmogul, Auftraggeber.



>   Das finde ich heraus. Ich mach das wissenschaftlich.
üë© üî¨

Das ist Angie, Data Scientistin.



### Modell 1: Preis als Funktion der Anzahl der Zimmer



>   "Hey Don! Mehr Zimmer, mehr Kohle!"
üë© üî¨





```{r d-plot-don1}
#| echo: false
#| message: false
d %>% 
  ggplot() +
  aes(x = bedrooms, y = price) +
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm")
```




### Posteriori-Verteilung von Modell 1


>   "Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend."

üë©

>   Zu wenig! ü§¨

üßë


Berechnen wir das Modell:


```{r m1, echo = TRUE}
m1 <- stan_glm(price ~ bedrooms,
               refresh = 0,
               data = d)
hdi(m1)
```


Mit `estimate_preditioncs` k√∂nnen wir Vorhersagen berechnen (bzw. sch√§tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist "sch√§tzen" vielleicht das treffendere Wort):

```{r echo = TRUE}
dons_house <- tibble(bedrooms = 2)
estimate_prediction(m1, data = dons_house)
```




### Don hat eine Idee 



>   "Ich bau eine Mauer! Genial! An die Arbeit, Angie! </br>
üßë

Don hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?

>   Das ist keine gute Idee, Don."

üë©

Berechnen wir die Vorhersagen f√ºr Dons neues Haus (mit den durch Mauern halbierten Zimmern).


```{r m1-estimate-pred, echo = TRUE}
dons_new_house <- tibble(bedrooms = 4)
estimate_prediction(m1, dons_new_house)
```


Mit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut `m1`.


>   Volltreffer! Jetzt verdien ich 100 Tausend mehr! ü§ë Ich bin der Gr√∂√üte!
üßë


```{r plot-pred-m1}
#| echo: false
pred <- estimate_relation(m1)
plot(pred)
```


:::callout-note
Zur Erinnerung: "4e+05" ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: $4 \cdot 100000 = 4\cdot10^5 = 400000$
:::


### R-Funktionen, um Beobachtungen vorhersagen 



`estimate_prediction(m1, dons_new_house)` erstellt *Vorhersageintervalle*, ber√ºcksichtigt also *zwei Quellen* von Ungewissheit:

- Ungewissheiten in den Parametern (Modellkoeffizienten, $\beta_0, \beta_1, ...$)
- Ungewissheit im "Strukturmodell": Wenn also z.B. in unserem Modell ein wichtiger Pr√§diktor fehlt, so kann die Vorhersagen nicht pr√§zise sein. Fehler im Strukturmodell schlagen sich in breiten Sch√§tzintervallen (bedingt durch ein gro√ües $\sigma$) nieder.



`estimate_expectation(m1, dons_new_house)` erstellt *Konfidenzintervalle*.  ber√ºcksichtigt also nur *eine Quelle* von Ungewissheit:

- Ungewissheiten in den Parametern (Modellkoeffizienten, $\beta_0, \beta_1, ...$)


Die Sch√§tzbereiche sind in dem Fall deutlich kleiner:


```{r plot-m1-dons-new-house}
estimate_expectation(m1, dons_new_house)
```




### Modell 2: `price ~ bedrooms + livingArea`

Berechnen wir das Modell  `m2: price ~ bedrooms + livingArea`.

```{r m2, echo = TRUE}
m2 <- stan_glm(price ~ bedrooms + livingArea, data = d, refresh = 0)

hdi(m2)
```

Was sind die Vorhersgaen des Modell? 


```{r m2-pred, echo = TRUE}
estimate_prediction(m2, data = tibble(bedrooms = 4, livingArea = 1200))
```


Andere, aber √§hnliche Frage: Wieviel Haus kostet ein Haus mit sagen wir 4 Zimmer *gemittelt* √ºber die verschiedenen Gr√∂√üen von `livingArea`? Stellen Sie sich alle H√§user mit 4 Zimmern vor (also mit verschiedenen Wohnfl√§chen). Wir m√∂chten nur wissen, was so ein Haus "im Mittel" kostet.
Wir m√∂chten also die Mittelwerte pro `bedroom` sch√§tzen, gemittelt f√ºr jeden Wert von `bedroom` √ºber `livingArea`:

```{r m2-pred-means}
estimate_means(m2, at = "bedrooms", length = 7)
```

>   "Die Zimmer zu halbieren,
hat den Wert des Hauses *verringert*,
Don!"

üë©


>   "Verringert!? Weniger Geld?! Oh nein!"
üßë





### Die Zimmerzahl ist negativ mit dem Preis korreliert 

... wenn man die Wohnfl√§che (Quadratmeter) kontrolliert.



>   **"Ne-Ga-Tiv!"**

üë©


[Hauspreis stratifizieren](img/hauspreis1.png)

[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Hauspreis-stratifizieren.Rmd)


## Kontrollieren von Variablen


üí° Durch das Aufnehmen von Pr√§diktoren in die multiple Regression werden die Pr√§diktoren *kontrolliert* (adjustiert, konditioniert):

Die Koeffizienten einer multiplen Regression zeigen den Zusammenhang $\beta$ des einen Pr√§diktors mit $y$, wenn man den (oder die) anderen Pr√§diktoren statistisch *konstant h√§lt*. 

Man nennt die Koeffizienten einer multiplen Regression daher auch *parzielle Regressionskoeffizienten*. Manchmal spricht man, eher umgangssprachlich, auch vom "Netto-Effekt" eines Pr√§diktors, oder davon, dass ein Pr√§diktor "bereinigt" wurde vom (linearen) Einfluss der anderen Pr√§diktoren auf $y$.

Damit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Pr√§diktors $x_1$ auf $y$ anzeigen *unabh√§ngig* vom Effekt der anderen Pr√§diktoren, $x_2,x_3,...$ auf $y$

Man kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Pr√§diktors $x_1$ wird f√ºr jede Auspr√§gung (Gruppe) des Pr√§diktors $x_2$ berechnet.




### Das Hinzuf√ºgen von Pr√§diktoren kann die Gewichte der √ºbrigen Pr√§diktoren √§ndern






>   Aber welche und wie viele Pr√§diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!

üßë

>   Leider kann die Statistik keine Antwort darauf geben.

üë©


>   Wozu ist sie dann gut?!

üßë


:::callout-important
In Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erkl√§rung der Ursachen heranzuziehen.
:::




## Welches Modell richtig ist, kann die Statistik nicht sagen

>   Often people want statistical modeling to do things that statical modeling cannot do.
For example, we'd like to know wheter an effect is "real" or rather spurios.
Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem.
Usually answers to lage world questions about truth and causation depend upon information not included in the model.
For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model.
But if we cannot think of the right variable,
we might never notice.
Therefore all statical models are vulnerable to and demand critique,
regardless of the precision of their estimates
and apparaent accuracy of their predictions.
Rounds of model criticism and revision embody the real tests of scientific hypotheses.
A true hypothesis will pass and fail many statistical "tests" on its way to acceptance.


@mcelreath_statistical_2020, S. 139



### Kausalmodell f√ºr Konfundierung, `km1`




```{r km1, fig.asp = .33, fig.width=9}
#| echo: false
#| warning: false
km1 <- confounder_triangle(x = "bedrooms",
                          y = "price",
                          z = "living area") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()

print(km1)
```

Wenn dieses Kausalmodell stimmt, findet man eine *Scheinkorrelation* zwischen `price` und `bedrooms`.

Eine Scheinkorrelation ist ein Zusammenhang, der *nicht* auf eine kausalen Einfluss beruht.

`d_connected` hei√üt, dass die betreffenden Variablen "verbunden" sind durch einen gerichteten (`d` wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flie√üt üåä. `d_separated` hei√üt, dass sie nicht `d_connected` sind.


### `m2` kontrolliert die Konfundierungsvariable `livingArea`

Wenn das Kausalmodell stimmt, dann zeigt `m2` den kausalen Effekt von `livingArea`.

>   Was tun wir jetzt blo√ü?! Oh jeh!

üßë


>   Wir m√ºssen die Konfundierungsvariable kontrollieren.

üë©




```{r confounder-triangle, fig.asp = 0.45, fig.width=9, dpi=300}
#| echo: false
#| warning: false
confounder_triangle(x = "bedrooms",
                          y = "price",
                          z = "living area") %>% 
 ggdag_dconnected(text = FALSE, use_labels = "label", 
                  controlling_for = "z") +
  theme_dag()
```

Durch das Kontrollieren ("adjustieren"), sind `bedrooms` und `price` nicht mehr korreliert, nicht mehr `d_connected`, sondern jetzt `d_separeted`.


### Konfundierer kontrollieren


```{r}
#| echo: false
source("https://raw.githubusercontent.com/sebastiansauer/QM2-Folien/41bc43754169f64abd6ad98f8d52b5c0e23eda80/R-Code/controlling-confounder.R")
```



1. Ohne Kontrollieren der Konfundierungsvariablen

Regressionsmodell:
`y ~ x`

```{r}
#| echo: false
p_konf1
```

Es wird (f√§lschlich) eine Korrelation zwischen `x` und `y`  angezeigt: Scheinkorrelation.


M2. it Kontrollieren der Konfundierungsvariablen


Regressionsmodell:
`y ~ x + group`

```{r plot-konf2}
#| echo: false
p_konf2
```

Es wird korrekt gezeigt, dass es keine Korrelation zwischen `x` und `y` gibt, wenn `group` kontrolliert wird.





[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Konfundierer-kontrollieren.Rmd)






### `m1` und `m2` passen nicht zu den Daten, wenn `km1` stimmt




```{r print-km1}
#| echo: false
print(km1)
```



Laut `km1` d√ºrfte es keine Assoziation (Korrelation) zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert.
Es gibt aber noch eine Assoziation zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert.
 Daher sind sowohl `m1` und `m2` nicht mit dem Kausalmodell `km1` vereinbar.





### Kausalmodell 2, `km2` 

Unser Modell `m2` sagt uns, 
dass beide Pr√§diktoren jeweils einen eigenen Beitrag zur Erkl√§rung der AV haben.



Daher k√∂nnte das folgende Kausalmodell, `km2` besser passen.

In diesem Modell gibt es eine *Wirkkette*: $a \rightarrow b \rightarrow p$.

Insgesamt gibt es zwei Kausaleinfl√ºsse von `a` auf `p`:
    - $a \rightarrow p$
    - $a \rightarrow b \rightarrow p$

Man nennt die mittlere Variable einer Wirkkette auch einen *Mediator* und den Pfad von der UV (`a`) √ºber den Mediator (`b`) zur AV (`p`) auch *Mediation*.



```{r km2}
#| echo: false
km2 <- 
  dagify(
  b ~ a,
  p ~ a,
  p ~ b,
  labels = c(b = "bedrooms",
             p = "price",
             a = "livingArea")) %>% 
    ggdag(use_labels = "label") +
  theme_dag()

print(km2)
```




### Schoki macht Nobelpreis! (?)

Eine Studie fand eine starke Korrelation, $r=0.79$ zwischen (H√∂he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes [@messerli_chocolate_2012].


```{r out.width="50%"}
#| echo: false
#| warning: false
knitr::include_graphics("img/correlation_550.png")
```



:::callout-important
üí£ Korrelation ungleich Kausation!
:::









### Kausalmodell f√ºr die Schoki-Studie



```{r fig.width=7}
#| echo: false
confounder_triangle(x = "Schoki",
                          y = "Nobelpreise",
                          z = "Entwicklungsstand") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()
```



### Dons Kausalmodell, `km3`



```{r km3, fig.asp = 1.3, fig.width=9}
#| echo: false
km3 <- collider_triangle(x = "bedrooms",
                          y = "livingArea",
                          m = "price") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()

print(km3)
```



>   Ich glaube aber an mein Kausalmodell. Mein Kausalmodell ist das gr√∂√üte! Alle anderen Kausalmodelle sind ein Disaster!"

üßë

</br>

>   "Don, nach deinem Kausalmodell m√ºssten `bedrooms` und `livingArea` unkorreliert sein. Sind sie aber nicht."


Rechne doch selber, die Korrelation aus, Don:


```{r}
d %>% 
  summarise(cor(bedrooms, livingArea))
```


üë©


### Unabh√§ngigkeiten laut `km1`

`b`: bedrooms, `p`: price, `a` area (living area)



```{r}
#| echo: false
km1
```



$b \indep p \, |\, a$: `bedrooms` sind unabh√§ngig von `price`, wenn man `livingArea` kontrolliert.

‚õàÔ∏è Passt nicht zu den Daten/zum Modell!





### Unabh√§ngigkeiten laut `km2`

`b`: bedrooms, `p`: price, `a` area (living area)




```{r}
#| echo: false
km2
```

keine Unabh√§ngigkeiten

‚ùì Passt zu den Daten/zum Modell




### Unabh√§ngigkeiten laut `km3`

`b`: bedrooms, `p`: price, `a` area (living area)





```{r}
#| echo: false
km3
```


$b \indep a$: `bedrooms` sind unabh√§ngig von `livingArea` (`a`)

‚õàÔ∏è Passt nicht zu den Daten/zum Modell!





## DAGs: Directed Acyclic Graphs


Was sind DAGs?

- DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.

- Ein *Graph* besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.

- DAGs sind *gerichtet*; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).

- DAGs sind *azyklisch*; die Wirkung eines Knoten darf nicht wieder auf ihn zur√ºckf√ºhren. 

- Ein *Pfad* ist ein Weg durch den DAG, von Knoten zu Knoten √ºber die Kanten, unabh√§ngig von der Pfeilrichtung.



### DAG von `km1`

```{r}
#| echo: false
km1
```




### Leider passen potenziell viele DAGs zu einer Datenlage

`b`: bedrooms, `p`: price, `a` area (living area)



```{r dag-km1, fig.width=9}
#| echo: false
dag_km1 <-
  dagitty("dag{
         a -> b
         a -> p
         }
         ")




coordinates(dag_km1) <- list(
  x = list(a = 0, b = 1, p = 1),
  y = list(a = 0.5, b= 1, p = 0 )
)

ggdag_equivalent_dags(dag_km1) +
  theme_dag()
```





### Was ist eigentlich eine Ursache?

Etwas verursachen kann man auch (ziemlich hochtrabend) als "Kausation" verwenden.

:::callout-note
Wei√ü man, was die Wirkung $W$ einer Handlung $H$ (Intervention) ist,  so hat man $H$ als Ursache von $W$ erkannt.
:::
  
@mcelreath_statistical_2020





```{r}
#| echo: false
knitr::include_graphics("img/correlation.png")
```


[Quelle](https://xkcd.com/552/) und [Erkl√§rung](https://www.explainxkcd.com/wiki/index.php/552:_Correlation)





### Fazit

Sind zwei Variablen korreliert (abh√§ngig, assoziiert), so kann es daf√ºr zwei Gr√ºnde geben:

- Kausaler Zusammenhang
- Nichtkausaler Zusammenhang ("Scheinkorrelation")
    
Eine m√∂gliche Ursache einer Scheinkorrelation ist Konfundierung.

Konfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Pr√§diktor in eine Regression aufnimmt.

Ist die Annahme einer Konfundierung korrekt, so l√∂st sich der Scheinzusammenhang nach dem Adjustieren auf.

L√∂st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenh√§nge nach Adjustieren um, so spricht man einem *Simpson Paradox*.

Die Daten alleine k√∂nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist n√∂tig, um DAGs auszuschlie√üen.


















## Kollision









### Kein Zusammenhang von Intelligenz und Sch√∂nheit (?)

```{r p-coll1}
#| echo: false

myf <- function(x) -x+0.75

myf2 <- function(x) -x + 1.25

n <- 1e3

d2 <- tibble(
  x = runif(n),
  y = runif(n),
  status = case_when(
    y > myf(x) & y < myf2(x) ~ TRUE,
    TRUE ~ FALSE
  )
)


p_coll1 <-
  d2 %>% 
  ggplot() +
  aes(x  = x,
      y = y) +
  geom_point() +
 # scale_color_manual(values = c("grey80", "black")) +
  theme_bw() +
  labs(x = "Looks",
       y = "Talent") +
    theme(legend.position = "bottom",
          axis.text = element_blank())
```



```{r}
#| echo: false
p_coll1
```

[Gott ist gerecht (?)](https://twitter.com/TheTweetOfGod/status/1462594155176026123)




### Aber Ihre Dates sind entweder schlau oder sch√∂n

Seltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates),
entweder sch√∂n sind oder schlau - aber seltens beides gleichzeitig (schade).


```{r p-coll2}
#| echo: false
p_coll2 <- 
  d2 %>% 
  ggplot() +
  aes(x  = x,
      y = y,
      color = status) +
  geom_point() +
  scale_color_manual(values = c("grey80", "black")) +
  theme_bw() +
  labs(x = "Looks",
       y = "Talent") +
    theme(legend.position = "bottom",
          axis.text = element_blank())
```



```{r}
#| echo: false
p_coll2
```

Wie kann das sein?




## DAG zur Rettung 

ü¶π ü¶∏

Dieser DAG bietet eine rettende Erkl√§rung:


```{r plot-coll-dag1}
#| echo: false
coll1_dag <-
  dagify(date ~ Looks + Talent)

p_coll_dag1 <- 
coll1_dag %>% 
  ggdag() +
  theme_dag()

p_coll_dag1
```




```{r p-coll-dag2, fig.width=9}
#| echo: false
p_coll_dag2 <-
  collider_triangle(x = "Looks",
                  y = "Talent",
                  m = "date") %>% 
  ggdag_dseparated(controlling_for = "m",
                   text = TRUE,
                   use_labels = "label") +
  theme_dag()

p_coll_dag2
```


```{r eval = FALSE}
#| echo: false
ggdag_adjust(coll1_dag, var = "date") +
  theme_dag()
```



### Was ist eine Kollision?



Als *Kollision* (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen).
Kontrolliert man  die *Wirkung* `m`, so entsteht eine Scheinkorrelation zwischen den Ursachen `x` und `y`.
Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen.



```{r fig.width=9, dpi=300, fig.asp=1}
#| echo: false
p_coll_dag2
```


@rohrer_thinking_2018


Man kann also zu viele oder falsche Pr√§diktoren einer Regression hinzuf√ºgen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.


### Einfaches Beispiel zur Kollision



In der Zeitung *Glitzer* werden nur folgende Menschen gezeigt:

- Sch√∂ne Menschen
- Reiche Menschen
    
ehen wir davon aus, dass Sch√∂nheit und Reichtum unabh√§ngig voneinander sind.

Wenn ich Ihnen sage, dass Don nicht sch√∂n ist, aber in der Glitzer h√§ufig auftaucht, was lernen wir dann √ºber seine finanzielle Situation?^[Don muss reich sein.]




>   "Ich bin sch√∂n, unglaublich sch√∂n, und gro√ü, gro√üartig, tolle Gene!!!" üßë





### Noch ein einfaches Beispiel zur Kollision

>   "So langsam check ich's!"



Sei Z = X + Y, wobei X und Y unabh√§ngig sind.

Wenn ich Ihnen sage, X = 3, lernen Sie nichts √ºber Y, da die beiden Variablen unabh√§ngig sind
 Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).

Also: X und Y sind abh√§ngig ‚Äì gegeben Z: $X \not\indep Y \,|\, Z$.


### Durch Kontrolle entsteht eine Verzerrung bei der Kollision




```{r}
#| echo: false
p_coll_dag1
```




```{r fig.width=9}
#| echo: false
collider_triangle(x = "x",
                  y = "y",
                  m = "z") %>% 
  ggdag_dseparated(controlling_for = "m") +
  theme_dag()
```


- Ohne Kontrolle von `date` entsteht keine Scheinkorrelation zwischen `Looks` und `Talent`. Der Pfad ("Fluss") von `Looks` √ºber `date` nach `Talent` ist blockiert.

- Kontrolliert man `date`, so *√∂ffnet* sich der Pfad `Looks`->`date`-> `Talent` und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr blockiert.

- Das Kontrollieren von `date` geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.




### IQ, Fleiss und Eignung f√ºrs Studium



```{r coll2-dag}
#| echo: false
coll2_dag <- ggdag::dagify(s ~ f + iq,
                      outcome = "s",
                      labels = c("s" = "Studium",
                                 "iq" = "Intelligenz",
                                 "d" = "Fleiss"))

p_coll_dag2 <- ggdag(coll2_dag, use_labels = "label")  + theme_dag_blank()
p_coll_dag2

# coll2_dag <-
#   dagify(eignung ~ fleiss + iq)
# 
# p_coll_dag2 <- 
# coll2_dag %>% 
#   ggdag() +
#   theme_dag()
# 
# p_coll_dag2
```

Bei positiver `eignung` wird ein Studium aufgenommen (`studium = 1`) ansonsten nicht (`studium = 0)`. 


[Quelle](https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/)



`eignung` (f√ºrs Studium) sei definiert als die Summe von `iq` und `fleiss`, plus etwas Gl√ºck:

```{r d-eignung, echo = TRUE}
set.seed(42)  # Reproduzierbarkeit
N <- 1e03  

d_eignung <-
tibble(
  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1
  fleiss = rnorm(N),
  glueck = rnorm(N, mean = 0, sd = .1),
  eignung = 1/2 * iq + 1/2 * fleiss + glueck,
  studium = ifelse(eignung > 0, 1, 0) # nur wer geeignet ist, studiert (in unserem Modell)
  )
```

Laut unserem Modell setzt sich Eignung zur H√§lfte aus Intelligenz und zur H√§lfte aus Fleiss zusammen, plus etwas Gl√ºck.



### Schlagzeile "Schlauheit macht Studentis faul!"

Eine Studie untersucht den Zusammenhang von Intelligenz (iq) und Flei√ü (f) bei Studentis (s).

Ergebnis: Ein negativer Zusammenhang. 



Berechnen wir das "Eignungsmodell", aber nur mit Studis:

```{r}
m_eignung <-
  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)

hdi(m_eignung)
```


```{r}
#| echo: false
d_eignung %>% 
  filter(studium == 1) %>% 
  ggplot(aes(x = fleiss, y = iq)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm") +
  labs(title = "Nativer Zusammenhang bei Studentis")
```


IQ ist nicht unabh√§ngig von Flei√ü in unseren Daten.





### Kollisionsverzerrung nur bei Stratifizierung

Nur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf.



Ohne Stratifizierung tritt keine Scheinkorrelation auf

```{r}
#| echo: false
d_eignung %>% 
 ggplot(aes(x = fleiss, y = iq)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")
```



Mit Stratifizierung tritt Scheinkorrelation auf

```{r}
#| echo: false
d_eignung %>% 
  mutate(studium = factor(studium)) %>% 
  ggplot(aes(x = fleiss, y = iq, color = studium)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")
```


Wildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausogut schaden wie n√ºtzen.

Nur Kenntnis des DAGs verr√§t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.


:::callout-note
Nimmt man eine Variable als zweiten Pr√§diktor auf,
so "kontrolliert" man diese Variable. Das Regressiongewicht des ersten Pr√§diktors wird "bereinigt" um den Einfluss des zweiten Pr√§diktors; insofern ist der zweite Pr√§diktor dann "kontrolliert".
:::




### Einfluss von Gro√üeltern und Eltern auf Kinder





Wir wollen hier den (kausalen) Einfluss der Eltern `E` und Gro√üeltern `G` auf den *Bildungserfolg* der Kinder `K` untersuchen.

Wir nehmen folgende Effekte an:

- indirekter Effekt von `G` auf `K`: $G \rightarrow E \rightarrow K$
- direkter Effekt von `E` auf `K`: $E \rightarrow K$
- direkter Effekt von `G` auf `K`: $G \rightarrow K$


Wir sind v.a. interessiert an $G \rightarrow K$, dem *direkten kausalen* Effekt von Gro√üeltern auf ihre Enkel.





```{r}
#| echo: false
dag_coords <-
  tibble(name = c("G", "E", "K"),
         x    = c(1, 2, 2),
         y    = c(2, 2, 1))

dagify(E ~ G,
       K ~ E + G,
       coords = dag_coords) %>%
  ggdag() +
  theme_dag()
```


Aber was ist, wenn wir vielleicht eine *u*nbekannte Variable √ºbersehen haben? (S. n√§chste Seite üëª)


@kurz_statistical_2021



## Vertiefung

üèéÔ∏èVERTIEFUNGüèéÔ∏è


### Der Gespenster-DAG

üëª


```{r}
#| echo: false

# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding
gg_fancy_dag <- function(d, x = 1, y = 1, circle = "U") {
  
  d %>% 
    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(aes(color = name == circle),
                   alpha = 1/2, size = 6.5, show.legend = F) +
    geom_point(x = x, y = y, 
               size = 6.5, shape = 1, stroke = 1, color = "orange") +
    geom_dag_text(color = "black") +
    geom_dag_edges() + 
    scale_color_manual(values = c("steelblue", "orange")) +
    theme_dag()
  
}
```



```{r}
#| echo: false
coll4_dag <-
  dagitty("dag
          {
          G -> E
          E -> K
          G -> K
          U -> E
          U -> K
          }
          ")

dag_coords <-
  tibble(name = c("G", "E", "K", "U"),
         x    = c(1, 2, 2, 2.5),
         y    = c(2, 2, 1, 1.5))

dagify(E ~ G + U,
       K ~ E + G + U,
       coords = dag_coords) %>% 
gg_fancy_dag(x = 2.5, y = 1.5, circle = "U")
```



- `U` k√∂nnte ein ungemessener Einfluss sein, der auf `E` und `K` wirkt, etwa *Nachbarschaft*.

- Die Gro√üeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.

- `E` ist sowohl f√ºr `G` als auch f√ºr `U` eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.

- Wenn wir `E` kontrollieren, wird es den Pfad $G \rightarrow K$ verzerren, auch wenn wir niemals `U` messen.


Die Sache ist chancenlos. Wir m√ºssen den DAG verloren geben. üëª

@mcelreath_statistical_2020, S. 180


















## Die Hintert√ºr schlie√üen



### Zur Erinnerung: Konfundierung





*Forschungsfrage*: Wie gro√ü ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?

`a:` livingArea, `b`: bedrooms, `p`: prize

UV: `b`, AV: `p`


```{r}
#| echo: false


# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding


gg_simple_dag <- function(d) {
  
  d %>% 
    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(color = "steelblue", alpha = 1/2, size = 6.5) +
    geom_dag_text(color = "black") +
    geom_dag_edges() + 
    theme_dag()
}
```


```{r}
#| echo: false
dag_coords <-
  tibble(name = c("a", "b", "p"),
         x    = c(0, -1, 1),
         y    = c(1, 0, 0))

dagify(p ~ a + b,
       b ~ a,
       coords = dag_coords) %>%
  gg_simple_dag()
```



 Im Regressionsmodell `p ~ b` wird der kausale Effekt verzerrt sein durch die Konfundierung mit `a`.
 Der Grund f√ºr die Konfundierung sind die zwei Pfade zwischen `b` und `p`:
 
1. $b \rightarrow p$
2. $b \rightarrow a \rightarrow p$

Beide Pfade erzeugen (statistische) Assoziation zwischen `b` und `p`.
Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal.
G√§be es nur nur den zweiten Pfad und wir w√ºrden `b` √§ndern, so w√ºrde sich `p` nicht √§ndern.



### Gute Experimente zeigen den echten kausalen Effekt



```{r}
#| echo: false
dag_coords <-
  tibble(name = c("a", "b", "p"),
         x    = c(0, -1, 1),
         y    = c(1, 0, 0))

dagify(p ~ a + b,
       coords = dag_coords) %>%
  gg_simple_dag()
```

Die "Hintert√ºr" der UV (`b`) ist jetzt zu!
Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen `b` und `p` ist jetzt komplett kausal.


- Eine ber√ºhmte L√∂sung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment.
- Wenn wir den H√§usern zuf√§llig (randomisiert) eine Anzahl von Schlafzimmern (`b`) zuweisen k√∂nnten (unabh√§ngig von ihrer Quadratmeterzahl, `a`), w√ºrde sich der Graph so √§ndern.
- Das Experiment *entfernt* den Einfluss von `a` auf `b`.
- Wenn wir selber die Werte von `b` einstellen im Rahmen des Experiments, so kann `a` keine Wirkung auf `b` haben.
- Damit wird der zweite Pfad, $b \rightarrow a \rightarrow p$ geschlossen ("blockiert").




### Hintert√ºr schlie√üen auch ohne Experimente

- Konfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch *die Hintert√ºr schlie√üen* (backdoor criterion).

- Wir wollen die Hintert√ºre schlie√üen, da wir sonst nicht den wahren, kausalen Effekt bestimmen k√∂nnen.

- Zum Gl√ºck gibt es neben Experimenten noch andere Wege, die Hintert√ºr zu schlie√üen, wie die Konfundierungsvariable `a` in eine Regression mit aufzunehmen.

- Warum blockt das Kontrollieren von `a`den Pfad $b \leftarrow a \rightarrow p$?
- Stellen Sie sich den Pfad als eigenen Modell vor.
- Sobald Sie `a` kennen, bringt Ihnen Kenntnis √ºber `b` kein zus√§tzliches Wissen √ºber `p`.
- Wissen Sie hingegen nichts √ºber `a`, lernen Sie bei Kenntnis von `b` auch etwas √ºber `p`.
- Konditionieren ist wie "gegeben, dass Sie `a` schon kennen...".

- $b \indep p \,|\,a$



### Die vier Atome der Kausalanalyse



```{r}
#| echo: false
p_conf <- confounder_triangle(x = NULL, y = NULL, z = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Konfundierung")
```

```{r}
#| echo: false
p_med <- 
  mediation_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Mediation")
```


```{r}
#| echo: false
p_coll <- collider_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Kollision")
```



```{r}
#| echo: false
dag_desc <- 
  dagitty('
          dag{
          
          m [pos="1.000,0.000"]
          x [exposure,pos="0.000,1.000"]
          y [outcome,pos="2.000,1.000"]
          d [pos="1,1"]

          x -> m
          y -> m
          m -> d
          }')

p_desc <-
  dag_desc %>%
  gg_simple_dag() +
  labs(title ="Der Nachfahre")
```





```{r}
#| echo: false
plots(p_conf, p_med, p_coll, p_desc, n_rows = 2)
```





### Mediation


```{r}
#| echo: false
p_med
```


Die *Mediation* (Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten gleiche Wirkrichtung haben: $x \rightarrow m \rightarrow y$.

- Ohne Kontrollieren ist der Pfad offen: Die Assoziation "flie√üt" den Pfad entlang (in beide Richtungen).
- Kontrollieren blockt (schlie√üt) die Kette (genau wie bei der Gabel).


## Der Nachfahre


```{r}
#| echo: false
p_desc
```


Ein *Nachfahre* (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird.
Kontrolliert man einen Nachfahren `d`, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), `m`.
Der Grund ist, dass `d` Information beinhaltet √ºber `m`.
Hier wird das Kontrollieren von `d` den Pfad von `x` nach `y` teilweise √∂ffnen, da `m` eine Kollisionsvariable ist.


### Kochrezept zur Analyse von DAGs

Wie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.

Hier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:

1. Listen Sie alle Pfade von UV (`X`) zu AV (`Y`) auf.
2. Beurteilen Sie jeden Pfad, ob er gerade geschlossen oder ge√∂ffnet ist.
3. Beurteilen Sie f√ºr jeden Pfad, ob er ein Hintert√ºrpfad ist (Hintert√ºrpfade haben einen Pfeil, der zur UV f√ºhrt).
4. Wenn es ge√∂ffnete Hinterpfade gibt, pr√ºfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlie√üen (falls m√∂glich).




## Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, `bsp1`

UV: $X$, AV: $Y$, drei Covariaten (A, B, C) und ein ungemessene Variable, U





```{r gg-fancey-dag, out.width="50%"}
#| echo: false
dag_coords <-
  tibble(name = c("A", "B", "C", "U", "X", "Y"),
         x    = c(2, 2, 3, 1, 1, 3),
         y    = c(4, 2, 3, 3, 1, 1))

dagify(B ~ C + U,
       C ~ A,
       U ~ A,
       X ~ U,
       Y ~ C + X,
       coords = dag_coords) %>%
  gg_fancy_dag(x = 1, y = 3, circle = "U")
```



Es gibt zwei Hintert√ºrpfade:

1. $X \leftarrow U \leftarrow A \rightarrow C \rightarrow Y$, offen
2. $X \leftarrow U \rightarrow B \leftarrow C \rightarrow Y$, geschlossen

Kontrollieren von $A$ oder (auch) $C$ schlie√üt die offene Hintert√ºr.



@mcelreath_statistical_2020, @kurz_statistical_2021, s.S. 186.





### Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, `bsp2`

UV: $W$, AV: $D$

```{r bsp2}
#| echo: false
dag_coords <-
  tibble(name = c("A", "D", "M", "S", "W"),
         x    = c(1, 3, 2, 1, 3),
         y    = c(1, 1, 2, 3, 3))

dagify(A ~ S,
       D ~ A + M + W,
       M ~ A + S,
       W ~ S,
       coords = dag_coords) %>%
  gg_simple_dag()
```

Kontrollieren Sie diese Variablen, um die offenen Hintert√ºren zu schlie√üen:

- entweder $A$ und $M$
- oder $S$

[Mehr Infos](https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#backdoor-waffles.)



@mcelreath_statistical_2020, @kurz_statistical_2021", s.S. 188.



### Implizierte bedingte Unabh√§ngigkeiten von `bsp2`

Ein Graph ohne `U`s ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme.
Auch wenn die Daten nicht sagen k√∂nnen, welcher DAG der richtige ist, k√∂nnen wir zumindest lernen, welcher DAG falsch ist.
Die vom Modell implizierten bedingten Unabh√§ngigkeiten geben uns M√∂glichkeiten, zu pr√ºfen, ob wir einen DAG verwerfen (ausschlie√üen) k√∂nnen.
Bedingten Unabh√§ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabh√§ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.

`bsp2` impliziert folgende bedingte Unabh√§ngigkeiten:

```{r bsp2-cond-independence}
#| echo: false
dag_6.2 <- 
  dagitty(
    "dag {
    A -> D
    A -> M -> D
    A <- S -> M
    S -> W -> D
    }"
  )

impliedConditionalIndependencies(dag_6.2)
```



### Fazit

Wie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren k√∂nnen, h√§ngt von der *epistemologischen Zielrichting* der Forschungsfrage ab:

- Bei *deskriptiven* Forschungsfragen k√∂nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. "Der Unterschied zwischen beiden Gruppen betr√§gt etwa ...". Allerdings ist eine kausale Interpretation nicht zul√§ssig.
- Bei *prognostischen* Fragestellungen spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, $\hat{y}_i$, z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht m√∂glich, aber auch nicht von Interesse.
- Bei *kausalen* Forschungsfragen d√ºrfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.
    
Modellkoeffizienten √§ndern sich (oft), wenn man Pr√§diktoren zum Modell hinzuf√ºgt oder wegnimmt.
Entgegen der verbreiteten Annahme ist es falsch, m√∂glichst viele Pr√§diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist.
Kenntnis der "kausalen Atome" ist Voraussetzung zur Ableitung von Kausalschl√ºsse in Beobachtungsstudien.










