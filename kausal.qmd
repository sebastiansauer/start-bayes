# Kausalinferenz

## Lernsteuerung


### R-Pakete


Für dieses Kapitel benötigen Sie folgende R-Pakete:

```{r}
#| warning: false
library(dagitty)
library(tidyverse)
library(rstanarm)
library(easystats)
```



```{r libs-hidden}
#| echo: false
library(gt)
library(DT)
library(ggdag)

theme_set(theme_modern())
```


### Lernziele


Nach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.

Sie können ... 

- rklären, wann eine Kausalaussage gegeben eines DAGs berechtigt ist
- die “Atome” der Kausalität eines DAGs benennen
- “kausale Hintertüren” schließen




## Statistik, was soll ich tun?


### Studie A: Östrogen

Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?

</br>

```{r}
#| echo: false
studie_a <-
  tibble::tribble(
     ~ Gruppe,      ~`Mit Medikament`,         ~`Ohne Medikament`,
"Männer",    "81/87 überlebt (93%)", "234/270 überlebt (87%)",
"Frauen",  "192/263 überlebt (73%)",   "55/80 überlebt (69%)",
"Gesamt",  "273/350 überlebt (78%)", "289/350 überlebt (83%)"
  ) 

studie_a %>% 
  gt()
```

</br>


Die Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualität (Beobachtungsstudie).
Bei Männern scheint das Medikament zu helfen; bei Frauen auch.
Aber *insgesamt* (Summe von Frauen und Männern) *nicht*?!
Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt?

@pearl_causal_2016





### Kausalmodell zur Studie A



Das Geschlecht (Östrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-).
Das Medikament hat einen Einfluss (+) auf Heilung.
Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Östrogen) und Medikament *vermengt* (konfundiert, confounded).



```{r dag-studie-a}
#| echo: false
dag_studie_a <-
  dagitty("dag{
          gender -> drug
          drug -> recovery
          gender -> recovery
          }
      ")

coordinates(dag_studie_a) <-
  list(x = c(gender = 0, drug = 0, recovery  = 1),
       y = c(gender = 0, drug = 1, recovery = 0.5))


plot(dag_studie_a)
```


:::callout-important
Betrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. 
Stratifizieren ist also in diesem Fall der korrekte, richtige Weg.
:::


Betrachtung der Gesamtdaten zeigt in diesem Fall einen *konfundierten* Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.


:::callout-important
Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige Lösung:
:::




### Studie B: Blutdruck

Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?


```{r dag-studie-b-table}
#| echo: false
#| message: false
studie_b <- 
  tibble::tribble(
~ Gruppe,          ~`Ohne Medikament`,          ~`Mit Medikament`,
"geringer Blutdruck",    "81/87 überlebt (93%)", "234/270 überlebt (87%)",
"hoher Blutdruck",  "192/263 überlebt (73%)",   "55/80 überlebt (69%)",
"Gesamt",  "273/350 überlebt (78%)", "289/350 überlebt (83%)"
  )

studie_b %>% 
  gt()
```






Die Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualität (Beobachtungsstudie).
Bei geringem Blutdruck scheint das Medikament zu schaden.
Bei hohem Blutdrck scheint das Medikamenet auch zu schaden.
Aber *insgesamt* (Summe über beide Gruppe) *nicht*, da scheint es zu nutzen?!
Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt???


@pearl_causal_2016


### Kausalmodell zur Studie B





Das Medikament hat einen (absenkenden) Einfluss auf den Blutdruck.
Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung.
Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung.
Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schädlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.





```{r dag-studie-b}
#| echo: false
dag_studie_b <-
  dagitty("dag{
          drug -> pressure
          drug -> toxic
          pressure -> recovery
          toxic -> recovery
          }
      ")

plot(dag_studie_b)
```

Betrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nützlichen (Reduktion des Blutdrucks).




:::callout-important
Betrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. 
Stratifizieren wäre falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wäre.
:::






### Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell



Studie A
```{r plot-dag-a-plot}
#| echo: false
#| message: false
plot(dag_studie_a)
```






Studie B
```{r plot-dag-a}
#| echo: false
#| message: false
plot(dag_studie_b)
```



Kausale Interpretation - und damit Entscheidungen für Handlungen - war nur möglich, wenn das Kausalmodell bekannt ist. 
Die Daten alleine reichen nicht.





### Sorry, Statistik: Du allein schaffst es nicht




Statistik alleine reicht nicht für Kausalschlüsse 🧟





Statistik plus Theorie erlaubt Kausalschlüsse 📚+📊=🤩


:::callout-important
Für Entscheidungen ("Was soll ich tun?") braucht man kausales Wissen.
Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.
:::




### Studie C: Nierensteine



Nehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ärzte tendieren zu Behandlung A bei großen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ärzte zu Behandlung B. 


Sollte ein Patient, der nicht weiß, ob sein Nierenstein groß oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratiﬁzierten Daten (Teildaten nach Steingröße) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wählt?






### Kausalmodell zur Studie C



Die Größe der Nierensteine hat einen Einfluss auf die Behandlungsmethode.
Die Behandlung hat eien Einfluss auf die Heilung.
Damit gibt es eine Mediation von Größe -> Behandlung -> Heilung.
Darüberhinaus gibt es noch einen Einfluss von Größe der Nierensteine auf die Heilung.


```{r dag-studie-c}
#| echo: false
dag_studie_c <-
  dagitty("dag{
         size -> recovery
         size -> treatment
         treatment -> recovery
          }
      ")

coordinates(dag_studie_c) <-
  list(x = c(size = 0, treatment = 0, recovery  = 1),
       y = c(size = 0, treatment = 1, recovery = 0.5))

plot(dag_studie_c)
```



### Mehr Beispiele




>   Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhöhen, wenn du heiratest.







>   Studien zeigen, dass Leute, die sich beeilen, zu spät zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spät zu deiner Besprechung.













## Konfundierung

\newcommand{\indep}{\perp \!\!\! \perp}




### Datensatz 'Hauspreise im Saratoga County'


[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv); 
[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SaratogaHouses.html)


```{r echo = TRUE}
d_path <- "https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv"
```



```{r read-data, echo = FALSE}
#| message: false
d <- read_csv(d_path)
```

```{r}
#| echo: false
d %>% 
  select(price, livingArea, bedrooms,waterfront) %>% 
  #slice_head(n=5) %>% 
  datatable(options = list(pageLength = 5))
```




### Immobilienpreise in einer schicken Wohngegend vorhersagen



>   Finden Sie den Wert meiner Immobilie heraus! </br>
Die muss viel wert sein!"

🧑 Das ist Don, Immobilienmogul, Auftraggeber.



>   Das finde ich heraus. Ich mach das wissenschaftlich.
👩 🔬

Das ist Angie, Data Scientistin.



### Modell 1: Preis als Funktion der Anzahl der Zimmer



>   "Hey Don! Mehr Zimmer, mehr Kohle!"
👩 🔬





```{r d-plot-don1}
#| echo: false
#| message: false
d %>% 
  ggplot() +
  aes(x = bedrooms, y = price) +
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm")
```




### Posteriori-Verteilung von Modell 1


>   "Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend."

👩

>   Zu wenig! 🤬

🧑


Berechnen wir das Modell:


```{r m1, echo = TRUE}
m1 <- stan_glm(price ~ bedrooms,
               refresh = 0,
               data = d)
hdi(m1)
```


Mit `estimate_preditioncs` können wir Vorhersagen berechnen (bzw. schätzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist "schätzen" vielleicht das treffendere Wort):

```{r echo = TRUE}
dons_house <- tibble(bedrooms = 2)
estimate_prediction(m1, data = dons_house)
```




### Don hat eine Idee 



>   "Ich bau eine Mauer! Genial! An die Arbeit, Angie! </br>
🧑

Don hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?

>   Das ist keine gute Idee, Don."

👩

Berechnen wir die Vorhersagen für Dons neues Haus (mit den durch Mauern halbierten Zimmern).


```{r m1-estimate-pred, echo = TRUE}
dons_new_house <- tibble(bedrooms = 4)
estimate_prediction(m1, dons_new_house)
```


Mit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut `m1`.


>   Volltreffer! Jetzt verdien ich 100 Tausend mehr! 🤑 Ich bin der Größte!
🧑


```{r plot-pred-m1}
#| echo: false
pred <- estimate_relation(m1)
plot(pred)
```


:::callout-note
Zur Erinnerung: "4e+05" ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: $4 \cdot 100000 = 4\cdot10^5 = 400000$
:::


### R-Funktionen, um Beobachtungen vorhersagen 



`estimate_prediction(m1, dons_new_house)` erstellt *Vorhersageintervalle*, berücksichtigt also *zwei Quellen* von Ungewissheit:

- Ungewissheiten in den Parametern (Modellkoeffizienten, $\beta_0, \beta_1, ...$)
- Ungewissheit im "Strukturmodell": Wenn also z.B. in unserem Modell ein wichtiger Prädiktor fehlt, so kann die Vorhersagen nicht präzise sein. Fehler im Strukturmodell schlagen sich in breiten Schätzintervallen (bedingt durch ein großes $\sigma$) nieder.



`estimate_expectation(m1, dons_new_house)` erstellt *Konfidenzintervalle*.  berücksichtigt also nur *eine Quelle* von Ungewissheit:

- Ungewissheiten in den Parametern (Modellkoeffizienten, $\beta_0, \beta_1, ...$)


Die Schätzbereiche sind in dem Fall deutlich kleiner:


```{r plot-m1-dons-new-house}
estimate_expectation(m1, dons_new_house)
```




### Modell 2: `price ~ bedrooms + livingArea`

Berechnen wir das Modell  `m2: price ~ bedrooms + livingArea`.

```{r m2, echo = TRUE}
m2 <- stan_glm(price ~ bedrooms + livingArea, data = d, refresh = 0)

hdi(m2)
```

Was sind die Vorhersgaen des Modell? 


```{r m2-pred, echo = TRUE}
estimate_prediction(m2, data = tibble(bedrooms = 4, livingArea = 1200))
```


Andere, aber ähnliche Frage: Wieviel Haus kostet ein Haus mit sagen wir 4 Zimmer *gemittelt* über die verschiedenen Größen von `livingArea`? Stellen Sie sich alle Häuser mit 4 Zimmern vor (also mit verschiedenen Wohnflächen). Wir möchten nur wissen, was so ein Haus "im Mittel" kostet.
Wir möchten also die Mittelwerte pro `bedroom` schätzen, gemittelt für jeden Wert von `bedroom` über `livingArea`:

```{r m2-pred-means}
estimate_means(m2, at = "bedrooms", length = 7)
```

>   "Die Zimmer zu halbieren,
hat den Wert des Hauses *verringert*,
Don!"

👩


>   "Verringert!? Weniger Geld?! Oh nein!"
🧑





### Die Zimmerzahl ist negativ mit dem Preis korreliert 

... wenn man die Wohnfläche (Quadratmeter) kontrolliert.



>   **"Ne-Ga-Tiv!"**

👩


[Hauspreis stratifizieren](img/hauspreis1.png)

[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Hauspreis-stratifizieren.Rmd)


## Kontrollieren von Variablen


💡 Durch das Aufnehmen von Prädiktoren in die multiple Regression werden die Prädiktoren *kontrolliert* (adjustiert, konditioniert):

Die Koeffizienten einer multiplen Regression zeigen den Zusammenhang $\beta$ des einen Prädiktors mit $y$, wenn man den (oder die) anderen Prädiktoren statistisch *konstant hält*. 

Man nennt die Koeffizienten einer multiplen Regression daher auch *parzielle Regressionskoeffizienten*. Manchmal spricht man, eher umgangssprachlich, auch vom "Netto-Effekt" eines Prädiktors, oder davon, dass ein Prädiktor "bereinigt" wurde vom (linearen) Einfluss der anderen Prädiktoren auf $y$.

Damit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Prädiktors $x_1$ auf $y$ anzeigen *unabhängig* vom Effekt der anderen Prädiktoren, $x_2,x_3,...$ auf $y$

Man kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Prädiktors $x_1$ wird für jede Ausprägung (Gruppe) des Prädiktors $x_2$ berechnet.




### Das Hinzufügen von Prädiktoren kann die Gewichte der übrigen Prädiktoren ändern






>   Aber welche und wie viele Prädiktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!

🧑

>   Leider kann die Statistik keine Antwort darauf geben.

👩


>   Wozu ist sie dann gut?!

🧑


:::callout-important
In Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erklärung der Ursachen heranzuziehen.
:::




## Welches Modell richtig ist, kann die Statistik nicht sagen

>   Often people want statistical modeling to do things that statical modeling cannot do.
For example, we'd like to know wheter an effect is "real" or rather spurios.
Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem.
Usually answers to lage world questions about truth and causation depend upon information not included in the model.
For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model.
But if we cannot think of the right variable,
we might never notice.
Therefore all statical models are vulnerable to and demand critique,
regardless of the precision of their estimates
and apparaent accuracy of their predictions.
Rounds of model criticism and revision embody the real tests of scientific hypotheses.
A true hypothesis will pass and fail many statistical "tests" on its way to acceptance.


@mcelreath_statistical_2020, S. 139



### Kausalmodell für Konfundierung, `km1`




```{r km1, fig.asp = .33, fig.width=9}
#| echo: false
#| warning: false
km1 <- confounder_triangle(x = "bedrooms",
                          y = "price",
                          z = "living area") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()

print(km1)
```

Wenn dieses Kausalmodell stimmt, findet man eine *Scheinkorrelation* zwischen `price` und `bedrooms`.

Eine Scheinkorrelation ist ein Zusammenhang, der *nicht* auf eine kausalen Einfluss beruht.

`d_connected` heißt, dass die betreffenden Variablen "verbunden" sind durch einen gerichteten (`d` wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss fließt 🌊. `d_separated` heißt, dass sie nicht `d_connected` sind.


### `m2` kontrolliert die Konfundierungsvariable `livingArea`

Wenn das Kausalmodell stimmt, dann zeigt `m2` den kausalen Effekt von `livingArea`.

>   Was tun wir jetzt bloß?! Oh jeh!

🧑


>   Wir müssen die Konfundierungsvariable kontrollieren.

👩




```{r confounder-triangle, fig.asp = 0.45, fig.width=9, dpi=300}
#| echo: false
#| warning: false
confounder_triangle(x = "bedrooms",
                          y = "price",
                          z = "living area") %>% 
 ggdag_dconnected(text = FALSE, use_labels = "label", 
                  controlling_for = "z") +
  theme_dag()
```

Durch das Kontrollieren ("adjustieren"), sind `bedrooms` und `price` nicht mehr korreliert, nicht mehr `d_connected`, sondern jetzt `d_separeted`.


### Konfundierer kontrollieren


```{r}
#| echo: false
source("https://raw.githubusercontent.com/sebastiansauer/QM2-Folien/41bc43754169f64abd6ad98f8d52b5c0e23eda80/R-Code/controlling-confounder.R")
```



1. Ohne Kontrollieren der Konfundierungsvariablen

Regressionsmodell:
`y ~ x`

```{r}
#| echo: false
p_konf1
```

Es wird (fälschlich) eine Korrelation zwischen `x` und `y`  angezeigt: Scheinkorrelation.


M2. it Kontrollieren der Konfundierungsvariablen


Regressionsmodell:
`y ~ x + group`

```{r plot-konf2}
#| echo: false
p_konf2
```

Es wird korrekt gezeigt, dass es keine Korrelation zwischen `x` und `y` gibt, wenn `group` kontrolliert wird.





[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Konfundierer-kontrollieren.Rmd)






### `m1` und `m2` passen nicht zu den Daten, wenn `km1` stimmt




```{r print-km1}
#| echo: false
print(km1)
```



Laut `km1` dürfte es keine Assoziation (Korrelation) zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert.
Es gibt aber noch eine Assoziation zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert.
 Daher sind sowohl `m1` und `m2` nicht mit dem Kausalmodell `km1` vereinbar.





### Kausalmodell 2, `km2` 

Unser Modell `m2` sagt uns, 
dass beide Prädiktoren jeweils einen eigenen Beitrag zur Erklärung der AV haben.



Daher könnte das folgende Kausalmodell, `km2` besser passen.

In diesem Modell gibt es eine *Wirkkette*: $a \rightarrow b \rightarrow p$.

Insgesamt gibt es zwei Kausaleinflüsse von `a` auf `p`:
    - $a \rightarrow p$
    - $a \rightarrow b \rightarrow p$

Man nennt die mittlere Variable einer Wirkkette auch einen *Mediator* und den Pfad von der UV (`a`) über den Mediator (`b`) zur AV (`p`) auch *Mediation*.



```{r km2}
#| echo: false
km2 <- 
  dagify(
  b ~ a,
  p ~ a,
  p ~ b,
  labels = c(b = "bedrooms",
             p = "price",
             a = "livingArea")) %>% 
    ggdag(use_labels = "label") +
  theme_dag()

print(km2)
```




### Schoki macht Nobelpreis! (?)

Eine Studie fand eine starke Korrelation, $r=0.79$ zwischen (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes [@messerli_chocolate_2012].


```{r out.width="50%"}
#| echo: false
#| warning: false
knitr::include_graphics("img/correlation_550.png")
```



:::callout-important
💣 Korrelation ungleich Kausation!
:::









### Kausalmodell für die Schoki-Studie



```{r fig.width=7}
#| echo: false
confounder_triangle(x = "Schoki",
                          y = "Nobelpreise",
                          z = "Entwicklungsstand") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()
```



### Dons Kausalmodell, `km3`



```{r km3, fig.asp = 1.3, fig.width=9}
#| echo: false
km3 <- collider_triangle(x = "bedrooms",
                          y = "livingArea",
                          m = "price") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()

print(km3)
```



>   Ich glaube aber an mein Kausalmodell. Mein Kausalmodell ist das größte! Alle anderen Kausalmodelle sind ein Disaster!"

🧑

</br>

>   "Don, nach deinem Kausalmodell müssten `bedrooms` und `livingArea` unkorreliert sein. Sind sie aber nicht."


Rechne doch selber, die Korrelation aus, Don:


```{r}
d %>% 
  summarise(cor(bedrooms, livingArea))
```


👩


### Unabhängigkeiten laut `km1`

`b`: bedrooms, `p`: price, `a` area (living area)



```{r}
#| echo: false
km1
```



$b \indep p \, |\, a$: `bedrooms` sind unabhängig von `price`, wenn man `livingArea` kontrolliert.

⛈️ Passt nicht zu den Daten/zum Modell!





### Unabhängigkeiten laut `km2`

`b`: bedrooms, `p`: price, `a` area (living area)




```{r}
#| echo: false
km2
```

keine Unabhängigkeiten

❓ Passt zu den Daten/zum Modell




### Unabhängigkeiten laut `km3`

`b`: bedrooms, `p`: price, `a` area (living area)





```{r}
#| echo: false
km3
```


$b \indep a$: `bedrooms` sind unabhängig von `livingArea` (`a`)

⛈️ Passt nicht zu den Daten/zum Modell!





## DAGs: Directed Acyclic Graphs


Was sind DAGs?

- DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.

- Ein *Graph* besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.

- DAGs sind *gerichtet*; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).

- DAGs sind *azyklisch*; die Wirkung eines Knoten darf nicht wieder auf ihn zurückführen. 

- Ein *Pfad* ist ein Weg durch den DAG, von Knoten zu Knoten über die Kanten, unabhängig von der Pfeilrichtung.



### DAG von `km1`

```{r}
#| echo: false
km1
```




### Leider passen potenziell viele DAGs zu einer Datenlage

`b`: bedrooms, `p`: price, `a` area (living area)



```{r dag-km1, fig.width=9}
#| echo: false
dag_km1 <-
  dagitty("dag{
         a -> b
         a -> p
         }
         ")




coordinates(dag_km1) <- list(
  x = list(a = 0, b = 1, p = 1),
  y = list(a = 0.5, b= 1, p = 0 )
)

ggdag_equivalent_dags(dag_km1) +
  theme_dag()
```





### Was ist eigentlich eine Ursache?

Etwas verursachen kann man auch (ziemlich hochtrabend) als "Kausation" verwenden.

:::callout-note
Weiß man, was die Wirkung $W$ einer Handlung $H$ (Intervention) ist,  so hat man $H$ als Ursache von $W$ erkannt.
:::
  
@mcelreath_statistical_2020





```{r}
#| echo: false
knitr::include_graphics("img/correlation.png")
```


[Quelle](https://xkcd.com/552/) und [Erklärung](https://www.explainxkcd.com/wiki/index.php/552:_Correlation)





### Fazit

Sind zwei Variablen korreliert (abhängig, assoziiert), so kann es dafür zwei Gründe geben:

- Kausaler Zusammenhang
- Nichtkausaler Zusammenhang ("Scheinkorrelation")
    
Eine mögliche Ursache einer Scheinkorrelation ist Konfundierung.

Konfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Prädiktor in eine Regression aufnimmt.

Ist die Annahme einer Konfundierung korrekt, so löst sich der Scheinzusammenhang nach dem Adjustieren auf.

Löst sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenhänge nach Adjustieren um, so spricht man einem *Simpson Paradox*.

Die Daten alleine können nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nötig, um DAGs auszuschließen.


















## Kollision









### Kein Zusammenhang von Intelligenz und Schönheit (?)

```{r p-coll1}
#| echo: false

myf <- function(x) -x+0.75

myf2 <- function(x) -x + 1.25

n <- 1e3

d2 <- tibble(
  x = runif(n),
  y = runif(n),
  status = case_when(
    y > myf(x) & y < myf2(x) ~ TRUE,
    TRUE ~ FALSE
  )
)


p_coll1 <-
  d2 %>% 
  ggplot() +
  aes(x  = x,
      y = y) +
  geom_point() +
 # scale_color_manual(values = c("grey80", "black")) +
  theme_bw() +
  labs(x = "Looks",
       y = "Talent") +
    theme(legend.position = "bottom",
          axis.text = element_blank())
```



```{r}
#| echo: false
p_coll1
```

[Gott ist gerecht (?)](https://twitter.com/TheTweetOfGod/status/1462594155176026123)




### Aber Ihre Dates sind entweder schlau oder schön

Seltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates),
entweder schön sind oder schlau - aber seltens beides gleichzeitig (schade).


```{r p-coll2}
#| echo: false
p_coll2 <- 
  d2 %>% 
  ggplot() +
  aes(x  = x,
      y = y,
      color = status) +
  geom_point() +
  scale_color_manual(values = c("grey80", "black")) +
  theme_bw() +
  labs(x = "Looks",
       y = "Talent") +
    theme(legend.position = "bottom",
          axis.text = element_blank())
```



```{r}
#| echo: false
p_coll2
```

Wie kann das sein?




## DAG zur Rettung 

🦹 🦸

Dieser DAG bietet eine rettende Erklärung:


```{r plot-coll-dag1}
#| echo: false
coll1_dag <-
  dagify(date ~ Looks + Talent)

p_coll_dag1 <- 
coll1_dag %>% 
  ggdag() +
  theme_dag()

p_coll_dag1
```




```{r p-coll-dag2, fig.width=9}
#| echo: false
p_coll_dag2 <-
  collider_triangle(x = "Looks",
                  y = "Talent",
                  m = "date") %>% 
  ggdag_dseparated(controlling_for = "m",
                   text = TRUE,
                   use_labels = "label") +
  theme_dag()

p_coll_dag2
```


```{r eval = FALSE}
#| echo: false
ggdag_adjust(coll1_dag, var = "date") +
  theme_dag()
```



### Was ist eine Kollision?



Als *Kollision* (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen).
Kontrolliert man  die *Wirkung* `m`, so entsteht eine Scheinkorrelation zwischen den Ursachen `x` und `y`.
Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen.



```{r fig.width=9, dpi=300, fig.asp=1}
#| echo: false
p_coll_dag2
```


@rohrer_thinking_2018


Man kann also zu viele oder falsche Prädiktoren einer Regression hinzufügen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.


### Einfaches Beispiel zur Kollision



In der Zeitung *Glitzer* werden nur folgende Menschen gezeigt:

- Schöne Menschen
- Reiche Menschen
    
ehen wir davon aus, dass Schönheit und Reichtum unabhängig voneinander sind.

Wenn ich Ihnen sage, dass Don nicht schön ist, aber in der Glitzer häufig auftaucht, was lernen wir dann über seine finanzielle Situation?^[Don muss reich sein.]




>   "Ich bin schön, unglaublich schön, und groß, großartig, tolle Gene!!!" 🧑





### Noch ein einfaches Beispiel zur Kollision

>   "So langsam check ich's!"



Sei Z = X + Y, wobei X und Y unabhängig sind.

Wenn ich Ihnen sage, X = 3, lernen Sie nichts über Y, da die beiden Variablen unabhängig sind
 Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).

Also: X und Y sind abhängig – gegeben Z: $X \not\indep Y \,|\, Z$.


### Durch Kontrolle entsteht eine Verzerrung bei der Kollision




```{r}
#| echo: false
p_coll_dag1
```




```{r fig.width=9}
#| echo: false
collider_triangle(x = "x",
                  y = "y",
                  m = "z") %>% 
  ggdag_dseparated(controlling_for = "m") +
  theme_dag()
```


- Ohne Kontrolle von `date` entsteht keine Scheinkorrelation zwischen `Looks` und `Talent`. Der Pfad ("Fluss") von `Looks` über `date` nach `Talent` ist blockiert.

- Kontrolliert man `date`, so *öffnet* sich der Pfad `Looks`->`date`-> `Talent` und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr blockiert.

- Das Kontrollieren von `date` geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.




### IQ, Fleiss und Eignung fürs Studium



```{r coll2-dag}
#| echo: false
coll2_dag <- ggdag::dagify(s ~ f + iq,
                      outcome = "s",
                      labels = c("s" = "Studium",
                                 "iq" = "Intelligenz",
                                 "d" = "Fleiss"))

p_coll_dag2 <- ggdag(coll2_dag, use_labels = "label")  + theme_dag_blank()
p_coll_dag2

# coll2_dag <-
#   dagify(eignung ~ fleiss + iq)
# 
# p_coll_dag2 <- 
# coll2_dag %>% 
#   ggdag() +
#   theme_dag()
# 
# p_coll_dag2
```

Bei positiver `eignung` wird ein Studium aufgenommen (`studium = 1`) ansonsten nicht (`studium = 0)`. 


[Quelle](https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/)



`eignung` (fürs Studium) sei definiert als die Summe von `iq` und `fleiss`, plus etwas Glück:

```{r d-eignung, echo = TRUE}
set.seed(42)  # Reproduzierbarkeit
N <- 1e03  

d_eignung <-
tibble(
  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1
  fleiss = rnorm(N),
  glueck = rnorm(N, mean = 0, sd = .1),
  eignung = 1/2 * iq + 1/2 * fleiss + glueck,
  studium = ifelse(eignung > 0, 1, 0) # nur wer geeignet ist, studiert (in unserem Modell)
  )
```

Laut unserem Modell setzt sich Eignung zur Hälfte aus Intelligenz und zur Hälfte aus Fleiss zusammen, plus etwas Glück.



### Schlagzeile "Schlauheit macht Studentis faul!"

Eine Studie untersucht den Zusammenhang von Intelligenz (iq) und Fleiß (f) bei Studentis (s).

Ergebnis: Ein negativer Zusammenhang. 



Berechnen wir das "Eignungsmodell", aber nur mit Studis:

```{r}
m_eignung <-
  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)

hdi(m_eignung)
```


```{r}
#| echo: false
d_eignung %>% 
  filter(studium == 1) %>% 
  ggplot(aes(x = fleiss, y = iq)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm") +
  labs(title = "Nativer Zusammenhang bei Studentis")
```


IQ ist nicht unabhängig von Fleiß in unseren Daten.





### Kollisionsverzerrung nur bei Stratifizierung

Nur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf.



Ohne Stratifizierung tritt keine Scheinkorrelation auf

```{r}
#| echo: false
d_eignung %>% 
 ggplot(aes(x = fleiss, y = iq)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")
```



Mit Stratifizierung tritt Scheinkorrelation auf

```{r}
#| echo: false
d_eignung %>% 
  mutate(studium = factor(studium)) %>% 
  ggplot(aes(x = fleiss, y = iq, color = studium)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")
```


Wildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausogut schaden wie nützen.

Nur Kenntnis des DAGs verrät die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.


:::callout-note
Nimmt man eine Variable als zweiten Prädiktor auf,
so "kontrolliert" man diese Variable. Das Regressiongewicht des ersten Prädiktors wird "bereinigt" um den Einfluss des zweiten Prädiktors; insofern ist der zweite Prädiktor dann "kontrolliert".
:::




### Einfluss von Großeltern und Eltern auf Kinder





Wir wollen hier den (kausalen) Einfluss der Eltern `E` und Großeltern `G` auf den *Bildungserfolg* der Kinder `K` untersuchen.

Wir nehmen folgende Effekte an:

- indirekter Effekt von `G` auf `K`: $G \rightarrow E \rightarrow K$
- direkter Effekt von `E` auf `K`: $E \rightarrow K$
- direkter Effekt von `G` auf `K`: $G \rightarrow K$


Wir sind v.a. interessiert an $G \rightarrow K$, dem *direkten kausalen* Effekt von Großeltern auf ihre Enkel.





```{r}
#| echo: false
dag_coords <-
  tibble(name = c("G", "E", "K"),
         x    = c(1, 2, 2),
         y    = c(2, 2, 1))

dagify(E ~ G,
       K ~ E + G,
       coords = dag_coords) %>%
  ggdag() +
  theme_dag()
```


Aber was ist, wenn wir vielleicht eine *u*nbekannte Variable übersehen haben? (S. nächste Seite 👻)


@kurz_statistical_2021



## Vertiefung

🏎️VERTIEFUNG🏎️


### Der Gespenster-DAG

👻


```{r}
#| echo: false

# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding
gg_fancy_dag <- function(d, x = 1, y = 1, circle = "U") {
  
  d %>% 
    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(aes(color = name == circle),
                   alpha = 1/2, size = 6.5, show.legend = F) +
    geom_point(x = x, y = y, 
               size = 6.5, shape = 1, stroke = 1, color = "orange") +
    geom_dag_text(color = "black") +
    geom_dag_edges() + 
    scale_color_manual(values = c("steelblue", "orange")) +
    theme_dag()
  
}
```



```{r}
#| echo: false
coll4_dag <-
  dagitty("dag
          {
          G -> E
          E -> K
          G -> K
          U -> E
          U -> K
          }
          ")

dag_coords <-
  tibble(name = c("G", "E", "K", "U"),
         x    = c(1, 2, 2, 2.5),
         y    = c(2, 2, 1, 1.5))

dagify(E ~ G + U,
       K ~ E + G + U,
       coords = dag_coords) %>% 
gg_fancy_dag(x = 2.5, y = 1.5, circle = "U")
```



- `U` könnte ein ungemessener Einfluss sein, der auf `E` und `K` wirkt, etwa *Nachbarschaft*.

- Die Großeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.

- `E` ist sowohl für `G` als auch für `U` eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.

- Wenn wir `E` kontrollieren, wird es den Pfad $G \rightarrow K$ verzerren, auch wenn wir niemals `U` messen.


Die Sache ist chancenlos. Wir müssen den DAG verloren geben. 👻

@mcelreath_statistical_2020, S. 180


















## Die Hintertür schließen



### Zur Erinnerung: Konfundierung





*Forschungsfrage*: Wie groß ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?

`a:` livingArea, `b`: bedrooms, `p`: prize

UV: `b`, AV: `p`


```{r}
#| echo: false


# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding


gg_simple_dag <- function(d) {
  
  d %>% 
    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(color = "steelblue", alpha = 1/2, size = 6.5) +
    geom_dag_text(color = "black") +
    geom_dag_edges() + 
    theme_dag()
}
```


```{r}
#| echo: false
dag_coords <-
  tibble(name = c("a", "b", "p"),
         x    = c(0, -1, 1),
         y    = c(1, 0, 0))

dagify(p ~ a + b,
       b ~ a,
       coords = dag_coords) %>%
  gg_simple_dag()
```



 Im Regressionsmodell `p ~ b` wird der kausale Effekt verzerrt sein durch die Konfundierung mit `a`.
 Der Grund für die Konfundierung sind die zwei Pfade zwischen `b` und `p`:
 
1. $b \rightarrow p$
2. $b \rightarrow a \rightarrow p$

Beide Pfade erzeugen (statistische) Assoziation zwischen `b` und `p`.
Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal.
Gäbe es nur nur den zweiten Pfad und wir würden `b` ändern, so würde sich `p` nicht ändern.



### Gute Experimente zeigen den echten kausalen Effekt



```{r}
#| echo: false
dag_coords <-
  tibble(name = c("a", "b", "p"),
         x    = c(0, -1, 1),
         y    = c(1, 0, 0))

dagify(p ~ a + b,
       coords = dag_coords) %>%
  gg_simple_dag()
```

Die "Hintertür" der UV (`b`) ist jetzt zu!
Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen `b` und `p` ist jetzt komplett kausal.


- Eine berühmte Lösung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment.
- Wenn wir den Häusern zufällig (randomisiert) eine Anzahl von Schlafzimmern (`b`) zuweisen könnten (unabhängig von ihrer Quadratmeterzahl, `a`), würde sich der Graph so ändern.
- Das Experiment *entfernt* den Einfluss von `a` auf `b`.
- Wenn wir selber die Werte von `b` einstellen im Rahmen des Experiments, so kann `a` keine Wirkung auf `b` haben.
- Damit wird der zweite Pfad, $b \rightarrow a \rightarrow p$ geschlossen ("blockiert").




### Hintertür schließen auch ohne Experimente

- Konfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch *die Hintertür schließen* (backdoor criterion).

- Wir wollen die Hintertüre schließen, da wir sonst nicht den wahren, kausalen Effekt bestimmen können.

- Zum Glück gibt es neben Experimenten noch andere Wege, die Hintertür zu schließen, wie die Konfundierungsvariable `a` in eine Regression mit aufzunehmen.

- Warum blockt das Kontrollieren von `a`den Pfad $b \leftarrow a \rightarrow p$?
- Stellen Sie sich den Pfad als eigenen Modell vor.
- Sobald Sie `a` kennen, bringt Ihnen Kenntnis über `b` kein zusätzliches Wissen über `p`.
- Wissen Sie hingegen nichts über `a`, lernen Sie bei Kenntnis von `b` auch etwas über `p`.
- Konditionieren ist wie "gegeben, dass Sie `a` schon kennen...".

- $b \indep p \,|\,a$



### Die vier Atome der Kausalanalyse



```{r}
#| echo: false
p_conf <- confounder_triangle(x = NULL, y = NULL, z = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Konfundierung")
```

```{r}
#| echo: false
p_med <- 
  mediation_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Mediation")
```


```{r}
#| echo: false
p_coll <- collider_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Kollision")
```



```{r}
#| echo: false
dag_desc <- 
  dagitty('
          dag{
          
          m [pos="1.000,0.000"]
          x [exposure,pos="0.000,1.000"]
          y [outcome,pos="2.000,1.000"]
          d [pos="1,1"]

          x -> m
          y -> m
          m -> d
          }')

p_desc <-
  dag_desc %>%
  gg_simple_dag() +
  labs(title ="Der Nachfahre")
```





```{r}
#| echo: false
plots(p_conf, p_med, p_coll, p_desc, n_rows = 2)
```





### Mediation


```{r}
#| echo: false
p_med
```


Die *Mediation* (Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten gleiche Wirkrichtung haben: $x \rightarrow m \rightarrow y$.

- Ohne Kontrollieren ist der Pfad offen: Die Assoziation "fließt" den Pfad entlang (in beide Richtungen).
- Kontrollieren blockt (schließt) die Kette (genau wie bei der Gabel).


## Der Nachfahre


```{r}
#| echo: false
p_desc
```


Ein *Nachfahre* (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird.
Kontrolliert man einen Nachfahren `d`, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), `m`.
Der Grund ist, dass `d` Information beinhaltet über `m`.
Hier wird das Kontrollieren von `d` den Pfad von `x` nach `y` teilweise öffnen, da `m` eine Kollisionsvariable ist.


### Kochrezept zur Analyse von DAGs

Wie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.

Hier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:

1. Listen Sie alle Pfade von UV (`X`) zu AV (`Y`) auf.
2. Beurteilen Sie jeden Pfad, ob er gerade geschlossen oder geöffnet ist.
3. Beurteilen Sie für jeden Pfad, ob er ein Hintertürpfad ist (Hintertürpfade haben einen Pfeil, der zur UV führt).
4. Wenn es geöffnete Hinterpfade gibt, prüfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schließen (falls möglich).




## Schließen Sie die Hintertür (wenn möglich)!, `bsp1`

UV: $X$, AV: $Y$, drei Covariaten (A, B, C) und ein ungemessene Variable, U





```{r gg-fancey-dag, out.width="50%"}
#| echo: false
dag_coords <-
  tibble(name = c("A", "B", "C", "U", "X", "Y"),
         x    = c(2, 2, 3, 1, 1, 3),
         y    = c(4, 2, 3, 3, 1, 1))

dagify(B ~ C + U,
       C ~ A,
       U ~ A,
       X ~ U,
       Y ~ C + X,
       coords = dag_coords) %>%
  gg_fancy_dag(x = 1, y = 3, circle = "U")
```



Es gibt zwei Hintertürpfade:

1. $X \leftarrow U \leftarrow A \rightarrow C \rightarrow Y$, offen
2. $X \leftarrow U \rightarrow B \leftarrow C \rightarrow Y$, geschlossen

Kontrollieren von $A$ oder (auch) $C$ schließt die offene Hintertür.



@mcelreath_statistical_2020, @kurz_statistical_2021, s.S. 186.





### Schließen Sie die Hintertür (wenn möglich)!, `bsp2`

UV: $W$, AV: $D$

```{r bsp2}
#| echo: false
dag_coords <-
  tibble(name = c("A", "D", "M", "S", "W"),
         x    = c(1, 3, 2, 1, 3),
         y    = c(1, 1, 2, 3, 3))

dagify(A ~ S,
       D ~ A + M + W,
       M ~ A + S,
       W ~ S,
       coords = dag_coords) %>%
  gg_simple_dag()
```

Kontrollieren Sie diese Variablen, um die offenen Hintertüren zu schließen:

- entweder $A$ und $M$
- oder $S$

[Mehr Infos](https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#backdoor-waffles.)



@mcelreath_statistical_2020, @kurz_statistical_2021", s.S. 188.



### Implizierte bedingte Unabhängigkeiten von `bsp2`

Ein Graph ohne `U`s ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme.
Auch wenn die Daten nicht sagen können, welcher DAG der richtige ist, können wir zumindest lernen, welcher DAG falsch ist.
Die vom Modell implizierten bedingten Unabhängigkeiten geben uns Möglichkeiten, zu prüfen, ob wir einen DAG verwerfen (ausschließen) können.
Bedingten Unabhängigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhängig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.

`bsp2` impliziert folgende bedingte Unabhängigkeiten:

```{r bsp2-cond-independence}
#| echo: false
dag_6.2 <- 
  dagitty(
    "dag {
    A -> D
    A -> M -> D
    A <- S -> M
    S -> W -> D
    }"
  )

impliedConditionalIndependencies(dag_6.2)
```



### Fazit

Wie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren können, hängt von der *epistemologischen Zielrichting* der Forschungsfrage ab:

- Bei *deskriptiven* Forschungsfragen können die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. "Der Unterschied zwischen beiden Gruppen beträgt etwa ...". Allerdings ist eine kausale Interpretation nicht zulässig.
- Bei *prognostischen* Fragestellungen spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, $\hat{y}_i$, z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht möglich, aber auch nicht von Interesse.
- Bei *kausalen* Forschungsfragen dürfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.
    
Modellkoeffizienten ändern sich (oft), wenn man Prädiktoren zum Modell hinzufügt oder wegnimmt.
Entgegen der verbreiteten Annahme ist es falsch, möglichst viele Prädiktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist.
Kenntnis der "kausalen Atome" ist Voraussetzung zur Ableitung von Kausalschlüsse in Beobachtungsstudien.










