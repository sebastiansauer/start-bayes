# Inferenz

```{r r-pckgs}
#| echo: false
#| message: false
library(tidyverse)
library(easystats)
library(nycflights13)
```


```{r r-setup}
#| echo: false
#| message: false
theme_set(theme_minimal())
#scale_color_okabeito()
scale_colour_discrete <- function(...) 
  scale_color_okabeito()
```


![Bayes:Start!](img/Golem_hex.png){width=10%}






## Lernsteuerung

### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.



### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...



- die Definition von Inferenzstatistik sowie Beispiele f√ºr inferenzstatistische Fragestellungen nennen
- zentrale Begriffe der Inferenzstatistik nennen und in Grundz√ºgen erkl√§ren
- den Nutzen von Inferenzstatistik nennen
- erl√§utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht
- anhand von Beispielen erkl√§ren, was ein statistisches Modell ist
- die Grundkonzepte der Regression angeben
- Unterschiede zwischen frequentistischer ("klassischer") und Bayes-Inferenz benennen
- Vor- und Nachteile der frequentistischen vs. Bayes-Inferenz diskutieren
- Die grundlegende Herangehensweise zur Berechnung des p-Werts informell erkl√§ren


### Begleitliteratur

Bei @gelman2021, Kap. 1 findet sich eine Darstellung √§hnlich zu der in diesem Kapitel.



### Vorbereitung im Eigenstudium

- [Statistik 1, Kap. "Rahmen"](https://statistik1.netlify.app/010-rahmen)
- [Statistik 1](https://statistik1.netlify.app/), dort alle Inhalte zum Thema "Modellieren" und "Regression"





### Begleitvideos

- [Video zur Inferenz, Teil 1](https://youtu.be/gcwWwBy0kPI)
- [Video zur Inferenz, Teil 2](https://https://youtu.be/QNMVi6IqQ90)


### Wozu ist Statistik √ºberhaupt da?


üì∫ [Ja, wozu ist Statistik eigentlich da?](https://www.youtube.com/watch?v=gcwWwBy0kPI&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=2)

Ja, diese Frage haben Sie sich auch schon mal gestellt? 
Abb. @fig-goals gibt einen √úberblick √ºber die Ziele der Statistik.^[Ziele existieren nicht "in echt" in der Welt. Wir denken sie uns aus.
Ziele haben also keine ontologische Wirklichkeit,
sie sind epistemologische Dinge (existieren nur in unserem Kopf).
Das hei√üt, dass man sich nach Beliebem Ziele ausdenken kann.
Allerdings hilft es, wenn man andere Menschen vom Nutzen der eigenen Ideen √ºberzeugen kann...]
Nach dieser Einteilung lassen sich drei Arten von Zielen unterscheiden: Beschreiben, Vorhersagen und Erkl√§ren.


:::{#exm-ziele-stat}
### Beispiele f√ºr die Zielarten statistischer Analysen
- Beschreiben: ‚ÄúWie gro√ü ist der Gender-Paygap in der Branche X im Zeitraum Y?‚Äù
- Vorhersagen: Wenn eine Person, Mr. X, 100 Stunden auf die Statistikklausur lernen, welche Note kann diese Person dann erwarten?
- Erkl√§ren: Wie viel bringt (mir) das Lernen auf die Statistikklausur?$\square$
:::

F√ºr die Wissenschaft ist *Erkl√§ren* das wichtigste Ziel. 
Bei wenig beackerten Wissenschaftsfeldern ist das *Beschreiben* ein sinnvoller erster Schritt,
der allerdings nicht Stolperfallen ist, wie in @sec-kausal erl√§utert.
*Vorhersagen* ist mehr f√ºr die Praxis als f√ºr die Wissenschaft relevant.^[Vielleicht hat Ihr Dozent Sie schon mal mit einem Prognosewettbewerb gequ√§lt? Ja? Genau! In einem Prognosewettbewerb ist das Ziel eine - nat√ºrlich m√∂glichst exakte - Vorhersage zu treffen.]

```{mermaid}
%%| label: fig-goals
%%| fig-cap: Eine Einteilung der Ziele von statistischen Analysen
flowchart TD 
  A{Goals} --> B(describe)
  A --> C(predict)
  A --> D(explain)
  B --> E(distribution)
  B --> F(assocation)
  B --> G(extrapolation)
  C --> H(point estimate)
  C --> I(interval)
  D --> J(causal inference)
  D --> K(population)
  D --> L(latent construct)

```








## Was ist Inferenz?

```{r}
#| include: false
library(tidyverse)
library(knitr)
library(easystats)
```


<!-- TODO: -->
<!-- Attentio Grabber zum Einstieg -->
<!-- An Vorwissen ankn√ºpfen -->
<!-- -- gilt auch f√ºr √ºbrige Kapitel und √ºbrige B√ºcher -->


<!-- ### Inferenz als Generalisieren -->


üì∫ [Was ist Inferenz?](https://www.youtube.com/watch?v=QNMVi6IqQ90&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN)



Statistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlie√üen, bzw. vom Konkreten auf das Abstrakte.
^[Statistische Inferenz sieht sich drei "Herausforderungen" gegen√ºber, laut  @gelman2021, Kap. 1.1.; 
Diese betreffen das Schlie√üen (oder Generalisieren) vom Einzelfall auf das Allgemeine: 
1. Von der Stichprobe aus die Grundgesamtheit (Population), 
2. Von der Experimental- auf die Kontrollgruppe (Kausalinferenz), 
3. Von einem Messwert auf das zugrundeliegende Konstrukt. 
In diesem Kurs besch√§ftigen wir uns mit den ersten beiden Herausforderungen.]


Typischerweise untersuchen im Rahmen einer statistischen Analyse eine *Stichprobe*, 
wie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht "Tolle Studie zu dem Geheimnis des Gl√ºcks!!!" zu klicken.
Ihr Freundeskreis ist ein *Teil* der Menschen (z.B. aus Deutschland), also eine Stichprobe.
Schauen wir uns den Unterschied zwischen Stichprobe und Population n√§her an.

## Stichprobe vs. Population


Nehmen wir an, wir m√∂chten herausfinden, wie gro√ü der Anteil der R-Fans in der Population der Studierenden ist. 
Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit `A`^[~~Meistens~~ Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?].

Das *Grundproblem der Inferenzstatistik* ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.

Wir m√ºssen also den Anteil der R-Fans *in der Population* auf Basis des Anteils *in der Stichprobe* schlie√üen:
Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. @fig-pop und @fig-sample.



:::: {layout-ncol="2"}

:::{#population}
![Population](img/pvoll.png){#fig-pop}
:::


:::{#sample}
![Sample](img/psti.png){#fig-sample}
:::



Population vs. Sample. Autor: Karsten L√ºbke. OEM
::::

<!-- Quelle: LAYOUT in PDF: https://github.com/quarto-dev/quarto-cli/discussions/7497 -->


<!-- ![Population](img/pvoll.png){#fig-pop width="40%"} -->
<!-- ![Sample](img/psti.png){#fig-sample width="40%"} -->
<!-- Ohne Zwischenzeile funktioniert die REferenz nicht, aber es s√§he besesr im PDF-Druck aus. -->


H√§ufig ist das praktische Vorgehen recht simpel: 
Ah, in unserer Stichprobe sind 42% R-Fans!^[Manch einer h√§tte mit mehr gerechnet; andere mit weniger...]. Man schreibt gerne: $p = 0.42$ (`p` wie `proportion`). Die Stichprobe sei repr√§sentativ f√ºr die Grundgesamtheit aller Studierender. 
Messerscharf schlie√üen wir:
In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, $\pi=0.42$.


:::callout-note
Wir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische ($\pi$) f√ºr Populationen.$\square$
:::




### Deskriptiv- vs. Inferenzstatistik

Statistik gibt es in zwei Geschmacksrichtungen, k√∂nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. @fig-inf1.





Vereinfacht gesprochen fasst die Deskriptivstatistik  Daten (einer Stichprobe) zu einer einzelnen Kennzahl zusammen.

::: {#exm-desk}
In einem H√∂rsaal sitzen 100 Studis. Alle schreiben Ihre K√∂rpergr√∂√üe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der K√∂rpergr√∂√üe der anwesenden Studentis aus. Voil√†: Deskriptive Statistik!$\square$
:::

![Deskriptiv- vs. Inferenzstatistik](img/desk_vs_inf-crop.png){#fig-inf1 width=70% fig-align="center"}


:::{#exr-smple-pop}
üèã Schlie√üen Sie die Augen und zeichnen Sie obiges Diagramm, @fig-inf1!$\square$
:::



:::{#def-desk}
### Deskriptivstatistik
*Deskriptivstastistik* fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.
:::

:::{#def-inf}
### Inferenzstatistik
*Inferenzstatistik* ist ein Verfahren zum Schlie√üen von Statistiken (Kennzahl einer Grundgesamtheit) auf *Parameter* (eine Kennzahl  einer Grundgesamtheit).


Inferenz bedeutet Schlie√üen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.

Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schl√ºsse zu ziehen.

:::




:::{#exr-inf}
üèãÔ∏èÔ∏è Heute Nacht vor dem Schlafen wiederholen Sie die Definition. √úben Sie jetzt schon mal.$\square$
:::


### Deskriptiv- und Inferenzstatistik gehen Hand in Hand

F√ºr jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, um den zugeh√∂rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle @tbl-kennwerte. 
Da man die Parameter der Population so gut wie nie sicher kennt (schlie√ülich hat man meist nur Ausz√ºge, Teile der Population, also Stichproben), muss man sich mit *Sch√§tzwerten* begn√ºgen.
Sch√§tzwerte macht man kenntlich mit einem "Dach-Zeichen" √ºber dem Parameter, also z.b. $\hat{\mu}$, lies: "m√º-Dach".

```{r}
#| echo: false
#| label: tbl-kennwerte
#| tbl-cap: Bezeichnungen f√ºr Kennwerte
#| message: false
x <- tribble(
    ~Kennwert, ~Stichprobe, ~`Grundgesamtheit (Aussprache)`, ~Sch√§tzwert,
   "Mittelwert", "$\\bar{X}$", "$\\mu$ (m√º)" ,      "$\\hat{\\mu}$",
  "Streuung",     "$sd$",      "$\\sigma$ (sigma)", "$\\hat{\\sigma}$",
  "Anteil", "$p$", "$\\pi$ (pi)", "$\\hat{\\pi}$",
  "Korrelation", "$r$", "$\\rho$ (rho)", "$\\hat{\\rho}$" ,
  "Regression", "$b$", "$\\beta$ (beta)", "$\\hat{\\beta}$"

)

knitr::kable(x, escape = FALSE, booktabs = TRUE, format = "simple") 
```





F√ºr Statistiken (Daten einer Stichprobe) verwendet man *lateinische* Buchstaben; 
f√ºr Parameter (Population) verwendet man *griechische* Buchstaben.


:::{#exr-greek}
üèãÔ∏è Geben Sie die griechischen Buchstaben f√ºr typische Statistiken an. Ohne auf die Tabelle zu schauen.üòú$\square$!
:::


### Sch√§tzen von Parametern einer Grundgesamtheit

Meist begn√ºgt man sich  beim Analysieren von Daten nicht mit Aussagen f√ºr eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.

Leider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit *Sch√§tzungen* begn√ºgen.

Sch√§tzwerte werden mit einem "Dach" √ºber dem Kennwert gekennzeichnet, s. letzte Spalte in @tbl-kennwerte.


In der angewandten Forschung interessieren h√§ufig Fragen wie: "Welche Entscheidung ist (wahrscheinlich) besser?".
Da bekanntlich (fast) keine Aussagen sicher sind, spielt *Wahrscheinlichkeit* eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.

:::callout-note
Wahrscheinlichkeit wird oft mit *Pr* oder *p* abgek√ºrzt, f√ºr engl. *probability*.$\square$
:::


:::{#exm-inf}
Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?

Dazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, $\bar{X}_{V1}$ und $\bar{X}_{V2}$. 
Die Mittelwerte unterscheiden sich etwas, $\bar{X}_{V1} > \bar{X}_{V2}$. 
Sind diese Unterschiede "zuf√§llig" oder "substanziell"? Gilt also $\mu_{V1} > \mu_{V2}$ oder gilt $\mu_{V1} \le \mu_{V2}$? 
Wie gro√ü ist die Wahrscheinlichkeit$Pr(\mu_{V1} > \mu_{V2})$?
:::


:::{#exr-pred-maint}
üèãÔ∏è VERTIEFUNG  *Predictive Maintenance* ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 [dieses Berichts](https://www.rolandberger.com/publications/publication_pdf/roland_berger_vdma_predictive_maintenance_d_1.pdf)!$\square$
:::


## Modellieren

### Modellieren als Grundraster des Erkennens


In
In der Wissenschaft -- wie auch oft in der Technik, Wirtschaft oder im Alltag --
betrachtet man einen Teil der Welt n√§her, 
meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.
Nun ist die Welt ein weites Feld. 
Jedes Detail zu ber√ºcksichtigen ist nicht m√∂glich.
Wir m√ºssen die Sache vereinfachen: 
Alle Informationen ausblenden, die nicht zwingend n√∂tig sind.
Aber gleichzeitig die Strukturelemente der wirklichen Welt, 
die f√ºr unsere Fragestellung zentral ist, beibehalten.



Dieses Tun nennt man *Modellieren*: Man erstellt sich ein Modell.

:::{#def-model}
### Modell
Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit.$\square$
:::

Der Nutzen eines Modells ist, einen (√ºberm√§√üig) komplexen Sachverhalt zu vereinfachen oder √ºberhaupt erst handhabbar zu machen.
Man versucht zu vereinfachen, 
ohne Wesentliches wegzulassen. 
Der Speck muss weg, sozusagen. Das Wesentliche bleibt.

Auf die Statistik bezogen hei√üt das,
dass man einen Datensatz dabei so zusammenfasst,
damit man das Wesentliche erkennt.

Was ist das "Wesentliche"? 
Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. 
Etwa: "Wie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?"^[Das ist nat√ºrlich nur ein fiktives, 
komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.]
Noch allgemeiner ist man dabei h√§ufig am Zusammenhang von `X ` und `Y` interessiert, 
s. @fig-xy, die ein Sinnbild von statistischen Modellen widergibt.

Was ist das "Wesentliche"? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. 
Etwa: "Wie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden 
habe?"^[Das ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, 
das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.]
Noch allgemeiner ist man dabei h√§ufig am Zusammenhang von `X ` und `Y` interessiert, 
s. @fig-xy, die ein Sinnbild von statistischen Modellen widergibt.





:::{#fig-xy fig-align="center"}


```{mermaid}
flowchart LR
X --> Y


X1 --> Y2
X2 --> Y2
```

oben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)


:::


Man kann @fig-xy als ein Sinnbild einer (mathematischen) Funktion lesen.

:::{#def-fun}
### Funktion
Eine Funktion $f$ setzt zwei Gr√∂√üen in Beziehung. $\square$
:::

In Mathe-Sprech:

$f: X \rightarrow Y$

oder:

$y = f(x)$, lies: "Y ist eine Funktion von X".






Es h√∂rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren:
Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet,
macht man sich ein Modell:
man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl,
die das forschungsleitende Interesse zusammenfasst.

### Vertiefung

Lesen Sie die Einf√ºhrung zum Thema Modellieren bei @poldrack2022 (Kap. 5.1).


:::callout-note
Nutzen Sie die √úbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.
:::


## Regression

Einflussreiche Leute schw√∂ren auf die Regressionsanalyse (@fig-gandalf).

![One regression](img/einring.jpg){width="50%" #fig-gandalf fig-align="center"}





::: {.content-visible when-format="html"}

@fig-linfun zeigt ein interaktives Beispiel einer linearen Funktion. 
Sie k√∂nnen Punkte per Klick/Touch hinzuf√ºgen.


:::{#fig-linfun}

::: {.figure-content}

<!-- ```{=html} -->
<!-- <iframe width="500" height="400" src="https://www.geogebra.org/m/vfjW1dZt" title="Visualisierung eines Geradenmodells"></iframe> -->
<!-- ``` -->



{{< include children/regression-interactive.qmd >}}

:::

Interaktives Beispiel f√ºr eines lineares Modell. F√ºgen Sie Punkte per Klick/Touch hinzu.

:::



Alternativ k√∂nnen Sie [diese App](https://gallery.shinyapps.io/simple_regression/) njutzen, Regressionskoeffizienten, Steigung (slope) und Achsenabschnitt (Intercept), zu optimieren.
Dabei meint "optimieren", die Abweichungen (Residuen, Residualfehler; die roten Balken in der App) zu minimieren.^[<https://gallery.shinyapps.io/simple_regression/>]



:::


[Hier](https://shinyapps.org/showapp.php?app=https://shiny.psy.lmu.de/felix/lmfit&by=Felix%20Sch%C3%B6nbrodt&title=Find-a-fit!&shorttitle=Find-a-fit!) finden Sie eine App, die Ihnen gestattet, selber Hand an eine Regressionsgerade zu legen.


:::{#exr-setosa-vis}
### VERTIEFUNG Regression mit Animationen erkl√§rt
Lesen Sie [diesen Post](https://setosa.io/ev/ordinary-least-squares-regression/), 
der Ihnen mit Hilfe von Bildern und Animationen (okay, und etwas) Text die Grundlagen der Regressionsanalyse erkl√§rt.$\square$
:::



### Regression zum Modellieren

Die Regression ist eine Art Schweizer Taschenmesser der Statistik: F√ºr vieles gut einsetzbar.
Anstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden.
Das ist nicht nur einfacher, sondern auch sch√∂ner. 
Wir werden im Folgenden stets die Regression zum Modellieren verwenden.
Dann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.


:::callout-note
Regression + Inferenz = üíñ
:::



Alternativ zur Regression k√∂nnte man sich in den Wald der statistischen Verfahren begeben, [wie hier von der Uni M√ºnster als Ausschnitt (!) aufgef√ºhrt](https://web.archive.org/web/20091029162244/http://www.wiwi.uni-muenster.de/ioeb/en/organisation/pfaff/stat_overview_table.html).
Auf dieser Basis kann man meditieren,
welches statistischen Verfahren man f√ºr eine bestimmte Fragestellung verwenden sollte, s. Abb.  @fig-choose-test.
Muss man aber nicht -- man kann stattdessen die Regression benutzen.

![W√§hle deine Statistik mit Bedacht. Oder w√§hle die Regressionsanalyse.](img/choose-test.png){#fig-choose-test}

:::callout-note
Es ist meist einfacher und n√ºtzlicher, die Regression zu verwenden, anstelle der Vielzahl von anderen Verfahren (die zumeist Spezialf√§lle der Regression sind). In diesem Kurs werden wir f√ºr alle Fragestellungen die Regression verwenden.^[Wie Jonas [Kristoffer Lindel√∏v](https://lindeloev.github.io/tests-as-linear/) uns erkl√§rt, sind viele statistische Verfahren, wie der sog. t-Test Spezialf√§lle der Regression.]$\square$
:::



:::{#exm-spezialfaelle-regr}
Typische Spezialf√§lle der Regression sind 

- t-Test: UV: zweistufig nominal, AV: metrisch
- ANOVA: UV: mehrstufig nominal, AV: metrisch 
- Korrelation: Wenn UV und AV z-standradisiert sind (d.h. Mittelwert von 0 und Standardabweichung von 1 haben), dann ist die Korrelation gleich dem Regressionskoeffizienten $\beta_1$ (bei einer einfachen Regression mit einer einzigen UV). $\square$
:::




<!-- ![Common statistical tests as linear models](img/linear_tests_cheat_sheet.png){#fig-lindeloev} -->



### In voller Pracht


Hier ist die Regressionsgleichung in voller Pracht; s. @fig-regr-rules.
Links sieht man eine einfache Regression mit `hp` als Pr√§diktor (`X`, unabh√§ngige Variable) und `mpg` als abh√§ngige Variable (`Y`).
Das rechte Teildiagramm zeigt eine multiple Regression mit den Pr√§diktoren `hp` und `am`.^[Der Datensatz `mtcars` wird gerne als Studienobjekt verwendet, da er einfach ist und f√ºr viele Beispiele geeignet. 
Wenn Sie sich einen Sachverhalt an einem einfachen Datensatz vergegenw√§rtigen wollen, bietet sich auch der Datensatz `mtcars` an. 
Zudem ist er "fest in R eingebaut"; mit `data(mtcars)` k√∂nnen Sie ihn verf√ºgbar machen.]

Im einfachsten Fall sind die vom Modell vorhergesagten (gesch√§tzten) Werte, $\hat{y}$, durch eine einfache Gerade beschrieben, s. @fig-regr-rules, links.
Eine Gerade l√§sst sich durch folgende Formel beschreiben: $\hat{y} = \beta_0 + \beta_1$. 
Dabei ist $\beta_0$ der *Achsenabschnitt* (eng. intercept) und $\beta_1$ die *Steigung* der Regressiongeraden.


:::{def-lm}
In allgemeiner Form schreibt man die Regressionsgleichung so, s. @eq-lm


$$y = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_k + \epsilon$${#eq-lm}

Man nennt alle $\beta_0, \beta_1, \beta_2, ...$ die *Koeffizienten*, *Regressionsgewichte* oder *Parameter* des Modells [@gelman2021].
:::

Anhand von @eq-lm erkennt man auch, warum man von einem *linearen Modell* spricht: 
Y wird als gewichteter Mittelwert mehrerer Summanden ($X_1, X_2, ...$) berechnet.



```{r}
#| message: false
#| echo: false
#| layout-ncol: 2
#| label: fig-regr-rules
#| fig-cap: Die Regressionsgerade in voller Pracht
#| fig-subcap: 
#|   - "Einfache Regression (ein Pr√§diktor: hp)"
#|   - "Multiple Regression (zwei Pr√§diktoren: hp und am)"
data(mtcars)

mtcars$am <- factor(mtcars$am)

ggplot(mtcars) +
  aes(x = hp, y = mpg) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal()

ggplot(mtcars) +
  aes(x = hp, y = mpg, color = am) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  scale_color_okabeito() +
  theme(legend.position = c(0.9, .90))
```



## Unsicherheit

### Inferenz beinhaltet Ungewissheit


Inferenzstatistische Schl√ºsse sind mit Unsicherheit (Ungewissheit) behaftet: Schlie√ülich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), m√∂chte aber vom Teil auf das Ganze schlie√üen.




:::callout-important
Nichts Genaues wei√ü man nicht: 
Schlie√üt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. 
Man spricht von *Ungewissheit*, da man sich auf die *Unsicherheit das Wissen* √ºber die Genauigkeit des Schlie√üens bezieht
:::



Schlie√üt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, 
so geschieht das unter Unsicherheit; es ist ungewiss.
Man ist sich nicht sicher, 
dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger.

Schlie√ülich hat man *nicht* die ganze Population gesehen bzw. vermessen. 
*Sicher* ist man sich hingegen f√ºr die Stichprobe (Messfehler einmal ausgeblendet).
Zur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer m√∂glich).
Die Wahrscheinlichkeitstheorie bzw. -rechnung wird daher auch als die Mathematik des Zufalls bezeichnet.

::: {#def-zufall}

## Zuf√§lliges Ereignis

Unter einem zuf√§lligen (engl. random) Ereignis verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, 
wie etwa die Augenzahl Ihres n√§chsten W√ºrfelwurfs. Zuf√§llig bedeutet nicht (zwangsl√§ufig), 
dass das Ereignisse keine Ursachen besitzt. 
So gehorchen die Bewegungen eines W√ºrfels den Gesetzen der Physik, 
nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.
:::

:::{#exr-muenz}
üèã Welche physikalischen Randbedingungen wirken wohl auf einen M√ºnzwurf ein?$\square$
:::


:::{#exm-muenz}
### Beispiele zur Quantifizierung von Ungewissheit

Aussagen mit Unsicherheit k√∂nnen unterschiedlich pr√§zise formuliert sein.

-   Morgen regnet's $\Leftrightarrow$ Morgen wird es hier mehr als 0 mm Niederschlag geben ($p=97\%$).

-   Methode $A$ ist besser als Methode $B$ $\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert von $Y$ f√ºr Methode $A$ h√∂her als f√ºr Methode $B$.

-   Die Maschine f√§llt demn√§chst aus $\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den n√§chsten 1-3 Tagen ausfallen, laut unserem Modell.

-   Die Investition lohnt sich $\Leftrightarrow$ Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.
:::


:::{#exr-ungewiss}
üèã Geben Sie weitere Beispiele an!
:::


### Wahrscheinlichkeit



:::{#def-wskt}
### Wahrscheinlichkeit
Die Wahrscheinlichkeit ist ein Ma√ü daf√ºr, f√ºr wie sicher jemand es h√§lt, dass ein Ereignis eintritt. Die Wahrscheinlichkeit eines Ereignisses wird als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unm√∂glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. 
Je n√§her die Wahrscheinlichkeit bei 0 (1) liegt, desto sicherer sind wir,
dass das Ereignis (nicht) der Fall ist.$\square$
:::

Die Wahrscheinlichkeitsrechnung ist die typische Methode, um Ungewissheit zu pr√§zisieren, d.h. zu quantifizieren.


### Zwei Arten von Ungewissheit

Im Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. @fig-zwei-arten.


1. Wie (un)gewiss ist man sich √ºber die *Regressionsgewichte*?

2. Wie (un)gewiss ist man sich √ºber die *Korrektheit* des Modells? (Sind alle relevanten Variablen im Modell enthalten? Sind die Annahmen des Modells erf√ºllt?


```{mermaid}
%%| label: fig-zwei-arten
%%| fig-cap: Zwei Arten der Ungewissheit beim Modellieren
flowchart LR
X1 -->|Pr√§zision von Steigung und Achsenabschnitt?|B
X2 -. Korrektheit des Modells? .-> B

```


### Ungewissheit der Modellkoeffizienten

Wie man in @fig-regr-div sieht, k√∂nnen sich die Koeffizienten (Achsenabschnitt und Steigung) unterscheiden.
Woran liegt das?

:::{#exm-flights}
### Stichproben der New Yorker Fl√ºge
Nehmen wir an, wir ziehen ein paar Zufallstichproben aus der Menge (Population) aller Fl√ºge, 
die in New York im Jahre 2013 gestartet sind.
In jeder Stichprobe berechnen wir eine Regression zwischen Flugzeit und Versp√§tung des Flugs am Ankunftsort.
Sicherlich werden sich die Stichproben in ihren Kennwerten, z.B. in den Koeffizienten der genannten Regression, unterscheiden.$\square$
:::

```{r}
#| echo: false

set.seed(42)
stipro1 <- sample_n(flights, size = 100)

set.seed(3141)
stipro2 <- sample_n(flights, size = 100)

set.seed(2718)
stipro3 <- sample_n(flights, size = 100)
```


```{r}
#| eval: false
library(nycflights13)
data(flights)

stipro1 <- sample_n(flights, size = 100)
stipro2 <- sample_n(flights, size = 100)
stipro3 <- sample_n(flights, size = 100)
```


```{r}
#| echo: false
#| fig-cap: Regressionsanalysen mit verschiedenen Koeffizienten aufgrund der Zuf√§lligkeit  des Stichprobenziehens 
#| label: fig-regr-div
#| layout-ncol: 3
#| fig-subcap: 
#|   - Stichprobe 1
#|   - Stichprobe 2
#|   - Stichprobe 3

ggplot(stipro1, aes(x = air_time, y = arr_delay)) +
  geom_point() +
  geom_smooth(method = "lm")

ggplot(stipro2, aes(x = air_time, y = arr_delay)) +
  geom_point() +
  geom_smooth(method = "lm")

ggplot(stipro3, aes(x = air_time, y = arr_delay)) +
  geom_point() +
  geom_smooth(method = "lm")
```


Der Grund f√ºr die Schwankungen der Modellparameter zwischen den Stichproben ist die Zuf√§lligkeit des Stichprobenziehens. 
Je nachdem, wie es der Zufall (oder sonst wer) will, landen bestimmte F√§lle (Fl√ºge in unserem Beispiel) in unserer Stichprobe.
Zumeist unterscheiden sich die Stichproben; theoretisch k√∂nnten sie aber auch rein zuf√§llig gleich sein.

:::callout-important
Stichproben-Kennwerte schwanken um den tats√§chlichen Wert in der Population herum.$\square$
:::

Um diese Ungewissheit, die sich in den Schwankungen der Stichproben-Regressionskoeffizienten ausdr√ºckt, anzuzeigen, 
ist ein "grauer Schleier" um die Regressionsgeraden in @fig-regr-div gekennzeichnet.
Dieser grauer Schleier gibt also eine Spannbreite anderer, 
plausibler Ergebnisse an, die sich in einer anderen Stichprobe auch manifestieren k√∂nnten.



#### Ungewissheit zur Korrektheit des Modells

Angenommen, wir sind uns *sicher* √ºber die Werte der Modellparameter,
also √ºber die Lage der Regressionsgeraden, anschaulich gesprochen.
Dann bliebe immer noch Ungewissheit, inwieweit das Modell korrekt spezifiziert ist: 
Sind genau die richtigen Variablen im Modell enthalten?


Diese Art der Ungewissheit ist dann interessant, 
wenn man f√ºr einzelne F√§lle eine Vorhersage macht und sich fragt, 
wie pr√§zise diese Vorhersage ist.


```{r}
#| label: fig-resid-var
#| fig-cap: Regressionsanalyse mit gleicher Regressionsgerade, aber unterschiedlicher Vorhersageg√ºte
#| fig-subcap: 
#|   - geringer Vorhersagefehler (hohe Vorhersageg√ºte)
#|   - hoher Vorhersagefehler
#|   - auch hoher Vorhersagefehler
#| echo: false
#| layout-ncol: 3

set.seed(42)
d1 <- tibble(
  x = rnorm(50),
  y1 = x + rnorm(50, mean = 0, sd = .5),
)

lm1 <-  lm(y1 ~ x, data = d1)

d1 <-
  d1 %>% 
  mutate(pred = predict(lm1)) %>% 
  mutate(above_pred = ifelse(y1 > pred, "above", "below"),
         e = resid(lm1),
         e2 = e * 3,
         e3 = ifelse(e > 0, + 2, -2),
         y2 = pred + e2,
         y3 = pred + e3)

ggplot(d1, aes(x, y1)) + 
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  scale_y_continuous(limits = c(-4, 4))


ggplot(d1, aes(x, y2)) + 
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  scale_y_continuous(limits = c(-4, 4))

ggplot(d1, aes(x, y3)) + 
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  scale_y_continuous(limits = c(-4, 4))

```




### Ich wei√ü, was ich nicht wei√ü: Ungewissheit angeben


Streng genommen ist eine Inferenz ohne Angabe der Ungewissheit (Genauigkeit der Sch√§tzung) wertlos.
Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% sch√§tzt, 
l√§sst aber offen wie *sicher* (pr√§zise) die Sch√§tzung (der Modellparameter) ist.
Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Sch√§tzung schlie√üt sogar 41% oder 43% aus.

:::callout-important
Schlie√üt man auf eine Population, sch√§tzt also die Modellparameter, 
so sollte stets die (Un-)Genauigkeit der Sch√§tzung, also die Ungewissheit des Modells, angegeben sein.$\square$
:::



Im Rahmen der Regressionsanalyse schl√§gt sich die Ungewissheit an zwei Stellen nieder:

1.  zur Pr√§zision der Regressionsgeraden $\beta_0$, $\beta_1$
2.  zur Modellg√ºte ($R^2$) bzw. zum Vorhersagefehler, $\sigma$^[$\sigma$, das griechische *s* f√ºr Streuung (um die Regressionsgerade herum), manchmal wird auch e wie *error* verwendet]



### Visualisierung von Ungewissheit


::: {#def-punktschaetzer}

### Punktsch√§tzer

Gibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem *Punktsch√§tzer*.


Punktsch√§tzer beinhalten *keine Angabe* der Sch√§tz(un)genauigkeit, s. Abb. @fig-ungewiss2, links. Rot markiert: Die Punktsch√§tzung von `mpg` f√ºr `hp=200`.

:::


<!-- ![Eine Punktsch√§tzung der Regressionsgeraden und die zugeh√∂rige Ungewissheit Ungewissheit](img/fig-punktschaetzer.png){#fig-punktschaetzer2} -->




```{r fig-punktschaetzer-ALT-DONT-RUN}
#| echo: false
#| message: false
#| eval: true

lm1_glm <- lm(mpg ~ hp, data = mtcars)

mtcars <-
  mtcars %>%
  mutate(pred = 30 - hp*0.07)


pred_interval <-
  tibble(
    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),
    mpg = predict(lm1_glm, newdata = data.frame(hp)),
    lwr = mpg - 2*3,
    upr = mpg + 2*3
  )

plot1 <-
  ggplot(mtcars,
       aes(x = hp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200,
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)


lm1_glm <- lm(mpg ~ hp, data = mtcars)

mtcars <- 
  mtcars %>% 
  mutate(pred = 30 - hp*0.07)


pred_interval <-
  tibble(
    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),
    mpg = predict(lm1_glm, newdata = data.frame(hp)),
    lwr = mpg - 2*3,
    upr = mpg + 2*3
  )


plot2 <-
  ggplot(mtcars,
       aes(x = hp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  annotate("point", x = 200,
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)
```


```{r}
#| echo: false
lm1 <- lm(mpg ~ hp, data = mtcars)

p_ungewiss1 <- 
  mtcars %>% 
  ggplot(aes(x = hp, y = mpg)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  scale_y_continuous(limits = c(0,40)) +
  annotate("point", x = 200, y = predict(lm1, newdata = data.frame(hp=200)),
           color = "red", size = 5, alpha = .5)

```







In Abb. @fig-ungewiss2, links, ist die Ungewissheit in den *Regressionskoeffizienten* visualisiert: 
Wie sicher sind wir uns bzgl. der Lage der Regressionskoeffizienten? Vgl. @def-punktschaetzer.



Auch wenn wir uns *sicher* w√§ren im Hinblick auf die Regressionsgewichte in Abb. @fig-ungewiss2, links, 
bliebe Ungewissheit bei der Vorhersage des Bereichs plausibler Werte f√ºr individuelle Vorhersagen, s. @fig-ungewiss2, rechts.
Unsere Sch√§tzungen w√§ren auch dann nicht sicher, nicht fehlerfrei, wenn wir den genauen Verlauf der Regressiongerade sicher w√ºssten.
Das liegt daran, da das Modell nicht alle Einfl√ºsse auf Y ber√ºcksichtigt, sondern nur einen einzigen, hier als X bezeichnet. 
Das Modell hat also keine perfekte Information, es ist ungewiss √ºber alle m√∂glichen Einflussfaktoren auf Y.
W√ºsste unser Modell alle Einflussfaktoren genau, so w√§re unser Vorhersageintervall sehr schmal (bzw. h√§tte null Breite). 

In Abb. @fig-ungewiss2, rechts, ist nicht nur die Ungewissheit durch die Regressionsgewichte, 
sondern auch die Ungewissheit zur Vorhersage der Y-Werte individueller Beobachtungen dargestellt. 
In diesem Fall spricht man von einem "Vorhersageintervall", da man nicht nur von "typischen F√§llen" auf der Regressiongeraden spricht, 
sondern f√ºr echte F√§lle Vorhersagen (Sch√§tzungen) t√§tigt, wo auch die Ungewissheit der Modellg√ºte relevant ist.


<!-- ![Das Vorhersageintevall zeigt eine Punktsch√§tzung und ihre Ungewissheit](img/fig-predintervall.png){fig-ungewiss2 width="50%"} -->


```{r p-zweifach}
#| echo: false
#| fig-cap: Die zwei Arten der Ungewissheit visualisiert
#| label: fig-ungewiss2
#| message: false
#| layout-ncol: 2
#| eval: true
#| fig-subcap: 
#|   - Eine Punktsch√§tzung der Regressionsgeraden und die zugeh√∂rige Ungewissheit der Koeffizienten
#|   - "Das Vorhersageintevall zur Regressionsgeraden zeigt die Ungewissheit f√ºr die jeweiligen Beobachtungen"


lm1_pred <- predict(lm1, interval = "prediction")

mtcars <-
  mtcars %>% 
  mutate(upr = predict(lm1, interval = "prediction")[, 3],
         lwr = predict(lm1, interval = "prediction")[, 2])

p_ungewiss2 <- ggplot(mtcars) +
  aes(x = hp, y = mpg) +
  geom_point()+
  # geom_line(aes(x = hp, y = upr), linetype = "dashed") +
  geom_ribbon(aes(ymin = lwr, ymax = upr, x = hp), fill = "#56B4E9FF", alpha = .3) +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200,
           y = predict(lm1, newdata = data.frame(hp = 200)),
           color = "#E69F00FF",
           alpha = .5,
           size = 5) +
  annotate("errorbar", x = 200, ymin = 8.5, ymax = 24.5, color = "#009E73FF", size = 2) +
  scale_y_continuous(limits = c(0,40))


p_ungewiss1 
p_ungewiss2
```

@fig-ungewiss2 zeigt auch, dass f√ºr eine Beobachtung mit `hp=200` der *Punktsch√§tzer* 
der gesch√§tzte Wert von `mpg` bei ca `16.5` liegt.
Das ist sozusagen unser *Best Guess*.
Weiterhin ist (in gr√ºn) das *Vorhersageintervall* f√ºr `hp=200` angezeigt.
F√ºr Beobachtungen mit `hp=200` liegt der Bereich plausibler `mpg`-Werte 
in dem (gr√ºn) markierten Bereich (ca. 8 bis 25).

:::{#def-vorhersageintervall}
### Vorhersageintervall
Ein Vorhersageintervall zeigt den Bereich plausibler Werte (laut unserer Analyse) 
f√ºr eine Beobachtung mit bestimmten Pr√§diktor-Werten.$\square$
:::



Wie man sieht, wird die Ungewissheit *gr√∂√üer*, wenn man beide Arten der Ungewissheit ber√ºcksichtigt. 
Das Vorhersage-Intervall ber√ºcksichtigt Ungewissheit in $\beta_0, \beta_1, \epsilon$ bei der Vorhersage von $\hat{y_i}$.


:::{#exr-zweifache-ungewissheit}
üèã Geben Sie ein vergleichbares Beispiel an!
:::



### Konfidenzintervall


Wir sehen in @fig-ungewiss2, dass ein "Ungewissheitskorridor" angegeben wird f√ºr die Lage der Regressionsgerade (linkes Teildiagramm) 
bzw. f√ºr den Bereich plausibler Vorhersagen im konkreten Fall einer Beobachtung mit bestimmten X-Wert.
Entsprechend wird nicht ein *Punktsch√§tzer*, sondern ein *Sch√§tzbereich* angegeben.
Man spricht auch von einem *Konfidenzintervall* oder *Unsicherheitsbereich*.^[Tats√§chlich gibt es mehrere Synonyme oder √§hnliche Begriffe f√ºr Konfidenzintervall. Wir kommen sp√§ter darauf detaillierter zu sprechen.]

::: {#def-konfintervall}

### Konfidenzintervall

Ein Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff f√ºr Sch√§tzbereiche f√ºr Parameter wie Regressionskoeffizienten . 
Die Grenzen eines Konfidenzintervall markieren einen Bereich plausibler Werte f√ºr einen Parameter. 

:::



Es gibt verschiedene Arten, Konfidenzintervalle zu berechnen; 
wir sprechen in sp√§teren Kapiteln dazu ausf√ºhrlicher.
Ein Konfidenzintervall wird h√§ufig mit 90% oder 95% Genauigkeit angegeben. 
Im Kontext der Bayes-Analyse - auf der dieser Kurs aufbaut - ist ein Konfidenzintervall einfach zu interpretieren. 
Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall f√ºr den Anteil der R-Fans angegeben wird, 
dass sich von 40 bis 44 Prozent erstreckt.
Dieser Befund l√§sst sich so interpretieren: ‚ÄúLaut Modell liegt der gesuchte Anteil der R-Fans mit einer Wahrscheinlichkeit von 95% im Bereich von 40 bis 44 Prozentpunkten.‚Äù 
Diese (einfache) Interpretation ist im Frequentismus *nicht* m√∂glich.





:::{#exm-ungewisskorr}
Geben Sie Beispiele f√ºr Konfidenzintervalle an.
:::

##  Frequentismus vs. Bayes-Inferenz


::::{.columns}
:::{.column}
###  Frequentismus: Klassische Inferenz

-   Die Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zur√ºckgewiesen.
-   Nur die Daten selber fliesen in die Ergebnisse ein, keine Vorannahmen.
-   Wahrscheinlichkeit wird √ºber relative H√§ufigkeiten definiert.
-   Es ist *nicht* m√∂glich, die Wahrscheinlichkeit einer Hypothese bzw. eines Werts in der Population (eines Parameters) anzugeben.
-   Stattdessen wird angegeben, wie h√§ufig eine vergleichbare Datenlage zu erwarten ist, wenn der Versuch sehr h√§ufig wiederholt ist.
-   Ein Gro√üteil der Forschung (in den Sozialwissenschaften) verwendet (aktuell) diesen Ansatz.
:::


:::{.column}
### Bayesianische Inferenz

-   Vorwissen (Priori-Wissen) flie√üt explizit in die Analyse ein (zusammen mit den Daten).
-   *Wenn* das Vorwissen gut ist, wird die Vorhersage durch das Vorwissen genauer, ansonsten ungenauer.
-   Die Wahl des Vorwissens muss explizit (kritisierbar) sein.
-   In der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen f√ºr Hypothesen m√∂glich.
-   Die Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (f√ºr g√§ngige Computer) komfortabel geworden.
:::
::::




### Frequentismus

#### Der p-Wert

Die zentrale Statistik des Frequentismus hei√üt der *p-Wert*

Der p-Wert ist so definiert, vgl. @wasserstein2016: 

>   Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zuf√§llig verschieden und auf Basis unseres Modells)?

Findet man $p<.05$ (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), 
so spricht man von "(statistischer) Signifikanz" und nimmt dies als Beleg, dass man einen Effekt gefunden hat, 
die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.
Faktisch entscheidet man sich, die Forschungshypothese weiterhin als "vorl√§ufig g√ºltig" 
oder zumindest als "nicht widerlegt" zu betrachten.


:::{#exr-p}
üèã Recherchieren Sie eine Definition des p-Werts und lesen Sie sie einem Freund. 
Beobachten sie die Reaktionen auf Ihre Erkl√§rung.$\square$
:::

Der p-Wert wird oft falsch verstanden [@badenes-ribera2016].
Aber er ist auch nicht leicht zu verstehen, meint Meister Yoda, s. @fig-yoda.
Hier sind einige *FALSCHE* Interpretationen zum p-Wert laut der Autoren:

- üôÖ‚Äç‚ôÄ Der p-Wert w√ºrde die Wahrscheinlichkeit der Nullhypothese oder der Forschungshypothese angeben. üôä 
- üôÖ‚Äç‚ôÄ Der p-Wert w√ºrde ein inhaltlich bedeutsames, praktisch signifikantes Ergebnis anzeigen. üôä 


![Der p-Wert ist wenig intuitiv, meint Meister Yoda](img/pvalue-yoda.jpg){#fig-yoda width=50%}


#### Konfidenzintervalle

Die korrekte Definition der Konfidenzintervalls in *frequentistischer* Lesart lautet:



>   Der Konfidenzbereich, z.B. von 95%, repr√§sentiert den Anteil der Konfidenzintervalle bei sehr vielen (oder undentlich vielen) Wiederholungen des Experiments, 
die den echten Parameterwert enthalten [@hoekstra2014].


::::: {.content-visible when-format="html"}

Die folgende Visualisierung (@fig-sim-ci) zeigt das Prinzip frequentistischer Konfidenzintervalle:
*Auf Dauer* enthalten 95% der Stichproben den wahren Wert (in der Population).
^[Siehe auch [hier](https://rpsychologist.com/d3/ci/) f√ºr eine sch√∂ne Visualisierung von [RPsychologist](https://rpsychologist.com/).]


::::{#fig-sim-ci}

::: {.figure-content}

<br><br><br> <!-- Insert vertical space here -->


{{< include children/sim-ci.qmd >}}

:::

Ein frequentistisches 95%-Konfidenzintervall: 
Auf Dauer enthalten 95% der Konfidenzintervalle den wahren Wert in der Population.

::::
:::::

:::{.callout-important}
Ein frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit 
eines Werts in der Population (eines Parameters). 
Stattdessen wird eine Aussage √ºber das Ergebnis einer sehr h√§ufig wiederholten Stichprobenziehung berichtet. Ob ein bestimmtes (unseres, Ihres) den wahren Wert enth√§lt, 
bzw. mit welcher Wahrscheinlichkeit es den wahren Wert enth√§lt, 
dar√ºber macht das frequentistische Konfidenzintervall keine Aussagen. $\square$
:::

#### Aus der Forschung (Vertiefung^[nicht pr√ºfungsrelevant])


Frequentistische Konfidenzintervalle werden oft falsch verstanden, 
wie die folgende Studie zeigt. 
Das liegt aber nicht daran, dass die Menschen zu dumm sind, 
sondern dass frequentistische Konfidenzintervalle f√ºr viele Menschen kontraintuitiv sind.

@hoekstra2014 berichten von einer Studie, in der $n=442$ Bachelor-Studentis, $n=34$ Master-Studentis und $n=120$ Forschende befragt wurden.

Den Versuchpersonen wurde folgender Fragebogen vorgelegt, s. @fig-bumbledorf.

![Frageobgen zu Konfidenzintervallen](img/bumbledorf.png){#fig-bumbledorf}

Kurz gesagt war die Frage, die die Befragten beantworten sollten:

>    In einem Experiment wird ein 95%-Konfidenzintervall mit dem Bereich von 0.1 bis 0.4 beichtet. Welcher der folgenden sechs Aussagen sind richtig bzw. falsch?

Mit "Konfidenzintervall" meinen die Forschenden ein *frequentistisches* Konfidenzintervall.

Alle diese sechs Aussagen sind *FALSCH*. Die Aussagen lauten:



1. Die Wahrscheinlichkeit, dass der wahre Mittelwert gr√∂√üer als 0 ist, betr√§gt mindestens 95 %.

2. Die Wahrscheinlichkeit, dass der wahre Mittelwert gleich 0 ist, ist kleiner als 5 %.

3. Die ‚ÄûNullhypothese‚Äú, dass der wahre Mittelwert gleich 0 ist, ist wahrscheinlich falsch.

4. Es gibt eine 95%ige Wahrscheinlichkeit, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.

5. Wir k√∂nnen mit 95%iger Sicherheit sagen, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.

6. Wenn wir das Experiment immer wieder wiederholen w√ºrden, dann liegt der wahre Mittelwert in 95 % der F√§lle zwischen 0,1 und 0,4.


Aussagen 1-4 weisen den Hypothesen bzw. den Parametern eine Wahrscheinlichkeit zu, 
was im Frequentismus nicht erlaubt ist. 
Aussagen 5-6 spezifizieren die Grenzen des Sch√§tzintervalls, 
allerdings kann das Konfidenzintervall nur Aussagen zu den zugrundeliegenden Stichproben, 
nicht zum Sch√§tzintervall, machen.


Die Ergebnisse zeigen, dass die Aussagen mehrheitlich *falsch* verstanden wurden, 
also mit "stimmt" angekreuzt wurden, s. @fig-ci-wrong.

![Eine hohe Zustimmung zu den sechs falschen Aussagen](img/ci-wrong.png){#fig-ci-wrong width=75%}


#### Bayes-Statistik

Die zentrale Statistik der Bayes-Statistik ist die *Posteriori-Verteilung*.

Die Posteriori-Verteilung beantwortet uns die Frage: 
"Wie wahrscheinlich ist die Forschungshypothese (oder Varianten von ihr), jetzt, 
nachdem wir die Daten kennen, auf Basis unseres Modells?"


In der Bayes-Statistik sind Aussagen folgender Art erlaubt:

>    Mit einer Wahrscheinlichkeit von 95% ist der neue Webshop besser als der alte.
>    Mit einer Wahrscheinlichkeit von 89% liegt die Wirksamkeit des neuen Medikaments zwischen 0.1 und 0.4.



[In diesem Post](https://data-se.netlify.app/2022/01/27/warum-bayes/) wird f√ºr Bayes geworben 
und (einseitig) Stellung pro Bayes bezogen.



### Frequentist und Bayesianer


Im Cartoon 1132 [von xkcd](https://xkcd.com/) wird sich √ºber das Nicht-Ber√ºcksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. @fig-xkcd-bayes.

![Frequentist wettet mit Bayesianer](img/frequentists_vs_bayesians_2x.png){#fig-xkcd-bayes width=50%}

[Quelle](https://xkcd.com/1132/)






<div>

<a href="https://imgflip.com/memegenerator">from Imgflip Meme Generator</a>

</div>

### Beispiel zum Nutzen von Apriori-Wissen 1

Ein Betrunkener behauptet, er k√∂nne hellsehen.
Er wirft eine M√ºnze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.
Die Wahrscheinlichkeit dieses Ergebnisses ist sehr gering ($2^{-10}$) unter der Hypothese, dass die M√ºnze fair ist, dass Ergebnis also "zuf√§llig" ist, also $p < .05$ und damit ist das Ergebnis "statistisch signifikant".

Unser Vorwissen l√§sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zuf√§lligkeit des Ergebnisses wohl nicht verwerfen.

### Beispiel zum Nutzen von Apriori-Wissen 2

Eine Studie [@gelman2021] fand einen "gro√üen Effekt" auf das Einkommen von Babies, die eine Stunde pro Woche w√§hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), $n=127$.
Nach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% h√∂her (als in der Kontrollgruppe) mit einem Konfidenzintervall von \[+2%,+98%\].

Allerdings l√§sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln l√§sst. Wir w√ºrden den Effekt lieber in einem konservativeren Intervall sch√§tzen (enger um Null).








## Fazit



:::callout-important
[Kontinuierliches Lernen](https://imgflip.com/i/77wn7m) ist der Schl√ºssel zum Erfolg.
:::




## Aufgaben


### Paper-Pencil-Aufgaben


1. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz/)
3. [ttest-als-regr](https://datenwerk.netlify.app/posts/ttest-als-regr/ttest-als-regr/)
4. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau/)
12. [Warum-Bayes](https://datenwerk.netlify.app/posts/warum-bayes/warum-bayes)
13. [samples-nyc2](https://datenwerk.netlify.app/posts/samples-nyc2/)




### Aufgaben, f√ºr die man einen Computer braucht


1. [korr-als-regr](https://datenwerk.netlify.app/posts/korr-als-regr/korr-als-regr/)
11. [punktschaetzer-reicht-nicht](https://datenwerk.netlify.app/posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html)
8. [ungewiss-arten-regr](https://datenwerk.netlify.app/posts/ungewiss-arten-regr/ungewiss-arten-regr.html)
6. [inferenz-fuer-alle](https://datenwerk.netlify.app/posts/inferenz-fuer-alle/inferenz-fuer-alle)
7. [adjustieren1a](https://datenwerk.netlify.app/posts/adjustieren1a/adjustieren1a.html)
5. [adjustieren2a](https://datenwerk.netlify.app/posts/adjustieren2a/adjustieren2a/)
10. [lm-standardfehler](https://datenwerk.netlify.app/posts/lm-standardfehler/lm-standardfehler)
9. [vorhersageintervall1](https://datenwerk.netlify.app/posts/vorhersageintervall1/vorhersageintervall1.html)




## ---



![](img/outro-02.jpg){width=100%}





