# Einfache lineare Modelle


## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...



- die Post-Verteilung f√ºr einfache lineare Modelle in R berechnen
- zentrale Informationen zu Modellparametern - wie Lage- oder Streuungsma√üe und auch Sch√§tzintervalle - aus der Post-Verteilung herauslesen
- k√ºnftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren


### Begleitliteratur

Der Stoff dieses Kapitels orientiert sich an @mcelreath2020, Kap. 4.4.





### Vorbereitung im Eigenstudium

- [Statistik1, Kap. "Geradenmodelle 1"](https://statistik1.netlify.app/080-regression1)




### Ben√∂tigte R-Pakete

In diesem Kapitel ben√∂tigen Sie folgende R-Pakete.


```{r}
#| message: false
library(tidyverse)
library(easystats)
library(rstanarm)  # Bayes-Golem
library(ggpubr)  # Datenvisualisierung
```


```{r libs-hidden}
#| include: false
library("latex2exp")
library("patchwork")
library("gt")

theme_set(theme_modern())
```


Da wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket `{easystats}` verwenden: [Hier](https://easystats.github.io/easystats/articles/list_of_functions.html) finden Sie eine √úbersicht aller Funktionen des Pakets.^[Da es viele Funktionen sind, bietet es sich an mit *Strg-F* auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.]


### Ben√∂tigte Daten {#sec-data-lm}

In diesem Kapitel ben√∂tigen wir den Datensatz zu den !Kung-Leuten, `Howell1a`, @mcelreath2020.
Sie k√∂nnen ihn [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv) herunterladen.

{{< downloadthis data/Howell1a.csv dname = "Howell1a" >}}

```{r Post-Regression-2}
#| fig-asp: 0.5
#| message: false
Kung_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv"  # <1>

d <- read.csv(Kung_path)   # <2>

d2 <- d %>% filter(age > 18)  # <3>
```
1. Pfad zum Datensatz; Sie m√ºssen online sein, um die Daten herunterzuladen.
2. Daten einlesen
3. Auf Erwachsene Personen begrenzen (d.h. Alter > 18)


### Einstieg


:::{#exm-wdh-lm}
### Grundkonzepte der linearen Regression
Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! $\square$
:::

:::{#exm-wdh-post}
### Was ist eine Post-Verteilung und wozu ist sie gut?
Erkl√§ren Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. $\square$
:::


### √úberblick

Dieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die K√∂rpergr√∂√üe auf das Gewicht zur√ºckgef√ºhrt wird; also ein sehr eing√§ngiges Modell.  
Neu ist dabei lediglich, dass die Parameter des Modells - $\beta_0$, $\beta_1$, $\sigma$ - jetzt √ºber eine Post-Verteilung verf√ºgen. 
Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik.
Die "normale" Regression hat uns nur einzelne Werte f√ºr die Modellparameter geliefert ("Punktsch√§tzer"). 
Mit Bayes haben wir eine ganz Verteilung pro Parameter.




## Post-Verteilung der Regression


### Einfache Regression



Die (einfache) Regression pr√ºft, inwieweit zwei Variablen, $Y$ und $X$ linear zusammenh√§ngen.
Je mehr sie zusammenh√§ngen, desto besser kann man $X$ nutzen, um $Y$ vorherzusagen (und umgekehrt).
H√§ngen $X$ und $Y$ zusammen, hei√üt das nicht (unbedingt), dass es einen *kausalen* Zusammenhang zwischen $X$ und $Y$ gibt.
*Linear* ist ein Zusammenhang, wenn der Zuwachs in $Y$ relativ zu $X$ konstant ist: wenn $X$ um eine Einheit steigt, steigt $Y$ immer um $b$ Einheiten (nicht kausal, sondern deskriptiv gemeint).^[
[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv), @mcelreath2020.]

Laden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y), @fig-kung-zshg.




:::::{#fig-kung-zshg}



:::: {.figure-content}

:::{.panel-tabset}

### Mit `ggplot2`

```{r}
d2 %>% 
  ggplot(
       aes(x = weight, y = height)) +
  geom_point(alpha = .7) +
  geom_smooth(method = "lm")
```


### Mit `ggpubr`

```{r}
ggscatter(d2,
          x = "weight", y = "height",
          add = "reg.line") 
```



:::
::::



Der Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y)

:::::



### Statistiken zum !Kung-Datensatz

```{r}
#| echo: false
rm(d)
rm(d2)
```


Die Daten k√∂nnen Sie [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv) herunterladen. 


@tbl-kung1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.

```{r Post-Regression-3}
#| echo: true
#| eval: true
#| results: hide
Kung_path <- "data/Howell1a.csv"  
d <- read_csv(Kung_path)  

d2 <- d %>% filter(age > 18)

describe_distribution(d2)
```



```{r Post-Regression-4, echo = FALSE, eval = TRUE}
#| echo: false
#| label: tbl-kung1
#| tbl-cap: "Verteiung der (metrischen) Variablen im !Kung-Datensatz"
describe_distribution(d2) |> display()
```


Wie aus @tbl-kung1 abzulesen ist, betr√§gt das mittlere K√∂rpergewicht (`weight`) liegt ca. 45kg (sd 7 kg).


### Etwas mehr EDA




Wir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket `DataExplorer` hat ein paar nette Hilfen zur explorativen Datenanalyse.


```{r}
#| message: false
library(DataExplorer)
```

#### Gibt es fehlende Werte?

Nein, s. Abb. @fig-na.

```{r}
#| fig-cap: Fehlende Werte - fehlen.
#| label: fig-na
d2 %>% plot_missing()
```



#### Verteilung der numerischen Variablen

Betrachten wir die Verteilung der *numerischen* Variablen des Datensatzes, s. @fig-d2-hists.


```{r}
#| label: fig-d2-hists
#| fig-cap: "Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes"
d2 %>% plot_histogram()
```



#### Verteilung der kategorialen Variablen


Betrachten wir die Verteilung der *kategorialen* Variablen des Datensatzes, s. @fig-d2-bars.


```{r}
#| label: fig-d2-bars
#| fig-cap: "Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes"
d2 %>% plot_bar()
```



#### Korrelationen

Die Korrelationen der (numerischen) Variablen sind in @fig-num-korrs dargestellt.

```{r}
#| label: fig-num-korrs
#| fig-cap: "Korrelationsmatrix"
d2 %>% plot_correlation()
```


:::{#exr-Bonus}
### EDA-Bericht

Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: `create_report(d2)`. $\square$
:::







### Pr√§diktor zentrieren 




Zieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor "zentrieren", engl. to *c*enter).
Wenn man den Pr√§diktor (`weight`) zentriert hat, ist der Achsenabschnitt, $\beta_0$, einfacher zu verstehen.
In einem Modell mit zentriertem Pr√§diktor (`weight`) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. 
W√ºrde man `weight` nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit `weight=0` an, was nicht wirklich sinnvoll zu interpretieren ist.
Vgl. @gelman2021, Kap. 10.4,  12.2.



Man zentriert eine Variable $X$, indem man von $x_i$ den Mittelwert $\bar{x}$ abzieht: $x_i - \bar{x}$.


```{r Post-Regression-7, echo = TRUE}
#| eval: false
d3 <-
  d2 %>% 
  mutate(weight_c = weight - mean(weight))
```


Mit Hilfe von `center()` aus `{easystats}` kann man sich das Zentrieren auch erleichtern.


```{r}
d3 <- 
  d2 %>% 
  mutate(weight_c = as.numeric(center(weight)))
```






```{r Post-Regression-8}
#| echo: false
d3 %>% 
  slice_head(n=3) %>% 
  gt() %>% 
  fmt_number(columns = everything(), decimals = 0)
```


Wie man sieht, wird die Verteilung von `weight` durch die Zentrierung "zur Seite geschoben": 
Der Mittelwert von `weight_c` (das zentrierte Gewicht) liegt jetzt bei 0, s. @fig-d3-center.



```{r Post-Regression-9, fig.asp=0.4}
#| echo: false
#| label: fig-d3-center
#| fig-cap: 'Das Zentrieren √§ndert die Verteilungsform nicht, sondern "schiebt" die Verteilung nur zur Seite'

d3 %>% 
  select(weight, weight_c) %>% 
  ggplot() +
  geom_histogram(aes(x = weight), fill = "grey40") +
  geom_histogram(aes(x = weight_c), fill = "black") +
  theme_minimal() +
  geom_segment(x = mean(d3$weight), 
               xend = 0, 
               y = 20, yend = 20, 
               arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
               color = okabeito_colors()[1], size = 2) +
  geom_vline(xintercept = mean(d3$weight), color = okabeito_colors()[1], 
             linetype = "dashed") +
  geom_vline(xintercept = 0, color = okabeito_colors()[1],
             linetype = "dashed") +
  annotate("label", x = 0, y = 5, label = "Gewicht zentriert") +
  annotate("label", x = mean(d3$weight), y = 5, label = "Gewicht")  +
  labs(caption = "Die vertikalen gepunkteten Linien zeigen die Mittelwerte der Verteilungen.")
```



Das schwierigste ist dabei, nicht zu vergessen, dass `d3` die Tabelle mit zentriertem Pr√§diktor ist, nicht `d2`.


## Modell m43: zentrierter Pr√§diktor

üì∫ [Pr√§diktoren zentrieren](https://youtu.be/3Z1dXPO_MSE)


Einige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren:
Bei einem (erwachsenen) Menschen mit *Gewicht 0*, was w√§re wohl die K√∂rpergr√∂√üe?
Hm, Philosophie steht heute nicht auf der Tagesordnung.

Da w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht.
Zum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!


:::callout-important
Durch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.
:::





### Modelldefinition von `m43`

F√ºr jede Auspr√§gung des Pr√§diktors (`weight_centered`), $wc_i$, wird eine Post-Verteilung f√ºr die abh√§ngige Variable (`height`, $h_i$) berechnet.
Der Mittelwert $\mu$ f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel).
 Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel).
 Wir brauchen Priori-Werte f√ºr die Steigung $\beta_1$ und den Achsenabschnitt $\beta_0$ der Regressionsgeraden.
 Au√üerdem brauchen wir einen Priori-Wert, der die Streuung $\sigma$ der Gr√∂√üe (`height`) angibt; dieser Wert wird als exonentialverteilt angenommen.
 Der Likelihood gibt an, wie wahrscheinlich ein Wert `height` ist, gegeben $\mu$ und $\sigma$. 
@thm-modm42 stellt die Modelldefinition dar.


::: ${#thm-modm42}

### Modelldefinition

$$\begin{align*}
\color{red}{\text{height}_i} & \color{red}\sim \color{red}{\operatorname{Normal}(\mu_i, \sigma)} && \color{red}{\text{Likelihood}} \\
\color{green}{\mu_i} & \color{green}= \color{green}{\beta_0 + \beta_1\cdot \text{weightcentered}_i}  && \color{green}{\text{Lineares Modell} } \\
\color{blue}{\beta_0} & \color{blue}\sim \color{blue}{\operatorname{Normal}(178, 20)} && \color{blue}{\text{Priori}} \\
\color{blue}{\beta_1}  & \color{blue}\sim \color{blue}{\operatorname{Normal}(0, 10)}  && \color{blue}{\text{Priori}}\\
\color{blue}\sigma & \color{blue}\sim \color{blue}{\operatorname{Exp}(0.1)}  && \color{blue}{\text{Priori}}
\end{align*}\quad \square$$
:::



:::callout-note
Der Achsenabschnitt (engl. *intercept*) eines Regressionsmodell wird in der Literatur oft mit $\beta_0$ bezeichnet,
aber manchmal auch mit $\alpha$.
Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ü§∑
:::






### Likelihood, `m43`



$$
\begin{aligned}
\color{red}{\text{height}_i} & \color{red}\sim \color{red}{\operatorname{Normal}(\mu_i, \sigma)} && \color{red}{\text{Likelihood}}
\end{aligned}
$$




 Der Likelihood von `m43` ist √§hnlich zu den vorherigen Modellen (`m41, m42`).
 Nur gibt es jetzt ein kleines "Index-i" am $\mu$ und am $h$ (h wie `heights`).
 Es gibt jetzt nicht mehr nur einen Mittelwert $\mu$, sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert $\mu_i$.
 Lies  etwa so:

>    "Die Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person $i$ zu beobachten, gegeben $\mu$ und $\sigma$ ist normalverteilt (mit Mittelwert $\mu$ und Streuung $\sigma$)".




### Regressionsformel, `m43`


$$
\begin{aligned}
\color{green}{\mu_i} & \color{green}= \color{green}{\beta_0 + \beta_1\cdot \text{weightcentered}_i}  && \color{green}{\text{Lineares Modell} } \\
\end{aligned}
$$


 $\mu$ ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. $\mu$ wird jetzt (deterministisch) *berechnet*. Gegeben $\beta_0$ und $\beta_1$ ist $\mu$ ohne Ungewissheit bekannt.
 $\text{weight}_i$ ist der Pr√§diktorwert (`weight`) der $i$ten Beobachtung, also einer !Kung-Person (Zeile $i$ im Datensatz).
Lies  etwa so:

>    "Der Mittelwert $\mu_i$ der $i$ten Person berechnet sich als Summe von $\beta_0$ und $\beta_1$ mal  $\text{weight}_i$".


 $\mu_i$ ist eine lineare Funktion von `weight`.
 $\beta_1$ gibt den Unterschied in `height` zweier Beobachtung an, die sich um eine Einheit in `weight` unterscheiden (Steigung der Regressionsgeraden).
 $\beta_0$ gibt an, wie gro√ü $\mu$ ist, wenn `weight` Null ist (Achsenabschnitt, engl. intercept).



### Priori-Werte des Modells `m43`



\begin{align*}
\color{blue}\beta_1 & \color{blue}\sim \color{blue}{\operatorname{Normal}(178, 20)} && \color{blue}{\text{Priori Achsenabschnitt}} \\
\color{blue}\beta_1  & \color{blue}\sim \color{blue}{\operatorname{Normal}(0, 10)}  && \color{blue}{\text{Priori Regressionsgewicht}}\\
\color{blue}\sigma & \color{blue}\sim \color{blue}{\operatorname{Exp}(0.1)}  && \color{blue}{\text{Priori Sigma}}
\end{align*}

Parameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.
$\beta_0$ wurde in `m41` als $\mu$ bezeichnet, da wir dort eine "Regression ohne Pr√§diktoren" berechnet haben.
$\sigma$ ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel.
Da `height` nicht zentriert ist, der Mittelwert von $\beta_0$ bei 178 und nicht 0.
$\beta_1$ fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist.
Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.









## Die Post-Verteilung befragen


üì∫ [Post-Verteilung auslesen 1](https://youtu.be/9ZUyN4GUNBY)

üì∫ [Post-Verteilung auslesen 2](https://youtu.be/8NrUQ1_d7vI)

### m43a


Sagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt: `height ~ weight_c`, s. @eq-m43a.

Prioris:

$$\beta_1 \sim N(5,3); \\
\beta_0 \sim N(178, 20); \\
\sigma \sim E(0.1)$${#eq-m43a}


Wir nennen das Modell `m43a`^[Wer ist hier f√ºr die Namensgebung zust√§ndig? Besoffen oder was?], s. @lst-m43a.




```{#lst-m43a .r lst-cap="Modelldefinition von m43a in R"}
m43a <-
  stan_glm(
    height ~ weight_c,  # Regressionsformel
    prior = normal(5, 3),  # Regressionsgewicht (beta 1)
    prior_intercept = normal(178, 20),  # beta 0
    prior_aux = exponential(0.1),  # sigma
    refresh = 0,  # zeig mir keine Details
    seed = 42,  # lege die Zufallszahlen fest f√ºr Reproduzierbarkeit
    data = d3)
```




```{r m43a, echo = FALSE}
# Posteriori-Vert. berechnen:
m43a <-
  stan_glm(
    height ~ weight_c,  # Regressionsformel
    prior = normal(5, 3),  # Regressionsgewicht (beta 1)
    prior_intercept = normal(178, 20),  # mu
    prior_aux = exponential(0.1),  # sigma
    refresh = 0,  # zeig mir keine Details
    seed = 42,  # lege die Zufallszahlen fest f√ºr Reproduzierbarkeit
    data = d3)
```


:::callout-note
Mit `seed` kann man die Zufallszahlen fixieren,
so dass jedes Mal die gleichen Werte resultieren.
So ist die Nachpr√ºfbarkeit der Ergebnisse ("Reproduzierbarkeit") sichergestellt^[oder zumindest *besser* sichergestellt].
Welche Wert f√ºr `seed` man verwendet, ist egal,
solange alle den gleichen verwenden.
Der Autor verwendet z.B. oft den Wert 42.
Zur Erinnerung: Der Golem zieht Zufallszahlen,
damit erstellt er Stichproben, die die Postverteilung sch√§tzen.
:::




### Mittelwerte von $\beta_0$ und $\beta_1$ aus der Post-Verteilung



Die ersten paar Zeilen:

```{r Post-Regression-befragen-3}
#| echo: false
m43a %>%  
  as_tibble() %>% 
  mutate(id = 1:nrow(.), .before = 1) %>% 
  head(n=3) %>% 
  gt() %>% 
  fmt_number(columns = 2:4, decimals = 1)
```

Hier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle `parameters`, s. @tbl-m43a-params.

```{r Post-Regression-befragen-4, echo = TRUE}
#| echo: true
#| results: hide
#| message: false
#| tbl-cap: Parameter von m43a
#| label: tbl-m43a-params
parameters(m43a)
```


```{r Post-Regression-befragen-5}
#| echo: false
parameters(m43a) %>% 
  display()
```



::: {#def-pd}

### Effektwahrscheinlichkeit

Die Kennzahl  `pd` (propability of direction) gibt die *Effektwahrscheinlichkeit* an: Die Wahrscheinlichkeit,
dass der Effekt positiv (also gr√∂√üer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist).
`pd` gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt.
Damit ist er so etwas (grob!) √Ñhnliches wie der p-Wert in der Frequentistischen Statistik [@makowski2019].

:::


Am besten das Diagramm dazu anschauen, s @fig-pd1.


```{r}
#| fig-cap: Diagramm zur Probability of Direction, Modell m43a
#| label: fig-pd1
plot(p_direction(m43a))
```



`Rhat` und `ESS` sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein.
`Rhat` sollte nicht (viel) gr√∂√üer als 1 oder 1,01 sein. `ESS` (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.

Wir werden uns aber mit diesen beiden Kennwerten nicht weiter besch√§ftigen in diesem Kurs.


### Visualisieren der "mittleren" Regressiongeraden



Zur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern,
hier $\beta_0$, $\beta_1$ und $\sigma$.
√úberzeugen wir uns mit einem Blick in die Post-Verteilung von `m43a`:



```{r}
m43a %>% 
  as_tibble() %>% 
  head()
```

Wir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die "mittlere" Regressionsgerade zu betrachten.


:::{.panel-tabset}

### Mit `ggplot`

```{r Post-Regression-befragen-6, echo = TRUE, eval = FALSE}
#| echo: true
#| eval: true
d3 %>% 
  ggplot() +
  aes(x = weight_c, y = height) +
  geom_point() +
  geom_abline(
    slope = 0.9,  # Median beta 1
    intercept = 154,  # Median beta 0
    color = "blue")
```


### Mit `easystats`

Einfacher ist die Syntax vielleicht, wenn man die Funktion `estimate_expectation` benutzt, s. @fig-expect-m43a-expect.
Mit "expectation" sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.

```{r}
#| fig-cap: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade
#| label: fig-expect-m43a-expect
m43_expect <- estimate_expectation(m43a)   # aus {easystats}
plot(m43_expect)
```

:::


### Zentrale Statistiken zu den Parametern

In diesem Modell gibt es drei Parameter: $\beta_0, \beta_1, \sigma$.^[In manchen Lehrb√ºchern wird $\beta_0$ auch als $\alpha$ bezeichnet.]
Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.


#### Lagema√üe zu den Parametern

- Was ist die mittlere Gr√∂√üe einer !Kung-Person? ($\beta_0$)
- Was ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? ($\beta_1$)
- Was ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? ($\sigma$)
- Was ist der wahrscheinlichste Wert f√ºr z.B: $\beta_1$?


Eine n√ºtzliche Zusammenfassung der Post-Verteilung bekommt man mit `parameters(modell)`, s. @tbl-m43a-params.

<!-- ```{r Post-Regression-befragen-7, echo = TRUE} -->
<!-- #| eval: false -->
<!-- m43a %>%  -->
<!--   parameters() -->
<!-- ``` -->


```{r Post-Regression-befragen-7a}
#| echo: false
#| eval: false
m43a %>% 
  parameters() %>% 
  display()
```


Wandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. `m43a`, mit `as_tibble()` in eine Tabelle um,
so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:


```{r}
m43a_post <- 
  m43a %>% 
  as_tibble()

m43a_post %>% 
  head()
```


Wie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder.
Speichern wir uns sie also als ein Objekt ab, `m43_post`.
Jetzt haben wir wieder eine sch√∂ne Tabelle mit Stichproben aus der Post-Verteilung,
die wir wie gewohnt befragen k√∂nnen.
Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob.,





Oder man erstellt selber ein Diagramm mit `ggplot` oder `ggpubr`, s. @fig-m43a-post.




```{r}
#| label: fig-m43a-post
#| fig-cap: "Postverteilung f√ºr den Parameter Gewicht (zentriert)"
m43a_post %>% 
  ggplot(aes(x = weight_c)) +
  geom_density(fill = "orange")
```


@fig-m43a-post zeigt, dass Mittelwert, Median und Modus eng zusammenliegen.
Zur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an.
Der Modus wird hier auch *Maximum a Posteriori* (MAP) genannt, daher:


```{r map-estimate-m43a}
#| eval: false
m43a_post %>% 
  summarise(map_b1 = map_estimate(weight_c))
```





Hier ist die Verteilung von $\sigma$ visualisiert, s. @fig-m43a-post2.


```{r}
#| label: fig-m43a-post2
#| fig-cap: "Die Post-Verteilung f√ºr den Parameter sigma, m43a"

m43a_post %>% 
  ggplot(aes(x = sigma)) +
  geom_density(fill = "orange")
```


Alternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen,
gleich mit Intervallgrenzen, z.B. 95%, s. @fig-m43a-plot.

```{r}
#| label: fig-m43a-plot
#| fig-cap: "Die Parameter Gewicht (zentriert) und sigma des Modells m43a"
m43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)

plot(m43a_hdi)
```

Erg√§nzt man bei `plot()` noch `show_intercept = TRUE` wird auch der Achsenabschnitt angezeigt.





### Streuungsma√üe zu den Parametern


- Wie unsicher sind wir uns in den Sch√§tzungen der Parameter?



Diese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.


:::callout-note
An einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls 
auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.
:::


### Ungewissheit von $\beta_0$ und $\beta_1$ aus der Post-Verteilung visualisiert



:::{.panel-tabset}

### 10

Die ersten 10 Stichproben:

```{r Post-Regression-befragen-10, echo = TRUE}
d3 %>% 
  ggplot(aes(x = weight_c, 
             y = height)) +
  geom_point() +
  geom_abline(
    data = m43a_post %>% 
      slice_head(n = 10),
    aes(slope = weight_c,
        intercept = `(Intercept)`),
    alpha = .3)
```

## 100

Die ersten 100 Stichproben:

```{r Post-Regression-befragen-11-ersten-1000, echo = TRUE}
d3 %>% 
  ggplot(aes(x = weight_c, 
             y = height)) +
  geom_point() +
  geom_abline(
    data = m43a_post %>% 
      slice_head(n = 100),
     aes(slope = weight_c,
        intercept = `(Intercept)`),
    alpha = .1)
```


### 1000

Die ersten `1e3` Stichproben:

```{r Post-Regression-befragen-11-die-ersten-1000, echo = TRUE}
d3 %>% 
  ggplot(aes(x = weight_c, 
             y = height)) +
  geom_point() +
  geom_abline(
    data = m43a_post %>% 
      slice_head(n = 1e3),
     aes(slope = weight_c,
        intercept = `(Intercept)`),
    alpha = .01)
```



### 1000000

Die ersten 1000000^[1e6] ... okay, lassen wir es gut sein^[Im Standard beschert uns `stan_glm()` 4000 Stichproben.].

:::


Einfacher ist die Visualisierung mit `estimate_expectation`, s. @fig-m43a-estimate-expectation.

```{r}
#| fig-cap: Sch√§tzbereich f√ºr die bedingten mittleren K√∂rpergr√∂√üe, also die Regressionsgerade mit Unsicherheitsintervall
#| label: fig-m43a-estimate-expectation
estimate_expectation(m43a, seed = 42) %>% plot()
```


### Fragen zu Quantilen des Achsenabschnitts 

:::callout-note
Zur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe^[$\mu$].
:::

- Welche mittlere Gr√∂√üe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht √ºberschritten?
- Welche mittlere Gr√∂√üe mit Wahrscheinlichkeit von 95% nicht unterschritten?
- Von wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?



Quantile:


```{r quantile-post}
m43a_post %>% 
  summarise(
    q_50 = quantile(`(Intercept)`, prob = .5),
    q_90 = quantile(`(Intercept)`, prob = .9),
    q_05 = quantile(`(Intercept)`, prob = .95))
```

50%-PI:

```{r}
m43a %>% 
  eti(ci = .5)
```



### Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts 



Wie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?


```{r echo = TRUE}
m43a_post %>% 
  count(gross = `(Intercept)` >= 155) %>% 
  mutate(prop = n / sum(n))
```

```{r}
#| echo: false
wskt_gross <- 
  m43a_post %>% 
  count(gross = `(Intercept)` >= 155) %>% 
  mutate(prop = n / sum(n)) %>% 
  pull(prop) %>% 
  `[`(2) %>% 
  round(2)
```

Die Wahrscheinlichkeit betr√§gt `r wskt_gross`.


Wie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?


```{r echo = TRUE}
m43a_post %>% 
  count(klein = (`(Intercept)` <= 154.5)) %>% 
  mutate(prop = n / sum(n))
```

```{r wsktklein}
#| echo: false
wskt_klein <- 
  m43a_post %>% 
  count(klein = `(Intercept)` <= 154.5) %>% 
  mutate(prop = n / sum(n)) %>% 
  pull(prop) %>% 
  `[`(2) %>% 
  round(2)
```


Die Wahrscheinlichkeit betr√§gt `r wskt_klein`.






<!-- ### Ungewissheit von Achsenabschnitt und Steigung  -->

<!-- ... als Histogramme visualisiert -->

<!--  -->

<!-- ### Achsenabschnitt -->

<!-- ```{r Post-Regression-befragen-13, echo = TRUE, eval = TRUE} -->
<!-- post_m43a %>%  -->
<!--   ggplot(aes(x = a)) + -->
<!--   geom_density() -->
<!-- ``` -->

<!-- ] -->

<!-- .pull-right[ -->

<!-- ### Regressionsgewicht (Steigung) -->

<!-- ```{r Post-Regression-befragen-14, echo = TRUE} -->
<!-- post_m43a %>%  -->
<!--   ggplot(aes(x = b)) + -->
<!--   geom_density() -->
<!-- ``` -->

<!-- ] -->



### Typischer Bayes-Nutzer in Aktion

![Typischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR](img/bayesianMaster.jpg){width="50%" fig-align="center"}

[Quelle](https://easystats.github.io/bayestestR/articles/bayestestR.html)





## Post-Verteilung bedingt auf einen Pr√§diktorwert


### Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr $\mu$


Komfort pur: Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von $\mu$) zu berechnen.

Hier am Beispiel von `m42`, s. @fig-post42.

```{r m42-read-from-disk, echo = FALSE}
#| echo: false
#| output: "hide"
m42 <- read_rds(paste0(here::here(),"/objects/m42.rds"))

m42_post <- as_tibble(m42)
names(m42_post) <- c("mu", "sigma")
```




```{r Post-Regression-10}
#| echo: false

plot_post_42 <- 
  m42_post %>% 
  ggplot() +
  aes(x = mu) +
  geom_density(fill = "grey60") +
  labs(x = expression(mu),
       title = TeX("Posteriori-Verteilung f√ºr $\\mu$, m42")) +
  scale_y_continuous(breaks = NULL)
```


```{r Plot-condition}
#| echo: false
lm1 <- lm(height ~ weight, data = d2)

d_pred <-
  tibble(weight = c(40, 45, 50, 55),
         height = predict(lm1, newdata = data.frame(weight)))



plot_condition <- 
  d2 %>% 
  #select(weight, height) %>% 
  #drop_na() %>% 
  ggplot(
       aes(x = weight, y = height)) +
  geom_point(alpha = .7) +
  geom_smooth(method = "lm") +
  geom_point(aes(color = as.factor(weight)), data = d_pred, size = 5, alpha = .5) +
  labs(color = "Gewicht",
       x = "Gewicht (weight)",
       y = "Gr√∂√üe (height)") +
  scale_color_okabeito()


k <- 3
n <- 50
sigma <- sigma(lm1)
ab <- coef(lm1); a <- ab[1]; b <- ab[2]

x <- seq(-k*sigma, k*sigma, length.out = n)
y <- dnorm(x, 0, sigma)/dnorm(0, 0, sigma) * 1

x0 <- 40
y0 <- a+b*x0
path1 <- data.frame(x = y + x0, y = x + y0)
segment1 <- data.frame(x = x0, y = y0 - k*sigma, xend = x0, yend = y0 + k*sigma)

x0 <- 45
y0 <- a+b*x0
path2 <- data.frame(x = y + x0, y = x + y0)
segment2 <- data.frame(x = x0, y = y0 - k*sigma, xend = x0, yend = y0 + k*sigma)

x0 <- 50
y0 <- a+b*x0
path3 <- data.frame(x = y + x0, y = x + y0)
segment3 <- data.frame(x = x0, y = y0 - k*sigma, xend = x0, yend = y0 + k*sigma)


x0 <- 55
y0 <- a+b*x0
path4 <- data.frame(x = y + x0, y = x + y0)
segment4 <- data.frame(x = x0, y = y0 - k*sigma, xend = x0, yend = y0 + k*sigma)

plot_condition_with_cond_post <- 
plot_condition +
  geom_path(aes(x,y), data = path1, 
            color = okabeito_colors()[1]) +
  geom_segment(aes(x=x,y=y,xend=xend,yend=yend), 
               data = segment1,
               color = okabeito_colors()[1]) +
  
  geom_path(aes(x,y), data = path2, 
            color = okabeito_colors()[2]) +
  geom_segment(aes(x=x,y=y,xend=xend,yend=yend), 
               data = segment2,
               color = okabeito_colors()[2]) +
  
   geom_path(aes(x,y), data = path3, 
            color = okabeito_colors()[3]) +
  geom_segment(aes(x=x,y=y,xend=xend,yend=yend), 
               data = segment3,
               color = okabeito_colors()[3]) +
  
   geom_path(aes(x,y), data = path4, 
            color = okabeito_colors()[4]) +
  geom_segment(aes(x=x,y=y,xend=xend,yend=yend), 
               data = segment4,
               color = okabeito_colors()[4]) 

```

```{r m3}
#| echo: false
#| results: "hide"
#| cache: true

d2 <-
  d2 %>% 
  mutate(weight_c = weight - mean(weight))

m43 <- 
  stan_glm(height ~ weight_c, 
           prior = normal(0, 10),
           prior_intercept = normal(178, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = d2)

m43_prior_pred <-
    stan_glm(height ~ weight_c, 
           prior_intercept = normal(178, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE, 
           prior_PD = TRUE,   # THIS LINE MAKES A PRIOR PRED
           data = d2)

stan_glm(height ~ weight_c, 
           prior = normal(0, 10),
           prior_intercept = normal(0, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = d2)

m43a_prior_pred <-
    stan_glm(height ~ weight_c, 
           prior_intercept = normal(0, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE, 
           prior_PD = TRUE,   # THIS LINE MAKES A PRIOR PRED
           data = d2)
```






```{r objects-m43-m43a-to-disk, eval = FALSE}
#| eval: false
#| echo: false
# print(m43)
# summary(m43_prior_pred)
# write_rds(m43, "objects/m43.rds")
# write_rds(m43a, "objects/m43a.rds")
```




```{r m43-plot}
#| echo: false
nd <- tibble(
  weight_c = c(-5, 0, +5, 10)
)

m43_post <- 
  m43 %>% 
  as_tibble()

m43_post <- 
m43_post |> 
  mutate(mu_at_45 = `(Intercept)`,
         mu_at_40 = mu_at_45 - 5 * weight_c,
         mu_at_50 = mu_at_45 + 5 * weight_c,
         mu_at_55 = mu_at_45 + 10 * weight_c)


m43_post_long <-
  m43_post |> 
  select(starts_with("mu_at_")) |> 
  pivot_longer(everything(),
               names_to = "Gewicht",
               values_to = "h")

m43_post_long_summary <-
  m43_post_long |> 
  group_by(Gewicht) |> 
  summarise(
    m = mean(h),
    s = sd(h)) |> 
  mutate(
    ci_low = m - 2*s,
    ci_high = m + 2*s)
```


```{r}
#| echo: false
p_post_at <-
  m43_post_long %>% 
  ggplot() +
  aes(x = h) +
  geom_density(aes(fill = Gewicht)) +
  facet_wrap(~ Gewicht, nrow = 1, scales = "free") +
  scale_y_continuous(breaks = NULL) +
  labs(
       caption = "Horizontale Balken zeigen MW¬±2sd",
       x = "Gr√∂√üe",
       y = "Post-Wskt") +
  geom_point(data = m43_post_long_summary,
             aes(x = m,
                 y = 0),
             size = 2, color = "blue", alpha = .5) +
  geom_segment(data = m43_post_long_summary,
               aes(x = m-2*s,
                   xend = m+2*s),
               y = 0,
               yend = 0,
               color = "blue",
               alpha = .5,
               linewidth = 2) +
  scale_x_continuous(breaks = NULL) +
  scale_fill_okabeito()
```



```{r Post-Regression-12, out.width="100%", fig.width=9}
#| echo: false
#| fig-asp: 1
#| label: fig-post42
#| fig-cap: "F√ºr jeden beliebigen Pr√§diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgew√§hlten Gewichtswerten. Es ist jeweils die Wahrscheinlichkeitsverteilung f√ºr den vorhergesagten Y-Wert dargestellt (hier sind die Verteilungen zu gro√ü dargestellt zur besseren Sichtbarkeit). B: F√ºr jeden beliebigen Gewichtswert (Y) bekommt man eine (auf den jeweiligen X-Wert bedingten) Post-Verteilung."


plots(plot_condition_with_cond_post, p_post_at, 
      n_rows = 2, tags = "A")
```






### Visualisierung


Was ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?

Angenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt.
Welche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?

Etwas formaler ausgedr√ºckt:

$\mu|\text{weight}=45$


45 kg entspricht genau dem Mittelwert von `weight`. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall `weight_c = 0`.
Erstellen wir uns dazu eine Tabelle:


```{r mu-at-45-def, echo = TRUE}
mu_at_45 <-
  m43a_post %>% 
  mutate(mu_at_45 = `(Intercept)`)
```

Und plotten diese, s. @fig-mu-at-45.

```{r Post-Regression-befragen-15, echo = TRUE, eval = FALSE}
#| eval: false

mu_at_45 %>% 
  ggplot(aes(x = mu_at_45)) +
  geom_density()
```



```{r Post-Regression-befragen-17}
#| echo: false
#| label: fig-mu-at-45
#| fig-cap: "Post-Verteilung der Gr√∂√üe (laut unserem Modell) bei einem Gewicht von 45kg"
mu_at_45 %>% 
  ggplot(aes(x = mu_at_45)) +
  geom_density() +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(mu["height | weight = 45"])) +
  scale_x_continuous(limits = c(150, 160))
```


Analog k√∂nnen wir fragen,
wie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.


50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also `weight_c = 5`. Auch dazu erstellen wir uns eine Tabelle, s. @tbl-mu-at-50.



```{r mu-at-50, echo = TRUE}
#| label: tbl-mu-at-50
#| tbl-cap: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.
mu_at_50 <-
  mu_at_45 %>% 
  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)

head(mu_at_50)
```

Die Verteilung der mittleren Gr√∂√üe bei einem Gewicht von 50kg ist weiter "rechts" (Richtung h√∂here Gr√∂√üe) zentriert, s. @fig-mu-at-50.


```{r Post-Regression-befragen-16, echo = TRUE, eval = FALSE}
#| eval: false
mu_at_50 %>% 
  ggplot(aes(x = mu_at_50)) +
  geom_density()
```





```{r Post-Regression-befragen-18}
#| echo: false
#| label: fig-mu-at-50
#| fig-cap: Post-Verteilung der mittleren Gr√∂√üe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg
mu_at_50 %>% 
  ggplot(aes(x = mu_at_50)) +
  geom_density() +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(mu["height | weight = 50"])) +
  scale_x_continuous(limits = c(150, 160))
```




### Lagema√üe und Streuungen

Befragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der K√∂rpergr√∂√üe.




Was ist das 90% PI f√ºr $\mu|w=50$ ?

```{r Post-Regression-befragen-19, echo = TRUE}
mu_at_50 %>% 
  eti(mu_at_50, ci = .9)
```

Die mittlere Gr√∂√üe - gegeben $w=50$ - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.



Welche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?

```{r Post-Regression-befragen-20, echo = TRUE}
mu_at_45 %>% 
  summarise(q_95 = quantile(mu_at_45, prob = .95))
```







## Prior-Pr√§diktiv-Verteilung

üèéüèéÔ∏è VERTIEFUNG (nicht pr√ºfungsrelevant ) üèéüèé




### Moment

 ü§î Moment. Dieser Prior, $\beta_1$ in `m43` erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!

Sind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Gr√∂√üe positiv oder negativ ist? [Nein, sind wir nicht.](https://media.giphy.com/media/daPCSjwus6UR2JxRX1/giphy.gif) 
    


### Priori-Pr√§diktiv-Verteilung f√ºr `m43`



Was denkt [wir](https://media.giphy.com/media/Aausss8uUBIe3bZ3d2/giphy.gif) bzw. unser Golem *apriori* √ºber den Zusammenhang von Gr√∂√üe und Gewicht?
Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also f√ºr $\beta_0$, $\beta_1$ und $\sigma$.



```{r m43-prior-pred}
m43_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),
             prior_intercept = normal(178, 20),  # mu
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # Schalter f√ºr Prior-Pred-Verteilung
             data = d3)


m43_prior_pred_draws <- 
  m43_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```



```{r}
#| echo: false
m43_prior_pred_draws %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```



Jede Zeile definiert eine Regressionsgerade.



### Prior-Pr√§diktiv-Simulation f√ºr `m43` mit `stan_glm()` 




```{r echo = TRUE, eval = FALSE}
m43_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),  # beta
             prior_intercept = normal(178, 20),  # alpha
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # DIESER Schalter macht's
             data = d3)

m43_prior_pred_draws <- 
  m43_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```



```{r echo = FALSE, eval = FALSE}
m43a_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),  # beta
             prior_intercept = normal(0, 20),  # alpha
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # DIESER Schalter machts
             data = d3)

m43a_prior_pred_draws <- 
  m43a_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```









### Visualisieren der Prior-Pr√§diktiv-Verteilung



```{r prior-pv1, echo = TRUE, eval = FALSE, fig.asp = .5}
d3 %>% ggplot() +
  geom_point(aes(x = weight_c, y = height)) + 
  geom_abline(data = m43_prior_pred_draws,
aes(intercept = a, slope = b), color = "skyblue", size = 0.2) +
  scale_y_continuous(limits = c(0, 500)) +
  geom_hline(yintercept = 272, size = .5) +
  geom_hline(yintercept = 0, linetype = "dashed")
```



ü§Ø Einige dieser Regressionsgeraden sind unsinnig!


```{r ref.label = "prior-pv1", eval = TRUE, fig.asp = .3}

```


Die durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.





### Ein positiver Wert f√ºr $\beta_1$ ist plausibler


#### Oh no

Eine Normalverteilung mit viel Streuung:

```{r Post-Regression-16, fig.asp = .5}
#| echo: false
d <-
  tibble(
    x = seq(-30,30,.1),
    y = dnorm(x, mean = 0, sd = 10)
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  scale_y_continuous(breaks = NULL) +
  labs(title = "mu=0, s=10")
```

üëé $\beta=-20$ w√§re mit diesem Prior gut m√∂glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.




#### Oh yes

Wir br√§uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):

```{r Post-Regression-17, fig.asp=.5}
#| echo: false
d <-
  tibble(
    x = seq(-30,30,.1),
    y = dnorm(x, mean = 3, sd = 2)
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  scale_y_continuous(breaks = NULL) +
  labs(title = "mu=5, sd = 3")
```

üëç Vermutlich besser: Ein Gro√üteil der Wahrscheinlichkeitsmasse ist $X>0$. Allerdings gibt's keine Gew√§hr, dass unser Prior "richtig" ist.




### Priori-Pr√§diktiv-Simulation, 2. Versuch





```{r echo = TRUE}
m43a_prior_pred <-
    stan_glm(
      height ~ weight_c, 
      prior = normal(2, 2),  # Regressionsgewicht
      prior_intercept = normal(178, 20),  # mu
      prior_aux = exponential(0.1),  # sigma
      refresh = FALSE, 
      # Schalter f√ºr Prior-Pred-Verteilung:
      prior_PD = TRUE, 
      data = d3)


m43a_prior_pred_draws <- 
  m43a_prior_pred %>% 
  as_tibble() %>% 
  # Spaltennamen k√ºrzen: 
  rename(a = `(Intercept)`) %>%  
  rename(b = weight_c,
         s = sigma)
```





```{r}
#| echo: false
m43a_prior_pred_draws %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```



Das Argument `prior_PD = TRUE` sorgt daf√ºr, dass keine Posteriori-Verteilung, sondern eine Prior-Pr√§diktiv-Verteilung berechnet wird.




### Visualisieren der Prior-Pr√§diktiv-Verteilung, `m43a`


Unsere Priori-Werte scheinen einigerma√üen vern√ºnftige Vorhersagen zu t√§tigen. Allerdings erwartet unser Golem einige Riesen.


```{r, eval = TRUE, fig.asp=.5}
d3 %>% 
  ggplot(aes(x = weight_c, y = height)) +
  geom_point() +
  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},
              aes(slope = b,
                  intercept = a),
              color = "skyblue",
              size = .2,
              alpha = .7) +
  geom_hline(yintercept = 272, size = .5) +
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_y_continuous(limits = c(0, 500)) 
```


Die durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.








### Moment, kann hier jeder machen, was er will?



Es doch den einen, richtigen, objektiven Priori-Wert geben?!

Kann denn jeder hier machen, was er will?! Wo kommen wir da hin?!


>    This is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.  

@mcelreath2020, p. 96.





### Hier ist unser Modell, `m43a`




\begin{align}
\text{height}_i &\sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot  \text{weight}_i\\
\alpha &\sim \operatorname{Normal}(178, 20)\\
\beta &\sim \operatorname{Normal}(5,3)\\
\sigma &\sim \operatorname{Exp}(0.1)
\end{align}



```{r Post-Regression-25, echo = TRUE}
# Posteriori-Vert. berechnen:
m43a <-
  stan_glm(
    height ~ weight_c,  # Regressionsformel
    prior = normal(5, 3),  # Regressionsgewicht (beta 1)
    prior_intercept = normal(178, 20),  # mu
    prior_aux = exponential(0.1),  # sigma
    refresh = 0,  # zeig mir keine Details
    seed = 42,  # Zufallszahlen festlegen
    data = d3)
```





### Eine Zusammenfassung der Posteriori-Verteilung f√ºr `m43a`


```{r}
#| eval: false
m43a %>% 
  parameters()
```



```{r}
#| echo: false
m43a %>% 
  parameters() %>% 
  display()
```



Unser Modell `m43a` sch√§tzt die typische K√∂rpergr√∂√üe einer !Kung-Person *mittleren Gewichts* (`weight_c = 0`) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher.
Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise;
auch hier ist sich das Modell ziemlich sicher, da dass zugeh√∂rige 95%-CI keine 20 Zentimenter umfasst.














## Die PPV befragen


üèéüèéÔ∏è VERTIEFUNG (nicht pr√ºfungsrelevant ) üèéüèé








Die Posterior-Pr√§diktiv-Verteilung (PPV) gibt uns die M√∂glichkeit,
nach der Wahrscheinlichkeit *tats√§chlicher* K√∂rpergr√∂√üen zu fragen - 
und nicht nur nach *mittleren* K√∂rpergr√∂√üen anhand der Post-Verteilung.


:::callout-important
Die Post-Verteilung macht *nur* Aussagen zur *mittleren* K√∂rpergr√∂√üe,
denn das ist was wir modellieren wollten.
M√∂chten wir Aussagen zur Wahrscheinlichkeit *tats√§chlicher* Gr√∂√üen treffen,
brauchen wir die PPV.
Allgemeiner gesagt: Die PPV macht Vorhersagen auf Basis eines Modells. 
F√ºr jede Vorhersage gibt es eine Verteilung, 
die wir zu einem Punktsch√§tzer (z.B. Median) und einem Sch√§tzbereich (z.B. 89%-HDI) zusammenfassen k√∂nnen.
:::

An dieser Stelle sollten wir uns vor Augen f√ºhren, dass die PPV *mehr* Ungewissheit beinhaltet,
denn sie ber√ºcksichtigt derer zweier Arten:

1. Ungewissheit bzgl. der Modellparameter (Steigung und Achsenabschnitt der Regressionsgeraden)
2. Ungewissheit der Vorhersagen (das Modell macht keine perfekten Vorhersagen)


Die *Post-Verteilung* ber√ºcksichtigt nur die Ungewissheit in den Modellparametern,
macht also nur Aussagen zur Regressionsgeraden.

Die PPV macht Aussagen f√ºr konkrete Beobachtungen.
Der Unterschied ist in @fig-ppv-vs-post dargestellt; die Funktionen stammen √ºbrigens aus `{easystats}`.


```{r}
#| label: fig-ppv-vs-post
#| layout-ncol: 2
#| fig-cap: "PPV vs. Post-Verteilung"
#| fig-subcap:
#|   - "PPV mit viel Ungewissheit"
#|   - "Post-Verteilung mit wenig(er) Ungewissheit"
estimate_prediction(m43a) %>% plot()
estimate_relation(m43a) %>% plot()
```


### Perzentil-Intervalle f√ºr bestimmte Pr√§diktor-Werte



>    Wie gro√ü ist ein !Kung-Mann mit mittlerem Gewicht?


```{r}
set.seed(42)
estimate_prediction(m43a, data = tibble(weight_c = 0), seed = 42)
```

Unser Modell, `ma43a` sch√§tzt ca. 145cm bis 165cm.


Wir k√∂nnen uns auch eine Sequenz an Pr√§diktorwerten, die uns interessieren, erstellen, s. `weight_df`:

```{r echo = TRUE}
weight_df <- tibble(weight_c = seq(-20,20, by = 5))
```


F√ºr diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:

```{r Post-Regression-befragen-21, echo = TRUE}
mus <- 
  estimate_prediction(m43a, data = weight_df) 

head(mus)
```

Um die Perzentilintervalle zu erstellen, wird von `estimate_prediction()` f√ºr jeden Pr√§diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil daf√ºr berechnet. 
Sie k√∂nnen die Voreinstellung √§ndern mittels des Arguments `ci`;
um ein 89%-PI zu berechnen, w√ºrde man z.B. schreiben `ci = .89`.

Um Reproduzierbarkeit sicherzustellen,
haben wir mit `set.seed(42)` die Zufallszahlen fixiert.


Hoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben.
Ja, denn die Post-Verteilung hat die Ungewissheit zum *Mittelwert* ausgedr√ºckt;
die PPV gibt die Ungewissheit *tats√§chlicher* beobachtbarer K√∂rpergr√∂√üen aus,
nicht nur die Ungewissheit zum Mittelwert.


Berechnen wir die PPV f√ºr die bestehenden Beobachtungen aus `m43a`:

```{r ppv-m43a}
ppv_m43a <- estimate_prediction(
  m43a,
  data = weight_df)

mus 
```






### Perzentilintervalle f√ºr verschiedenen Pr√§diktorwerte visualisiert

@fig-m43a-nochmal visualisiert die Ungewissheit von Vorhersagen laut der PPV.
Die Ungewissheit in @fig-m43a-nochmal ist die Antwort auf die Frage: "Wie sicher sind wir uns,
zur Gr√∂√üe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?"
Eine Vorhersage bezeichnet man auch als "bedingte Verteilung", da man den Wert einer Verteilung voraussagt,
*gegeben* einer Bedingung, z.B. `weight_c = 10`.  


```{r mus-d3}
#| echo: false
#| label: fig-m43a-nochmal 
#| fig-cap: "Visualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV gr√∂√üer als die der Post-Verteilung."
mus <- 
  mus %>% 
  mutate(height = 154.6 + 0.9*weight_c)

d3 %>% 
  ggplot(aes(x = weight_c, y = height)) +
  geom_point(color = "grey60") +
  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = "blue") +
  geom_errorbar(data = mus,
                aes(ymin = CI_low,
                    ymax = CI_high),
                size = .5,
                width = .5,
                color = "firebrick")
```


Die vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.

Noch eine andere Visualisierung, s. @fig-katzenaugen; 
je dicker die "Katzenaugen", desto mehr Stichproben (samples) liegen vor an der Stelle,
und umso genauer ist die Sch√§tzung.


```{r ppv-m43-weight}
#| echo: false
#| label: fig-katzenaugen
#| fig-cap: Die PPV f√ºr bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen
#| layout-ncol: 2

ppv_m43_weight_df <-
  posterior_predict(m43a,
                    newdata = weight_df) %>% 
  as_tibble() %>% 
  pivot_longer(everything(),
               names_to = "weight_condition",
               values_to = "height")

weight_df <-
  weight_df %>% 
  mutate(weight_condition = as.character(c(1:9)))

ppv_m43_weight_df <- 
  ppv_m43_weight_df %>% 
  full_join(weight_df, by = "weight_condition")

d3 %>% 
  ggplot() +
  geom_violin(data = ppv_m43_weight_df,
              aes(x = weight_c, y = height, group = weight_c),
                fill = "grey80",
              width = 1) +
    geom_point(aes(x = weight_c, y = height)) +
  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = "blue")
```


Also: Je dicker die Violine, desto wahrscheinlicher $\mu | w_i$.



### Die PPV √ºber alle Beobachtungen visualisiert

Gerade eben haben wir *bedingte* PPVen angeschaut: Also eine PPV f√ºr einen *bestimmten* Pr√§diktorwert, z.B. bei einer Person mittleren Gewichts.
Wir k√∂nnen auch den Mittelwert √ºber alle bedingten PPV anschauen, sozusagen die "*Master-PPV*" oder "unbedingte PPV" oder schlicht PPV.
Vergleichen wir die echten Werte f√ºr `height`, $y$, mit den von der PPV simulierten Werten f√ºr `height`, $y_{rep}$, s. @fig-ppv-check.

```{r ppv-plot1}
#| label: fig-ppv-check
#| fig-cap: Vergleich der Vorhersagen f√ºr y (leichte, blaue Linien) mit der beobachteten Verteilung von y
check_predictions(m43a)  # aus easystatss
```

`?check_predictions` zeigt Hilfe f√ºr diese Funktion. 
Die Funktion zeigt die Vorhersagen f√ºr die AV laut der Posteriori-Verteilung.



Die zwei Gipfel hat unser Modell nicht mitgekriegt, 
ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.








### Fragen an die Master-PPV

- Wie gro√ü sind die !Kung im Schnitt?
- Welche Gr√∂√üe wird von 90% der Personen nicht √ºberschritten?
- Wie gro√ü sind die 10% kleinsten?


```{r}
ppv_m43a <- posterior_predict(
  m43a,
  newdata = weight_df,
  draws = 100) %>% 
  as_tibble() %>% 
  pivot_longer(
    cols = everything(),
    names_to = "weight_condition",
    values_to = "height")
head(ppv_m43a)
```



```{r}
ppv_m43a <-
  ppv_m43a <- posterior_predict(
  m43a,
  newdata = weight_df,
  draws = 100) %>% 
  as_tibble() %>% 
  pivot_longer(
    cols = everything(),
    names_to = "weight_condition",
    values_to = "height")

head(ppv_m43a)
```



```{r Post-Regression-befragen-29, echo = TRUE }
ppv_m43a %>% 
  summarise(
    q_10 = quantile(height, prob = .1),
    height_mean = mean(height),
    q_50 = quantile(height, prob = .5),
    q_90 = quantile(height, prob = .9)
  )
```


Was ist der 50% Bereich der K√∂rpergr√∂√üe?

```{r Post-Regression-befragen-30, echo = TRUE}
ppv_m43a %>% 
  eti(ci = .5)
```


## Fazit



### Ausstieg

:::{#exm-ausstieg-post}
### Fassen Sie das Wesentliche zusammen!
Schreiben Sie 5-10 S√§tze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! $\square$
:::


### Vertiefung

@mcelreath2020 bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. @kurz2021 greift die R-Inhalte von @mcelreath2020 auf und setzt sie mit anderen R-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen m√∂chte.
@gelman2021 bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einem frequentistischen als auch aus einer Bayes-Perspektive.

## Aufgaben


### Papier-und-Bleistift-Aufgaben


1. [Bayes-Ziel1](https://datenwerk.netlify.app/posts/bayes-ziel1/bayes-ziel1)
2. [Bayesmod-bestimmen01](https://datenwerk.netlify.app/posts/bayesmod-bestimmen01/bayesmod-bestimmen01)
14. [mtcars-post2a](https://datenwerk.netlify.app/posts/mtcars-post2a/)
8. [Bed-Post-Wskt1](https://datenwerk.netlify.app/posts/bed-post-wskt1/bed-post-wskt1)
9. [mtcars-post3a](https://datenwerk.netlify.app/posts/mtcars-post3a/)
<!-- 5. [Postvert-Regr-01](https://datenwerk.netlify.app/posts/postvert-regr-01/postvert-regr-01) -->
6. [regression1a](https://datenwerk.netlify.app/posts/regression1a/regression1a.html)
7. [regression1b](https://datenwerk.netlify.app/posts/regression1b/regression1b)
7. [Regression2](https://datenwerk.netlify.app/posts/regression2/regression2)
9. [Priorwahl1](https://datenwerk.netlify.app/posts/priorwahl1/priorwahl1)
10. [Bayesmod-bestimmen02](https://datenwerk.netlify.app/posts/bayesmod-bestimmen02/bayesmod-bestimmen02)
11. [Aussagen-einfache-Regr](https://datenwerk.netlify.app/posts/aussagen-einfache-regr/aussagen-einfache-regr)
12. [Likelihood-identifizieren](https://datenwerk.netlify.app/posts/likelihood-identifizieren/likelihood-identifizieren)
13. [Priorwahl2](https://datenwerk.netlify.app/posts/priorwahl2/priorwahl2)
3. [Likelihood2](https://datenwerk.netlify.app/posts/likelihood2/likelihood2)
14. [interpret-koeff](https://datenwerk.netlify.app/posts/interpret-koeff/interpret-koeff)
15. [bed-post-wskt1](https://datenwerk.netlify.app/posts/bed-post-wskt1/bed-post-wskt1)

### Computer-Aufgaben

1. [Post-befragen1](https://datenwerk.netlify.app/posts/post-befragen1/post-befragen1)
2. [penguins-stan-01](https://datenwerk.netlify.app/posts/penguins-stan-01/penguins-stan-01.html)



## ---



![](img/outro-09.jpg){width=100%}




