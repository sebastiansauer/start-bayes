# Verteilungen



![Bayes:Start!](img/Golem_hex.png){width=10%}

## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...


- den Begriff der Zufallsvariablen erl√§utern
- die Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erl√§utern 
- den Begriff einer Gleichverteilung erl√§utern 
- den Begriff einer Binomialverteilung erl√§utern
- Ben Begriff einer halben Normalverteilung erl√§utern
- den Begriff einer Exponentialverteilung erl√§utern
- zentrale Konzepte in R umsetzen



### Begleitliteratur

Der Stoff dieses Kapitels deckt sich (weitgehend) mit @bourier2011, Kap. 6.1 und 6.3 sowie 7.1 und und 7.2.



### Vorbereitung im Eigenstudium

Dieses Kapitel setzt einige Grundbegriffe voraus,
wie im Buch [Statistik1]() vorgestellt, insbesondere im Kapitel ["Rahmen"](https://statistik1.netlify.app/010-rahmen#was-sind-daten).
Ben√∂tigt wird auch der Begriff der [Normalverteilung](https://statistik1.netlify.app/040-verbildlichen#spezialfall-normalverteilung) sowie der Begriff der [Quantile](https://statistik1.netlify.app/050-zusammenfassen.html#quantile).

Lesen Sie selbst√§ndig, zus√§tzlich  zum Stoff dieses Kapitels, noch in @bourier2011 folgende Abschnitte:

<!-- - Kap. 6.1 (Zum Begriff Zufallsvariable) -->
<!-- - Kap. 6.3 (Stetige Zufallsvariablen) -->
- Kap. 7.1.1 (Binomialverteilung)
- Kap. 7.2.1 (Gleichverteilung)
- Kap. 7.2.3 (Normalverteilung)

L√∂sen Sie auch die √úbungsaufgaben dazu.


Weitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, @bourier2022.


### Pr√ºfungsrelevanter Stoff

Beachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff pr√ºfungsrelevant ist.


### Ben√∂tigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(ggpubr)  # f√ºr Plots
```


```{r}
#| include: false
library(gt)
library(patchwork)
#library(faux)
library(openintro)
library(easystats)
library(ggraph)
library(knitr)

source("funs/uniform_plot.R")  # oder "uniformplot.R"????
source("funs/binomial_plot.R")
```




```{r r-setup}
#| echo: false
#| message: false
theme_set(theme_minimal())
#scale_color_okabeito()
scale_colour_discrete <- function(...) 
  scale_color_okabeito()
```





### Zentrale Begriffe




#### Eigenschaften von Zufallsvariablen

- Zufallsvariable (random variable)
- Diskret vs. stetig
- Wahrscheinlichkeitsdichte (Dichte, (probability) density, f)
- Wahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)


#### Verteilungen

- Gleichverteilung
- Normalverteilung
- Standardnormalverteilung

### Begleitvideos


- [√úberblick zu Verteilungen](https://youtu.be/7GqIE4sKDs4)
- [Gleichverteilung](https://youtu.be/CJxi4e89aDs)
- [Binomialverteilung](https://youtu.be/xe7JL3fEKsg)



## Wichtige Verteilungen

Im Folgenden sind einige wichtige Verteilungen aufgef√ºhrt, die in diesem Skript (und in der Statistik und Wahrscheinlichkeitstheorie) eine zentrale Rolle spielen.

üì∫ [Einstieg in Verteilungen](https://www.youtube.com/watch?v=HKWwondYsW8&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=5)

## Gleichverteilung

### Indifferenz als Grundlage

Eine Gleichverteilung nimmt an, dass jede Auspr√§gung  der zugeh√∂rigen Zufallsvariablen *gleichwahrscheinlich* ist.
Wenn man keinen hinreichenden Grund hat, eine bestimmte Auspr√§gung einer Zufallsvariablen f√ºr plausibler als einen anderen zu halten,
ist eine Gleichverteilung eine passende Verteilung.
Gleichverteilungen gibt es im diskreten und im stetigen Fall.

Abb. @fig-uniform zeigt ein Beispiel f√ºr eine (stetige) Gleichverteilung.


```{r Normalverteilung-4, fig.asp = 0.5}
#| echo: false
#| fig-cap: "Stetige Gleichverteilung; man beachte jeweils die Y-Achse"
#| fig-subcap: 
#|   - "Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2"
#|   - "Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3"
#| label: fig-uniform
#| layout-ncol: 2
#
#source: https://dk81.github.io/dkmathstats_site/rmath-uniform-plots.html

uniform_plot(-1, 1)
uniform_plot(0, 3)
```




@fig-uniform, (a): Bei $X=0$ hat *eine Einheit* von $X$ (z.B. von -1 bis 0) die Wahrscheinlichkeitsmasse von 50%, 
da der Bereich $[-1, 0]$ die H√§lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. 
Bei jedem anderen Punkt $x$ ist die Dichte identisch.
@fig-uniform, (b): Bei $X=0$ hat *eine Einheit* von $X$ die Wahrscheinlichkeitsmasse von ca. 33%, 
da der Bereich $[0, 1]$ ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. 
Bei jedem anderen Punkt $x$ ist die Dichte identisch
Definierendes Kennzeichen einer Gleichverteilung ist die *konstante Dichte*.



## Binomialverteilung {#sec-bin-distrib}

### Grundlagen

:::{#def-binvert}
### Binomialverteilung
Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines $n$-fach wiederholten binomialen Zufallexperiments,
eines Zufallsexperiments mit *zwei*^[von lat. *bis* "zweimal"] Ergebnissen bzw. Elementarereignissen also. 
Dabei interessiert uns nur die *Anzahl* der $k$ Treffer, aber nicht die Reihenfolge.
Bei jeder Wiederholung liegt die Wahrscheinlichkeit eines Treffers bei $p$.
bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die M√ºnze ver√§ndert sich nicht durch die W√ºrfe (*Ziehen mit Zur√ºcklegen*, ZmZ). 
Au√üerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit 
eines bestimmten Ergebnisses im zweiten Wurf, etc., sog. "iid": *independent and identically distributed*.] $\square$ 
:::



$$\overbrace{X}^{\text{Unsere Zufallsvariable}} \underbrace{\sim}_{\text{ist verteilt nach der}} \underbrace{\overbrace{\text{Bin}(n, p)}^{\text{Binomialverteilung}}}_{\text{mit den Parametern n, p}}$${#eq-binvert}


<!-- TODO over, underbrace wie hier: https://chrispiech.github.io/probabilityForComputerScientists/en/part2/binomial/ -->



F√ºr eine binomialverteilte Zufallsvariable $X$ schreibt man kurz wie in @thm-binvert gezeigt.

::: {#thm-binvert}

### Notation f√ºr eine binomialverteilte Zufallsvariable

$$X \sim \text{Bin}(n, k) \quad \square$$
:::



:::{#exm-binom1}
Anwendungsbeispiele: Wie viele defekte Teile sind in einer Stichprobe von produzierten Schrauben zu erwarten? Wie wahrscheinlich ist es, dass das neue Blutdruck-Medikament einer bestimmten Anzahl von Menschen hilft? Wie viele Personen stimmen in einer Umfrage der Frage "Ich halte die √∂ffentlich-rechtlichen Sender f√ºr wichtig." zu? Was ist die Wahrscheinlichkeit, 6 mal hintereinander eine *6* zu w√ºrfeln bei einem fairen W√ºrfel? Eine M√ºnze, die in 7 von 10 W√ºrfen "Kopf" zeigt -- sollte sie als "unfair" eingesch√§tzt werden?  $\square$
:::

Stellen wir uns eine Kistchen^[In den Lehrb√ºchern h√§ufig als Urne bezeichnet, was den b√∂sen Spott von "Friedhofstatistik" nach sich zog.] mit sehr vielen^[praktisch unendlich vielen] Losen vor, 
darunter 2/5 *T*reffer (Gewinn) und 3/5 *N*ieten, s. Abb. @fig-urne.
Der Versuch l√§uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zur√ºck und ziehen erneut. Da *sehr* viele Lose im K√§stchen liegen, ist es praktisch egal, ob wir das Los wieder zur√ºcklegen. Die Wahrscheinlichkeit f√ºr einen Treffer √§ndert sich (so gut wie) nicht.
Jetzt ziehen wir z.B. drei Lose.
Wie gro√ü ist die Wahrscheinlichkeit, 
davon 2 Treffer zu erzielen (egal in welcher Reihenfolge)?



```{r echo = FALSE}
#| fig-cap: Ein Losk√§stchen mit 2/5 Treffer und 3/5 Nieten
#| label: fig-urne
#| fig-asp: 0.3
#| echo: false  



d <- tibble(id = 1:5,
         event = c("T", "T", "N", "N", "N"))

p_urn <- 
  ggplot(d) +
  aes(x = id, label = id) +
  theme_minimal() +
  annotate("rect", xmin = 0, xmax = 6, ymin = 0, ymax = 2, fill = "grey80", alpha = .8) +
  geom_point(size = 10, y = 1, aes(color = event) )+
  geom_text(aes(label = id), y = 1) +
  theme(axis.text = element_blank()) +
  labs(x = "", color = "") +
  scale_color_okabeito()

d2 <-
  tibble(id = 1:1e3,
         Treffer = sample(0:1, 1e3, replace = TRUE, prob = c(3/5, 2/5)))  |> 
  mutate(Treffer = ifelse(Treffer == 1, "Treffer", "Niete"))

p_urn2 <- 
  ggplot(d2) +
  aes(color = Treffer) +
  geom_jitter(aes(x = 1, y = 1)) +
  scale_color_okabeito() +
  theme_void()

p_urn2
  
```



Praktischerweise ist die Binomialverteilung in R eingebaut,  
hier ist Pseudocode f√ºr Ihre Anwendung, s. @lst-binomial.

```{r}
#| lst-cap: "R-Pseudocode f√ºr die Binomialverteilung"
#| lst-label: lst-binomial
#| eval: false
dbinom(x = <Anzahl der Treffer>, 
       size = <Anzahl der W√ºrfe>, 
       prob = <Wahrscheinlichkeit eines Treffers>)
```


### M√∂glichkeiten z√§hlen


:::{#exm-bin1}
### Drei Lose gekauft, davon zwei Treffer?

Wie gro√ü ist die Wahrscheinlichkeit $p$ bei $n=3$ Z√ºgen $k=2$ Treffer zu erzielen (und $n-k=1$ Niete)? 
(Nennen wir dieses gesuchte Ereignis der K√ºrze halber $A^{\prime}$).
Die Trefferwahrscheinlichkeit ist (bei jedem Zug) $p=2/5$ und die 
Nietenwahrscheinlichkeit $1-p=3/5 \quad \square$, s. @fig-sort3.
@fig-dreimuenzen zeigt den entsprechenden Baum;
@tbl-3lose2treffer zeigt die Ergebnisse dieses Zufallsexperiments.
:::




```{r}
#| fig-cap: Wie viele M√∂glichkeiten gibt es, 3 Lose zu sortieren, von denen 2 Treffer sind und 1 Niete?
#| label: fig-sort3
#| fig-asp: 0.2
#| echo: false

d <- 
  tibble(id = 1:3,
         event = c("T", "T", "N"))

p_urn2 <- ggplot(d) +
  aes(x = id) +
  theme_minimal() +
  annotate("rect", xmin = 0, xmax = 4, ymin = 0, ymax = 2, fill = "grey80", alpha = .8) +
  geom_point(size = 10, y = 1, aes(color = event) )+
  geom_text(aes(label = event), y = 1) +
  theme(axis.text = element_blank()) +
  labs(x = "", color = "")

p_urn2
```






| Pfad (Ereignis) | Anzahl Treffer | Wahrscheinlichkeit                                                       |
| --------------- | -------------- | ------------------------------------------------------------------------ |
| TTT             | 3              | $p^3 = \left(\tfrac{2}{5}\right)^3 = \tfrac{8}{125} \approx 0.064$       |
| TTN             | 2              | $p^2 q = \tfrac{4}{25}\cdot\tfrac{3}{5} = \tfrac{12}{125} \approx 0.096$ |
| TNT             | 2              | $p^2 q = \tfrac{12}{125} \approx 0.096$                                  |
| NTT             | 2              | $p^2 q = \tfrac{12}{125} \approx 0.096$                                  |
| TNN             | 1              | $p q^2 = \tfrac{2}{5}\cdot\tfrac{9}{25} = \tfrac{18}{125} \approx 0.144$ |
| NTN             | 1              | $p q^2 = \tfrac{18}{125} \approx 0.144$                                  |
| NNT             | 1              | $p q^2 = \tfrac{18}{125} \approx 0.144$                                  |
| NNN             | 0              | $q^3 = \left(\tfrac{3}{5}\right)^3 = \tfrac{27}{125} \approx 0.216$      |

: Alle acht Ergebnisse des Zufallsexperiment mit ihren Wahrscheinlichkeiten im √úberblick {#tbl-3lose2treffer}





Mit Blick auf @exm-bin1: 
Wir k√∂nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen
(*Multiplikationssatz*, @thm-multtheorem), vgl. @fig-baum3.
Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit (*Additionssatz*, @thm-add-disjunkt).
Diagramme zeichnen ist einfach, dauert aber.


Beachtet man die *verschiedenen Reihenfolgen nicht*, 
so z√§hlt man 3 g√ºnstige Pfade (T: Treffer; N: Niete), s. @fig-dreimuenzen:

1. TTN
2. TNT
3. NTT.




Wir haben also die M√∂glichkeiten (2 Treffer und 1 Niete zu erhalten)

- *ohne Beachtung der Reihenfolge* und
- *ohne Zur√ºcklegen* (der M√∂glichkeiten)

gez√§hlt.







Schneller geht es, wenn man rechnet. 
Wir k√∂nnten auch R auffordern, die Anzahl der g√ºnstigen Pfade zu berechnen, s. @thm-binkoeff mit `choose(3,2)`, was die Antwort `3` liefert.




### Anzahl Pfade mal Pfad-Wahrscheinlichkeit



In diesem Fall ist die Wahrscheinlichkeit *eines* (g√ºnstigen) Pfades, $A$:

$Pr(A) = Pr(T)^2 \cdot Pr(N)^1 = \left( \frac{2}{5} \right)^2 \cdot \left( \frac{3}{5} \right)^1 \approx 0.096$.

```{r}
p_a = (2/5)^2 * (3/5)^1
p_a
```

Damit ist die Wahrscheinlichkeit des gesuchten Ereignisses $A^{\prime}$ (2 Treffer bei 3 Z√ºgen) 
gleich der Anzahl der g√ºnstigen $k$ Pfade (3) mal der Wahrscheinlichkeit eines Pfades (0.1):

$Pr(A^{\prime}) = k \cdot Pr(A) = 3 \cdot 0.096 = 0.29$.

```{r}
p_a_strich = 3 * p_a
p_a_strich
```

Die Wahrscheinlichkeit, bei 3 Z√ºgen 2 Treffer zu erzielen, 
betr√§gt also ca. 29%.

Dabei steht $k$ f√ºr die Anzahl der g√ºnstigen Pfade und $Pr(A)$ f√ºr die Wahrscheinlichkeit eines g√ºnstigen Pfades 
(d.h. 2 Treffer und 1 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.





### Formel der Binomialverteilung




@thm-binomial zeigt die mathematische Definition der Binomialverteilung.
Dabei liegt immer ein Zufallsversuch mit $n$ Durchg√§ngen und $k$ Treffern zugrunde. Jeder Durchgang hat die Trefferwahrscheinlichkeit $p$ und jeder Durchgang ist unabh√§ngig von allen anderen.


::: {#thm-binomial}
#### Binomialverteilung

$$Pr(X=k|p,n) = \frac{n}{k!(n-k)!}p^k(1-p)^{n-k}\quad \square$$
:::


 @thm-binomial kann wie folgt auf Deutsch √ºbersetzen:

>   Die Wahrscheinlichkeit f√ºr das Ereignis $X$ gegeben $p$ und $n$ berechnet als Produkt von zwei Termen. Der erste Term ist der Quotient von der Fakult√§t von n im Z√§hler und im Nenner das Produkt von erstens der Fakult√§t von k mit zweitens der Fakult√§t von (n-k). Der zweite Term ist das Produkt von p hoch k mal der komplement√§ren Wahrscheinlichkeit von p hoch (n-k).

Oder noch k√ºrzer:

>    Die Wahrscheinlichkeit f√ºr das Ereignis "X" gegeben p und k berechnet als Produkt von zwei Termen. Erstens der Anzahl der g√ºnstigen Pfade, k und zweitens der Wahrscheinlichkeit f√ºr einen g√ºnstigen Pfad, P(A).




Die Anzahl der (g√ºnstigen) Pfade kann man mit dem *Binomialkoeffizient* ausrechnen, den man so darstellt, s. @thm-binkoeff.^[wobei gelten muss $n \ge k$]

:::{#def-binkoeff}
#### Binomialkoeffizient
Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von $n$ verschiedenen Objekten $k$ Objekte ziehen kann (ohne Zur√ºcklegen und ohne Beachtung der Reihenfolge). $\square$
:::

::: {#thm-binkoeff}

#### Binomialkoeffizient

$$\tbinom{n}{k}= \frac{n!}{k!(n-k)!} \quad \square$$

Lies: "W√§hle aus $n$ m√∂glichen Ereignissen (Pfade im Baum) $k$ g√ºnstige Ereignisse (g√ºnstige Pfade) oder k√ºrzer "k aus n".\square
:::

Um den Binomialkoeffizient zu berechnen, 
muss man die Fakult√§t berechnen.
Die Fakult√§t ist eine Rechenvorschrift f√ºr nat√ºrliche Zahlen.
Man schreibt sie mit einem Ausrufezeichen hinter der Zahl, also zum Beispiel $3!$.
Dabei multipliziert man alle nat√ºrlichen Zahlen von der gegebenen Zahl bis hinunter zur 1.

:::{#exm-fakultaet}
- $3! = 3 \cdot 2 \cdot 1$
- $4! = 4 \cdot 3 \cdot 2 \cdot 1$
- $0! = 1$ (per Definition) $\square$
:::




Puh, Formeln sind vielleicht doch ganz praktisch, 
wenn man sich diese lange √úbersetzung der Formel in Prosa duchliest.
Noch praktischer ist es aber, dass es Rechenmaschinen gibt, 
die die Formel kennen und f√ºr uns ausrechnen. 




::: {#exm-klausur20}

#### Klausur mit 20-Richtig-Falsch-Fragen

Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen.
Wie gro√ü ist die Wahrscheinlichkeit, 
durch blo√ües M√ºnze werfen *genau* 15 Fragen richtig zu raten?^[Hey, endlich mal was f√ºr echte Leben!]



```{r QM2-Thema2-kleineModelle-23, echo = TRUE}
# Wskt f√ºr genau 15 Treffer bei 20 Versuchen mit einer fairen M√ºnze:
dbinom(x = 15, size = 20, prob = .5)
```
Die Wahrscheinlichkeit liegt bei ca 1%.

Um *h√∂chstens* 15 Treffer zu erzielen, 
m√ºssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern aufsummieren.

Praktischerweise gibt es einen R-Befehl, der das Aufsummieren f√ºr uns √ºbernimmt: `pbinom`.

```{r}
pbinom(q = 15, size = 20, prob = .5)
```


Die Wahrscheinlichkeit h√∂chstens 15 Treffer (d.h. 0, 1, 2, ... 15 Treffer) zu erzielen, liegt f√ºr `prob = .5` laut Binomialverteilung mit `pbinom` bei gut 99%.


:::



::: {#exm-globus4}

#### 3 M√ºnzw√ºrfe mit 3 Treffern

Was ist die Wahrscheinlichkeit bei 3 M√ºnzw√ºrfen (genau) 3 Treffer (Kopf) zu erzielen, s. @fig-p-bin-exms, links?

Das ist eine Frage an die Binomialverteilung;
in R kann man das mit der Funktion `dbinom` beantworten.

```{r QM2-Thema2-kleineModelle-24, echo = TRUE}
dbinom(x = 3, size = 3, prob = 1/2)
```

Die L√∂sung lautet also $p=1/8 = .125.\qquad \square$

Man kann sich auch vor Augen f√ºhren,
dass es genau 1 g√ºnstigen Pfad gibt, n√§mlich TTT.
Nach dem Multiplikationssatz gilt also: $Pr(X=3) = 1 \cdot \left( \frac{1}{2} \right)^3 = \frac{1}{8} = .125$.

```{r}
#| include: false
options(digits = 3)
```


```{r}
loesung <- (1/2)^3
loesung
```

```{r}
#| include: false
options(digits = 2)
```

:::


<!-- Todo: XXX -->

```{r QM2-Thema2-kleineModelle-25}
#| echo: false
#| label: fig-p-bin-exms
#| fig-cap: "Verschiedene Binomialverteilungen"
#| layout-ncol: 2
#| fig-subcap: 
#|   - "n=3, p=1/2"
#|   - "n=9, p=.7"

binomial_plot(3, 1/2)

binomial_plot(9, .7)
```




:::{#exr-binom}
Ô∏è Was f√§llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Ver√§ndert sich die Wahrscheinlichkeit linear?
:::


:::{#exr-binom2}
Was ist die Wahrscheinlichkeit f√ºr 0, 1, 2, ..., 9 Treffern bei 9 W√ºrfen, wenn die Trefferwahrscheinlichkeit 70% betr√§gt? @fig-p-bin-exms, rechts, zeigt die Antwort.
:::




### Rechnen mit der Binomialverteilung





Die Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen: z.B. `dbinom(x = 2, size = 3, prob = 2/5)`. 
Das ist komfortabler als selber rechnen.
Mit diesem Befehl rechnet R aus, wie hoch die Wahrscheinlichkeit ist, bei `size = 3` "M√ºnzw√ºrfen", `x = 2` Treffer zu erzielen, wobei die Trefferwahrscheinlichkeit jeweils `prob = 2/5` betr√§gt.



:::{#exm-binkoeff}
#### Lotto

Wie viele Zahlenkombinationen gibt es im Lotto f√ºr 6 Richtige?
Der Binomialkoeffizient verr√§t es uns:
$\tbinom{49}{6}= 13\,983\,816\square$
Ander gesagt: Der Binomialkoeffizient sagt uns,
wie viele M√∂glichkeiten es gibt, aus z.B. 46 B√§llen 6 zu ziehen
(ohne Beachtung der Reihenfolge und ohne Zur√ºcklegen). $\square$
:::



<!-- Auf Errisch geht das so: -->


<!-- :::: {.columns} -->

<!-- ::: {.column width="50%"} -->
<!-- >    üë®‚Äçüè´ Hey R, Wie viele M√∂glichkeiten gibt es, aus $n=3$ Z√ºgen $k=2$ auszuw√§hlen? -->


<!-- ::: -->

<!-- ::: {.column width="50%"} -->
<!-- >    ü§ñ √Ñh, Moment, oh herzliches Leberwesen -->
<!-- ```{r} -->
<!-- choose(5,2) -->
<!-- ``` -->
<!-- ::: -->

<!-- :::: -->



<!-- :::{#exm-2aus3} -->
<!-- Wie viele M√∂glichkeiten gibt es,  2 Treffer bei 3 Z√ºgen zu erzielen? -->

<!-- ```{r} -->
<!-- choose(4, 2) -->
<!-- ``` -->
<!-- ::: -->



:::{#exm-2aus4}
Wie viele M√∂glichkeiten gibt es,  2 Treffer bei 4 Z√ºgen zu erzielen?

Das sind folgende Ergebnisse: 
1. TTNN, 2. TNTN, 3. TNNT, 4. NTTN, 5. NTNT, 6. NNTT. 

$\tbinom{4}{2} = \frac{4!}{2! \cdot (4-2)!} \overset{\text{k√ºrzen}}= \frac{2\cdot 3}{1}=6$ 

Es sind also 6 M√∂glichkeiten. 
:::


In R kann man sich die Fakult√§t mit dem Befehl `factorial` ausrechnen lassen. Der R-Befehl `choose` berechnet den Binomialkoeffizienten.^[Bei Taschenrechnern ist diese Funktion oft als "nCr" zu finden.]



```{r}
anzahl_pfade_2_aus_4 <- 
  factorial(4) / (factorial(2) * factorial(4-2))
anzahl_pfade_2_aus_4

choose(4, 2)
```


$\square$


:::{#exm-2aus5}
Hier sind die 10 Kombinationen, um aus 5 Losen genau 2 Treffer und 3 Nieten zu ziehen:

TTNNN, TNTNN, TNNTN, TNNNT, NTTNN, NTNTN, NTNNT, NNTTN, NNTNT, NNNTT 

```{r}
choose(5, 2)

anzahl_pfade_2_aus_5 <- 
  factorial(5) / (factorial(2) * factorial(5-2))
anzahl_pfade_2_aus_5
```

$\square$
:::


```{r}
#| echo: false
# Define the values of n and k
n <- 5  # Total number of items
k <- 2  # Number of items to choose

# Generate all combinations
combinations <- combn(n, k) |> t() |> as_tibble()
```








:::{#exm-bef√∂rdern}
### Bef√∂rderung
Aus einem Team mit 25 Personen sollen 11 Personen bef√∂rdert werden. Wie viele m√∂gliche Kombinationen (von bef√∂rderten Personen) k√∂nnen gebildet werden?

$\tbinom{25}{11} = \frac{25!}{11!\cdot(25-11)!} = 4\,457\,400$


```{r}
choose(n = 25, k = 11)
```

Es gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht ber√ºcksichtigt.$\square$
:::




### Pumpstation-Beispiel zur Binomialverteilung

In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% f√§llt ein Motor aus und ist f√ºr den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie gro√ü ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb f√§llt?

$Pr(X=k)$ (oder kurz: $Pr(k)$) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an f√ºr das Ereignis, dass *k* Motoren arbeiten.

Lassen wir R mal $Pr(X=5)$ ausrechnen.


```{r}
dbinom(x = 5, size = 7, prob = .95)
```


Es gilt also $Pr(X=5) \approx .04$. Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist demnach relativ gering -- wobei "gering" subjektiv ist, die Betreiberfirma findet diese Wahrscheinlichkeit, 
dass 2 Pumpen ausfallen, wohl viel zu hoch.
Die Wahrscheinlichkeit, dass $k=0 \ldots 7$ Motoren laufen, ist in @fig-motoren dargestellt.


`dbinom()` steht f√ºr die Wahrscheinlichkeits*d*ichte (im diskreten Fall, wie hier, Wahrscheinlichkeitsfunktion genannt) und `binom` f√ºr die Binomialverteilung. `x` gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); `size` gibt die Stichprobengr√∂√üe an (hier 7 Motoren).

Damit gilt:

$Pr(X\ge 5) = Pr(X=5) + Pr(X=6) + Pr(X=7)$

Berechnen wir zun√§chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen mit Hilfe der Binomialverteilung. 


```{r}
p_5 <- dbinom(x = 5, size = 7, prob = .95)
p_6 <- dbinom(x = 6, size = 7, prob = .95)
p_7 <- dbinom(x = 7, size = 7, prob = .95)

p_5
p_6
p_7
```

Das sind `r round(p_5, 2)`, `r round(p_6, 2)`, `r round(p_7, 2)`.
Die gesuchte Wahrscheinlichkeit, `p_mind_5`,
ist die Summe der drei Einzelwahrscheinlichkeiten.



```{r}
p_mind_5 <- p_5 + p_6 + p_7

p_mind_5
```


Die Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betr√§gt also 
`r round(p_mind_5, 4)`.


Das komplement√§re Ereignis zu diesem Ereignis ist, 
dass *nicht* mind. 5 Motoren arbeiten, 
also *h√∂chstens 4* und es daher zu einem Ausfall kommt.
Es gilt also $Pr(\bar{X}) = 1- Pr(X)$.


```{r}
p_weniger_als_4 <- 1 - p_mind_5
p_weniger_als_4
```

Das sind also `r round(p_weniger_als_4, 4)` also`r round(p_weniger_als_4, 4)*100` % Wahrscheinlichkeit, dass die Pumpstation ausf√§llt.


```{r}
#| echo: false
#| fig-cap: "Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen"
#| label: fig-motoren

font_size <- 6

ps <- dbinom(x = 0:7, size = 7, prob = .95)

ps_df <-
  tibble(Motorenzahl = 0:7,
         Pr = ps,
         Pr_log = log(ps, base = 2))

ps_df |> 
  ggplot(aes(x = Motorenzahl, y = Pr)) +
  geom_col() +
  scale_x_continuous(breaks = 0:7) +
  geom_label(aes(label = round(Pr, 3)), size = font_size)

```


Alternativ kann man mit der Verteilungsfunktion `pbinom()` rechnen, 
die $Pr(X \le 4)$ berechnet.




In R kann man die Funktion `pbinom()` nutzen (*p* f√ºr (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen.

```{r}
pbinom(q = 4, size = 7, prob = .95)
```

`q = 4` steht f√ºr $X \le 4$, also f√ºr h√∂chstens 4 Treffer (arbeitende Motoren); `size = 7` meint die Stichprobengr√∂√üe, hier 7 Motoren; `prob` gibt die Trefferwahrscheinlichkeit an. $\square$





:::{#exr-binom-peer}
### Peer-Instruction: Qualit√§tskontrolle in einer Fabrik

Eine Fabrik produziert USB-Sticks.
Die Wahrscheinlichkeit, dass ein USB-Stick defekt ist, betr√§gt 2%. 
Aus der laufenden Produktion werden regelm√§√üig 10 USB-Sticks zuf√§llig ausgew√§hlt und getestet.
Sei $X$ die Anzahl defekter USB-Sticks in dieser Stichprobe.

Welche Aussage ist richtig bzw. passt am besten?

A) Mit 98% sind alle 10 USB-Sticks in Ordnung.
B) Mit 82% sind alle 10 USB-Sticks in Ordnung.
C) Mit 2% sind alle 10 USB-Sticks defekt.
D) Es ist unm√∂glich, dass alle 10 USB-Sticks defekt sind.
E) Es ist unm√∂glihc, dass alle 10 USB-Sticks in Ordnung sind. $\square$
:::



## Die halbe Normalverteilung

[Grundlagen √ºber die Normalverteilung](https://statistik1.netlify.app/040-verbildlichen#spezialfall-normalverteilung) k√∂nnen in @sauer2025 nachgelesen werden.

Ein Spezialfall der Normalverteilung ist die *halbe* (oder halbseitige) Normalverteilung, s. @fig-halbe-nv.

```{r}
#| fig-cap: "Die halbe Normalverteilung"
#| label: fig-halbe-nv
df <- data.frame(x = seq(-4, 4, length.out = 500))
df$y <- dnorm(df$x)

# Separate shading regions
df_left  <- subset(df, x <= 0) 
df_right <- subset(df, x >= 0)

ggplot(df, aes(x, y)) +
  geom_area(data = df_left, aes(x, y), fill = "grey90") +
  geom_area(data = df_right, aes(x, y), fill = "grey80") +
  #geom_line(size = 1) +
  theme_minimal() +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(
    axis.title.y = element_blank(),
    axis.text.y  = element_blank(),
    axis.ticks.y = element_blank(),
    axis.line.y  = element_blank()
  ) +
  scale_x_continuous(limits = c(0, 4))
```


:::{#def-halbe-nv}
### Halbe Normalverteilung
Wenn man die (negativen) Vorzeichen bei den Werten der Normalverteilung ignoriert, erh√§lt man die halbe Normalverteilung.
Man "spiegelt" die negative Seite auf die positive. $\square$
:::


Man kann sie verwenden, wenn man von normalverteilten Werten ausgeht, die gr√∂√üer als Null sein m√ºssen.
Sie hat zwei Parameter, Mittelwert und SD, analog zur Normalverteilung.


:::{#exm-halbe-NV}
### Halbe Normalverteilungen

- Die Entfernung Ihres Dart-Pfeiles zur Mitte der Zielscheibe
- Die Entfernung des vom Baum gefallenen Apfels zum Stamm
- Die Abweichung des Gewichts eines Produktionsgegenstands (z.B. einer Schraube) vom Soll-Gewicht
- Die Reaktionszeiten einer Versuchsperson in einer Reaktionszeitaufgabe $\square$
:::



## Die Exponentialverteilung

{{< include children/Exponentialverteilung.qmd >}}


## Vertiefung

@bourier2011, Kap. 6.2 und 7.1 erl√§utert einige (grundlegende) theoretische Hintergr√ºnde 
zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. 
Wichtigstes Exemplar f√ºr den Stoff dieses Kapitels ist dabei die Binomialverteilung.

@mittag2020 stellen in Kap. 12 und 13 Zufallsvariablen vor; 
zum Teil geht die Darstellung dort √ºber die Lernziele bzw. Inhalte dieses Kurses hinaus.


## Aufgaben


Zus√§tzlich zu den Aufgaben in der genannten Literatur sind folgende Aufgaben zu empfehlen.





### Paper-Pencil-Aufgaben



- [alphafehler-inflation3](https://datenwerk.netlify.app/posts/alphafehler-inflation3/alphafehler-inflation3.html)
- [alphafehler-inflation4](https://datenwerk.netlify.app/posts/alphafehler-inflation4/alphafehler-inflation4.html)
- [iq1a](https://datenwerk.netlify.app/posts/iq01a/)
- [iq2a](https://datenwerk.netlify.app/posts/iq02a/)
- [iq3a](https://datenwerk.netlify.app/posts/iq03a/)
- [simu-uniform](https://datenwerk.netlify.app/posts/simu-uniform/)
- [simu-unif2](https://datenwerk.netlify.app/posts/simu-unif2/)
- [simu-unif3](https://datenwerk.netlify.app/posts/simu-unif3/)
- [Quiz zum Thema Verteilungen](https://datenwerk.netlify.app/#category=Verteilungen-Quiz24)
- [Bsp-Binomial](https://datenwerk.netlify.app/posts/bsp-binomial/bsp-binomial)
- [distros](https://sebastiansauer.github.io/Datenwerk/posts/distros/)
- [bfi10](https://sebastiansauer.github.io/Datenwerk/posts/bfi10/)
- [wskt-quiz10](https://sebastiansauer.github.io/Datenwerk/posts/wskt-quiz10/wskt-quiz10.html)
- [Schiefe1](https://sebastiansauer.github.io/Datenwerk/posts/Schiefe1/Schiefe1.html)
- [exp-tab](https://sebastiansauer.github.io/Datenwerk/posts/exp-tab/)
- [exp1](https://sebastiansauer.github.io/Datenwerk/posts/exp1/)
- [small-wide-normal](https://sebastiansauer.github.io/Datenwerk/posts/small-wide-normal/)
- [likelihood-nv](https://datenwerk.netlify.app/posts/likelihood-nv/likelihood-nv.html)
- [schmalstepost](https://datenwerk.netlify.app/posts/schmalste-post/)



### Aufgaben, f√ºr die man einen Computer braucht

- [alphafehler-inflation2](https://datenwerk.netlify.app/posts/alphafehler-inflation2/alphafehler-inflation2.html)
- [Quiz (Aufgabensammlung) zu Verteilungen](https://datenwerk.netlify.app/#category=Verteilungen-Quiz)
- [wuerfel01](https://datenwerk.netlify.app/posts/wuerfel01/wuerfel01.html)
- [wuerfel02](https://datenwerk.netlify.app/posts/wuerfel02/wuerfel02.html)
- [wuerfel03](https://datenwerk.netlify.app/posts/wuerfel03/wuerfel03.html)
- [wuerfel04](https://datenwerk.netlify.app/posts/wuerfel04/wuerfel04.html)
- [iq01](https://datenwerk.netlify.app/posts/iq01/iq01)
- [iq02](https://datenwerk.netlify.app/posts/iq02/iq02)
- [iq03](https://datenwerk.netlify.app/posts/iq03/iq03)
- [iq04](https://datenwerk.netlify.app/posts/iq04/iq04)
- [iq05](https://datenwerk.netlify.app/posts/iq05/iq05)
- [iq06](https://datenwerk.netlify.app/posts/iq06/iq06)
- [iq07](https://datenwerk.netlify.app/posts/iq07/iq07)
- [iq08](https://datenwerk.netlify.app/posts/iq08/iq08)
<!-- - [iq09](https://datenwerk.netlify.app/posts/iq09/iq09) -->
<!-- - [iq10](https://datenwerk.netlify.app/posts/iq010/iq10) -->
- [Bus1](https://datenwerk.netlify.app/posts/bus1/bus1)


## ---



![](img/outro-04.jpg){width=100%}




