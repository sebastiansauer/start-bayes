# Verteilungen

<!-- TODO Dieses Kapitel hat nicht nur Verteilungen,  -->
<!-- sondern auch Stoff zum Thema Wahrscheinlichkeit, -->
<!-- das sollte entflechtet werden. -->


## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...


- den Begriff der Zufallsvariablen erl√§utern
- die Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erl√§utern 
- den Begriff einer Gleichverteilung erl√§utern 
- den Begriff einer Binomialverteilung erl√§utern
- die Parameter einer Normalverteilung nennen und erl√§utern
- zentrale Konzepte in R umsetzen



### Begleitliteratur

Der Stoff dieses Kapitels deckt sich (weitgehend) mit @bourier2011, Kap. 6.1 und 6.3 sowie 7.1 und und 7.2.



### Vorbereitung im Eigenstudium

Dieses Kapitel setzt einige Grundbegriffe voraus,
wie im Buch [Statistik1]() vorgestellt, insbesondere im Kapitel ["Rahmen"](https://statistik1.netlify.app/010-rahmen#was-sind-daten).
Ben√∂tigt wird auch der Begriff der [Normalverteilung](https://statistik1.netlify.app/040-verbildlichen#spezialfall-normalverteilung) sowie der Begriff der [Quantile](https://statistik1.netlify.app/050-zusammenfassen.html#quantile).

Lesen Sie selbst√§ndig, zus√§tzlich  zum Stoff dieses Kapitels, noch in @bourier2011 folgende Abschnitte:

<!-- - Kap. 6.1 (Zum Begriff Zufallsvariable) -->
<!-- - Kap. 6.3 (Stetige Zufallsvariablen) -->
- Kap. 7.1.1 (Binomialverteilung)
- Kap. 7.2.1 (Gleichverteilung)
- Kap. 7.2.3 (Normalverteilung)

L√∂sen Sie auch die √úbungsaufgaben dazu.


Weitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, @bourier2022.


### Pr√ºfungsrelevanter Stoff

Beachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff pr√ºfungsrelevant ist.


### Ben√∂tigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(ggpubr)  # f√ºr Plots
```


```{r}
#| include: false
library(gt)
library(patchwork)
#library(faux)
library(openintro)
library(easystats)
library(ggraph)
library(knitr)

source("funs/uniform_plot.R")  # oder "uniformplot.R"????
source("funs/binomial_plot.R")
```




```{r r-setup}
#| echo: false
#| message: false
theme_set(theme_minimal())
#scale_color_okabeito()
scale_colour_discrete <- function(...) 
  scale_color_okabeito()
```





### Zentrale Begriffe




#### Eigenschaften von Zufallsvariablen

- Zufallsvariable (random variable)
- Diskret vs. stetig
- Wahrscheinlichkeitsdichte (Dichte, (probability) density, f)
- Wahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)


#### Verteilungen

- Gleichverteilung
- Normalverteilung
- Standardnormalverteilung

### Begleitvideos


- [√úberblick zu Verteilungen](https://youtu.be/7GqIE4sKDs4)
- [Gleichverteilung](https://youtu.be/CJxi4e89aDs)
- [Binomialverteilung](https://youtu.be/xe7JL3fEKsg)



## Wichtige Verteilungen

Im Folgenden sind einige wichtige Verteilungen aufgef√ºhrt, die in diesem Skript (und in der Statistik und Wahrscheinlichkeitstheorie) eine zentrale Rolle spielen.

üì∫ [Einstieg in Verteilungen](https://www.youtube.com/watch?v=HKWwondYsW8&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=5)

## Gleichverteilung

### Indifferenz als Grundlage

Eine Gleichverteilung nimmt an, dass jeder Wert im Ergebnisraum der zugeh√∂rigen Zufallsvariable *gleichwahrscheinlich* ist.
Wenn man keinen hinreichenden Grund hat, eine Realisation einer Zufallsvariablen f√ºr plausibler als einen anderen zu halten,
ist eine Gleichverteilung eine passende Verteilung.
Gleichverteilungen gibt es im diskreten und im stetigen Fall.

Abb. @fig-uniform zeigt ein Beispiel f√ºr eine (stetige) Gleichverteilung.


```{r Normalverteilung-4, fig.asp = 0.5}
#| echo: false
#| fig-cap: "Stetige Gleichverteilung; man beachte jeweils die Y-Achse"
#| fig-subcap: 
#|   - "Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2"
#|   - "Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3"
#| label: fig-uniform
#| layout-ncol: 2
#
#source: https://dk81.github.io/dkmathstats_site/rmath-uniform-plots.html

uniform_plot(-1, 1)
uniform_plot(0, 3)
```




@fig-uniform, links: Bei $X=0$ hat *eine Einheit* von $X$ (d.h. von -0.5 bis +0.5) die Wahrscheinlichkeitsmasse von 50%, 
da der Bereich $[-0.5, +0.5]$ die H√§lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. 
Bei jedem anderen Punkt $x$ ist die Dichte gleich.
@fig-uniform, rechts: Bei $X=0$ hat *eine Einheit* von $X$ die Wahrscheinlichkeitsmasse von ca. 33%, 
da der Bereich $[-0.5, +0.5]$ ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. 
Bei jedem anderen Punkt $x$ ist die Dichte gleich.
Definierendes Kennzeichen einer Gleichverteilung ist die *konstante Dichte*.



### Simulation


M√∂chte man die Verteilungsfunktion einer stetigen Zufallsvariablen berechnen,
kann die Mathe ganz sch√∂n kompliziert werden, schlie√ülich muss man Integrale l√∂sen.
Aber es gibt einen Trick, wie man die Sache stark vereinfachen kann: 
man simuliert die Verteilung. Was bedeutet das?



Angenommen, die Wartezeit auf einen Bus ist gleichverteilt (engl. *uniform distribution*); 
der Bus kommt regelm√§√üig und p√ºnktlich alle 10 Minuten. 
Die minimale Wartezeit betr√§gt also 0 Minuten und die maximale 10 Minuten.
Nennen wir die zugeh√∂rige Zufallsvariable $X$, das ist sch√∂n kurz zu schreiben.

Eine gleichverteilte Zufallsvariable $X$ mit Min $m_0$ und Maximum $m_1$ schreibt man auch wie folgt in Kurzschreibweise:

$$X \sim Unif(m_0,m_1).$$



Ja, das sieht fancy aus, ist aber daf√ºr sch√∂n kurz, aber wo ist der versprochene Trick zum Vereinfachen?
Kommt gleich, Moment.

Eine Frage k√∂nnte nun lauten, wie gro√ü ist die Wahrscheinlichkeit, dass man zwischen 3 und 5 Minuten auf den Bus warten muss?
Achtung: Hier ist der Trick. N√§mlich, dass wir Integralrechnung gegen stumpfes Z√§hlen eintauschen.

Computer (und damit R) haben eingebaute Funktionen, die eine beliebige Zufallszahl ziehen k√∂nnen,
zum Beispiel gleichverteilte.
Auf Errisch hei√üt das Zauberwort `runif()`:
Mit dieser Funktion kann man gleichverteilte Zufallszahlen ziehen.
Einfach gesprochen: Der Computer greift in eine S√§ckchen mit Murmeln, die mit verschiedenen Zahlen beschriftet sind, wobei alle Zahlen gleich h√§ufig sind, und greift eine heraus.


```{r}
#| eval: false
set.seed(42)  # Zufallszahl festlegen, nur f√ºr Reproduzierbarkeit
# "r" wie random, "unif" wie "uniform" (gleich):
runif(n = 1, min = 0, max = 10) 
```

Auf Deutsch hei√üt das: 

> üë®‚Äçüè´   "Hey R, ich h√§tte gerne eine (daher `n = 1`) Zufallszahl (*r* wie *random*),
die gleichverteilt ist (*uniform*) mit `min = 0` und `max = 10`.

>   ü§ñ Jawohl, oh herrliches Leberwesen



(Zu) anschaulich gesprochen: R hat den Bus kommen lassen und es hat gut 9.1 Minuten gedauert,
bis er da war.
Achtung, jetzt kommt's: Jetzt lassen wir R mal $10^5$ (`1e5` auf Computersprech) Busse vorfahren. 
R soll jedes Mal notieren, wie lange man auf den Bus warten musste.^[Machen Sie das mal ohne Computer, wenn Sie ein Wochenende lang Langeweile haben.]




```{r}
#| eval: false
x_simu <- runif(n = 1e5, min = 0, max = 10)
```

```{r}
#| echo: false
n <- 1e5
set.seed(42)
x_simu <- runif(n = n, min = 0, max = 10)  # gibt Vektor zur√ºck

x_simu_df <-
  tibble(id = 1:n,
         x = x_simu)
```



Schauen wir uns die Verteilung an, s. @fig-simu-gleichvert.^[Alternativ kann man z.B. auch `ggplot` verwenden: `ggplot(x_simu_df, aes(x = x_simu)) +  geom_histogram(bins = 50)`.]

```{r}
#| eval: false
library(ggpubr)
gghistogram(x_simu_df, x = "x_simu", fill = "grey20")
```




```{r}
#| label: fig-simu-gleichvert
#| fig-cap: "Simulation einer gleichverteiluten Zufallsvariablen"
#| eval: true
#| echo: false

library(ggpubr)
gghistogram(x_simu_df, x = "x_simu", fill = "grey20")
```






Okay, unsere Verteilung sieht nicht *exakt* gleichverteilt, aber einigerma√üen. 
Gut genug f√ºr unsere Zwecke!

So, und jetzt kommt das Ernten.
Wir k√∂nnen jetzt n√§mlich einfach z√§hlen (`count()`), um die Antwort auf unsere Frage (der Wartezeit 3-5 Min.) zu erhalten, s. @tbl-count-simu-bus.


:::: {.columns}

::: {.column width="50%"}
```{r}
#| eval: false
x_simu_df %>% 
  count(Schnittmenge = x > 3 & x < 5)
```

:::

::: {.column width="50%"}
```{r}
#| echo: false
#| tbl-cap: H√§ufigkiten auslesen anstelle von Integralen berechnen
#| label: tbl-count-simu-bus
x_simu_df %>% 
  count(Schnittmenge = x > 3 & x < 5)
```

:::

::::




Das Zeichen `&` ist das logische UND, also die Schnittmenge der zwei Mengen $A$ ($X$ ist gr√∂√üer als 3) und $B$ ($X$ ist kleiner als 5), d.h. $A := \{x|x>3\}$ und $B := \{x|x<5\}$, 
also $A \cap B$.

Wie man sieht, fallen ca. 20% der Stichproben in den entsprechenden Bereich. 


Da viele Probleme, wenn sie komplexer werden, kaum noch "analytisch" (d.h. wie Ausrechnen von Integralen) l√∂sbar sind,
greift man in der modernen (Analyse-)Welt oft lieber auf Simulationsverfahren zur√ºck -- Dank sei den schnellen Rechnern.
F√ºr uns Menschen ist damit die Aufgabe des Integrierens auf schn√∂des Z√§hlen zur√ºckgef√ºhrt.







## Binomialverteilung {#sec-bin-distrib}

### Grundlagen

:::{#def-binvert}
### Binomialverteilung
Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines $n$-fach wiederholten binomialen Zufallexperiments,
eines Zufallsexperiments mit *zwei*^[von lat. *bis* "zweimal"] Ergebnissen bzw. Elementarereignissen also. 
Dabei interessiert die *Anzahl* der $k$ Treffer, aber nicht die Reihenfolge.
Bei jeder Wiederholung liegt die Wahrscheinlichkeit eines Treffers bei $p$.
Typisches Beispiel ist ein (wiederholter) M√ºnzwurf.^[Bei jeder Wiederholung des Zufallexperiments 
bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die M√ºnze ver√§ndert sich nicht durch die W√ºrfe (*Ziehen mit Zur√ºcklegen*, ZmZ). 
Au√üerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit 
eines bestimmten Ergebnisses im zweiten Wurf, etc., sog. "iid": *independent and identically distributed*.] $\square$ 
:::



$$\overbrace{X}^{\text{Unsere Zufallsvariable}} \underbrace{\sim}_{\text{ist verteilt nach der}} \underbrace{\overbrace{\text{Bin}(n, p)}^{\text{Binomialverteilung}}}_{\text{mit den Parametern n, p}}$${#eq-binvert}


<!-- TODO over, underbrace wie hier: https://chrispiech.github.io/probabilityForComputerScientists/en/part2/binomial/ -->



F√ºr eine binomialverteilte Zufallsvariable $X$ schreibt man kurz wie in @thm-binvert gezeigt.

::: {#thm-binvert}

### Notation f√ºr eine binomialverteilte Zufallsvariable

$$X \sim \text{Bin}(n, k) \quad \square$$
:::



:::{#exm-binom1}
Anwendungsbeispiele: Wie viele defekte Teile sind in einer Stichprobe von produzierten Schrauben zu erwarten? Wie wahrscheinlich ist es, dass das neue Blutdruck-Medikament einer bestimmten Anzahl von Menschen hilft? Wie viele Personen stimmen in einer Umfrage der Frage "Ich halte die √∂ffentlich-rechtlichen Sender f√ºr wichtig." zu? $\square$
:::

Stellen wir uns eine Kistchen^[In den Lehrb√ºchern h√§ufig als Urne bezeichnet, was den b√∂sen Spott von "Friedhofstatistik" nach sich zog.] mit sehr vielen^[praktisch unendlich vielen] Losen vor, 
darunter 2/5 *T*reffer (Gewinn) und 3/5 *N*ieten, s. Abb. @fig-urne.
Der Versuch l√§uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zur√ºck und ziehen erneut.^[Da *sehr* viele Lose im K√§stchen liegen, ist es praktisch egal, ob wir das Los wieder zur√ºcklegen. Die Wahrscheinlichkeit f√ºr einen Treffer √§ndert sich (so gut wie) nicht.] 
Jetzt ziehen wir z.B. drei Lose.
Wie gro√ü ist die Wahrscheinlichkeit, 
davon 2 Treffer zu erzielen (egal in welcher Reihenfolge)?



```{r echo = FALSE}
#| fig-cap: Ein Losk√§stchen mit 2/5 Treffer und 3/5 Nieten
#| label: fig-urne
#| fig-asp: 0.3
#| echo: false  



d <- tibble(id = 1:5,
         event = c("T", "T", "N", "N", "N"))

p_urn <- 
  ggplot(d) +
  aes(x = id, label = id) +
  theme_minimal() +
  annotate("rect", xmin = 0, xmax = 6, ymin = 0, ymax = 2, fill = "grey80", alpha = .8) +
  geom_point(size = 10, y = 1, aes(color = event) )+
  geom_text(aes(label = id), y = 1) +
  theme(axis.text = element_blank()) +
  labs(x = "", color = "") +
  scale_color_okabeito()

d2 <-
  tibble(id = 1:1e3,
         Treffer = sample(0:1, 1e3, replace = TRUE, prob = c(3/5, 2/5)))  |> 
  mutate(Treffer = ifelse(Treffer == 1, "Treffer", "Niete"))

p_urn2 <- 
  ggplot(d2) +
  aes(color = Treffer) +
  geom_jitter(aes(x = 1, y = 1)) +
  scale_color_okabeito() +
  theme_void()

p_urn2
  
```



Praktischerweise ist die Binomialverteilung in R eingebaut,  
hier ist Pseudocode f√ºr Ihre Anwendung, s. @lst-binomial.

```{r}
#| lst-cap: "R-Pseudocode f√ºr die Binomialverteilung"
#| lst-label: lst-binomial
#| eval: false
dbinom(x = <Anzahl der Treffer>, 
       size = <Anzahl der W√ºrfe>, 
       prob = <Wahrscheinlichkeit eines Treffers>)
```


### M√∂glichkeiten z√§hlen


:::{#exm-bin1}
### Drei Lose gekauft, davon zwei Treffer?

Wie gro√ü ist die Wahrscheinlichkeit $p$ bei $n=3$ Z√ºgen $k=2$ Treffer zu erzielen (und $n-k=1$ Niete)? 
(Nennen wir dieses Ereignis der K√ºrze halber $A^{\prime}$).
Die Trefferwahrscheinlichkeit ist (bei jedem Zug) $p=2/5$ und die 
Nietenwahrscheinlichkeit $1-p=3/5 \quad \square$.
:::


:::{.to-scource}
```{r}
df_binom <-
  tibble(
    k = 0:3,
    p = dbinom(0:3, size = 3, prob = 2/5))
```
:::



Mit Blick auf @exm-bin1: 
Wir k√∂nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen
(*Multiplikationssatz*, @thm-multtheorem), vgl. @fig-baum3.
Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit (*Additionssatz*, @thm-add-disjunkt).
Diagramme zeichnen ist einfach, dauert aber.


Beachtet man die *verschiedenen Reihenfolgen nicht*  (in @fig-baum3), 
so z√§hlt man 3 g√ºnstige Pfade (vgl. @fig-sort3):

1. TTN
2. TNT
3. NTT.



```{r}
#| fig-cap: Wie viele M√∂glichkeiten gibt es, 3 Lose zu sortieren, von denen 2 Treffer sind und 1 Niete?
#| label: fig-sort3
#| fig-asp: 0.2
#| echo: false

d <- 
  tibble(id = 1:3,
         event = c("T", "T", "N"))

p_urn2 <- ggplot(d) +
  aes(x = id) +
  theme_minimal() +
  annotate("rect", xmin = 0, xmax = 4, ymin = 0, ymax = 2, fill = "grey80", alpha = .8) +
  geom_point(size = 10, y = 1, aes(color = event) )+
  geom_text(aes(label = event), y = 1) +
  theme(axis.text = element_blank()) +
  labs(x = "", color = "")

p_urn2
```




Wir haben also die M√∂glichkeiten (2 Treffer und 1 Niete zu erhalten)

- *ohne Beachtung der Reihenfolge* und
- *ohne Zur√ºcklegen* (der M√∂glichkeiten)

gez√§hlt.




```{mermaid}
%%| fig-cap: "Baumdiagramm f√ºr das Ziehen von 2 Treffern und 1 Niete"
%%| label: fig-baum3
flowchart LR
  A[Start] -->B[Zug 1 - T]
  A -->C[Zug 1 - T]
  A -->D[Zug 1 - N]
  B -->E[Zug 2 - T]
  B -->F[Zug 2 -  N]
  C -->G[Zug 2 - T]
  C -->H[Zug 2 - N]
  D -->I[Zug 2 - T]
  D -->J[Zug 2 - T]
  E -->K[Zug 3 - N]
  F -->L[Zug 3 - T]
  G -->M[Zug 3 - N]
  H -->N[Zug 3 - T]
  I -->O[Zug 3 - T]
  J -->P[Zug 3 - T]
  K -->Q[TTN]
  L -->R[TNT]
  M -->S[TTN]
  N -->T[TNT]
  O -->U[NTT]
  P -->V[NTT]
  
```


Schneller geht es, wenn man rechnet. 
Wir k√∂nnten auch R auffordern, die Anzahl der g√ºnstigen Pfade zu berechnen, s. @thm-binkoeff:

```{r}
choose(3,2)
```




### Anzahl Pfade mal Pfad-Wahrscheinlichkeit



In diesem Fall ist die Wahrscheinlichkeit *eines* (g√ºnstigen) Pfades, $A$:

$Pr(A) = Pr(T)^2 \cdot Pr(N)^1 = \left( \frac{2}{5} \right)^2 \cdot \left( \frac{3}{5} \right)^1$.

```{r}
p_a = (2/5)^2 * (3/5)^1
p_a
```

Damit ist die Wahrscheinlichkeit des gesuchten Ereignisses $A^{\prime}$ (2 Treffer bei 3 Z√ºgen) gleich der Anzahl der g√ºnstigen Pfade mal der Wahrscheinlichkeit eines Pfades, , s. @eq-binkoeff-hand:

$Pr(A^{\prime}) = 3 \cdot Pr(A)$.

```{r}
p_a_strich = 3 * p_a
p_a_strich
```

Die Wahrscheinlichkeit, bei 3 Z√ºgen 2 Treffer zu erzielen, betr√§gt also ca. 29%, vgl. @eq-binkoeff-hand.



$$Pr(A^{\prime}) = k \cdot Pr(A)$${#eq-binkoeff-hand}

Dabei steht $k$ f√ºr die Anzahl der g√ºnstigen Pfade und $Pr(A)$ f√ºr die Wahrscheinlichkeit eines g√ºnstigen Pfades 
(d.h. 2 Treffer und 1 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.


### Rechnen mit der Binomialverteilung





Die Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen.
Das ist komfortabler als selber rechnen.



```{r}
dbinom(x = 2, size = 3, prob = 2/5)
```

Die Wahrscheinlichkeit,  2 Treffer bei 3 Z√ºgen zu erzielen mit $p=2/5$, betr√§gt demnach ca. 29%.


Dabei gehen wir davon aus, dass die Wahrscheinlichkeit eines Treffers stets $p=2/5$ betr√§gt.


:::{#exm-binkoeff}
### Lotto

Wie viele Zahlenkombinationen gibt es im Lotto f√ºr 6 Richtige?
Der Binomialkoeffizient verr√§t es uns:
$\tbinom{49}{6}= 13\,983\,816\square$
:::

<!-- Auf Errisch geht das so: -->


<!-- :::: {.columns} -->

<!-- ::: {.column width="50%"} -->
<!-- >    üë®‚Äçüè´ Hey R, Wie viele M√∂glichkeiten gibt es, aus $n=3$ Z√ºgen $k=2$ auszuw√§hlen? -->


<!-- ::: -->

<!-- ::: {.column width="50%"} -->
<!-- >    ü§ñ √Ñh, Moment, oh herzliches Leberwesen -->
<!-- ```{r} -->
<!-- choose(5,2) -->
<!-- ``` -->
<!-- ::: -->

<!-- :::: -->



<!-- :::{#exm-2aus3} -->
<!-- Wie viele M√∂glichkeiten gibt es,  2 Treffer bei 3 Z√ºgen zu erzielen? -->

<!-- ```{r} -->
<!-- choose(4, 2) -->
<!-- ``` -->
<!-- ::: -->



:::{#exm-2aus4}
Wie viele M√∂glichkeiten gibt es,  2 Treffer bei 4 Z√ºgen zu erzielen?

1. TTNN, 2. TNTN, 3. TNNT, 4. NTTN ,5. NTNT, 6. NNTT. 

$\tbinom{4}{2} = \frac{4!}{2! \cdot (4-2)!} \overset{\text{k√ºrzen}}= \frac{2\cdot 3}{1}=6$ 

Es sind also 6 M√∂glichkeiten. 
:::


In R kann man sich die Fakult√§t mit dem Befehl `factorial` ausrechnen lassen. Der R-Befehl `choose` berechnet den Binomialkoeffizienten.^[Bei Taschenrechnern ist diese Funktion oft als "nCr" zu finden.]



```{r}
anzahl_pfade_2_aus_4 <- 
  factorial(4) / (factorial(2) * factorial(4-2))
anzahl_pfade_2_aus_4

choose(4, 2)
```


$\square$


:::{#exm-2aus5}
Hier sind die 10 Kombinationen, um aus 5 Losen genau 2 Treffer und 3 Nieten zu ziehen:

TTNNN, TNTNN, TNNTN, TNNNT, NTTNN, NTNTN, NTNNT, NNTTN, NNTNT, NNNTT 

```{r}
choose(5, 2)

anzahl_pfade_2_aus_5 <- 
  factorial(5) / (factorial(2) * factorial(5-2))
anzahl_pfade_2_aus_5
```

$\square$
:::


```{r}
#| echo: false
# Define the values of n and k
n <- 5  # Total number of items
k <- 2  # Number of items to choose

# Generate all combinations
combinations <- combn(n, k) |> t() |> as_tibble()
```








:::{#exm-bef√∂rdern}
### Bef√∂rderung
Aus einem Team mit 25 Personen sollen 11 Personen bef√∂rdert werden. Wie viele m√∂gliche Kombinationen (von bef√∂rderten Personen) k√∂nnen gebildet werden?

$\tbinom{25}{11} = \frac{25!}{11!\cdot(25-11)!} = 4\,457\,400$


```{r}
choose(n = 25, k = 11)
```

Es gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht ber√ºcksichtigt.$\square$
:::



::: {#exm-binom}
### Pumpstation-Beispiel zur Binomialverteilung

In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% f√§llt ein Motor aus und ist f√ºr den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie gro√ü ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb f√§llt?

$Pr(X=k)$ (oder kurz: $Pr(k)$) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an f√ºr das Ereignis, dass *k* Motoren arbeiten.

Lassen wir R mal $Pr(X=5)$ ausrechnen.


```{r}
dbinom(x = 5, size = 7, prob = .95)
```


Es gilt also $Pr(X=5) \approx .04$. Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist relativ gering^[wobei "gering" subjektiv ist, die Betreiberfirma findet diese Wahrscheinlichkeit, dass 2 Pumpen ausfallen, wohl viel zu hoch.].
Die Wahrscheinlichkeit, dass $k=0 \ldots 7$ Motoren laufen, ist in @fig-motoren dargestellt.


`dbinom()` steht f√ºr die Wahrscheinlichkeits*d*ichte (im diskreten Fall, wie hier, Wahrscheinlichkeitsfunktion genannt) und `binom` f√ºr die Binomialverteilung. `x` gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); `size` gibt die Stichprobengr√∂√üe an (hier 7 Motoren).

Damit gilt:

$Pr(X\ge 5) = Pr(X=5) + Pr(X=6) + Pr(X=7)$

Berechnen wir zun√§chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen mit Hilfe der Binomialverteilung. 


```{r}
p_5 <- dbinom(x = 5, size = 7, prob = .95)
p_6 <- dbinom(x = 6, size = 7, prob = .95)
p_7 <- dbinom(x = 7, size = 7, prob = .95)

p_5
p_6
p_7
```

Das sind `r round(p_5, 2)`, `r round(p_6, 2)`, `r round(p_7, 2)`.



Die gesuchte Wahrscheinlichkeit, `p_mind_5`,
ist die Summe der drei Einzelwahrscheinlichkeiten.



```{r}
p_mind_5 <- p_5 + p_6 + p_7

p_mind_5
```


Die Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betr√§gt also 
`r round(p_mind_5, 4)`.


Das komplement√§re Ereignis zu diesem Ereignis ist, 
dass *nicht* mind. 5 Motoren arbeiten, 
also *h√∂chstens 4* und es daher zu einem Ausfall kommt.
Es gilt also $Pr(\bar{X}) = 1- Pr(X)$.


```{r}
p_weniger_als_4 <- 1 - p_mind_5
p_weniger_als_4
```

Das sind also `r round(p_weniger_als_4, 4)` oder 0.0003, also 0.03% Wahrscheinlichkeit, dass die Pumpstation ausf√§llt.


```{r}
#| echo: false
#| fig-cap: "Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen"
#| fig-subcap: 
#|   - "In 'normaler' Wahrscheinlichkeit, 0<p<1"
#|   - "In Log-Einheiten (Basis 2), 'Halbierungen'"
#| label: fig-motoren
#| layout-ncol: 2
#| 

font_size <- 6

ps <- dbinom(x = 0:7, size = 7, prob = .95)

ps_df <-
  tibble(Motorenzahl = 0:7,
         Pr = ps,
         Pr_log = log(ps, base = 2))

ps_df |> 
  ggplot(aes(x = Motorenzahl, y = Pr)) +
  geom_col() +
  scale_x_continuous(breaks = 0:7) +
  geom_label(aes(label = round(Pr, 3)), size = font_size)

ps_df |> 
  ggplot(aes(x = Motorenzahl, y = Pr_log)) +
  geom_col() +
  scale_x_continuous(breaks = 0:7) +
  geom_label(aes(label = round(Pr_log, 0)), size = font_size)
```


Alternativ kann man mit der Verteilungsfunktion `pbinom()` rechnen, 
die $Pr(X \le 4)$ berechnet.




In R kann man die Funktion `pbinom()` nutzen (p f√ºr (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen.

```{r}
pbinom(q = 4, size = 7, prob = .95)
```

`q = 4` steht f√ºr $X \le 4$, also f√ºr h√∂chstens 4 Treffer (arbeitende Motoren); `size = 7` meint die Stichprobengr√∂√üe, hier 7 Motoren; `prob` gibt die Trefferwahrscheinlichkeit an. $\square$

:::


:::callout-important

Die Funktion, die die Wahrscheinlichkeit daf√ºr angibt, dass die diskrete Zufallsvariable $X$ eine Realisation annimmt, die *kleiner oder gleich* (h√∂chstens) einem Wert $X=x$ ist, hei√üt *Verteilungsfunktion*.

$F(X=x) = Pr(X \le x)$

:::





#### Formel der Binomialverteilung




@thm-binomial zeigt die mathematische Definition der Binomialverteilung.
Dabei liegt immer ein Zufallsversuch mit $n$ Durchg√§ngen und $k$ Treffern zugrunde. Jeder Durchgang hat die Trefferwahrscheinlichkeit $p$ und jeder Durchgang ist unabh√§ngig von allen anderen.


::: {#thm-binomial}

### Binomialverteilung

$$Pr(X=k|p,n) = \frac{n}{k!(n-k)!}p^k(1-p)^{n-k}\quad \square$$
:::


 @thm-binomial kann wie folgt auf Deutsch √ºbersetzen:

>   Die Wahrscheinlichkeit f√ºr das Ereignis $X$ gegeben $p$ und $n$ berechnet als Produkt von zwei Termen. Der erste Term ist der Quotient von der Fakult√§t von n im Z√§hler und im Nenner das Produkt von erstens der Fakult√§t von k mit zweitens der Fakult√§t von (n-k). Der zweite Term ist das Produkt von p hoch k mal der komplement√§ren Wahrscheinlichkeit von p hoch (n-k).

Oder noch k√ºrzer:

>    Die Wahrscheinlichkeit f√ºr das Ereignis "X" gegeben p und k berechnet als Produkt von zwei Termen. Erstens der Anzahl der g√ºnstigen Pfade, k und zweitens der Wahrscheinlichkeit f√ºr einen g√ºnstigen Pfad, P(A).




Die Anzahl der (g√ºnstigen) Pfade kann man mit dem *Binomialkoeffizient* ausrechnen, den man so darstellt, s. @thm-binkoeff.^[wobei gelten muss $n \ge k$]

:::{#def-binkoeff}
### Binomialkoeffizient
Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von $n$ verschiedenen Objekten $k$ Objekte ziehen kann (ohne Zur√ºcklegen und ohne Beachtung der Reihenfolge). $\square$
:::

::: {#thm-binkoeff}

### Binomialkoeffizient

$$k = \tbinom{n}{k}= \frac{n!}{k!(n-k)!} \quad \square$$

Lies: "W√§hle aus $n$ m√∂glichen Ereignissen (Pfade im Baum) $k$ g√ºnstige Ereignisse (g√ºnstige Pfade) oder k√ºrzer "k aus n".\square
:::



Puh, Formeln sind vielleicht doch ganz praktisch, 
wenn man sich diese lange √úbersetzung der Formel in Prosa duchliest.
Noch praktischer ist es aber, dass es Rechenmaschinen gibt, 
die die Formel kennen und f√ºr uns ausrechnen. 




::: {#exm-klausur20}

#### Klausur mit 20-Richtig-Falsch-Fragen

Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen.
Wie gro√ü ist die Wahrscheinlichkeit, 
durch blo√ües M√ºnze werfen genau 15 Fragen richtig zu raten?^[Hey, endlich mal was f√ºr echte Leben!]

```{r QM2-Thema2-kleineModelle-23, echo = TRUE}
# Wskt f√ºr genau 15 Treffer bei 20 Versuchen mit einer fairen M√ºnze:
dbinom(x = 15, size = 20, prob = .5)
```

Um *h√∂chstens* 15 Treffer zu erzielen, 
m√ºssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern addieren.

Praktischerweise gibt es einen R-Befehl, der das f√ºr uns √ºbernimmt: `pbinom`.

```{r}
pbinom(q = 15, size = 20, prob = .5)
```


Die Wahrscheinlichkeit 0, 1, 2, ... oder 15 Treffer zu erzielen, liegt laut Binomialverteilung mit `pbinom` bei gut 99%.


:::



::: {#exm-globus4}

#### 3 M√ºnzw√ºrfe mit 3 Treffern

Was ist die Wahrscheinlichkeit bei 3 M√ºnzw√ºrfen (genau) 3 Treffer (Kopf) zu erzielen, s. @fig-p-bin-exms?

Das ist eine Frage an die Binomialverteilung;
in R kann man das mit der Funktion `dbinom` beantworten.

```{r QM2-Thema2-kleineModelle-24, echo = TRUE}
dbinom(x = 3, size = 3, prob = 1/2)
```

Die L√∂sung lautet also $p=1/8 = .125.\qquad \square$

Man kann sich auch vor Augen f√ºhren,
dass es genau 1 g√ºnstigen Pfad gibt, n√§mlich TTT.
Nach dem Multiplikationssatz gilt also: $Pr(X=3) = 1 \cdot \left( \frac{1}{2} \right)^3 = \frac{1}{8} = .125$.

```{r}
loesung <- (1/2)^3
loesung
```


:::


<!-- Todo: XXX -->

```{r QM2-Thema2-kleineModelle-25}
#| echo: false
#| label: fig-p-bin-exms
#| fig-cap: "Verschiedene Binomialverteilungen"
#| layout-ncol: 2
#| fig-subcap: 
#|   - "n=3, p=1/2"
#|   - "n=9, p=.7"

binomial_plot(3, 1/2)

binomial_plot(9, .7)
```




:::{#exr-binom}
üèãÔ∏èÔ∏è Was f√§llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Ver√§ndert sich die Wahrscheinlichkeit linear?
:::



## Die halbe Normalverteilung

[Grundlagen √ºber die Normalverteilung](https://statistik1.netlify.app/040-verbildlichen#spezialfall-normalverteilung) k√∂nnen in @sauer2025 nachgelesen werden.

Ein Spezialfall der Normalverteilung ist die *halbe* (oder halbseitige) Normalverteilung, s. @fig-halbe-nv.

```{r}
#| fig-cap: "Die halbe Normalverteilung"
#| label: fig-halbe-nv
df <- data.frame(x = seq(-4, 4, length.out = 500))
df$y <- dnorm(df$x)

# Separate shading regions
df_left  <- subset(df, x <= 0)
df_right <- subset(df, x >= 0)

ggplot(df, aes(x, y)) +
  geom_area(data = df_left, aes(x, y), fill = "grey90") +
  geom_area(data = df_right, aes(x, y), fill = "blue") +
  #geom_line(size = 1) +
  theme_minimal() +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(
    axis.title.y = element_blank(),
    axis.text.y  = element_blank(),
    axis.ticks.y = element_blank(),
    axis.line.y  = element_blank()
  )
```


:::{#def-halbe-nv}
### Halbe Normalverteilung
Wenn man die (negativen) Vorzeichen bei den Werten der Normalverteilung ignoriert, erh√§lt man die halbe Normalverteilung.
Man "spiegelt" die negative Seite auf die positive. $\square$
:::


Man kann sie verwenden, wenn man von normalverteilten Werten ausgeht, die gr√∂√üer als Null sein m√ºssen.


:::{#exm-halbe-NV}
### Halbe Normalverteilungen

- Die Entfernung Ihres Dart-Pfeiles zur Mitte der Zielscheibe
- Die Entfernung des vom Baum gefallenen Apfels zum Stamm
- Die Abweichung des Gewichts eines Produktionsgegenstands (z.B. einer Schraube) vom Soll-Gewicht
- Die Reaktionszeiten einer Versuchsperson in einer Reaktionszeitaufgabe $\square$
:::



## Vertiefung

@bourier2011, Kap. 6.2 und 7.1 erl√§utert einige (grundlegende) theoretische Hintergr√ºnde 
zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. 
Wichtigstes Exemplar f√ºr den Stoff dieses Kapitels ist dabei die Binomialverteilung.

@mittag2020 stellen in Kap. 12 und 13 Zufallsvariablen vor; 
zum Teil geht die Darstellung dort √ºber die Lernziele bzw. Inhalte dieses Kurses hinaus.


## Aufgaben


Zus√§tzlich zu den Aufgaben in der genannten Literatur sind folgende Aufgaben zu empfehlen.





### Paper-Pencil-Aufgaben



- [alphafehler-inflation3](https://datenwerk.netlify.app/posts/alphafehler-inflation3/alphafehler-inflation3.html)
- [alphafehler-inflation4](https://datenwerk.netlify.app/posts/alphafehler-inflation4/alphafehler-inflation4.html)
- [iq1a](https://datenwerk.netlify.app/posts/iq01a/)
- [iq2a](https://datenwerk.netlify.app/posts/iq02a/)
- [iq3a](https://datenwerk.netlify.app/posts/iq03a/)
- [simu-uniform](https://datenwerk.netlify.app/posts/simu-uniform/)
- [simu-unif2](https://datenwerk.netlify.app/posts/simu-unif2/)
- [simu-unif3](https://datenwerk.netlify.app/posts/simu-unif3/)
- [Quiz zum Thema Verteilungen](https://datenwerk.netlify.app/#category=Verteilungen-Quiz24)
- [Bsp-Binomial](https://datenwerk.netlify.app/posts/bsp-binomial/bsp-binomial)


### Aufgaben, f√ºr die man einen Computer braucht

- [alphafehler-inflation2](https://datenwerk.netlify.app/posts/alphafehler-inflation2/alphafehler-inflation2.html)
- [Quiz (Aufgabensammlung) zu Verteilungen](https://datenwerk.netlify.app/#category=Verteilungen-Quiz)
- [wuerfel01](https://datenwerk.netlify.app/posts/wuerfel01/wuerfel01.html)
- [wuerfel02](https://datenwerk.netlify.app/posts/wuerfel02/wuerfel02.html)
- [wuerfel03](https://datenwerk.netlify.app/posts/wuerfel03/wuerfel03.html)
- [wuerfel04](https://datenwerk.netlify.app/posts/wuerfel04/wuerfel04.html)
- [iq01](https://datenwerk.netlify.app/posts/iq01/iq01)
- [iq02](https://datenwerk.netlify.app/posts/iq02/iq02)
- [iq03](https://datenwerk.netlify.app/posts/iq03/iq03)
- [iq04](https://datenwerk.netlify.app/posts/iq04/iq04)
- [iq05](https://datenwerk.netlify.app/posts/iq05/iq05)
- [iq06](https://datenwerk.netlify.app/posts/iq06/iq06)
- [iq07](https://datenwerk.netlify.app/posts/iq07/iq07)
- [iq08](https://datenwerk.netlify.app/posts/iq08/iq08)
<!-- - [iq09](https://datenwerk.netlify.app/posts/iq09/iq09) -->
<!-- - [iq10](https://datenwerk.netlify.app/posts/iq010/iq10) -->
- [Bus1](https://datenwerk.netlify.app/posts/bus1/bus1)


## ---



![](img/outro-04.jpg){width=100%}




