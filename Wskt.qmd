
# Wahrscheinlichkeit

```{r}
#| include: false
library(tidyverse)
library(easystats)
theme_set(theme_modern())
```



```{r}
#| echo: false
#| fig-width: 7

plot16a <-
  ggplot(data.frame(A = c(0, 1),
                    B = c(0, 1))) +
  aes(x = A, y = B) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0, ymax = .5,
           color = "yellow", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0.5, ymax = 1,
           color = NA, alpha = .5, fill = "yellow") +
  annotate("rect", xmin = 0, xmax =0.5, ymin = 0, ymax = 1,
           color = "blue", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0.5, xmax = 1, ymin = 0, ymax = 1,
           color = "blue", alpha = .5, fill = "blue") +
  scale_x_continuous(breaks = c(0.25, 0.75), labels = c("¬A", "A")) +
  scale_y_continuous(breaks = c(0.25, 0.75), labels = c("¬B", "B"))


plot16a1 <-
  ggplot(data.frame(A = c(0, 1),
                    B = c(0, 1))) +
  aes(x = A, y = B) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0, ymax = .5,
           color = "yellow", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0.5, ymax = 1,
           color = NA, alpha = .5, fill = "yellow") +
  scale_x_continuous(breaks = c(0.25, 0.75), labels = c("¬A", "A")) +
  scale_y_continuous(breaks = c(0.25, 0.75), labels = c("¬B", "B")) +
  annotate("label", x = .5, y = .75, label = "Pr(B) = 50%")

plot16a2 <-
  ggplot(data.frame(A = c(0, 1),
                    B = c(0, 1))) +
  aes(x = A, y = B) +
  annotate("rect", xmin = 0, xmax =0.5, ymin = 0, ymax = 1,
           color = "blue", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0.5, xmax = 1, ymin = 0, ymax = 1,
           color = "blue", alpha = .5, fill = "blue") +
  scale_x_continuous(breaks = c(0.25, 0.75), labels = c("¬A", "A")) +
  scale_y_continuous(breaks = c(0.25, 0.75), labels = c("¬B", "B")) +
  annotate("label", x = .75, y = .5, label = "Pr(A) = 50%")


plot16b <-
ggplot(data.frame(A = c(0, 1),
                  B = c(0, 1))) +
  aes(x = A, y = B) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0, ymax = .5,
           color = "yellow", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0.5, ymax = 1,
           color = NA, alpha = .5, fill = "yellow") +
  annotate("rect", xmin = 0, xmax =0.5, ymin = 0, ymax = 1,
           color = "blue", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0.5, xmax = 1, ymin = 0, ymax = 1,
           color = "blue", alpha = .5, fill = "blue") +
  annotate("rect", xmin = 0.5, xmax = 1, ymin = 0.5, ymax = 1,
           color = "green", alpha = .7, fill = NA) +
  scale_x_continuous(breaks = c(0.25, 0.75), labels = c("¬A", "A")) +
  scale_y_continuous(breaks = c(0.25, 0.75), labels = c("¬B", "B")) +
  annotate(geom = "label", x = .75, y = 0.75, label = "A,B")





plot16c <-
  ggplot(data.frame(A = c(0, 1),
                    B = c(0, 1))) +
  aes(x = A, y = B) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0, ymax = .5,
           color = "yellow", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0, xmax = 1, ymin = 0.5, ymax = 1,
           color = NA, alpha = .5, fill = "NA") +
  annotate("rect", xmin = 0, xmax =0.5, ymin = 0, ymax = 1,
           color = "blue", alpha = .7, fill = NA) +
  annotate("rect", xmin = 0.5, xmax = 1, ymin = 0, ymax = 1,
           color = "blue", alpha = .5, fill = "blue", linewidth = 2) +
  annotate("rect", xmin = 0.5, xmax = 1, ymin = 0.5, ymax = 1,
           color = "green", alpha = .3, fill = "green") +
  scale_x_continuous(breaks = c(0.25, 0.75), labels = c("¬A", "A")) +
  scale_y_continuous(breaks = c(0.25, 0.75), labels = c("¬B", "B")) +
  annotate(geom = "label", x = .75, y = 0.75, label = "B|A")


```

## Lernsteuerung


### Lernziele

Nach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.

Sie können ...


- die Grundbegriffe der Wahrscheinlichkeitsrechnung erläuternd definieren
- die drei Arten der direkten Ermittlung von Wahrscheinlichkeit erläutern
- typische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen
- mit Wahrscheinlichkeiten rechnen



### Prüfungsrelevanter Stoff

Lesen Sie dazu @bourier_2018, Kap. 2-4. Weitere Übungsaufgaben finden Sie im dazugehörigen Übungsbuch, @bourier_statistik-ubungen_2022.



## Unterstützung: Wahrscheinlichkeit in Bildern

Wahrscheinlichkeit in Bildern: zur einfachen Erschließung des Materials,
ein Unterstützungsangebot.


Im Folgenden sind einige Schlüsselbegriffe und -regeln in (ver-)einfach(t)er Form schematisch bzw. visuell dargestellt mit dem Ziel, den Stoff einfacher zu erschließen.


### Zufall

Werfen Sie eine Münze!

Diese hier zum Beispiel:

![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Coin-155597.svg/1024px-Coin-155597.svg.png){width=25%}

[Quelle: By OpenClipartVectors, CC0]( https://pixabay.com/pt/moeda-euro-europa-fran%C3%A7a-dinheiro-155597)

Wiederholen Sie den Versuch 10, nein, 100, nein 1000, nein: $10^6$ Mal.

Notieren Sie das Ergebnis!

Oder probieren Sie die [App der Brown University](https://seeing-theory.brown.edu/basic-probability/index.html#section1).



### Relationen von Mengen

Venn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren.



#### Überblick

Die folgenden Diagramme stammen von [Wikipedia (En)](https://en.wikipedia.org/wiki/Venn_diagram).

Wir gehen von Ereignisraum $\Omega$ aus, mit dem Ereignis $A$ als Teilmenge: $A \subset B$.


::: {#fig-sets layout-ncol=2}




![$A \cap B$](https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Venn0001.svg/2560px-Venn0001.svg.png)




![$A \cup B$](https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Venn0111.svg/2560px-Venn0111.svg.png)




![$\bar{A}$](https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Venn1010.svg/2560px-Venn1010.svg.png)






![$A \setminus B$](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Venn0100.svg/2560px-Venn0100.svg.png){width=25%}

Typische Mengenoperationen
:::



#### Disjunkte Ereignisse


(Engl. disjoint events)

$A= \{1,2,3\}; B= \{4,5,6\}$

$A$ und $B$ sind disjunkt: ihre Schnittmenge ist leer: $A \cap B = \emptyset$.





![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Disjunkte_Mengen.svg/2880px-Disjunkte_Mengen.svg.png){width=25%}





#### Eselsbrücke zur Vereinigungs- und Schnittmenge

![](http://www.rither.de/images/mathematik/stochastik/mengentheorie-und-venn-diagramme/ven_cup_cap.jpg){width=55%}

[Quelle: rither.de](http://www.rither.de/a/mathematik/stochastik/mengentheorie-und-venn-diagramme/)


#### Animationen


[Animation zu Mengenoperationen](https://seeing-theory.brown.edu/compound-probability/index.html)



[Animation zur Vereinigung von Mengen](https://www.geogebra.org/m/GEZV4xXc#material/cmXR8fHN)

[Quelle](Geogebra, J. Merschhemke)


### Additionssatz 

Der Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass *mindestens eines der Ereignisse* eintritt.

#### Diskunkte Ereignisse

$\Omega = {1,2,3,4,5,6}$



$\boxed{1\; 2\; 3\; 4\; 5\; 6}$

Gesucht sei die Wahrscheinlichkeit des Ereignis $A=\{1,2\}$.


$\boxed{\boxed{1\; 2}\; \color{grey}{ 3\; 4\; 5\; 6}}$

$P(1 \cup 2) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6}$


#### Allgemein (disjunkt oder nicht disjunkt)


Bei der Addition der Wahrscheinlichkeiten für $A$ und $B$ wird der Schnitt $A\cap B$ doppelt erfasst. Er muss daher noch abgezogen werden:



$$P(A \cup B) = P(A) + P(B) - P(A\cap B)$$
$A \cup B$

![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Venn0111.svg/2560px-Venn0111.svg.png){width=25%}

$A \cap B$


![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Venn0001.svg/2560px-Venn0001.svg.png){width=25%}




### Bedingte Wahrscheinlichkeit


#### Animation


Schauen Sie sich mal diese [Wahnsinnsanimation von Victor Powell an](https://setosa.io/conditional/). Hammer!


#### Schema

```{r bed-w-schema}
#| echo: false
plots(plot16a1, plot16a2, plot16c)
```



Bedingte Wahrscheinlichkeit ist vergleichbar zu Filtern einer Tabelle:

```{r}
#| echo: true
d <- 
  tibble::tribble(
      ~id, ~A, ~B,
      "1", 1L, 0L,
      "2", 0L, 1L,
      "3", 1L, 1L,
      "4", 1L, 1L,
      "5", 0L, 0L,
  "SUMME", 4L, 4L
  )

```


$P(A) = 4/5$

$P(B) = 4/5$

$P(A \cap B) = 2/5$

$P(A|B) = 2/3$






### (Un-)Abhängigkeit

Stochastische Unabhängigkeit ist ein Spezialfall von Abhängigkeit: Es gibt sehr viele Ausprägungen für Abhängigkeit, aber nur eine für Unabhängigkeit.
Können wir Unabhängigkeit nachweisen, haben wir also eine starke Aussage getätigt.






```{r}
#| echo: false
library(titanic)

data("titanic_train")


plottitanic1 <-
titanic_train %>%
  select(Pclass, Survived) %>%
  mutate(Survived = factor(Survived)) %>%
  ggplot(aes(x = Pclass)) +
  geom_bar(aes(fill = Survived), position = "fill") +
  theme(legend.position = "bottom")


plottitanic2 <-
titanic_train %>%
  select(Survived, Embarked) %>%
  filter(Embarked %in% c("C", "Q", "S")) %>%
  mutate(Survived = factor(Survived)) %>%
  ggplot(aes(x = Embarked)) +
  geom_bar(aes(fill = Survived), position = "fill") +
  theme(legend.position = "bottom")



library(gmp)

plottitanic3 <-
  titanic_train %>%
  select(Survived, Age) %>%
  mutate(Age_prime = isprime(Age),
         Age_prime = factor(Age_prime)) %>%
  mutate(Survived = factor(Survived)) %>%
  ggplot(aes(x = Age_prime)) +
  geom_bar(aes(fill = Survived), position = "fill") +
  theme(legend.position = "bottom") +
  scale_x_discrete(breaks = c(0, 2),
                     labels = c("Nicht Prim", "Prim"))

# plottitanic3

```



Abhängig:

$P(A|B) \ne Pr(A) \ne Pr(A|\neg B)$
```{r QM2-Thema1-WasistInferenz-31, out.width="100%"}
#| echo: false
plottitanic1
```


Überleben auf der Titanic ist offenbar abhängig von der Passagierklasse.



Unabhängig:

$P(A|B) = Pr(A) = Pr(A|\neg B)$

```{r QM2-Thema1-WasistInferenz-32, out.width="100%"}
#| echo: false
plottitanic3 
```

Überleben auf der Titanic ist *un*abhängig vom Ereignis *Alter ist eine Primzahl*.







Sind die Ereignisse *Tod durch Covid*  bzw. *Impfquote* ($A$) und *Land*^[hier mit den zwei Ausprägungen *DEU* und *USA*] ($B$) voneinander abhängig?

```{r covid1}
#| message: false
#| echo: false
#| cache: true

# source: https://ourworldindata.org/covid-vaccinations
# access date: 2021-09-24
# licence: https://ourworldindata.org/covid-vaccinations#licence



dfile <- "data/owid-covid-data.csv"

library(lubridate)

d <- read_csv(dfile)

d2<-
  d %>%
  filter(iso_code %in% c("DEU", "USA")) %>%
  mutate(date = as_date(date)) %>%
  rename(Land = iso_code) %>%
  select(date,
         Land,
         #total_deaths,
         #new_deaths,
         people_fully_vaccinated_per_hundred,
         total_deaths_per_million,
         #new_vaccinations,
         total_vaccinations) %>%
  filter(date == "2021-09-23") %>%
  group_by(Land)


# d2 %>%
#   ungroup() %>%
#   count(people_fully_vaccinated_per_hundred)

plot_covid1 <-
  d2 %>%
  ggplot(aes(x = Land,
             y = people_fully_vaccinated_per_hundred)) +
  geom_col() +
  labs(title = "Anteil komplett geimpfter Personen",
       subtitle = "2021-09-23")




plot_covid2 <-
  d2 %>%
  ggplot(aes(x = Land,
             y = total_deaths_per_million)) +
  geom_col()+
  labs(title = "Corona-Tote pro Million",
       subtitle = "2021-09-23")
```

Ja, da in beiden Diagrammen gilt: $P(A|B) \ne Pr(A) \ne Pr(A|\neg B)$.


```{r plotcovid1}
#| echo: false
plot_covid1
```


```{r plotcovid2}
#| echo: false
plot_covid2
```



Daten von [Our World in Data](https://ourworldindata.org/covid-deaths).











### Multiplikationssatz

Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass *alle Ereignisse* eintreten.


#### Unabhängige Ereignisse


Wir werfen eine faire Münze *zwei* Mal:


![](img/muenz1.png)


```{r}
#| echo: false
tibble::tribble(
  ~Ereignis,               ~Pr,
       "0K", "1/2 * 1/2 = 1/4",
       "1K", "1/4 + 1/4 = 1/2",
       "2K", "1/2 * 1/2 = 1/4"
  )
```

Wir werfen eine faire Münze *drei* Mal:

![](img/muenz2.png)



```{r QM2-Thema1-WasistInferenz-27}
#| echo: false
tibble::tribble(
  ~Ereignis,                     ~Pr,
       "0K", "1/2 * 1/2 * 1/2 = 1/8",
       "1K", "1/8 + 1/8 + 1/8 = 3/8",
       "2K",          "3 * 1/8 = 3/8",
       "3K", "1/2 * 1/2 * 1/2 = 1/8"
  ) 
```




$Pr(AB) = Pr(A) \cdot Pr(B) = 50\% \cdot 50\% = 25\%$

```{r plot-unabh-ereignisse}
#| echo: false
plots(plot16a1, plot16a2, plot16c)
```


Es gilt also: $P(A\cap B) = P(A) \cdot P(B) = P(B) \cdot P(A)$.


#### Kalt und Regen

Von @mcelreath_statistical_2020 stammt diese Verdeutlichung der gmeinsamen Wahrscheinlichkeit:

Was ist die Wahrscheinlichkeit für *kalt ❄ und Regen ⛈️*?

Die Wahrscheinlichkeit für kalt und Regen ist die Wahrscheinlichkeit von *Regen* ⛈, wenn's *kalt* ❄ ist mal die Wahrscheinlichkeit von *Kälte* ❄.

Ebenfalls gilt:

Die Wahrscheinlichkeit für kalt und Regen ist die Wahrscheinlichkeit von *Kälte* ❄, wenn's *regnet* ⛈️ mal die Wahrscheinlichkeit von *Regen* ⛈️.

Das Gesagte als Emoji-Gleichung:

$P(❄️ und ⛈️) = P(⛈️ |❄️ ) \cdot P(❄️) =  P(❄️ |⛈️ ) \cdot P(⛈️) = P(⛈️ und  ❄️)$



Allgemein:

$P(A\cap B) = P(A) \cdot P(B|A) = P(B) \cdot P(A|B)$


Man kann also die "Gleichung drehen".

#### Abhängige Ereignisse



Ein Baumdiagramm bietet sich zur Visualisierung abhängiger Ereignisse an. Für unabhängige Ereignisse übrigens auch.


In einer Urne befinden sich fünf Kugeln, von denen vier rot sind und eine blau ist.

wie groß ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zurücklegen (*ZOZ*) *zwei rote Kugeln* gezogen werden [@bourier_2018], S. 47.


Hier ist unsere Urne:

$$\boxed{\color{red}{R, R, R, R}, \color{blue}B}$$

Und jetzt ziehen wir. Hier ist das Baumdiagramm:


```{mermaid}
flowchart LR
  A[Start] -->|4/5|B[1. Zug: R]
  A -->|1/5|C[1. Zug: B]
  B -->|3/4|D[2. Zug: R]
  B -->|1/4|E[2. Zug: B]
  D --- H[Fazit: RR:  12/20]
  E --- I[Fazit: RB: 4/20]
  C -->|4/4|F[2. Zug: R]
  C -->|0/4|G[2. Zug: B]
  F --- J[Fazit: BR: 4/20]
  G --- K[Fazit: BB: 0/20]
```



Es gilt also: $P(A\cap B) = P(A) \cdot P(B|A)$.



### Totale Wahrscheinlichkeit




Hier ist das Baumdiagramm für die Aufgabe @bourier_2018, S. 56.

```{mermaid}
flowchart LR
  A[Start] -->|0.6|B[A1]
  A -->|0.1|C[A2]
  A -->|0.3|D[A3]
  B -->|0.05|E[B]
  B -.->|0.95|F[Nicht-B]
  C -->|0.02|G[B]
  C -.->|0.98|H[Nicht-B]
  D -->|0.04|I[B]
  D -.->|0.96|J[Nicht-B]
```



Gesucht ist die Wahrscheinlichkeit $P(B)$.

Dazu addieren wir die Warhscheinlichkeiten der relevanten Äste.

```{r}
W_total <- 0.6 * 0.05 + 0.1 * 0.02 + 0.3 * 0.04
W_total
```

Die totale Wahrscheinlichkeit beträgt also $P(B) = 4.4\%$.

Einfacher noch ist es, wenn man anstelle von Wahrscheinlichkeiten absolute Häufigkeiten verwendet.


### Bayes

#### Bayes als Baum

Gesucht sei $P(A_1|B)$.

Für Bayes' Formel setzt man die Wahrscheinlichkeit des  *günstigen* Ast zur Wahrscheinlichkeit aller relevanten Äste, $P(B)$.

Der günstige Ast ist hier schwarz gedruckt, die übrigen Äste gestrichelt.

```{mermaid}
flowchart LR
  A[Start] -->|0.6|B[A1]
  A -.->|0.1|C[A2]
  A -.->|0.3|D[A3]
  B --->|0.05|E[B]
  B -.->|0.95|F[Nicht-B]
  C -.->|0.02|G[B]
  C -.->|0.98|H[Nicht-B]
  D -.->|0.04|I[B]
  D -.->|0.96|J[Nicht-B]
```



$$P(A|B) = \frac{P(A1 \cap B)}{P(B)} = \frac{0.6 \cdot 0.05}{0.03 + 0.002 + 0.012} = \frac{0.03}{0.044} \approx 0.68$$

$P(A|B)$ beträgt also ca. 68%.

Zur Erinnerung $P(B)$ ist die totale Wahrscheinlichkeit.


#### Bayes als bedingte Wahrscheinlichkeit


Bayes' Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:


$P(A|B) = \frac{\overbrace{ P(A\cap B)}^\text{umformen}}{P(B)}$

$P(A\cap B)$ kann man aber umformen:

$\frac{P(A\cap B)}{P(B)} = \frac{P(B|A) \cdot P(A)}{P(B)}$

Man kann sich Bayes' Theorem  auch wie folgt herleiten:



$P(A\cap B) = P(B \cap A) = P(A) \cdot P(B|A) = P(B) \cdot P(A|B)$

Dann lösen wir nach P$(A|B)$ auf:


$P(AB) = \frac{P(A) \cdot P(B|A)}{P(B)}$



#### Bayes-Video von 3b1b

Das [Video zu Bayes von 3b1b](https://youtu.be/HZGCoVF3YvM) verdeutlicht das Vorgehen mit der Bayes-Methode auf einfache und anschauliche Weise.



## Zentrale Begriffe


### Grundbegriffe

- Zufallsvorgang (Zufallsexperiment)
- Elementarereignis
- Ereignisraum
- Zufallsereignis (zufälliges Ereignis)
- Sicheres Ereignis
- Unmögliches Ereignis


### Wahrscheinlichkeitsbegriffe

- Klassische Wahrscheinlichkeit (LaPlace'sche Wahrscheinlichkeit)
- Statistische (empirische) Wahrscheinlichkeitsermittlung
- Subjektive (Bayes) Wahrscheinlichkeitsermittlung


### Wahrscheinlichkeitsrelationen

- Vereinigung von Ereignissen
- Schnitt(menge) von Ereignissen
- Komplementärereignis
- Vollständiges Ereignissystem
- Kolmogorovs Definition von Wahrscheinlichkeit


### Wahrscheinlichkeitsrechnung

- Allgemeiner Additionsssatz
- Disjunkte Ereignisse
- Additionssatz für disjunkte Ereignisse
- Bedingte Wahrscheinlichkeit
- (Stochastische) Unabhängigkeit
- Baumdiagramm für gemeinsame Wahrscheinlichkeit
- Allgemeiner Multiplikationssatz
- Multiplikationssatz für unabhängige Ereignisse
- Totale Wahrscheinlichkeit
- Satz von Bayes





