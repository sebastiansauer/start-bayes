[
  {
    "objectID": "0900-lineare-modelle.html",
    "href": "0900-lineare-modelle.html",
    "title": "9  Einfache lineare Modelle",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "9  Einfache lineare Modelle",
    "section": "",
    "text": "9.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Post-Verteilung für einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder Streuungsmaße und auch Schätzintervalle - aus der Post-Verteilung herauslesen\nkünftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4.\n\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. “Geradenmodelle 1”\n\n\n\n9.1.5 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine Übersicht aller Funktionen des Pakets.1\n\n\n9.1.6 Benötigte Daten\nIn diesem Kapitel benötigen wir den Datensatz zu den !Kung-Leuten, Howell1a, McElreath (2020). Sie können ihn hier herunterladen.\n Download \n\n\nCode\n1Kung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\n2kung &lt;- read.csv(Kung_path)\n\n3kung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\n\n\n1\n\nPfad zum Datensatz; Sie müssen online sein, um die Daten herunterzuladen.\n\n2\n\nDaten einlesen\n\n3\n\nAuf Erwachsene Personen begrenzen (d.h. Alter &gt; 18)\n\n\n\n\n\n\n9.1.7 Einstieg\n\nBeispiel 9.1 (Grundkonzepte der linearen Regression) Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! \\(\\square\\)\n\n\nBeispiel 9.2 (Was ist eine Post-Verteilung und wozu ist sie gut?) Erklären Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. \\(\\square\\)\n\n\n\n9.1.8 Überblick\nDieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die Körpergröße auf das Gewicht zurückgeführt wird; also ein sehr eingängiges Modell.\nNeu ist dabei lediglich, dass die Parameter des Modells - \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) - jetzt über eine Post-Verteilung verfügen. Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik. Die “normale” Regression hat uns nur einzelne Werte für die Modellparameter geliefert (“Punktschätzer”). Mit Bayes haben wir eine ganz Verteilung pro Parameter.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "9  Einfache lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\nDie (einfache) Regression prüft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhängen. Je mehr sie zusammenhängen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). Hängen \\(X\\) und \\(Y\\) zusammen, heißt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).2\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X, UV) und Größe (Y, AV), Abbildung 9.1.\n\nCode\nkung_erwachsen %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\nCode\nggscatter(kung_erwachsen,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\") \n\n\n\n\n\n\nMit ggplot2Mit ggpubr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 9.1: Der Zusammenhang zwischen Gewicht (X) und Größe (Y)\n\n\n\n\n\n9.2.2 Statistiken zum !Kung-Datensatz\nDie Daten können Sie hier herunterladen.\nTabelle 9.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path &lt;- \"data/Howell1a.csv\"  \nkung &lt;- read_csv(Kung_path)  \n\nkung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelle 9.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus Tabelle 9.1 abzulesen ist, beträgt das mittlere Körpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n\n9.2.3 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n9.2.3.1 Gibt es fehlende Werte?\nNein, s. Abb. Abbildung 9.2.\n\n\nCode\nkung_erwachsen %&gt;% plot_missing()\n\n\n\n\n\n\n\n\nAbbildung 9.2: Fehlende Werte - fehlen.\n\n\n\n\n\n\n\n9.2.3.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. Abbildung 9.3.\n\n\nCode\nkung_erwachsen %&gt;% plot_histogram()\n\n\n\n\n\n\n\n\nAbbildung 9.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. Abbildung 9.4.\n\n\nCode\nkung_erwachsen %&gt;% plot_bar()\n\n\n\n\n\n\n\n\nAbbildung 9.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in Abbildung 9.5 dargestellt.\n\n\nCode\nkung_erwachsen %&gt;% plot_correlation()\n\n\n\n\n\n\n\n\nAbbildung 9.5: Korrelationsmatrix\n\n\n\n\n\n\nÜbungsaufgabe 9.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(kung_erwachsen). \\(\\square\\)\n\n\n\n\n9.2.4 Prädiktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Prädiktor “zentrieren”, engl. to center). Wenn man den Prädiktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\beta_0\\), einfacher zu verstehen. In einem Modell mit zentriertem Prädiktor (weight) gibt der Achsenabschnitt die Größe einer Person mit durchschnittlichem Gewicht an. Würde man weight nicht zentrieren, gibt der Achsenabschnitt die Größe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman et al. (2021), Kap. 10.4, 12.2.\nMan zentriert eine Variable \\(X\\), indem man von \\(x_i\\) den Mittelwert \\(\\bar{x}\\) abzieht: \\(x_i - \\bar{x}\\).\n\n\nCode\nkung_zentriert &lt;-\n  kung_erwachsen %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\nMit Hilfe von center() aus {easystats} kann man sich das Zentrieren auch erleichtern.\n\n\nCode\nkung_zentriert &lt;- \n  kung_erwachsen %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\n−9\n\n\n137\n32\n65\n0\n−13\n\n\n\n\n\n\n\nWie man sieht, wird die Verteilung von weight durch die Zentrierung “zur Seite geschoben”: Der Mittelwert von weight_c (das zentrierte Gewicht) liegt jetzt bei 0, s. Abbildung 9.6.\n\n\n\n\n\n\n\n\nAbbildung 9.6: Das Zentrieren ändert die Verteilungsform nicht, sondern “schiebt” die Verteilung nur zur Seite\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass kung_zentriert die Tabelle mit zentriertem Prädiktor ist, nicht kung_erwachsen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-prädiktor",
    "href": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-prädiktor",
    "title": "9  Einfache lineare Modelle",
    "section": "9.3 Modell m_kung_gewicht_c: zentrierter Prädiktor",
    "text": "9.3 Modell m_kung_gewicht_c: zentrierter Prädiktor\n📺 Prädiktoren zentrieren\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wäre wohl die Körpergröße? Hm, Philosophie steht heute nicht auf der Tagesordnung. Da wäre es schön, wenn wir die Daten so umformen könnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Glück geht das leicht: Wir zentrieren den Prädiktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m_kung_gewicht_c\nFür jede Ausprägung des Prädiktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung für die abhängige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) für jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte für die Steigung \\(\\beta_1\\) und den Achsenabschnitt \\(\\beta_0\\) der Regressionsgeraden. Außerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Größe (height) angibt; dieser Wert wird als exponentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\). Theorem 9.1 stellt die Modelldefinition dar. ?fig-kruschke_regr_one_predctor zeigt, wie die drei Parameter zusammen die Likelihood definieren.\n\n\nTheorem 9.1 (Modelldefinition m_kung_gewicht_c) \\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}{\\beta_0} & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}{\\beta_1}  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\quad \\square\\]\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnitt (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. 🤷\n\n\n\n\n9.3.2 Likelihood, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m_kung_gewicht_c ist ähnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines “Index-i” am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern für jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\n“Die Wahrscheinlichkeit, eine bestimmte Größe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))”.\n\n\n\n9.3.3 Regressionsformel, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschätzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\beta_0\\) und \\(\\beta_1\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der Prädiktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\n“Der Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\beta_0\\) und \\(\\beta_1\\) mal \\(\\text{weight}_i\\)”.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta_1\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\beta_0\\) gibt an, wie groß \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n9.3.4 Priori-Werte des Modells m_kung_gewicht_c\n\\[\\begin{align*}\n\\color{blue}\\beta_1 & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta_1  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen. \\(\\beta_0\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine “Regression ohne Prädiktoren” berechnet haben. \\(\\sigma\\) ist uns schon als Parameter bekannt und behält seine Bedeutung aus dem letzten Kapitel. Da height nicht zentriert ist, der Mittelwert von \\(\\beta_0\\) bei 178 und nicht 0. \\(\\beta_1\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Größe positiv (gleichsinnig) ist. Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.\n\n\n9.3.5 Prioris plus Daten gleich Post\n![Parameter ]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9  Einfache lineare Modelle",
    "section": "9.4 Die Post-Verteilung befragen",
    "text": "9.4 Die Post-Verteilung befragen\n📺 Post-Verteilung auslesen 1\n📺 Post-Verteilung auslesen 2\n\n9.4.1 m_kung_starkes_beta1\nSagen wir, auf Basis gut geprüfter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. Gleichung 9.1. Dabei haben wir folgende Prioris gewählt:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{9.1}\\]\nWir nennen das Modell m_kung_starkes_beta13, s. Listing 9.1.\n\n\n\nListing 9.1: Modelldefinition von m_kung_starkes_beta1 in R\n\n\n\n\nCode\nm_kung_starkes_beta1 &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # beta 0\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = kung_zentriert)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die Nachprüfbarkeit der Ergebnisse (“Reproduzierbarkeit”) sichergestellt4. Welche Wert für seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung schätzen.\n\n\n\n\n9.4.2 Mittelwerte von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. Tabelle 9.2.\n\n\n\nTabelle 9.2: Parameter von m_kung_starkes_beta1\n\n\n\nCode\nparameters(m_kung_starkes_beta1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 9.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also größer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) Ähnliches wie der p-Wert in der Frequentistischen Statistik (Makowski et al., 2019).\n\nAm besten das Diagramm dazu anschauen, s Abbildung 9.7.\n\n\nCode\nplot(p_direction(m_kung_starkes_beta1))\n\n\n\n\n\n\n\n\nAbbildung 9.7: Diagramm zur Probability of Direction, Modell m_kung_starkes_beta1\n\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) größer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschäftigen in diesem Kurs.\n\n\n9.4.3 Visualisieren der “mittleren” Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). Überzeugen wir uns mit einem Blick in die Post-Verteilung von m_kung_starkes_beta1:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n\n  \n\n\n\nWir können z.B. ein Lagemaß wie den Median hernehmen, um die “mittlere” Regressionsgerade zu betrachten, s. Abbildung 9.8.\n\nCode\nkung_zentriert %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") |&gt; plot()  # aus {easystats}\n\n\n\n\n\nMit ggplotMit easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. Abbildung 9.8 (a). Mit “expectation” sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\n\n\n\n\n\n\n(a) Erwartete Werte des Modell m_kung_starkes_beta1, sprich, die Regressionsgerade\n\n\n\n\n\n\n\n\n\n\nAbbildung 9.8\n\n\n\n\n\n9.4.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).5 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen können.\n\n9.4.4.1 Lagemaße zu den Parametern\n\nWas ist die mittlere Größe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Schätzwert für den Zusammenhang von Gewicht und Größe? (\\(\\beta_1\\))\nWas ist der Schätzwert für Ungewissheit in der Schätzung der Größe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert für z.B: \\(\\beta_1\\)?\n\nEine nützliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. Tabelle 9.2.\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m_kung_starkes_beta1, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm_kung_starkes_beta1_post &lt;- \n  m_kung_starkes_beta1 %&gt;% \n  as_tibble()\n\nm_kung_starkes_beta1_post %&gt;% \n  head()\n\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m_kung_starkes_beta1_post. Jetzt haben wir wieder eine schöne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen können. Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsmaße der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. Abbildung 9.9.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung 9.9: Die Postverteilung für den Parameter Gewicht (zentriert); die plausiblen Werte liegen zwischen 0.8 und 1.0 cm pro Kilogramm Gewicht\n\n\n\n\n\nAbbildung 9.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den häufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. Abbildung 9.10.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung 9.10: Die Post-Verteilung für den Parameter sigma, m_kung_starkes_beta1; die plausiblen Werte liegen zwischen 4.7 cm und 5.5 cm.\n\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. Abbildung 9.11.\n\n\nCode\nm_kung_starkes_beta1_hdi &lt;- hdi(m_kung_starkes_beta1_post)  # analog mit eti(m_kung_starkes_beta1)\n\nplot(m_kung_starkes_beta1_hdi)\n\n\n\n\n\n\n\n\nAbbildung 9.11: Die Parameter Gewicht (zentriert) und sigma des Modells m_kung_starkes_beta1\n\n\n\n\n\nErgänzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt. Den Parameter der Vorhersage-Genauigkeit, \\(\\sigma\\) bekommt man mit get_sigma:\n\n\nCode\nget_sigma(m_kung_starkes_beta1)\n## [1] 5.1\n## attr(,\"class\")\n## [1] \"insight_aux\" \"numeric\"\n\n\n\n\n\n9.4.5 Streuungsmaße zu den Parametern\n\nWie unsicher sind wir uns in den Schätzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebräuchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilität.\n\n\n\n\n9.4.6 Ungewissheit von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung visualisiert\nAbbildung 9.12 stellt die Ungewissheit der Post-Verteilung dar, in dem einige Stichproben aus der Post-Verteilung visualisiert werden.\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\n1010010001000000\n\n\nDie ersten 10 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 100 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 10000006 … okay, lassen wir es gut sein7.\n\n\n\n\n\nAbbildung 9.12\n\n\n\nEinfacher ist die Visualisierung mit estimate_expectation, s. Abbildung 9.13.\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildung 9.13: Schätzbereich für die bedingten mittleren Körpergröße, also die Regressionsgerade mit Unsicherheitsintervall\n\n\n\n\n\n\n\n9.4.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten Prädiktor misst der Achsenabschnitt die mittlere Größe8.\n\n\n\nWelche mittlere Größe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht überschritten?\nWelche mittlere Größe mit Wahrscheinlichkeit von 95% nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Schätzbereich der mittleren Größe?\n\nQuantile:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n  \n\n\n\n50%-PI:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  eti(ci = .5)\n\n\n\n  \n\n\n\n\n\n9.4.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Größe bei mind. 155 cm liegt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit beträgt 0.1.\nWie wahrscheinlich ist es, dass die mittlere Größe höchstens 154.5 cm beträgt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit beträgt 0.29.\n\n\n9.4.9 Typischer Bayes-Nutzer in Aktion\n\n\n\n\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prädiktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prädiktorwert",
    "title": "9  Einfache lineare Modelle",
    "section": "9.5 Post-Verteilung bedingt auf einen Prädiktorwert",
    "text": "9.5 Post-Verteilung bedingt auf einen Prädiktorwert\n\n9.5.1 Bei jedem Prädiktorwert eine Post-Verteilung für \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns für jeden beliebigen Wert des Prädiktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m_kung_post, s. Abbildung 9.14.\n\n\n\n\n\n\n\n\nAbbildung 9.14: Für jeden beliebigen Prädiktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgewählten Gewichtswerten. Es ist jeweils die Wahrscheinlichkeitsverteilung für den vorhergesagten Y-Wert dargestellt (hier sind die Verteilungen zu groß dargestellt zur besseren Sichtbarkeit). B: Für jeden beliebigen Gewichtswert (Y) bekommt man eine (auf den jeweiligen X-Wert bedingten) Post-Verteilung.\n\n\n\n\n\n\n\n9.5.2 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der Körpergröße bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche Körpergröße ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns über diesen Mittelwert?\nEtwas formaler ausgedrückt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Prädiktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 &lt;-\n  m_kung_gewicht_c_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. Abbildung 9.15.\n\n\nCode\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung 9.15: Post-Verteilung der Größe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\n\nAnalog können wir fragen, wie groß wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns über diesen Mittelwert sind.\n50 kg, das sind 5 über dem Mittelwert, in zentrierten Einheiten ausgedrückt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. Tabelle 9.3.\n\n\nCode\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\nTabelle 9.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren Größe bei einem Gewicht von 50kg ist weiter “rechts” (Richtung höhere Größe) zentriert, s. Abbildung 9.16.\n\n\nCode\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung 9.16: Post-Verteilung der mittleren Größe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n\n9.5.3 Lagemaße und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der Körpergröße.\nWas ist das 90% PI für \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %&gt;% \n  eti(ci = .9)\n\n\n\n  \n\n\n\nDie mittlere Größe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere Größe wird mit 95% Wahrscheinlichkeit nicht überschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#fazit",
    "href": "0900-lineare-modelle.html#fazit",
    "title": "9  Einfache lineare Modelle",
    "section": "9.6 Fazit",
    "text": "9.6 Fazit\n\n9.6.1 Ausstieg\n\nBeispiel 9.3 (Fassen Sie das Wesentliche zusammen!) Schreiben Sie 5-10 Sätze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! \\(\\square\\)\n\n\n\n9.6.2 Vertiefung\nMcElreath (2020) bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. Kurz (2021) greift die R-Inhalte von McElreath (2020) auf und setzt sie mit Tidyverse-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen möchte. Gelman et al. (2021) bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einer frequentistischen als auch aus einer Bayes-Perspektive.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "9  Einfache lineare Modelle",
    "section": "9.7 Aufgaben",
    "text": "9.7 Aufgaben\n\n9.7.1 Papier-und-Bleistift-Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nmtcars-post2a\nBed-Post-Wskt1\nmtcars-post3a \nregression1a\nregression1b\nRegression2\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\nLikelihood2\ninterpret-koeff\nbed-post-wskt1\n\n\n\n9.7.2 Computer-Aufgaben\n\nPost-befragen1\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-4",
    "href": "0900-lineare-modelle.html#section-4",
    "title": "9  Einfache lineare Modelle",
    "section": "9.8 —",
    "text": "9.8 —\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKurz, S. (2021). Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & Lüdecke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#footnotes",
    "href": "0900-lineare-modelle.html#footnotes",
    "title": "9  Einfache lineare Modelle",
    "section": "",
    "text": "Da es viele Funktionen sind, bietet es sich an mit Strg-F auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.↩︎\n Datenquelle, McElreath (2020).↩︎\nWer ist hier für die Namensgebung zuständig? Besoffen oder was?↩︎\noder zumindest besser sichergestellt↩︎\nIn manchen Lehrbüchern wird \\(\\beta_0\\) auch als \\(\\alpha\\) bezeichnet.↩︎\n1e6↩︎\nIm Standard beschert uns stan_glm() 4000 Stichproben.↩︎\n\\(\\mu\\)↩︎",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html",
    "href": "0800-gauss.html",
    "title": "8  Gauss-Modelle",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "8  Gauss-Modelle",
    "section": "",
    "text": "8.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nein Gaußmodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n8.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.1 bis 4.3.\n\n\n8.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. “Modellgüte”\nStatistik1, Kap. “Punktmodelle 2”\nStatistik1, Abschnitt “Normalverteilung”\n\n\n\n8.1.5 Benötigte R-Pakete\nFür rstanarm wird ggf. weitere Software benötigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, müssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio müssen Sie die (benötigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Modelle berechnen\nlibrary(easystats)  # Statistik-Komfort\nlibrary(DataExplorer)  # Daten verbildlichen\nlibrary(ggpubr)  # Daten verbildlichen\nlibrary(hexbin)  # stat_bin_hex ggplot2\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nAb diesem Kapitel benötigen Sie das R-Paket rstanarm. \\(\\square\\)\n\n\n\n\n8.1.6 Benötigte Daten\nWir benötigen den Datensatz !Kung. Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\n\n\nCode\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nkung &lt;- read.csv(Kung_path) \n\nhead(kung)\n\n\n\n  \n\n\n\nDatenquelle\n Download \n\n\n8.1.7 Einstieg\n\nBeispiel 8.1 (Was war noch mal eine Normalverteilung?) In diesem Kapitel benötigen Sie ein gutes Verständnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! \\(\\square\\)\n\n\nBeispiel 8.2 (Was war noch mal eine Posteriori-Verteilung?) In diesem Kapitel befragen wir die Post-Verteilung für ein normalverteilte Zufallsvariable, nämlich die Körpergröße der !Kung San. Was war noch mal eine Post-Verteilung und wozu ist sie gut? \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-groß-sind-die-kung-san",
    "href": "0800-gauss.html#wie-groß-sind-die-kung-san",
    "title": "8  Gauss-Modelle",
    "section": "8.2 Wie groß sind die !Kung San?",
    "text": "8.2 Wie groß sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. ?fig-kungs.\n\nThe ǃKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names ǃKung (ǃXun) and Ju are variant words for ‘people’, preferred by different ǃKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of ǃKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\nWir interessieren uns für die Größe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als kung_erwachsen.\n\n\nCode\nkung_erwachsen &lt;- kung %&gt;% \n  filter(age &gt;= 18)\n\nnrow(kung_erwachsen)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tatsächlich recht easy, s. Tabelle 8.1.\n\n\nCode\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelle 8.1: Statistiken der metrischen Variablen im Kung-Datensatz\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\n−0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\n−0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\n−0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\n−2.00\n352.00\n0\n\n\n\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus {DataExplorer}), s. Abbildung 8.1.\n\n\nCode\nplot_density(kung_erwachsen)\n\n\n\n\n\n\n\n\nAbbildung 8.1: Verteilungen der Variablen im Kung-Datensatz. Größe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n\n\n\n8.2.2 Wir gehen apriori von normalverteilter Größe Der !Kung aus\nForschungsfrage: Wie groß sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also für den Mittelwert der Körpergröße (erwachsene Person1), \\(\\mu\\).\n\n\n\nMensch, Wikimedia Commons2\n\n\nWir sind uns über diesen Mittelwert in der Population nicht sicher3, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178 cm und Streuung von 20 cm, s. Gleichung 8.1.\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{8.1}\\]\nGleichung 8.1 definiert ein Modell: Unsere Vorstellung der mittleren (“typischen”) Körpergröße der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.4 In einer echten Untersuchung sollte man einen inhaltlichen Grund für einen Priori-Wert haben. Oder man wählt “schwach informative” Prioris, wie das {rstanarm} tut: Damit lässt man kaum Vorab-Information in das Modell einfließen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern bei der Körpergröße).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der Körpergrößen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. Darüber hinaus ist eine Normalverteilung nicht unplausibel.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "8  Gauss-Modelle",
    "section": "8.3 Unser Gauss-Modell der !Kung",
    "text": "8.3 Unser Gauss-Modell der !Kung\n📺 Teil 1\n\n8.3.1 Modelldefinition\nWir nehmen an, dass die mittleren Größen, \\(\\mu\\), und die tatsächlichen Größen, \\(h_i\\), normalverteilt sind und \\(\\sigma\\) exponentialverteilt ist (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior für den Parameter \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior für den Parameter \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn Abbildung 8.2 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\n\n\n\n\n\n\n(a) Priori der mittleren Körpergröße\n\n\n\n\n\n\n\n\n\n\n\n(b) Priori der Schätzungenauigkeit\n\n\n\n\n\n\nAbbildung 8.2: Prioris unseres (ersten) Kung-Modells (m_kung)\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDieses Modell hat zwei Parameter, \\(\\mu\\) und \\(\\sigma\\). \\(\\square\\)\n\n\n\n\n8.3.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie Körpergrößen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})   \\qquad{\\text{Likelihood}}\\]\n\n\n8.3.3 Prioris der Parameter\nDer Mittelwert der Körpergröße sei normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)} \\qquad{\\text{Prior}}\\]\nDie Streuung \\(\\sigma\\) der Größen sei exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)} \\qquad{\\text{Prior}}\\]\n\n\n8.3.4 m_kung: fertig!\nJetzt haben wir unser Modell (m_kung) definiert!\nWeil es so schön ist, schreiben/zeichnen wir es hier noch einmal auf, Gleichung 8.2, Abbildung 8.3.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) & \\text{Likelihood}  \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) & \\text{Prior} \\\\\n\\sigma &\\sim \\mathcal{E}(1/8) & \\text{Prior}\n\\end{aligned}\n\\tag{8.2}\\]\n\n\n\n\n\n\nAbbildung 8.3: Modellschema für das Modell m_kung\n\n\n\nZur Berechnung von m_kung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich kräftig der Bursche, der soll die Arbeit für uns tun. Der Golem hört auf den Namen rstanarm5.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#zufällige-motivationsabschnitt",
    "href": "0800-gauss.html#zufällige-motivationsabschnitt",
    "title": "8  Gauss-Modelle",
    "section": "8.4 Zufällige Motivationsabschnitt",
    "text": "8.4 Zufällige Motivationsabschnitt\n\n\n\nGut gemacht!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-größen-modells-m_kung",
    "href": "0800-gauss.html#posteriori-verteilung-des-größen-modells-m_kung",
    "title": "8  Gauss-Modelle",
    "section": "8.5 Posteriori-Verteilung des Größen-Modells, m_kung",
    "text": "8.5 Posteriori-Verteilung des Größen-Modells, m_kung\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m_kung6.\n\n\nCode\n1m_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)\n2m41_post &lt;- as_tibble(m_kung)\n3names(m41_post) &lt;- c(\"mu\", \"sigma\")\n\n\n\n1\n\nBayes-Regressionsmodell berechnen\n\n2\n\nModellergebnis in Tabelle umwandeln\n\n3\n\nSchönere Namen für die Spalten geben\n\n\n\n\nDas Argument refresh = 0 ist nur eine Nebensache, aber es ist praktisch, da es verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrücke. stan_glm7 ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein “richtiges” Regressionsmodell. Man könnte sagen, wir haben eine AV (Körpergröße), aber keine UV (keine Prädiktoren). Glücklicherweise können wir auch solche “armen” Regressionsmodelle formulieren: av ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen möchte, aber keine Prädiktoren hat (das soll die 1 symbolisieren). Für das Modell m_kung haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung (defaults) der Prioris von rstanarm zurück. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wäre, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die gemeinsame Posteriori-Verteilung von m_kung, s. Abbildung 8.4\n\nFliesendiagrammStreudiagrammHistogramm\n\n\nGemeinsame Post-Verteilung von Mittelwert und Streuung\n\n\nCode\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\n\n\n\nAbbildung 8.4: Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m_kung_neue_prioris\n\n\n\n\n\nDa das Modell zwei Parameter hat, können wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen können die Parameter korreliert sein.\nAbbildung 8.4 erlaubt uns, für jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\n\n\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m_kung_neue_prioris, s. Abbildung 8.5.\n\n\n\n\n\n\n\n\nAbbildung 8.5: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\n\n\n\nUnd hier kommt die Post-Verteilung nur des Mittelwerts.\nNatürlich können wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. Abbildung 8.6.\n\n\n\n\n\n\n\n\nAbbildung 8.6: Die Post-Verteilung von mu in m_kung_neue_prioris; ein Balkendiagramm bietet sich an.\n\n\n\n\n\n\n\n\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung für \\(\\mu\\) und eine für \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, für die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte für \\(\\mu\\) und \\(\\sigma\\) klein: Die große Stichprobe hat die Priori-Werte überstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so können wir interessante Fragen stellen.\n\n\n8.5.1 Hallo, Posteriori-Verteilung\n… wir hätten da mal ein paar Fragen an Sie. 🕵\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person größer als 1,55m?\nWelche mittlere Körpergröße wird mit 95% Wahrscheinlichkeit nicht überschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die Schätzung der mittleren Körpergröße behaftet?\nWas ist der mediane Schätzwert der mittleren Körpergröße, sozusagen der “Best Guess”?\n\nAntworten folgen etwas weiter unten.\nAbschließend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), Abbildung 8.7.\n\n\n\n\n\n\n\n\nAbbildung 8.7: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen für mu und für sigma\n\n\n\n\n\n\n\n8.5.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() können wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - ähnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurück.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so: stan_glm(AV ~ UV, data = meine_daten).\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum Größenmittelwert (von Stan übernommen)\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der Größen (von Stan übernommen)\n\n\n8.5.3 Ausgabe von stan_glm()\nWir können, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir können es aber auch komfortabler haben … Mit dem Befehl parameters kann man sich die geschätzten Parameterwerte einfach ausgeben lassen (s. Abbildung 8.4).\n\n\nCode\nm_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)  # aus Paket rstanarm\n\nparameters(m_kung)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem schätzt den Größenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.76 bis 155.41 schätzt. Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu später mehr.\n\n\n\n\n\n\nHinweis\n\n\n\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren 🤓 Wer Näheres wissen will, findet hier einen Anfang. Außerdem sei an McElreath (2020) und Gelman et al. (2021) verwiesen. \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "8  Gauss-Modelle",
    "section": "8.6 Wie tickt stan_glm()?",
    "text": "8.6 Wie tickt stan_glm()?\n\n\n Quelle\n\nHier ein paar Kerninfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan für uns bereit.\nstan_glm() ist für die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schätzen, so hat man man … eine Regression ohne Prädiktor.\nEine Regression ohne Prädiktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also für die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\n\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n8.6.1 Schätzwerte zu den Modellparameter\nDie Parameter eines Modells sind die Größen, für die wir eine Priori-Verteilung annehmen. Außerdem wählen wir einen einen Likelihood-Funktion, so dass wir die Likelihood berechnen können. Auf dieser Basis schätzen wir dann die Post-Verteilung. Ich sage schätzen, um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren Schätzungen) einfach mit parameters(modellname) auslesen.\n\n\n8.6.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, können wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_kung:\n\n\nCode\npost_kung &lt;- as_tibble(m_kung)\nhead(post_kung)\n\n\n\n  \n\n\n\nIn einer Regression ohne Prädiktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss über unsere Schätzwerte zu \\(\\mu\\) (der Körpergröße).\n\nÜbungsaufgabe 8.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\n\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prägnanter\n\npost_kung %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschließen, dass die Kung im Schnitt größer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. \\(\\square\\)\n\n\n\n\n\nÜbungsaufgabe 8.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prägnanter\n\npost_kung %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nOh, diese Hypothese können wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschließen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschließen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\n\n\nBeispiel 8.3 (Welche mittlere Körpergröße wird mit 95% Wahrscheinlichkeit nicht überschritten, laut dem Modell m_kung?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n  \n\n\n\n\n\n\n\n\nÜbungsaufgabe 8.3 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  eti()\n\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\n\n\n\nÜbungsaufgabe 8.4 (Mit welcher Unsicherheit ist die Schätzung der mittleren Körpergröße behaftet?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nm_kung %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nSeeing is believing, s. Abbildung 8.8.\n\n\nCode\nm_kung %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nAbbildung 8.8: Parameter von m_kung, nur einer: der Intercept\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren Körpergröße liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\n\n\n\nÜbungsaufgabe 8.5 (Was ist der mediane Schätzwert der mittleren Körpergröße, sozusagen der “Best Guess”?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\nparameters(m_kung) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n\n\n\n🏋️ Ähnliche Fragen bleiben als Übung für die Lesis. 🤓\n\n\n8.6.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt für uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m_kung)\n## Priors for model 'm_kung' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden dafür die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage für die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht “pures Bayes”, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte wären auch denkbar.\n\n\n\n\n\n\nStandardwerte von stan_glm\n\n\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (für \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals “Streuung”, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen. \\(\\square\\)\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wählen, dass man nicht übergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschließen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einfließen zu lassen und eigene Entscheidungen zu begründen. Häufig sind mehrere Entscheidungen möglich. Möchte man lieber vorsichtig sein, weil man wenig über den Gegenstand weiß, dann könnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die “schwachinformativ” ist, also nur wenig Priori-Information in das Modell einfließen lässt.\n\n\n\n\n8.6.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund für Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu zählen hat. Außerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister prüfen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier Durchführungen (auch “Ketten” engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist “dumm gelaufen”. An dieser Stelle schauen wir uns die Ketten nicht näher an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. Möchte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit, s. m_kung_1kette.\n\n\nCode\nm_kung_1kette &lt;- stan_glm(height ~ 1, \n                 data = kung_erwachsen, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m_kung_1kette)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "title": "8  Gauss-Modelle",
    "section": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte",
    "text": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte\n📺 Teil 2\nIm Modell m_kung haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einfließen, in unserem zweiten Kung-Modell, m_kung_neue_prioris.\n\n8.7.1 m_kung_neue_prioris\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.8 Dieses Mal geben wir die Priori-Werte explizit an, Tabelle 8.2.\n\n\nCode\nm_kung_neue_prioris &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = kung_erwachsen)\nparameters(m_kung_neue_prioris)\n\n\n\n\n\n\nTabelle 8.2: Parameter von m_kung_neue_prioris mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482\nNormal (178 +- 20)\n\n\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in Tabelle 8.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige Fähigkeit im Studium. 🤓\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m_kung und m_kung_neue_prioris! Was fällt Ihnen auf? Nichts? Gut! Tatsächlich liefern beide Modelle sehr ähnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigermaßen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gewählt waren.\n\n\n\n\n8.7.2 Posteriori-Verteilung und Parameter plotten\nLeider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zurück.\n\n👨‍🏫 Böser Golem!\n\n\n🤖 Beim nächsten Mal strenge ich mich mehr an!\n\nDaher müssen wir die Ausgabe des Stan-Golemns erst in eine schöne Tabelle umwandeln:\n\n\nCode\nm_kung_neue_prioris_tibble &lt;-\n  as_tibble(m_kung_neue_prioris)\n\nhead(m_kung_neue_prioris_tibble)\n\n\n\n  \n\n\n\nAußerdem ist der Name der ersten Spalte eigentlich unzulässig, da Spaltennamen in R nicht mit Sonderzeichen anfangen dürfen (sondern mit Buchstaben). Daher müssen wir den Namen mit “Samthandschuhen” anpacken. Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln müssen, s. die folgende Syntax.\n\nMit {ggpubr}Mit {ggplot}\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  gghistogram(x = \"`(Intercept)`\")  # Aus dem Paket \"ggpubr\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nAls Ausblick: Ein Vergleich mehrerer Priori-Werte wäre auch nützlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewählten Priori-Werte zu überzeugen.\n\n\n8.7.3 Welche Körpergrößen erwartet unser Modell\nBisher haben wir untersucht, wie die Verteilung der mittleren Körpergrößen, \\(\\mu\\), laut unserem Modell aussehen könnte; wir haben uns also mit der Post-Verteilung von \\(\\mu\\) beschäftigt. Wir könnten aber auch an der Frage der Verteilung der tatsächlichen Körpergrößen, \\(h_i\\), laut Modell, interessiert sein: Wie groß sind sie denn, die !Kung, laut unserem Modell?\nWie wir wissen, liefert unser Stan-Golem eine Stichproben-Postverteilung. Wenn wir das Ergebnisobjekt unserer Analyse, m_kung in eine Tabelle (Tibble) umwandeln und (die ersten paar Zeilen) betrachen, sehen wir diese Stichproben:\n\n\nCode\nm_kung |&gt; as_tibble() |&gt; head()\n\n\n\n  \n\n\n\nLaut unserem Modell sind die Körpergrößen, \\(h_i\\), normalverteilt mit \\(\\mu\\) und \\(\\sigma\\). \\(\\mu\\) wird von Stan, der in Begriffen der Regressionsanalyse denkt, schnöde als (Intercept) bezeichnet. Wir könnten jetzt also für jede Zeile eine Normalverteilung berechnen. Und daraus zufällig eine Zahl ziehen. Damit hätten wir dann unsere Verteilung von Körpergrößen laut Modell. Diese Verteilung nennt man auch Posterior-Prädiktiv-Verteilung. Prädiktiv daher, weil sie die Werte der Körpergrößen “vorhersagt”.\nWir können uns diese Verteilung auch komfortabel von R ausgeben lassen, s. Abbildung 8.9.\n\nCode\npp_check(m_kung)\npp_check(m_kung, \"stat\")\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Die dunkle, dicke Dichtekurve zeigt die tatsächliche Verteilung der Körpergrößen im Datensatz. Die hellen, leichten Dichtekurven zeigen die Verteilungen laut der Post-Verteilung unseres Modells.\n\n\n\n\n\n\n\n\n\n\n\n(b) Der wahre Wert einer Test-Statistik (T), hier der Mittelwert der Körpergrößen, wird mit der Verteilung der Körpergrößen in Bezug gesetzt.\n\n\n\n\n\n\n\nAbbildung 8.9: Die Posterior-Prädiktiv-Verteilung: Die Verteilung der tatsächlichen Körpergrößen auf Basis der Post-Verteilung. Unser Modell stellt die tatsächliche Verteilung ganz gut nach.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "8  Gauss-Modelle",
    "section": "8.8 Fazit",
    "text": "8.8 Fazit\n\n\n8.8.1 Zusammenfassung\nWir haben die Posteriori-Verteilung für ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Prädiktoren, betrachtet. Die Zielvariable, Körpergröße (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. Für \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung für \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n8.8.2 Botschaft von einem Statistiker\n\n\n\n🧡 Bleiben Sie dran!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schlüssel zum Erfolg.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "href": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "title": "8  Gauss-Modelle",
    "section": "8.9 Vertiefung: Wahl der Priori-Werte",
    "text": "8.9 Vertiefung: Wahl der Priori-Werte\n🏎️ Dieser Abschnitt ist eine VERTIEFUNG und nicht prüfungsrelevant. 🏎\n\n8.9.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\n\n💭 Was denkt der Golem (m_kung) apriori von der Größe der !Kung?\n🦾 Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voilà:\n\n\nCode\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MW±3SD\",\n       x = \"Größe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\n\n\n\n\nQuellcode\n\n\n8.9.2 Priori-Werte prüfen mit der Priori-Prädiktiv-Verteilung\n\nDie Priori-Prädiktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo können wir prüfen, ob die Priori-Werte vernünftig sind.\n\nDie Priori-Prädiktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Größenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\n\nCode\nanteil_großer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_großer_kung\n\n\n\n  \n\n\n\n🤔 Sehr große Buschleute? 17 Prozent sind größer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsläufig ein schlechter Prior sein.\n\n\n8.9.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n\n\n\n\n8.9.4 Extrem vage Priori-Verteilung für die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\n\n\n\n\nDie Streuung der Größen ist weit:\n\n\nCode\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n🤔 Das Modell geht apriori von ein paar Prozent Menschen mit negativer Größe aus. Ein Haufen Riesen 👹 werden auch erwartet.\n🤯 Vage (flache, informationslose, “neutrale”, “objektive”) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "8  Gauss-Modelle",
    "section": "8.10 Aufgaben",
    "text": "8.10 Aufgaben\n\n8.10.1 Papier-und-Bleistift-Aufgaben\n\n\nexp-tab\nexp-tab2\nnorms-sd\nsmall-wide-normal\nexp1\ndistros\nmtcars-post_paper\ngroesse03\npupil-size2\ngroesse04\nReThink4e2\nPriorwahl1\n\n\n\n8.10.2 Aufgaben, für die man einen Computer benötigt\n\nstan_glm01\nReThink4e1\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "8  Gauss-Modelle",
    "section": "8.11 —",
    "text": "8.11 —\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#footnotes",
    "href": "0800-gauss.html#footnotes",
    "title": "8  Gauss-Modelle",
    "section": "",
    "text": "Der Einfachheit halber gehen wir davon aus, dass Männer und Frauen im Schnitt gleich groß sind.↩︎\nBildquelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, 3.0↩︎\nDarum machen wir hier ja die ganz Show!↩︎\nDer Autor des zugrundeliegenden Lehrbuchs, Richard McElreath, gibt 178cm als seine Körpergröße an.↩︎\nHey, ich habe ihn diesen Namen nicht gegeben.↩︎\nm wie Modell und 4, weil das Modell in Kapitel 4 von McElreath (2020) in ähnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.↩︎\naus dem R-Paket rstanam, das zuvor installiert und gestartet sein muss, bevor Sie den Befehl nutzen können↩︎\nHey Stan, los, an die Arbeit!↩︎",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html",
    "href": "1050-Schaetzen-Testen.html",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "",
    "text": "10.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können…\n\nden Unterschied zwischen dem Schätzen von Modellparametern und dem Testen von Hypothesen erläutern\nVor- und Nachteile des Schätzens und Testens diskutieren\nDas ROPE-Konzept erläutern und anwenden\nDie Güte von Regressionsmodellen einschätzen und berechnen\n\n10.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an Kruschke (2018).\n\n10.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. “Geradenmodelle 2”\n\n10.1.5 R-Pakete\nIn diesem Kapitel werden die üblichen R-Pakete benötigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n10.1.6 Benötigte Daten: Pinguine\nWir benötigen in diesem Kapitel den Datensatz zu Pinguinen: penguins.\nSie können den Datensatz penguins entweder via dem Pfad importieren.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \nOder via dem zugehörigen R-Paket.\n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\nBeide Möglichkeit sind okay.\n\n10.1.7 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\n“Lernen für die Klausur bringt etwas!”\n“Wie viel bringt Lernen für die Klausur?”\n\n\nBeispiel 10.1 Diskutieren Sie die epistemologische Ausrichtung sowie mögliches Für und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#schätzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#schätzen-oder-testen",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "\n10.2 Schätzen oder Testen?",
    "text": "10.2 Schätzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen testen: “Die Daten widerlegen die Hypothese (nicht)”\n\nParameter schätzen: “Der Effekt von X auf Y liegt zwischen A und B”.\n\n\n10.2.1 Hypothesen testen\nHypothesen testende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann natürlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 10.2 (“Lernen erhöht den Prüfungserfolg”) Die Hypothese Lernen erhöht den Prüfungserfolg kann durch eine Studie und eine entsprechende Analyse grundsätzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts für den Klausurerfolg. 2) Die Daten unterstützen die Hypothese: Lernen erhöht den Prüfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Prüfungserfolg möglich. \\(\\square\\)\n\nDas Testen einer Hypothese kann zu drei Arten von Ergebnissen führen. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\n🟥 Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubwürdigkeit der Hypothese gelitten.\n🟢 Die Daten unterstützen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubwürdigkeit gewonnen.\n❓ Die Datenlage ist unklar; zum Teil unterstützen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schlüsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen prüfen ist binär in dem Sinne, dass sie zu “Schwarz-Weiß-Ergebnissen” führen (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine gängige Variante des Hypothesen testen1 ist das Testen der Hypothese “kein Effekt” (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n10.2.2 Beispiele für Nullhypothesen\n\n“Lernen bringt nichts”\n“Frauen und Männer parken gleich schnell ein”\n“Es gibt keinen Zusammenhang von Babies und Störchen”\n“Früher war es auch nicht besser (sondern gleich gut)”\n“Bei Frauen ist der Anteil, derer, die Statistik mögen gleich hoch wie bei Männern” (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterstützen kann, da es die Komplexität reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht bestätigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht bestätigen (verifizieren) kann, hat großen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausgeübt (Popper, 2013). Schlagend ist das Beispiel zur Hypothese “Alle Schwäne sind weiß”. Auch eine große Stichprobe an weißen Schwänen kann die Wahrheit der Hypothese nicht beweisen. Schließlich ist es möglich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben. 2 Umgekehrt reicht die (zuverlässige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im bestätigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverlässiger, repräsentativer Daten erscheint plausibel, dass Hypothesen sowohl bestätigt als auch widerlegt werden können (Kruschke, 2018; Morey & Rouder, 2011). \\(\\square\\)\n\n\n\n10.2.3 Parameter schätzen\nBeim Parameter schätzen untersucht man, wie groß ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein “ja/nein”, was beim Hypothesen testen der Fall ist.\nBeim Parameter schätzen gibt es zwei Varianten:\n\n⚫️ Punktschätzung: Das Schätzen eines einzelnen Parameterwerts, sozusagen ein “Best Guess”\n📏 Bereichsschätzung: Das Schätzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Schätzen von Parameterns auch wie einen Hypothesentest verstehen: Ist ein bestimmter Wert, etwa die Null, nicht im Schätzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 10.3 Wie groß ist der Schätzbereich für den Effekt des Parameter “Geschlecht” auf das Gewicht von Pinguinen? Anders gefragt: Um welchen Wert sind männliche Tiere im Schnitt schwerer als weibliche Tiere?\n\nCodedata(penguins, package = \"palmerpenguins\")\npenguins_nona &lt;-\n  penguins |&gt; drop_na(sex, body_mass_g)  # keine fehlenden Werte\n\nm_penguins_sex &lt;- \n  stan_glm(body_mass_g ~ sex, data = penguins_nona)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3862.94\n(3757.82, 3969.47)\n100%\n1.000\n4246\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n682.94\n(528.12, 833.63)\n100%\n1.000\n4468\nNormal (0.00 +- 4020.19)\n\n\n\n\n\nGrob gesagt sind männliche Tiere ca. 500 g bis 800 g schwerer als weibliche Tiere im Schnitt, laut unserem Modell. \\(\\square\\)\n\n\nBeispiel 10.4 (Parameterschätzen als Nullhypothesentest)  \n\nForschungsfrage: Sind männliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nTheorem 10.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\nTheorem 10.1 (Nullhypothesentest) \\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0\\quad \\square\\]\n\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nCodem1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\n\nDann zählen wir einfach den Anteil der Stichproben in der Post-Verteilung für die UV sexmale, die einen Wert größer Null aufweisen:\n\nCodem1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert größer Null für sexmale, dass also weibliche Tiere leichter bzw. männliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der für das Gegenteil spricht (das weibliche Tiere schwerer wären). Damit resümieren wir, dass unser Modell 100% Wahrscheinlichkeit für die Hypothese einräumt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der Parameterschätzung ist die Nuanciertheit des Ergebnisses, die der Komplexität echter Systeme besser Rechnung trägt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "\n10.3 ROPE: Bereich von “praktisch Null”",
    "text": "10.3 ROPE: Bereich von “praktisch Null”\n📺 Teil 2\nNullhypothesen sind fast immer falsch, s. Abbildung 10.1.\n\n\n\n\n\n\n\nAbbildung 10.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman et al., 2021)\n\n\n10.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest möglich ist.3\nEin anderer Grund ist vermutlich, … wir haben es schon immer so gemacht. 🤷‍♀️\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke, 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n10.3.2 “Praktisch” kein Unterschied: Das Rope-Konzept\n📺 ROPE-Video\n\nBeispiel 10.5 (Beispiele für ROPE) Sagen wir, wenn sich zwei Preismittelwerte um höchstens \\(d=100\\)€ unterscheiden, gilt dieser Unterschied für uns als “praktisch gleich”, “praktisch kein Unterschied” bzw. vernachlässigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g “vernachlässigbar wenig” ist.\nEine findige Geschäftsfrau entscheidet für ihre Firma, dass ein Umsatzunterschied von 100k Euro “praktisch irrelevant” sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese (bzw. “Praktisch-Null-Hypothese”): \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Überlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Äquivalenzzone, Bereich eines vernachlässigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prüfen wir, ob ein “Großteil” der Posteriori-Stichproben im Rope liegt. Unter “Großteil” wird häufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroßteil liegt innerhalb von Rope \\(\\rightarrow\\) Annahme der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\n\nGroßteil liegt außerhalb von Rope \\(\\rightarrow\\) Ablehnung der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\n\nAnsonsten \\(\\rightarrow\\) keine Entscheidung\n\nMit “Großteil” meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n10.3.3 Vernachlässigbarer Regressionseffekt\nKruschke (2018) schlägt vor, einen Regressionskoeffizienten unter folgenden Umständen als “praktisch Null” zu bezeichnen:\nWenn eine Veränderung über “praktisch den ganzen Wertebereich” von \\(x\\) nur einen vernachlässigbaren Effekt auf \\(y\\) hat. Ein vernachlässigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der “praktisch ganze Wertebereich” von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Veränderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlässigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) für z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die Größe des ROPE ±5% der SD der AV. \\(\\square\\)\n\n\n\n10.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildung 10.2: Die Entscheidungsregeln zum ROPE illustiert (Kruschke, 2018).\n\n\n\n\nAbbildung 10.2 illustriert die Entscheidungsregel zum ROPE für mehrere Situationen (Kruschke, 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett außerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung möglich; die Datenlage ist unklar.\n\n10.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erklärt (m_penguins_species).\n\nCodem_penguins_species &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\n\nDen Rope berechnet man mit rope(model).\n\nCoderope(m_penguins_species)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen beträchtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir können daher für diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschließende Entscheidung über die Hypothese möglich.\nAber: Gentoo liegt zu 0% im Rope. Für Gentoo können wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas hört sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. 🎨\n\n10.3.6 Visualisierung unserer Rope-Werte, m_penguins_species\nEin Großteil der Posteriori-Masse von m_penguins_species liegt nicht innerhalb des Rope. Aber können wir umgekehrt sagen, dass ein Großteil außerhalb liegt? Das erkennt man optisch ganz gut, s. Abbildung 10.3.\n\nCoderope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\nAbbildung 10.3: Rope und HDI überlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die “Berge” der Posteriori-Verteilung für Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir können das Nullhypothese für Chinstrap nicht verwerfen, aber auch nicht bestätigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom “blauen Fluss” des Rope: Gentoo liegt außerhalb des Rope. Es gibt einen “substanziellen” Unterschied, größer als das ROPE. Wir verwerfen die “Praktisch-Null-Hypothese” in diesem Fall.\n\n10.3.7 Finetuning des Rope\nWir können festlegen, was wir unter “praktischer Äquivalenz” verstehen, also die Grenzen des Ropes verändern. Sagen wir, 100 Gramm sind unsere Grenze für einen vernachlässigbaren Effekt, s. Abbildung 10.4.\n\nCoderope(m_penguins_species, range = c(-100, 100))\nplot(rope(m_penguins_species, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 10.4: ROPE mit selber eingestellter Grenze von ±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so ändern, wenn man möchte:\n\nCoderope(m_penguins_species, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht für ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n10.3.8 Beantwortung der Forschungsfrage\nFür die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. Für Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs möglich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellgüte",
    "href": "1050-Schaetzen-Testen.html#modellgüte",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "\n10.4 Modellgüte",
    "text": "10.4 Modellgüte\n\n10.4.1 Wozu Modellgüte?\nHat man ein Modell aufgestellt und geprüft und Ergebnisse erhalten, möchte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellgüte. Diese Kennwerte zielen z.B. darauf ab, wie präzise die Aussagen des Modells sind. Je präziser die Aussagen eines Modells, desto nützlicher ist es natürlich. Bei einer Parameterschätzung erhält man auch Informationen zur Präzision der Schätzung: Ist der Schätzbereich schmal, so ist die Schätzung präzise (und vice versa). Allerdings könnte ein Modell aus mehreren Parameterschätzungen bestehen, die unterschiedlich präzise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur Präzision, oder allgemeiner zur Güte des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebräuchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n10.4.2 Modellgüte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklärt. - Höhere Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklärt. \\(R^2\\) wird normalerweise auf Basis eines Punktschätzers definiert. Solch eine Definition lässt aber viel Information - über die Ungewissheit der Schätzung - außen vor. Daher ist es wünschenswert, diese Information in \\(R^2\\) einfließen zu lassen: Bayes-R-Quadrat.\nMöchte man es ausführlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R^22\\) ausgeben lassen, s. Abbildung 10.5.\n\nCodem_penguins_species_r2 &lt;-\n  m_penguins_species %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m_penguins_species_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung 10.5: Die Verteilung von R-Quadrat im Modell m_penguins_species\n\n\n\n\n\\(R^2\\) und \\(\\sigma\\) sind negativ assoziert: In einem Datensatz mit mit hohem \\(R^2\\) ist \\(\\sigma\\) gering und umgekehrt. Beide Koeffizienten berechen sich auf Basis der Vorhersagefehler.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "\n10.5 Fazit",
    "text": "10.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorzüge der Parameterschätzung. Möchte man aber, um sich bestimmter bestehender Forschung anzunähern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "\n10.6 Aufgaben",
    "text": "10.6 Aufgaben\n\n10.6.1 Papier-und-Bleistift-Aufgaben\n\nrope-luecke\npenguins-rope\nWskt-Schluckspecht2\npenguins-stan-01a\nrope-regr\nrope1\nrope2a\nrope3a\npenguins-stan-04a\nstan_glm01a\npenguins-regr02a\npenguins-stan-02a\npenguins-stan-05a\n\n10.6.2 Computer-Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope2\nrope3\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter Values in Bayesian Estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270–280. https://doi.org/10.1177/2515245918771304\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes Factor Approaches for Testing Interval Null Hypotheses. Psychological Methods, 16(4), 406–419. https://doi.org/10.1037/a0024377\n\n\nPopper, K. (2013). Logik Der Forschung (H. Keuth, Hrsg.). Akademie Verlag. https://doi.org/10.1524/9783050063782",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#footnotes",
    "href": "1050-Schaetzen-Testen.html#footnotes",
    "title": "\n10  Schätzen vs. Testen\n",
    "section": "",
    "text": "vor allem in der Frequentistischen Statistik↩︎\nTatsächlich gibt es schwarze Schwäne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan↩︎\nMittlerweile gibt es neue Frequentistische Ansätze für ein Verfahren ähnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.↩︎\n89 ist die nächst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert für Schätzbereiche verwendet. Damit ist 95 hier eine “magic number”, ein Defacto-Standard ohne hinreichende Begründung. Um darauf hinzuweisen, benutzen einige Forschis mit ähem subtilen Humor lieber die 89 als die 95. 🤷‍♂️ ↩︎",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html",
    "href": "1000-metrische-AV.html",
    "title": "\n11  Fallbeispiele\n",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n11  Fallbeispiele\n",
    "section": "",
    "text": "11.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können…\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme übersetzen\ntypische Forschungsfragen auswerten\n\n11.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman et al. (2021), Kap. 7 und 10.\n\n11.1.4 Vorbereitung im Eigenstudium\nFrischen Sie Ihr Wissen in den Grundlagen der einfachen und multiplen Regression (inkl. Interaktionseffekte) auf. Dazu sind z.B. folgende Literaturstellen geeignet.\n\nStatistik1, Kap. “Geradenmodelle 1”\nStatistik1, Kap. “Geradenmodelle 2”\n\n11.1.5 R-Pakete\nIn diesem Kapitel werden die üblichen R-Pakete benötigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n11.1.6 Benötigte Daten\nWir benötigen in diesem Kapitel folgende Datensätze: kidiq, penguins.\n\n11.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\nCodedata(\"kidiq\", package = \"rstanarm\")\n\n\nAlternativ können Sie die Daten hier herunterladen.\n Download \n\n11.1.6.2 penguins\n\nSie können den Datensatz penguins entweder via dem Pfad importieren oder via dem zugehörigen R-Paket. Beide Möglichkeit sind okay.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\n\n11.1.7 Einstieg\n\nBeispiel 11.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, müssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 11.2 (Was war noch einmal die Interaktion?) Erkären Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n11.1.8 Überblick\nWenn Sie die Skalenniveaus wissen, können Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und ähnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, …) lernen müssen. Außerdem ist die Regressionsanalyse (für viele Situationen) die beste Heransgehensweise, da sie viele Möglichkeiten für Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels gängige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. Natürlich würzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-Küche. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "href": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.2 Taxonomie von Forschungsfragen",
    "text": "11.2 Taxonomie von Forschungsfragen\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus. Im Folgenden sind für die UV(s) nominale sowie metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind ebenfalls erlaubt.\nWir untersuchen in diesem Kapitel häufig verwendete Arten von Forschungsfragen mittels Regressionsanalysen. Für jede Variante ist zumeist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abhängige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabhängige Variable (querschnittlich)\n\nb: binäre Variable\n\nx: metrische unabhängige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-b",
    "href": "1000-metrische-AV.html#y-b",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.3 y ~ b\n",
    "text": "11.3 y ~ b\n\n\n11.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im öffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwändigen Studie die Intelligenz vieler Kinder gemessen. Zusätzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, “Risikofaktoren” für geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nIst der mittlere IQ-Wert (kid_score) von Kindern, deren jeweilige Mutter über einen Schlusabschluss (mom_hs, \\(x=1\\)) verfügt höher, als bei Kinderen, deren jeweilige Mutter nicht über einen Schulabschluss verfügt (\\(x=0\\))? (ceteris paribus)4.\n\nDie Modellformel zur Forschungsfrage lautet: y ~  b bzw. kid_iq ~ mom_hs.\nFormaler ausgedrückt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (Theorem 11.1).\n\nTheorem 11.1 (Hypothese für ungleiche Mittelwerte) \\[H_A: \\mu_{x=0|M} \\ne \\mu_{x=1|M}\\quad \\square\\]\n\nIn Worten: “Der mittlere IQ-Wert für Kinder, deren Mütter über einen Schulabschluss verfügen ist höher als in der Gruppe von Kindern, deren Mütter über keinen Schulabschluss verfügen”. Zu beachten ist, dass sich eine Population immer auf Parameterwerte bezieht, also auf die Population, nicht auf die Statistiken der Stichprobe.\nDie zugehörige Nullhypothese lautet:\n\\[H_0: \\mu_{x=1|M} = \\mu_{x=0|M}\\quad \\square\\]\n\n11.3.2 Modell\nDie Regressionsformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in Abbildung 11.1 dargestellt. Y hat, laut unserem Modell, zwei Ursachen:\n\nmom_hs (b)\nu, das steht für “unbekannt”5\n\n\n\n\n\n\n\n\n\nAbbildung 11.1: DAG für kid_iq ~ mom_hs\n\n\n\n\n\nCodedata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nDer Einfachheit halber übernehmen wir die Prioriwerte von Stan, s. Listing 11.1.\n\n\n\nListing 11.1: Standard-Prioriwerte für m10.1, von Stan vergeben\n\nCodeprior_summary(m10.1)\n## Priors for model 'm10.1' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 87, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 87, scale = 51)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = 0, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 0, scale = 124)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.049)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\n\n\nDie komplette Modellspezifikation ist in Gleichung 11.1 aufgeführt.\n\\[\\begin{align*}\n\\text{kid score}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{Lineares Modell} \\\\\n\\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{Prior Regressionsgewicht} \\\\\n\\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{Prior Vorhersagegüte}\n\\end{align*} \\tag{11.1}\\]\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. Tabelle 11.1.\n\n\n\nTabelle 11.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt, da meistens nicht von hohem Interesse)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\n\n11.3.3 Interpretation der Koeffizienten\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren Mütter über keinen Schulabschluss (mom_hs = 0) verfügen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit Mütter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit Mütter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die Schätzung (Vorhersage) ist bzw. wie stark Prädiktor (UV) und Kriterium (AV) zusammenhängen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tatsächlichen IQ-Wert des Kindes (\\(y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n11.3.4 y ~ g als Mittelwertsdifferenz\nEin lineares Modell der Art y ~ g kann man als Berechnung des Unterschieds im Mittelwert von y zwischen beiden Gruppen (g0 vs. g1) verstehen.\n\n👨‍🏫 Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heißen kid_score_avg. An die Arbeit!\n\n\n🤖 Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nCodekidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von Müttern mit Abschluss.\n\n\n\nIn Abbildung 11.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt, auf Basis des Datensatzes kidiq.\n\nCodeestimate_relation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nAbbildung 11.2: Kinder, deren Mütter über einen Schulabschluss verfügen, haben im Mittel einen höheren Intelligenztestwert, laut dem vorliegenden Modell. Die Regressionsgerade ist als durchgezogene Linie dargestellt. Die Mittelwerte pro Gruppe als Punkte und als gestrichelte, horizontale Linie.\n\n\n\n\n\n11.3.5 Rope\nPrüfen wir mit rope(m10.1), ob der Effekt der UV (Unterschied zwischen den Gruppen) “praktisch Null” ist; dazu nutzen wir das ROPE-Verfahren.\n\nCoderope(m10.1)\n\n\n\n\n\n\n\n\n\n\nDas Ergebnis zeigt uns, dass es 0% Überlappung vom Rope und dem 95%-HDI (der Posterior-Verteilung) gibt.\nFazit: Wir verwerfen die Praktisch-Null-Hypothese. Adios! Abbildung 11.3 visualisiert die Erstreckung der Posteriori-Verteilung (und des 95%-HDI) sowie des Rope.\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.1) %&gt;% plot()\n\n\n\n\n\n\nAbbildung 11.3: Rope und HDI überlappen nicht. Wir verwerfen die Praktisch-Null-Hypothese.\n\n\n\n11.3.6 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation – Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das prüft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nAlternativ zum t-Test kann man – unabhängig, ob man Frequentistisch oder Bayesianisch unterwegs ist – mit einer Regression vom Typ y ~ b das in etwa gleiche Ergebnis erreichen.7\n\n11.3.7 Antwort auf die Forschungsfrage\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nCodem10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schönere Namen\n\n\n\n\nHier sind die ersten paar Zeilen, s. Tabelle 11.2.\n\n\n\nTabelle 11.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n76.1\n12.8\n19.7\n\n\n72.9\n17.5\n20.5\n\n\n79.0\n11.7\n20.5\n\n\n75.7\n13.7\n20.6\n\n\n77.0\n12.6\n20.0\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir zur Übung ein 95%-PI von Hand; komfortabler geht es mit eti(m10.1), s. Tabelle 11.1.\n\nCodepi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von Müttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschließend die Posteriori-Verteilung, s. Abbildung 11.4.\n\nCodeplot(eti(m10.1))\n\n\n\n\n\n\nAbbildung 11.4: Das 95% ETI zum (statistischen) Effekt des mütterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem “Effekt” zu sprechen, lässt in den meisten Köpfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang. Für eine Kausalaussage braucht man ein Argument, etwa einen Verweis auf bestehende Studien oder eine Theorie.\n\n\n\n\n\n\n\n\n\n\n11.3.8 Vertiefung: Toleranzbereich\n🏎️VERTIEFUNG, nicht prüfungsrelevant🏎️\nBerechnet man ein Regressionsmodell mit stan_glm (🤖😁), dann zieht man dabei Zufallszahlen 🎲. Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zufällig. Das erklärt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen können.\nUm zu prüfen, ob Ihre Ergebnisse “ähnlich genug” oder “innerhalb eines Toleranzbereichs” sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nGröße des Toleranzbereichs\n\n\n\nDie Größe des relativen Toleranzbereichs ist in is_in_toleranzce() auf 5% festgelegt. Das heißt, ein Unterschied von 5% zwischen einem Referenzwert (dem “wahren” Wert) und Ihrem Wert ist okay, also im Toleranzbereich. Außerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der größere der beiden Werte gilt. \\(\\square\\)\n\n\nWenn Sie diese Funktion nutzen wollen, müssen Sie zunächst das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN) und dann wie gewohnt starten.\n\nCodelibrary(remotes)  # dieses Paket können Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\nlibrary(prada)\n\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der “richtige” oder “wahre” Wert (oder schlicht der Wert einer Musterlösung) für \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nCodeis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. ✅",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b",
    "href": "1000-metrische-AV.html#y-x-b",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.4 y ~ x + b\n",
    "text": "11.4 y ~ x + b\n\n\n11.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b bzw. kid_score ~ mom_iq + mom_hs.\nDie Hypothesen lauten:\n\nDer Schulabschluss der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momhs} &gt; 0\\).\nDer IQ der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momiq} &gt; 0\\).\n\nDer Kausalgraph8 zur Modellformel sieht aus in Abbildung 11.5 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) Einflüsse, b und u, wobei u für “unbekannt” steht, also für alle sonstigen Einflüsse.9\n\n\n\n\n\n\n\nAbbildung 11.5: DAG für y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle Tabelle 11.3 dargestellt.\n\nCodedata(\"kidiq\")  # Paket rstanarm, alternativ über CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\nTabelle 11.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n11.4.2 1 metrischer Prädiktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. Tabelle 11.4.\n\nCodem10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\n\nTabelle 11.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. Abbildung 11.6.\n\nCodekidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildung 11.6: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. Abbildung 11.7.\n\nCodeplot(estimate_relation(m10.2))\n\n\n\n\n\n\nAbbildung 11.7: Die geschätzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder für verschiedene IQ-Werte der Mütter. Vergleicht man Teilpopulationen von Müttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n11.4.3 Beide Prädiktoren, m10.3\n\nBerechnen wir als nächstes ein Modell mit beiden Prädiktoren: kid_score ~ mom_hs + mom_iq, s. Tabelle 11.5.\n\nCodem10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\nTabelle 11.5: Parameter des Modells m10.3 (ohne sigma; ETI-Intervalle)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktschätzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\nCodecoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##       25.74        0.57        6.04\n\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nMöchte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\nCodecoef(m10.3)[3]\n## mom_hs \n##      6\n\n\nAber natürlich ist es möglich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. Abbildung 11.8.\n\nCodekidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\npred &lt;- estimate_relation(m10.3a)\nplot(pred)\n\n\n\n\n\n\nAbbildung 11.8: Der Effekt von sowohl mütterlicher Intelligenz als auch mütterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schätzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum mütterlichen Schulabschluss: Vergleicht man Kinder von Müttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur mütterlichen IQ: Vergleicht man Kinder von Müttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n11.4.4 Antwort auf die Forschungsfrage\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von Müttern mit bzw. ohne Schulabschluss im Bereich von 1.6 bis 10.1 IQ-Punkten, laut unserem Modell. Der Effekt des mütterlichen IQs wird auf 0.5 bis 0.7 geschätzt (95%-ETI). Da für beide UV die Null nicht im Intervall plausibler Werte liegt, kann ein Null-Effekt (die exakte Nullhypothese) abgelehnt werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b-xb",
    "href": "1000-metrische-AV.html#y-x-b-xb",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.5 y ~ x + b + x:b\n",
    "text": "11.5 y ~ x + b + x:b\n\n\n11.5.1 Forschungsfrage und Modelldefinition\n\nGibt es einen Interaktionseffekt zwischen mütterlichem Schulabschluss und mütterlichem IQ (auf den IQ-Wert des Kindes)?\n\nAußerdem ist man vermutlich auch an den Effekten der beiden UV auf die AV interessiert; diese Fragen haben wir im letzten Abschnitt untersucht (und greifen sie daher nicht noch mal ausführlich auf).\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b. Der Einfachheit halber übernehmen wir wieder die Prioris wie vom R-Paket rstanarm bereitgestellt.\nDer DAG zur Modellformel sieht aus in Abbildung 11.9 dargestellt.\n\n\n\n\n\n\n\nAbbildung 11.9: DAG für y ~ x + b + x:b\n\n\n\n\n\n11.5.2 Interaktion zur Modellformel hinzufügen\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. Listing 11.2, Abbildung 11.10 und Tabelle 11.6.\n\n\n\nListing 11.2: Die Modelldefition von m10.4 mit stanglm\n\nCodem10.4 &lt;- \n  stan_glm(kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\nIn der Regressionsformel sieht man, dass ein zusätzlicher Parametern, eben der Interaktionseffekt, in das Modell aufgenommen wurde.\n\n\n\nTabelle 11.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.68\n(-37.44, 15.92)\n77.12%\n1.000\n1338\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.000\n1340\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n50.36\n(21.58, 80.70)\n99.98%\n1.001\n1311\nNormal (0.00 +- 124.21)\n\n\nmom_iq:mom_hs\n-0.47\n(-0.79, -0.17)\n99.88%\n1.001\n1293\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_relation(m10.4) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung 11.10.\n\n\n\n\n\n\n\nAbbildung 11.10: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt für diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n11.5.3 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Schätzwerte für Kinder mit Mütter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-Schätzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-Schätzwerte zwischen Kindern mit Müttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten für mom_iq zwischen Mütter mit bzw. ohne Schulabschluss.\nFür beide Gruppen, mom_hs=0 und mom_hs=1 gilt folgende Regressionsformel, s. Gleichung 11.2.\n\\[\\text{kid score} = \\beta_0 + \\beta_1 \\cdot \\text{mom hs} + \\beta_2 \\cdot \\text{mom iq} + \\beta_3 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.2}\\]\n\\(\\beta_3\\) gibt die Stärke des Interaktionseffekts an.\nAuf Errisch schreibt mit Gleichung 11.2 so (s. Listing 11.2):\nkid_score ~ mom_iq + mom_hs + mom_hs:mom_iq.\nDer Doppelpunkt zwischen mom_hs und mom_iq steht für den Interaktionseffekt der beiden Variablen.\nTrägt man die Werte der Koeffizienten (\\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\)) ein, so erhält man Gleichung 11.3.\n\\[\\text{kid score} = -10.7 + 50.4 \\cdot \\text{mom hs} + 1  \\cdot \\text{mom iq} + -0.5 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.3}\\]\nTeilen wir die Regressionsformel einmal auf die beiden Gruppen (mom_hs=0 bzw. mom_hs=1) auf:\nmom_hs=0:\nkid_score = -10.7 + 50.4*0 + 1*mom_iq  - -0.5*0*mom_iq\n          = -10 + 1.1*mom_iq\nmom_hs=1:\nkid_score = -10.7 + 50.4*mom_hs + 1*mom_iq  - -0.5*mom_hs*mom_iq\n          = -10 + 1.1*mom_iq\nNach der Interpretation von 20 unzentrierten Koeffizienten …\n\n\n\nvia GIPHY\n\nWir müssen dringend die unzentrierten Prädiktoren loswerden …\n\n11.5.4 Antwort auf die Forschungsfrage\nWie in Tabelle 11.6 ersichtlich, kann für alle drei Effekte (mütterliche IQ, mütterlicher Schulabschluss und Interaktion von mütterlichem IQ mit mütterlichem Schulabschluss) ein Nulleffekt ausgeschlossen werden. Ob die Effekte stärker als “praktisch Null” sind, kann mittels des ROPE-Verfahren untersucht werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "href": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.6 y ~ x_c + b + x_c:b\n",
    "text": "11.6 y ~ x_c + b + x_c:b\n\n\n11.6.1 Zentrieren von Prädiktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq; die zentrierte Variable kennzeichnen wir durch den Suffix _c, also mom_iq_c.\nMan könnte auch mom_hs zentrieren, aber für eine einfache Interpretation ist es meist nützlich, nur metrische Prädiktoren zu zentrieren.\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\n\ncoef(m10.5)  # nur die Punktschätzer für die Koeffizienten ausgeben\n\n\nTabelle 11.7 zeigt die Punktschätzer der Koeffizienten von m10.5.\n\n\n\nTabelle 11.7: Punktschätzer von m10.5 (zentrierte UV)\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.34\n\n\nmom_hs\n2.86\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n\n\n\n11.6.2 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den geschätzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten für mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nMit estimate_relation(m10.5) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung 11.11.\n\n\n\n\n\n\n\nAbbildung 11.11: m10.5: Mit zentrierten Prädiktoren gibt der Achsenabschnitt den Y-Wert für eine Beobachtung mit mittleren X-Wert an; daher ist der Achsenabschnitt besser zu interpretieren als ohne Zentrierung.\n\n\n\n\n\n11.6.3 Zentrieren ändert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5: Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren ändert auch nicht die zentrierten Regressionskoeffizienten, da die Streuungen dieser Variable nicht verändert wurden.\n\n11.6.4 Perzentilintervalle aus der Posterori-Verteilung\nTabelle 11.8 zeigt die Punktschätzer der Parameter für m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie dafür parameters(m10.5), s. Tabelle 11.8.\n\n\n\nTabelle 11.8: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(81.17, 89.61)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.80, 7.62)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. Tabelle 11.9.\n\nCodeparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelle 11.9: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(80.96, 89.39)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.64, 7.75)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.17)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n11.6.5 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei Müttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]); die Befundlage ist unklar. Hingegen fand sich ein Effekt der mütterlichen Intelligenz; pro Punkt Unterschied in mütterlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte beim Kind (95%PI). Außerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei Mütter mit Schulabschluss war der Regressionskoeffizient zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell hat mittels Abbildung 11.12 mutig Kausalaussagen postuliert. Das ist zwar schön, bedarf aber einer Begründung mit Rückgriff auf die Literatur (was hier nicht getan wurde).",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#sec-yg",
    "href": "1000-metrische-AV.html#sec-yg",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.7 y ~ g\n",
    "text": "11.7 y ~ g\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n11.7.1 Forschungsfrage\nNach Ihrem Studium wurden Sie reich als Unternehmensberaterin; Ihre Kompetenz als Wirtschaftspsychologi war heiß begehrt. Von Statistik wollte niemand etwas wissen… Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt führte Sie in die Antarktis… Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um Größenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren Körpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in Abbildung 11.12 dargestellt.\n\n\n\n\n\n\n\nAbbildung 11.12: DAG für y ~ g\n\n\n\n\n\n11.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? 🤔 Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere Körpergewichte in Abhängigkeit von der Pinguinart?\n\nAlternativ können wir die Hypothese prüfen, ob die Mittelwerte “praktisch” gleich sind, also sich “kaum” unterscheiden. Der Grenzwert für “praktisch gleich” bzw. “kaum unterschiedlich” ist subjektiv. Dazu in Kapitel 10.3 mehr.\n\n11.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, Tabelle 11.10.\n\nCodepenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\nTabelle 11.10: Die Verteilung des Körpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas fällt Ihnen auf?\n\n11.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. Abbildung 11.13?\n\n\n\n\n\n\n\nAbbildung 11.13: Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.7.5 Gewicht pro Spezies, m10.6\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und Tabelle 11.11.\nDie Modellformel für m10.6 lautet also body_mass_g ~ species.\n\nCodeoptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\n\nTabelle 11.11: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3700.62\n(3627.04, 3773.47)\n100%\n0.999\n4057\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.49\n(-104.84, 168.88)\n68.53%\n1.000\n4282\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.43\n(1263.00, 1492.13)\n100%\n1.000\n4454\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n11.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, Ausprägungen; hier: Spezies), aber es werden in Tabelle 11.11 nur zwei Stufen angezeigt (also eine weniger) zusätzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrückt (Intercept). Die Koeffizienten für species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in Abbildung 11.14 verdeutlicht.\n\nCodeplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 11.14: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\n\n11.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich höher als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich ähnlich.\nWie in Abbildung 11.14 ersichtlich, überlappt sich der Schätzbereich für den Parameter von Gentoo nicht mit der Null; hingegen überlappt sich der Schätzbereich des Parameters für Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hätte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prüfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primär die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.\n\n11.7.8 Priori-Werte ändern\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. Für Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfür Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich mit prior_summary(modell) ausgeben lassen.\n\nCodeprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man über mehr inhaltliches Wissen verfügt, so wird man die Prioris anpassen wollen. So könnte man z.B. auf Basis von Fachwissen über das Gewicht von Pinguinen postulieren, dass Adelie-Pinguine im Mittel 3000 g wiegen. Und dass die anderen zwei Pinguin-Arten im Mittel sich nicht unterscheiden vom Mittelwert der Adelie-Pinguine.\n\nCodem10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3704               24             1358\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nCodem10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(3000, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3700               29             1375\n\n\nDen Parameter für die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen.\n\nCodesigma(m10.6b)\n## [1] 463\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die Größe der Konfidenzintervalle.\nÜbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren.12\n\n11.7.9 Vertiefung: Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\nCodepenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge ändern.\n\nCodelevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nCodelibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verfügbar sein muss.\nJetzt haben wir die Referenzkategorie geändert:\n\nCodelevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie ändert nichts Wesentliches am Modell, s. Tabelle 11.12.\n\nCodem10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nTabelle 11.12: m10.6a mit geänderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 4988.13, 5155.48]\n\n\nspeciesAdelie\n[-1486.15, -1260.32]\n\n\nspeciesChinstrap\n[-1474.66, -1198.00]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1-x2",
    "href": "1000-metrische-AV.html#y-x1-x2",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.8 y ~ x1 + x2\n",
    "text": "11.8 y ~ x1 + x2\n\nHier untersuchen wir Forschungsfragen mit zwei metrischen UV (und einer metrischen AV).\n\n11.8.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhängig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa “IQ der Mutter ist die Ursache zum IQ des Kindes”) wird impliziert.\nEs geht in dieser Forschungsfrage rein darum, Zusammenhänge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. Für solche Fragen ist ein Kausalmodell nötig: Fachlich fundierte Annahmen über Kausalzusammenhänge zwischen UV und AV.\n\n11.8.2 Was heißt, X hängt mit Y zusammen?\n\nDer Begriff “Zusammenhang” ist nicht exakt.\nHäufig wird er (für metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groß der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem “Effekt von X auf Y” übersetzt. Vorsicht: “Effekt” klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begründung für einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der Stärke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehörigen Regression im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten, bevor man ein (Regressions-)Modell aufstellt, s. Tabelle 11.13.\n\nCodekidiq %&gt;% \n  correlation()\n\n\n\n\n\nTabelle 11.13: Korrelation der Variablen im Datensatz kidiq (inkl. frequentistischer Statistiken wie t- und p-Werten, die wir hier ignorieren)\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.166\n\n\nkid_score\nmom_iq_c\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_hs\nmom_iq_c\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\nmom_iq\nmom_iq_c\n1.00\n(1.00, 1.00)\n1.39e+09\n&lt; .001***\n\n\nmom_age\nmom_iq_c\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\n\n\nTabelle 11.14 zeigt die Korrelationsmatrix als Korrelationsmatrix.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\n\nTabelle 11.14: Die Korrelationen zwischen den Variablen der Tabelle kidiq. Die Sterne geben einen Bereich des p-Werts an (wir ignorieren die Sterne hier).\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_iq_c\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.45***\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.28***\n0.21***\n0.28***\n\n\n\nmom_iq\n1.00***\n0.09\n\n\n\n\nmom_age\n0.09\n\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nNützlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, Abbildung 11.15.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung 11.15: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n11.8.3 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro Prädiktor, also eine für mom_iq und eine für mom_age.\n\nCodem10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nTabelle 11.15 zeigt die Ergebnisse für mom_iq.\n\n\n\nTabelle 11.15: Parameter für m10.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.79\n(14.59, 37.16)\n100%\n1.000\n4452\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.72)\n100%\n1.000\n4436\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nTabelle 11.16 zeigt die Ergebnisse für mom_age.\n\n\n\nTabelle 11.16: Parameter für m10.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n71.39\n(54.39, 87.44)\n100%\n0.999\n3923\nNormal (86.80 +- 51.03)\n\n\nmom_age\n0.68\n(-0.02, 1.41)\n96.92%\n0.999\n3917\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n11.8.4 Visualisierung der univariaten Regressionen\nIn Abbildung 11.16 ist die univariate Regression mit jeweils einem der beiden Prädiktoren dargestellt.\nm10.7: Die Steigung beträgt 0.6. m10.8: Die Steigung beträgt 0.7.\n\n\n\n\n\n\n\nAbbildung 11.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n11.8.5 Multiples Modell (beide Prädiktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein Prädiktor im Modell aufgenommen ist, s Tabelle 11.17.\n\nCodem10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\nparameters(m10.9)\n\n\n\n\n\nTabelle 11.17: Parameter für m10.9\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n17.61\n(-0.06, 35.67)\n97.42%\n1.000\n6102\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.60\n(0.48, 0.72)\n100%\n1.000\n5162\nNormal (0.00 +- 3.40)\n\n\nmom_age\n0.39\n(-0.23, 1.02)\n88.22%\n1.000\n4952\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich (potenziell) zu den von den jeweiligen univariaten Regressionen.\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils “bereinigt” vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht. Das bedeutet anschaulich, man betrachtet den den Zusammenhang einee UV mit der AV, wobei man gleichzeitig den anderen Prädiktor konstant hält.\nIn Abbildung 11.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildung 11.17: 3D-Visualisierung von m10.9 (zwei Prädiktoren)\n\n\n\nAbbildung 11.18 zeigt eine Visualisierung von m10.9, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildung 11.18: Modell m10.9; die Farbverläufe zeigen der Wert der abhängigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farbänderung) die Veränderung für die AV (kid_score). Auf der Achse für mom_age sieht man, dass sich die AV kaum ändert, wenn sich mom_age ändert.\n\n11.8.6 Visualisierung in 10 Dimensionen\nAbbildung 11.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildung 11.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schwächen, eine große Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y-x1_z-x2_z",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.9 y ~ x1_z + x2_z\n",
    "text": "11.9 y ~ x1_z + x2_z\n\nIn diesem Abschnitt untersuchen wir ein Modell mit zwei z-standardisierten, metrischen Prädiktoren (und einer metrischen, nicht-standardisierten AV).\n\n11.9.1 Relevanz der Prädiktoren\nWoher weiß man, welche UV am stärksten mit der AV zusammenhängt? Man könnte auch sagen: Welcher Prädiktor (welche UV) am “wichtigsten” ist oder den “stärksten Einfluss” auf die AV ausübt? Bei solchen kausal konnotierten Ausdrücken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann für sich nur Muster in den Daten, also Zusammenhänge bzw. Unterschiede, entdecken, s. Abbildung 11.20. Möchte man die Relevanz von Prädiktoren vergleichen, so ist ein Kausalmodell empfehlenswert.\n\n\n\n\n\nAbbildung 11.20: Made at imgflip.com\n\n\nWelcher Prädiktor ist nun “wichtiger” oder “stärker” in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)? Die Antwort hängt auch von der Streuung bzw. Skalierung der Variablen ab. mom_iq hat den größeren Koeffizienten und viel Streuung; mom_age hat weniger Streuung.\nUm die Relevanz der Prädiktoren vergleichen zu können, müsste man vielleicht die Veränderung von kid_score betrachten, wenn man von kleinsten zum größten Prädiktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die Veränderung in der AV zu betrachten, wenn man den Prädiktor von “unterdurchschnittlich” auf “überdurchschnittlich” ändert. Das kann man mit z-Standardisierung erreichen, s. ?sec-standardnormalverteilung.\n\n\n\n\nCodekidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;%  # z-Transformation\n  select(mom_iq, mom_iq_z) \n\nkidiq2 %&gt;% \n  head()\n\n\n  \n\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit der Effekte von UV, die (zuvor) verschiedene Mittelwerte und Streuungen hatten13. Die Standardisierung ist ähnlich zur Vergabe von Prozenträngen: “Dieser Messwert gehört zu den Top-3-Prozent”. Diese Aussage ist bedeutsam für Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen für verschiedene Verteilungen möglich.\n\n11.9.2 Statistiken zu den z-transformierten Variablen\nTabelle 11.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Ausprägung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener Prädiktoren sind einfacher in ihrer Größe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und ähnlich große Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (“Skalierung”) mit standardize (aus easystats) durchführen, s. Tabelle 11.18.\n\nCodekidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\n\nTabelle 11.18: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nmom_iq_c\npred_m10.9\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_c_z\npred_m10.9_z\n\n\n\n65\n1\n121.12\n27\n21.12\n101.14\n-1.07\n0.52\n1.41\n1.56\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n-10.64\n81.22\n0.55\n0.52\n-0.71\n0.82\n-0.71\n-0.60\n\n\n85\n1\n115.44\n27\n15.44\n97.72\n-0.09\n0.52\n1.03\n1.56\n1.03\n1.19\n\n\n83\n1\n99.45\n25\n-0.55\n87.30\n-0.19\n0.52\n-0.04\n0.82\n-0.04\n0.06\n\n\n115\n1\n92.75\n27\n-7.25\n84.04\n1.38\n0.52\n-0.48\n1.56\n-0.48\n-0.30\n\n\n98\n0\n107.90\n18\n7.90\n89.67\n0.55\n-1.91\n0.53\n-1.77\n0.53\n0.32\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafür, dass die ursprünglichen Variablen beim z-Standardisieren nicht überschrieben werden, sondern angehängt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nCodekidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. Tabelle 11.19. Dazu verwendet man den Befehl scale().\n\nCodekidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\n\nTabelle 11.19: Z-Standardisierung ohne Extrapaket”\n\n\n\n  \n\n\n\n\n\n\n\n11.9.3 Modell\nBerechnen wir das Modell m10.10: y ~ x1_z + x2_z.\n\nCodem10.10 &lt;- stan_glm(kid_score ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\nparameters(m10.10)\n\n\n\n\n\nTabelle 11.20: Parameter von m10.12\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n86.77\n(85.05, 88.48)\n100%\n1.000\n4917\nNormal (86.80 +- 51.03)\n\n\nmom_iq_z\n9.04\n(7.34, 10.83)\n100%\n1.000\n4719\nNormal (0.00 +- 51.03)\n\n\nmom_age_z\n1.04\n(-0.73, 2.78)\n88.02%\n0.999\n4786\nNormal (0.00 +- 51.03)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.10 y_z ~ x1_z + x2_z\n",
    "text": "11.10 y_z ~ x1_z + x2_z\n\nIn diese Abschnitt berechnen wir ein Modell (Modell m10.12), in dem sowohl die Prädiktoren z-transformiert sind (standardisiert) als auch die AV. Das z-Standardisieren der AV, kid_score ist zwar nicht nötig, um den Effekt der Prädiktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darüber, um wie viele SD-Einheiten sich die AV verändert, wenn sich ein Prädiktor um eine SD-Einheit verändert. Das kann auch eine interessante(re) Aussage sein.\n\n11.10.1 Modell y_z ~ x1_z + x2_z\n\nBerechnen wir das Modell m10.12: y_z ~ x1_z + x2_z.\n\nCodem10.12 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z   mom_age_z \n##    -0.00014     0.44384     0.05072\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient für mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_iq um eine SD-Einheit ändert.\nDer Koeffizient für mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_age um eine SD-Einheit ändert.\n\nJetzt sind die Prädiktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar. Man sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n11.10.2 95%-PI\nMit parameters können wir uns ein PI für m10.12 ausgeben lassen, s. Abbildung 11.21; im Standard wird ein 95%-ETI berichtet14.\n\nCodeparameters(m10.12) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-1.38e-04\n(-0.08, 0.08)\n50.20%\n1.000\n5259\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n4713\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.85%\n0.999\n4990\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nCodeplot(eti(m10.12)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 11.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI für m10.12\n\n\n\n\n\n11.10.3 Modellgüte\n\nCoder2(m10.12)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.144, 0.271])\n\n\nIst dieser Wert von \\(R2\\) “gut”? Diese Frage ist ähnlich zur Frage “Ist das viel Geld?”; man kann die Frage nur im Kontext beantworten.\nEine einfache Lösung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklärt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufällig hohen Werten der Modellgüte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine “objektive” Antwort auf die Frage “wie viel ist viel?” haben wollen, ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage “Wieviel ist viel?” gegeben hat (Cohen, 1992):\n\nCodeinterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n11.10.4 Priori-Verteilung für m10.12 und Modelldefinition\nDie Prioris für m10.12 kann man sich mit prior_summary(m10.12) ausgeben lassen. Danke, Stan!\n\nCodeprior_summary(m10.12)  # aus rstanarm\n## Priors for model 'm10.12' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\n🤖 Nix zu danken!\n\nWie gesagt, Stan nimmt dafür einfach die empirischen Mittelwerte und Streuungen her.15\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. Gleichung 11.4.\n\\[\n\\begin{aligned}\n\\text{kidscore}^z_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{momiq}_i^z + \\beta_2\\text{momage}_i^z \\\\\n\\beta_0 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{11.4}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.12. Dadurch, dass nicht nur UV, sondern auch AV z-standardisiert (d.h. zentriert und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuführen.\n\nBeispiel 11.3 (Anzahl der Modellparameter) Wie viele Modellparameter hat m10.12?16\n\n\n11.10.5 Antwort auf die Forschungsfrage\n\nDas Modell spricht sich klar für einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Pro Einheit Standardabweichung in der UV (Intelligenz der Mutter) ändert sich die AV um ca. 0.44 Standardabweichungseinheiten. Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkärt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al., 2020) zurück (s. Anhang für Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem “statistischen Effekt” gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenhänge, und nicht um kausale Zusammenhänge, handelt. Kausale Zusammenhänge dürfen wir nur verkünden, wenn wir sie a) explizit untersuchen und b) sich in der Literatur Belege dafür finden oder c) wir ein Experiment fachgerecht durchgeführt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.11 Vertiefung",
    "text": "11.11 Vertiefung\n🏎️VERTIEFUNG, nicht prüfungsrelevant🏎️\n\n11.11.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch, s. Theorem 11.2.\n\nTheorem 11.2 (Regression als Korrelation) \\[b = r \\frac{sd_x}{sd_y}\\quad \\square\\]\n\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die Punktschätzer für die Regressionskoeffizienten, s. m10.12.\n\nCodem10.12 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z \n##    -0.00033     0.44993\n\n\nVergleichen Sie diese Werte mit der Korrelation, s. Tabelle 11.21.17\n\nCodekidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelle 11.21: Correlation Matrix (pearson-method)\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n11.11.2 Prüfen der Linearitätsannahme\nZentrale Annahme eines linearen Modells: Die AV ist eine lineare Funktion der einzelnen Prädiktoren, $y= _0 + _1x_1 + _2 x_2 + $, vgl. Theorem 2.1.\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression häufig normalverteilte Residuen an18, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schätzen (Gelman et al., 2021).\nIst die Linearitätsannahme erfüllt, so sollte der Residualplot nur zufällige Streuung um \\(y=0\\) herum zeigen, s. Abbildung 11.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsächlichem Wert: \\(e_i = y_i - \\hat{y}_i\\)\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.12_pred = predict(m10.12),  # vorhergesagten Werte\n         m10.12_resid = resid(m10.12))  # Residuen\n\n\n\nCodekidiq %&gt;% \n  ggplot(aes(x = m10.12_pred, y = m10.12_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildung 11.22: Die Verteilung der Fehler scheint keinem starken Trend (in Abhängigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine größeren Auffälligkeiten.\n\n11.11.3 Modellprüfung mit der PPV\n\nCodepp_check(m10.12)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht häufig.\n\n11.11.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildung 11.23: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildung 11.23 zeigt in der oberen Reihe die Regression eines Prädiktors auf den anderen Prädiktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhängt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhängt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n11.11.5 Bayesianisch gleich Frequentistisch?\nÜbrigens liefern stan_glm() und lm oft ähnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nCodestan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.911      -0.019      -2.285\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.908      -0.019      -2.265\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch ähnlich sein können, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.12 Fazit",
    "text": "11.12 Fazit\n\n11.12.1 Austieg: Bayes in fünf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\n📺 Musterlösung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\n📺 Musterlösung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n11.12.2 Ausblick: Binäre AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: Hängen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\nCodedata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m14: am ~ mpg_z:\n\nCodem14 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m14)\n## (Intercept)       mpg_z \n##         0.4         0.3\n\n\nAb mpg_z = 0.4, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nCodemtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m14)[1],\n              slope = coef(m14)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nCodeneg_am &lt;- predict(m14, newdata = tibble(mpg_z = -1.3))\n\n\nFür kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte für am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. Müssen wir mal bei Gelegenheit besser machen.\n\n11.12.3 Genug für heute\nWir waren fleißig …\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schlüssel zum Erfolg.\n\n\nGenug für heute. 👍\n\n11.12.4 Weiterführende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman et al. (2021), Kap. 10, insbesondere 10.3.\nGelman et al. (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit führenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig überschaubarem mathematischen Aufwand.\nFür das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.13 Aufgaben",
    "text": "11.13 Aufgaben\n\n11.13.1 Papier-und-Bleistift-Aufgaben\n\nanz-params\nfofrage-regrformel2\nmodelldef-regrformel\nfinde-prior/\nNullhyp-Beispiel\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nzwert-berechnen\nstan_glm_parameterzahl\nkausale-verben\n\n11.13.2 Aufgaben, für die man einen Computer benötigt\n\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope4\n\n11.13.3 Vertiefung\n\nAnova-skalenniveau\nttest-skalenniveau\nstan_glm_prioriwerte",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n11  Fallbeispiele\n",
    "section": "\n11.14 —",
    "text": "11.14 —\n\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155–159.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). Rstanarm: Bayesian Applied Regression Modeling via Stan. https://mc-stan.org/rstanarm\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#footnotes",
    "href": "1000-metrische-AV.html#footnotes",
    "title": "\n11  Fallbeispiele\n",
    "section": "",
    "text": "Hier ist eine kurze Erklärung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablen↩︎\nHier finden Sie eine kurze Erklärung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktion↩︎\nauch DAG genannt, s. ?sec-kausal↩︎\nHäufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - “größer als/kleiner als” - zu formulieren, anstelle der “empirisch ärmeren” einfachen, ungerichteten Ungleichheit↩︎\nunknown, sozusagen der unbekannte Gott, also für alle sonstigen Einflüsse; man kann das “u” ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgeführt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es gäbe keine anderen Einflüsse als mom_hs auf die IQ des Kindes.↩︎\nGenauer gesagt wird geprüft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.↩︎\nGenauer gesagt, erlaubt der t-Test in der Form des Welche-Tests auch Abweichungen von der Varianzhomogenität der gestesten Gruppen. Die Regression geht hingegen von Varianzhomogenität (Homoskedastizität) aus. Allerdings ist diese Annahme nicht von besonderer Bedeutung, wenn es um die Regressionskoeffizienten geht.↩︎\nDAG, s. ?sec-kausal↩︎\nDabei nehmen wir an, dass x und u nicht voneinander abhängen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.↩︎\nVgl. Abschnitt “UV zentrieren” im Kursbuch Statistik1.↩︎\nauch ETI (Equal Tails Interval) genannt↩︎\ns. Details hier.↩︎\nam nützlichsten ist diese Standardisierung bei normal verteilten Variablen.↩︎\nZumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen können sich ändern. Am besten in der Dokumentation nachlesen: ?parameters.↩︎\nNicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Schätzer der echten Parameter sein müssten, wenn die Stichprobe, die wir ihm angeschleppt hätten, tatsächlich gut ist…↩︎\n4: \\(\\beta_0, \\beta_1, \\beta_2, \\sigma\\)↩︎\nIgnorieren Sie die Zeile mit dem Befehl display(). Dieser Befehl dient nur dazu, die Ausgabe zu verschönern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.↩︎\nwas auf normal verteilte AV hinauslaufen kann aber nicht muss↩︎",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html",
    "href": "1200-abschluss.html",
    "title": "12  Abschluss",
    "section": "",
    "text": "12.1 Lernsteuerung",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "12  Abschluss",
    "section": "",
    "text": "12.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerläutern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische “Lieblingsfehler” benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik übersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n12.1.2 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nCodelibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n\n12.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#probeklausur",
    "href": "1200-abschluss.html#probeklausur",
    "title": "12  Abschluss",
    "section": "\n12.2 Probeklausur",
    "text": "12.2 Probeklausur\n\n12.2.1 2024\n(Diese Liste ist im Aufbau. Bitte konsultieren Sie für weitere Aufgaben selbständig alle relevanten Aufgaben, die in den Kapiteln vorgestellt wurden.)\n\nttest-als-regr\nAdditionssatz1\n\nNerd-gelockert q\nUrne1\ncorona-blutgruppe\nvoll-normal\nalphafehler-inflation3\nverteilungen-quiz-05\nverteilungen-quiz-03\nverteilungen-quiz-04\nKekse03\nglobus-bin2\nglobus2\niq01a\ngem-wskt4\nRethink2m3\nmtcars-post2a\ngroesse03\nbath42\nklausur-raten\nbed-post-wskt1\nmtcars-post3a\nexp-tab\nnorms-sd\nmtcars-post_paper\nbfi10\nrope-luecke\nwskt-schluckspecht2a\npenguins-stan-06\n\n12.2.2 2023\nDieser Tag auf dem Datenwerk stellt Fragen einer Probeprüfung (Version 2023) zusammen.\n\n12.2.3 2022\nDieser Tag auf dem Datenwerk stellt Fragen einer Probeprüfung (Version 2022) zusammen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "12  Abschluss",
    "section": "\n12.3 Lieblinglingsfehler",
    "text": "12.3 Lieblinglingsfehler\nLieblingsfehler im Überblick 🤷:\n\nQuantile und Verteilungsfunktion verwechseln\nPrädiktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n12.3.1 Post-Präd-Verteilung (PPV) und Post-Verteilung verwechseln 🤷\n🏎 🏎 Vertiefung: Dieser Abschnitt ist nicht prüfungsrelevant. 🏎️ 🏎\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nCodem1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle 12.1.\n\nCodepost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle 12.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. Häufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und Punktschätzer auszulesen.\nDie Posterior-Prädiktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n12.3.2 Quantile und Verteilungsfuntion verwechseln 🤷\n\n12.3.2.1 Quantil für \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung 12.1.\n\n\n\n\n\n\n\nAbbildung 12.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) beträgt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist größer oder gleich dem \\(p\\)-Quantil.\n\n12.3.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung 12.2.\n\n\n\n\n\n\n\nAbbildung 12.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit beträgt hier 50%, dass \\(x\\) nicht größer ist als 0.\n\n12.3.3 Interaktion falsch interpretieren 🤷\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kürzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nCodem2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten, s. Tabelle 12.2.\n\nCodeparameters(m2)\n\n\n\n\n\nTabelle 12.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.68\n(18.99, 30.27)\n100%\n1.000\n2120.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.75%\n1.000\n2200.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.80\n(4.96, 22.96)\n99.78%\n1.000\n1573.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.19, -0.03)\n99.52%\n1.000\n1837.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle 12.2 zeigt die Visualisierung der Parameter von m2.\n\nCodeplot(parameters(m2))\n\n\n\n\n\n\nAbbildung 12.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch 😈 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11.\nRichtig 👼 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11 – wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Prädiktoren wären hier eine sinnvolle Lösung.\nGelman et al. (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "12  Abschluss",
    "section": "\n12.4 Kochrezepte 🍲",
    "text": "12.4 Kochrezepte 🍲\n\n12.4.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen über ein Phänomen, \\(y\\), Kausalfrage finden 2. Literatur wälzen, um mögliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese präzisieren 4. Modell präzisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prüfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n12.4.2 Parameter schätzen vs. Hypothesen prüfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schätzen. Beispiel Hypothesenprüfung: “Frauen parken im Durchschnitt schneller ein als Männer”. Beispiel Parameterschätzung: “Wie groß ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und Männern?”\nJe ausgereifter ein Forschungsfeld, desto kühnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nächste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nächste Sonnenfinsternis wird in den nächsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen für den Klausurerfolg. Kühne Hypothesen sind wünschenswert 🦹\n\n12.4.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist höher als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist größer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "12  Abschluss",
    "section": "\n12.5 Kerngedanken Bayes",
    "text": "12.5 Kerngedanken Bayes\n📺 Bayes in fünf Minuten\n📺 Bayes in zehn Minuten\n\n12.5.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nCodem3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung 12.4.\n\n\n\n\n\n\n\nAbbildung 12.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist möglich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind möglich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings übermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n12.5.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-für-prüfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-für-prüfungsaufgaben",
    "title": "12  Abschluss",
    "section": "\n12.6 Beispiele für Prüfungsaufgaben",
    "text": "12.6 Beispiele für Prüfungsaufgaben\n\n12.6.1 Geben Sie den korrekten Begriff an!\n🌬🚙🙋️👨⬅️Hans 👧⬅️Anna 👩⬅️Lise\nPuh, wie erstelle ich für alle Studis ein anderes Rätsel2?\n\n\n\n\n\n12.6.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung 12.5.\n\n\n\n\n\n\n\nAbbildung 12.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 12.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge für x und y gibt eine kleinstmögliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu “identifizieren”). \\(\\square\\)\n\n❓Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n❗ Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n12.6.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung 12.6.\n\n\n\n\n\n\n\nAbbildung 12.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n12.6.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung 12.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung 12.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set für den totalen Kausaleffekt: {AIS, ALN}\n\n12.6.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrüfungsfragen zu Modellen könnten z.B. sein:\n\nGeben Sie den Punktschätzer (Median) für den Prädiktor X im Modell Y an!\nGeben Sie ein 89%-HDI für den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris …\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI für den Prädiktor X im Modell Y?\nWas verändert sich an den Parametern, wenn Sie die Prädiktoren zentrieren/z-standardisieren?\n…",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "12  Abschluss",
    "section": "\n12.7 Aufgabensammlungen",
    "text": "12.7 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere “Prüfungsnähe” könnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prüfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prüfung",
    "title": "12  Abschluss",
    "section": "\n12.8 Viel Erfolg bei der Prüfung!",
    "text": "12.8 Viel Erfolg bei der Prüfung!\n🥳🏆🍀🍀🍀",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section-3",
    "href": "1200-abschluss.html#section-3",
    "title": "12  Abschluss",
    "section": "\n12.9 —",
    "text": "12.9 —\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nvan Kampen, D. (2014). The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs. European Psychiatry, 29(7), 437–448. https://doi.org/10.1016/j.eurpsy.2013.11.001",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#footnotes",
    "href": "1200-abschluss.html#footnotes",
    "title": "12  Abschluss",
    "section": "",
    "text": "langweiliges↩︎\nFahr-Hier-Hans-Anna-Lise: Varianzanalyse↩︎\ndas ist keine vollständige Liste, sondern eine Anregung. Andere Tags könnten auch relevant sein↩︎",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "definitions.html",
    "href": "definitions.html",
    "title": "13  Definitionen",
    "section": "",
    "text": "Kausale Abhängigkeit: ?def-abh\nAdditionssatz für disjunkte Ereignisse: Definition 4.1\nAllgemeiner Additionssatz: Definition 4.2\nBinomialkoeffizient: Definition 5.2\nBinomialverteilung: Definition 5.1\nBlockieren: ?def-blocking\nKollision: ?def-collision\nKonfundierungsvariable: ?def-confound\nDAG: ?def-dag\nDeskriptivstatistik: Definition 2.1\nDirekter Effekt: ?def-dir-eff\nEffekt: ?def-effekt\nElementarereignis: ?def-elementarereignis\nEreignis: Definition 3.3\nEreignisraum: ?def-ereignisraum\nPerzentilintervall (PI): Definition 7.1\nEvidenz: Definition 6.4\nFunktion: Definition 2.4\nGemeinsame Wahrscheinlichkeit: Definition 4.6\nIntervalle höchster Dichte (Highest Density Intervals): Definition 7.2\nHintertür: ?def-hintertuer\nIndirekter Effekt: ?def-ind-eff\nStochastische Unabhängigkeit: Definition 4.4\nIndifferenzprinzip: Definition 3.10\nInferenzstatistik: Definition 2.2\nKettenregel: Definition 4.7\nKonfidenzintervall: Definition 2.7\nLikelihood: Definition 6.2\nLaplace-Experimt: Definition 3.11\nLogarithmus: ?def-logarithmus\nMächtigkeit: Definition 3.7\nMediator: ?def-mediator\nKomplementärereignis: Definition 3.15\nLogische Differenz: Definition 3.16\nSchnittmenge von Ereignissen: Definition 3.14\nVereinigung von Ereignissen: Definition 3.13\nMinimale Adjustierungsmenge : Definition 12.1\nModell: Definition 2.3\nMultiplikationssatz für unabhängige Ereignisse: Definition 4.5\nNachfahre: ?def-Nachfahre\nNullhypothese: Definition 2.9\nNormalverteilung: ?def-nv\nParameter: ?def-parameter\nEffektwahrscheinlichkeit: Definition 9.1\nPfad: ?def-pfad\nPosteriori-Verteilung: Definition 6.3\nBedingte Wahrscheinlichkeit: Definition 4.3\nPriori-Verteilung: Definition 6.1\nPunktschätzer: ?def-punktschaetzer\nRelation: Definition 3.12\nSignifikanz: Definition 2.8\nStratifizieren: ?def-stratifizieren\nTotaler Effekt: ?def-tce\nTotale Wahrscheinlichkeit: Definition 4.8\nUnmögliches und sicheres Ereignis: Definition 3.4\nVerteilungsfunktion: Definition 3.19\nVerteilungsfunktion: Definition 3.22\nVollständiges Ereignissystem: Definition 3.6\nVorhersageintervall: ?def-vorhersageintervall\nWahrscheinlichkeitsfunktion: ?def-w-fun\nWahrscheinlichkeitsdichte: Definition 3.21\nWahrscheinlichkeit: Definition 3.9\nDiskrete Wahrscheinlichkeitsverteilung: Definition 3.18\nStetige Wahrscheinlichkeitsverteilung: ?def-wvert-stetig\nZufälliges Ereignis: Definition 3.1\nZufallsvorgang: Definition 3.1\nZufallsvariable: Definition 3.17\nStetige Zufallsvariable: Definition 3.20",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "theorems.html",
    "href": "theorems.html",
    "title": "14  Theoreme",
    "section": "",
    "text": "Stochastische Abhängigkeit: Theorem 4.6\nStochastische Abhängigkeit 2: Theorem 4.7\nAllgemeiner Additionssatz: Theorem 4.2\nAdditionssatz für disjunkte Ereignisse: Theorem 4.1\nBayes’ Theorem: Theorem 6.1\nBayes’ Theorem 2: Theorem 6.8\nBayes’ Theorem 3: Theorem 6.8\nBayes’ Theorem für zusammengesetzte Hypothesen: Theorem 6.9\nBinomialkoeffizient: Theorem 5.3\nBinomialverteilung: Theorem 5.2\nNotation für eine binomialverteilte Zufallsvariable: Theorem 5.1\nRegression als Korrelation: Theorem 11.2\nIndifferenzprinzip: Theorem 3.1\nEvidenz: Theorem 6.3\nEvidenz 2: Theorem 6.4\nHypothese für ungleiche Mittelwerte: Theorem 11.1\nGemeinsame Wahrscheinlichkeit: Theorem 4.10\nStochastische Unabhängigkeit: Theorem 4.4\nSymmetrie der Unabhängigkeit: Theorem 4.8\nStochastische Unabhängigkeit 2: Theorem 4.5\nKettenregel: Theorem 4.11\nLaplace-Experiment: Theorem 3.2\nLineares Modell (Regressionsgleichung): Theorem 2.1\nLogarithmus: ?thm-logarithmus\nModelldefinition: Theorem 9.1\nNullhypothesentest: Theorem 10.1\nMultiplikationssatz für unabhängige Ereignisse: Theorem 4.9\nStandardisierte Posteriori-Verteilung: Theorem 6.6\nPosteriori-Verteilung 2: Theorem 6.7\nBedingte Wahrscheinlichkeit: Theorem 4.3\nStandardnormalverteilung: ?thm-standardnormal\nTotale Wahrscheinlichkeit: Theorem 4.12\nUnstandardisierte Posteriori-Wahrscheinlichkeit : Theorem 6.5\nz-Transformation: ?thm-ztrans",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Theoreme</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Badenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A.,\n& Longobardi, C. (2016). Misconceptions of the p-value among\nChilean and Italian Academic Psychologists.\nFrontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schließende\nStatistik: praxisorientierte Einführung mit Aufgaben und Lösungen\n(7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-übungen: Beschreibende\nstatistik – wahrscheinlichkeitsrechnung – schließende statistik (7.\nAuflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of\nModeling, Probability &\nStatistics. Springer.\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155–159.\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020).\nRstanarm: Bayesian applied regression modeling via\nStan. https://mc-stan.org/rstanarm\n\n\nHenze, N. (2019). Stochastik: Eine Einführung mit Grundzügen der\nMaßtheorie: Inkl. zahlreicher Erklärvideos. Springer Berlin\nHeidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157–1164.\nhttp://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability theory:\nThe logic of science. Cambridge University Press.\n\n\nKabadayi, F. (2024). Smartphone addiction, depression, distress,\neustress, loneliness, and sleep deprivation in adolescents: A latent\nprofile and network analysis approach. BMC Psychology,\n12(1), 608. https://doi.org/10.1186/s40359-024-02117-6\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter\nValues in Bayesian Estimation. Advances in\nMethods and Practices in Psychological Science, 1(2),\n270–280. https://doi.org/10.1177/2515245918771304\n\n\nKurz, S. (2021). Statistical Rethinking with\nBrms, Ggplot2, and the Tidyverse:\nSecond Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & Lüdecke, D.\n(2019). Indices of Effect Existence and\nSignificance in the Bayesian Framework.\nFrontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd ed.). Taylor and Francis, CRC\nPress.\n\n\nMittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes factor approaches for\ntesting interval null hypotheses. Psychological Methods,\n16(4), 406–419. https://doi.org/10.1037/a0024377\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference\nin statistics: A primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPopper, K. (2013). Logik der Forschung (H. Keuth,\nEd.). Akademie Verlag. https://doi.org/10.1524/9783050063782\n\n\nSauer, S. (2025). Statistik1. Independently published via\nAmazon. https://www.amazon.de/Statistik1-Einf%C3%BChrung-Statistik-Schwerpunkt-Prognose-Modellierung/dp/B0F673WGG5\n\n\nShmueli, G. (2010). To Explain or to Predict?\nStatistical Science, 25(3), 289–310. https://doi.org/10.1214/10-STS330\n\n\nvan Kampen, D. (2014). The SSQ model of schizophrenic\nprodromal unfolding revised: An analysis of its causal\nchains based on the language of directed graphs. European\nPsychiatry, 29(7), 437–448. https://doi.org/10.1016/j.eurpsy.2013.11.001\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s\nStatement on p-Values: Context,\nProcess, and Purpose. The American\nStatistician, 70(2), 129–133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Anhang",
      "Literaturverzeichnis"
    ]
  },
  {
    "objectID": "imprint.html",
    "href": "imprint.html",
    "title": "15  Impressum",
    "section": "",
    "text": "15.1 Vertreten durch:\nAngaben gemäß § 5 DDG\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach\nSebastian Sauer",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#kontakt",
    "href": "imprint.html#kontakt",
    "title": "15  Impressum",
    "section": "15.2 Kontakt:",
    "text": "15.2 Kontakt:\nTelefon: 0981 4877 0, E-Mail: sebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#aufsichtsbehörde",
    "href": "imprint.html#aufsichtsbehörde",
    "title": "15  Impressum",
    "section": "15.3 Aufsichtsbehörde:",
    "text": "15.3 Aufsichtsbehörde:\nNürnberg",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#verantwortlich-für-den-inhalt-nach-55-abs.-2-rstv",
    "href": "imprint.html#verantwortlich-für-den-inhalt-nach-55-abs.-2-rstv",
    "title": "15  Impressum",
    "section": "15.4 Verantwortlich für den Inhalt nach § 55 Abs. 2 RStV:",
    "text": "15.4 Verantwortlich für den Inhalt nach § 55 Abs. 2 RStV:\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#haftungsausschluss",
    "href": "imprint.html#haftungsausschluss",
    "title": "15  Impressum",
    "section": "15.5 Haftungsausschluss:",
    "text": "15.5 Haftungsausschluss:\n\n15.5.1 Haftung für Inhalte\nDie Inhalte unserer Seiten wurden mit größter Sorgfalt erstellt. Für die Richtigkeit, Vollständigkeit und Aktualität der Inhalte können wir jedoch keine Gewähr übernehmen. Als Diensteanbieter sind wir gemäß § 7 Abs.1 DDG für eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach §§ 8 bis 10 DDG sind wir als Diensteanbieter jedoch nicht verpflichtet, übermittelte oder gespeicherte fremde Informationen zu überwachen oder nach Umständen zu forschen, die auf eine rechtswidrige Tätigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unberührt. Eine diesbezügliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung möglich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\n\n\n15.5.2 Haftung für Links\nUnser Angebot enthält Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb können wir für diese fremden Inhalte auch keine Gewähr übernehmen. Für die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mögliche Rechtsverstöße überprüft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n\n\n15.5.3 Urheberrecht\nDie durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielfältigung, Bearbeitung, Verbreitung und jede Art der Verwertung außerhalb der Grenzen des Urheberrechtes bedürfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur für den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n\n\n15.5.4 Datenschutz\nDie Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten möglich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit möglich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdrückliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Datenübertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitslücken aufweisen kann. Ein lückenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht möglich. Der Nutzung von im Rahmen der Impressumspflicht veröffentlichten Kontaktdaten durch Dritte zur Übersendung von nicht ausdrücklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdrücklich widersprochen. Die Betreiber der Seiten behalten sich ausdrücklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, Fachanwälte für Familienrecht",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "data-privacy.html",
    "href": "data-privacy.html",
    "title": "16  Datenschutzhinweise",
    "section": "",
    "text": "16.1 Einleitung\nDiese Datenschutzhinweise informieren Sie über die Art, den Umfang und den Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend “Daten”) im Rahmen der Nutzung dieser Webseite (nachfolgend “Webseite”), die auf GitHub gehostet wird.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#einleitung",
    "href": "data-privacy.html#einleitung",
    "title": "16  Datenschutzhinweise",
    "section": "",
    "text": "16.1.1 Verantwortliche Person\nProf. Dr. habil. Sebastian Sauer, Residenzstr. 10, 90522 Ansbach, sebastian.sauer@hs-ansbach.de\n\n\n16.1.2 Hosting durch GitHub\nUnsere Webseite wird von GitHub Inc., 88 Colin P. Kelly Jr. St, San Francisco, CA 94107, USA (“GitHub”) gehostet. GitHub verarbeitet in unserem Auftrag Daten von Webseitenbesuchern (z.B. IP-Adressen). Dies ist für den Betrieb der Webseite und die Bereitstellung von Inhalten erforderlich. GitHub ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europäische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC&status=Active).\nWeitere Informationen zum Datenschutz bei GitHub finden Sie in der Datenschutzerklärung von GitHub: https://docs.github.com/de/site-policy/privacy-policies/github-general-privacy-statement",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#datenerhebung-und--verarbeitung",
    "href": "data-privacy.html#datenerhebung-und--verarbeitung",
    "title": "16  Datenschutzhinweise",
    "section": "16.2 Datenerhebung und -verarbeitung",
    "text": "16.2 Datenerhebung und -verarbeitung\n\n16.2.1 Server-Log-Dateien\nBei jedem Zugriff auf unsere Webseite erfasst GitHub automatisiert Daten und speichert diese in Server-Log-Dateien. Zu diesen Daten gehören: IP-Adresse des zugreifenden Geräts Datum und Uhrzeit des Zugriffs Name und URL der abgerufenen Datei Webseite, von der aus der Zugriff erfolgt (Referrer-URL) Verwendeter Browser und ggf. das Betriebssystem des zugreifenden Geräts Name des Access-Providers\nDie Verarbeitung dieser Daten erfolgt, um die Funktionsfähigkeit der Webseite sicherzustellen, die Nutzung der Webseite zu analysieren und unser Angebot zu verbessern. Rechtsgrundlage für die Datenverarbeitung ist Art. 6 Abs. 1 lit. f DSGVO (berechtigtes Interesse). Unser berechtigtes Interesse liegt in den oben genannten Zwecken.\n\n\n16.2.2 Cookies\nUnsere Webseite verwendet keine Cookies.\n\n\n16.2.3 Einbindung von Drittinhalten\nEs können Inhalte von Drittanbietern wie Videos, Schriftarten oder Karten eingebunden sein. Beim Abruf dieser Inhalte wird Ihre IP-Adresse möglicherweise an den Drittanbieter übertragen. Für weitere Informationen konsultiere bitte die Datenschutzrichtlinien der jeweiligen Anbieter.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#ihre-rechte",
    "href": "data-privacy.html#ihre-rechte",
    "title": "16  Datenschutzhinweise",
    "section": "16.3 Ihre Rechte",
    "text": "16.3 Ihre Rechte\nSie habengegenüber uns folgende Rechte hinsichtlich der dich betreffenden personenbezogenen Daten: Recht auf Auskunft (Art. 15 DSGVO) Recht auf Berichtigung (Art. 16 DSGVO) Recht auf Löschung (Art. 17 DSGVO) Recht auf Einschränkung der Verarbeitung (Art. 18 DSGVO) Recht auf Datenübertragbarkeit (Art. 20 DSGVO) Recht auf Widerspruch gegen die Verarbeitung (Art. 21 DSGVO)\nSie haben zudem das Recht, sich bei einer Datenschutz-Aufsichtsbehörde über die Verarbeitung deiner personenbezogenen Daten durch uns zu beschweren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "href": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "title": "16  Datenschutzhinweise",
    "section": "16.4 Anwendbare Rechtsgrundlagen",
    "text": "16.4 Anwendbare Rechtsgrundlagen\nNachstehend geben wir Ihnen eine Übersicht der rechtlichen Grundlagen der DSGVO, auf deren Basis personenbezogene Daten auf dieser Webseite verarbeitet werden. Bitte beachten Sie, dass neben den Regelungen der DSGVO auch nationale Datenschutzvorgaben in Ihrem oder unserem Land relevant sein können. Sofern in Einzelfällen spezifische Rechtsgrundlagen gelten, werden diese in der Datenschutzerklärung gesondert erwähnt.\n\n16.4.1 Vertragserfüllung und vorvertragliche Maßnahmen (Art. 6 Abs. 1 S. 1 lit. b) DSGVO)\nDie Verarbeitung personenbezogener Daten ist erforderlich zur Erfüllung eines Vertrags, bei dem die betroffene Person Vertragspartei ist, oder zur Durchführung vorvertraglicher Maßnahmen, die auf Anfrage der betroffenen Person erfolgen.\n\n\n16.4.2 Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO)\nDie Datenverarbeitung erfolgt zur Wahrung berechtigter Interessen des Verantwortlichen oder eines Dritten, sofern keine entgegenstehenden Interessen, Grundrechte oder Grundfreiheiten der betroffenen Person, die den Schutz ihrer personenbezogenen Daten erfordern, überwiegen.\n\n\n16.4.3 Nationale Datenschutzbestimmungen in Deutschland\nNeben der DSGVO gelten in Deutschland nationale Datenschutzvorgaben, insbesondere das Bundesdatenschutzgesetz (BDSG). Das BDSG beinhaltet spezielle Regelungen zum Recht auf Auskunft, Löschung, Widerspruch, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung für andere Zwecke sowie zur Datenübermittlung und zu automatisierten Einzelentscheidungen einschließlich Profiling. In bestimmten Fällen können auch Datenschutzgesetze der Bundesländer Anwendung finden.\n\n\n16.4.4 Hinweis auf die Geltung von DSGVO und Schweizer DSG\nDiese Datenschutzhinweise berücksichtigen die Vorgaben sowohl der DSGVO als auch des Schweizer Datenschutzgesetzes (DSG). Zur besseren Verständlichkeit und zur Vermeidung wiederholter Begriffsdefinitionen werden die Begriffe der DSGVO verwendet. Begriffe wie „Verarbeitung“, „personenbezogene Daten“, „berechtigtes Interesse“ und „besondere Kategorien von Daten“ entsprechen inhaltlich den Begriffen „Bearbeitung“, „Personendaten“, „überwiegendes Interesse“ und „besonders schützenswerte Personendaten“ des Schweizer DSG. Die genaue Auslegung und Anwendung erfolgt jedoch gemäß den Vorgaben des Schweizer DSG.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#sicherheitsmaßnahmen",
    "href": "data-privacy.html#sicherheitsmaßnahmen",
    "title": "16  Datenschutzhinweise",
    "section": "16.5 Sicherheitsmaßnahmen",
    "text": "16.5 Sicherheitsmaßnahmen\nWir setzen angemessene technische und organisatorische Maßnahmen zum Schutz Ihrer Daten entsprechend den gesetzlichen Anforderungen um. Dabei berücksichtigen wir den aktuellen Stand der Technik, die Implementierungskosten, Art, Umfang, Umstände und Zweck der Verarbeitung sowie die Wahrscheinlichkeit und Schwere möglicher Risiken für die Rechte und Freiheiten betroffener Personen.\nZu den Schutzmaßnahmen gehören insbesondere: Sicherstellung der Vertraulichkeit, Integrität und Verfügbarkeit von Daten durch Kontrolle des Zugriffs auf die Daten und die Infrastruktur, der Eingaben, Weitergaben und Trennungen von Daten. Zudem haben wir Verfahren eingerichtet, um die Rechte betroffener Personen zu gewährleisten, Daten zu löschen und angemessen auf Bedrohungen zu reagieren. Bereits in der Entwicklung und Auswahl von Hard- und Software sowie Verfahren berücksichtigen wir Datenschutzprinzipien wie Datenschutz durch Technikgestaltung und datenschutzfreundliche Voreinstellungen.\nSicherung von Online-Verbindungen mit TLS-/SSL-Verschlüsselung (HTTPS) Um die Datenübertragung über unsere Online-Dienste vor unbefugtem Zugriff zu schützen, nutzen wir die TLS-/SSL-Verschlüsselungstechnologie. Dies gewährleistet eine sichere Datenübertragung zwischen unserem Server und Ihrem Browser, erkennbar an der HTTPS-Kennung in der URL-Leiste.\n\n16.5.1 Internationale Datenübertragungen\nFalls Datenverarbeitungen in Drittländern (außerhalb der EU und des EWR) stattfinden oder personenbezogene Daten an Dritte im Ausland übermittelt werden, erfolgt dies ausschließlich unter Einhaltung gesetzlicher Anforderungen. Sofern ein Angemessenheitsbeschluss der EU-Kommission für das betreffende Drittland vorliegt (Art. 45 DSGVO), gilt dieser als Grundlage der Übertragung. Falls kein Angemessenheitsbeschluss vorliegt, sichern Standardvertragsklauseln (Art. 46 Abs. 2 lit. c) DSGVO), eine ausdrückliche Einwilligung oder gesetzliche Erfordernisse die Übertragung ab (Art. 49 Abs. 1 DSGVO).\nWeitere Informationen zu den Angemessenheitsbeschlüssen der EU-Kommission finden Sie auf dieser Seite. Die USA bieten mit dem sogenannten „Data Privacy Framework“ (DPF) eine Regelung zur Sicherstellung eines angemessenen Datenschutzniveaus, das durch die EU-Kommission am 10.07.2023 anerkannt wurde. Die Liste der zertifizierten Unternehmen und weitere Informationen finden Sie auf der Webseite des US-Handelsministeriums unter Data Privacy Framework.\nWir informieren Sie in unseren Datenschutzhinweisen, welche Drittanbieter unter diesem Rahmen zertifiziert sind.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#kontakt",
    "href": "data-privacy.html#kontakt",
    "title": "16  Datenschutzhinweise",
    "section": "16.6 Kontakt",
    "text": "16.6 Kontakt\nFür Anfragen zum Datenschutz können Sie sich an uns wenden:\nProf. Dr. habil. Sebastian Sauer\nResidenzstr. 10, 90522 Ansbach\nsebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#änderung-der-datenschutzhinweise",
    "href": "data-privacy.html#änderung-der-datenschutzhinweise",
    "title": "16  Datenschutzhinweise",
    "section": "16.7 Änderung der Datenschutzhinweise",
    "text": "16.7 Änderung der Datenschutzhinweise\nWir behalten uns vor, diese Datenschutzhinweise jederzeit anzupassen, um sie an geänderte Rechtslagen oder bei Änderungen des Dienstes sowie der Datenverarbeitung anzupassen.\nStand: 15. November 2024",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  }
]