[
  {
    "objectID": "0900-lineare-modelle.html",
    "href": "0900-lineare-modelle.html",
    "title": "9¬† Einfache lineare Modelle",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "9¬† Einfache lineare Modelle",
    "section": "",
    "text": "9.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Post-Verteilung f√ºr einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder Streuungsma√üe und auch Sch√§tzintervalle - aus der Post-Verteilung herauslesen\nk√ºnftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4.\n\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\n\n\n\n9.1.5 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine √úbersicht aller Funktionen des Pakets.1\n\n\n9.1.6 Ben√∂tigte Daten\nIn diesem Kapitel ben√∂tigen wir den Datensatz zu den !Kung-Leuten, Howell1a, McElreath (2020). Sie k√∂nnen ihn hier herunterladen.\n Download \n\n\nCode\n1Kung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\n2kung &lt;- read.csv(Kung_path)\n\n3kung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\n\n\n1\n\nPfad zum Datensatz; Sie m√ºssen online sein, um die Daten herunterzuladen.\n\n2\n\nDaten einlesen\n\n3\n\nAuf Erwachsene Personen begrenzen (d.h. Alter &gt; 18)\n\n\n\n\n\n\n9.1.7 Einstieg\n\nBeispiel 9.1 (Grundkonzepte der linearen Regression) Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! \\(\\square\\)\n\n\nBeispiel 9.2 (Was ist eine Post-Verteilung und wozu ist sie gut?) Erkl√§ren Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. \\(\\square\\)\n\n\n\n9.1.8 √úberblick\nDieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die K√∂rpergr√∂√üe auf das Gewicht zur√ºckgef√ºhrt wird; also ein sehr eing√§ngiges Modell.\nNeu ist dabei lediglich, dass die Parameter des Modells - \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) - jetzt √ºber eine Post-Verteilung verf√ºgen. Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik. Die ‚Äúnormale‚Äù Regression hat uns nur einzelne Werte f√ºr die Modellparameter geliefert (‚ÄúPunktsch√§tzer‚Äù). Mit Bayes haben wir eine ganz Verteilung pro Parameter.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\nDie (einfache) Regression pr√ºft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenh√§ngen. Je mehr sie zusammenh√§ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). H√§ngen \\(X\\) und \\(Y\\) zusammen, hei√üt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).2\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X, UV) und Gr√∂√üe (Y, AV), Abbildung¬†9.1.\n\nCode\nkung_erwachsen %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\nCode\nggscatter(kung_erwachsen,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\") \n\n\n\n\n\n\nMit ggplot2Mit ggpubr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.1: Der Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y)\n\n\n\n\n\n9.2.2 Statistiken zum !Kung-Datensatz\nDie Daten k√∂nnen Sie hier herunterladen.\nTabelle¬†9.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path &lt;- \"data/Howell1a.csv\"  \nkung &lt;- read_csv(Kung_path)  \n\nkung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelle¬†9.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus Tabelle¬†9.1 abzulesen ist, betr√§gt das mittlere K√∂rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n\n9.2.3 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n9.2.3.1 Gibt es fehlende Werte?\nNein, s. Abb. Abbildung¬†9.2.\n\n\nCode\nkung_erwachsen %&gt;% plot_missing()\n\n\n\n\n\n\n\n\nAbbildung¬†9.2: Fehlende Werte - fehlen.\n\n\n\n\n\n\n\n9.2.3.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. Abbildung¬†9.3.\n\n\nCode\nkung_erwachsen %&gt;% plot_histogram()\n\n\n\n\n\n\n\n\nAbbildung¬†9.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. Abbildung¬†9.4.\n\n\nCode\nkung_erwachsen %&gt;% plot_bar()\n\n\n\n\n\n\n\n\nAbbildung¬†9.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in Abbildung¬†9.5 dargestellt.\n\n\nCode\nkung_erwachsen %&gt;% plot_correlation()\n\n\n\n\n\n\n\n\nAbbildung¬†9.5: Korrelationsmatrix\n\n\n\n\n\n\n√úbungsaufgabe 9.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(kung_erwachsen). \\(\\square\\)\n\n\n\n\n9.2.4 Pr√§diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor ‚Äúzentrieren‚Äù, engl. to center). Wenn man den Pr√§diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\beta_0\\), einfacher zu verstehen. In einem Modell mit zentriertem Pr√§diktor (weight) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. W√ºrde man weight nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman et al. (2021), Kap. 10.4, 12.2.\nMan zentriert eine Variable \\(X\\), indem man von \\(x_i\\) den Mittelwert \\(\\bar{x}\\) abzieht: \\(x_i - \\bar{x}\\).\n\n\nCode\nkung_zentriert &lt;-\n  kung_erwachsen %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\nMit Hilfe von center() aus {easystats} kann man sich das Zentrieren auch erleichtern.\n\n\nCode\nkung_zentriert &lt;- \n  kung_erwachsen %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\n‚àí9\n\n\n137\n32\n65\n0\n‚àí13\n\n\n\n\n\n\n\nWie man sieht, wird die Verteilung von weight durch die Zentrierung ‚Äúzur Seite geschoben‚Äù: Der Mittelwert von weight_c (das zentrierte Gewicht) liegt jetzt bei 0, s. Abbildung¬†9.6.\n\n\n\n\n\n\n\n\nAbbildung¬†9.6: Das Zentrieren √§ndert die Verteilungsform nicht, sondern ‚Äúschiebt‚Äù die Verteilung nur zur Seite\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass kung_zentriert die Tabelle mit zentriertem Pr√§diktor ist, nicht kung_erwachsen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-pr√§diktor",
    "href": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-pr√§diktor",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.3 Modell m_kung_gewicht_c: zentrierter Pr√§diktor",
    "text": "9.3 Modell m_kung_gewicht_c: zentrierter Pr√§diktor\nüì∫ Pr√§diktoren zentrieren\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was w√§re wohl die K√∂rpergr√∂√üe? Hm, Philosophie steht heute nicht auf der Tagesordnung. Da w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m_kung_gewicht_c\nF√ºr jede Auspr√§gung des Pr√§diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung f√ºr die abh√§ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte f√ºr die Steigung \\(\\beta_1\\) und den Achsenabschnitt \\(\\beta_0\\) der Regressionsgeraden. Au√üerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Gr√∂√üe (height) angibt; dieser Wert wird als exponentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\). Theorem¬†9.1 stellt die Modelldefinition dar. ?fig-kruschke_regr_one_predctor zeigt, wie die drei Parameter zusammen die Likelihood definieren.\n\n\nTheorem 9.1 (Modelldefinition m_kung_gewicht_c) \\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}{\\beta_0} & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}{\\beta_1}  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\quad \\square\\]\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnitt (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ü§∑\n\n\n\n\n9.3.2 Likelihood, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m_kung_gewicht_c ist √§hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines ‚ÄúIndex-i‚Äù am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\n‚ÄúDie Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))‚Äù.\n\n\n\n9.3.3 Regressionsformel, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\beta_0\\) und \\(\\beta_1\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der Pr√§diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\n‚ÄúDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\beta_0\\) und \\(\\beta_1\\) mal \\(\\text{weight}_i\\)‚Äù.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta_1\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\beta_0\\) gibt an, wie gro√ü \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n9.3.4 Priori-Werte des Modells m_kung_gewicht_c\n\\[\\begin{align*}\n\\color{blue}\\beta_1 & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta_1  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen. \\(\\beta_0\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine ‚ÄúRegression ohne Pr√§diktoren‚Äù berechnet haben. \\(\\sigma\\) ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel. Da height nicht zentriert ist, der Mittelwert von \\(\\beta_0\\) bei 178 und nicht 0. \\(\\beta_1\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist. Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.\n\n\n9.3.5 Prioris plus Daten gleich Post\n![Parameter ]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.4 Die Post-Verteilung befragen",
    "text": "9.4 Die Post-Verteilung befragen\nüì∫ Post-Verteilung auslesen 1\nüì∫ Post-Verteilung auslesen 2\n\n9.4.1 m_kung_starkes_beta1\nSagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. Gleichung¬†9.1. Dabei haben wir folgende Prioris gew√§hlt:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{9.1}\\]\nWir nennen das Modell m_kung_starkes_beta13, s. Listing¬†9.1.\n\n\n\nListing¬†9.1: Modelldefinition von m_kung_starkes_beta1 in R\n\n\n\n\nCode\nm_kung_starkes_beta1 &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # beta 0\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = kung_zentriert)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die Nachpr√ºfbarkeit der Ergebnisse (‚ÄúReproduzierbarkeit‚Äù) sichergestellt4. Welche Wert f√ºr seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung sch√§tzen.\n\n\n\n\n9.4.2 Mittelwerte von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. Tabelle¬†9.2.\n\n\n\nTabelle¬†9.2: Parameter von m_kung_starkes_beta1\n\n\n\nCode\nparameters(m_kung_starkes_beta1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 9.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also gr√∂√üer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) √Ñhnliches wie der p-Wert in der Frequentistischen Statistik (Makowski et al., 2019).\n\nAm besten das Diagramm dazu anschauen, s Abbildung¬†9.7.\n\n\nCode\nplot(p_direction(m_kung_starkes_beta1))\n\n\n\n\n\n\n\n\nAbbildung¬†9.7: Diagramm zur Probability of Direction, Modell m_kung_starkes_beta1\n\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) gr√∂√üer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter besch√§ftigen in diesem Kurs.\n\n\n9.4.3 Visualisieren der ‚Äúmittleren‚Äù Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). √úberzeugen wir uns mit einem Blick in die Post-Verteilung von m_kung_starkes_beta1:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n\n  \n\n\n\nWir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die ‚Äúmittlere‚Äù Regressionsgerade zu betrachten, s. Abbildung¬†9.8.\n\nCode\nkung_zentriert %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") |&gt; plot()  # aus {easystats}\n\n\n\n\n\nMit ggplotMit easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. Abbildung¬†9.8 (a). Mit ‚Äúexpectation‚Äù sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\n\n\n\n\n\n\n(a) Erwartete Werte des Modell m_kung_starkes_beta1, sprich, die Regressionsgerade\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.8\n\n\n\n\n\n9.4.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).5 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.\n\n9.4.4.1 Lagema√üe zu den Parametern\n\nWas ist die mittlere Gr√∂√üe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? (\\(\\beta_1\\))\nWas ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert f√ºr z.B: \\(\\beta_1\\)?\n\nEine n√ºtzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. Tabelle¬†9.2.\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m_kung_starkes_beta1, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm_kung_starkes_beta1_post &lt;- \n  m_kung_starkes_beta1 %&gt;% \n  as_tibble()\n\nm_kung_starkes_beta1_post %&gt;% \n  head()\n\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m_kung_starkes_beta1_post. Jetzt haben wir wieder eine sch√∂ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen k√∂nnen. Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. Abbildung¬†9.9.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung¬†9.9: Die Postverteilung f√ºr den Parameter Gewicht (zentriert); die plausiblen Werte liegen zwischen 0.8 und 1.0 cm pro Kilogramm Gewicht\n\n\n\n\n\nAbbildung¬†9.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. Abbildung¬†9.10.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung¬†9.10: Die Post-Verteilung f√ºr den Parameter sigma, m_kung_starkes_beta1; die plausiblen Werte liegen zwischen 4.7 cm und 5.5 cm.\n\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. Abbildung¬†9.11.\n\n\nCode\nm_kung_starkes_beta1_hdi &lt;- hdi(m_kung_starkes_beta1_post)  # analog mit eti(m_kung_starkes_beta1)\n\nplot(m_kung_starkes_beta1_hdi)\n\n\n\n\n\n\n\n\nAbbildung¬†9.11: Die Parameter Gewicht (zentriert) und sigma des Modells m_kung_starkes_beta1\n\n\n\n\n\nErg√§nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt. Den Parameter der Vorhersage-Genauigkeit, \\(\\sigma\\) bekommt man mit get_sigma:\n\n\nCode\nget_sigma(m_kung_starkes_beta1)\n## [1] 5.1\n## attr(,\"class\")\n## [1] \"insight_aux\" \"numeric\"\n\n\n\n\n\n9.4.5 Streuungsma√üe zu den Parametern\n\nWie unsicher sind wir uns in den Sch√§tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.\n\n\n\n\n9.4.6 Ungewissheit von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung visualisiert\nAbbildung¬†9.12 stellt die Ungewissheit der Post-Verteilung dar, in dem einige Stichproben aus der Post-Verteilung visualisiert werden.\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\n1010010001000000\n\n\nDie ersten 10 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 100 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 10000006 ‚Ä¶ okay, lassen wir es gut sein7.\n\n\n\n\n\nAbbildung¬†9.12\n\n\n\nEinfacher ist die Visualisierung mit estimate_expectation, s. Abbildung¬†9.13.\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildung¬†9.13: Sch√§tzbereich f√ºr die bedingten mittleren K√∂rpergr√∂√üe, also die Regressionsgerade mit Unsicherheitsintervall\n\n\n\n\n\n\n\n9.4.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe8.\n\n\n\nWelche mittlere Gr√∂√üe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht √ºberschritten?\nWelche mittlere Gr√∂√üe mit Wahrscheinlichkeit von 95% nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?\n\nQuantile:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n  \n\n\n\n50%-PI:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  eti(ci = .5)\n\n\n\n  \n\n\n\n\n\n9.4.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.29.\n\n\n9.4.9 Typischer Bayes-Nutzer in Aktion\n\n\n\n\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.5 Post-Verteilung bedingt auf einen Pr√§diktorwert",
    "text": "9.5 Post-Verteilung bedingt auf einen Pr√§diktorwert\n\n9.5.1 Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m_kung_post, s. Abbildung¬†9.14.\n\n\n\n\n\n\n\n\nAbbildung¬†9.14: F√ºr jeden beliebigen Pr√§diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgew√§hlten Gewichtswerten. Es ist jeweils die Wahrscheinlichkeitsverteilung f√ºr den vorhergesagten Y-Wert dargestellt (hier sind die Verteilungen zu gro√ü dargestellt zur besseren Sichtbarkeit). B: F√ºr jeden beliebigen Gewichtswert (Y) bekommt man eine (auf den jeweiligen X-Wert bedingten) Post-Verteilung.\n\n\n\n\n\n\n\n9.5.2 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?\nEtwas formaler ausgedr√ºckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 &lt;-\n  m_kung_gewicht_c_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. Abbildung¬†9.15.\n\n\nCode\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.15: Post-Verteilung der Gr√∂√üe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\n\nAnalog k√∂nnen wir fragen, wie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.\n50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. Tabelle¬†9.3.\n\n\nCode\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\nTabelle¬†9.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren Gr√∂√üe bei einem Gewicht von 50kg ist weiter ‚Äúrechts‚Äù (Richtung h√∂here Gr√∂√üe) zentriert, s. Abbildung¬†9.16.\n\n\nCode\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.16: Post-Verteilung der mittleren Gr√∂√üe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n\n9.5.3 Lagema√üe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der K√∂rpergr√∂√üe.\nWas ist das 90% PI f√ºr \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %&gt;% \n  eti(ci = .9)\n\n\n\n  \n\n\n\nDie mittlere Gr√∂√üe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#fazit",
    "href": "0900-lineare-modelle.html#fazit",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.6 Fazit",
    "text": "9.6 Fazit\n\n9.6.1 Ausstieg\n\nBeispiel 9.3 (Fassen Sie das Wesentliche zusammen!) Schreiben Sie 5-10 S√§tze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! \\(\\square\\)\n\n\n\n9.6.2 Vertiefung\nMcElreath (2020) bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. Kurz (2021) greift die R-Inhalte von McElreath (2020) auf und setzt sie mit Tidyverse-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen m√∂chte. Gelman et al. (2021) bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einer frequentistischen als auch aus einer Bayes-Perspektive.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.7 Aufgaben",
    "text": "9.7 Aufgaben\n\n9.7.1 Papier-und-Bleistift-Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nmtcars-post2a\nBed-Post-Wskt1\nmtcars-post3a \nregression1a\nregression1b\nRegression2\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\nLikelihood2\ninterpret-koeff\nbed-post-wskt1\n\n\n\n9.7.2 Computer-Aufgaben\n\nPost-befragen1\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-4",
    "href": "0900-lineare-modelle.html#section-4",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.8 ‚Äî",
    "text": "9.8 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKurz, S. (2021). Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#footnotes",
    "href": "0900-lineare-modelle.html#footnotes",
    "title": "9¬† Einfache lineare Modelle",
    "section": "",
    "text": "Da es viele Funktionen sind, bietet es sich an mit Strg-F auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.‚Ü©Ô∏é\n Datenquelle, McElreath (2020).‚Ü©Ô∏é\nWer ist hier f√ºr die Namensgebung zust√§ndig? Besoffen oder was?‚Ü©Ô∏é\noder zumindest besser sichergestellt‚Ü©Ô∏é\nIn manchen Lehrb√ºchern wird \\(\\beta_0\\) auch als \\(\\alpha\\) bezeichnet.‚Ü©Ô∏é\n1e6‚Ü©Ô∏é\nIm Standard beschert uns stan_glm() 4000 Stichproben.‚Ü©Ô∏é\n\\(\\mu\\)‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html",
    "href": "0800-gauss.html",
    "title": "8¬† Gauss-Modelle",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "8¬† Gauss-Modelle",
    "section": "",
    "text": "8.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nein Gau√ümodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n8.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.1 bis 4.3.\n\n\n8.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúModellg√ºte‚Äù\nStatistik1, Kap. ‚ÄúPunktmodelle 2‚Äù\nStatistik1, Abschnitt ‚ÄúNormalverteilung‚Äù\n\n\n\n8.1.5 Ben√∂tigte R-Pakete\nF√ºr rstanarm wird ggf. weitere Software ben√∂tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, m√ºssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio m√ºssen Sie die (ben√∂tigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Modelle berechnen\nlibrary(easystats)  # Statistik-Komfort\nlibrary(DataExplorer)  # Daten verbildlichen\nlibrary(ggpubr)  # Daten verbildlichen\nlibrary(hexbin)  # stat_bin_hex ggplot2\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nAb diesem Kapitel ben√∂tigen Sie das R-Paket rstanarm. \\(\\square\\)\n\n\n\n\n8.1.6 Ben√∂tigte Daten\nWir ben√∂tigen den Datensatz !Kung. Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\n\n\nCode\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nkung &lt;- read.csv(Kung_path) \n\nhead(kung)\n\n\n\n  \n\n\n\nDatenquelle\n Download \n\n\n8.1.7 Einstieg\n\nBeispiel 8.1 (Was war noch mal eine Normalverteilung?) In diesem Kapitel ben√∂tigen Sie ein gutes Verst√§ndnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! \\(\\square\\)\n\n\nBeispiel 8.2 (Was war noch mal eine Posteriori-Verteilung?) In diesem Kapitel befragen wir die Post-Verteilung f√ºr ein normalverteilte Zufallsvariable, n√§mlich die K√∂rpergr√∂√üe der !Kung San. Was war noch mal eine Post-Verteilung und wozu ist sie gut? \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-gro√ü-sind-die-kung-san",
    "href": "0800-gauss.html#wie-gro√ü-sind-die-kung-san",
    "title": "8¬† Gauss-Modelle",
    "section": "8.2 Wie gro√ü sind die !Kung San?",
    "text": "8.2 Wie gro√ü sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. ?fig-kungs.\n\nThe «ÉKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names «ÉKung («ÉXun) and Ju are variant words for ‚Äòpeople‚Äô, preferred by different «ÉKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of «ÉKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\nWir interessieren uns f√ºr die Gr√∂√üe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als kung_erwachsen.\n\n\nCode\nkung_erwachsen &lt;- kung %&gt;% \n  filter(age &gt;= 18)\n\nnrow(kung_erwachsen)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tats√§chlich recht easy, s. Tabelle¬†8.1.\n\n\nCode\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelle¬†8.1: Statistiken der metrischen Variablen im Kung-Datensatz\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\n‚àí0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\n‚àí0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\n‚àí0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\n‚àí2.00\n352.00\n0\n\n\n\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus {DataExplorer}), s. Abbildung¬†8.1.\n\n\nCode\nplot_density(kung_erwachsen)\n\n\n\n\n\n\n\n\nAbbildung¬†8.1: Verteilungen der Variablen im Kung-Datensatz. Gr√∂√üe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n\n\n\n8.2.2 Wir gehen apriori von normalverteilter Gr√∂√üe Der !Kung aus\nForschungsfrage: Wie gro√ü sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also f√ºr den Mittelwert der K√∂rpergr√∂√üe (erwachsene Person1), \\(\\mu\\).\n\n\n\nMensch, Wikimedia Commons2\n\n\nWir sind uns √ºber diesen Mittelwert in der Population nicht sicher3, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178 cm und Streuung von 20 cm, s. Gleichung¬†8.1.\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{8.1}\\]\nGleichung¬†8.1 definiert ein Modell: Unsere Vorstellung der mittleren (‚Äútypischen‚Äù) K√∂rpergr√∂√üe der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.4 In einer echten Untersuchung sollte man einen inhaltlichen Grund f√ºr einen Priori-Wert haben. Oder man w√§hlt ‚Äúschwach informative‚Äù Prioris, wie das {rstanarm} tut: Damit l√§sst man kaum Vorab-Information in das Modell einflie√üen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern bei der K√∂rpergr√∂√üe).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der K√∂rpergr√∂√üen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. Dar√ºber hinaus ist eine Normalverteilung nicht unplausibel.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "8¬† Gauss-Modelle",
    "section": "8.3 Unser Gauss-Modell der !Kung",
    "text": "8.3 Unser Gauss-Modell der !Kung\nüì∫ Teil 1\n\n8.3.1 Modelldefinition\nWir nehmen an, dass die mittleren Gr√∂√üen, \\(\\mu\\), und die tats√§chlichen Gr√∂√üen, \\(h_i\\), normalverteilt sind und \\(\\sigma\\) exponentialverteilt ist (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr den Parameter \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior f√ºr den Parameter \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn Abbildung¬†8.2 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\n\n\n\n\n\n\n(a) Priori der mittleren K√∂rpergr√∂√üe\n\n\n\n\n\n\n\n\n\n\n\n(b) Priori der Sch√§tzungenauigkeit\n\n\n\n\n\n\nAbbildung¬†8.2: Prioris unseres (ersten) Kung-Modells (m_kung)\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDieses Modell hat zwei Parameter, \\(\\mu\\) und \\(\\sigma\\). \\(\\square\\)\n\n\n\n\n8.3.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie K√∂rpergr√∂√üen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})   \\qquad{\\text{Likelihood}}\\]\n\n\n8.3.3 Prioris der Parameter\nDer Mittelwert der K√∂rpergr√∂√üe sei normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)} \\qquad{\\text{Prior}}\\]\nDie Streuung \\(\\sigma\\) der Gr√∂√üen sei exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)} \\qquad{\\text{Prior}}\\]\n\n\n8.3.4 m_kung: fertig!\nJetzt haben wir unser Modell (m_kung) definiert!\nWeil es so sch√∂n ist, schreiben/zeichnen wir es hier noch einmal auf, Gleichung¬†8.2, Abbildung¬†8.3.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) & \\text{Likelihood}  \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) & \\text{Prior} \\\\\n\\sigma &\\sim \\mathcal{E}(1/8) & \\text{Prior}\n\\end{aligned}\n\\tag{8.2}\\]\n\n\n\n\n\n\nAbbildung¬†8.3: Modellschema f√ºr das Modell m_kung\n\n\n\nZur Berechnung von m_kung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich kr√§ftig der Bursche, der soll die Arbeit f√ºr uns tun. Der Golem h√∂rt auf den Namen rstanarm5.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#zuf√§llige-motivationsabschnitt",
    "href": "0800-gauss.html#zuf√§llige-motivationsabschnitt",
    "title": "8¬† Gauss-Modelle",
    "section": "8.4 Zuf√§llige Motivationsabschnitt",
    "text": "8.4 Zuf√§llige Motivationsabschnitt\n\n\n\nGut gemacht!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-gr√∂√üen-modells-m_kung",
    "href": "0800-gauss.html#posteriori-verteilung-des-gr√∂√üen-modells-m_kung",
    "title": "8¬† Gauss-Modelle",
    "section": "8.5 Posteriori-Verteilung des Gr√∂√üen-Modells, m_kung",
    "text": "8.5 Posteriori-Verteilung des Gr√∂√üen-Modells, m_kung\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m_kung6.\n\n\nCode\n1m_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)\n2m41_post &lt;- as_tibble(m_kung)\n3names(m41_post) &lt;- c(\"mu\", \"sigma\")\n\n\n\n1\n\nBayes-Regressionsmodell berechnen\n\n2\n\nModellergebnis in Tabelle umwandeln\n\n3\n\nSch√∂nere Namen f√ºr die Spalten geben\n\n\n\n\nDas Argument refresh = 0 ist nur eine Nebensache, aber es ist praktisch, da es verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdr√ºcke. stan_glm7 ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein ‚Äúrichtiges‚Äù Regressionsmodell. Man k√∂nnte sagen, wir haben eine AV (K√∂rpergr√∂√üe), aber keine UV (keine Pr√§diktoren). Gl√ºcklicherweise k√∂nnen wir auch solche ‚Äúarmen‚Äù Regressionsmodelle formulieren: av ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen m√∂chte, aber keine Pr√§diktoren hat (das soll die 1 symbolisieren). F√ºr das Modell m_kung haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung (defaults) der Prioris von rstanarm zur√ºck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade w√§re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die gemeinsame Posteriori-Verteilung von m_kung, s. Abbildung¬†8.4\n\nFliesendiagrammStreudiagrammHistogramm\n\n\nGemeinsame Post-Verteilung von Mittelwert und Streuung\n\n\nCode\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\n\n\n\nAbbildung¬†8.4: Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m_kung_neue_prioris\n\n\n\n\n\nDa das Modell zwei Parameter hat, k√∂nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen k√∂nnen die Parameter korreliert sein.\nAbbildung¬†8.4 erlaubt uns, f√ºr jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\n\n\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m_kung_neue_prioris, s. Abbildung¬†8.5.\n\n\n\n\n\n\n\n\nAbbildung¬†8.5: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\n\n\n\nUnd hier kommt die Post-Verteilung nur des Mittelwerts.\nNat√ºrlich k√∂nnen wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. Abbildung¬†8.6.\n\n\n\n\n\n\n\n\nAbbildung¬†8.6: Die Post-Verteilung von mu in m_kung_neue_prioris; ein Balkendiagramm bietet sich an.\n\n\n\n\n\n\n\n\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung f√ºr \\(\\mu\\) und eine f√ºr \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, f√ºr die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte f√ºr \\(\\mu\\) und \\(\\sigma\\) klein: Die gro√üe Stichprobe hat die Priori-Werte √ºberstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so k√∂nnen wir interessante Fragen stellen.\n\n\n8.5.1 Hallo, Posteriori-Verteilung\n‚Ä¶ wir h√§tten da mal ein paar Fragen an Sie. üïµ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person gr√∂√üer als 1,55m?\nWelche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?\nWas ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der ‚ÄúBest Guess‚Äù?\n\nAntworten folgen etwas weiter unten.\nAbschlie√üend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), Abbildung¬†8.7.\n\n\n\n\n\n\n\n\nAbbildung¬†8.7: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen f√ºr mu und f√ºr sigma\n\n\n\n\n\n\n\n8.5.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() k√∂nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - √§hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zur√ºck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so: stan_glm(AV ~ UV, data = meine_daten).\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum Gr√∂√üenmittelwert (von Stan √ºbernommen)\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der Gr√∂√üen (von Stan √ºbernommen)\n\n\n8.5.3 Ausgabe von stan_glm()\nWir k√∂nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir k√∂nnen es aber auch komfortabler haben ‚Ä¶ Mit dem Befehl parameters kann man sich die gesch√§tzten Parameterwerte einfach ausgeben lassen (s. Abbildung¬†8.4).\n\n\nCode\nm_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)  # aus Paket rstanarm\n\nparameters(m_kung)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem sch√§tzt den Gr√∂√üenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.76 bis 155.41 sch√§tzt. Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu sp√§ter mehr.\n\n\n\n\n\n\nHinweis\n\n\n\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren ü§ì Wer N√§heres wissen will, findet hier einen Anfang. Au√üerdem sei an McElreath (2020) und Gelman et al. (2021) verwiesen. \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "8¬† Gauss-Modelle",
    "section": "8.6 Wie tickt stan_glm()?",
    "text": "8.6 Wie tickt stan_glm()?\n\n\n Quelle\n\nHier ein paar Kerninfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan f√ºr uns bereit.\nstan_glm() ist f√ºr die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) sch√§tzen, so hat man man ‚Ä¶ eine Regression ohne Pr√§diktor.\nEine Regression ohne Pr√§diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also f√ºr die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\n\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n8.6.1 Sch√§tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die Gr√∂√üen, f√ºr die wir eine Priori-Verteilung annehmen. Au√üerdem w√§hlen wir einen einen Likelihood-Funktion, so dass wir die Likelihood berechnen k√∂nnen. Auf dieser Basis sch√§tzen wir dann die Post-Verteilung. Ich sage sch√§tzen, um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren Sch√§tzungen) einfach mit parameters(modellname) auslesen.\n\n\n8.6.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, k√∂nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_kung:\n\n\nCode\npost_kung &lt;- as_tibble(m_kung)\nhead(post_kung)\n\n\n\n  \n\n\n\nIn einer Regression ohne Pr√§diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss √ºber unsere Sch√§tzwerte zu \\(\\mu\\) (der K√∂rpergr√∂√üe).\n\n√úbungsaufgabe 8.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\n\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist pr√§gnanter\n\npost_kung %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlie√üen, dass die Kung im Schnitt gr√∂√üer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. \\(\\square\\)\n\n\n\n\n\n√úbungsaufgabe 8.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist pr√§gnanter\n\npost_kung %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nOh, diese Hypothese k√∂nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlie√üen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschlie√üen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\n\n\nBeispiel 8.3 (Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell m_kung?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n  \n\n\n\n\n\n\n\n\n√úbungsaufgabe 8.3 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  eti()\n\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\n\n\n\n√úbungsaufgabe 8.4 (Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nm_kung %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nSeeing is believing, s. Abbildung¬†8.8.\n\n\nCode\nm_kung %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nAbbildung¬†8.8: Parameter von m_kung, nur einer: der Intercept\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren K√∂rpergr√∂√üe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\n\n\n\n√úbungsaufgabe 8.5 (Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der ‚ÄúBest Guess‚Äù?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\nparameters(m_kung) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n\n\n\nüèãÔ∏è √Ñhnliche Fragen bleiben als √úbung f√ºr die Lesis. ü§ì\n\n\n8.6.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt f√ºr uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m_kung)\n## Priors for model 'm_kung' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden daf√ºr die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage f√ºr die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht ‚Äúpures Bayes‚Äù, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte w√§ren auch denkbar.\n\n\n\n\n\n\nStandardwerte von stan_glm\n\n\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (f√ºr \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals ‚ÄúStreuung‚Äù, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen. \\(\\square\\)\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu w√§hlen, dass man nicht √ºbergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlie√üen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflie√üen zu lassen und eigene Entscheidungen zu begr√ºnden. H√§ufig sind mehrere Entscheidungen m√∂glich. M√∂chte man lieber vorsichtig sein, weil man wenig √ºber den Gegenstand wei√ü, dann k√∂nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die ‚Äúschwachinformativ‚Äù ist, also nur wenig Priori-Information in das Modell einflie√üen l√§sst.\n\n\n\n\n8.6.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund f√ºr Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu z√§hlen hat. Au√üerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister pr√ºfen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier Durchf√ºhrungen (auch ‚ÄúKetten‚Äù engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist ‚Äúdumm gelaufen‚Äù. An dieser Stelle schauen wir uns die Ketten nicht n√§her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. M√∂chte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit, s. m_kung_1kette.\n\n\nCode\nm_kung_1kette &lt;- stan_glm(height ~ 1, \n                 data = kung_erwachsen, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m_kung_1kette)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "title": "8¬† Gauss-Modelle",
    "section": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte",
    "text": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte\nüì∫ Teil 2\nIm Modell m_kung haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflie√üen, in unserem zweiten Kung-Modell, m_kung_neue_prioris.\n\n8.7.1 m_kung_neue_prioris\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.8 Dieses Mal geben wir die Priori-Werte explizit an, Tabelle¬†8.2.\n\n\nCode\nm_kung_neue_prioris &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = kung_erwachsen)\nparameters(m_kung_neue_prioris)\n\n\n\n\n\n\nTabelle¬†8.2: Parameter von m_kung_neue_prioris mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482\nNormal (178 +- 20)\n\n\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in Tabelle¬†8.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige F√§higkeit im Studium. ü§ì\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m_kung und m_kung_neue_prioris! Was f√§llt Ihnen auf? Nichts? Gut! Tats√§chlich liefern beide Modelle sehr √§hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigerma√üen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gew√§hlt waren.\n\n\n\n\n8.7.2 Posteriori-Verteilung und Parameter plotten\nLeider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zur√ºck.\n\nüë®‚Äçüè´ B√∂ser Golem!\n\n\nü§ñ Beim n√§chsten Mal strenge ich mich mehr an!\n\nDaher m√ºssen wir die Ausgabe des Stan-Golemns erst in eine sch√∂ne Tabelle umwandeln:\n\n\nCode\nm_kung_neue_prioris_tibble &lt;-\n  as_tibble(m_kung_neue_prioris)\n\nhead(m_kung_neue_prioris_tibble)\n\n\n\n  \n\n\n\nAu√üerdem ist der Name der ersten Spalte eigentlich unzul√§ssig, da Spaltennamen in R nicht mit Sonderzeichen anfangen d√ºrfen (sondern mit Buchstaben). Daher m√ºssen wir den Namen mit ‚ÄúSamthandschuhen‚Äù anpacken. Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln m√ºssen, s. die folgende Syntax.\n\nMit {ggpubr}Mit {ggplot}\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  gghistogram(x = \"`(Intercept)`\")  # Aus dem Paket \"ggpubr\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nAls Ausblick: Ein Vergleich mehrerer Priori-Werte w√§re auch n√ºtzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gew√§hlten Priori-Werte zu √ºberzeugen.\n\n\n8.7.3 Welche K√∂rpergr√∂√üen erwartet unser Modell\nBisher haben wir untersucht, wie die Verteilung der mittleren K√∂rpergr√∂√üen, \\(\\mu\\), laut unserem Modell aussehen k√∂nnte; wir haben uns also mit der Post-Verteilung von \\(\\mu\\) besch√§ftigt. Wir k√∂nnten aber auch an der Frage der Verteilung der tats√§chlichen K√∂rpergr√∂√üen, \\(h_i\\), laut Modell, interessiert sein: Wie gro√ü sind sie denn, die !Kung, laut unserem Modell?\nWie wir wissen, liefert unser Stan-Golem eine Stichproben-Postverteilung. Wenn wir das Ergebnisobjekt unserer Analyse, m_kung in eine Tabelle (Tibble) umwandeln und (die ersten paar Zeilen) betrachen, sehen wir diese Stichproben:\n\n\nCode\nm_kung |&gt; as_tibble() |&gt; head()\n\n\n\n  \n\n\n\nLaut unserem Modell sind die K√∂rpergr√∂√üen, \\(h_i\\), normalverteilt mit \\(\\mu\\) und \\(\\sigma\\). \\(\\mu\\) wird von Stan, der in Begriffen der Regressionsanalyse denkt, schn√∂de als (Intercept) bezeichnet. Wir k√∂nnten jetzt also f√ºr jede Zeile eine Normalverteilung berechnen. Und daraus zuf√§llig eine Zahl ziehen. Damit h√§tten wir dann unsere Verteilung von K√∂rpergr√∂√üen laut Modell. Diese Verteilung nennt man auch Posterior-Pr√§diktiv-Verteilung. Pr√§diktiv daher, weil sie die Werte der K√∂rpergr√∂√üen ‚Äúvorhersagt‚Äù.\nWir k√∂nnen uns diese Verteilung auch komfortabel von R ausgeben lassen, s. Abbildung¬†8.9.\n\nCode\npp_check(m_kung)\npp_check(m_kung, \"stat\")\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Die dunkle, dicke Dichtekurve zeigt die tats√§chliche Verteilung der K√∂rpergr√∂√üen im Datensatz. Die hellen, leichten Dichtekurven zeigen die Verteilungen laut der Post-Verteilung unseres Modells.\n\n\n\n\n\n\n\n\n\n\n\n(b) Der wahre Wert einer Test-Statistik (T), hier der Mittelwert der K√∂rpergr√∂√üen, wird mit der Verteilung der K√∂rpergr√∂√üen in Bezug gesetzt.\n\n\n\n\n\n\n\nAbbildung¬†8.9: Die Posterior-Pr√§diktiv-Verteilung: Die Verteilung der tats√§chlichen K√∂rpergr√∂√üen auf Basis der Post-Verteilung. Unser Modell stellt die tats√§chliche Verteilung ganz gut nach.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "8¬† Gauss-Modelle",
    "section": "8.8 Fazit",
    "text": "8.8 Fazit\n\n\n8.8.1 Zusammenfassung\nWir haben die Posteriori-Verteilung f√ºr ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Pr√§diktoren, betrachtet. Die Zielvariable, K√∂rpergr√∂√üe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. F√ºr \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung f√ºr \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n8.8.2 Botschaft von einem Statistiker\n\n\n\nüß° Bleiben Sie dran!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "href": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "title": "8¬† Gauss-Modelle",
    "section": "8.9 Vertiefung: Wahl der Priori-Werte",
    "text": "8.9 Vertiefung: Wahl der Priori-Werte\nüèéÔ∏è Dieser Abschnitt ist eine VERTIEFUNG und nicht pr√ºfungsrelevant. üèé\n\n8.9.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\n\nüí≠ Was denkt der Golem (m_kung) apriori von der Gr√∂√üe der !Kung?\nü¶æ Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voil√†:\n\n\nCode\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MW¬±3SD\",\n       x = \"Gr√∂√üe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\n\n\n\n\nQuellcode\n\n\n8.9.2 Priori-Werte pr√ºfen mit der Priori-Pr√§diktiv-Verteilung\n\nDie Priori-Pr√§diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo k√∂nnen wir pr√ºfen, ob die Priori-Werte vern√ºnftig sind.\n\nDie Priori-Pr√§diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Gr√∂√üenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\n\nCode\nanteil_gro√üer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_gro√üer_kung\n\n\n\n  \n\n\n\nü§î Sehr gro√üe Buschleute? 17 Prozent sind gr√∂√üer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsl√§ufig ein schlechter Prior sein.\n\n\n8.9.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n\n\n\n\n8.9.4 Extrem vage Priori-Verteilung f√ºr die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\n\n\n\n\nDie Streuung der Gr√∂√üen ist weit:\n\n\nCode\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nü§î Das Modell geht apriori von ein paar Prozent Menschen mit negativer Gr√∂√üe aus. Ein Haufen Riesen üëπ werden auch erwartet.\nü§Ø Vage (flache, informationslose, ‚Äúneutrale‚Äù, ‚Äúobjektive‚Äù) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "8¬† Gauss-Modelle",
    "section": "8.10 Aufgaben",
    "text": "8.10 Aufgaben\n\n8.10.1 Papier-und-Bleistift-Aufgaben\n\n\nexp-tab\nexp-tab2\nnorms-sd\nsmall-wide-normal\nexp1\ndistros\nmtcars-post_paper\ngroesse03\npupil-size2\ngroesse04\nReThink4e2\nPriorwahl1\n\n\n\n8.10.2 Aufgaben, f√ºr die man einen Computer ben√∂tigt\n\nstan_glm01\nReThink4e1\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "8¬† Gauss-Modelle",
    "section": "8.11 ‚Äî",
    "text": "8.11 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#footnotes",
    "href": "0800-gauss.html#footnotes",
    "title": "8¬† Gauss-Modelle",
    "section": "",
    "text": "Der Einfachheit halber gehen wir davon aus, dass M√§nner und Frauen im Schnitt gleich gro√ü sind.‚Ü©Ô∏é\nBildquelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, 3.0‚Ü©Ô∏é\nDarum machen wir hier ja die ganz Show!‚Ü©Ô∏é\nDer Autor des zugrundeliegenden Lehrbuchs, Richard McElreath, gibt 178cm als seine K√∂rpergr√∂√üe an.‚Ü©Ô∏é\nHey, ich habe ihn diesen Namen nicht gegeben.‚Ü©Ô∏é\nm wie Modell und 4, weil das Modell in Kapitel 4 von McElreath (2020) in √§hnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.‚Ü©Ô∏é\naus dem R-Paket rstanam, das zuvor installiert und gestartet sein muss, bevor Sie den Befehl nutzen k√∂nnen‚Ü©Ô∏é\nHey Stan, los, an die Arbeit!‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html",
    "href": "1050-Schaetzen-Testen.html",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "10.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen‚Ä¶\n\nden Unterschied zwischen dem Sch√§tzen von Modellparametern und dem Testen von Hypothesen erl√§utern\nVor- und Nachteile des Sch√§tzens und Testens diskutieren\nDas ROPE-Konzept erl√§utern und anwenden\nDie G√ºte von Regressionsmodellen einsch√§tzen und berechnen\n\n10.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an Kruschke (2018).\n\n10.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 2‚Äù\n\n10.1.5 R-Pakete\nIn diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n10.1.6 Ben√∂tigte Daten: Pinguine\nWir ben√∂tigen in diesem Kapitel den Datensatz zu Pinguinen: penguins.\nSie k√∂nnen den Datensatz penguins entweder via dem Pfad importieren.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \nOder via dem zugeh√∂rigen R-Paket.\n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\nBeide M√∂glichkeit sind okay.\n\n10.1.7 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\n‚ÄúLernen f√ºr die Klausur bringt etwas!‚Äù\n‚ÄúWie viel bringt Lernen f√ºr die Klausur?‚Äù\n\n\nBeispiel 10.1 Diskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sch√§tzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#sch√§tzen-oder-testen",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.2 Sch√§tzen oder Testen?",
    "text": "10.2 Sch√§tzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen testen: ‚ÄúDie Daten widerlegen die Hypothese (nicht)‚Äù\n\nParameter sch√§tzen: ‚ÄúDer Effekt von X auf Y liegt zwischen A und B‚Äù.\n\n\n10.2.1 Hypothesen testen\nHypothesen testende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 10.2 (‚ÄúLernen erh√∂ht den Pr√ºfungserfolg‚Äù) Die Hypothese Lernen erh√∂ht den Pr√ºfungserfolg kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. \\(\\square\\)\n\nDas Testen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\nüü• Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.\nüü¢ Die Daten unterst√ºtzen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.\n‚ùì Die Datenlage ist unklar; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen pr√ºfen ist bin√§r in dem Sinne, dass sie zu ‚ÄúSchwarz-Wei√ü-Ergebnissen‚Äù f√ºhren (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine g√§ngige Variante des Hypothesen testen1 ist das Testen der Hypothese ‚Äúkein Effekt‚Äù (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n10.2.2 Beispiele f√ºr Nullhypothesen\n\n‚ÄúLernen bringt nichts‚Äù\n‚ÄúFrauen und M√§nner parken gleich schnell ein‚Äù\n‚ÄúEs gibt keinen Zusammenhang von Babies und St√∂rchen‚Äù\n‚ÄúFr√ºher war es auch nicht besser (sondern gleich gut)‚Äù\n‚ÄúBei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern‚Äù (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterst√ºtzen kann, da es die Komplexit√§t reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht best√§tigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann, hat gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt (Popper, 2013). Schlagend ist das Beispiel zur Hypothese ‚ÄúAlle Schw√§ne sind wei√ü‚Äù. Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. Schlie√ülich ist es m√∂glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben. 2 Umgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverl√§ssiger, repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als auch widerlegt werden k√∂nnen (Kruschke, 2018; Morey & Rouder, 2011). \\(\\square\\)\n\n\n\n10.2.3 Parameter sch√§tzen\nBeim Parameter sch√§tzen untersucht man, wie gro√ü ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein ‚Äúja/nein‚Äù, was beim Hypothesen testen der Fall ist.\nBeim Parameter sch√§tzen gibt es zwei Varianten:\n\n‚ö´Ô∏è Punktsch√§tzung: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein ‚ÄúBest Guess‚Äù\nüìè Bereichssch√§tzung: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Sch√§tzen von Parameterns auch wie einen Hypothesentest verstehen: Ist ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 10.3 Wie gro√ü ist der Sch√§tzbereich f√ºr den Effekt des Parameter ‚ÄúGeschlecht‚Äù auf das Gewicht von Pinguinen? Anders gefragt: Um welchen Wert sind m√§nnliche Tiere im Schnitt schwerer als weibliche Tiere?\n\nCodedata(penguins, package = \"palmerpenguins\")\npenguins_nona &lt;-\n  penguins |&gt; drop_na(sex, body_mass_g)  # keine fehlenden Werte\n\nm_penguins_sex &lt;- \n  stan_glm(body_mass_g ~ sex, data = penguins_nona)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3862.94\n(3757.82, 3969.47)\n100%\n1.000\n4246\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n682.94\n(528.12, 833.63)\n100%\n1.000\n4468\nNormal (0.00 +- 4020.19)\n\n\n\n\n\nGrob gesagt sind m√§nnliche Tiere ca. 500 g bis 800 g schwerer als weibliche Tiere im Schnitt, laut unserem Modell. \\(\\square\\)\n\n\nBeispiel 10.4 (Parametersch√§tzen als Nullhypothesentest) ¬†\n\nForschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nTheorem¬†10.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\nTheorem 10.1 (Nullhypothesentest) \\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0\\quad \\square\\]\n\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nCodem1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\n\nDann z√§hlen wir einfach den Anteil der Stichproben in der Post-Verteilung f√ºr die UV sexmale, die einen Wert gr√∂√üer Null aufweisen:\n\nCodem1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr sexmale, dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht (das weibliche Tiere schwerer w√§ren). Damit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der Parametersch√§tzung ist die Nuanciertheit des Ergebnisses, die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.3 ROPE: Bereich von ‚Äúpraktisch Null‚Äù",
    "text": "10.3 ROPE: Bereich von ‚Äúpraktisch Null‚Äù\nüì∫ Teil 2\nNullhypothesen sind fast immer falsch, s. Abbildung¬†10.1.\n\n\n\n\n\n\n\nAbbildung¬†10.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman et al., 2021)\n\n\n10.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest m√∂glich ist.3\nEin anderer Grund ist vermutlich, ‚Ä¶ wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke, 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n10.3.2 ‚ÄúPraktisch‚Äù kein Unterschied: Das Rope-Konzept\nüì∫ ROPE-Video\n\nBeispiel 10.5 (Beispiele f√ºr ROPE) Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens \\(d=100\\)‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als ‚Äúpraktisch gleich‚Äù, ‚Äúpraktisch kein Unterschied‚Äù bzw. vernachl√§ssigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g ‚Äúvernachl√§ssigbar wenig‚Äù ist.\nEine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umsatzunterschied von 100k Euro ‚Äúpraktisch irrelevant‚Äù sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese (bzw. ‚ÄúPraktisch-Null-Hypothese‚Äù): \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt pr√ºfen wir, ob ein ‚ÄúGro√üteil‚Äù der Posteriori-Stichproben im Rope liegt. Unter ‚ÄúGro√üteil‚Äù wird h√§ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGro√üteil liegt innerhalb von Rope \\(\\rightarrow\\) Annahme der Nullhypothese ‚Äúpraktisch kein Effekt‚Äù, \\(H_0\\)\n\nGro√üteil liegt au√üerhalb von Rope \\(\\rightarrow\\) Ablehnung der Nullhypothese ‚Äúpraktisch kein Effekt‚Äù, \\(H_0\\)\n\nAnsonsten \\(\\rightarrow\\) keine Entscheidung\n\nMit ‚ÄúGro√üteil‚Äù meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n10.3.3 Vernachl√§ssigbarer Regressionseffekt\nKruschke (2018) schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als ‚Äúpraktisch Null‚Äù zu bezeichnen:\nWenn eine Ver√§nderung √ºber ‚Äúpraktisch den ganzen Wertebereich‚Äù von \\(x\\) nur einen vernachl√§ssigbaren Effekt auf \\(y\\) hat. Ein vernachl√§ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der ‚Äúpraktisch ganze Wertebereich‚Äù von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Ver√§nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) f√ºr z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±5% der SD der AV. \\(\\square\\)\n\n\n\n10.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildung¬†10.2: Die Entscheidungsregeln zum ROPE illustiert (Kruschke, 2018).\n\n\n\n\nAbbildung¬†10.2 illustriert die Entscheidungsregel zum ROPE f√ºr mehrere Situationen (Kruschke, 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.\n\n10.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (m_penguins_species).\n\nCodem_penguins_species &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\n\nDen Rope berechnet man mit rope(model).\n\nCoderope(m_penguins_species)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir k√∂nnen daher f√ºr diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.\nAber: Gentoo liegt zu 0% im Rope. F√ºr Gentoo k√∂nnen wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®\n\n10.3.6 Visualisierung unserer Rope-Werte, m_penguins_species\nEin Gro√üteil der Posteriori-Masse von m_penguins_species liegt nicht innerhalb des Rope. Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. Abbildung¬†10.3.\n\nCoderope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\nAbbildung¬†10.3: Rope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die ‚ÄúBerge‚Äù der Posteriori-Verteilung f√ºr Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir k√∂nnen das Nullhypothese f√ºr Chinstrap nicht verwerfen, aber auch nicht best√§tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom ‚Äúblauen Fluss‚Äù des Rope: Gentoo liegt au√üerhalb des Rope. Es gibt einen ‚Äúsubstanziellen‚Äù Unterschied, gr√∂√üer als das ROPE. Wir verwerfen die ‚ÄúPraktisch-Null-Hypothese‚Äù in diesem Fall.\n\n10.3.7 Finetuning des Rope\nWir k√∂nnen festlegen, was wir unter ‚Äúpraktischer √Ñquivalenz‚Äù verstehen, also die Grenzen des Ropes ver√§ndern. Sagen wir, 100 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. Abbildung¬†10.4.\n\nCoderope(m_penguins_species, range = c(-100, 100))\nplot(rope(m_penguins_species, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†10.4: ROPE mit selber eingestellter Grenze von ¬±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:\n\nCoderope(m_penguins_species, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht f√ºr ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n10.3.8 Beantwortung der Forschungsfrage\nF√ºr die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. F√ºr Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellg√ºte",
    "href": "1050-Schaetzen-Testen.html#modellg√ºte",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.4 Modellg√ºte",
    "text": "10.4 Modellg√ºte\n\n10.4.1 Wozu Modellg√ºte?\nHat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, m√∂chte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. Diese Kennwerte zielen z.B. darauf ab, wie pr√§zise die Aussagen des Modells sind. Je pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich. Bei einer Parametersch√§tzung erh√§lt man auch Informationen zur Pr√§zision der Sch√§tzung: Ist der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa). Allerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n10.4.2 Modellg√ºte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt. - H√∂here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erkl√§rt. \\(R^2\\) wird normalerweise auf Basis eines Punktsch√§tzers definiert. Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor. Daher ist es w√ºnschenswert, diese Information in \\(R^2\\) einflie√üen zu lassen: Bayes-R-Quadrat.\nM√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R^22\\) ausgeben lassen, s. Abbildung¬†10.5.\n\nCodem_penguins_species_r2 &lt;-\n  m_penguins_species %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m_penguins_species_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung¬†10.5: Die Verteilung von R-Quadrat im Modell m_penguins_species\n\n\n\n\n\\(R^2\\) und \\(\\sigma\\) sind negativ assoziert: In einem Datensatz mit mit hohem \\(R^2\\) ist \\(\\sigma\\) gering und umgekehrt. Beide Koeffizienten berechen sich auf Basis der Vorhersagefehler.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.5 Fazit",
    "text": "10.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. M√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.6 Aufgaben",
    "text": "10.6 Aufgaben\n\n10.6.1 Papier-und-Bleistift-Aufgaben\n\nrope-luecke\npenguins-rope\nWskt-Schluckspecht2\npenguins-stan-01a\nrope-regr\nrope1\nrope2a\nrope3a\npenguins-stan-04a\nstan_glm01a\npenguins-regr02a\npenguins-stan-02a\npenguins-stan-05a\n\n10.6.2 Computer-Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope2\nrope3\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter Values in Bayesian Estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270‚Äì280. https://doi.org/10.1177/2515245918771304\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes Factor Approaches for Testing Interval Null Hypotheses. Psychological Methods, 16(4), 406‚Äì419. https://doi.org/10.1037/a0024377\n\n\nPopper, K. (2013). Logik Der Forschung (H. Keuth, Hrsg.). Akademie Verlag. https://doi.org/10.1524/9783050063782",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#footnotes",
    "href": "1050-Schaetzen-Testen.html#footnotes",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "vor allem in der Frequentistischen Statistik‚Ü©Ô∏é\nTats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan‚Ü©Ô∏é\nMittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.‚Ü©Ô∏é\n89 ist die n√§chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. Damit ist 95 hier eine ‚Äúmagic number‚Äù, ein Defacto-Standard ohne hinreichende Begr√ºndung. Um darauf hinzuweisen, benutzen einige Forschis mit √§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html",
    "href": "1000-metrische-AV.html",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "",
    "text": "11.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen‚Ä¶\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme √ºbersetzen\ntypische Forschungsfragen auswerten\n\n11.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman et al. (2021), Kap. 7 und 10.\n\n11.1.4 Vorbereitung im Eigenstudium\nFrischen Sie Ihr Wissen in den Grundlagen der einfachen und multiplen Regression (inkl. Interaktionseffekte) auf. Dazu sind z.B. folgende Literaturstellen geeignet.\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\nStatistik1, Kap. ‚ÄúGeradenmodelle 2‚Äù\n\n11.1.5 R-Pakete\nIn diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n11.1.6 Ben√∂tigte Daten\nWir ben√∂tigen in diesem Kapitel folgende Datens√§tze: kidiq, penguins.\n\n11.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\nCodedata(\"kidiq\", package = \"rstanarm\")\n\n\nAlternativ k√∂nnen Sie die Daten hier herunterladen.\n Download \n\n11.1.6.2 penguins\n\nSie k√∂nnen den Datensatz penguins entweder via dem Pfad importieren oder via dem zugeh√∂rigen R-Paket. Beide M√∂glichkeit sind okay.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\n\n11.1.7 Einstieg\n\nBeispiel 11.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, m√ºssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 11.2 (Was war noch einmal die Interaktion?) Erk√§ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n11.1.8 √úberblick\nWenn Sie die Skalenniveaus wissen, k√∂nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und √§hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, ‚Ä¶) lernen m√ºssen. Au√üerdem ist die Regressionsanalyse (f√ºr viele Situationen) die beste Heransgehensweise, da sie viele M√∂glichkeiten f√ºr Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels g√§ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. Nat√ºrlich w√ºrzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-K√ºche. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "href": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.2 Taxonomie von Forschungsfragen",
    "text": "11.2 Taxonomie von Forschungsfragen\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus. Im Folgenden sind f√ºr die UV(s) nominale sowie metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind ebenfalls erlaubt.\nWir untersuchen in diesem Kapitel h√§ufig verwendete Arten von Forschungsfragen mittels Regressionsanalysen. F√ºr jede Variante ist zumeist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abh√§ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabh√§ngige Variable (querschnittlich)\n\nb: bin√§re Variable\n\nx: metrische unabh√§ngige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-b",
    "href": "1000-metrische-AV.html#y-b",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.3 y ~ b\n",
    "text": "11.3 y ~ b\n\n\n11.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im √∂ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufw√§ndigen Studie die Intelligenz vieler Kinder gemessen. Zus√§tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, ‚ÄúRisikofaktoren‚Äù f√ºr geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nIst der mittlere IQ-Wert (kid_score) von Kindern, deren jeweilige Mutter √ºber einen Schlusabschluss (mom_hs, \\(x=1\\)) verf√ºgt h√∂her, als bei Kinderen, deren jeweilige Mutter nicht √ºber einen Schulabschluss verf√ºgt (\\(x=0\\))? (ceteris paribus)4.\n\nDie Modellformel zur Forschungsfrage lautet: y ~  b bzw. kid_iq ~ mom_hs.\nFormaler ausgedr√ºckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (Theorem¬†11.1).\n\nTheorem 11.1 (Hypothese f√ºr ungleiche Mittelwerte) \\[H_A: \\mu_{x=0|M} \\ne \\mu_{x=1|M}\\quad \\square\\]\n\nIn Worten: ‚ÄúDer mittlere IQ-Wert f√ºr Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen ist h√∂her als in der Gruppe von Kindern, deren M√ºtter √ºber keinen Schulabschluss verf√ºgen‚Äù. Zu beachten ist, dass sich eine Population immer auf Parameterwerte bezieht, also auf die Population, nicht auf die Statistiken der Stichprobe.\nDie zugeh√∂rige Nullhypothese lautet:\n\\[H_0: \\mu_{x=1|M} = \\mu_{x=0|M}\\quad \\square\\]\n\n11.3.2 Modell\nDie Regressionsformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in Abbildung¬†11.1 dargestellt. Y hat, laut unserem Modell, zwei Ursachen:\n\nmom_hs (b)\nu, das steht f√ºr ‚Äúunbekannt‚Äù5\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.1: DAG f√ºr kid_iq ~ mom_hs\n\n\n\n\n\nCodedata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nDer Einfachheit halber √ºbernehmen wir die Prioriwerte von Stan, s. Listing¬†11.1.\n\n\n\nListing¬†11.1: Standard-Prioriwerte f√ºr m10.1, von Stan vergeben\n\nCodeprior_summary(m10.1)\n## Priors for model 'm10.1' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 87, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 87, scale = 51)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = 0, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 0, scale = 124)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.049)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\n\n\nDie komplette Modellspezifikation ist in Gleichung¬†11.1 aufgef√ºhrt.\n\\[\\begin{align*}\n\\text{kid score}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{Lineares Modell} \\\\\n\\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{Prior Regressionsgewicht} \\\\\n\\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{Prior Vorhersageg√ºte}\n\\end{align*} \\tag{11.1}\\]\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. Tabelle¬†11.1.\n\n\n\nTabelle¬†11.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt, da meistens nicht von hohem Interesse)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\n\n11.3.3 Interpretation der Koeffizienten\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren M√ºtter √ºber keinen Schulabschluss (mom_hs = 0) verf√ºgen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit M√ºtter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit M√ºtter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die Sch√§tzung (Vorhersage) ist bzw. wie stark Pr√§diktor (UV) und Kriterium (AV) zusammenh√§ngen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tats√§chlichen IQ-Wert des Kindes (\\(y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n11.3.4 y ~ g als Mittelwertsdifferenz\nEin lineares Modell der Art y ~ g kann man als Berechnung des Unterschieds im Mittelwert von y zwischen beiden Gruppen (g0 vs.¬†g1) verstehen.\n\nüë®‚Äçüè´ Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll hei√üen kid_score_avg. An die Arbeit!\n\n\nü§ñ Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nCodekidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von M√ºttern mit Abschluss.\n\n\n\nIn Abbildung¬†11.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt, auf Basis des Datensatzes kidiq.\n\nCodeestimate_relation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.2: Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen, haben im Mittel einen h√∂heren Intelligenztestwert, laut dem vorliegenden Modell. Die Regressionsgerade ist als durchgezogene Linie dargestellt. Die Mittelwerte pro Gruppe als Punkte und als gestrichelte, horizontale Linie.\n\n\n\n\n\n11.3.5 Rope\nPr√ºfen wir mit rope(m10.1), ob der Effekt der UV (Unterschied zwischen den Gruppen) ‚Äúpraktisch Null‚Äù ist; dazu nutzen wir das ROPE-Verfahren.\n\nCoderope(m10.1)\n\n\n\n\n\n\n\n\n\n\nDas Ergebnis zeigt uns, dass es 0% √úberlappung vom Rope und dem 95%-HDI (der Posterior-Verteilung) gibt.\nFazit: Wir verwerfen die Praktisch-Null-Hypothese. Adios! Abbildung¬†11.3 visualisiert die Erstreckung der Posteriori-Verteilung (und des 95%-HDI) sowie des Rope.\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.1) %&gt;% plot()\n\n\n\n\n\n\nAbbildung¬†11.3: Rope und HDI √ºberlappen nicht. Wir verwerfen die Praktisch-Null-Hypothese.\n\n\n\n11.3.6 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation ‚Äì Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das pr√ºft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nAlternativ zum t-Test kann man ‚Äì unabh√§ngig, ob man Frequentistisch oder Bayesianisch unterwegs ist ‚Äì mit einer Regression vom Typ y ~ b das in etwa gleiche Ergebnis erreichen.7\n\n11.3.7 Antwort auf die Forschungsfrage\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nCodem10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # sch√∂nere Namen\n\n\n\n\nHier sind die ersten paar Zeilen, s. Tabelle¬†11.2.\n\n\n\nTabelle¬†11.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n76.1\n12.8\n19.7\n\n\n72.9\n17.5\n20.5\n\n\n79.0\n11.7\n20.5\n\n\n75.7\n13.7\n20.6\n\n\n77.0\n12.6\n20.0\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir zur √úbung ein 95%-PI von Hand; komfortabler geht es mit eti(m10.1), s. Tabelle¬†11.1.\n\nCodepi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlie√üend die Posteriori-Verteilung, s. Abbildung¬†11.4.\n\nCodeplot(eti(m10.1))\n\n\n\n\n\n\nAbbildung¬†11.4: Das 95% ETI zum (statistischen) Effekt des m√ºtterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem ‚ÄúEffekt‚Äù zu sprechen, l√§sst in den meisten K√∂pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang. F√ºr eine Kausalaussage braucht man ein Argument, etwa einen Verweis auf bestehende Studien oder eine Theorie.\n\n\n\n\n\n\n\n\n\n\n11.3.8 Vertiefung: Toleranzbereich\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\nBerechnet man ein Regressionsmodell mit stan_glm (ü§ñüòÅ), dann zieht man dabei Zufallszahlen üé≤. Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zuf√§llig. Das erkl√§rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen k√∂nnen.\nUm zu pr√ºfen, ob Ihre Ergebnisse ‚Äú√§hnlich genug‚Äù oder ‚Äúinnerhalb eines Toleranzbereichs‚Äù sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nGr√∂√üe des Toleranzbereichs\n\n\n\nDie Gr√∂√üe des relativen Toleranzbereichs ist in is_in_toleranzce() auf 5% festgelegt. Das hei√üt, ein Unterschied von 5% zwischen einem Referenzwert (dem ‚Äúwahren‚Äù Wert) und Ihrem Wert ist okay, also im Toleranzbereich. Au√üerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der gr√∂√üere der beiden Werte gilt. \\(\\square\\)\n\n\nWenn Sie diese Funktion nutzen wollen, m√ºssen Sie zun√§chst das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN) und dann wie gewohnt starten.\n\nCodelibrary(remotes)  # dieses Paket k√∂nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\nlibrary(prada)\n\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der ‚Äúrichtige‚Äù oder ‚Äúwahre‚Äù Wert (oder schlicht der Wert einer Musterl√∂sung) f√ºr \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nCodeis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. ‚úÖ",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b",
    "href": "1000-metrische-AV.html#y-x-b",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.4 y ~ x + b\n",
    "text": "11.4 y ~ x + b\n\n\n11.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b bzw. kid_score ~ mom_iq + mom_hs.\nDie Hypothesen lauten:\n\nDer Schulabschluss der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momhs} &gt; 0\\).\nDer IQ der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momiq} &gt; 0\\).\n\nDer Kausalgraph8 zur Modellformel sieht aus in Abbildung¬†11.5 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) Einfl√ºsse, b und u, wobei u f√ºr ‚Äúunbekannt‚Äù steht, also f√ºr alle sonstigen Einfl√ºsse.9\n\n\n\n\n\n\n\nAbbildung¬†11.5: DAG f√ºr y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle Tabelle¬†11.3 dargestellt.\n\nCodedata(\"kidiq\")  # Paket rstanarm, alternativ √ºber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\nTabelle¬†11.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n11.4.2 1 metrischer Pr√§diktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. Tabelle¬†11.4.\n\nCodem10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\n\nTabelle¬†11.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. Abbildung¬†11.6.\n\nCodekidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildung¬†11.6: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. Abbildung¬†11.7.\n\nCodeplot(estimate_relation(m10.2))\n\n\n\n\n\n\nAbbildung¬†11.7: Die gesch√§tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder f√ºr verschiedene IQ-Werte der M√ºtter. Vergleicht man Teilpopulationen von M√ºttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n11.4.3 Beide Pr√§diktoren, m10.3\n\nBerechnen wir als n√§chstes ein Modell mit beiden Pr√§diktoren: kid_score ~ mom_hs + mom_iq, s. Tabelle¬†11.5.\n\nCodem10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\nTabelle¬†11.5: Parameter des Modells m10.3 (ohne sigma; ETI-Intervalle)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktsch√§tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\nCodecoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##       25.74        0.57        6.04\n\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nM√∂chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\nCodecoef(m10.3)[3]\n## mom_hs \n##      6\n\n\nAber nat√ºrlich ist es m√∂glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. Abbildung¬†11.8.\n\nCodekidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\npred &lt;- estimate_relation(m10.3a)\nplot(pred)\n\n\n\n\n\n\nAbbildung¬†11.8: Der Effekt von sowohl m√ºtterlicher Intelligenz als auch m√ºtterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann sch√§tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum m√ºtterlichen Schulabschluss: Vergleicht man Kinder von M√ºttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur m√ºtterlichen IQ: Vergleicht man Kinder von M√ºttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n11.4.4 Antwort auf die Forschungsfrage\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 1.6 bis 10.1 IQ-Punkten, laut unserem Modell. Der Effekt des m√ºtterlichen IQs wird auf 0.5 bis 0.7 gesch√§tzt (95%-ETI). Da f√ºr beide UV die Null nicht im Intervall plausibler Werte liegt, kann ein Null-Effekt (die exakte Nullhypothese) abgelehnt werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b-xb",
    "href": "1000-metrische-AV.html#y-x-b-xb",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.5 y ~ x + b + x:b\n",
    "text": "11.5 y ~ x + b + x:b\n\n\n11.5.1 Forschungsfrage und Modelldefinition\n\nGibt es einen Interaktionseffekt zwischen m√ºtterlichem Schulabschluss und m√ºtterlichem IQ (auf den IQ-Wert des Kindes)?\n\nAu√üerdem ist man vermutlich auch an den Effekten der beiden UV auf die AV interessiert; diese Fragen haben wir im letzten Abschnitt untersucht (und greifen sie daher nicht noch mal ausf√ºhrlich auf).\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b. Der Einfachheit halber √ºbernehmen wir wieder die Prioris wie vom R-Paket rstanarm bereitgestellt.\nDer DAG zur Modellformel sieht aus in Abbildung¬†11.9 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†11.9: DAG f√ºr y ~ x + b + x:b\n\n\n\n\n\n11.5.2 Interaktion zur Modellformel hinzuf√ºgen\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. Listing¬†11.2, Abbildung¬†11.10 und Tabelle¬†11.6.\n\n\n\nListing¬†11.2: Die Modelldefition von m10.4 mit stanglm\n\nCodem10.4 &lt;- \n  stan_glm(kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\nIn der Regressionsformel sieht man, dass ein zus√§tzlicher Parametern, eben der Interaktionseffekt, in das Modell aufgenommen wurde.\n\n\n\nTabelle¬†11.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.68\n(-37.44, 15.92)\n77.12%\n1.000\n1338\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.000\n1340\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n50.36\n(21.58, 80.70)\n99.98%\n1.001\n1311\nNormal (0.00 +- 124.21)\n\n\nmom_iq:mom_hs\n-0.47\n(-0.79, -0.17)\n99.88%\n1.001\n1293\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_relation(m10.4) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung¬†11.10.\n\n\n\n\n\n\n\nAbbildung¬†11.10: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt f√ºr diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n11.5.3 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Sch√§tzwerte f√ºr Kinder mit M√ºtter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit M√ºttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten f√ºr mom_iq zwischen M√ºtter mit bzw. ohne Schulabschluss.\nF√ºr beide Gruppen, mom_hs=0 und mom_hs=1 gilt folgende Regressionsformel, s. Gleichung¬†11.2.\n\\[\\text{kid score} = \\beta_0 + \\beta_1 \\cdot \\text{mom hs} + \\beta_2 \\cdot \\text{mom iq} + \\beta_3 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.2}\\]\n\\(\\beta_3\\) gibt die St√§rke des Interaktionseffekts an.\nAuf Errisch schreibt mit Gleichung¬†11.2 so (s. Listing¬†11.2):\nkid_score ~ mom_iq + mom_hs + mom_hs:mom_iq.\nDer Doppelpunkt zwischen mom_hs und mom_iq steht f√ºr den Interaktionseffekt der beiden Variablen.\nTr√§gt man die Werte der Koeffizienten (\\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\)) ein, so erh√§lt man Gleichung¬†11.3.\n\\[\\text{kid score} = -10.7 + 50.4 \\cdot \\text{mom hs} + 1  \\cdot \\text{mom iq} + -0.5 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.3}\\]\nTeilen wir die Regressionsformel einmal auf die beiden Gruppen (mom_hs=0 bzw. mom_hs=1) auf:\nmom_hs=0:\nkid_score = -10.7 + 50.4*0 + 1*mom_iq  - -0.5*0*mom_iq\n          = -10 + 1.1*mom_iq\nmom_hs=1:\nkid_score = -10.7 + 50.4*mom_hs + 1*mom_iq  - -0.5*mom_hs*mom_iq\n          = -10 + 1.1*mom_iq\nNach der Interpretation von 20 unzentrierten Koeffizienten ‚Ä¶\n\n\n\nvia GIPHY\n\nWir m√ºssen dringend die unzentrierten Pr√§diktoren loswerden ‚Ä¶\n\n11.5.4 Antwort auf die Forschungsfrage\nWie in Tabelle¬†11.6 ersichtlich, kann f√ºr alle drei Effekte (m√ºtterliche IQ, m√ºtterlicher Schulabschluss und Interaktion von m√ºtterlichem IQ mit m√ºtterlichem Schulabschluss) ein Nulleffekt ausgeschlossen werden. Ob die Effekte st√§rker als ‚Äúpraktisch Null‚Äù sind, kann mittels des ROPE-Verfahren untersucht werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "href": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.6 y ~ x_c + b + x_c:b\n",
    "text": "11.6 y ~ x_c + b + x_c:b\n\n\n11.6.1 Zentrieren von Pr√§diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq; die zentrierte Variable kennzeichnen wir durch den Suffix _c, also mom_iq_c.\nMan k√∂nnte auch mom_hs zentrieren, aber f√ºr eine einfache Interpretation ist es meist n√ºtzlich, nur metrische Pr√§diktoren zu zentrieren.\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\n\ncoef(m10.5)  # nur die Punktsch√§tzer f√ºr die Koeffizienten ausgeben\n\n\nTabelle¬†11.7 zeigt die Punktsch√§tzer der Koeffizienten von m10.5.\n\n\n\nTabelle¬†11.7: Punktsch√§tzer von m10.5 (zentrierte UV)\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.34\n\n\nmom_hs\n2.86\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n\n\n\n11.6.2 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den gesch√§tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten f√ºr mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nMit estimate_relation(m10.5) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung¬†11.11.\n\n\n\n\n\n\n\nAbbildung¬†11.11: m10.5: Mit zentrierten Pr√§diktoren gibt der Achsenabschnitt den Y-Wert f√ºr eine Beobachtung mit mittleren X-Wert an; daher ist der Achsenabschnitt besser zu interpretieren als ohne Zentrierung.\n\n\n\n\n\n11.6.3 Zentrieren √§ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5: Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren √§ndert auch nicht die zentrierten Regressionskoeffizienten, da die Streuungen dieser Variable nicht ver√§ndert wurden.\n\n11.6.4 Perzentilintervalle aus der Posterori-Verteilung\nTabelle¬†11.8 zeigt die Punktsch√§tzer der Parameter f√ºr m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie daf√ºr parameters(m10.5), s. Tabelle¬†11.8.\n\n\n\nTabelle¬†11.8: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(81.17, 89.61)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.80, 7.62)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. Tabelle¬†11.9.\n\nCodeparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelle¬†11.9: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(80.96, 89.39)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.64, 7.75)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.17)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n11.6.5 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei M√ºttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]); die Befundlage ist unklar. Hingegen fand sich ein Effekt der m√ºtterlichen Intelligenz; pro Punkt Unterschied in m√ºtterlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte beim Kind (95%PI). Au√üerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei M√ºtter mit Schulabschluss war der Regressionskoeffizient zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell hat mittels Abbildung¬†11.12 mutig Kausalaussagen postuliert. Das ist zwar sch√∂n, bedarf aber einer Begr√ºndung mit R√ºckgriff auf die Literatur (was hier nicht getan wurde).",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#sec-yg",
    "href": "1000-metrische-AV.html#sec-yg",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.7 y ~ g\n",
    "text": "11.7 y ~ g\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n11.7.1 Forschungsfrage\nNach Ihrem Studium wurden Sie reich als Unternehmensberaterin; Ihre Kompetenz als Wirtschaftspsychologi war hei√ü begehrt. Von Statistik wollte niemand etwas wissen‚Ä¶ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt f√ºhrte Sie in die Antarktis‚Ä¶ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um Gr√∂√üenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren K√∂rpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in Abbildung¬†11.12 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†11.12: DAG f√ºr y ~ g\n\n\n\n\n\n11.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere K√∂rpergewichte in Abh√§ngigkeit von der Pinguinart?\n\nAlternativ k√∂nnen wir die Hypothese pr√ºfen, ob die Mittelwerte ‚Äúpraktisch‚Äù gleich sind, also sich ‚Äúkaum‚Äù unterscheiden. Der Grenzwert f√ºr ‚Äúpraktisch gleich‚Äù bzw. ‚Äúkaum unterschiedlich‚Äù ist subjektiv. Dazu in Kapitel 10.3 mehr.\n\n11.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, Tabelle¬†11.10.\n\nCodepenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\nTabelle¬†11.10: Die Verteilung des K√∂rpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas f√§llt Ihnen auf?\n\n11.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. Abbildung¬†11.13?\n\n\n\n\n\n\n\nAbbildung¬†11.13: Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.7.5 Gewicht pro Spezies, m10.6\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und Tabelle¬†11.11.\nDie Modellformel f√ºr m10.6 lautet also body_mass_g ~ species.\n\nCodeoptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\n\nTabelle¬†11.11: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3700.62\n(3627.04, 3773.47)\n100%\n0.999\n4057\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.49\n(-104.84, 168.88)\n68.53%\n1.000\n4282\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.43\n(1263.00, 1492.13)\n100%\n1.000\n4454\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n11.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, Auspr√§gungen; hier: Spezies), aber es werden in Tabelle¬†11.11 nur zwei Stufen angezeigt (also eine weniger) zus√§tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedr√ºckt (Intercept). Die Koeffizienten f√ºr species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in Abbildung¬†11.14 verdeutlicht.\n\nCodeplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†11.14: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\n\n11.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich h√∂her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich √§hnlich.\nWie in Abbildung¬†11.14 ersichtlich, √ºberlappt sich der Sch√§tzbereich f√ºr den Parameter von Gentoo nicht mit der Null; hingegen √ºberlappt sich der Sch√§tzbereich des Parameters f√ºr Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise h√§tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis pr√ºfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.\n\n11.7.8 Priori-Werte √§ndern\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. F√ºr Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nf√ºr Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich mit prior_summary(modell) ausgeben lassen.\n\nCodeprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Prioris anpassen wollen. So k√∂nnte man z.B. auf Basis von Fachwissen √ºber das Gewicht von Pinguinen postulieren, dass Adelie-Pinguine im Mittel 3000 g wiegen. Und dass die anderen zwei Pinguin-Arten im Mittel sich nicht unterscheiden vom Mittelwert der Adelie-Pinguine.\n\nCodem10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3704               24             1358\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nCodem10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(3000, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3700               29             1375\n\n\nDen Parameter f√ºr die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen.\n\nCodesigma(m10.6b)\n## [1] 463\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die Gr√∂√üe der Konfidenzintervalle.\n√úbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren.12\n\n11.7.9 Vertiefung: Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\nCodepenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern.\n\nCodelevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nCodelibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verf√ºgbar sein muss.\nJetzt haben wir die Referenzkategorie ge√§ndert:\n\nCodelevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell, s. Tabelle¬†11.12.\n\nCodem10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nTabelle¬†11.12: m10.6a mit ge√§nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 4988.13, 5155.48]\n\n\nspeciesAdelie\n[-1486.15, -1260.32]\n\n\nspeciesChinstrap\n[-1474.66, -1198.00]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1-x2",
    "href": "1000-metrische-AV.html#y-x1-x2",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.8 y ~ x1 + x2\n",
    "text": "11.8 y ~ x1 + x2\n\nHier untersuchen wir Forschungsfragen mit zwei metrischen UV (und einer metrischen AV).\n\n11.8.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabh√§ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa ‚ÄúIQ der Mutter ist die Ursache zum IQ des Kindes‚Äù) wird impliziert.\nEs geht in dieser Forschungsfrage rein darum, Zusammenh√§nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. F√ºr solche Fragen ist ein Kausalmodell n√∂tig: Fachlich fundierte Annahmen √ºber Kausalzusammenh√§nge zwischen UV und AV.\n\n11.8.2 Was hei√üt, X h√§ngt mit Y zusammen?\n\nDer Begriff ‚ÄúZusammenhang‚Äù ist nicht exakt.\nH√§ufig wird er (f√ºr metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie gro√ü der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem ‚ÄúEffekt von X auf Y‚Äù √ºbersetzt. Vorsicht: ‚ÄúEffekt‚Äù klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begr√ºndung f√ºr einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der St√§rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugeh√∂rigen Regression im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten, bevor man ein (Regressions-)Modell aufstellt, s. Tabelle¬†11.13.\n\nCodekidiq %&gt;% \n  correlation()\n\n\n\n\n\nTabelle¬†11.13: Korrelation der Variablen im Datensatz kidiq (inkl. frequentistischer Statistiken wie t- und p-Werten, die wir hier ignorieren)\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.166\n\n\nkid_score\nmom_iq_c\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_hs\nmom_iq_c\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\nmom_iq\nmom_iq_c\n1.00\n(1.00, 1.00)\n1.39e+09\n&lt; .001***\n\n\nmom_age\nmom_iq_c\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\n\n\nTabelle¬†11.14 zeigt die Korrelationsmatrix als Korrelationsmatrix.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\n\nTabelle¬†11.14: Die Korrelationen zwischen den Variablen der Tabelle kidiq. Die Sterne geben einen Bereich des p-Werts an (wir ignorieren die Sterne hier).\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_iq_c\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.45***\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.28***\n0.21***\n0.28***\n\n\n\nmom_iq\n1.00***\n0.09\n\n\n\n\nmom_age\n0.09\n\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nN√ºtzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, Abbildung¬†11.15.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung¬†11.15: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n11.8.3 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro Pr√§diktor, also eine f√ºr mom_iq und eine f√ºr mom_age.\n\nCodem10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nTabelle¬†11.15 zeigt die Ergebnisse f√ºr mom_iq.\n\n\n\nTabelle¬†11.15: Parameter f√ºr m10.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.79\n(14.59, 37.16)\n100%\n1.000\n4452\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.72)\n100%\n1.000\n4436\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nTabelle¬†11.16 zeigt die Ergebnisse f√ºr mom_age.\n\n\n\nTabelle¬†11.16: Parameter f√ºr m10.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n71.39\n(54.39, 87.44)\n100%\n0.999\n3923\nNormal (86.80 +- 51.03)\n\n\nmom_age\n0.68\n(-0.02, 1.41)\n96.92%\n0.999\n3917\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n11.8.4 Visualisierung der univariaten Regressionen\nIn Abbildung¬†11.16 ist die univariate Regression mit jeweils einem der beiden Pr√§diktoren dargestellt.\nm10.7: Die Steigung betr√§gt 0.6. m10.8: Die Steigung betr√§gt 0.7.\n\n\n\n\n\n\n\nAbbildung¬†11.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n11.8.5 Multiples Modell (beide Pr√§diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein Pr√§diktor im Modell aufgenommen ist, s Tabelle¬†11.17.\n\nCodem10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\nparameters(m10.9)\n\n\n\n\n\nTabelle¬†11.17: Parameter f√ºr m10.9\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n17.61\n(-0.06, 35.67)\n97.42%\n1.000\n6102\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.60\n(0.48, 0.72)\n100%\n1.000\n5162\nNormal (0.00 +- 3.40)\n\n\nmom_age\n0.39\n(-0.23, 1.02)\n88.22%\n1.000\n4952\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich (potenziell) zu den von den jeweiligen univariaten Regressionen.\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils ‚Äúbereinigt‚Äù vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht. Das bedeutet anschaulich, man betrachtet den den Zusammenhang einee UV mit der AV, wobei man gleichzeitig den anderen Pr√§diktor konstant h√§lt.\nIn Abbildung¬†11.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildung¬†11.17: 3D-Visualisierung von m10.9 (zwei Pr√§diktoren)\n\n\n\nAbbildung¬†11.18 zeigt eine Visualisierung von m10.9, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildung¬†11.18: Modell m10.9; die Farbverl√§ufe zeigen der Wert der abh√§ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farb√§nderung) die Ver√§nderung f√ºr die AV (kid_score). Auf der Achse f√ºr mom_age sieht man, dass sich die AV kaum √§ndert, wenn sich mom_age √§ndert.\n\n11.8.6 Visualisierung in 10 Dimensionen\nAbbildung¬†11.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildung¬†11.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schw√§chen, eine gro√üe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y-x1_z-x2_z",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.9 y ~ x1_z + x2_z\n",
    "text": "11.9 y ~ x1_z + x2_z\n\nIn diesem Abschnitt untersuchen wir ein Modell mit zwei z-standardisierten, metrischen Pr√§diktoren (und einer metrischen, nicht-standardisierten AV).\n\n11.9.1 Relevanz der Pr√§diktoren\nWoher wei√ü man, welche UV am st√§rksten mit der AV zusammenh√§ngt? Man k√∂nnte auch sagen: Welcher Pr√§diktor (welche UV) am ‚Äúwichtigsten‚Äù ist oder den ‚Äúst√§rksten Einfluss‚Äù auf die AV aus√ºbt? Bei solchen kausal konnotierten Ausdr√ºcken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann f√ºr sich nur Muster in den Daten, also Zusammenh√§nge bzw. Unterschiede, entdecken, s. Abbildung¬†11.20. M√∂chte man die Relevanz von Pr√§diktoren vergleichen, so ist ein Kausalmodell empfehlenswert.\n\n\n\n\n\nAbbildung¬†11.20: Made at imgflip.com\n\n\nWelcher Pr√§diktor ist nun ‚Äúwichtiger‚Äù oder ‚Äúst√§rker‚Äù in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)? Die Antwort h√§ngt auch von der Streuung bzw. Skalierung der Variablen ab. mom_iq hat den gr√∂√üeren Koeffizienten und viel Streuung; mom_age hat weniger Streuung.\nUm die Relevanz der Pr√§diktoren vergleichen zu k√∂nnen, m√ºsste man vielleicht die Ver√§nderung von kid_score betrachten, wenn man von kleinsten zum gr√∂√üten Pr√§diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die Ver√§nderung in der AV zu betrachten, wenn man den Pr√§diktor von ‚Äúunterdurchschnittlich‚Äù auf ‚Äú√ºberdurchschnittlich‚Äù √§ndert. Das kann man mit z-Standardisierung erreichen, s. ?sec-standardnormalverteilung.\n\n\n\n\nCodekidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;%  # z-Transformation\n  select(mom_iq, mom_iq_z) \n\nkidiq2 %&gt;% \n  head()\n\n\n  \n\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit der Effekte von UV, die (zuvor) verschiedene Mittelwerte und Streuungen hatten13. Die Standardisierung ist √§hnlich zur Vergabe von Prozentr√§ngen: ‚ÄúDieser Messwert geh√∂rt zu den Top-3-Prozent‚Äù. Diese Aussage ist bedeutsam f√ºr Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen f√ºr verschiedene Verteilungen m√∂glich.\n\n11.9.2 Statistiken zu den z-transformierten Variablen\nTabelle¬†11.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Auspr√§gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener Pr√§diktoren sind einfacher in ihrer Gr√∂√üe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und √§hnlich gro√üe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (‚ÄúSkalierung‚Äù) mit standardize (aus easystats) durchf√ºhren, s. Tabelle¬†11.18.\n\nCodekidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\n\nTabelle¬†11.18: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nmom_iq_c\npred_m10.9\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_c_z\npred_m10.9_z\n\n\n\n65\n1\n121.12\n27\n21.12\n101.14\n-1.07\n0.52\n1.41\n1.56\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n-10.64\n81.22\n0.55\n0.52\n-0.71\n0.82\n-0.71\n-0.60\n\n\n85\n1\n115.44\n27\n15.44\n97.72\n-0.09\n0.52\n1.03\n1.56\n1.03\n1.19\n\n\n83\n1\n99.45\n25\n-0.55\n87.30\n-0.19\n0.52\n-0.04\n0.82\n-0.04\n0.06\n\n\n115\n1\n92.75\n27\n-7.25\n84.04\n1.38\n0.52\n-0.48\n1.56\n-0.48\n-0.30\n\n\n98\n0\n107.90\n18\n7.90\n89.67\n0.55\n-1.91\n0.53\n-1.77\n0.53\n0.32\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt daf√ºr, dass die urspr√ºnglichen Variablen beim z-Standardisieren nicht √ºberschrieben werden, sondern angeh√§ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nCodekidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. Tabelle¬†11.19. Dazu verwendet man den Befehl scale().\n\nCodekidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\n\nTabelle¬†11.19: Z-Standardisierung ohne Extrapaket‚Äù\n\n\n\n  \n\n\n\n\n\n\n\n11.9.3 Modell\nBerechnen wir das Modell m10.10: y ~ x1_z + x2_z.\n\nCodem10.10 &lt;- stan_glm(kid_score ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\nparameters(m10.10)\n\n\n\n\n\nTabelle¬†11.20: Parameter von m10.12\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n86.77\n(85.05, 88.48)\n100%\n1.000\n4917\nNormal (86.80 +- 51.03)\n\n\nmom_iq_z\n9.04\n(7.34, 10.83)\n100%\n1.000\n4719\nNormal (0.00 +- 51.03)\n\n\nmom_age_z\n1.04\n(-0.73, 2.78)\n88.02%\n0.999\n4786\nNormal (0.00 +- 51.03)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.10 y_z ~ x1_z + x2_z\n",
    "text": "11.10 y_z ~ x1_z + x2_z\n\nIn diese Abschnitt berechnen wir ein Modell (Modell m10.12), in dem sowohl die Pr√§diktoren z-transformiert sind (standardisiert) als auch die AV. Das z-Standardisieren der AV, kid_score ist zwar nicht n√∂tig, um den Effekt der Pr√§diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage dar√ºber, um wie viele SD-Einheiten sich die AV ver√§ndert, wenn sich ein Pr√§diktor um eine SD-Einheit ver√§ndert. Das kann auch eine interessante(re) Aussage sein.\n\n11.10.1 Modell y_z ~ x1_z + x2_z\n\nBerechnen wir das Modell m10.12: y_z ~ x1_z + x2_z.\n\nCodem10.12 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z   mom_age_z \n##    -0.00014     0.44384     0.05072\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient f√ºr mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) √§ndert, wenn sich mom_iq um eine SD-Einheit √§ndert.\nDer Koeffizient f√ºr mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) √§ndert, wenn sich mom_age um eine SD-Einheit √§ndert.\n\nJetzt sind die Pr√§diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar. Man sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n11.10.2 95%-PI\nMit parameters k√∂nnen wir uns ein PI f√ºr m10.12 ausgeben lassen, s. Abbildung¬†11.21; im Standard wird ein 95%-ETI berichtet14.\n\nCodeparameters(m10.12) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-1.38e-04\n(-0.08, 0.08)\n50.20%\n1.000\n5259\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n4713\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.85%\n0.999\n4990\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nCodeplot(eti(m10.12)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†11.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI f√ºr m10.12\n\n\n\n\n\n11.10.3 Modellg√ºte\n\nCoder2(m10.12)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.144, 0.271])\n\n\nIst dieser Wert von \\(R2\\) ‚Äúgut‚Äù? Diese Frage ist √§hnlich zur Frage ‚ÄúIst das viel Geld?‚Äù; man kann die Frage nur im Kontext beantworten.\nEine einfache L√∂sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erkl√§rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zuf√§llig hohen Werten der Modellg√ºte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine ‚Äúobjektive‚Äù Antwort auf die Frage ‚Äúwie viel ist viel?‚Äù haben wollen, ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage ‚ÄúWieviel ist viel?‚Äù gegeben hat (Cohen, 1992):\n\nCodeinterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n11.10.4 Priori-Verteilung f√ºr m10.12 und Modelldefinition\nDie Prioris f√ºr m10.12 kann man sich mit prior_summary(m10.12) ausgeben lassen. Danke, Stan!\n\nCodeprior_summary(m10.12)  # aus rstanarm\n## Priors for model 'm10.12' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\nü§ñ Nix zu danken!\n\nWie gesagt, Stan nimmt daf√ºr einfach die empirischen Mittelwerte und Streuungen her.15\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. Gleichung¬†11.4.\n\\[\n\\begin{aligned}\n\\text{kidscore}^z_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{momiq}_i^z + \\beta_2\\text{momage}_i^z \\\\\n\\beta_0 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{11.4}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.12. Dadurch, dass nicht nur UV, sondern auch AV z-standardisiert (d.h. zentriert und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuf√ºhren.\n\nBeispiel 11.3 (Anzahl der Modellparameter) Wie viele Modellparameter hat m10.12?16\n\n\n11.10.5 Antwort auf die Forschungsfrage\n\nDas Modell spricht sich klar f√ºr einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Pro Einheit Standardabweichung in der UV (Intelligenz der Mutter) √§ndert sich die AV um ca. 0.44 Standardabweichungseinheiten. Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erk√§rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al., 2020) zur√ºck (s. Anhang f√ºr Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem ‚Äústatistischen Effekt‚Äù gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenh√§nge, und nicht um kausale Zusammenh√§nge, handelt. Kausale Zusammenh√§nge d√ºrfen wir nur verk√ºnden, wenn wir sie a) explizit untersuchen und b) sich in der Literatur Belege daf√ºr finden oder c) wir ein Experiment fachgerecht durchgef√ºhrt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.11 Vertiefung",
    "text": "11.11 Vertiefung\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\n\n11.11.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch, s. Theorem¬†11.2.\n\nTheorem 11.2 (Regression als Korrelation) \\[b = r \\frac{sd_x}{sd_y}\\quad \\square\\]\n\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die Punktsch√§tzer f√ºr die Regressionskoeffizienten, s. m10.12.\n\nCodem10.12 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z \n##    -0.00033     0.44993\n\n\nVergleichen Sie diese Werte mit der Korrelation, s. Tabelle¬†11.21.17\n\nCodekidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelle¬†11.21: Correlation Matrix (pearson-method)\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n11.11.2 Pr√ºfen der Linearit√§tsannahme\nZentrale Annahme eines linearen Modells: Die AV ist eine lineare Funktion der einzelnen Pr√§diktoren, $y= _0 + _1x_1 + _2 x_2 + $, vgl. Theorem¬†2.1.\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression h√§ufig normalverteilte Residuen an18, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu sch√§tzen (Gelman et al., 2021).\nIst die Linearit√§tsannahme erf√ºllt, so sollte der Residualplot nur zuf√§llige Streuung um \\(y=0\\) herum zeigen, s. Abbildung¬†11.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tats√§chlichem Wert: \\(e_i = y_i - \\hat{y}_i\\)\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.12_pred = predict(m10.12),  # vorhergesagten Werte\n         m10.12_resid = resid(m10.12))  # Residuen\n\n\n\nCodekidiq %&gt;% \n  ggplot(aes(x = m10.12_pred, y = m10.12_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildung¬†11.22: Die Verteilung der Fehler scheint keinem starken Trend (in Abh√§ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine gr√∂√üeren Auff√§lligkeiten.\n\n11.11.3 Modellpr√ºfung mit der PPV\n\nCodepp_check(m10.12)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht h√§ufig.\n\n11.11.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildung¬†11.23: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildung¬†11.23 zeigt in der oberen Reihe die Regression eines Pr√§diktors auf den anderen Pr√§diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das hei√üt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenh√§ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das hei√üt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenh√§ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n11.11.5 Bayesianisch gleich Frequentistisch?\n√úbrigens liefern stan_glm() und lm oft √§hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nCodestan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.911      -0.019      -2.285\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.908      -0.019      -2.265\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch √§hnlich sein k√∂nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.12 Fazit",
    "text": "11.12 Fazit\n\n11.12.1 Austieg: Bayes in f√ºnf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\nüì∫ Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\nüì∫ Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n11.12.2 Ausblick: Bin√§re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\nCodedata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m14: am ~ mpg_z:\n\nCodem14 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m14)\n## (Intercept)       mpg_z \n##         0.4         0.3\n\n\nAb mpg_z = 0.4, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nCodemtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m14)[1],\n              slope = coef(m14)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nCodeneg_am &lt;- predict(m14, newdata = tibble(mpg_z = -1.3))\n\n\nF√ºr kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte f√ºr am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. M√ºssen wir mal bei Gelegenheit besser machen.\n\n11.12.3 Genug f√ºr heute\nWir waren flei√üig ‚Ä¶\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.\n\n\nGenug f√ºr heute. üëç\n\n11.12.4 Weiterf√ºhrende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman et al. (2021), Kap. 10, insbesondere 10.3.\nGelman et al. (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit f√ºhrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig √ºberschaubarem mathematischen Aufwand.\nF√ºr das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.13 Aufgaben",
    "text": "11.13 Aufgaben\n\n11.13.1 Papier-und-Bleistift-Aufgaben\n\nanz-params\nfofrage-regrformel2\nmodelldef-regrformel\nfinde-prior/\nNullhyp-Beispiel\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nzwert-berechnen\nstan_glm_parameterzahl\nkausale-verben\n\n11.13.2 Aufgaben, f√ºr die man einen Computer ben√∂tigt\n\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope4\n\n11.13.3 Vertiefung\n\nAnova-skalenniveau\nttest-skalenniveau\nstan_glm_prioriwerte",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.14 ‚Äî",
    "text": "11.14 ‚Äî\n\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155‚Äì159.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). Rstanarm: Bayesian Applied Regression Modeling via Stan. https://mc-stan.org/rstanarm\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#footnotes",
    "href": "1000-metrische-AV.html#footnotes",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "",
    "text": "Hier ist eine kurze Erkl√§rung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablen‚Ü©Ô∏é\nHier finden Sie eine kurze Erkl√§rung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktion‚Ü©Ô∏é\nauch DAG genannt, s. ?sec-kausal‚Ü©Ô∏é\nH√§ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - ‚Äúgr√∂√üer als/kleiner als‚Äù - zu formulieren, anstelle der ‚Äúempirisch √§rmeren‚Äù einfachen, ungerichteten Ungleichheit‚Ü©Ô∏é\nunknown, sozusagen der unbekannte Gott, also f√ºr alle sonstigen Einfl√ºsse; man kann das ‚Äúu‚Äù ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgef√ºhrt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es g√§be keine anderen Einfl√ºsse als mom_hs auf die IQ des Kindes.‚Ü©Ô∏é\nGenauer gesagt wird gepr√ºft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.‚Ü©Ô∏é\nGenauer gesagt, erlaubt der t-Test in der Form des Welche-Tests auch Abweichungen von der Varianzhomogenit√§t der gestesten Gruppen. Die Regression geht hingegen von Varianzhomogenit√§t (Homoskedastizit√§t) aus. Allerdings ist diese Annahme nicht von besonderer Bedeutung, wenn es um die Regressionskoeffizienten geht.‚Ü©Ô∏é\nDAG, s. ?sec-kausal‚Ü©Ô∏é\nDabei nehmen wir an, dass x und u nicht voneinander abh√§ngen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.‚Ü©Ô∏é\nVgl. Abschnitt ‚ÄúUV zentrieren‚Äù im Kursbuch Statistik1.‚Ü©Ô∏é\nauch ETI (Equal Tails Interval) genannt‚Ü©Ô∏é\ns. Details hier.‚Ü©Ô∏é\nam n√ºtzlichsten ist diese Standardisierung bei normal verteilten Variablen.‚Ü©Ô∏é\nZumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen k√∂nnen sich √§ndern. Am besten in der Dokumentation nachlesen: ?parameters.‚Ü©Ô∏é\nNicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Sch√§tzer der echten Parameter sein m√ºssten, wenn die Stichprobe, die wir ihm angeschleppt h√§tten, tats√§chlich gut ist‚Ä¶‚Ü©Ô∏é\n4: \\(\\beta_0, \\beta_1, \\beta_2, \\sigma\\)‚Ü©Ô∏é\nIgnorieren Sie die Zeile mit dem Befehl display(). Dieser Befehl dient nur dazu, die Ausgabe zu versch√∂nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.‚Ü©Ô∏é\nwas auf normal verteilte AV hinauslaufen kann aber nicht muss‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html",
    "href": "1200-abschluss.html",
    "title": "12¬† Abschluss",
    "section": "",
    "text": "12.1 Lernsteuerung",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "12¬† Abschluss",
    "section": "",
    "text": "12.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerl√§utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische ‚ÄúLieblingsfehler‚Äù benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik √ºbersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n12.1.2 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\nCodelibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n\n12.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#probeklausur",
    "href": "1200-abschluss.html#probeklausur",
    "title": "12¬† Abschluss",
    "section": "\n12.2 Probeklausur",
    "text": "12.2 Probeklausur\n\n12.2.1 2024\n(Diese Liste ist im Aufbau. Bitte konsultieren Sie f√ºr weitere Aufgaben selbst√§ndig alle relevanten Aufgaben, die in den Kapiteln vorgestellt wurden.)\n\nttest-als-regr\nAdditionssatz1\n\nNerd-gelockert q\nUrne1\ncorona-blutgruppe\nvoll-normal\nalphafehler-inflation3\nverteilungen-quiz-05\nverteilungen-quiz-03\nverteilungen-quiz-04\nKekse03\nglobus-bin2\nglobus2\niq01a\ngem-wskt4\nRethink2m3\nmtcars-post2a\ngroesse03\nbath42\nklausur-raten\nbed-post-wskt1\nmtcars-post3a\nexp-tab\nnorms-sd\nmtcars-post_paper\nbfi10\nrope-luecke\nwskt-schluckspecht2a\npenguins-stan-06\n\n12.2.2 2023\nDieser Tag auf dem Datenwerk stellt Fragen einer Probepr√ºfung (Version 2023) zusammen.\n\n12.2.3 2022\nDieser Tag auf dem Datenwerk stellt Fragen einer Probepr√ºfung (Version 2022) zusammen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "12¬† Abschluss",
    "section": "\n12.3 Lieblinglingsfehler",
    "text": "12.3 Lieblinglingsfehler\nLieblingsfehler im √úberblick ü§∑:\n\nQuantile und Verteilungsfunktion verwechseln\nPr√§diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n12.3.1 Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑\nüèé üèé Vertiefung: Dieser Abschnitt ist nicht pr√ºfungsrelevant. üèéÔ∏è üèé\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nCodem1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle¬†12.1.\n\nCodepost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle¬†12.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. H√§ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und Punktsch√§tzer auszulesen.\nDie Posterior-Pr√§diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n12.3.2 Quantile und Verteilungsfuntion verwechseln ü§∑\n\n12.3.2.1 Quantil f√ºr \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung¬†12.1.\n\n\n\n\n\n\n\nAbbildung¬†12.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betr√§gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist gr√∂√üer oder gleich dem \\(p\\)-Quantil.\n\n12.3.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung¬†12.2.\n\n\n\n\n\n\n\nAbbildung¬†12.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betr√§gt hier 50%, dass \\(x\\) nicht gr√∂√üer ist als 0.\n\n12.3.3 Interaktion falsch interpretieren ü§∑\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber k√ºrzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nCodem2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten, s. Tabelle¬†12.2.\n\nCodeparameters(m2)\n\n\n\n\n\nTabelle¬†12.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.68\n(18.99, 30.27)\n100%\n1.000\n2120.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.75%\n1.000\n2200.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.80\n(4.96, 22.96)\n99.78%\n1.000\n1573.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.19, -0.03)\n99.52%\n1.000\n1837.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle¬†12.2 zeigt die Visualisierung der Parameter von m2.\n\nCodeplot(parameters(m2))\n\n\n\n\n\n\nAbbildung¬†12.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch üòà Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11.\nRichtig üëº Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11 ‚Äì wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Pr√§diktoren w√§ren hier eine sinnvolle L√∂sung.\nGelman et al. (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "12¬† Abschluss",
    "section": "\n12.4 Kochrezepte üç≤",
    "text": "12.4 Kochrezepte üç≤\n\n12.4.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen √ºber ein Ph√§nomen, \\(y\\), Kausalfrage finden 2. Literatur w√§lzen, um m√∂gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese pr√§zisieren 4. Modell pr√§zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell pr√ºfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n12.4.2 Parameter sch√§tzen vs.¬†Hypothesen pr√ºfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter sch√§tzen. Beispiel Hypothesenpr√ºfung: ‚ÄúFrauen parken im Durchschnitt schneller ein als M√§nner‚Äù. Beispiel Parametersch√§tzung: ‚ÄúWie gro√ü ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und M√§nnern?‚Äù\nJe ausgereifter ein Forschungsfeld, desto k√ºhnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die n√§chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die n√§chste Sonnenfinsternis wird in den n√§chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen f√ºr den Klausurerfolg. K√ºhne Hypothesen sind w√ºnschenswert ü¶π\n\n12.4.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist h√∂her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist gr√∂√üer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "12¬† Abschluss",
    "section": "\n12.5 Kerngedanken Bayes",
    "text": "12.5 Kerngedanken Bayes\nüì∫ Bayes in f√ºnf Minuten\nüì∫ Bayes in zehn Minuten\n\n12.5.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nCodem3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung¬†12.4.\n\n\n\n\n\n\n\nAbbildung¬†12.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist m√∂glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind m√∂glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings √ºbermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n12.5.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "title": "12¬† Abschluss",
    "section": "\n12.6 Beispiele f√ºr Pr√ºfungsaufgaben",
    "text": "12.6 Beispiele f√ºr Pr√ºfungsaufgaben\n\n12.6.1 Geben Sie den korrekten Begriff an!\nüå¨üöôüôãÔ∏èüë®‚¨ÖÔ∏èHans üëß‚¨ÖÔ∏èAnna üë©‚¨ÖÔ∏èLise\nPuh, wie erstelle ich f√ºr alle Studis ein anderes R√§tsel2?\n\n\n\n\n\n12.6.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung¬†12.5.\n\n\n\n\n\n\n\nAbbildung¬†12.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 12.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge f√ºr x und y gibt eine kleinstm√∂gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu ‚Äúidentifizieren‚Äù). \\(\\square\\)\n\n‚ùìGeben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n‚ùó Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n12.6.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung¬†12.6.\n\n\n\n\n\n\n\nAbbildung¬†12.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n12.6.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung¬†12.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung¬†12.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set f√ºr den totalen Kausaleffekt: {AIS, ALN}\n\n12.6.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPr√ºfungsfragen zu Modellen k√∂nnten z.B. sein:\n\nGeben Sie den Punktsch√§tzer (Median) f√ºr den Pr√§diktor X im Modell Y an!\nGeben Sie ein 89%-HDI f√ºr den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris ‚Ä¶\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI f√ºr den Pr√§diktor X im Modell Y?\nWas ver√§ndert sich an den Parametern, wenn Sie die Pr√§diktoren zentrieren/z-standardisieren?\n‚Ä¶",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "12¬† Abschluss",
    "section": "\n12.7 Aufgabensammlungen",
    "text": "12.7 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere ‚ÄúPr√ºfungsn√§he‚Äù k√∂nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "title": "12¬† Abschluss",
    "section": "\n12.8 Viel Erfolg bei der Pr√ºfung!",
    "text": "12.8 Viel Erfolg bei der Pr√ºfung!\nü•≥üèÜüçÄüçÄüçÄ",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section-3",
    "href": "1200-abschluss.html#section-3",
    "title": "12¬† Abschluss",
    "section": "\n12.9 ‚Äî",
    "text": "12.9 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nvan Kampen, D. (2014). The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs. European Psychiatry, 29(7), 437‚Äì448. https://doi.org/10.1016/j.eurpsy.2013.11.001",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#footnotes",
    "href": "1200-abschluss.html#footnotes",
    "title": "12¬† Abschluss",
    "section": "",
    "text": "langweiliges‚Ü©Ô∏é\nFahr-Hier-Hans-Anna-Lise: Varianzanalyse‚Ü©Ô∏é\ndas ist keine vollst√§ndige Liste, sondern eine Anregung. Andere Tags k√∂nnten auch relevant sein‚Ü©Ô∏é",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "definitions.html",
    "href": "definitions.html",
    "title": "13¬† Definitionen",
    "section": "",
    "text": "Kausale Abh√§ngigkeit: ?def-abh\nAdditionssatz f√ºr disjunkte Ereignisse: Definition¬†4.1\nAllgemeiner Additionssatz: Definition¬†4.2\nBinomialkoeffizient: Definition¬†5.2\nBinomialverteilung: Definition¬†5.1\nBlockieren: ?def-blocking\nKollision: ?def-collision\nKonfundierungsvariable: ?def-confound\nDAG: ?def-dag\nDeskriptivstatistik: Definition¬†2.1\nDirekter Effekt: ?def-dir-eff\nEffekt: ?def-effekt\nElementarereignis: ?def-elementarereignis\nEreignis: Definition¬†3.3\nEreignisraum: ?def-ereignisraum\nPerzentilintervall (PI): Definition¬†7.1\nEvidenz: Definition¬†6.4\nFunktion: Definition¬†2.4\nGemeinsame Wahrscheinlichkeit: Definition¬†4.6\nIntervalle h√∂chster Dichte (Highest Density Intervals): Definition¬†7.2\nHintert√ºr: ?def-hintertuer\nIndirekter Effekt: ?def-ind-eff\nStochastische Unabh√§ngigkeit: Definition¬†4.4\nIndifferenzprinzip: Definition¬†3.10\nInferenzstatistik: Definition¬†2.2\nKettenregel: Definition¬†4.7\nKonfidenzintervall: Definition¬†2.7\nLikelihood: Definition¬†6.2\nLaplace-Experimt: Definition¬†3.11\nLogarithmus: ?def-logarithmus\nM√§chtigkeit: Definition¬†3.7\nMediator: ?def-mediator\nKomplement√§rereignis: Definition¬†3.15\nLogische Differenz: Definition¬†3.16\nSchnittmenge von Ereignissen: Definition¬†3.14\nVereinigung von Ereignissen: Definition¬†3.13\nMinimale Adjustierungsmenge : Definition¬†12.1\nModell: Definition¬†2.3\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse: Definition¬†4.5\nNachfahre: ?def-Nachfahre\nNullhypothese: Definition¬†2.9\nNormalverteilung: ?def-nv\nParameter: ?def-parameter\nEffektwahrscheinlichkeit: Definition¬†9.1\nPfad: ?def-pfad\nPosteriori-Verteilung: Definition¬†6.3\nBedingte Wahrscheinlichkeit: Definition¬†4.3\nPriori-Verteilung: Definition¬†6.1\nPunktsch√§tzer: ?def-punktschaetzer\nRelation: Definition¬†3.12\nSignifikanz: Definition¬†2.8\nStratifizieren: ?def-stratifizieren\nTotaler Effekt: ?def-tce\nTotale Wahrscheinlichkeit: Definition¬†4.8\nUnm√∂gliches und sicheres Ereignis: Definition¬†3.4\nVerteilungsfunktion: Definition¬†3.19\nVerteilungsfunktion: Definition¬†3.22\nVollst√§ndiges Ereignissystem: Definition¬†3.6\nVorhersageintervall: ?def-vorhersageintervall\nWahrscheinlichkeitsfunktion: ?def-w-fun\nWahrscheinlichkeitsdichte: Definition¬†3.21\nWahrscheinlichkeit: Definition¬†3.9\nDiskrete Wahrscheinlichkeitsverteilung: Definition¬†3.18\nStetige Wahrscheinlichkeitsverteilung: ?def-wvert-stetig\nZuf√§lliges Ereignis: Definition¬†3.1\nZufallsvorgang: Definition¬†3.1\nZufallsvariable: Definition¬†3.17\nStetige Zufallsvariable: Definition¬†3.20",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "theorems.html",
    "href": "theorems.html",
    "title": "14¬† Theoreme",
    "section": "",
    "text": "Stochastische Abh√§ngigkeit: Theorem¬†4.6\nStochastische Abh√§ngigkeit 2: Theorem¬†4.7\nAllgemeiner Additionssatz: Theorem¬†4.2\nAdditionssatz f√ºr disjunkte Ereignisse: Theorem¬†4.1\nBayes‚Äô Theorem: Theorem¬†6.1\nBayes‚Äô Theorem 2: Theorem¬†6.8\nBayes‚Äô Theorem 3: Theorem¬†6.8\nBayes‚Äô Theorem f√ºr zusammengesetzte Hypothesen: Theorem¬†6.9\nBinomialkoeffizient: Theorem¬†5.3\nBinomialverteilung: Theorem¬†5.2\nNotation f√ºr eine binomialverteilte Zufallsvariable: Theorem¬†5.1\nRegression als Korrelation: Theorem¬†11.2\nIndifferenzprinzip: Theorem¬†3.1\nEvidenz: Theorem¬†6.3\nEvidenz 2: Theorem¬†6.4\nHypothese f√ºr ungleiche Mittelwerte: Theorem¬†11.1\nGemeinsame Wahrscheinlichkeit: Theorem¬†4.10\nStochastische Unabh√§ngigkeit: Theorem¬†4.4\nSymmetrie der Unabh√§ngigkeit: Theorem¬†4.8\nStochastische Unabh√§ngigkeit 2: Theorem¬†4.5\nKettenregel: Theorem¬†4.11\nLaplace-Experiment: Theorem¬†3.2\nLineares Modell (Regressionsgleichung): Theorem¬†2.1\nLogarithmus: ?thm-logarithmus\nModelldefinition: Theorem¬†9.1\nNullhypothesentest: Theorem¬†10.1\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse: Theorem¬†4.9\nStandardisierte Posteriori-Verteilung: Theorem¬†6.6\nPosteriori-Verteilung 2: Theorem¬†6.7\nBedingte Wahrscheinlichkeit: Theorem¬†4.3\nStandardnormalverteilung: ?thm-standardnormal\nTotale Wahrscheinlichkeit: Theorem¬†4.12\nUnstandardisierte Posteriori-Wahrscheinlichkeit : Theorem¬†6.5\nz-Transformation: ?thm-ztrans",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Theoreme</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Badenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A.,\n& Longobardi, C. (2016). Misconceptions of the p-value among\nChilean and Italian Academic Psychologists.\nFrontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende\nStatistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen\n(7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√ºbungen: Beschreibende\nstatistik ‚Äì wahrscheinlichkeitsrechnung ‚Äì schlie√üende statistik (7.\nAuflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of\nModeling, Probability &\nStatistics. Springer.\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155‚Äì159.\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020).\nRstanarm: Bayesian applied regression modeling via\nStan. https://mc-stan.org/rstanarm\n\n\nHenze, N. (2019). Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der\nMa√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Springer Berlin\nHeidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157‚Äì1164.\nhttp://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability theory:\nThe logic of science. Cambridge University Press.\n\n\nKabadayi, F. (2024). Smartphone addiction, depression, distress,\neustress, loneliness, and sleep deprivation in adolescents: A latent\nprofile and network analysis approach. BMC Psychology,\n12(1), 608. https://doi.org/10.1186/s40359-024-02117-6\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter\nValues in Bayesian Estimation. Advances in\nMethods and Practices in Psychological Science, 1(2),\n270‚Äì280. https://doi.org/10.1177/2515245918771304\n\n\nKurz, S. (2021). Statistical Rethinking with\nBrms, Ggplot2, and the Tidyverse:\nSecond Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D.\n(2019). Indices of Effect Existence and\nSignificance in the Bayesian Framework.\nFrontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd ed.). Taylor and Francis, CRC\nPress.\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes factor approaches for\ntesting interval null hypotheses. Psychological Methods,\n16(4), 406‚Äì419. https://doi.org/10.1037/a0024377\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference\nin statistics: A primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPopper, K. (2013). Logik der Forschung (H. Keuth,\nEd.). Akademie Verlag. https://doi.org/10.1524/9783050063782\n\n\nSauer, S. (2025). Statistik1. Independently published via\nAmazon. https://www.amazon.de/Statistik1-Einf%C3%BChrung-Statistik-Schwerpunkt-Prognose-Modellierung/dp/B0F673WGG5\n\n\nShmueli, G. (2010). To Explain or to Predict?\nStatistical Science, 25(3), 289‚Äì310. https://doi.org/10.1214/10-STS330\n\n\nvan Kampen, D. (2014). The SSQ model of schizophrenic\nprodromal unfolding revised: An analysis of its causal\nchains based on the language of directed graphs. European\nPsychiatry, 29(7), 437‚Äì448. https://doi.org/10.1016/j.eurpsy.2013.11.001\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs\nStatement on p-Values: Context,\nProcess, and Purpose. The American\nStatistician, 70(2), 129‚Äì133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Anhang",
      "Literaturverzeichnis"
    ]
  },
  {
    "objectID": "imprint.html",
    "href": "imprint.html",
    "title": "15¬† Impressum",
    "section": "",
    "text": "15.1 Vertreten durch:\nAngaben gem√§√ü ¬ß 5 DDG\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach\nSebastian Sauer",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#kontakt",
    "href": "imprint.html#kontakt",
    "title": "15¬† Impressum",
    "section": "15.2 Kontakt:",
    "text": "15.2 Kontakt:\nTelefon: 0981 4877 0, E-Mail: sebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#aufsichtsbeh√∂rde",
    "href": "imprint.html#aufsichtsbeh√∂rde",
    "title": "15¬† Impressum",
    "section": "15.3 Aufsichtsbeh√∂rde:",
    "text": "15.3 Aufsichtsbeh√∂rde:\nN√ºrnberg",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "href": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "title": "15¬† Impressum",
    "section": "15.4 Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:",
    "text": "15.4 Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#haftungsausschluss",
    "href": "imprint.html#haftungsausschluss",
    "title": "15¬† Impressum",
    "section": "15.5 Haftungsausschluss:",
    "text": "15.5 Haftungsausschluss:\n\n15.5.1 Haftung f√ºr Inhalte\nDie Inhalte unserer Seiten wurden mit gr√∂√üter Sorgfalt erstellt. F√ºr die Richtigkeit, Vollst√§ndigkeit und Aktualit√§t der Inhalte k√∂nnen wir jedoch keine Gew√§hr √ºbernehmen. Als Diensteanbieter sind wir gem√§√ü ¬ß 7 Abs.1 DDG f√ºr eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach ¬ß¬ß 8 bis 10 DDG sind wir als Diensteanbieter jedoch nicht verpflichtet, √ºbermittelte oder gespeicherte fremde Informationen zu √ºberwachen oder nach Umst√§nden zu forschen, die auf eine rechtswidrige T√§tigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unber√ºhrt. Eine diesbez√ºgliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung m√∂glich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\n\n\n15.5.2 Haftung f√ºr Links\nUnser Angebot enth√§lt Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb k√∂nnen wir f√ºr diese fremden Inhalte auch keine Gew√§hr √ºbernehmen. F√ºr die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf m√∂gliche Rechtsverst√∂√üe √ºberpr√ºft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n\n\n15.5.3 Urheberrecht\nDie durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielf√§ltigung, Bearbeitung, Verbreitung und jede Art der Verwertung au√üerhalb der Grenzen des Urheberrechtes bed√ºrfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur f√ºr den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n\n\n15.5.4 Datenschutz\nDie Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten m√∂glich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit m√∂glich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdr√ºckliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Daten√ºbertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitsl√ºcken aufweisen kann. Ein l√ºckenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht m√∂glich. Der Nutzung von im Rahmen der Impressumspflicht ver√∂ffentlichten Kontaktdaten durch Dritte zur √úbersendung von nicht ausdr√ºcklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdr√ºcklich widersprochen. Die Betreiber der Seiten behalten sich ausdr√ºcklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, Fachanw√§lte f√ºr Familienrecht",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "data-privacy.html",
    "href": "data-privacy.html",
    "title": "16¬† Datenschutzhinweise",
    "section": "",
    "text": "16.1 Einleitung\nDiese Datenschutzhinweise informieren Sie √ºber die Art, den Umfang und den Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend ‚ÄúDaten‚Äù) im Rahmen der Nutzung dieser Webseite (nachfolgend ‚ÄúWebseite‚Äù), die auf GitHub gehostet wird.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#einleitung",
    "href": "data-privacy.html#einleitung",
    "title": "16¬† Datenschutzhinweise",
    "section": "",
    "text": "16.1.1 Verantwortliche Person\nProf.¬†Dr.¬†habil. Sebastian Sauer, Residenzstr. 10, 90522 Ansbach, sebastian.sauer@hs-ansbach.de\n\n\n16.1.2 Hosting durch GitHub\nUnsere Webseite wird von GitHub Inc., 88 Colin P. Kelly Jr.¬†St, San Francisco, CA 94107, USA (‚ÄúGitHub‚Äù) gehostet. GitHub verarbeitet in unserem Auftrag Daten von Webseitenbesuchern (z.B. IP-Adressen). Dies ist f√ºr den Betrieb der Webseite und die Bereitstellung von Inhalten erforderlich. GitHub ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europ√§ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC&status=Active).\nWeitere Informationen zum Datenschutz bei GitHub finden Sie in der Datenschutzerkl√§rung von GitHub: https://docs.github.com/de/site-policy/privacy-policies/github-general-privacy-statement",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#datenerhebung-und--verarbeitung",
    "href": "data-privacy.html#datenerhebung-und--verarbeitung",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.2 Datenerhebung und -verarbeitung",
    "text": "16.2 Datenerhebung und -verarbeitung\n\n16.2.1 Server-Log-Dateien\nBei jedem Zugriff auf unsere Webseite erfasst GitHub automatisiert Daten und speichert diese in Server-Log-Dateien. Zu diesen Daten geh√∂ren: IP-Adresse des zugreifenden Ger√§ts Datum und Uhrzeit des Zugriffs Name und URL der abgerufenen Datei Webseite, von der aus der Zugriff erfolgt (Referrer-URL) Verwendeter Browser und ggf. das Betriebssystem des zugreifenden Ger√§ts Name des Access-Providers\nDie Verarbeitung dieser Daten erfolgt, um die Funktionsf√§higkeit der Webseite sicherzustellen, die Nutzung der Webseite zu analysieren und unser Angebot zu verbessern. Rechtsgrundlage f√ºr die Datenverarbeitung ist Art. 6 Abs. 1 lit. f DSGVO (berechtigtes Interesse). Unser berechtigtes Interesse liegt in den oben genannten Zwecken.\n\n\n16.2.2 Cookies\nUnsere Webseite verwendet keine Cookies.\n\n\n16.2.3 Einbindung von Drittinhalten\nEs k√∂nnen Inhalte von Drittanbietern wie Videos, Schriftarten oder Karten eingebunden sein. Beim Abruf dieser Inhalte wird Ihre IP-Adresse m√∂glicherweise an den Drittanbieter √ºbertragen. F√ºr weitere Informationen konsultiere bitte die Datenschutzrichtlinien der jeweiligen Anbieter.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#ihre-rechte",
    "href": "data-privacy.html#ihre-rechte",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.3 Ihre Rechte",
    "text": "16.3 Ihre Rechte\nSie habengegen√ºber uns folgende Rechte hinsichtlich der dich betreffenden personenbezogenen Daten: Recht auf Auskunft (Art. 15 DSGVO) Recht auf Berichtigung (Art. 16 DSGVO) Recht auf L√∂schung (Art. 17 DSGVO) Recht auf Einschr√§nkung der Verarbeitung (Art. 18 DSGVO) Recht auf Daten√ºbertragbarkeit (Art. 20 DSGVO) Recht auf Widerspruch gegen die Verarbeitung (Art. 21 DSGVO)\nSie haben zudem das Recht, sich bei einer Datenschutz-Aufsichtsbeh√∂rde √ºber die Verarbeitung deiner personenbezogenen Daten durch uns zu beschweren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "href": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.4 Anwendbare Rechtsgrundlagen",
    "text": "16.4 Anwendbare Rechtsgrundlagen\nNachstehend geben wir Ihnen eine √úbersicht der rechtlichen Grundlagen der DSGVO, auf deren Basis personenbezogene Daten auf dieser Webseite verarbeitet werden. Bitte beachten Sie, dass neben den Regelungen der DSGVO auch nationale Datenschutzvorgaben in Ihrem oder unserem Land relevant sein k√∂nnen. Sofern in Einzelf√§llen spezifische Rechtsgrundlagen gelten, werden diese in der Datenschutzerkl√§rung gesondert erw√§hnt.\n\n16.4.1 Vertragserf√ºllung und vorvertragliche Ma√ünahmen (Art. 6 Abs. 1 S. 1 lit. b) DSGVO)\nDie Verarbeitung personenbezogener Daten ist erforderlich zur Erf√ºllung eines Vertrags, bei dem die betroffene Person Vertragspartei ist, oder zur Durchf√ºhrung vorvertraglicher Ma√ünahmen, die auf Anfrage der betroffenen Person erfolgen.\n\n\n16.4.2 Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO)\nDie Datenverarbeitung erfolgt zur Wahrung berechtigter Interessen des Verantwortlichen oder eines Dritten, sofern keine entgegenstehenden Interessen, Grundrechte oder Grundfreiheiten der betroffenen Person, die den Schutz ihrer personenbezogenen Daten erfordern, √ºberwiegen.\n\n\n16.4.3 Nationale Datenschutzbestimmungen in Deutschland\nNeben der DSGVO gelten in Deutschland nationale Datenschutzvorgaben, insbesondere das Bundesdatenschutzgesetz (BDSG). Das BDSG beinhaltet spezielle Regelungen zum Recht auf Auskunft, L√∂schung, Widerspruch, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung f√ºr andere Zwecke sowie zur Daten√ºbermittlung und zu automatisierten Einzelentscheidungen einschlie√ülich Profiling. In bestimmten F√§llen k√∂nnen auch Datenschutzgesetze der Bundesl√§nder Anwendung finden.\n\n\n16.4.4 Hinweis auf die Geltung von DSGVO und Schweizer DSG\nDiese Datenschutzhinweise ber√ºcksichtigen die Vorgaben sowohl der DSGVO als auch des Schweizer Datenschutzgesetzes (DSG). Zur besseren Verst√§ndlichkeit und zur Vermeidung wiederholter Begriffsdefinitionen werden die Begriffe der DSGVO verwendet. Begriffe wie ‚ÄûVerarbeitung‚Äú, ‚Äûpersonenbezogene Daten‚Äú, ‚Äûberechtigtes Interesse‚Äú und ‚Äûbesondere Kategorien von Daten‚Äú entsprechen inhaltlich den Begriffen ‚ÄûBearbeitung‚Äú, ‚ÄûPersonendaten‚Äú, ‚Äû√ºberwiegendes Interesse‚Äú und ‚Äûbesonders sch√ºtzenswerte Personendaten‚Äú des Schweizer DSG. Die genaue Auslegung und Anwendung erfolgt jedoch gem√§√ü den Vorgaben des Schweizer DSG.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#sicherheitsma√ünahmen",
    "href": "data-privacy.html#sicherheitsma√ünahmen",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.5 Sicherheitsma√ünahmen",
    "text": "16.5 Sicherheitsma√ünahmen\nWir setzen angemessene technische und organisatorische Ma√ünahmen zum Schutz Ihrer Daten entsprechend den gesetzlichen Anforderungen um. Dabei ber√ºcksichtigen wir den aktuellen Stand der Technik, die Implementierungskosten, Art, Umfang, Umst√§nde und Zweck der Verarbeitung sowie die Wahrscheinlichkeit und Schwere m√∂glicher Risiken f√ºr die Rechte und Freiheiten betroffener Personen.\nZu den Schutzma√ünahmen geh√∂ren insbesondere: Sicherstellung der Vertraulichkeit, Integrit√§t und Verf√ºgbarkeit von Daten durch Kontrolle des Zugriffs auf die Daten und die Infrastruktur, der Eingaben, Weitergaben und Trennungen von Daten. Zudem haben wir Verfahren eingerichtet, um die Rechte betroffener Personen zu gew√§hrleisten, Daten zu l√∂schen und angemessen auf Bedrohungen zu reagieren. Bereits in der Entwicklung und Auswahl von Hard- und Software sowie Verfahren ber√ºcksichtigen wir Datenschutzprinzipien wie Datenschutz durch Technikgestaltung und datenschutzfreundliche Voreinstellungen.\nSicherung von Online-Verbindungen mit TLS-/SSL-Verschl√ºsselung (HTTPS) Um die Daten√ºbertragung √ºber unsere Online-Dienste vor unbefugtem Zugriff zu sch√ºtzen, nutzen wir die TLS-/SSL-Verschl√ºsselungstechnologie. Dies gew√§hrleistet eine sichere Daten√ºbertragung zwischen unserem Server und Ihrem Browser, erkennbar an der HTTPS-Kennung in der URL-Leiste.\n\n16.5.1 Internationale Daten√ºbertragungen\nFalls Datenverarbeitungen in Drittl√§ndern (au√üerhalb der EU und des EWR) stattfinden oder personenbezogene Daten an Dritte im Ausland √ºbermittelt werden, erfolgt dies ausschlie√ülich unter Einhaltung gesetzlicher Anforderungen. Sofern ein Angemessenheitsbeschluss der EU-Kommission f√ºr das betreffende Drittland vorliegt (Art. 45 DSGVO), gilt dieser als Grundlage der √úbertragung. Falls kein Angemessenheitsbeschluss vorliegt, sichern Standardvertragsklauseln (Art. 46 Abs. 2 lit. c) DSGVO), eine ausdr√ºckliche Einwilligung oder gesetzliche Erfordernisse die √úbertragung ab (Art. 49 Abs. 1 DSGVO).\nWeitere Informationen zu den Angemessenheitsbeschl√ºssen der EU-Kommission finden Sie auf dieser Seite. Die USA bieten mit dem sogenannten ‚ÄûData Privacy Framework‚Äú (DPF) eine Regelung zur Sicherstellung eines angemessenen Datenschutzniveaus, das durch die EU-Kommission am 10.07.2023 anerkannt wurde. Die Liste der zertifizierten Unternehmen und weitere Informationen finden Sie auf der Webseite des US-Handelsministeriums unter Data Privacy Framework.\nWir informieren Sie in unseren Datenschutzhinweisen, welche Drittanbieter unter diesem Rahmen zertifiziert sind.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#kontakt",
    "href": "data-privacy.html#kontakt",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.6 Kontakt",
    "text": "16.6 Kontakt\nF√ºr Anfragen zum Datenschutz k√∂nnen Sie sich an uns wenden:\nProf.¬†Dr.¬†habil. Sebastian Sauer\nResidenzstr. 10, 90522 Ansbach\nsebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "href": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.7 √Ñnderung der Datenschutzhinweise",
    "text": "16.7 √Ñnderung der Datenschutzhinweise\nWir behalten uns vor, diese Datenschutzhinweise jederzeit anzupassen, um sie an ge√§nderte Rechtslagen oder bei √Ñnderungen des Dienstes sowie der Datenverarbeitung anzupassen.\nStand: 15. November 2024",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  }
]