[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 Einf√ºhrung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie ‚Ä¶\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden k√∂nnen\ng√§ngige einschl√§gige Forschungsfragen in statistische Modelle √ºbersetzen und mit R auswerten k√∂nnen\nkausale Forschungsfragen in statistische Modelle √ºbersetzen und pr√ºfen k√∂nnen\ndie G√ºte und Grenze von statistischen Modellen einsch√§tzen k√∂nnen\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage f√ºr Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und M√§nner vor eine Einpark-Aufgabe gestellt (nat√ºrlich alles sch√∂n standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen k√∂nnen schneller einparken als M√§nner, im Durchschnitt. Das h√§tten wir also gekl√§rt. Aber haben wir das ganz sicher gekl√§rt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich wei√ü, das ist jetzt ein harter Schlag f√ºr Sie‚Ä¶ Aber die gute Nachricht ist: Wir k√∂nnen angeben, wie (un)sicher wir bei mit einer Aussage (‚ÄúFrauen parken schneller‚Ä¶‚Äù) sind. Zum Beispiel k√∂nnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie n√§chste Woche ei Fahri f√ºr Ihren neuen Rolls Royce anheuern, m√ºssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, m√ºssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen ‚Äúlaut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauen‚Äù. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es √ºblich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den ‚ÄúTop 20 job roles in increasing and decreasing demand across industries‚Äù (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 Modul√ºberblick\nAbbildung¬†1.1 gibt einen √úberblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n  subgraph Kausalit√§t\n    Kausalstart\n  end \n  Wskt --&gt; Bayes --&gt; Regression --&gt; Kausalit√§t\n\n\n\n\nAbbildung¬†1.1: Modulverlauf im √úberblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelle¬†1.1 gibt einen √úberblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist n√ºtzlich f√ºr Sie, die Tabelle Tabelle¬†1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als n√§chstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelle¬†1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\nKW\nJahr\nWochenstart\nVL-frei\nNr\nThema\nKommentar\n\n\n\n40\n2024\n2024-09-30\nteilweise\n1\nEinstieg\nVL-frei am Do.; Di frei NUR f√ºr Erstis\n\n\n41\n2024\n2024-10-07\nnein\n2\nInferenz\nNA\n\n\n42\n2024\n2024-10-14\nnein\n3\nWahrscheinlichkeit\nNA\n\n\n43\n2024\n2024-10-21\nnein\n4\nVerteilungen\nNA\n\n\n44\n2024\n2024-10-28\nteilweise\n5\nAufholwoche\nVL-frei am Do und Fr\n\n\n45\n2024\n2024-11-04\nnein\n7\nGlobusversuch\nNA\n\n\n46\n2024\n2024-11-11\nnein\n7\nDie Post befragen\nNA\n\n\n47\n2024\n2024-11-18\nja\nNA\n-\nBlockwoche\n\n\n48\n2024\n2024-11-25\nnein\n8\nGauss-Modelle\nNA\n\n\n49\n2024\n2024-12-02\nnein\n9\nEinfache lineare Modelle\nNA\n\n\n50\n2024\n2024-12-09\nnein\n10\nSch√§tzen vs. Testen\nNA\n\n\n51\n2024\n2024-12-16\nnein\n11\nAufholwoche\nNA\n\n\n52\n2024\n2024-12-23\nja\nNA\n-\nNA\n\n\n1\n2025\n2024-12-30\nja\nNA\n-\nNA\n\n\n2\n2025\n2025-01-06\nteilweise\n12\nFallbeispiele\nVL-frei am Mo\n\n\n3\n2025\n2025-01-13\nnein\n13\nAbschluss\nNA\n\n\n4\n2025\n2025-01-20\nja\nNA\n-\nPr√ºfungszeit beginnt\n\n\n5\n2025\n2025-01-27\nja\nNA\n-\nVL-freie Zeit beginnt\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nF√ºr dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, m√∂glichst auch mit dem tidyverse\n\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.B. im Online-Buch ‚ÄúStatistik1‚Äù vermittelt. Alle Inhalte daraus werden in diesem Kurs ben√∂tigt.\n\n1.1.6 PDF-Version\nSie k√∂nnen die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.\nAlternativ finden Sie hier die Kapitel als PDF-Version. Achtung: Diese PDF-Versionen sind nicht unbedingt aktuell.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#lernhilfen",
    "href": "index.html#lernhilfen",
    "title": "Start:Bayes!",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nHier finden Sie einen √úberblick zu Lernhilfen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Start:Bayes!",
    "section": "\n1.3 Software",
    "text": "1.3 Software\nSie ben√∂tigen R, RStudio und einige R-Pakete insbesondere rstanarm f√ºr diesen Kurs.\nHier finden Sie Installationshinweise.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.4 Hinweise",
    "text": "1.4 Hinweise\n\n\n\n\n\n\nHinweis\n\n\n\nAlle formalen Hinweise (Pr√ºfung, Unterrichtsorganisation, ‚Ä¶) sind auf der Seite https://hinweisbuch.netlify.app/ zu finden. \\(\\square\\)\n\n\n\nüì∫ Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine Pr√ºfung in diesem Modul ist jedes Semester m√∂glich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#tutorium",
    "href": "index.html#tutorium",
    "title": "Start:Bayes!",
    "section": "\n1.5 Tutorium",
    "text": "1.5 Tutorium\nF√ºr dieses Modul wird ggf. ein Tutorium angeboten.\nDer Besuch des Tutoriums ist zu empfehlen. Arbeiten Sie auch das Materials auf der Webseite des Tutoriums durch.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#pr√ºfung",
    "href": "index.html#pr√ºfung",
    "title": "Start:Bayes!",
    "section": "\n1.6 Pr√ºfung",
    "text": "1.6 Pr√ºfung\nDas aktuelle Pr√ºfungsformat ist: Klausur im Mehrfachwahlverfahren (Multiple Choice).\nHilfsmittel wie Skripte oder Notizen sind nicht zul√§ssig. Die Pr√ºfung findet (ausschlie√ülich) in Pr√§senz statt.\n\nAllgemeine Pr√ºfungshinweise\n\n\nHinweise zu quantitativen Pr√ºfungen\nPr√ºfungsvorbereitung\n\nIn Kapitel 13 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren k√∂nnen:\n@book{sauer_startbayes,\n    title = {Start:Bayes},\n    rights = {CC-BY-NC},\n    url = {https://start-bayes.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2023},\n}\nHier ist die DOI:\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Start:Bayes!",
    "section": "\n1.8 Zum Autor",
    "text": "1.8 Zum Autor\nN√§here Hinweise zum Autor, Sebastian Sauer, finden Sie hier.\n\n\n\n\nForum, W. E. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html",
    "href": "0200-Inferenz.html",
    "title": "\n2¬† Inferenz\n",
    "section": "",
    "text": "2.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#lernsteuerung",
    "href": "0200-Inferenz.html#lernsteuerung",
    "title": "\n2¬† Inferenz\n",
    "section": "",
    "text": "2.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n2.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Definition von Inferenzstatistik sowie Beispiele f√ºr inferenzstatistische Fragestellungen nennen\nzentrale Begriffe der Inferenzstatistik nennen und in Grundz√ºgen erkl√§ren\nden Nutzen von Inferenzstatistik nennen\nerl√§utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nanhand von Beispielen erkl√§ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen frequentistischer (‚Äúklassischer‚Äù) und Bayes-Inferenz benennen\nVor- und Nachteile der frequentistischen vs.¬†Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erkl√§ren\n\n2.1.3 Begleitliteratur\nBei Gelman et al. (2021), Kap. 1 findet sich eine Darstellung √§hnlich zu der in diesem Kapitel.\n\n2.1.4 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. ‚ÄúRahmen‚Äù\n\nStatistik 1, dort alle Inhalte zum Thema ‚ÄúModellieren‚Äù und ‚ÄúRegression‚Äù\n\n2.1.5 Begleitvideos\n\nVideo zur Inferenz, Teil 1\nVideo zur Inferenz, Teil 2\n\n2.1.6 Wozu ist Statistik √ºberhaupt da?\nüì∫ Ja, wozu ist Statistik eigentlich da?\nJa, diese Frage haben Sie sich auch schon mal gestellt? Abb. Abbildung¬†2.1 gibt einen √úberblick √ºber die Zielarten der statistikbasierten wissenschaftlichen Forschung.1 Nach dieser Einteilung lassen sich drei Arten von Zielen unterscheiden: Beschreiben, Vorhersagen und Erkl√§ren (Shmueli, 2010).\nüìÑ Beschreiben (deskriptiv)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von Gr√∂√üe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\nüîÆ Vorhersagen (pr√§diktiv, prognostisch)\n\nWie schwer ist ein deutscher Mann der Gr√∂√üe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts f√ºr die Klausur lernt?\nWie viel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufh√§lt?\n\nüîó Erkl√§ren (kausal)\n\nIst Gr√∂√üe eine Ursache von Gewicht (bei deutschen M√§nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erkl√§rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie geh√∂rt.\n\n\n\nBeispiel 2.1 (Beispiele f√ºr die Zielarten statistischer Analysen) ¬†\n\nBeschreiben: ‚ÄúWie gro√ü ist der Gender-Paygap in der Branche X im Zeitraum Y?‚Äù\nVorhersagen: Wenn eine Person, Mr.¬†X, 100 Stunden auf die Statistikklausur lernen, welche Note kann diese Person dann erwarten?\nErkl√§ren: Wie viel bringt (mir) das Lernen auf die Statistikklausur?\\(\\square\\)\n\n\n\nF√ºr die Wissenschaft ist Erkl√§ren das wichtigste Ziel. Bei wenig beackerten Wissenschaftsfeldern ist das Beschreiben ein sinnvoller erster Schritt, der allerdings nicht Stolperfallen ist, wie in Kapitel 11 erl√§utert. Vorhersagen ist mehr f√ºr die Praxis als f√ºr die Wissenschaft relevant.2\n\n\n\n\n\nflowchart TD \n  A{Goals} --&gt; B(describe)\n  A --&gt; C(predict)\n  A --&gt; D(explain)\n  B --&gt; E(distribution)\n  B --&gt; F(assocation)\n  B --&gt; G(extrapolation)\n  C --&gt; H(point estimate)\n  C --&gt; I(interval)\n  D --&gt; J(causal inference)\n  D --&gt; K(population)\n  D --&gt; L(latent construct)\n\n\n\n\n\nAbbildung¬†2.1: Eine Einteilung der Ziele von statistischen Analysen",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#was-ist-inferenz",
    "href": "0200-Inferenz.html#was-ist-inferenz",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.2 Was ist Inferenz?",
    "text": "2.2 Was ist Inferenz?\n\n\n\n\n\nüì∫ Was ist Inferenz?\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlie√üen, bzw. vom Konkreten auf das Abstrakte. 3\nTypischerweise untersuchen im Rahmen einer statistischen Analyse eine Stichprobe, wie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht ‚ÄúTolle Studie zu dem Geheimnis des Gl√ºcks!!!‚Äù zu klicken. Ihr Freundeskreis ist ein Teil der Menschen (z.B. aus Deutschland), also eine Stichprobe. Schauen wir uns den Unterschied zwischen Stichprobe und Population n√§her an.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#stichprobe-vs.-population",
    "href": "0200-Inferenz.html#stichprobe-vs.-population",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.3 Stichprobe vs.¬†Population",
    "text": "2.3 Stichprobe vs.¬†Population\nNehmen wir an, wir m√∂chten herausfinden, wie gro√ü der Anteil der R-Fans in der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A4.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.\nWir m√ºssen also den Anteil der R-Fans in der Population auf Basis des Anteils in der Stichprobe schlie√üen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. Abbildung¬†2.2 und Abbildung¬†2.3.\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†2.2: Population\n\n\n\n\n\n\n\n\n\nAbbildung¬†2.3: Sample\n\n\n\n\n\n\nPopulation vs.¬†Sample. Autor: Karsten L√ºbke. OEM\n\n\n\n\n\n\n\nH√§ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!5. Man schreibt gerne: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei repr√§sentativ f√ºr die Grundgesamtheit aller Studierender. Messerscharf schlie√üen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische (\\(\\pi\\)) f√ºr Populationen.\\(\\square\\)\n\n\n\n2.3.1 Deskriptiv- vs.¬†Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtungen, k√∂nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. Abbildung¬†2.4.\nVereinfacht gesprochen fasst die Deskriptivstatistik Daten (einer Stichprobe) zu einer einzelnen Kennzahl zusammen.\n\nBeispiel 2.2 In einem H√∂rsaal sitzen 100 Studis. Alle schreiben Ihre K√∂rpergr√∂√üe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der K√∂rpergr√∂√üe der anwesenden Studentis aus. Voil√†: Deskriptive Statistik!\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†2.4: Deskriptiv- vs.¬†Inferenzstatistik\n\n\n\n√úbungsaufgabe 2.1 üèã Schlie√üen Sie die Augen und zeichnen Sie obiges Diagramm, Abbildung¬†2.4!\\(\\square\\)\n\n\nDefinition 2.1 (Deskriptivstatistik) Deskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\n\n\nDefinition 2.2 (Inferenzstatistik) Inferenzstatistik ist ein Verfahren zum Schlie√üen von Statistiken (eine Kennzahl einer Stichprobe) auf Parameter (eine Kennzahl einer Grundgesamtheit). Inferenz bedeutet Schlie√üen bzw. Schlussfolgdern: auf Basis von vorliegenden Wissen wird neues Wissen generiert. Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schl√ºsse zu ziehen.\n\n\n√úbungsaufgabe 2.2 üèãÔ∏èÔ∏è Heute Nacht vor dem Schlafen wiederholen Sie die Definition. √úben Sie jetzt schon mal.\\(\\square\\)\n\n\n2.3.2 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nF√ºr jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, um den zugeh√∂rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle Tabelle¬†2.1. Da man die Parameter der Population so gut wie nie sicher kennt (schlie√ülich hat man meist nur Ausz√ºge, Teile der Population, also Stichproben), muss man sich mit Sch√§tzwerten begn√ºgen.\n\n\n\nTabelle¬†2.1: Bezeichnungen f√ºr Kennwerte\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit (Aussprache)\nSch√§tzwert\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\n\\(\\mu\\) (m√º)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\n\\(\\sigma\\) (sigma)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\n\\(\\pi\\) (pi)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\n\\(\\rho\\) (rho)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\n\\(\\beta\\) (beta)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n\nF√ºr Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; f√ºr Parameter (Population) verwendet man griechische Buchstaben.\n\n√úbungsaufgabe 2.3 üèãÔ∏è Geben Sie die griechischen Buchstaben f√ºr typische Statistiken an. Ohne auf die Tabelle zu schauen.üòú\\(\\square\\)!\n\n\n2.3.3 Sch√§tzen von Parametern einer Grundgesamtheit\nMeist begn√ºgt man sich beim Analysieren von Daten nicht mit Aussagen f√ºr eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit Sch√§tzungen begn√ºgen. Sch√§tzwerte werden mit einem ‚ÄúDach‚Äù √ºber dem Kennwert gekennzeichnet, s. letzte Spalte in Tabelle¬†2.1.\nIn der angewandten Forschung interessieren h√§ufig Fragen wie: ‚ÄúWelche Entscheidung ist (wahrscheinlich) besser?‚Äù. Da bekanntlich (fast) keine Aussagen sicher sind, spielt Wahrscheinlichkeit eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinlichkeit wird oft mit Pr oder p abgek√ºrzt, f√ºr engl. probability.\\(\\square\\)\n\n\n\nBeispiel 2.3 Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.¬†V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\). Die Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} &gt; \\bar{X}_{V2}\\). Sind diese Unterschiede ‚Äúzuf√§llig‚Äù oder ‚Äúsubstanziell‚Äù? Gilt also \\(\\mu_{V1} &gt; \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)? Wie gro√ü ist die Wahrscheinlichkeit \\(Pr(\\mu_{V1} &gt; \\mu_{V2})\\)?\n\n\n√úbungsaufgabe 2.4 üèãÔ∏è VERTIEFUNG Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#modellieren",
    "href": "0200-Inferenz.html#modellieren",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.4 Modellieren",
    "text": "2.4 Modellieren\n\n2.4.1 Modellieren als Grundraster des Erkennens\nIn In der Wissenschaft ‚Äì wie auch oft in der Technik, Wirtschaft oder im Alltag ‚Äì betrachtet man einen Teil der Welt n√§her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen. Nun ist die Welt ein weites Feld. Jedes Detail zu ber√ºcksichtigen ist nicht m√∂glich. Wir m√ºssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend n√∂tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die f√ºr unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\nDefinition 2.3 (Modell) Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit.\\(\\square\\)\n\nDer Nutzen eines Modells ist, einen (√ºberm√§√üig) komplexen Sachverhalt zu vereinfachen oder √ºberhaupt erst handhabbar zu machen. Man versucht zu vereinfachen, ohne Wesentliches wegzulassen. Der Speck muss weg, sozusagen. Das Wesentliche bleibt.\nAuf die Statistik bezogen hei√üt das, dass man einen Datensatz dabei so zusammenfasst, damit man das Wesentliche erkennt.\nWas ist das ‚ÄúWesentliche‚Äù? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. Etwa: ‚ÄúWie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?‚Äù6 Noch allgemeiner ist man dabei h√§ufig am Zusammenhang von X und Y interessiert, s. Abbildung¬†2.5, die ein Sinnbild von statistischen Modellen widergibt.\nWas ist das ‚ÄúWesentliche‚Äù? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. Etwa: ‚ÄúWie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?‚Äù7 Noch allgemeiner ist man dabei h√§ufig am Zusammenhang von X und Y interessiert, s. Abbildung¬†2.5, die ein Sinnbild von statistischen Modellen widergibt.\n\n\n\n\n\n\n\nflowchart LR\nX --&gt; Y\n\n\nX1 --&gt; Y2\nX2 --&gt; Y2\n\n\n\n\n\n\n\n\nAbbildung¬†2.5: oben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\nMan kann Abbildung¬†2.5 als ein Sinnbild einer (mathematischen) Funktion lesen.\n\nDefinition 2.4 (Funktion) Eine Funktion \\(f\\) setzt zwei Gr√∂√üen in Beziehung. \\(\\square\\)\n\nIn Mathe-Sprech: \\(f: X \\rightarrow Y\\)\noder: \\(y = f(x)\\), lies: ‚ÄúY ist eine Funktion von X‚Äù.\nEs h√∂rt sich zugespitzt an, aber eigentlich ist fast alles, was man tut, Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\nDie Statistik kann man verstehen als ein Verfahren, dass wissenschaftliche Modelle in statistische √ºbersetzt und letztere dann einer empirischen Analyse unterzieht.\nAlle statistischen Ergebnisse beruhen auf Modelle und sind nur insoweit g√ºltig, wie das zugrundeliegende Modell g√ºltig ist.\n\n2.4.2 Vertiefung\nLesen Sie die Einf√ºhrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nHinweis\n\n\n\nNutzen Sie die √úbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#regression",
    "href": "0200-Inferenz.html#regression",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.5 Regression",
    "text": "2.5 Regression\nEinflussreiche Leute schw√∂ren auf die Regressionsanalyse (Abbildung¬†2.6).\n\n\n\n\n\nAbbildung¬†2.6: One regression\n\n\nAbbildung¬†2.7 zeigt ein interaktives Beispiel einer linearen Funktion. Sie k√∂nnen Punkte per Klick/Touch hinzuf√ºgen.\nCoderesetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\nCodeviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\nCoderSquaredPlot = RSquaredPlot({ width: width })\nCoderegressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\nCodewidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\nCodeanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\nCodefunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R¬≤\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\nCode// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\nCoded3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelle\n\n\n\nAbbildung¬†2.7: Interaktives Beispiel f√ºr eines lineares Modell. F√ºgen Sie Punkte per Klick/Touch hinzu.\n\n\nAlternativ k√∂nnen Sie diese App njutzen, Regressionskoeffizienten, Steigung (slope) und Achsenabschnitt (Intercept), zu optimieren. Dabei meint ‚Äúoptimieren‚Äù, die Abweichungen (Residuen, Residualfehler; die roten Balken in der App) zu minimieren.8\nHier finden Sie eine App, die Ihnen gestattet, selber Hand an eine Regressionsgerade zu legen.\n\n√úbungsaufgabe 2.5 (VERTIEFUNG Regression mit Animationen erkl√§rt) Lesen Sie diesen Post, der Ihnen mit Hilfe von Bildern und Animationen (okay, und etwas) Text die Grundlagen der Regressionsanalyse erkl√§rt.\\(\\square\\)\n\n\n2.5.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmesser der Statistik: F√ºr vieles gut einsetzbar. Anstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch sch√∂ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden. Dann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nHinweis\n\n\n\nRegression + Inferenz = üíñ\n\n\nAlternativ zur Regression k√∂nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni M√ºnster als Ausschnitt (!) aufgef√ºhrt. Auf dieser Basis kann man meditieren, welches statistischen Verfahren man f√ºr eine bestimmte Fragestellung verwenden sollte, s. Abb. Abbildung¬†2.8. Muss man aber nicht ‚Äì man kann stattdessen die Regression benutzen.\n\n\n\n\n\nAbbildung¬†2.8: W√§hle deine Statistik mit Bedacht. Oder w√§hle die Regressionsanalyse.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEs ist meist einfacher und n√ºtzlicher, die Regression zu verwenden, anstelle der Vielzahl von anderen Verfahren (die zumeist Spezialf√§lle der Regression sind). In diesem Kurs werden wir f√ºr alle Fragestellungen die Regression verwenden.9\\(\\square\\)\n\n\n\nBeispiel 2.4 Typische Spezialf√§lle der Regression sind\n\nt-Test: UV: zweistufig nominal, AV: metrisch\nANOVA: UV: mehrstufig nominal, AV: metrisch\nKorrelation: Wenn UV und AV z-standradisiert sind (d.h. Mittelwert von 0 und Standardabweichung von 1 haben), dann ist die Korrelation gleich dem Regressionskoeffizienten \\(\\beta_1\\) (bei einer einfachen Regression mit einer einzigen UV). \\(\\square\\)\n\n\n\n\n\n2.5.2 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; s. Abbildung¬†2.9. Links sieht man eine einfache Regression mit hp als Pr√§diktor (X, unabh√§ngige Variable) und mpg als abh√§ngige Variable (Y). Das rechte Teildiagramm zeigt eine multiple Regression mit den Pr√§diktoren hp und am.10\nIm einfachsten Fall sind die vom Modell vorhergesagten (gesch√§tzten) Werte, \\(\\hat{y}\\), durch eine einfache Gerade beschrieben, s. Abbildung¬†2.9, links. Eine Gerade l√§sst sich durch folgende Formel beschreiben: \\(\\hat{y} = \\beta_0 + \\beta_1\\). Dabei ist \\(\\beta_0\\) der Achsenabschnitt (eng. intercept) und \\(\\beta_1\\) die Steigung der Regressiongeraden.\n\nIn allgemeiner Form schreibt man die Regressionsgleichung als lineare Gleichung, d.h. in Form einer Gerade, s. Theorem¬†2.1. \\(\\square\\)\n\n\nTheorem 2.1 (Lineares Modell (Regressionsgleichung)) \\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nMan nennt alle \\(\\beta_0, \\beta_1, \\beta_2, ...\\) die Koeffizienten, Regressionsgewichte oder Parameter des Modells (Gelman et al., 2021). \\(\\square\\)\n\nAnhand von Theorem¬†2.1 erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden (\\(X_1, X_2, ...\\)) berechnet.\n\n\n\n\n\n\n\n\n\n(a) Einfache Regression (ein Pr√§diktor: hp)\n\n\n\n\n\n\n\n\n\n(b) Multiple Regression (zwei Pr√§diktoren: hp und am)\n\n\n\n\n\n\nAbbildung¬†2.9: Die Regressionsgerade in voller Pracht",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#unsicherheit",
    "href": "0200-Inferenz.html#unsicherheit",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.6 Unsicherheit",
    "text": "2.6 Unsicherheit\n\n2.6.1 Inferenz beinhaltet Ungewissheit\nInferenzstatistische Schl√ºsse sind mit Unsicherheit (Ungewissheit) behaftet: Schlie√ülich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), m√∂chte aber vom Teil auf das Ganze schlie√üen.\n\n\n\n\n\n\nWichtig\n\n\n\nNichts Genaues wei√ü man nicht: Schlie√üt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man sich auf die Unsicherheit das Wissen √ºber die Genauigkeit des Schlie√üens bezieht\n\n\nSchlie√üt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit; es ist ungewiss. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger.\nSchlie√ülich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen f√ºr die Stichprobe (Messfehler einmal ausgeblendet). Zur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer m√∂glich). Die Wahrscheinlichkeitstheorie bzw. -rechnung wird daher auch als die Mathematik des Zufalls bezeichnet.\n\nDefinition 2.5 (Zuf√§lliges Ereignis) Unter einem zuf√§lligen (engl. random) Ereignis verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres n√§chsten W√ºrfelwurfs. Zuf√§llig bedeutet nicht (zwangsl√§ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines W√ºrfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\n√úbungsaufgabe 2.6 üèã Welche physikalischen Randbedingungen wirken wohl auf einen M√ºnzwurf ein?\\(\\square\\)\n\n\nBeispiel 2.5 (Beispiele zur Quantifizierung von Ungewissheit) Aussagen mit Unsicherheit k√∂nnen unterschiedlich pr√§zise formuliert sein.\n\nMorgen regnet‚Äôs \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert von \\(Y\\) f√ºr Methode \\(A\\) h√∂her als f√ºr Methode \\(B\\).\nDie Maschine f√§llt demn√§chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den n√§chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n\n\n√úbungsaufgabe 2.7 üèã Geben Sie weitere Beispiele an!\n\n\n2.6.2 Wahrscheinlichkeit\n\nDefinition 2.6 (Wahrscheinlichkeit) Die Wahrscheinlichkeit ist ein Ma√ü daf√ºr, f√ºr wie sicher jemand es h√§lt, dass ein Ereignis eintritt. Die Wahrscheinlichkeit eines Ereignisses wird als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unm√∂glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. Je n√§her die Wahrscheinlichkeit bei 0 (1) liegt, desto sicherer sind wir, dass das Ereignis (nicht) der Fall ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsrechnung ist die typische Methode, um Ungewissheit zu pr√§zisieren, d.h. zu quantifizieren.\n\n2.6.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. Abbildung¬†2.10.\n\nWie (un)gewiss ist man sich √ºber die Regressionsgewichte?\nWie (un)gewiss ist man sich √ºber die Korrektheit der Modellspezifikation? (Sind alle relevanten Variablen im Modell enthalten? Sind die Annahmen des Modells erf√ºllt? ‚Ä¶)\n\n\n\n\n\n\nflowchart LR\nX1 --&gt;|Pr√§zision von Steigung und Achsenabschnitt?|B\nX2 -. Korrektheit des Modells? .-&gt; Y\n\n\n\n\n\nAbbildung¬†2.10: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n2.6.4 Ungewissheit der Modellkoeffizienten\nWie man in Abbildung¬†2.11 sieht, k√∂nnen sich die Koeffizienten (Achsenabschnitt und Steigung) unterscheiden. Woran liegt das?\n\nBeispiel 2.6 (Stichproben der New Yorker Fl√ºge) Nehmen wir an, wir ziehen ein paar Zufallstichproben aus der Menge (Population) aller Fl√ºge, die in New York im Jahre 2013 gestartet sind. In jeder Stichprobe berechnen wir eine Regression zwischen Flugzeit und Versp√§tung des Flugs am Ankunftsort. Sicherlich werden sich die Stichproben in ihren Kennwerten, z.B. in den Koeffizienten der genannten Regression, unterscheiden.\\(\\square\\)\n\n\nCodelibrary(nycflights13)\ndata(flights)\n\nstipro1 &lt;- sample_n(flights, size = 100)\nstipro2 &lt;- sample_n(flights, size = 100)\nstipro3 &lt;- sample_n(flights, size = 100)\n\n\n\n\n\n\n\n\n\n\n\n(a) Stichprobe 1\n\n\n\n\n\n\n\n\n\n(b) Stichprobe 2\n\n\n\n\n\n\n\n\n\n(c) Stichprobe 3\n\n\n\n\n\n\nAbbildung¬†2.11: Regressionsanalysen mit verschiedenen Koeffizienten aufgrund der Zuf√§lligkeit des Stichprobenziehens\n\n\nDer Grund f√ºr die Schwankungen der Modellparameter zwischen den Stichproben ist die Zuf√§lligkeit des Stichprobenziehens. Je nachdem, wie es der Zufall (oder sonst wer) will, landen bestimmte F√§lle (Fl√ºge in unserem Beispiel) in unserer Stichprobe. Zumeist unterscheiden sich die Stichproben; theoretisch k√∂nnten sie aber auch rein zuf√§llig gleich sein.\n\n\n\n\n\n\nWichtig\n\n\n\nStichproben-Kennwerte schwanken um den tats√§chlichen Wert in der Population herum.\\(\\square\\)\n\n\nUm diese Ungewissheit, die sich in den Schwankungen der Stichproben-Regressionskoeffizienten ausdr√ºckt, anzuzeigen, ist ein ‚Äúgrauer Schleier‚Äù um die Regressionsgeraden in Abbildung¬†2.11 gekennzeichnet. Dieser grauer Schleier gibt also eine Spannbreite anderer, plausibler Ergebnisse an, die sich in einer anderen Stichprobe auch manifestieren k√∂nnten.\n\n2.6.4.1 Ungewissheit zur Korrektheit des Modells\nAngenommen, wir sind uns sicher √ºber die Werte der Modellparameter, also √ºber die Lage der Regressionsgeraden, anschaulich gesprochen. Dann bliebe immer noch Ungewissheit, inwieweit das Modell korrekt spezifiziert ist: Sind genau die richtigen Variablen im Modell enthalten?\nDiese Art der Ungewissheit ist dann interessant, wenn man f√ºr einzelne F√§lle eine Vorhersage macht und sich fragt, wie pr√§zise diese Vorhersage ist.\n\n\n\n\n\n\n\n\n\n(a) geringer Vorhersagefehler (hohe Vorhersageg√ºte)\n\n\n\n\n\n\n\n\n\n(b) hoher Vorhersagefehler\n\n\n\n\n\n\n\n\n\n(c) auch hoher Vorhersagefehler\n\n\n\n\n\n\nAbbildung¬†2.12: Regressionsanalyse mit gleicher Regressionsgerade, aber unterschiedlicher Vorhersageg√ºte\n\n\n\n2.6.5 Ich wei√ü, was ich nicht wei√ü: Ungewissheit angeben\nStreng genommen ist eine Inferenz ohne Angabe der Ungewissheit (Genauigkeit der Sch√§tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% sch√§tzt, l√§sst aber offen wie sicher (pr√§zise) die Sch√§tzung (der Modellparameter) ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Sch√§tzung schlie√üt sogar 41% oder 43% aus.\n\n\n\n\n\n\nWichtig\n\n\n\nSchlie√üt man auf eine Population, sch√§tzt also die Modellparameter, so sollte stets die (Un-)Genauigkeit der Sch√§tzung, also die Ungewissheit des Modells, angegeben sein.\\(\\square\\)\n\n\nIm Rahmen der Regressionsanalyse schl√§gt sich die Ungewissheit an zwei Stellen (und in drei Parametern) nieder:\n\nzur Pr√§zision der Regressionsgeraden \\(\\beta_0\\), \\(\\beta_1\\)\n\nzur Modellg√ºte (\\(R^2\\)) bzw. zum Vorhersagefehler, \\(\\sigma\\)11\n\n\n2.6.6 Visualisierung von Ungewissheit\n\nDefinition 2.7 (Punktsch√§tzer) Gibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem Punktsch√§tzer.\nPunktsch√§tzer beinhalten keine Angabe der Sch√§tz(un)genauigkeit, s. Abb. Abbildung¬†2.13, links. Rot markiert: Die Punktsch√§tzung von mpg f√ºr hp=200.\n\n\nIn Abb. Abbildung¬†2.13, links, ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns bzgl. der Lage der Regressionskoeffizienten? Vgl. Definition¬†2.7.\nAuch wenn wir uns sicher w√§ren im Hinblick auf die Regressionsgewichte in Abb. Abbildung¬†2.13, links, bliebe Ungewissheit bei der Vorhersage des Bereichs plausibler Werte f√ºr individuelle Vorhersagen, s. Abbildung¬†2.13, rechts. Unsere Sch√§tzungen w√§ren auch dann nicht sicher, nicht fehlerfrei, wenn wir den genauen Verlauf der Regressiongerade sicher w√ºssten. Das liegt daran, da das Modell nicht alle Einfl√ºsse auf Y ber√ºcksichtigt, sondern nur einen einzigen, hier als X bezeichnet. Das Modell hat also keine perfekte Information, es ist ungewiss √ºber alle m√∂glichen Einflussfaktoren auf Y. W√ºsste unser Modell alle Einflussfaktoren genau, so w√§re unser Vorhersageintervall sehr schmal (bzw. h√§tte null Breite).\nIn Abb. Abbildung¬†2.13, rechts, ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die Ungewissheit zur Vorhersage der Y-Werte individueller Beobachtungen dargestellt. In diesem Fall spricht man von einem ‚ÄúVorhersageintervall‚Äù, da man nicht nur von ‚Äútypischen F√§llen‚Äù auf der Regressiongeraden spricht, sondern f√ºr echte F√§lle Vorhersagen (Sch√§tzungen) t√§tigt, wo auch die Ungewissheit der Modellg√ºte relevant ist.\n\n\n\n\n\n\n\n\n\n\n(a) Eine Punktsch√§tzung der Regressionsgeraden und die zugeh√∂rige Ungewissheit der Koeffizienten\n\n\n\n\n\n\n\n\n\n(b) Das Vorhersageintevall zur Regressionsgeraden zeigt die Ungewissheit f√ºr die jeweiligen Beobachtungen\n\n\n\n\n\n\nAbbildung¬†2.13: Die zwei Arten der Ungewissheit visualisiert\n\n\nAbbildung¬†2.13 zeigt auch, dass f√ºr eine Beobachtung mit hp=200 der Punktsch√§tzer der gesch√§tzte Wert von mpg bei ca 16.5 liegt. Das ist sozusagen unser Best Guess. Weiterhin ist (in gr√ºn) das Vorhersageintervall f√ºr hp=200 angezeigt. F√ºr Beobachtungen mit hp=200 liegt der Bereich plausibler mpg-Werte in dem (gr√ºn) markierten Bereich (ca. 8 bis 25).\n\nDefinition 2.8 (Vorhersageintervall) Ein Vorhersageintervall zeigt den Bereich plausibler Werte (laut unserer Analyse) f√ºr eine Beobachtung mit bestimmten Pr√§diktor-Werten.\\(\\square\\)\n\nWie man sieht, wird die Ungewissheit gr√∂√üer, wenn man beide Arten der Ungewissheit ber√ºcksichtigt. Das Vorhersage-Intervall ber√ºcksichtigt Ungewissheit in erstens der Regressionsgerade, \\(\\beta_0, \\beta_1\\), und in der Pr√§zision der Vorhersagen, \\(\\sigma\\), bei der Vorhersage von \\(\\hat{y_i}\\).\n\n√úbungsaufgabe 2.8 üèã Geben Sie ein vergleichbares Beispiel an!\n\n\n2.6.7 Konfidenzintervall\nWir sehen in Abbildung¬†2.13, dass ein ‚ÄúUngewissheitskorridor‚Äù angegeben wird f√ºr die Lage der Regressionsgerade (linkes Teildiagramm) bzw. f√ºr den Bereich plausibler Vorhersagen im konkreten Fall einer Beobachtung mit bestimmten X-Wert. Entsprechend wird nicht ein Punktsch√§tzer, sondern ein Sch√§tzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich.12\n\nDefinition 2.9 (Konfidenzintervall) Ein Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff f√ºr Sch√§tzbereiche f√ºr Parameter wie Regressionskoeffizienten.\nDie Grenzen eines Konfidenzintervall markieren die Grenzen eines Bereichs plausibler Werte f√ºr einen Parameter.\n\nEs gibt verschiedene Arten, Konfidenzintervalle zu berechnen; wir sprechen in sp√§teren Kapiteln dazu ausf√ºhrlicher. Ein Konfidenzintervall wird h√§ufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse - auf der dieser Kurs aufbaut - ist ein Konfidenzintervall einfach zu interpretieren. Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall f√ºr den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt. Dieser Befund l√§sst sich so interpretieren: ‚ÄúLaut Modell liegt der gesuchte Anteil der R-Fans mit einer Wahrscheinlichkeit von 95% im Bereich von 40 bis 44 Prozentpunkten.‚Äù Diese (einfache) Interpretation ist im Frequentismus nicht m√∂glich.\n\nBeispiel 2.7 Geben Sie Beispiele f√ºr Konfidenzintervalle an.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#frequentismus-vs.-bayes-inferenz",
    "href": "0200-Inferenz.html#frequentismus-vs.-bayes-inferenz",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.7 Frequentismus vs.¬†Bayes-Inferenz",
    "text": "2.7 Frequentismus vs.¬†Bayes-Inferenz\n\n\n\n2.7.1 Frequentismus: Klassische Inferenz\n\nDie Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zur√ºckgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein, keine Vorannahmen.\nWahrscheinlichkeit wird √ºber relative H√§ufigkeiten definiert.\nEs ist nicht m√∂glich, die Wahrscheinlichkeit einer Hypothese bzw. eines Werts in der Population (eines Parameters) anzugeben.\nStattdessen wird angegeben, wie h√§ufig eine vergleichbare Datenlage zu erwarten ist, wenn der Versuch sehr h√§ufig wiederholt ist.\nEin Gro√üteil der Forschung (in den Sozialwissenschaften) verwendet (aktuell) diesen Ansatz.\n\n\n\n2.7.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) flie√üt explizit in die Analyse ein (zusammen mit den Daten).\n\nWenn das Vorwissen gut ist, wird die Vorhersage durch das Vorwissen genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen f√ºr Hypothesen m√∂glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (f√ºr g√§ngige Computer) komfortabel geworden.\n\n\n\n\n2.7.3 Frequentismus\n\n2.7.3.1 Der p-Wert\nDer zentrale Kennwert des Frequentismus hei√üt der p-Wert.\nDer p-Wert ist so definiert, vgl. Wasserstein & Lazar (2016):\n\nWie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zuf√§llig verschieden und auf Basis unseres Modells)?\n\n\n√úbungsaufgabe 2.9 üèã Recherchieren Sie eine Definition des p-Werts und lesen Sie sie einem Freund. Beobachten sie die Reaktionen auf Ihre Erkl√§rung.\\(\\square\\)\n\nDer p-Wert wird oft falsch verstanden (Badenes-Ribera et al., 2016). Aber er ist auch nicht leicht zu verstehen, meint Meister Yoda, s. Abbildung¬†2.14. Hier sind einige FALSCHE Interpretationen zum p-Wert laut der Autoren:\n\nüôÖ‚Äç‚ôÄ Der p-Wert w√ºrde die Wahrscheinlichkeit der Nullhypothese oder der Forschungshypothese angeben. üôä\nüôÖ‚Äç‚ôÄ Der p-Wert w√ºrde ein inhaltlich bedeutsames, praktisch signifikantes Ergebnis anzeigen. üôä\n\n\n\n\n\n\nAbbildung¬†2.14: Der p-Wert ist wenig intuitiv, meint Meister Yoda\n\n\n\n2.7.3.2 Konfidenzintervalle\nDie korrekte Definition der Konfidenzintervalls in frequentistischer Lesart lautet:\n\nDer Konfidenzbereich, z.B. von 95%, repr√§sentiert den Anteil der Konfidenzintervalle bei sehr vielen (oder unentlich vielen) Wiederholungen des Experiments, die den echten Parameterwert enthalten (Hoekstra et al., 2014).\n\nDie folgende Visualisierung (Abbildung¬†2.15) zeigt das Prinzip frequentistischer Konfidenzintervalle: Auf Dauer enthalten 95% der Stichproben den wahren Wert (in der Population). 13\nCodeviewof settings = Inputs.form([\n  Inputs.range([-5, 5], {value: 1, label: tex`\\text{MW, }\\mu`, step: 0.01}),\n  Inputs.range([0.01, 5], {value: 1, label: tex`\\text{SD, }\\sigma`, step: 0.01}),\n  Inputs.range([0, 99], {value: 90, label: \"Konfidenzlevel\", step: 1}),\n  Inputs.range([0, 200], {value: 50, label: \"n\", step: 1})\n])\n\nviewof nrep = Scrubber(d3.ticks(1, 1000, 1000), {\n  autoplay: false,\n  loop: false,\n  initial: 1,\n  delay: 500,\n  format: x =&gt; `number of datasets = ${x.toFixed(0)}`\n})\n\ntextinfo = md`\nVon insgesamt ${nrep} Stichproben, ${d3.sum(dataci.map(d =&gt; d.rep &lt;= nrep && (mu &gt;= d.lower && mu &lt;= d.upper)))} (**&lt;span style=\"color:red\"&gt;${(d3.sum(dataci.map(d =&gt; d.rep &lt;= nrep && (mu &gt;= d.lower && mu &lt;= d.upper)))*100/nrep).toFixed(3)}%&lt;/span&gt;**) von den ${confidence}% Konfindenzintervallen enthielten den wahren (tats√§chlichen) Populationswert ${tex`\\mu= `} ${mu}.\n`\n\nlockvertical = Inputs.toggle({label: \"Achse einrasten\", value: false})\n\nplt = Plot.plot({\n  style: {fontSize: \"12px\"},\n  width: 960,\n  y: {\n    label: \"mean\",\n    domain: lockvertical ? [mu - 3, mu + 3] : [mu - 5 * sigma / Math.sqrt(nobs), mu + 5 * sigma / Math.sqrt(nobs)]\n  },\n  x: {\n    label: \"Stichprobennummer\",\n    domain:  [0, nrep]\n  },\n  marks: [\n    Plot.ruleX([0]),    \n    Plot.ruleX(dataci, {\n      filter: d =&gt; (d.rep &lt;= nrep && mu &gt;= d.lower && mu &lt;= d.upper),\n      x: \"rep\",\n      y1: \"lower\",\n      y2: \"upper\",  \n      stroke: \"steelblue\",\n      strokeWidth: 1.5\n    }),\n    Plot.dot(dataci, {filter: d =&gt; (d.rep &lt;= nrep && mu &gt;= d.lower && mu &lt;= d.upper), x: \"rep\", y: \"xbar\", fill: \"steelblue\", r: 3}),\n\n    Plot.ruleX(dataci, {\n      filter: d =&gt; d.rep &lt;= nrep && (mu &lt; d.lower || mu &gt; d.upper),\n      x: \"rep\",\n      y1: \"lower\",\n      y2: \"upper\",  \n      stroke: \"orange\",\n      strokeWidth: 1.5\n    }),\n    Plot.dot(dataci, {filter: d =&gt; d.rep &lt;= nrep && (mu &lt; d.lower || mu &gt; d.upper), x: \"rep\", y: \"xbar\", fill: \"orange\", r: 3}),\n    Plot.ruleY([mu], {stroke: \"#D22B2B\", strokeWidth: 1.5})\n  ]\n})\n\njstat = require('jstat')\nimport {Scrubber} from \"@mbostock/scrubber\"\n\nfunction simulate_means(mu, sigma, nobs, nrep){\n  const tvalue = jstat.studentt.inv(1 - (1 - (confidence / 100)) / 2, nobs - 1);\n  var dataci = [];\n  for (let j = 1; j &lt;= nrep; j++){\n    let sample = d3.range(nobs).map(() =&gt; d3.randomNormal(mu, sigma)());\n    let xbar = d3.mean(sample);\n    let s = jstat.stdev(sample, true); \n    let lower = xbar - tvalue * s / Math.sqrt(nobs);\n    let upper = xbar + tvalue * s / Math.sqrt(nobs);\n    dataci.push({rep: j, xbar: xbar, lower: lower, upper: upper});\n  }\n  return dataci;\n}\n\nmu = 1\nsigma = 1\nconfidence = 90\nnobs = 50\n\ndataci = simulate_means(mu, sigma, nobs, 1000)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†2.15: Ein frequentistisches 95%-Konfidenzintervall: Auf Dauer enthalten 95% der Konfidenzintervalle den wahren Wert in der Population.\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nEin frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters). Stattdessen wird eine Aussage √ºber das Ergebnis einer sehr h√§ufig wiederholten Stichprobenziehung berichtet. Ob ein bestimmtes (unseres, Ihres) den wahren Wert enth√§lt, bzw. mit welcher Wahrscheinlichkeit es den wahren Wert enth√§lt, dar√ºber macht das frequentistische Konfidenzintervall keine Aussagen. \\(\\square\\)\n\n\n\n2.7.4 Statistische Signifikanz\nIm Frequentismus spricht man von statistischer Signifikanz, wenn man \\(p&lt;.05\\) (oder einen anderen Prozentwert als 5%, aber meistens wird 5% hergenommen), findet. Man nimmt diesen Befund als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann. Faktisch entscheidet man sich, die Forschungshypothese weiterhin als ‚Äúvorl√§ufig g√ºltig‚Äù oder zumindest als ‚Äúnicht widerlegt‚Äù zu betrachten.\nIn der Bayes-Statistik ist der Begriff nicht einheitlich definiert. Mit Bezug auf Gelman et al. (2021) wird in diesem Buch der Begriff wie folgt definiert.\n\nDefinition 2.10 Ist Null nicht im Konfidenzintervall enthalten, so liegt ein statistisch signifikantes Ergebnis vor. \\(\\square\\)\n\nOft werden 95%-Konfidenzintervalle verwendet, obwohl das nur eine Konvention ist. Die Signifikanzaussage bezieht sich immer auf die Gr√∂√üe des Konfidenzintervalls (und des Modells inklusive Daten).\nLiegt ein statistisch signifikantes Ergebnis vor, so verwirft man die Nullhypothese.\n\nDefinition 2.11 (Nullhypothese) Die Nullhypothese, \\(H_0\\), besagt, dass kein Effekt (Unterschied, Zusammenhang, Ver√§nderung, ‚Ä¶) vorliegt. \\(\\square\\)\n\n√úbrigens sollte man nicht nur von ‚ÄúSignifikanz‚Äù, sondern von ‚Äústatistischer Signifikanz‚Äù sprechen, um klar zu machen, dass man nicht ein Alltagsverst√§ndnis von Signifikanz (‚Äúgro√ü‚Äù, ‚Äúbedeutsam‚Äù) meint, sondern einen wohl definierten statistischen Begriff. Das ist wichtig, weil es sonst leicht zu Fehlinterpretationen kommt.\n\n2.7.4.1 Aus der Forschung (Vertiefung14)\nFrequentistische Konfidenzintervalle werden oft falsch verstanden, wie die folgende Studie zeigt. Das liegt aber nicht daran, dass die Menschen zu dumm sind, sondern dass frequentistische Konfidenzintervalle f√ºr viele Menschen kontraintuitiv sind.\nHoekstra et al. (2014) berichten von einer Studie, in der \\(n=442\\) Bachelor-Studentis, \\(n=34\\) Master-Studentis und \\(n=120\\) Forschende befragt wurden.\nDen Versuchpersonen wurde folgender Fragebogen vorgelegt, s. Abbildung¬†2.16.\n\n\n\n\n\nAbbildung¬†2.16: Frageobgen zu Konfidenzintervallen\n\n\nKurz gesagt war die Frage, die die Befragten beantworten sollten:\n\nIn einem Experiment wird ein 95%-Konfidenzintervall mit dem Bereich von 0.1 bis 0.4 beichtet. Welcher der folgenden sechs Aussagen sind richtig bzw. falsch?\n\nMit ‚ÄúKonfidenzintervall‚Äù meinen die Forschenden ein frequentistisches Konfidenzintervall.\nAlle diese sechs Aussagen sind FALSCH. Die Aussagen lauten:\n\nDie Wahrscheinlichkeit, dass der wahre Mittelwert gr√∂√üer als 0 ist, betr√§gt mindestens 95 %.\nDie Wahrscheinlichkeit, dass der wahre Mittelwert gleich 0 ist, ist kleiner als 5 %.\nDie ‚ÄûNullhypothese‚Äú, dass der wahre Mittelwert gleich 0 ist, ist wahrscheinlich falsch.\nEs gibt eine 95%ige Wahrscheinlichkeit, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\nWir k√∂nnen mit 95%iger Sicherheit sagen, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\nWenn wir das Experiment immer wieder wiederholen w√ºrden, dann liegt der wahre Mittelwert in 95 % der F√§lle zwischen 0,1 und 0,4.\n\nAussagen 1-4 weisen den Hypothesen bzw. den Parametern eine Wahrscheinlichkeit zu, was im Frequentismus nicht erlaubt ist. Aussagen 5-6 spezifizieren die Grenzen des Sch√§tzintervalls, allerdings kann das Konfidenzintervall nur Aussagen zu den zugrundeliegenden Stichproben, nicht zum Sch√§tzintervall, machen.\nDie Ergebnisse zeigen, dass die Aussagen mehrheitlich falsch verstanden wurden, also mit ‚Äústimmt‚Äù angekreuzt wurden, s. Abbildung¬†2.17.\n\n\n\n\n\nAbbildung¬†2.17: Eine hohe Zustimmung zu den sechs falschen Aussagen\n\n\n\n2.7.4.2 Bayes-Statistik\nDie zentrale Statistik der Bayes-Statistik ist die Posteriori-Verteilung.\nDie Posteriori-Verteilung beantwortet uns die Frage: ‚ÄúWie wahrscheinlich ist die Forschungshypothese (oder Varianten von ihr), jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?‚Äù\nIn der Bayes-Statistik sind Aussagen folgender Art erlaubt:\n\nMit einer Wahrscheinlichkeit von 95% ist der neue Webshop besser als der alte. Mit einer Wahrscheinlichkeit von 89% liegt die Wirksamkeit des neuen Medikaments zwischen 0.1 und 0.4.\n\nIn diesem Post wird f√ºr Bayes geworben und (einseitig) Stellung pro Bayes bezogen.\n\n2.7.5 Frequentist und Bayesianer\nIm Cartoon 1132 von xkcd wird sich √ºber das Nicht-Ber√ºcksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. Abbildung¬†2.18.\n\n\n\n\n\nAbbildung¬†2.18: Frequentist wettet mit Bayesianer\n\n\nQuelle\n\nfrom Imgflip Meme Generator\n\n\n2.7.6 Beispiel zum Nutzen von Apriori-Wissen 1\nEin Betrunkener behauptet, er k√∂nne hellsehen. Er wirft eine M√ºnze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird. Die Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die M√ºnze fair ist, dass Ergebnis also ‚Äúzuf√§llig‚Äù ist, also \\(p &lt; .05\\) und damit ist das Ergebnis ‚Äústatistisch signifikant‚Äù.\nUnser Vorwissen l√§sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zuf√§lligkeit des Ergebnisses wohl nicht verwerfen.\n\n2.7.7 Beispiel zum Nutzen von Apriori-Wissen 2\nEine Studie (Gelman et al., 2021) fand einen ‚Äúgro√üen Effekt‚Äù auf das Einkommen von Babies, die eine Stunde pro Woche w√§hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\). Nach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% h√∂her (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings l√§sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln l√§sst. Wir w√ºrden den Effekt lieber in einem konservativeren Intervall sch√§tzen (enger um Null).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#fazit",
    "href": "0200-Inferenz.html#fazit",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.8 Fazit",
    "text": "2.8 Fazit\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#aufgaben",
    "href": "0200-Inferenz.html#aufgaben",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.9 Aufgaben",
    "text": "2.9 Aufgaben\n\n2.9.1 Paper-Pencil-Aufgaben\n\nGriech-Buchstaben-Inferenz\ninferenz-fuer-alle\nttest-als-regr\nttest-skalenniveau\nWarum-Bayes\nsamples-nyc2\n\n2.9.2 Aufgaben, f√ºr die man einen Computer braucht\n\nkorr-als-regr\npunktschaetzer-reicht-nicht\nungewiss-arten-regr\ninferenz-fuer-alle\nadjustieren1a\nadjustieren2a\nlm-standardfehler\nvorhersageintervall1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#section",
    "href": "0200-Inferenz.html#section",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.10 ‚Äî",
    "text": "2.10 ‚Äî\n\n\n\n\n\nBadenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A., & Longobardi, C. (2016). Misconceptions of the P-Value among Chilean and Italian Academic Psychologists. Frontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust Misinterpretation of Confidence Intervals. Psychonomic bulletin & review, 21(5), 1157‚Äì1164. http://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nShmueli, G. (2010). To Explain or to Predict? Statistical Science, 25(3), 289‚Äì310. https://doi.org/10.1214/10-STS330\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs Statement on p-Values: Context, Process, and Purpose. The American Statistician, 70(2), 129‚Äì133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#footnotes",
    "href": "0200-Inferenz.html#footnotes",
    "title": "\n2¬† Inferenz\n",
    "section": "",
    "text": "Ziele existieren nicht ‚Äúin echt‚Äù in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das hei√üt, dass man sich nach Belieben Ziele ausdenken kann. Allerdings hilft es, wenn man andere Menschen vom Nutzen der eigenen Ideen √ºberzeugen kann.‚Ü©Ô∏é\nVielleicht hat Ihr Dozent Sie schon mal mit einem Prognosewettbewerb gequ√§lt? Ja? Genau! In einem Prognosewettbewerb ist das Ziel eine - nat√ºrlich m√∂glichst exakte - Vorhersage zu treffen.‚Ü©Ô∏é\nStatistische Inferenz sieht sich drei ‚ÄúHerausforderungen‚Äù gegen√ºber, laut Gelman et al. (2021), Kap. 1.1.; Diese betreffen das Schlie√üen (oder Generalisieren) vom Einzelfall auf das Allgemeine: 1. Von der Stichprobe aus die Grundgesamtheit (Population), 2. Von der Experimental- auf die Kontrollgruppe (Kausalinferenz), 3. Von einem Messwert auf das zugrundeliegende Konstrukt. In diesem Kurs besch√§ftigen wir uns mit den ersten beiden Herausforderungen.‚Ü©Ô∏é\nMeistens Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?‚Ü©Ô∏é\nManch einer h√§tte mit mehr gerechnet; andere mit weniger‚Ä¶‚Ü©Ô∏é\nDas ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.‚Ü©Ô∏é\nDas ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.‚Ü©Ô∏é\nhttps://gallery.shinyapps.io/simple_regression/‚Ü©Ô∏é\nWie Jonas Kristoffer Lindel√∏v uns erkl√§rt, sind viele statistische Verfahren, wie der sog. t-Test Spezialf√§lle der Regression.‚Ü©Ô∏é\nDer Datensatz mtcars wird gerne als Studienobjekt verwendet, da er einfach ist und f√ºr viele Beispiele geeignet. Wenn Sie sich einen Sachverhalt an einem einfachen Datensatz vergegenw√§rtigen wollen, bietet sich auch der Datensatz mtcars an. Zudem ist er ‚Äúfest in R eingebaut‚Äù; mit data(mtcars) k√∂nnen Sie ihn verf√ºgbar machen.‚Ü©Ô∏é\n\\(\\sigma\\), das griechische s f√ºr Streuung (um die Regressionsgerade herum), manchmal wird auch e wie error verwendet‚Ü©Ô∏é\nTats√§chlich gibt es mehrere Synonyme oder √§hnliche Begriffe f√ºr Konfidenzintervall. Wir kommen sp√§ter darauf detaillierter zu sprechen.‚Ü©Ô∏é\nSiehe auch hier f√ºr eine sch√∂ne Visualisierung von RPsychologist.‚Ü©Ô∏é\nnicht pr√ºfungsrelevant‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html",
    "href": "0300-Wskt.html",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "",
    "text": "3.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#lernsteuerung",
    "href": "0300-Wskt.html#lernsteuerung",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "",
    "text": "3.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n3.1.2 √úberblick\nDieses Kapitel hat die Wahrscheinlichkeitstheorie (synonym: Wahrscheinlichkeitsrechnung) bzw. das Konzept der Wahrscheinlichkeit zum Thema.1 Es geht sozusagen um die Mathematik des Zufalls.\n\n3.1.3 Wozu brauche ich dieses Kapitel?\nIm wirklichen Leben sind Aussagen (Behauptungen) so gut wie nie sicher.\n\n‚ÄúWeil sie so schlau ist, ist sie erfolgreich.‚Äù\n‚ÄúIn Elektroautos liegt die Zukunft.‚Äù\n‚ÄúDas klappt sicher, meine Meinung.‚Äù\n‚ÄúDer n√§chste Pr√§sident wird XYZ.‚Äù\n\nAussagen sind nur mehr oder weniger (graduell) sicher. Wir k√∂nnen die Regeln der Wahrscheinlichkeitslogik verwenden, um den Grad der Sicherheit (von ganz unsicher bis ganz sicher) zu pr√§zisieren. Daher sagt man auch, Wahrscheinlichkeit sei die Logik der Wissenschaft (Jaynes & Bretthorst, 2003).\n\n3.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erl√§uternd definieren\ndie drei Arten der direkten Ermittlung von Wahrscheinlichkeit erl√§utern\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n3.1.5 Begleitliteratur\nLesen Sie zur Begleitung dieses Kapitels Bourier (2011), Kap. 2-4.\n\n3.1.6 Eigenstudium\n\n\n\n\n\n\nWichtig\n\n\n\nDieses Kapitel ist selbst√§ndig im Eigenstudium vorzubereiten vor dem Unterricht. Lesen Sie dazu die angegebene Literatur.\\(\\square\\)\n\n\n\n3.1.7 Pr√ºfungsrelevanter Stoff\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 2-4. Weitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verf√ºgbar sein. Pr√ºfen Sie, ob Ihr Dozent Ihnen weitere Hilfen im gesch√ºtzten Bereich (Moodle) eingestellt hat.\\(\\square\\)\n\n\n\n3.1.8 Zentrale Begriffe\n\n3.1.8.1 Grundbegriffe\n\nZufallsvorgang (Zufallsexperiment)\nElementarereignis\nEreignisraum\nZufallsereignis (zuf√§lliges Ereignis)\nSicheres Ereignis\nUnm√∂gliches Ereignis\n\n3.1.8.2 Wahrscheinlichkeitsbegriffe\n\nKlassische Wahrscheinlichkeit (LaPlace‚Äôsche Wahrscheinlichkeit)\nStatistische (empirische) Wahrscheinlichkeitsermittlung\nSubjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n3.1.8.3 Wahrscheinlichkeitsrelationen\n\nVereinigung von Ereignissen\nSchnitt(menge) von Ereignissen\nKomplement√§rereignis\nVollst√§ndiges Ereignissystem\nAnforderungen an eine Definition von Wahrscheinlichkeit\n\n3.1.8.4 Wahrscheinlichkeitsrechnung\n\nAllgemeiner Additionsssatz\nDisjunkte Ereignisse\nAdditionssatz f√ºr disjunkte Ereignisse\nBedingte Wahrscheinlichkeit\n(Stochastische) Unabh√§ngigkeit\nBaumdiagramm f√ºr gemeinsame Wahrscheinlichkeit\nAllgemeiner Multiplikationssatz\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse\nTotale Wahrscheinlichkeit\nSatz von Bayes\n\n3.1.9 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#grundbegriffe-1",
    "href": "0300-Wskt.html#grundbegriffe-1",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.2 Grundbegriffe",
    "text": "3.2 Grundbegriffe\n\nBeispiel 3.1 Klassisches Beispiel f√ºr einen Zufallsvorgang ist das (einmalige oder mehrmalige) Werfen einer M√ºnze.\\(\\square\\)\nWerfen Sie eine M√ºnze! Diese hier zum Beispiel:\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10 Mal.\nDas reicht Ihnen nicht? Okay, wiederholen Sie den Versuch 100, nein 1000, nein: \\(10^6\\) Mal.2\nNotieren Sie als Ergebnis, wie oft die Seite mit der Zahl oben liegen kommt (‚ÄúTreffer‚Äù).\\(\\square\\)\n\nOder probieren Sie die App der Brown University, wenn Sie keine Sehnenscheidenentz√ºndung bekommen wollen.\n\nDefinition 3.1 (Zufallsvorgang) Ein Zufallsvorgang oder Zufallsexperiment ist eine einigerma√üen klar beschriebene T√§tigkeit, deren Ergebnis nicht bekannt ist. Allerdings ist die Menge m√∂glicher Ergebnisse sicher und die Wahrscheinlichkeit f√ºr die Ergebnisse kann quantifiziert werden.\\(\\square\\)\n\n\n√úbungsaufgabe 3.1 Nennen Sie Beispiele f√ºr Zufallsvorg√§nge!3\n\n\n\n\n\n\n\nVorsicht\n\n\n\nZufall hei√üt nicht, dass ein Vorgang keine Ursachen h√§tte. So gehorcht der Fall einer M√ºnze komplett den Gesetzen der Gravitation. W√ºrden wir diese Gesetze und die Ausgangsbedingungen (Luftdruck, Fallh√∂he, Oberfl√§chenbeschaffenheit, Gewichtsverteilungen, ‚Ä¶) exakt kennen, k√∂nnten wir theoretisch sehr genaue Vorhersagen machen. Der ‚ÄúZufall‚Äù w√ºrde aus dem M√ºnzwurf verschwinden. Man sollte ‚ÄúZufall‚Äù also besser verstehen als ‚Äúunbekannt‚Äù.\\(\\square\\)\n\n\n\n√úbungsaufgabe 3.2 Mit dieser App k√∂nnen Sie W√ºrfelw√ºrfe simulieren und die Ausg√§nge dieses Zufallsexperiments beobachten.\\(\\square\\)\n\n\nDefinition 3.2 (Ereignisraum) Die m√∂glichen Ergebnisse eines Zufallvorgangs fasst man als Menge mit dem Namen Ereignisraum4 zusammen. Man verwendet den griechischen Buchstaben \\(\\Omega\\) f√ºr diese Menge. Die Elemente \\(\\omega\\) (kleines Omega) von \\(\\Omega\\) nennt man Ergebnisse.\\(\\square\\)\n\n\nBeispiel 3.2 Beobachtet man beim W√ºrfelwurf (s. Abbildung¬†3.8) die oben liegende Augenzahl, so ist\n\\[\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{‚öÄ, ‚öÅ, ‚öÇ, ‚öÉ, ‚öÑ, ‚öÖ\\}\\]\nein nat√ºrlicher Grundraum (Henze, 2019).\\(\\square\\)\n\nDie Wahrscheinlichkeitsrechnung baut auf der Mengenlehre auf, daher wird die Notation der Mengenlehre hier verwendet.\n\n\n\n\n\nAbbildung¬†3.1: Ein (sechsseitiger) W√ºrfel, Bildquelle: Peter Steinberg, Wikipedia, CC-BY-\n\n\n\nDefinition 3.3 (Ereignis) Jede Teilmenge5 von \\(\\Omega\\) hei√üt Ereignis; \\(A \\subseteq \\Omega\\) .\\(\\square\\)\n\n\nBeispiel 3.3 Beim Mensch-√§rger-dich-nicht Spielen habe ich eine 6 geworfen.6 Das Nennen wir das Ereignis \\(A\\): ‚ÄúAugenzahl 6 liegt oben‚Äù und schreiben in Kurzform:\n\\(A= \\{6\\}\\square\\)\n\n\nBeispiel 3.4 Sie werfen eine M√ºnze (Sie haben keinen Grund, an ihrer Fairness zu zweifeln). ‚ÄúSoll ich jetzt lernen f√ºr die Klausur (Kopf) oder lieber zur Party gehen (Zahl)?‚Äù\nAbbildung¬†3.2 zeigt die m√∂glichen Ausg√§nge (T wie Treffer (Party) und N (Niete, Lernen)) dieses Zufallexperiments.\n\n\n\n\n\nflowchart LR\n M[Sie werfen die M√ºnze] --&gt; T[\"T (Treffer) ü•≥\"]\n  M --&gt; N[\"N (Niete) üìö\"]\n\n\n\n\nAbbildung¬†3.2: Sie werfen eine M√ºnze. Party oder Lernen???\n\n\n\n\nDas Ereignis Zahl ist eingetreten! Treffer! Gl√ºck gehabt!7\\(\\square\\)\n\n\nDefinition 3.4 (Unm√∂gliches und sicheres Ereignis) Die leere Menge \\(\\varnothing\\) hei√üt das um√∂gliche, der Grundraum \\(\\Omega\\) hei√üt das sichere Ereignis. \\(\\square\\)\n\n\nBeispiel 3.5 (Unm√∂gliches Ereignis) Alois behauptet, er habe mit seinem W√ºrfel eine 7 geworfen. Schorsch erg√§nzt, sein W√ºrfel liege auf einer Ecke, so dass keine Augenzahl oben liegt. Draco hat seinen W√ºrfel runtergeschluckt. Dracos und Alois‚Äô Ereignisse sind unm√∂gliche Ereignisse, zumindest nach unserer Vorstellung des Zufallsexperiments.\\(\\square\\)\n\n\nBeispiel 3.6 (Sicheres Ereignis) Nach dem der W√ºrfel geworfen wurde, liegt eine Augenzahl zwischen 1 und 6 oben.\\(\\square\\)\n\n\nDefinition 3.5 (Elementarereignis) Jede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) hei√üt Elementarereignis (h√§ufig mit \\(A\\) bezeichnet). 8 \\(\\square\\)\n\n\nBeispiel 3.7 (Elementarereignis) ¬†\n\nSie spielen Mensch-√§rger-dich-nicht. Und brauchen dringend eine 6. Sie w√ºrfeln. Das Ereignis \\(A = \\{1\\}\\) tritt ein.9\nSie schreiben eine Statistik-Klausur. Irgendwie haben Sie das Gef√ºhl, das Ergebnis sei ein Zufallsexperiment‚Ä¶ Jedenfalls k√∂nnen nach Adam Riese zwei Dinge passieren: \\(\\Omega= \\{\\text{bestehen, nicht bestehen}\\}\\). Das erste der beiden Elementarereignisse tritt ein. Yeah!\nSie f√ºhren eine Studie durch zur Wirksamkeit einer Lern-App. Es ist nicht klar, ob die App wirklich was bringt f√ºr den Lernerfolg. Vereinfacht gesprochen ist der Grundraum dieses Experiments: \\(\\Omega = \\{\\text{schadet, bringt nichts, n√ºtzt}\\}\\). Die Daten sprechen f√ºr das Ereignis \\(A = \\{\\text{bringt nichts}\\}\\).\n\n\n\nDefinition 3.6 (Vollst√§ndiges Ereignissystem) Wird der Grundraum \\(\\Omega\\) vollst√§ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollst√§ndiges Ereignissystem, s. Abbildung¬†3.3.\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.3: Zerlegung des Grundraums in ein vollst√§ndiges Ereignissystem\n\n\n\nBeispiel 3.8 Sei \\(\\Omega\\) der typische Ereignisraum des W√ºrfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) ‚Äúgerade Zahlen‚Äù, und \\(B\\) ‚Äúungerade Zahlen‚Äù. Damit haben wir ein vollst√§ndiges Ereignissystem erstellt, s. Abbildung¬†3.4.\n\n\n\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\}  \\qquad  \\hfill \\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6 }\n\n\\end{align}\\]\n\n\n\nAbbildung¬†3.4\n\n\nEin Beispiel f√ºr ein vollst√§ndiges Ereignissystem\n\n\nBeispiel 3.9 Sei \\(\\Omega\\) der typische Ereignisraum des W√ºrfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) ‚Äú1,2,3‚Äù, und \\(B\\) ‚Äú4,5,6‚Äù. Damit haben wir ein vollst√§ndiges Ereignissystem erstellt, s. Abbildung¬†3.4.\n\n\n\n\\[\\begin{align}\nA = \\{1,2,3\\} \\qquad \\qquad \\hfill  \\boxed{\\boxed{ \\color{black}{1\\; 2\\; 3}}\\; \\color{gray}{4\\; 5\\; 6}} \\\\\nB = \\{4,5, 6\\} \\qquad \\qquad  \\hfill \\boxed{\\color{gray}{1 \\; 2 \\; 3}\\; \\boxed{\\color{black}{4\\; 5 \\; 6}}} \\\\\n\n\\newline\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\} \\qquad \\qquad \\hfill  \\boxed{1\\; 2\\; 3\\; 4\\; 5\\;6}\n\\end{align}\\]\n\n\n\nAbbildung¬†3.5: Noch ein Beispiel f√ºr ein vollst√§ndiges Ereignissystem\n\n\n\n\nDefinition 3.7 (M√§chtigkeit) Die Anzahl der Elementarereignisse eines Ereignismraums nennt man die M√§chtigkeit (des Ereignisraums).10\\(\\square\\)\n\nDie M√§chtigkeit von \\(\\Omega\\) bezeichnet man mit dem Symbol \\(|\\Omega|\\).\n\nBeispiel 3.10 Beim Wurf eines W√ºrfels mit \\(\\Omega=\\{1,2,3,4,5,6\\}\\) gibt es 6 Elementarereignisse. Die M√§chtigkeit ist also 6: \\(|\\Omega|=6\\).\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#direkte-ermittlung-von-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#direkte-ermittlung-von-wahrscheinlichkeiten",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.3 Direkte Ermittlung von Wahrscheinlichkeiten",
    "text": "3.3 Direkte Ermittlung von Wahrscheinlichkeiten\nWir haben schon mit Definition¬†2.6 eine erste Definition von Wahrscheinlichkeit versucht. Jetzt gehen wir die Sache noch etwas n√§her an.\n\n3.3.1 Formallogische Wahrscheinlichkeit\nDie formallogische Konzeption von Wahrscheinlichkeit sieht Wahrscheinlichkeit als Erweiterung der formalen Logik. 11 In der formalen Logik ist ein Ereignis entweder falsch oder wahr. In der formallogischen Konzeption wird der Platz zwischen ‚Äúfalsch‚Äù (0) und ‚Äúrichtig‚Äù (1 als die (nicht sichere) Wahrscheinlichkeit \\(0&lt;p&lt;1\\), gesehen (Briggs, 2016), s. Abbildung¬†3.6.\n\n\n\n\n\nAbbildung¬†3.6: Wahrscheinlichkeit als Erweiterung der Logik\n\n\nNach dieser ‚ÄúWahrscheinlichkeitslogik‚Äù kann man ein Ereignis, von dessen Eintreten man ‚Äúwenig √ºberzeugt‚Äù ist, z.B. mit 0.2 quantifizieren. Hingegen einem Ereignis, von man ‚Äúrecht sicher‚Äù ist, mit 0.8 quantifizieren, s. Abbildung¬†3.7.\n\n\n\n\n\nAbbildung¬†3.7: Ein Ereignis von dessen Eintreten man gering bzw. stark √ºberzeugt ist\n\n\n\nDefinition 3.8 (Indifferenzprinzip) Das Indifferenzprinzip (synonym: Prinzip des unzureichenden Grundes) besagt, dass in Abwesenheit jeglicher Informationen, die bestimmte Ereignisse bevorzugen oder benachteiligen w√ºrden, alle m√∂glichen Ereignisse als gleich wahrscheinlich angesehen werden sollten. \\(\\square\\)\n\nVor uns liegt ein W√ºrfel. Schlicht, ruhig, unbesonders. Wir haben keinen Grund anzunehmen, dass eine seiner \\(n=6\\) Seiten bevorzugt nach oben zu liegen kommt. Jedes der sechs Elementarereignisse ist uns gleich plausibel; der W√ºrfel erscheint uns fair. In Ermangelung weiteres Wissens zu unserem W√ºrfel gehen wir schlicht davon aus, dass jedes der \\(n\\) Elementarereignis gleich wahrscheinlich ist. Es gibt keinerlei Notwendigkeit, den W√ºrfel in die Hand zu nehmen, um zu einer Wahrscheinlichkeitsaussage auf diesem Weg zu kommen. Nat√ºrlich k√∂nnten wir unsere Auffassung eines fairen W√ºrfels testen, aber auch ohne das Testen k√∂nnen wir eine stringente Aussage (basierend auf dem Indifferenzprinzip (s. Definition¬†3.8) der \\(n\\) Elementarereignisse) zur Wahrscheinlichkeit eines bestimmten (Elementar-)Ereignisses \\(A\\) kommen (Briggs, 2016), s. Theorem¬†3.1.\n\nTheorem 3.1 (Indifferenzprinzip) \\[Pr(A) = \\frac{1}{n}= \\frac{1}{|\\Omega|} \\quad \\square\\]\n\n\nBeispiel 3.11 Sei \\(A\\) = ‚ÄúDer W√ºrfel wird beim n√§chsten Wurf eine 6 zeigen.‚Äù Die Wahrscheinlichkeit f√ºr \\(A\\) ist \\(1/6. \\square\\)\n\n\nDefinition 3.9 (Laplace-Experimt) Ein Zufallsexperiment, bei dem alle Elementarereignisse dieselbe Wahrscheinlichkeit haben, nennt man man ein Laplace-Experiment, s. thm-laplace. \\(\\square\\)\n\nIn Erweiterung von Theorem¬†3.1 k√∂nnen wir f√ºr ein Laplace-Experiment schreiben, s. Theorem¬†3.2.\n\nTheorem 3.2 (Laplace-Experiment) \\[Pr(A)=\\frac{\\text{Anzahl Treffer}}{\\text{Anzahl m√∂glicher Ergebnisse}} \\quad \\square\\]\n\n\n3.3.2 Frequentistische Wahrscheinlichkeit\nIn Ermangelung einer Theorie zum Verhalten eines (uns) unbekannten Zufallsvorgangs und unter der Vermutung, dass die Elementarereignisse nicht gleichwahrscheinlich sind, bleibt uns ein einfacher (aber aufw√§ndiger) Ausweg: Ausprobieren.\nAngenommen, ein Statistik-Dozent, bekannt f√ºr seine Vorliebe zum Gl√ºcksspiel und mit scheinbar endlosen Gl√ºcksstr√§hnen (er wirft andauernd eine 6), hat seinen Lieblingsw√ºrfel versehentlich liegen gelassen. Das ist die Gelegenheit! Sie greifen sich den W√ºrfel, und ‚Ä¶ Ja, was jetzt? Nach kurzer √úberlegung kommen Sie zum Entschluss, den W√ºrfel einem ‚ÄúPraxistest‚Äù zu unterziehen: Sie werfen ihn 1000 Mal (Puh!) und z√§hlen den Anteil der 6. Falls der W√ºrfel fair ist, m√ºsste gelten \\(Pr(A=6)=1/6\\approx .17\\). Schauen wir mal!\nUnd hier der Anteil von 6 im Verlauf unserer W√ºrfe, s. Abbildung¬†3.8.\n\n\n\n\n\n\n\nAbbildung¬†3.8: Das Gesetz der gro√üen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten W√ºrfelwurf\n\n\n\n\nHm, auf den ersten Blick ist kein (starkes) Anzeichen f√ºr Schummeln bzw. einen gezinkten W√ºrfel zu finden.\n\n3.3.3 Subjektive Wahrscheinlichkeit\nUm subjektiv zu einer Wahrscheinlichkeit zu kommen, sagt man einfach seine Meinung. Das h√∂rt sich nat√ºrlich total plump an. Und tats√§chlich besteht die Gefahr, dass die so ermittelten Wahrscheinlichkeiten aus der Luft gegriffen, also haltlos, sind.\nAllerdings kann diese Art von Wahrscheinlichkeitsermittlung auch sehr wertvoll sein. In komplizierten Situation im echten Leben12 kommt man oft in die Situation, dass weder die formallogischen noch die frequentistische Variante verwendet werden kann. Dann muss man auf Sch√§tzungen, Vorwissen, Erfahrung, theoretischen √úberlegungen etc. zur√ºckgreifen.\n\n3.3.4 Kolmogorovs Wahrscheinlichkeitsdefinition\nWir richten eine Reihe von Forderungen an eine Definition von bzw. an das Rechnen mit Wahrscheinlichkeiten, die direkt plausibel erscheinen:13\n\n\nNichtnegativit√§t: Die Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein.\n\nNormierung: Das sichere Ereignis hat die Wahrscheinlichkeit 1 bzw. 100%: \\(Pr(\\Omega)=1\\); das unm√∂gliche Ereignis hat die Wahrscheinlichkeit 0: \\(Pr(\\emptyset)=0\\).\n\nAdditivit√§t. Sind \\(A\\) und \\(B\\) disjunkt, dann ist die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt (\\(A\\cup B\\)) gleich der Summe der beiden Einzelwahrscheinlichkeiten von \\(A\\) und \\(B\\).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#relationen-von-ereignissen",
    "href": "0300-Wskt.html#relationen-von-ereignissen",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.4 Relationen von Ereignissen",
    "text": "3.4 Relationen von Ereignissen\nF√ºr das Rechnen mit Wahrscheinlichkeiten ist es hilfreich, ein paar Werkzeuge zu kennen, die wir uns im Folgenden anschauen.\n\nDefinition 3.10 (Relation) Eine Relation (zweier Ereignisse) bezeichnet die Beziehung, in der die beiden Ereignisse zueinander stehen. \\(\\square\\)\n\nTypische Relationen sind Gleichheit, Ungleichheit, Vereinigung, Schnitt.\n\n3.4.1 √úberblick\nWir gehen von Grundraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge von \\(\\Omega\\): \\(A \\subset \\Omega\\).\nDa wir Ereignisse als Mengen auffassen, verwenden wir im Folgenden die beiden Begriffe synonym.\nDabei nutzen wir u.a. Venn-Diagramme. Venn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren. Die folgenden Venn-Diagramme stammen von Wikipedia (En).\n\n\n\n\n\n\nWozu sind die Venn-Diagramme gut? Warum soll ich die lernen?\n\n\n\nVenn-Diagramme zeigen Kreise und ihre √ºberlappenden Teile; daraus lassen sich R√ºckschl√ºsse auf Rechenregeln f√ºr Wahrscheinlichkeiten ableiten. Viele Menschen tun sich leichter, Rechenregeln visuell aufzufassen als mit Formeln und Zahlen alleine. Aber entscheiden Sie selbst!\\(\\square\\)\n\n\nDiese App versinnbildlicht das Rechnen mit Relationen von Ereignissen anhand von Venn-Diagrammen.14\n\n3.4.2 Vereinigung von Ereignissen\n\nDefinition 3.11 (Vereinigung von Ereignissen) Vereinigt man zwei Ereignisse \\(A\\) und \\(B\\), dann besteht das neue Ereignis \\(C\\) genau aus den Elementarereignissen der vereinigten Ereignisse. Man schreibt \\(C = A \\cup B\\), lies: ‚ÄúC ist A vereinigt mit B‚Äù.\\(\\square\\)\n\nAbbildung¬†3.9 zeigt ein Venn-Diagramm zur Verdeutlichung der Vereinigung von Ereignissen.\n\n\n\n\n\nAbbildung¬†3.9: \\(A \\cup B\\): Vereinigung\n\n\n\nBeispiel 3.12 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem n√§chsten Wurf mindestens eines der beiden Ereignisse \\(A= {1,2}\\) oder \\(B={2,3}\\) eintreten, s. Abbildung¬†3.10.\n\n\n\n\\[\\begin{aligned}\nA = \\{1,2\\} \\qquad \\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}} \\\\\nB = \\{2,3\\} \\qquad  \\boxed{1\\; \\boxed{2\\; 3}\\; \\color{gray}{ 4\\; 5\\; 6}} \\\\\n\\newline\n\\hline \\\\\nA \\cup B = \\{1,2,3\\} \\qquad \\boxed{\\boxed{1\\; 2\\; 3}\\; \\color{gray}{4\\; 5\\; \\boxed{6}}}\n\\end{aligned}\\]\n\n\n\nAbbildung¬†3.10: Beispiel zur Vereinigung zweier Mengen\n\n\n\nZur besseren Verbildlichung betrachten Sie mal diese Animation zur Vereinigung von Mengen; Quelle.\nIn R hei√üt die Vereinigung von Mengen union(). Praktisch zum Ausprobieren:\n\nCodeA &lt;- c(1, 2)\nB &lt;- c(2, 3)\n\nunion(A, B)\n## [1] 1 2 3\n\n\n\n3.4.3 (Durch-)Schnitt von Ereignissen\n\nDefinition 3.12 (Schnittmenge von Ereignissen) Die Schnittmenge zweier Ereignisse \\(A\\) und \\(B\\) umfasst genau die Elementarereignisse, die Teil beider Ereignisse sind. Man schreibt: \\(A \\cap B.\\)15 Lies: ‚ÄúA geschnitten B‚Äù. \\(\\square\\)\n\nAbbildung¬†3.11 zeigt ein Sinnbild zur Schnittmenge zweier Ereignisse.\n\n\n\n\n\nAbbildung¬†3.11: \\(A \\cap B\\): Schnitt zweier Mengen\n\n\n\nBeispiel 3.13 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem n√§chsten Wurf sowohl das Ereignis \\(A\\) = ‚Äúgerade Augenzahl‚Äù als auch \\(B\\) = ‚ÄúAugenzahl gr√∂√üer 4‚Äù, s. Abbildung¬†3.12.\n\n\n\n\\[\\begin{align}\n& A = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n& B = \\{5,6\\} \\qquad \\qquad \\hfill  \\boxed{ \\color{gray}{1\\; 2\\; 3\\; 4\\;} \\boxed{\\color{black}{5\\; 6}}} \\\\\n\\newline\n\\hline \\\\\n& A \\cap B = \\{6\\} \\qquad \\qquad \\hfill  \\boxed{\\color{gray}{1\\; 2\\; 3\\; 4\\; 5\\;} \\color{black}{6}}\n\\end{align}\\]\n\n\n\nAbbildung¬†3.12: Beispiel zum Schnitt zweier Mengen\n\n\n\n\nCodeA &lt;- c(2, 4, 6)\nB &lt;- c(5, 6)\nintersect(A, B)\n## [1] 6\n\n\n\n\n\n\n\n\nEselsbr√ºcke zur Vereinigungs- und Schnittmenge\n\n\n\nDas Zeichen f√ºr eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen f√ºr einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine Eselbr√ºcke gelesen, s. Abbildung¬†3.13.\n\n\n\n\n\nAbbildung¬†3.13: Eselsbr√ºcke f√ºr Vereinigungs- und Schnittmenge\n\n\n\n\n\n3.4.4 Komplement√§rereignis\n\nDefinition 3.13 (Komplement√§rereignis) Ein Ereignis \\(A\\) ist genau dann ein Komplement√§rereignis zu \\(B\\), wenn es genau die Elementarereignisse von \\(\\Omega\\) umfasst, die nicht Elementarereignis des anderen Ereignisses sind, s. Abbildung¬†3.15.\\(\\square\\)\n\nMan schreibt f√ºr das Komplement√§rereignis16 von \\(A\\) oft \\(\\bar{A}\\) oder \\(\\neg A\\)17; lies ‚ÄúNicht-A‚Äù oder ‚ÄúA-quer‚Äù.\n\nBeispiel 3.14 Beim normalen W√ºrfelwurf sei \\(A\\) das Ereignis ‚Äúgerade Augenzahl‚Äù; das Komplement√§rereignis18 ist dann \\(\\neg A\\) ‚Äúungerade Augenzahl‚Äù, s. Abbildung¬†3.14.\n\n\n\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n\\hline \\\\\n\\neg A = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\end{align}\\]\n\n\n\nAbbildung¬†3.14: Ein Beispiel f√ºr ein Komplement\n\n\n\n\n\n\n\n\nAbbildung¬†3.15: \\(\\bar{A}\\): Komplement\n\n\n\n3.4.5 Logische Differenz\n\nDefinition 3.14 (Logische Differenz) Die logische Differenz der Ereignisse \\(A\\) und \\(B\\) ist das Ereignis, das genau aus den Elementarereignissen besteht von \\(A\\) besteht, die nicht zugleich Elementarereignis von \\(B\\) sind, s. Abbildung¬†3.16.\\(\\square\\)\n\nDie logische Differenz von \\(A\\) zu \\(B\\) schreibt man h√§ufig so: \\(A \\setminus B\\); lies ‚ÄúA minus B‚Äù.\n\n\n\n\n\nAbbildung¬†3.16: \\(A \\setminus B\\)\n\n\n\nBeispiel 3.15 Sei \\(A\\) die Menge ‚Äúgro√üe Zahlen‚Äù mit \\(A = \\{4,5,6 \\}\\). Sei \\(B\\) die Menge ‚Äúgerade Zahlen‚Äù mit \\(B = \\{2,4,6\\}\\). Wir suchen die logische Differenz, \\(A \\setminus B\\), s. Abbildung¬†3.17.\n\n\n\n\\[\\begin{align}\nA = \\{4,5, 6\\} \\qquad \\hfill \\boxed{\\color{red}{4}\\; \\color{green}{5}\\; \\color{red}{6}} \\\\\nB = \\{2,4,6\\} \\qquad  \\hfill \\boxed{\\color{grey}{2}\\; \\color{red}{4}\\; \\color{red}{6}} \\\\\n\\hline \\\\\nA \\setminus B \\qquad \\hfill \\boxed{\\color{green}{5}}\n\\end{align}\\]\n\n\n\nAbbildung¬†3.17: Beispiel f√ºr die logische Differenz\n\n\n\nIn R gibt es die Funktion setdiff(), die eine Mengendifferenz ausgibt.\n\nCodeA &lt;- c(4, 5, 6)\nB &lt;- c(2, 4, 6)\n\nsetdiff(A, B)\n## [1] 5\n\n\nü§Ø Von der Menge \\(A\\) die Menge \\(B\\) abzuziehen, ist etwas anderes, als von \\(B\\) die Menge \\(A\\) abzuziehen:\n\nCodesetdiff(B, A)\n## [1] 2\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\n\\(A \\setminus B \\ne B \\setminus A\\).\n\n\n\n3.4.6 Disjunkte Ereignisse\nSeien \\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\).\n\\(A\\) und \\(B\\) sind disjunkt19: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. Abbildung¬†3.18.\n\n\n\n\n\nAbbildung¬†3.18: Zwei disjunkte Ereignisse, dargestellt noch √ºberlappungsfreie Kreise\n\n\nQuelle: rither.de\n\nBeispiel 3.16 Das Ereignis \\(A\\) ‚ÄúGerade Augenzahl beim W√ºrfelwurf‚Äù, \\(A={2,4,6}\\) und das Ereignis \\(B\\) ‚ÄúUngerade Augenzahl beim W√ºrfelwurf‚Äù, \\(B={1,3,5}\\) sind disjunkt, s. Abbildung¬†3.19.\n\n\n\n\\[\\begin{align}\nA = \\{2,4, 6\\} \\qquad \\hfill \\boxed{2\\; 4\\; 6} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{1\\; 3\\; 5} \\\\\n\\hline \\\\\nA \\cap B = \\qquad  \\hfill  \\emptyset\n\\end{align}\\]\n\n\n\nAbbildung¬†3.19: Beispiel f√ºr disjunkte Ereignisse\n\n\n\n\nDie Ereignisse ‚Äúnormaler Wochentag‚Äù und ‚ÄúSonntag‚Äù sind disjunkt. \\(\\square\\)\n\n\n3.4.7 Vertiefung\nAnimation zu Mengenoperationen",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#indirekte-ermittlung-von-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#indirekte-ermittlung-von-wahrscheinlichkeiten",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.5 Indirekte Ermittlung von Wahrscheinlichkeiten",
    "text": "3.5 Indirekte Ermittlung von Wahrscheinlichkeiten\nDie indirekte Ermittlung von Wahrscheinlichkeiten meint das Ableiten von Wahrscheinlichkeitsaussagen, wenn man schon etwas √ºber die Wahrscheinlichkeiten des Grundraums wei√ü. Dazu greift man auf Rechenregeln der Stochastik zur√ºck: Man rechnet mit Wahrscheinlichkeiten. Das h√∂rt sich vielleicht wild an, ist aber oft ganz einfach.\n\nBeispiel 3.17 (Wahrscheinlichkeit f√ºr eine gerade Zahl beim W√ºrfelwurf) Ein (normaler) W√ºrfel wird geworfen. Was ist die Wahrscheinlichkeit f√ºr eine gerade Zahl, also f√ºr das Ereignis \\(A=\\{2, 4, 6\\}\\)? Diese Wahrscheinlichkeit betr√§gt \\(Pr(\\text{gerade Zahl}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2\\). \\(\\square\\)\n\n\nBeispiel 3.18 (Gezinkter W√ºrfel) Ein gezinkter W√ºrfel hat eine erh√∂hte Wahrscheinlichkeit f√ºr das Ereignis \\(A=\\)‚Äú6 liegt oben‚Äù, und zwar gelte \\(Pr(A)=1/3\\). Was ist die Wahrscheinlichkeit, keine 6 zu w√ºrfeln?\\(\\square\\)20",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#additionssatz",
    "href": "0300-Wskt.html#additionssatz",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.6 Additionssatz",
    "text": "3.6 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse A und B eintritt. ‚ÄúMindestens eines der Ereignisse A und‚Äù schreibt man \\(A \\cup B\\) und sagt ‚ÄúA vereinigt B‚Äù.\n\n3.6.1 Disjunkte Ereignisse\nGegeben sei \\(\\Omega = {1,2,3,4,5,6}\\) beim normalen W√ºrfelwurf. Als Sinnbild: \\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\). Gesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\), das also eine 1 oder\neine 2 geworfen wird. Man beachte, dass die beiden Ergebnisse disjunkt sind, s. Abbildung¬†3.18.\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\nDie Wahrscheinlichkeit f√ºr \\(A\\) ist die Summe der Wahrscheinlichkeiten der einzelnen Ereignisse (1 und 2):\n\\(P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\nDefinition 3.15 (Additionssatz f√ºr disjunkte Ereignisse) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt, ist die Summe der Einzelwahrscheinlichkeiten, s. Theorem¬†3.3.\n\n\nTheorem 3.3 (Additionssatz f√ºr disjunkte Ereignisse) \\[P(A \\cup B) = P(A) + P(B) \\square\\]\n\n\nBeispiel 3.19 Was ist die Wahrscheinlichkeit, an einem Samstag oder Sonntag geboren zu sein? Unter der (vereinfachten) Annahme, dass alle Jahre zu gleichen Teilen aus allen Wochentagen bestehen und dass an allen Tagen gleich viele Babies geworden werden21, ist die Antwort \\(Pr(A)=1/7 + 1/7 = 2/7\\).\\(\\square\\)\n\n\n3.6.2 Allgemein (disjunkt oder nicht disjunkt)\nBei der Addition der Wahrscheinlichkeiten f√ºr \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) (der √úberlappungsbereich) doppelt erfasst.22 Der √úberlappungsbereich muss daher noch abgezogen werden, s. Abbildung¬†3.20.\n\nDefinition 3.16 (Allgemeiner Additionssatz) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse \\(A\\) und \\(B\\) eintritt, ist gleich der Summe ihrer Wahrscheinlichkeiten minus ihrer gemeinsamen Wahrscheinlichkeit, s. Theorem¬†3.4 und Abbildung¬†3.20. \\(\\square\\)\n\n\nTheorem 3.4 (Allgemeiner Additionssatz) \\[P(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\square\\]\n\n\n\n\n\n\nAbbildung¬†3.20: Der allgemeine Additionssatz gibt die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt.\n\n\n\n\n\n\n\n\n\nBeispiel 3.20 (Lernen und Klausur bestehen) In einem angewandten Psychologie-Studiengang sind die Studis verdonnert, zwei Statistik-Module (\\(S1, S2\\)) zu belegen. Die meisten bestehen (\\(B\\)), einige leider nicht (\\(N\\)), s. Tabelle¬†3.1.\nEreignis \\(S_1B\\) sei ‚ÄúKlausur Statistik 1 bestanden‚Äù Ereignis \\(S_2B\\) ist analog f√ºr ‚ÄúKlausur Statistik 2‚Äù.\nWir suchen die Wahrscheinlichkeit des Ereignisses A, mindestens eine der beiden Klausuren zu bestehen: \\(Pr(A) = Pr(S_1B \\cup S_2B)\\).\n\n\n\nTabelle¬†3.1: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n.\nS1_B\nS1_NB\nSumme\n\n\n\nS2_B\n85\n9\n94\n\n\nS2_NB\n5\n1\n6\n\n\nSumme\n90\n10\n100\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(A) &= Pr(S_1B \\cup S_2B) \\\\\n&= Pr(S1_B) + Pr(S_2B) - Pr(S_1B \\cap S_2B)  \\\\\n&= (90 + 94 - 85) / 100 = 99 / 100\\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen liegt bei 99%. Umgekehrt liegt die Wahrscheinlichkeit, keine der beiden Klausuren zu bestehen, liegt bei \\(Pr(\\neg A) = 1- Pr(A) = 0.01 = 1\\%\\); ein Sachverhalt, der sich auch mit einem kurzen Blick in die Datentabelle erkennen l√§sst.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#bedingte-wahrscheinlichkeit",
    "href": "0300-Wskt.html#bedingte-wahrscheinlichkeit",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.7 Bedingte Wahrscheinlichkeit",
    "text": "3.7 Bedingte Wahrscheinlichkeit\n\n3.7.1 Illustration zur bedingten Wahrscheinlichkeit\n\nDefinition 3.17 (Bedingte Wahrscheinlichkeit) Die bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit, dass \\(A\\) eintritt, gegeben dass \\(B\\) schon eingetreten ist. \\(\\square\\)\n\nMan schreibt: \\(Pr(A|B).\\) Lies: ‚ÄúA gegeben B‚Äù oder ‚ÄúA wenn B‚Äù.\n\n√úbungsaufgabe 3.3 Schauen Sie sich mal diese Wahnsinnsanimation von Victor Powell an zu bedingten Wahrscheinlichkeiten. Hammer!\n\nAbbildung¬†3.21 illustriert unbedingte Wahrscheinlichkeit, \\(Pr(A), Pr(B)\\), gemeinsame Wahrscheinlichkeit \\(P(A \\cap B)\\), und bedingte Wahrscheinlichkeit, \\(P(A|B)\\).\n\n\n\n\n\\(Pr(A)\\)\n\\(Pr(B)\\)\n\\(Pr(B|A)\\)\n\\(Pr(A \\cap B)\\)\n\n\n\n\n\n\n\n\n\n\n(a) Unbedingte Wahrscheinlichkeit f√ºr Ereignis A: 50%=1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Unbedingte Wahrscheinlichkeit f√ºr Ereignis B: 50%=1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Wahrscheinlichkeit f√ºr Ereignis B gegeben A, \\(Pr(B|A)=1/2\\)\n\n\n\n\n\n\n\\(Pr(A \\cap B)\\) wird auch h√§ufig (synonym) geschrieben als \\(Pr(AB)\\).\n\n\n\n\n\n\n\n(d) Wahrscheinlichkeit f√ºr das gemeinsame Eintreten von A und B: \\(Pr(AB)=1/4\\)\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.21: Illustration von unbedingter, gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\nBeispiel 3.21 (Bedingte Wahrscheinlichkeit) Sei \\(A\\) ‚ÄúSch√∂nes Wetter‚Äù und \\(B\\) ‚ÄúKlausur steht an‚Äù. Dann meint \\(Pr(A|B)\\) die Wahrscheinlichkeit, dass das Wetter sch√∂n ist, wenn gerade eine Klausur ansteht.\\(\\square\\)\n\n\nBeispiel 3.22 (Von P√§psten und M√§nnern) Man(n) beachte, dass die Wahrscheinlichkeit, Papst \\(P\\) zu sein, wenn man Mann \\(M\\) ist etwas anderes ist, als die Wahrscheinlichkeit, Mann zu sein, wenn man Papst ist: \\(Pr(P|M) \\ne Pr(M|P)\\). Das h√∂rt sich erst verwirrend an, aber wenn man dar√ºber nachdenkt, wird es plausibel.\\(\\square\\)\n\n\nBeispiel 3.23 Gustav Gro√ü-G√ºtz verkauft eine Tinktur23, die schlau machen soll, ‚ÄúG√ºtzis Gehirn Gr√ºtze‚Äù.24 Gustav trinkt die Gr√ºtze und sagt schlaue Dinge. Was schlie√üen wir daraus? Sei \\(H\\) (wie Hypothese) ‚ÄúG√ºtzis Gr√ºtze macht schlau‚Äù; sei \\(D\\) (wie Daten) die Beobachtung, dass Gustav schlaue Dinge gesagt hat. Ohne exakte Zahlen zu suchen, wie hoch ist wohl \\(Pr(D|H)\\)? In Worten: ‚ÄúWie wahrscheinlich ist es, schlaue Dinge gesagt zu haben, wenn die Gr√ºtze wirklich schlau macht?‚Äù. Vermutlich ist diese Wahrscheinlichkeit sehr hoch. Aber wie hoch ist wohl \\(Pr(H|D)\\)? In Worten: ‚ÄúWie wahrscheinlich ist es, dass die Gr√ºtze wirklich schlau macht, gegeben, dass wir gesehen hat, dass jemand etwas schlaues gesagt hat, nachdem er besagte Gr√ºtze getrunken hat?‚Äù Skeptische Geister werden der Meinung sein, \\(Pr(H|D)\\) ist gering. Das Beispiel zeigt u.a. \\(Pr(H|D) \\ne Pr(D|H).\\square\\)\n\n\n3.7.2 Bedingte Wahrscheinlichkeit als Filtern einer Tabelle\n\nBetrachten wir Tabelle¬†3.2. Dort sind sind vier Tage aufgelistet, mit jeweils Regen (oder kein Regen) bzw. an denen es kalt ist (oder nicht). Filtern wir z.B. die Tabelle so, dass nur kalte Tage √ºbrig bleiben, dann gibt der Anteil der Zeilen, die ‚ÄúRegen‚Äù anzeigen, die bedingte Wahrscheinlichkeit \\(Pr(\\text{Regen}|\\text{kalt})\\) an.\n\n\n\nTabelle¬†3.2: Die Tabelle zeigt vier Tage, an denen es jeweils kalt ist (oder nicht) bzw. regnet (oder nicht). Die bedingte Wahrscheinlichkeit \\(Pr(\\text{Regen}|\\text{kalt})\\) entspricht dem Anteil der Zeilen mit Regen, wenn f√ºr ‚Äòkalt‚Äô ein Filter in der Tabelle gesetzt ist.\n\n\n\n\n\n\n\n\n\n\nAlso: Das Berechnen einer bedingten Wahrscheinlichkeit, \\(Pr(A|B)\\), ist vergleichbar zum Filtern einer Tabelle, s. Tabelle¬†3.3.\n\n\n\nTabelle¬†3.3: Eine bedingte Wahrscheinlichkeit kann man als gefilterte Tabelle verstehen\n\n\n\n\nid\nkalt\nRegen\n\n\n\n1\n0\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n1\n1\n\n\nSUMME\n2\n2\n\n\n\n\n\n\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(Pr(A) = 2/4; Pr(B) = 2/4; Pr(A \\cap B) = 1/4; Pr(A|B) = 1/2\\)\nDie Wahrscheinlichkeit f√ºr \\(A\\), wenn \\(B\\) schon eingetreten ist, berechnet sich so, s. Theorem¬†3.5 und Abbildung¬†3.21 (c).\n\nTheorem 3.5 (Bedingte Wahrscheinlichkeit) \\[Pr(A|B) = \\frac{Pr(A \\cap B)}{Pr(B)}\\]\nAu√üerdem gilt analog\n\\[Pr(B|A) = \\frac{Pr(B \\cap A)}{Pr(A)} \\quad \\square\\]\n\n\nBeispiel 3.24 (Lernen und Klausur bestehen) Sie bereiten sich gerade auf die Klausur bei Prof.¬†S√º√ü vor. Das hei√üt: Sie √ºberlegen, ob Sie sich auf die Klausur vorbereiten sollten. Vielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr gro√ü? Aber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen k√∂nnen, s. Tabelle¬†3.4. In der Tabelle sind die Daten von 100 Studis ausgewiesen. Ein Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die ‚ÄúLerner‚Äù. Ein anderer Teil hat nicht gelernt, \\(NL\\) bzw. \\(\\neg L\\). Ein Teil hat bestanden, \\(B\\), ein Teil nicht \\(NB\\) oder \\(\\neg B\\).\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: \\(Pr(B |\\neg L)\\).\n\n\n\nTabelle¬†3.4: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n.\nL\nNL\nSumme\n\n\n\nB\n80\n1\n81\n\n\nNB\n5\n14\n19\n\n\nSumme\n85\n15\n100\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(B |\\neg L) &= \\frac{Pr(B \\cap \\neg L)}{Pr(\\neg L)} \\\\\n&=\\frac{1/100}{15/100} = 1/15 \\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat, liegt bei 1 von 15, also ca. 7%.25 \\(\\square\\)\n\n\nBeispiel 3.25 (Kalt und Regen) Die Wahrscheinlichkeit, dass es kalt ist, wenn es regnet, ist gleich der Wahrscheinlichkeit, dass es gleichzeitig kalt ist und regnet, geteilt durch die Wahrscheinlichkeit, dass es regnet.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#stochastische-un-abh√§ngigkeit",
    "href": "0300-Wskt.html#stochastische-un-abh√§ngigkeit",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.8 Stochastische (Un-)Abh√§ngigkeit",
    "text": "3.8 Stochastische (Un-)Abh√§ngigkeit\n\n3.8.1 Unabh√§ngigkeit\nStochastische Unabh√§ngigkeit ist ein Spezialfall von Abh√§ngigkeit: Es gibt sehr viele Auspr√§gungen f√ºr Abh√§ngigkeit, aber nur eine f√ºr Unabh√§ngigkeit. K√∂nnen wir Unabh√§ngigkeit nachweisen, haben wir also eine starke Aussage get√§tigt.\n\nDefinition 3.22 (Stochastische Unabh√§ngigkeit) Zwei Ereignisse sind (stochastisch) unabh√§ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abh√§ngt, ob \\(B\\) der Fall ist, s. Theorem¬†3.6. Anders gesagt:26\n\n\nTheorem 3.6 (Stochastische Unabh√§ngigkeit) \\[Pr(A|B) = Pr(A) = Pr(A|\\neg B). \\square\\]\nDie Unabh√§ngigkeit von \\(A\\) und \\(B\\) wird manchmal so in Kurzschreibweise ausgedr√ºckt: \\(\\perp \\!\\!\\! \\perp(A, B) \\square\\).\n\n\nTheorem 3.7 (Stochastische Unabh√§ngigkeit 2) Setzt man Theorem¬†3.5 in Theorem¬†3.6 (linke Seite) ein, so folgt27\n\\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B).\\quad \\square\\]\n\n\nBeispiel 3.26 (Augenfarbe und Statistikliebe) Ich vermute, dass die Ereignisse \\(A\\), ‚ÄúAugenfarbe ist blau‚Äù, und \\(B\\), ‚ÄúIch liebe Statistik‚Äù, voneinander unabh√§ngig sind.\\(\\square\\)28\n\n\nBeispiel 3.27 (√úberleben auf der Titanic) S. Abbildung¬†3.22, links: √úberleben (√ú) auf der Titanic ist offenbar abh√§ngig von der Passagierklasse (\\(K_1, K_2, K_3\\)). In Abbildung¬†3.22, links gilt also \\(Pr(√ú|K_1) \\ne Pr(√ú|K_2) \\ne Pr(√ú|K_3) \\ne Pr(√ú)\\).\nAuf der anderen Seite: Das Ereignis √úberleben (√ú) auf der Titanic ist unabh√§ngig vom Ereignis Alter ist eine Primzahl (P), s. Abbildung¬†3.22, rechts. Also: \\(Pr(√ú|P) = Pr(√ú|\\neg P) = Pr(√ú)\\), vgl. Tabelle¬†3.5.\n\n\n\nTabelle¬†3.5: Kontingenztablle (H√§ufigkeiten) f√ºr ‚Äò√úberleben auf der Titanic‚Äô und ‚ÄòAlter ist Primzahl‚Äô. Wie man sieht, gibt es keine stochastische Abh√§ngigkeit.\n\n\n\n\n\n\nAge_prime\nn\nprop\n\n\n\n0\n\n\nnon-prime\n96\n0.17\n\n\nprime\n453\n0.83\n\n\n1\n\n\nnon-prime\n58\n0.17\n\n\nprime\n282\n0.83\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) √úberleben und Passagierklasse sind abh√§ngig\n\n\n\n\n\n\n\n\n\n(b) √úberleben und ‚ÄòGeburstag ist eine Primzahl‚Äô sind nicht abh√§ngig\n\n\n\n\n\n\nAbbildung¬†3.22: Abh√§ngigkeit und Unabh√§ngigkeit zweier Ereignisse\n\n\n\n3.8.2 Stochastische Abh√§ngigkeit\nLiegt keine Unabh√§ngigkeit vor, so spricht man von (stochatistischer) Abh√§ngigkeit, s. Theorem¬†3.8. In diesem Fall ver√§ndert sich unser Wissen √ºber die Wahrscheinlihkeit von \\(A\\), wenn wir wissen, dass \\(B\\) eingetroffen ist, s. Theorem¬†3.8.\n\nTheorem 3.8 (Stochastische Abh√§ngigkeit) \\[Pr(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B) \\quad \\square\\]\nTheorem¬†3.8 gilt nat√ºrlich in dieser Form f√ºr alle anderen Variablen ebenso, s. z.B. Theorem¬†3.9. \\(\\square\\)\n\n\nTheorem 3.9 (Stochastische Abh√§ngigkeit 2) \\[Pr(B|A) \\ne Pr(B) \\ne Pr(B|\\neg A) \\quad \\square\\]\n\n\nBeispiel 3.28 Die Ereignisse ‚ÄúLernen‚Äù und ‚ÄúKlausur bestehen‚Äù seien voneinander abh√§ngig. Unsere Ansicht zur Wahrscheinlichkeit von K √§ndert sich, wenn wir wissen, dass L vorliegt. Genauso wird sich unsere Einsch√§tzung zur Wahrschienlichkeit von K √§ndern, wenn wir wissen, dass L nicht vorliegt. \\(\\square\\)\n\n\nBeispiel 3.29 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land29 (\\(B\\)) voneinander abh√§ngig (s. Abbildung¬†3.23)?\n\n\n\n\n\n\n\n\n\n(a) Impfquote und Land sind voneinander abh√§ngig\n\n\n\n\n\n\n\n\n\n(b) Anteil Corona-Tote und Land sind voneinander abh√§ngig\n\n\n\n\n\n\nAbbildung¬†3.23: Impfquote und Sterblichkeit sind voneinander abh√§ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\nJa, die beiden Ereignisse sind abh√§ngig, da in beiden Diagrammen gilt: \\(P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\\(\\square\\)30\n\n\n3.8.3 Unabh√§ngigkeit ist symmetrisch\nStochastische Unabh√§ngigkeit ist symmetrisch: Wenn \\(A\\) unabh√§ngig zu \\(B\\) ist auch \\(B\\) unabh√§ngig zu \\(A\\), s. Theorem¬†3.10.\n\nTheorem 3.10 (Symmetrie der Unabh√§ngigkeit) \\[Pr(A|B) = Pr(A) \\leftrightarrow Pr(B|A) = Pr(B)\\]\nMan beachte, dass stochastische Unabh√§ngigkeit und kausale Unabh√§ngigkeit unterschiedliche Dinge sind (Henze, 2019): Stochastische Unabh√§ngigkeit impliziert nicht kausale Unabh√§ngigkeit. \\(\\square\\)\n\n\n3.9 Multiplikationssatz\nGegeben seien die Ereignisse \\(A\\) und \\(B\\). Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass beide Ereignisse \\(A\\) und \\(B\\) eintreten; s. Abbildung¬†3.21 (d) verdeutlicht dies f√ºr zwei unabh√§ngige Ereignisse. Man schreibt ‚ÄúA und B‚Äù als \\(A \\cap B\\) (lies ‚ÄúA geschnitten B‚Äù oder ‚ÄúA und B‚Äù) oder kurz \\(AB\\), um anzuzeigen, dass sowohl \\(A\\) als auch \\(B\\) eingetreten sind.\n\n\n\n\nBeide Ereignisse A und B sind eingetreten\n\n\n\n\nBeispiel 3.30 (Wieder kalt und Regen) Es ist eine Sache, zu fragen, wie wahrscheinlich ist ist, dass es kalt ist (bei K√§lte), wenn es regnet (bei Regen): \\(Pr(K|R)\\). Anders gesagt: ‚ÄúWie gro√ü ist die Wahrscheinlichkeit f√ºr K√§lte, gegeben dass es regnet?‚Äù Eine andere Sache ist es, nach der Wahrscheinlichkeit zu fragen, dass es gleichzeitig kalt ist und regnet, dass also beide Ereignisse (kalt und Regen) eintreten: \\(Pr(K \\cap R), PR(KR)\\). \\(\\square\\)\n\n\n3.9.1 Gemeinsame Wahrscheinlichkeit unabh√§ngiger Ereignisse\n\nBeispiel 3.31 Wir f√ºhren das Zufallsexperiment ‚ÄúWurf einer fairen M√ºnze‚Äù zwei Mal aus (Abbildung¬†3.24). Wie gro√ü ist die Wahrscheinlichkeit, 2 Mal Kopf zu werfen? Dabei vereinbaren wir, dass ‚ÄúKopf‚Äù als ‚ÄúTreffer‚Äù z√§hlt (und ‚ÄúZahl‚Äù als ‚ÄúNiete‚Äù).\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.24: Wir werfen zwei faire M√ºnzen: Zweifach wiederholtes Zufallexperiment\n\n\nAbbildung¬†3.24 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis des Zufallexperiments. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom ‚ÄúStart‚Äù (schwarzer Kreis) f√ºhren zwei m√∂gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch Bl√§tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen M√ºnzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der Bl√§tter. In diesen Diagramm gibt es vier Pfade (und Bl√§tter).\nDen Wurf der ersten M√ºnze nennen wir in gewohnter Manier \\(A\\); den Wurf der zweiten M√ºnze \\(B\\).\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in Tabelle¬†3.6.\n\n\n\nTabelle¬†3.6: Wahrscheinlichkeiten der Ereignisse im zweimaligen M√ºnzwurf\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\n\n\nSei \\(K_1\\) das Ereignis, mit der 1. M√ºnze Kopf zu werfen; sei \\(K_2\\) das Ereignis, mit der 2. M√ºnze Kopf zu werfen-\nWir suchen \\(Pr(K_1 \\cap K_2)\\). Aufgrund der stochastischen Unabh√§ngigkeit der beiden Ereignisse gilt: \\(Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)\\).\n\nCodePr_K1K2 &lt;- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n\n\n\nDefinition 3.18 (Multiplikationssatz f√ºr unabh√§ngige Ereignisse) Die Wahrscheinlichkeit, dass zwei (oder mehr) unabh√§ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. Theorem¬†3.11. \\(\\square\\)\n\n\nTheorem 3.11 (Multiplikationssatz f√ºr unabh√§ngige Ereignisse) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B)\\]\nMan beachte, dass es egal ist, ob \\(A\\) gemeinsam mit \\(B\\) oder \\(B\\) gemeinsam mit \\(A\\) eintreten: \\(Pr(A \\cap B) = Pr(B \\cap A)\\).31 \\(\\square\\)\n\nMit dieser App k√∂nnen Sie das Baumdiagramm f√ºr den zweifachen M√ºnzwurf n√§her erkunden.\nWir f√ºhren das Zufallsexperiment ‚ÄúWurf einer fairen M√ºnze‚Äù drei Mal aus (Abbildung¬†3.25). Dabei vereinbaren wir wieder, dass ‚ÄúKopf‚Äù (K) als ‚ÄúTreffer‚Äù gilt und ‚ÄúZahl‚Äù (Z) als ‚ÄúNiete‚Äù.\n\n\n\n\n\nAbbildung¬†3.25: Wir werfen drei faire M√ºnzen: Dreifach wiederholtes Zufallexperiment\n\n\nBeim Wurf von ‚Äúfairen‚Äù M√ºnzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere Einsch√§tzung des Ergebnis des 2. Wurfes nicht ver√§ndert etc. Anders gesagt: Wir gehen von (stochastischer) Unabh√§ngigkeit aus.\nF√ºr z.B. das Ereignis \\(A=\\{ZZZ\\}\\) gilt: \\(Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3\\). Da jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jeweils gleich.\nAllgemeiner gilt: F√ºr ein Zufallsexpriment, das aus \\(k\\) Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit \\(Pr(X)=p\\) ist, so ist die Wahrscheinlichkeit f√ºr einen Endkonten \\(Pr(X^k)=p^k\\).\n\n\n\nTabelle¬†3.7: Ausgew√§hlte Wahrscheinlichkeiten von Ereignissen im dreifachen M√ºnzwurf\n\n\n\n  \n\n\n\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. Tabelle¬†3.7.\nAbbildung¬†3.21 versinnbildlicht nicht nur die Bedingtheit zweier Ereignisse, sondern auch die (Un-)Abh√§ngigkeit zweier Ereignisse, \\(A\\) und \\(B\\). In diesem Fall ist die Wahrscheinlichkeit von \\(A\\) gleich \\(B\\): \\(Pr(A)=Pr(B)=.5\\). Man sieht, dass die Wahrscheinlichkeit von \\(A\\) bzw. von \\(B\\) jeweils die H√§lfte der Fl√§che (der Gesamtfl√§che, d.h von \\(Pr(\\Omega)=1\\)) ausmacht. Die Schnittmenge der Fl√§che von \\(A\\) und \\(B\\) entspricht einem Viertel der Fl√§che: \\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.\\) In diesem Fall sind \\(A\\) und \\(B\\) unabh√§ngig. Abbildung¬†3.21 zeigt weiterhin, dass gilt: \\(P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\). Man beachte dass diese Formel nur bei Unabh√§ngigkeit (von A und B) gilt.\n\n3.9.2 Gemeinsame Wahrscheinlichkeit abh√§ngiger Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung abh√§ngiger Ereignisse an, s. Abbildung¬†3.26. F√ºr unabh√§ngige Ereignisse √ºbrigens auch.\n\nBeispiel 3.32 In einer Urne befinden sich f√ºnf Kugeln, von denen vier rot sind und eine blau ist.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nWie gro√ü ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zur√ºcklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier, 2011), S. 47. Ereignis A: ‚ÄúKugel im 1. Zug hat die Farbe Rot‚Äù. Ereignis B: ‚ÄúKugel im 2. Zug hat die Farbe Rot‚Äù.\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. Abbildung¬†3.26.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|4/5|B[Zug 1 - R]\n  A --&gt;|1/5|C[Zug 1 - B]\n  B --&gt;|3/4|D[Zug 2 - R]\n  B --&gt;|1/4|E[Zug 2 -  B]\n  D --- H[Fazit: RR - 4/5*3/4 = 12/20]\n  E --- I[Fazit: RB - 4/5*1/4 = 4/20]\n  C --&gt;|4/4|F[Zug 2 - R]\n  C --&gt;|0/4|G[Zug 2 - B]\n  F --- J[Fazit: BR - 1/5*4/4 = 4/20]\n  G --- K[Fazit: BB - 1/5*0/4 = 0/20]\n  \n\n\n\n\nAbbildung¬†3.26: Baumdiagramm f√ºr ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abh√§ngig ist vom 1. Zug.\n\n\n\n\nWie man in Abbildung¬†3.26 nachrechnen kann gilt also: \\(P(A\\cap B) = P(A) \\cdot P(B|A) \\square\\).\n\n\nDefinition 3.19 (Gemeinsame Wahrscheinlichkeit) Die Wahrscheinlichkeit, dass zwei abh√§ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt der Wahrscheinlichkeit von \\(A\\) und der bedingten Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\), s. Theorem¬†3.12. \\(\\square\\)\n\n\nTheorem 3.12 (Gemeinsame Wahrscheinlichkeit) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B|A) \\quad \\square\\]\n\n\nBeispiel 3.33 (Kalt und Regen) Von McElreath (2020) stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit. Was ist die Wahrscheinlichkeit f√ºr das gemeinsame Auftreten von kalt ‚ùÑ und Regen ‚õàÔ∏è? Die Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von Regen ‚õà, wenn‚Äôs kalt ‚ùÑ ist mal die Wahrscheinlichkeit von K√§lte ‚ùÑ.\nEbenfalls gilt: Die Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von K√§lte ‚ùÑ, wenn‚Äôs regnet ‚õàÔ∏è mal die Wahrscheinlichkeit von Regen ‚õàÔ∏è.\nDas Gesagte als Emoji-Gleichung ist in Gleichung¬†3.1 dargestellt.\n\\[P(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è |‚ùÑÔ∏è ) \\cdot P(‚ùÑÔ∏è) =  P(‚ùÑÔ∏è |‚õàÔ∏è ) \\cdot P(‚õàÔ∏è) \\tag{3.1}\\]\nMan kann die ‚ÄúGleichung drehen‚Äù32, s. Gleichung¬†3.2.\n\\[P(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è \\text{ und } ‚ùÑÔ∏è) \\tag{3.2}\\] \\(\\square\\)\n\n\nBeispiel 3.34 (Bertie Botts Bohnen jeder Geschmacksrichtung) ¬†\n\nSei blo√ü vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gew√∂hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.‚Äú\n\n‚Äî Ron Weasley zu Harry Potter33\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=2\\) furchtbar scheu√üliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erkl√§rt, \\(k=2\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt hei√üt es tapfer sein. Ziehen und runter damit!\nWie gro√ü ist die Wahrscheinlichkeit, genau eine scheu√üliche Bohne zu erwischen?\nEs gibt 2 Pfade f√ºr 1 Treffer bei 2 Wiederholungen (Z√ºge aus dem Beutel):\n\nCodePfad1 &lt;- 3/20 * 17/19  # scheu√üliche Bohne im 1. Zug\nPfad2 &lt;- 17/20 * 3/19  # scheu√üliche Bohne im 2. Zug\n\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 \nGesamt_Pr\n## [1] 0.2684211\n\n\nNutzen Sie diese App, um das auszuprobieren. Sie m√ºssen in der App noch die Zahl der Bohnen (\\(n\\)) und die Zahl der scheu√ülichen Bohnen (\\(x\\)) einstellen.\\(\\square\\)\n\n\nDefinition 3.20 (Kettenregel) Allgemein gesagt, spricht man von der Kettenregel der Wahrscheinlichkeitsrechnung, wenn man die gemeinsame Wahrscheinlichkeit auf die bedingte zur√ºckf√ºhrt, s. Theorem¬†3.13. \\(\\square\\)\n\n\nTheorem 3.13 (Kettenregel) \\[P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B) \\square\\]\nIn Worten: Die Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) ist gleich der Wahrscheinlichkeit von \\(A\\) mal der Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\).\n\n\n√úbungsaufgabe 3.4 (Baumdiagramm sucht Problem) √úberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit dieser Baumdiagramm-App gel√∂st werden kann.\\(\\square\\)\n\n\n3.10 Totale Wahrscheinlichkeit\n\nBeispiel 3.35 (Gesamter Ausschussanteil) Die folgende Aufgabe bezieht sich auf Bourier (2011), S. 56. Drei Maschinen (\\(M_1, M_2, M_3\\)) produzieren einen Artikel. Die Maschinen haben einen Anteil an der Produktion von 60, 10 bzw. 30% und eine Ausschussquote von 5,2 bzw. 4%. Sei \\(M\\) das Ereignis, dass ein Artikel von Maschine \\(M\\) stammt, und \\(S\\) (Schrott) das Ereignis, dass ein Artikel Ausschuss (Schrott) ist. Wie gro√ü ist der Ausschussanteil insgesamt (√ºber alle drei Maschinen?) Anders gesagt: Wie hoch ist die Wahrscheinlichkeit, dass ein zuf√§llig gezogener Artikel Ausschuss ist. Abbildung¬†3.27 zeigt das Baumdiagramm f√ºr die Aufgabe. \\(\\square\\)\n\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[M1]\n  A --&gt;|0.1|C[M2]\n  A --&gt;|0.3|D[M3]\n  B --&gt;|0.05|E[S]\n  B -.-&gt;|0.95|F[Nicht-S]\n  C --&gt;|0.02|G[S]\n  C -.-&gt;|0.98|H[Nicht-S]\n  D --&gt;|0.04|I[S]\n  D -.-&gt;|0.96|J[Nicht-S]\n\n\n\n\nAbbildung¬†3.27: Totale Wahrscheinlichkeit\n\n\n\n\nGesucht ist also die Wahrscheinlichkeit \\(P(B)\\); \\(A\\) ist ein vollst√§ndiges Ereignissystem.\nDazu addieren wir die Wahrscheinlichkeiten der relevanten √Ñste. Jeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse \\(A_i\\) und \\(B\\) dar.\n\nCodeW_Ast1 &lt;- 0.6 * 0.05  # Wahrscheinlichkeit f√ºr Ast 1\nW_Ast2 &lt;- 0.1 * 0.02  # ... Ast 2\nW_Ast3 &lt;- 0.3 * 0.04  # ... Ast 3\nW_total &lt;- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n\n\nDie totale Wahrscheinlichkeit (f√ºr Ausschuss) betr√§gt in diesem Beispiel also \\(P(B) = 4.4\\%\\).34\n\nDefinition 3.21 (Totale Wahrscheinlichkeit) Bilden die Ereignisse \\(A_1, A_2, ..., A_n\\) ein vollst√§ndiges Ereignissystem und ist \\(B\\) ein beliebiges Ereignis dann gilt Theorem¬†3.14. \\(\\square\\)\n\n\nTheorem 3.14 (Totale Wahrscheinlichkeit) \\[Pr(B) = \\sum_{i=1}^n Pr(A_i) \\cdot Pr(B|A_i).\\square\\]\n\nMan kann die totale Wahrscheinlichkeit auffassen als die Summe der gewichteten Teil-Wahrscheinlichkeiten.\n\nIn Abbildung¬†3.27 (Beispiel¬†3.35) gilt \\(Pr(B) = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot  0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square\\)\n\n\n√úbungsaufgabe 3.5 (Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2) Es ist die gleich Aufgabe wie Beispiel¬†3.34, aber jetzt lautet die Frage: Wie gro√ü ist die Wahrscheinlichkeit, mindestens eine scheu√üliche Bohne bei 3 Z√ºgen zu erwischen?35 \\(\\square\\)\n\n\n3.10.1 Baumsammlung\nBaumdiagramme sind ein hilfreiches Werkzeug f√ºr wiederholte Zufallsexperimente. Daher ist hier eine ‚ÄúBaumsammlung‚Äù36 zusammengestellt.\n\nSie werfen 1 M√ºnze, Abbildung¬†3.2.\nSie werfen 2 M√ºnzen, Abbildung¬†3.24.\nSie werfen 3 M√ºnzen, Abbildung¬†3.25.\nSie werfen 4 M√ºnzen, Abbildung¬†4.1.\nSie werfen 9 M√ºnzen, ü§Ø Abbildung¬†5.7.\n\n3.11 Vertiefung\nBei Henze (2019) findet sich eine anspruchsvollere Einf√ºhrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes der Kapitel 2 und 3 von Henze (2019).\nMit dieser App, die ein zweistufiges Baumdiagramm zeigt, k√∂nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\nDiese App l√§sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\nMittag & Sch√ºller (2020) stellen in Kap. 11 die Grundlagen der Wahrscheinlichkeitstheorie vor. √Ñhnliche Darstellungen finden sich in einer gro√üen Zahl an Lehrb√ºchern.\n\n3.12 Aufgaben\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. Sie k√∂nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\n3.12.1 Paper-Pencil-Aufgaben\n\nAdditionssatz1\nNerd-gelockert\nUrne1\nUrne2\nk-coins-k-hits\nsicherheit\nsicherheit2\nKlausuren-bestehen\nGem-Wskt1\nGem-Wskt2\nGem-Wskt3\nGem-Wskt4\nwuerfel05\nwuerfel06\nBed-Wskt1\nBed-Wskt2\nBed-Wskt3\nvoll-normal\ncorona-blutgruppe\ntotale-Wskt1\nwskt-quiz14\nwskt-quiz09\n\n3.12.2 Aufgaben, f√ºr die man einen Computer braucht\n\nmtcars-abhaengig\nmtcars-abhaengig-var2\nmtcars-abhaengig_var3a\nwskt-df-r\n\n3.13 ‚Äî\n\n\n\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende Statistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√úbungen: Beschreibende Statistik ‚Äì Wahrscheinlichkeitsrechnung ‚Äì Schlie√üende Statistik (7. Auflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of Modeling, Probability & Statistics. Springer.\n\n\nHenze, N. (2019). Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der Ma√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability Theory: The Logic of Science. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#multiplikationssatz",
    "href": "0300-Wskt.html#multiplikationssatz",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.9 Multiplikationssatz",
    "text": "3.9 Multiplikationssatz\nGegeben seien die Ereignisse \\(A\\) und \\(B\\). Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass beide Ereignisse \\(A\\) und \\(B\\) eintreten; s. Abbildung¬†3.21 (d) verdeutlicht dies f√ºr zwei unabh√§ngige Ereignisse. Man schreibt ‚ÄúA und B‚Äù als \\(A \\cap B\\) (lies ‚ÄúA geschnitten B‚Äù oder ‚ÄúA und B‚Äù) oder kurz \\(AB\\), um anzuzeigen, dass sowohl \\(A\\) als auch \\(B\\) eingetreten sind.\n\n\n\n\nBeide Ereignisse A und B sind eingetreten\n\n\n\n\nBeispiel 3.30 (Wieder kalt und Regen) Es ist eine Sache, zu fragen, wie wahrscheinlich ist ist, dass es kalt ist (bei K√§lte), wenn es regnet (bei Regen): \\(Pr(K|R)\\). Anders gesagt: ‚ÄúWie gro√ü ist die Wahrscheinlichkeit f√ºr K√§lte, gegeben dass es regnet?‚Äù Eine andere Sache ist es, nach der Wahrscheinlichkeit zu fragen, dass es gleichzeitig kalt ist und regnet, dass also beide Ereignisse (kalt und Regen) eintreten: \\(Pr(K \\cap R), PR(KR)\\). \\(\\square\\)\n\n\n3.9.1 Gemeinsame Wahrscheinlichkeit unabh√§ngiger Ereignisse\n\nBeispiel 3.31 Wir f√ºhren das Zufallsexperiment ‚ÄúWurf einer fairen M√ºnze‚Äù zwei Mal aus (Abbildung¬†3.24). Wie gro√ü ist die Wahrscheinlichkeit, 2 Mal Kopf zu werfen? Dabei vereinbaren wir, dass ‚ÄúKopf‚Äù als ‚ÄúTreffer‚Äù z√§hlt (und ‚ÄúZahl‚Äù als ‚ÄúNiete‚Äù).\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.24: Wir werfen zwei faire M√ºnzen: Zweifach wiederholtes Zufallexperiment\n\n\nAbbildung¬†3.24 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis des Zufallexperiments. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom ‚ÄúStart‚Äù (schwarzer Kreis) f√ºhren zwei m√∂gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch Bl√§tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen M√ºnzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der Bl√§tter. In diesen Diagramm gibt es vier Pfade (und Bl√§tter).\nDen Wurf der ersten M√ºnze nennen wir in gewohnter Manier \\(A\\); den Wurf der zweiten M√ºnze \\(B\\).\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in Tabelle¬†3.6.\n\n\n\nTabelle¬†3.6: Wahrscheinlichkeiten der Ereignisse im zweimaligen M√ºnzwurf\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\n\n\nSei \\(K_1\\) das Ereignis, mit der 1. M√ºnze Kopf zu werfen; sei \\(K_2\\) das Ereignis, mit der 2. M√ºnze Kopf zu werfen-\nWir suchen \\(Pr(K_1 \\cap K_2)\\). Aufgrund der stochastischen Unabh√§ngigkeit der beiden Ereignisse gilt: \\(Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)\\).\n\nCodePr_K1K2 &lt;- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n\n\n\nDefinition 3.18 (Multiplikationssatz f√ºr unabh√§ngige Ereignisse) Die Wahrscheinlichkeit, dass zwei (oder mehr) unabh√§ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. Theorem¬†3.11. \\(\\square\\)\n\n\nTheorem 3.11 (Multiplikationssatz f√ºr unabh√§ngige Ereignisse) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B)\\]\nMan beachte, dass es egal ist, ob \\(A\\) gemeinsam mit \\(B\\) oder \\(B\\) gemeinsam mit \\(A\\) eintreten: \\(Pr(A \\cap B) = Pr(B \\cap A)\\).31 \\(\\square\\)\n\nMit dieser App k√∂nnen Sie das Baumdiagramm f√ºr den zweifachen M√ºnzwurf n√§her erkunden.\nWir f√ºhren das Zufallsexperiment ‚ÄúWurf einer fairen M√ºnze‚Äù drei Mal aus (Abbildung¬†3.25). Dabei vereinbaren wir wieder, dass ‚ÄúKopf‚Äù (K) als ‚ÄúTreffer‚Äù gilt und ‚ÄúZahl‚Äù (Z) als ‚ÄúNiete‚Äù.\n\n\n\n\n\nAbbildung¬†3.25: Wir werfen drei faire M√ºnzen: Dreifach wiederholtes Zufallexperiment\n\n\nBeim Wurf von ‚Äúfairen‚Äù M√ºnzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere Einsch√§tzung des Ergebnis des 2. Wurfes nicht ver√§ndert etc. Anders gesagt: Wir gehen von (stochastischer) Unabh√§ngigkeit aus.\nF√ºr z.B. das Ereignis \\(A=\\{ZZZ\\}\\) gilt: \\(Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3\\). Da jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jeweils gleich.\nAllgemeiner gilt: F√ºr ein Zufallsexpriment, das aus \\(k\\) Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit \\(Pr(X)=p\\) ist, so ist die Wahrscheinlichkeit f√ºr einen Endkonten \\(Pr(X^k)=p^k\\).\n\n\n\nTabelle¬†3.7: Ausgew√§hlte Wahrscheinlichkeiten von Ereignissen im dreifachen M√ºnzwurf\n\n\n\n  \n\n\n\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. Tabelle¬†3.7.\nAbbildung¬†3.21 versinnbildlicht nicht nur die Bedingtheit zweier Ereignisse, sondern auch die (Un-)Abh√§ngigkeit zweier Ereignisse, \\(A\\) und \\(B\\). In diesem Fall ist die Wahrscheinlichkeit von \\(A\\) gleich \\(B\\): \\(Pr(A)=Pr(B)=.5\\). Man sieht, dass die Wahrscheinlichkeit von \\(A\\) bzw. von \\(B\\) jeweils die H√§lfte der Fl√§che (der Gesamtfl√§che, d.h von \\(Pr(\\Omega)=1\\)) ausmacht. Die Schnittmenge der Fl√§che von \\(A\\) und \\(B\\) entspricht einem Viertel der Fl√§che: \\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.\\) In diesem Fall sind \\(A\\) und \\(B\\) unabh√§ngig. Abbildung¬†3.21 zeigt weiterhin, dass gilt: \\(P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\). Man beachte dass diese Formel nur bei Unabh√§ngigkeit (von A und B) gilt.\n\n3.9.2 Gemeinsame Wahrscheinlichkeit abh√§ngiger Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung abh√§ngiger Ereignisse an, s. Abbildung¬†3.26. F√ºr unabh√§ngige Ereignisse √ºbrigens auch.\n\nBeispiel 3.32 In einer Urne befinden sich f√ºnf Kugeln, von denen vier rot sind und eine blau ist.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nWie gro√ü ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zur√ºcklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier, 2011), S. 47. Ereignis A: ‚ÄúKugel im 1. Zug hat die Farbe Rot‚Äù. Ereignis B: ‚ÄúKugel im 2. Zug hat die Farbe Rot‚Äù.\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. Abbildung¬†3.26.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|4/5|B[Zug 1 - R]\n  A --&gt;|1/5|C[Zug 1 - B]\n  B --&gt;|3/4|D[Zug 2 - R]\n  B --&gt;|1/4|E[Zug 2 -  B]\n  D --- H[Fazit: RR - 4/5*3/4 = 12/20]\n  E --- I[Fazit: RB - 4/5*1/4 = 4/20]\n  C --&gt;|4/4|F[Zug 2 - R]\n  C --&gt;|0/4|G[Zug 2 - B]\n  F --- J[Fazit: BR - 1/5*4/4 = 4/20]\n  G --- K[Fazit: BB - 1/5*0/4 = 0/20]\n  \n\n\n\n\nAbbildung¬†3.26: Baumdiagramm f√ºr ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abh√§ngig ist vom 1. Zug.\n\n\n\n\nWie man in Abbildung¬†3.26 nachrechnen kann gilt also: \\(P(A\\cap B) = P(A) \\cdot P(B|A) \\square\\).\n\n\nDefinition 3.19 (Gemeinsame Wahrscheinlichkeit) Die Wahrscheinlichkeit, dass zwei abh√§ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt der Wahrscheinlichkeit von \\(A\\) und der bedingten Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\), s. Theorem¬†3.12. \\(\\square\\)\n\n\nTheorem 3.12 (Gemeinsame Wahrscheinlichkeit) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B|A) \\quad \\square\\]\n\n\nBeispiel 3.33 (Kalt und Regen) Von McElreath (2020) stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit. Was ist die Wahrscheinlichkeit f√ºr das gemeinsame Auftreten von kalt ‚ùÑ und Regen ‚õàÔ∏è? Die Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von Regen ‚õà, wenn‚Äôs kalt ‚ùÑ ist mal die Wahrscheinlichkeit von K√§lte ‚ùÑ.\nEbenfalls gilt: Die Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von K√§lte ‚ùÑ, wenn‚Äôs regnet ‚õàÔ∏è mal die Wahrscheinlichkeit von Regen ‚õàÔ∏è.\nDas Gesagte als Emoji-Gleichung ist in Gleichung¬†3.1 dargestellt.\n\\[P(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è |‚ùÑÔ∏è ) \\cdot P(‚ùÑÔ∏è) =  P(‚ùÑÔ∏è |‚õàÔ∏è ) \\cdot P(‚õàÔ∏è) \\tag{3.1}\\]\nMan kann die ‚ÄúGleichung drehen‚Äù32, s. Gleichung¬†3.2.\n\\[P(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è \\text{ und } ‚ùÑÔ∏è) \\tag{3.2}\\] \\(\\square\\)\n\n\nBeispiel 3.34 (Bertie Botts Bohnen jeder Geschmacksrichtung) ¬†\n\nSei blo√ü vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gew√∂hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.‚Äú\n\n‚Äî Ron Weasley zu Harry Potter33\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=2\\) furchtbar scheu√üliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erkl√§rt, \\(k=2\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt hei√üt es tapfer sein. Ziehen und runter damit!\nWie gro√ü ist die Wahrscheinlichkeit, genau eine scheu√üliche Bohne zu erwischen?\nEs gibt 2 Pfade f√ºr 1 Treffer bei 2 Wiederholungen (Z√ºge aus dem Beutel):\n\nCodePfad1 &lt;- 3/20 * 17/19  # scheu√üliche Bohne im 1. Zug\nPfad2 &lt;- 17/20 * 3/19  # scheu√üliche Bohne im 2. Zug\n\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 \nGesamt_Pr\n## [1] 0.2684211\n\n\nNutzen Sie diese App, um das auszuprobieren. Sie m√ºssen in der App noch die Zahl der Bohnen (\\(n\\)) und die Zahl der scheu√ülichen Bohnen (\\(x\\)) einstellen.\\(\\square\\)\n\n\nDefinition 3.20 (Kettenregel) Allgemein gesagt, spricht man von der Kettenregel der Wahrscheinlichkeitsrechnung, wenn man die gemeinsame Wahrscheinlichkeit auf die bedingte zur√ºckf√ºhrt, s. Theorem¬†3.13. \\(\\square\\)\n\n\nTheorem 3.13 (Kettenregel) \\[P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B) \\square\\]\nIn Worten: Die Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) ist gleich der Wahrscheinlichkeit von \\(A\\) mal der Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\).\n\n\n√úbungsaufgabe 3.4 (Baumdiagramm sucht Problem) √úberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit dieser Baumdiagramm-App gel√∂st werden kann.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#totale-wahrscheinlichkeit",
    "href": "0300-Wskt.html#totale-wahrscheinlichkeit",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.10 Totale Wahrscheinlichkeit",
    "text": "3.10 Totale Wahrscheinlichkeit\n\nBeispiel 3.35 (Gesamter Ausschussanteil) Die folgende Aufgabe bezieht sich auf Bourier (2011), S. 56. Drei Maschinen (\\(M_1, M_2, M_3\\)) produzieren einen Artikel. Die Maschinen haben einen Anteil an der Produktion von 60, 10 bzw. 30% und eine Ausschussquote von 5,2 bzw. 4%. Sei \\(M\\) das Ereignis, dass ein Artikel von Maschine \\(M\\) stammt, und \\(S\\) (Schrott) das Ereignis, dass ein Artikel Ausschuss (Schrott) ist. Wie gro√ü ist der Ausschussanteil insgesamt (√ºber alle drei Maschinen?) Anders gesagt: Wie hoch ist die Wahrscheinlichkeit, dass ein zuf√§llig gezogener Artikel Ausschuss ist. Abbildung¬†3.27 zeigt das Baumdiagramm f√ºr die Aufgabe. \\(\\square\\)\n\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[M1]\n  A --&gt;|0.1|C[M2]\n  A --&gt;|0.3|D[M3]\n  B --&gt;|0.05|E[S]\n  B -.-&gt;|0.95|F[Nicht-S]\n  C --&gt;|0.02|G[S]\n  C -.-&gt;|0.98|H[Nicht-S]\n  D --&gt;|0.04|I[S]\n  D -.-&gt;|0.96|J[Nicht-S]\n\n\n\n\nAbbildung¬†3.27: Totale Wahrscheinlichkeit\n\n\n\n\nGesucht ist also die Wahrscheinlichkeit \\(P(B)\\); \\(A\\) ist ein vollst√§ndiges Ereignissystem.\nDazu addieren wir die Wahrscheinlichkeiten der relevanten √Ñste. Jeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse \\(A_i\\) und \\(B\\) dar.\n\nCodeW_Ast1 &lt;- 0.6 * 0.05  # Wahrscheinlichkeit f√ºr Ast 1\nW_Ast2 &lt;- 0.1 * 0.02  # ... Ast 2\nW_Ast3 &lt;- 0.3 * 0.04  # ... Ast 3\nW_total &lt;- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n\n\nDie totale Wahrscheinlichkeit (f√ºr Ausschuss) betr√§gt in diesem Beispiel also \\(P(B) = 4.4\\%\\).34\n\nDefinition 3.21 (Totale Wahrscheinlichkeit) Bilden die Ereignisse \\(A_1, A_2, ..., A_n\\) ein vollst√§ndiges Ereignissystem und ist \\(B\\) ein beliebiges Ereignis dann gilt Theorem¬†3.14. \\(\\square\\)\n\n\nTheorem 3.14 (Totale Wahrscheinlichkeit) \\[Pr(B) = \\sum_{i=1}^n Pr(A_i) \\cdot Pr(B|A_i).\\square\\]\n\nMan kann die totale Wahrscheinlichkeit auffassen als die Summe der gewichteten Teil-Wahrscheinlichkeiten.\n\nIn Abbildung¬†3.27 (Beispiel¬†3.35) gilt \\(Pr(B) = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot  0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square\\)\n\n\n√úbungsaufgabe 3.5 (Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2) Es ist die gleich Aufgabe wie Beispiel¬†3.34, aber jetzt lautet die Frage: Wie gro√ü ist die Wahrscheinlichkeit, mindestens eine scheu√üliche Bohne bei 3 Z√ºgen zu erwischen?35 \\(\\square\\)\n\n\n3.10.1 Baumsammlung\nBaumdiagramme sind ein hilfreiches Werkzeug f√ºr wiederholte Zufallsexperimente. Daher ist hier eine ‚ÄúBaumsammlung‚Äù36 zusammengestellt.\n\nSie werfen 1 M√ºnze, Abbildung¬†3.2.\nSie werfen 2 M√ºnzen, Abbildung¬†3.24.\nSie werfen 3 M√ºnzen, Abbildung¬†3.25.\nSie werfen 4 M√ºnzen, Abbildung¬†4.1.\nSie werfen 9 M√ºnzen, ü§Ø Abbildung¬†5.7.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#vertiefung-1",
    "href": "0300-Wskt.html#vertiefung-1",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.11 Vertiefung",
    "text": "3.11 Vertiefung\nBei Henze (2019) findet sich eine anspruchsvollere Einf√ºhrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes der Kapitel 2 und 3 von Henze (2019).\nMit dieser App, die ein zweistufiges Baumdiagramm zeigt, k√∂nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\nDiese App l√§sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\nMittag & Sch√ºller (2020) stellen in Kap. 11 die Grundlagen der Wahrscheinlichkeitstheorie vor. √Ñhnliche Darstellungen finden sich in einer gro√üen Zahl an Lehrb√ºchern.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#aufgaben",
    "href": "0300-Wskt.html#aufgaben",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.12 Aufgaben",
    "text": "3.12 Aufgaben\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. Sie k√∂nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\n3.12.1 Paper-Pencil-Aufgaben\n\nAdditionssatz1\nNerd-gelockert\nUrne1\nUrne2\nk-coins-k-hits\nsicherheit\nsicherheit2\nKlausuren-bestehen\nGem-Wskt1\nGem-Wskt2\nGem-Wskt3\nGem-Wskt4\nwuerfel05\nwuerfel06\nBed-Wskt1\nBed-Wskt2\nBed-Wskt3\nvoll-normal\ncorona-blutgruppe\ntotale-Wskt1\nwskt-quiz14\nwskt-quiz09\n\n3.12.2 Aufgaben, f√ºr die man einen Computer braucht\n\nmtcars-abhaengig\nmtcars-abhaengig-var2\nmtcars-abhaengig_var3a\nwskt-df-r",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#section",
    "href": "0300-Wskt.html#section",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "\n3.13 ‚Äî",
    "text": "3.13 ‚Äî",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#footnotes",
    "href": "0300-Wskt.html#footnotes",
    "title": "\n3¬† Wahrscheinlichkeit\n",
    "section": "",
    "text": "Die Wahrscheinlichkeitstheorie bildet zusammen mit der Statistik das Fachgebiet der Stochastik.‚Ü©Ô∏é\n\\(10^6 = 1000000\\)‚Ü©Ô∏é\nBeispiele f√ºr Zufallsexperimente sind das Werfen einer M√ºnze, das Ziehen einer Karte aus einem Kartenspiel, das Messen eines Umweltph√§nomens wie der Temperatur oder die Anzahl der Kunden, die einen Laden betreten. In jedem dieser F√§lle sind die m√∂glichen Ergebnisse nicht im Voraus bekannt und h√§ngen von nicht komplett bekannten Faktoren ab.‚Ü©Ô∏é\nleider gibt es eine F√ºlle synonymer Namen: Ereignisraum, Elementarereignisraum, Ergebnisraum oder Grundraum‚Ü©Ô∏é\n\\(A\\) ist eine Teilmenge von \\(B\\), wenn alle Elemente von \\(A\\) auch Teil von \\(B\\) sind.‚Ü©Ô∏é\nSchon wieder.‚Ü©Ô∏é\n?‚Ü©Ô∏é\nEin Ergebnis ist ein Element von \\(\\Omega\\). Elementarereignisse sind die einelementigen Teilmengen von \\(\\Omega\\). Konzeptionell sind die beiden Begriffe sehr √§hnlich, vgl. https://de.wikipedia.org/wiki/Ergebnis_(Stochastik). Wir werden uns hier auf den Begriff Elementarereignis konzentrieren und den Begriff Ergebnis nicht weiter verwenden.‚Ü©Ô∏é\nNa toll.‚Ü©Ô∏é\nDie Menge aller Teilmengen einer Menge \\(A\\) nennt man die Potenzmenge \\(\\mathcal{P}(A)\\), vgl. hier.‚Ü©Ô∏é\nManchmal wird diese Art der Wahrscheinlichkeit auch epistemologische Wahrscheinlichkeit genannt.‚Ü©Ô∏é\ndie sog. ‚ÄúPraxis‚Äù‚Ü©Ô∏é\nEin Herr Kolmogorov hat das mal aufgeschrieben.‚Ü©Ô∏é\nhttps://www.geogebra.org/m/QZvCMSDs‚Ü©Ô∏é\nSynonym und k√ºrzer: \\(AB\\) anstelle von \\(A \\cap B\\).‚Ü©Ô∏é\nsynonym: Komplement‚Ü©Ô∏é\nmanchmal auch \\(A^C\\); C wie complementary event‚Ü©Ô∏é\ndas ‚ÄúKomplement‚Äù, nicht zu verwechseln mit ‚ÄúKompliment‚Äù‚Ü©Ô∏é\nengl. disjoint‚Ü©Ô∏é\nDie Wahrscheinlichkeit, keine 6 zu w√ºrfeln, liegt bei \\(2/3\\).‚Ü©Ô∏é\nvermutlich gibt es noch mehr Annahmen, die wir uns explizit machen sollten.‚Ü©Ô∏é\nsofern sie nicht disjunkt sind, aber wenn sie disjunkt sind, so ist der Schnitt gleich Null und wir machen auch dann nichts falsch.‚Ü©Ô∏é\ngenauer besehen sieht sie eher aus wie eine Gr√ºtze oder ein Brei‚Ü©Ô∏é\nSie schmeckt scheu√ülich.‚Ü©Ô∏é\n\\(Pr(L).85; Pr(\\neg L) = .15; Pr(B) =.81; Pr(\\neg B) = .19\\)‚Ü©Ô∏é\nExakte Gleichheit ist in dieser Welt empirisch schwer zu finden. Daher kann man vereinbaren, dass Unabh√§ngigkeit erf√ºllt ist, wenn die Gleichheit ‚Äúeinigerma√üen‚Äù oder ‚Äúziemlich‚Äù gilt, die Gleichheit gewisserma√üen ‚Äúpraktisch bedeutsam‚Äù ist.‚Ü©Ô∏é\nVgl. Theorem¬†3.11‚Ü©Ô∏é\nWer Daten dazu hat oder eine Theorie, der melde sich bitte bei mir.‚Ü©Ô∏é\nhier mit den zwei Auspr√§gungen DEU und USA‚Ü©Ô∏é\n Daten von Our World in Data, https://ourworldindata.org/covid-deaths.‚Ü©Ô∏é\nMan spricht auch von Symmetrie der Multiplikation.‚Ü©Ô∏é\nDer Multiplikationssatz ist symmetrisch‚Ü©Ô∏é\nQuelle: https://harrypotter.fandom.com/de/wiki/Bertie_Botts_Bohnen_jeder_Geschmacksrichtung‚Ü©Ô∏é\nEinfacher als das Rechnen mit Wahrscheinlichkeiten ist es in solchen F√§llen, wenn man anstelle von Wahrscheinlichkeiten absolute H√§ufigkeiten zum Rechnen verwendet.‚Ü©Ô∏é\nDie Wahrscheinlichkeit keine scheu√üliche Bohne zu ziehen ist \\(17/20 \\cdot 16/19 \\cdot 15/18) \\approx 0.5964912\\). Daher ist die gesuchte Wahrscheinlichkeit (mindestens eine scheu√üliche Bohne) das Komplement davon: \\(0.4\\).‚Ü©Ô∏é\nWald?‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html",
    "href": "0400-Verteilungen.html",
    "title": "\n4¬† Verteilungen\n",
    "section": "",
    "text": "4.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#lernsteuerung",
    "href": "0400-Verteilungen.html#lernsteuerung",
    "title": "\n4¬† Verteilungen\n",
    "section": "",
    "text": "4.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n4.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nden Begriff der Zufallsvariablen erl√§utern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erl√§utern\nden Begriff einer Gleichverteilung erl√§utern\nden Begriff einer Binomialverteilung erl√§utern\ndie Parameter einer Normalverteilung nennen und erl√§utern\nzentrale Konzepte in R umsetzen\n\n4.1.3 Begleitliteratur\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 6.1 und 6.3 sowie 7.1 und und 7.2.\n\n4.1.4 Vorbereitung im Eigenstudium\nDieses Kapitel setzt einige Grundbegriffe voraus, wie im Buch Statistik1 vorgestellt, insbesondere im Kapitel ‚ÄúRahmen‚Äù. Ben√∂tigt wird auch der Begriff der Normalverteilung sowie der Begriff der Quantile.\nLesen Sie selbst√§ndig, zus√§tzlich zum Stoff dieses Kapitels, noch in Bourier (2011) folgende Abschnitte:\n\nKap. 6.1 (Zum Begriff Zufallsvariable)\nKap. 6.3 (Stetige Zufallsvariablen)\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung)\nKap. 7.2.3 (Normalverteilung)\n\nL√∂sen Sie auch die √úbungsaufgaben dazu.\nWeitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, Bourier (2022).\n\n4.1.5 Pr√ºfungsrelevanter Stoff\nBeachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff pr√ºfungsrelevant ist.\n\n4.1.6 Ben√∂tigte R-Pakete\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)  # f√ºr Plots\n\n\n\n4.1.7 Zentrale Begriffe\n\n4.1.7.1 Eigenschaften von Zufallsvariablen\n\nZufallsvariable (random variable)\nDiskret vs.¬†stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n4.1.7.2 Verteilungen\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n4.1.8 Begleitvideos\n\n√úberblick zu Verteilungen\nGleichverteilung\nBinomialverteilung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#zufallsvariable",
    "href": "0400-Verteilungen.html#zufallsvariable",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.2 Zufallsvariable",
    "text": "4.2 Zufallsvariable\n\nBeispiel 4.1 Schorsch sucht eine Betreuerin f√ºr seine Abschlussarbeit. An die ideale Betreuerin setzt er 4 Kriterien an: a) klare, schriftliche fixierte Rahmenbedingungen, b) viel Erfahrung, c) guten Ruf und d) interessante Forschungsinteressen. Je mehr dieser 4 Kriterien erf√ºllt sind, desto besser. Schorsch geht davon aus, dass die 4 Kriterien voneinander unabh√§ngig sind (ob eines erf√ºllt ist oder nicht, √§ndert nichts an der Wahrscheinlichkeit eines anderen Kriteriums). Schorsch interessiert sich also f√ºr die Anzahl der erf√ºllten Kriterien, also eine Zahl von 0 bis 4. Er sch√§tzt die Wahrscheinlichkeit f√ºr einen ‚ÄúTreffer‚Äù in jedem seiner 4 Kriterien auf 50%. Viel Gl√ºck, Schorsch! Sein Zufallsexperiment hat 16 Ausg√§nge (Knoten 16 bis 31), s. Abbildung¬†4.1 und Tabelle¬†4.1. Ganz sch√∂n komplex. Eigentlich w√ºrden ihm ja eine Darstellung mit 5 Ergebnissen, also der ‚ÄúGutachter-Score‚Äù von 0 bis 4 ja reichen. Wie k√∂nnen wir es √ºbersichtlicher f√ºr Schorsch?\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung¬†4.1: Ein Baumdiagramm mit 16 Ausg√§ngen, analog zur 4 M√ºnzw√ºrfen. Jede M√ºnze ist in einer anderen Farbe dargestellt. Der Knoten ‚Äò1‚Äô ist der Start, da ist noch keine M√ºnze geworfen.\n\n\n\n\n\n\n\nTabelle¬†4.1: Schorschs Zufallsexperiment, Auszug der Elementarereignisse\n\n\n\n\ni\nElementarereignis\nPr(EE)\nTrefferzahl\nPr(Trefferzahl)\n\n\n\n1\nNNNN\n1/16\n0\n1/16\n\n\n2\nNNNT\n1/16\n1\n1/4\n\n\n3\nNNTN\n1/16\n1\n1/4\n\n\n4\nNTNN\n1/16\n1\n1/4\n\n\n5\nTNNN\n1/16\n1\n1/4\n\n\n6\nNNTT\n1/16\n2\n‚Ä¶\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\n\n\n\n\n\nSchorsch braucht also eine √ºbersichtlichere Darstellung; die Zahl der Treffer und ihre Wahrscheinlichkeit w√ºrde ihm ganz reichen. In vielen Situationen ist man an der Anzahl der Treffer interessiert. Die Wahrscheinlichkeit f√ºr eine bestimmte Trefferanzahl bekommt man einfach durch Addieren der Wahrscheinlichkeiten der zugeh√∂rigen Elementarereignisse, s. Tabelle¬†4.1. Hier kommt die Zufallsvariable ins Spiel. Wir nutzen sie, um die Anzahl der Treffer in einem Zufallsexperiment zu z√§hlen.\n\nDefinition 4.1 (Zufallsvariable) Die Zuordnung der Elementarereignisse eines Zufallsexperiments zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable.\\(\\square\\)\n\nDie den Elementarereignissen zugewiesenen Zahlen nennt man Realisationen oder Auspr√§gungen der Zufallsvariablen.\n\nBeispiel 4.2 (Lotto) Ein Lottospiel hat ca. 14 Millionen Elementarereignisse. Die Zufallsvariable ‚ÄúAnzahl der Treffer‚Äù hat nur 7 Realisationen: 0,1,‚Ä¶,6.\\(\\square\\)\n\nEs hat sich eingeb√ºrgert, Zufallszahlen mit \\(X\\) zu bezeichnen (oder anderen Buchstaben weit hinten aus dem Alphabet).\nMan schreibt f√ºr eine Zufallsvariable kurz: \\(X: \\Omega \\rightarrow \\mathbb{R}\\). ‚ÄúX ist eine Zufallsvariable, die jedem Elementarereignis \\(\\omega\\) eine reelle Zahl zuordnet.‚Äù Um die Vorschrift der Zuordnung genauer zu bestimmen, kann man folgende Kurzschreibweise nutzen:\n\\({\\displaystyle X(\\omega )={\\begin{cases}1,&{\\text{wenn }}\\omega ={\\text{Kopf}},\\\\[6pt]0,&{\\text{wenn }}\\omega ={\\text{Zahl}}.\\end{cases}}}\\)\nAbbildung¬†4.2 stellt diese Abbildung dar.\n\n\n\n\n\nflowchart LR\n  subgraph A[Ereignis]\n    Kopf\n    Zahl\n  end\n  subgraph B[Realisation]\n    null[0]\n    eins[1]\n  end\n  subgraph C[Wahrscheinlichkeit]\n    half[50%]\n  end\n  \n  Kopf --&gt; null\n  Zahl --&gt; eins\n  null --&gt; half\n  eins --&gt; half\n\n\n\n\nAbbildung¬†4.2: Eine Zufallsvariable ist eine Abbildung eines Ereignisses im Ereignisraum zu den Realisationen der Zufallsvariable. Au√üerdem sieht man, wie diskrete Wahrscheinlichkeitsfunktionen genutzt werden, um den numerischen Ausg√§ngen eines Zufallsexperiments eine Wahrscheinlichkeit zuzuordnen, d.h. um Wahrscheinlichkeiten zu bestimmen.\n\n\n\n\nZufallsverteilungen kann im zwei Artein einteilen:\n\ndiskrete Zufallsvariablen\nstetige Zufallsvariablen\n\n\n4.2.1 Diskrete Zufallsvariable\n\n4.2.1.1 Grundlagen\nEine diskrete Zufallsvariable ist dadurch gekennzeichnet, dass nur bestimmte Realisationen m√∂glich sind, zumeist nat√ºrliche Zahlen, wie 0, 1, 2,‚Ä¶, . Abbildung¬†4.3 versinnbildlicht die Zufallsvariable des ‚ÄúGutachter-Scores‚Äù, s. Beispiel¬†4.1.\n\n\n\n\n\n\n\nAbbildung¬†4.3: Sinnbild einer diskreten Zufallsvariablen X f√ºr Schorschs Suche nach einer Betreuerin seiner Abschlussarbeit. X gibt den Score der Gutachterin wider.\n\n\n\n\n\nBeispiel 4.3 (Diskrete Zufallsvariablen) ¬†\n\nAnzahl der Bewerbungen bis zum ersten Job-Interview\nAnzahl Anl√§ufe bis zum Bestehen der Statistik-Klausur\nAnzahl der Absolventen an der HS Ansbach pro Jahr\nAnzahl Treffer beim Kauf von Losen\nAnzahl Betriebsunf√§lle\nAnzahl der Produkte in der Produktpalette\\(\\square\\)\n\n\n\n\nBeispiel 4.4 Der zweifache W√ºrfelwurf ist ein typisches Lehrbuchbeispiel f√ºr eine diskrete Zufallsvariable. 1 Hier ist \\(S\\)2 die Augensumme des zweifachen W√ºrfelwurfs und \\(S\\) ist eine Zahl zwischen 2 und 12. F√ºr jede Realisation \\(X=x\\) kann man die Wahrscheinlichkeit berechnen, Abbildung¬†4.4 versinnbildlicht die Wahrscheinlichkeit f√ºr jede Realisation von \\(X\\).\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†4.4: Augensumme des zweifachen W√ºrfelwurfs; f√ºr jede Realisation von S ist die zugeh√∂rige Wahrscheinlichkeit dargestellt. Bildquelle: Tim Stellmach, Wikipedia, PD\n\n\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariablen eine Wahrscheinlichkeit zuzuordnen.\n\nDefinition 4.2 (Diskrete Wahrscheinlichkeitsverteilung) Eine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) Auspr√§gungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu.\\(\\square\\)\n\n\nBeispiel 4.5 (Wahrscheinlichkeit des Geschlechts bei der Geburt) So hat die Variable Geschlecht eines Babies die beiden Auspr√§gungen M√§dchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\), laut einer Studie (Gelman et al., 2021).\\(\\square\\)\n\nZwischen der deskriptiven Statistik und der Wahrscheinlichkeitstheorie bestehen enge Parallelen, Tabelle¬†4.2 stellt einige zentrale Konzepte gegen√ºber.\n\n\n\nTabelle¬†4.2: Gegen√ºberstellung von Wahrscheinlichkeitstheorie und deskriptiver Statistik\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDesktiptive.Statistik\n\n\n\nZufallsvariable\nMerkmal\n\n\nWahrscheinlichkeit\nrelative H√§ufigkeit, Anteil\n\n\nWahrscheinlichkeitsfunktion\neinfache relative H√§ufigkeitsverteilung\n\n\nVerteilungsfunktion\nkumulierte relative H√§ufigkeitsverteilung\n\n\nErwartungswert\nMittelwert\n\n\nVarianz\nVarianz\n\n\n\n\n\n\n\n\n\nEine Verteilung zeigt, welche Auspr√§gungen eine Variable aufweist und wie h√§ufig bzw. wahrscheinlich diese sind. Einfach gesprochen veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet H√§ufigkeitsverteilungen (s. Abb. Abbildung¬†4.6) von Wahrscheinlichkeitsverteilungen (Abb. Abbildung¬†4.5).\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.5: Wahrscheinlichkeitsverteilung der Zufallsvariable ‚ÄúAugenzahl im zweifachen W√ºrfelwurf‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.6: (relative und absolute) H√§ufigkeiten des zweifachen W√ºrfelwurfs, 1000 Mal wiederholt\n\n\n\n\n\n\n\nBeispiel 4.6 (Wahrscheinlichkeitsfunktion eines W√ºrfels) Abbildung¬†4.7 zeigt die Wahrscheinlichkeitsfunktion eines einfachen W√ºrfelwurfs.\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†4.7: Wahrscheinlichkeitsfunktion eines einfachen W√ºrfelwurfs, Bildrechte: Olex Alexandrov, Wikipedia, PD\n\n\n\n\nDie H√§ufigkeitsverteilung eines diskreten Merkmals \\(X\\) mit \\(k\\) Auspr√§gungen zeigt (vgl. Tabelle¬†4.3), wie h√§ufig die einzelnen Auspr√§gungen sind. So hat die Variable Zylinder (in einem Datensatz) etwa die Auspr√§gungen 4,6 und 8.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.8: H√§ufigkeitsverteilung von cyl und hp (diskretisiert in 10 K√∂rbe oder Gruppen)\n\n\n\n\n\n\n\n\nTabelle¬†4.3: Eine diskrete H√§ufigkeitsverteilung, dargestellt in einer H√§ufigkeitstabelle\n\n\n\n  \n\n\n\n\n\n\n\n\nAbb. Abbildung¬†4.8, links, visualisiert die H√§ufigkeitsverteilung von cyl. Ein stetiges Merkmal, wie hp (PS-Zahl), l√§sst sich durch Klassenbildung in ein diskretes umwandeln (diskretisieren), s. Abb. Abbildung¬†4.8, rechts.\n\n4.2.1.2 Wahrscheinlichkeitsfunktion\n\nDefinition 4.3 (Wahrscheinlichkeitsfunktion) Die Funktion \\(f\\), die den m√∂glichen Realisationen \\(x_i\\) der diskreten Zufallsvariablen \\(X\\) die Eintrittswahrscheinlichkeiten zuordnet, hei√üt Wahrscheinlichkeitsfunktion.\\(\\square\\)\n\n\nBeispiel 4.7 Die Wahrscheinlichkeitsfunktion f√ºr \\(X\\) ‚ÄúAugensumme im zweifachen W√ºrfelwurf‚Äù ist in Abbildung¬†4.5 visualisiert.\\(\\square\\)\n\n\nBeispiel 4.8 Die Wahrscheinlichkeitsfunktion f√ºr \\(X\\) ‚ÄúTreffer im einfachen M√ºnzwurf, mit Zahl ist Treffer‚Äù ist \\(Pr(X=1)=1/2.\\), vgl. Abbildung¬†4.2.\\(\\square\\)\n\nüí° Einfach gesprochen gibt die Wahrscheinlichkeitsfunktion die Wahrscheinlichkeit einer bestimmten Realisation einer Zufallsvariable an.\n\n4.2.1.3 Verteilungsfunktion\n\nDefinition 4.4 (Verteilungsfunktion) Die Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist.\\(\\square\\)\n\nDie Berechnung von \\(F(x)\\) erfolgt, indem die Wahrscheinlichkeiten aller m√∂glichen Realisationen \\(x_i\\), die kleiner oder gleich dem vorgegebenen Realisationswert \\(x\\) sind, addiert werden:\n\\(F(x) = \\sum_{x_ \\le x} Pr(X=x_i).\\)\nDie Verteilungsfunktion ist das Pendant zur kumulierten H√§ufigkeitsverteilung, vgl. Abbildung¬†4.9 und Abbildung¬†4.10: Was die kumulierte H√§ufigkeitsverteilung f√ºr H√§ufigkeiten ist, ist die Verteilungsfunktion f√ºr Wahrscheinlichkeiten.\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.9: Verteilungsfunktion \\(F(X \\le x_i)\\) f√ºr die Zufallsvariable ‚ÄúAugenzahl im zweifachen W√ºrfelwurf‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.10: Empirische Verteilungsfunktion (kumulierte H√§ufigkeitsverteilung) \\(F(X \\le x_i)\\) von 1000 zweifachen M√ºnzw√ºrfen\n\n\n\n\n\n\n\n4.2.2 Stetige Zufallsvariablen\nüì∫ Verteilungen metrischer Zufallsvariablen\nAbbildung¬†4.11 versinnbildlicht die stetige Zufallsvariable ‚ÄúK√∂rpergr√∂√üe‚Äù, die (theoretisch, in Ann√§herung) jeden beliebigen Wert zwischen 0 und (vielleicht) 2 Meter annehmen kann.\n\n\n\n\n\n\n\nAbbildung¬†4.11: Sinnbild f√ºr eine stetige Zufallsvariable X ‚ÄúK√∂rpergr√∂√üe‚Äù\n\n\n\n\n\nDefinition 4.5 (Stetige Zufallsvariable) Eine stetige Zufallsvariable gleicht einer diskreten, nur dass alle Werte im Intervall erlaubt sind.\\(\\square\\)\n\n\nBeispiel 4.9 ¬†\n\nSpritverbrauch\nK√∂rpergewicht von Professoren\nSchnabell√§ngen von Pinguinen\nGeschwindigkeit beim Geblitztwerden\\(\\square\\)\n\n\n\n\n√úbungsaufgabe 4.1 (Warten auf den Bus, 42 Sekunden) Sie stehen an der Bushaltestellen und warten auf den Bus. Langweilig. Da kommt Ihnen ein Gedanken in den Sinn: Wie hoch ist wohl die Wahrscheinlichkeit, dass Sie exakt 42 Sekunden auf den Bus warten m√ºssen, s. Abbildung¬†4.13? Weiterhin √ºberlegen Sie, dass davon auszugehen ist, dass jede Wartezeit zwischen 0 und 10 Minuten gleich wahrscheinlich ist. Sp√§testens nach 10 Minuten kommt der Bus, so ist die Taktung (extrem zuverl√§ssig). Exakt hei√üt exakt, also nicht 42.1s, nicht 42.01s, nicht 42.001s, etc. bis zur x-ten Dezimale.\\(\\square\\)\n\nNicht so einfach (?). Hingegen ist die Frage, wie hoch die Wahrscheinlichkeit ist, zwischen 0 und 5 Minuten auf den Bus zu warten (\\(0&lt;x&lt;5\\)), einfach: Sie betr√§gt 50%, wie man in Abbildung¬†4.12 gut sehen kann.\n\n\n\n\n\n\n\nAbbildung¬†4.12: Wie gro√ü ist die Wahrscheinlichkeit, zwischen 0 und 5 Minuten auf den Bus zu warten? 50 Prozent!\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.13: Wie gro√ü ist die Wahrscheinlichkeit, genau 42 Sekunden auf den Bus zu warten? Hm.\n\n\n\n\n\n\nVergleicht man Abbildung¬†4.13 und Abbildung¬†4.12 kommt man (vielleicht) zu dem Schluss, dass die Wahrscheinlichkeit exakt 42s auf den Bus zu warten, praktisch Null ist. Der Grund ist, dass die Fl√§che des Intervalls gegen Null geht, wenn das Intervall immer schm√§ler wird. Aus diesem Grund kann man bei stetigen Zufallszahlen nicht von einer Wahrscheinlichkeit eines bestimmten Punktes \\(X=x\\) sprechen. F√ºr einen bestimmten Punkt \\(X=x\\) kann man aber die Dichte der Wahrscheinlichkeit angeben.\nWas gleich ist in beiden Situationen (\\(Pr(X=.42)\\) und \\(Pr(0&lt;x&lt;0.5)\\)) ist die Wahrscheinlichkeitsdichte, \\(f\\). In Abbildung¬†4.13 und Abbildung¬†4.12 ist die Wahrscheinlichkeitsdichte gleich, \\(f=1/10=0.1\\).\n\nDefinition 4.6 (Wahrscheinlichkeitsdichte) Die Wahrscheinlichkeitsdichte \\(f(x)\\) gibt an, wie viel Wahrscheinlichkeitsmasse pro Einheit von \\(X\\) an an der Stelle \\(x\\) ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsdichte zeigt an, an welchen Stellen \\(x\\) die Wahrscheinlichkeit besonders ‚Äúgeballt‚Äù oder ‚Äúdicht‚Äù sind, s. Abbildung¬†4.14.\n\n\n\n\n\nAbbildung¬†4.14: Die Wahrscheinlichkeit, dass eine Zufallsvariable einen Wert zwischen und annimmt, entspricht dem Inhalt der Fl√§che unter dem Graph der Wahrscheinlichkeitsdichtefunktion. Bildrechte: 4C, Wikipedia, CC-BY-SA .\n\n\n\n\n\nDefinition 4.7 (Verteilungsfunktion) Die Verteilungsfunktion einer stetigen Zufallsvariablen gibt wie im diskreten Fall an, wie gro√ü die Wahrscheinlichkeit f√ºr eine Realisation kleiner oder gleich einem vorgegebenen Realisationswert \\(x\\) ist.\\(\\square\\)\nDie Verteilungsfunktion \\(F(x)\\) ist analog zur kumulierten H√§ufigkeitsverteilung zu verstehen, vgl. Abbildung¬†4.15. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.15: Verteilungsfunktion F f√ºr X=‚ÄúWartezeit auf den Bus‚Äù\n\n\n\n\n\n\n\nDefinition 4.8 (Stetige Wahrscheinlichkeitsverteilung) Bei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen Auspr√§gungen aus; die Wahrscheinlichkeit einer bestimmten Auspr√§gung ist Null: \\(Pr(X=x_j)=0, \\quad j=1,...,+\\infty \\square\\).\n\n\nBeispiel 4.10 (Wahrscheinlichkeitsverteilung f√ºr die K√∂rpergr√∂√üe) So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666‚Ä¶ cm gro√ü ist, (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\).\\(\\square\\)\n\nF√ºr praktische Fragen berechnet man zumeist die Wahrscheinlichkeit von Intervallen, s. Abbildung¬†4.14.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#wichtige-verteilungen",
    "href": "0400-Verteilungen.html#wichtige-verteilungen",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.3 Wichtige Verteilungen",
    "text": "4.3 Wichtige Verteilungen\nIm Folgenden sind einige wichtige Verteilungen aufgef√ºhrt, die in diesem Skript (und in der Statistik und Wahrscheinlichkeitstheorie) eine zentrale Rolle spielen.\nüì∫ Einstieg in Verteilungen",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#gleichverteilung",
    "href": "0400-Verteilungen.html#gleichverteilung",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.4 Gleichverteilung",
    "text": "4.4 Gleichverteilung\n\n4.4.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jeder Wert im Ergebnisraum der zugeh√∂rigen Zufallsvariable gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine Realisation einer Zufallsvariablen f√ºr plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. Abbildung¬†4.16 zeigt ein Beispiel f√ºr eine (stetige) Gleichverteilung.\n\n\n\n\n\n\n\n\n\n(a) Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2\n\n\n\n\n\n\n\n\n\n(b) Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3\n\n\n\n\n\n\nAbbildung¬†4.16: Stetige Gleichverteilung; man beachte jeweils die Y-Achse\n\n\nAbbildung¬†4.16, links: Bei \\(X=0\\) hat eine Einheit von \\(X\\) (d.h. von -0.5 bis +0.5) die Wahrscheinlichkeitsmasse von 50%, da der Bereich \\([-0.5, +0.5]\\) die H√§lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte gleich. Abbildung¬†4.16, rechts: Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von ca. 33%, da der Bereich \\([-0.5, +0.5]\\) ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte gleich. Definierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.\n\n4.4.2 Simulation\nM√∂chte man die Verteilungsfunktion einer stetigen Zufallsvariablen berechnen, kann die Mathe ganz sch√∂n kompliziert werden, schlie√ülich muss man Integrale l√∂sen. Aber es gibt einen Trick, wie man die Sache stark vereinfachen kann: man simuliert die Verteilung. Was bedeutet das?\nAngenommen, die Wartezeit auf einen Bus ist gleichverteilt (engl. uniform distribution); der Bus kommt regelm√§√üig und p√ºnktlich alle 10 Minuten. Die minimale Wartezeit betr√§gt also 0 Minuten und die maximale 10 Minuten. Nennen wir die zugeh√∂rige Zufallsvariable \\(X\\), das ist sch√∂n kurz zu schreiben.\nEine gleichverteilte Zufallsvariable \\(X\\) mit Min \\(m_0\\) und Maximum \\(m_1\\) schreibt man auch wie folgt in Kurzschreibweise:\n\\[X \\sim Unif(m_0,m_1).\\]\nJa, das sieht fancy aus, ist aber daf√ºr sch√∂n kurz, aber wo ist der versprochene Trick zum Vereinfachen? Kommt gleich, Moment.\nEine Frage k√∂nnte nun lauten, wie gro√ü ist die Wahrscheinlichkeit, dass man zwischen 3 und 5 Minuten auf den Bus warten muss? Achtung: Hier ist der Trick. N√§mlich, dass wir Integralrechnung gegen stumpfes Z√§hlen eintauschen.\nComputer (und damit R) haben eingebaute Funktionen, die eine beliebige Zufallszahl ziehen k√∂nnen, zum Beispiel gleichverteilte. Auf Errisch hei√üt das Zauberwort runif(): Mit dieser Funktion kann man gleichverteilte Zufallszahlen ziehen. Einfach gesprochen: Der Computer greift in eine S√§ckchen mit Murmeln, die mit verschiedenen Zahlen beschriftet sind, wobei alle Zahlen gleich h√§ufig sind, und greift eine heraus.\n\nCodeset.seed(42)  # Zufallszahl festlegen, nur f√ºr Reproduzierbarkeit\n# \"r\" wie random, \"unif\" wie \"uniform\" (gleich):\nrunif(n = 1, min = 0, max = 10) \n\n\nAuf Deutsch hei√üt das:\n\nüë®‚Äçüè´ ‚ÄúHey R, ich h√§tte gerne eine (daher n = 1) Zufallszahl (r wie random), die gleichverteilt ist (uniform) mit min = 0 und max = 10.\n\n\nü§ñ Jawohl, oh herrliches Leberwesen\n\n(Zu) anschaulich gesprochen: R hat den Bus kommen lassen und es hat gut 9.1 Minuten gedauert, bis er da war. Achtung, jetzt kommt‚Äôs: Jetzt lassen wir R mal \\(10^5\\) (1e5 auf Computersprech) Busse vorfahren. R soll jedes Mal notieren, wie lange man auf den Bus warten musste.3\n\nCodex_simu &lt;- runif(n = 1e5, min = 0, max = 10)\n\n\nSchauen wir uns die Verteilung an, s. Abbildung¬†4.17.4\n\nCodelibrary(ggpubr)\ngghistogram(x_simu_df, x = \"x_simu\", fill = \"grey20\")\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.17: Simulation einer gleichverteiluten Zufallsvariablen\n\n\n\n\nOkay, unsere Verteilung sieht nicht exakt gleichverteilt, aber einigerma√üen. Gut genug f√ºr unsere Zwecke!\nSo, und jetzt kommt das Ernten. Wir k√∂nnen jetzt n√§mlich einfach z√§hlen (count()), um die Antwort auf unsere Frage (der Wartezeit 3-5 Min.) zu erhalten, s. Tabelle¬†4.4.\n\n\n\nCodex_simu_df %&gt;% \n  count(Schnittmenge = x &gt; 3 & x &lt; 5)\n\n\n\n\n\n\nTabelle¬†4.4: H√§ufigkiten auslesen anstelle von Integralen berechnen\n\n\n\n  \n\n\n\n\n\n\n\n\nDas Zeichen & ist das logische UND, also die Schnittmenge der zwei Mengen \\(A\\) (\\(X\\) ist gr√∂√üer als 3) und \\(B\\) (\\(X\\) ist kleiner als 5), d.h. \\(A := \\{x|x&gt;3\\}\\) und \\(B := \\{x|x&lt;5\\}\\), also \\(A \\cap B\\).\nWie man sieht, fallen ca. 20% der Stichproben in den entsprechenden Bereich.\nDa viele Probleme, wenn sie komplexer werden, kaum noch ‚Äúanalytisch‚Äù (d.h. wie Ausrechnen von Integralen) l√∂sbar sind, greift man in der modernen (Analyse-)Welt oft lieber auf Simulationsverfahren zur√ºck - Dank sei den schnellen Rechnern. F√ºr uns Menschen ist damit die Aufgabe des Integrierens auf schn√∂des Z√§hlen zur√ºckgef√ºhrt.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#sec-bin-distrib",
    "href": "0400-Verteilungen.html#sec-bin-distrib",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.5 Binomialverteilung",
    "text": "4.5 Binomialverteilung\n\n4.5.1 Grundlagen\n\nDefinition 4.9 (Binomialverteilung) Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines \\(n\\)-fach wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei5 Ergebnissen bzw. Elementarereignissen also. Dabei interessiert die Anzahl der \\(k\\) Treffer (aber nicht die Reihenfolge). Typisches Beispiel ist ein (wiederholter) M√ºnzwurf.6 \\(\\square\\)\n\nF√ºr eine binomialverteilte Zufallsvariable \\(X\\) schreibt man kurz wie in Theorem¬†4.1 gezeigt.\n\nTheorem 4.1 (Notation f√ºr eine binomialverteilte Zufallsvariable) \\[X \\sim \\text{Bin}(n, k)\\squad \\square\\]\n\n\nBeispiel 4.11 Anwendungsbeispiele: Wie viele defekte Teile sind in einer Stichprobe von produzierten Schrauben zu erwarten? Wie wahrscheinlich ist es, dass das neue Blutdruck-Medikament einer bestimmten Anzahl von Menschen hilft? Wie viele Personen stimmen in einer Umfrage der Frage ‚ÄúIch halte die √∂ffentlich-rechtlichen Sender f√ºr wichtig.‚Äù zu? \\(\\square\\)\n\nStellen wir uns eine Kistchen7 mit sehr vielen8 Losen vor, darunter 2/5 Treffer (Gewinn) und 3/5 Nieten, s. Abb. Abbildung¬†4.18. Der Versuch l√§uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zur√ºck und ziehen erneut.9 Jetzt ziehen wir z.B. drei Lose. Wie gro√ü ist die Wahrscheinlichkeit, davon 2 Treffer zu erzielen (egal in welcher Reihenfolge)?\n\n\n\n\n\n\n\nAbbildung¬†4.18: Ein Losk√§stchen mit 2/5 Treffer und 3/5 Nieten\n\n\n\n\nPraktischerweise ist die Binomialverteilung in R eingebaut,\nhier ist Pseudocode f√ºr Ihre Anwendung, s. Listing¬†4.1.\n\n\n\nListing¬†4.1: R-Pseudocode f√ºr die Binomialverteilung\n\ndbinom(x = &lt;Anzahl der Treffer&gt;, \n       size = &lt;Anzahl der W√ºrfe&gt;, \n       prob = &lt;Wahrscheinlichkeit&gt;)\n\n\n\n\n\n4.5.2 M√∂glichkeiten z√§hlen\n\nBeispiel 4.12 (Drei Lose gekauft, davon zwei Treffer?) Wie gro√ü ist die Wahrscheinlichkeit bei \\(n=3\\) Z√ºgen \\(k=2\\) Treffer zu erzielen (und \\(n-k=1\\) Niete)? (Nennen wir dieses Ereignis der K√ºrze halber \\(A^{\\prime}\\).) Die Trefferwahrscheinlichkeit ist (bei jedem Zug) \\(p=2/5\\) und die Nietenwahrscheinlichkeit \\(1-p=3/5\\).\\(\\square\\)\n\n\n\nCodedf_binom &lt;-\n  tibble(\n    k = 0:3,\n    p = dbinom(0:3, size = 3, prob = 2/5))\n\n\n\nMit Blick auf Beispiel¬†4.12: Wir k√∂nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz, Theorem¬†3.11), vgl. Abbildung¬†4.20. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit (Additionssatz, Theorem¬†3.3). Diagramme zeichnen ist einfach, dauert aber.\nBeachtet man die verschiedenen Reihenfolgen nicht (in Abbildung¬†4.20), so z√§hlt man 3 g√ºnstige Pfade (vgl. Abbildung¬†4.19):\n\nTTN\nTNT\nNTT.\n\n\n\n\n\n\n\n\nAbbildung¬†4.19: Wie viele M√∂glichkeiten gibt es, 3 Lose zu sortieren, von denen 2 Treffer sind und 1 Niete?\n\n\n\n\nWir haben also die M√∂glichkeiten (2 Treffer und 1 Niete zu erhalten)\n\n\nohne Beachtung der Reihenfolge und\n\nohne Zur√ºcklegen (der M√∂glichkeiten)\n\ngez√§hlt.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;B[Zug 1 - T]\n  A --&gt;C[Zug 1 - T]\n  A --&gt;D[Zug 1 - N]\n  B --&gt;E[Zug 2 - T]\n  B --&gt;F[Zug 2 -  N]\n  C --&gt;G[Zug 2 - T]\n  C --&gt;H[Zug 2 - N]\n  D --&gt;I[Zug 2 - T]\n  D --&gt;J[Zug 2 - T]\n  E --&gt;K[Zug 3 - N]\n  F --&gt;L[Zug 3 - T]\n  G --&gt;M[Zug 3 - N]\n  H --&gt;N[Zug 3 - T]\n  I --&gt;O[Zug 3 - T]\n  J --&gt;P[Zug 3 - T]\n  K --&gt;Q[TTN]\n  L --&gt;R[TNT]\n  M --&gt;S[TTN]\n  N --&gt;T[TNT]\n  O --&gt;U[NTT]\n  P --&gt;V[NTT]\n  \n\n\n\n\nAbbildung¬†4.20: Baumdiagramm f√ºr das Ziehen von 2 Treffern und 1 Niete\n\n\n\n\nSchneller geht es, wenn man rechnet. Wir k√∂nnten auch R auffordern, die Anzahl der g√ºnstigen Pfade zu berechnen, s. Theorem¬†4.3:\n\nCodechoose(3,2)\n## [1] 3\n\n\n\n4.5.3 Anzahl Pfade mal Pfad-Wahrscheinlichkeit\nIn diesem Fall ist die Wahrscheinlichkeit eines (g√ºnstigen) Pfades, \\(A\\):\n\\(Pr(A) = Pr(T)^2 \\cdot Pr(N)^1 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right)^1\\).\n\nCodep_a = (2/5)^2 * (3/5)^1\np_a\n## [1] 0.096\n\n\nDamit ist die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 3 Z√ºgen) gleich der Anzahl der g√ºnstigen Pfade mal der Wahrscheinlichkeit eines Pfades, , s. Gleichung¬†4.1:\n\\(Pr(A^{\\prime}) = 3 \\cdot Pr(A)\\).\n\nCodep_a_strich = 3 * p_a\np_a_strich\n## [1] 0.288\n\n\nDie Wahrscheinlichkeit, bei 3 Z√ºgen 2 Treffer zu erzielen, betr√§gt also ca. 29%.\n\\[Pr(A^{\\prime}) = k \\cdot Pr(A) \\tag{4.1}\\]\nDabei steht \\(k\\) f√ºr die Anzahl der g√ºnstigen Pfade und \\(Pr(A)\\) f√ºr die Wahrscheinlichkeit eines g√ºnstigen Pfades (d.h. 2 Treffer und 1 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\n\n4.5.4 Rechnen mit der Binomialverteilung\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen. Das ist komfortabler als selber rechnen.\n\nCodedbinom(x = 2, size = 3, prob = 2/5)\n## [1] 0.288\n\n\nDie Wahrscheinlichkeit, 2 Treffer bei 3 Z√ºgen zu erzielen mit \\(p=2/5\\), betr√§gt ca. 29%.\nDabei gehen wir davon aus, dass die Wahrscheinlichkeit eines Treffers stets \\(p=2/5\\) betr√§gt.\n\nBeispiel 4.13 (Lotto) Wie viele Zahlenkombinationen gibt es im Lotto f√ºr 6 Richtige? Der Binomialkoeffizient verr√§t es uns: \\(\\tbinom{49}{6}= 13\\,983\\,816\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeispiel 4.14 Wie viele M√∂glichkeiten gibt es, 2 Treffer bei 4 Z√ºgen zu erzielen?\n\nTTNN, 2. TNTN, 3. TNNT, 4. NTTN ,5. NTNT, 6. NNTT.\n\n\\(\\tbinom{4}{2} = \\frac{4!}{2! \\cdot (4-2)!} \\overset{\\text{k√ºrzen}}= \\frac{2\\cdot 3}{1}=6\\)\nEs sind also 6 M√∂glichkeiten.\nIn R kann man sich die Fakult√§t mit dem Befehl factorial ausrechnen lassen. Der R-Befehl choose berechnet den Binomialkoeffizienten.10\n\nCodeanzahl_pfade_2_aus_4 &lt;- \n  factorial(4) / (factorial(2) * factorial(4-2))\nanzahl_pfade_2_aus_4\n## [1] 6\n\n\n\nCodechoose(4, 2)\n## [1] 6\n\n\n\\(\\square\\)\n\n\nBeispiel 4.15 Hier sind die 10 Kombinationen, um aus 5 Losen genau 2 Treffer und 3 Nieten zu ziehen:\nTTNNN, TNTNN, TNNTN, TNNNT, NTTNN, NTNTN, NTNNT, NNTTN, NNTNT, NNNTT\n\nCodechoose(5, 2)\n## [1] 10\n\n\n\nCodeanzahl_pfade_2_aus_5 &lt;- \n  factorial(5) / (factorial(2) * factorial(5-2))\nanzahl_pfade_2_aus_5\n## [1] 10\n\n\n\\(\\square\\)\n\n\nBeispiel 4.16 (Bef√∂rderung) Aus einem Team mit 25 Personen sollen 11 Personen bef√∂rdert werden. Wie viele m√∂gliche Kombinationen (von bef√∂rderten Personen) k√∂nnen gebildet werden?\n\\(\\tbinom{25}{11} = \\frac{25!}{11!\\cdot(25-11)!} = 4\\,457\\,400\\)\n\nCodechoose(n = 25, k = 11)\n## [1] 4457400\n\n\nEs gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht ber√ºcksichtigt.\\(\\square\\)\n\n\nBeispiel 4.17 (Pumpstation-Beispiel zur Binomialverteilung) In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% f√§llt ein Motor aus und ist f√ºr den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie gro√ü ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb f√§llt?\n\\(Pr(X=k)\\) (oder kurz: \\(Pr(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an f√ºr das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(Pr(X=5)\\) ausrechnen.\n\nCodedbinom(x = 5, size = 7, prob = .95)\n## [1] 0.0406235\n\n\nEs gilt also \\(Pr(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist relativ gering11. Die Wahrscheinlichkeit, dass \\(k=0 \\ldots 7\\) Motoren laufen, ist in Abbildung¬†4.21 dargestellt.\ndbinom() steht f√ºr die Wahrscheinlichkeitsdichte (im diskreten Fall, wie hier, Wahrscheinlichkeitsfunktion genannt) und binom f√ºr die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die Stichprobengr√∂√üe an (hier 7 Motoren).\nDamit gilt:\n\\(Pr(X\\ge 5) = Pr(X=5) + Pr(X=6) + Pr(X=7)\\)\nBerechnen wir zun√§chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen mit Hilfe der Binomialverteilung.\n\nCodep_5 &lt;- dbinom(x = 5, size = 7, prob = .95)\np_6 &lt;- dbinom(x = 6, size = 7, prob = .95)\np_7 &lt;- dbinom(x = 7, size = 7, prob = .95)\n\np_5\n## [1] 0.0406235\np_6\n## [1] 0.2572822\np_7\n## [1] 0.6983373\n\n\nDas sind 0.04, 0.26, 0.7.\nDie gesuchte Wahrscheinlichkeit, p_mind_5, ist die Summe der drei Einzelwahrscheinlichkeiten.\n\nCodep_mind_5 &lt;- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 0.996243\n\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betr√§gt also 0.9962.\nDas komplement√§re Ereignis zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also h√∂chstens 4 und es daher zu einem Ausfall kommt. Es gilt also \\(Pr(\\bar{X}) = 1- Pr(X)\\).\n\nCodep_weniger_als_4 &lt;- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.003757043\n\n\nDas sind also 0.0038 oder 0.0003, also 0.03% Wahrscheinlichkeit, dass die Pumpstation ausf√§llt.\n\n\n\n\n\n\n\n\n\n(a) In ‚Äònormaler‚Äô Wahrscheinlichkeit, 0&lt;p&lt;1\n\n\n\n\n\n\n\n\n\n(b) In Log-Einheiten (Basis 2), ‚ÄòHalbierungen‚Äô\n\n\n\n\n\n\nAbbildung¬†4.21: Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen\n\n\nAlternativ kann man mit der Verteilungsfunktion pbinom() rechnen, die \\(Pr(X \\le 4)\\) berechnet.\nIn R kann man die Funktion pbinom() nutzen (p f√ºr (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen:\n\nCodepbinom(q = 4, size = 7, prob = .95)\n## [1] 0.003757043\n\n\nq = 4 steht f√ºr \\(X \\le 4\\), also f√ºr h√∂chstens 4 Treffer (arbeitende Motoren); size = 7 meint die Stichprobengr√∂√üe, hier 7 Motoren; prob gibt die Trefferwahrscheinlichkeit an. \\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Funktion, die die Wahrscheinlichkeit daf√ºr angibt, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich (h√∂chstens) einem Wert \\(X=x\\) ist, hei√üt Verteilungsfunktion.\n\\(F(X=x) = Pr(X \\le x)\\)\n\n\n\n4.5.4.1 Formel der Binomialverteilung\nTheorem¬†4.2 zeigt die mathematische Definition der Binomialverteilung. Dabei liegt immer ein Zufallsversuch mit \\(n\\) Durchg√§ngen und \\(k\\) Treffern zugrunde. Jeder Durchgang hat die Trefferwahrscheinlichkeit \\(p\\) und jeder Durchgang ist unabh√§ngig von allen anderen.\n\nTheorem 4.2 (Binomialverteilung) \\[Pr(X=k|p,n) = \\frac{n}{k!(n-k)!}p^k(1-p)^{n-k}\\quad \\square\\]\n\nTheorem¬†4.2 kann wie folgt auf Deutsch √ºbersetzen:\n\nDie Wahrscheinlichkeit f√ºr das Ereignis \\(X\\) gegeben \\(p\\) und \\(n\\) berechnet als Produkt von zwei Termen. Der erste Term ist der Quotient von der Fakult√§t von n im Z√§hler und im Nenner das Produkt von erstens der Fakult√§t von k mit zweitens der Fakult√§t von (n-k). Der zweite Term ist das Produkt von p hoch k mal der komplement√§ren Wahrscheinlichkeit von p hoch (n-k).\n\nOder noch k√ºrzer:\n\nDie Wahrscheinlichkeit f√ºr das Ereignis ‚ÄúX‚Äù gegeben p und k berechnet als Produkt von zwei Termen. Erstens der Anzahl der g√ºnstigen Pfade, k und zweitens der Wahrscheinlichkeit f√ºr einen g√ºnstigen Pfad, P(A).\n\nDie Anzahl der (g√ºnstigen) Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt, s. Theorem¬†4.3.12\n\nDefinition 4.10 (Binomialkoeffizient) Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von \\(n\\) verschiedenen Objekten \\(k\\) Objekte ziehen kann (ohne Zur√ºcklegen und ohne Beachtung der Reihenfolge). \\(\\square\\)\n\n\nTheorem 4.3 (Binomialkoeffizient) \\[k = \\tbinom{n}{k}= \\frac{n!}{k!(n-k)!} \\quad \\square\\]\nLies: ‚ÄúW√§hle aus \\(n\\) m√∂glichen Ereignissen (Pfade im Baum) \\(k\\) g√ºnstige Ereignisse (g√ºnstige Pfade) oder k√ºrzer‚Äùk aus n‚Äù.\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange √úbersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und f√ºr uns ausrechnen.\n\nBeispiel 4.18 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie gro√ü ist die Wahrscheinlichkeit, durch blo√ües M√ºnze werfen genau 15 Fragen richtig zu raten?13\n\nCode# Wskt f√ºr genau 15 Treffer bei 20 Versuchen mit einer fairen M√ºnze:\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.01478577\n\n\nUm h√∂chstens 15 Treffer zu erzielen, m√ºssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern addieren.\nPraktischerweise gibt es einen R-Befehl, der das f√ºr uns √ºbernimmt: pbinom.\n\nCodepbinom(q = 15, size = 20, prob = .5)\n## [1] 0.994091\n\n\nDie Wahrscheinlichkeit 0, 1, 2, ‚Ä¶ oder 15 Treffer zu erzielen, liegt laut Binomialverteilung mit pbinom bei gut 99%.\n\n\nBeispiel 4.19 (3 M√ºnzw√ºrfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 M√ºnzw√ºrfen (genau) 3 Treffer (Kopf) zu erzielen, s. Abbildung¬†4.22?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\nCodedbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.125\n\n\nDie L√∂sung lautet also \\(p=1/8 = .125.\\qquad \\square\\)\nMan kann sich auch vor Augen f√ºhren, dass es genau 1 g√ºnstigen Pfad gibt, n√§mlich TTT. Nach dem Multiplikationssatz gilt also: \\(Pr(X=3) = 1 \\cdot \\left( \\frac{1}{2} \\right)^3 = \\frac{1}{8} = .125\\).\n\nCodeloesung &lt;- (1/2)^3\nloesung\n## [1] 0.125\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) n=3, p=1/2\n\n\n\n\n\n\n\n\n\n(b) n=9, p=.7\n\n\n\n\n\n\nAbbildung¬†4.22: Verschiedene Binomialverteilungen\n\n\n\n√úbungsaufgabe 4.2 üèãÔ∏èÔ∏è Was f√§llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Ver√§ndert sich die Wahrscheinlichkeit linear?\n\n\n4.5.5 Vertiefung\n\n4.5.5.1 Logarithmus\nEin Logarithmus ist die Umkehrung der Potenzierung.\nDer Logarithmus beantwortet folgende Frage: Mit welchem Exponenten muss ich eine bestimmte Zahl (die Basis) potenzieren, um eine andere Zahl zu erhalten? Die Antwort auf diese Frage ist der Logarithmus.\nFormal ausgedr√ºckt:\n\nDefinition 4.11 (Logarithmus) Der Logarithmus von einer Zahl \\(a\\) zur Basis \\(b\\) ist die Zahl \\(x\\), mit der man \\(b\\) potenzieren muss, um \\(a\\) zu erhalten, s. Theorem¬†4.4. \\(\\square\\)\n\n\nTheorem 4.4 (Logarithmus) \\[\\log b(x) = y \\quad \\text{wenn und nur wenn} \\quad b^y = x\\]\n\nDer Logarithmus zur Basis 214 gibt die ‚ÄúVerdopplungen‚Äù bzw. ‚ÄúHalbierungen‚Äù der Wahrscheinlichkeit an, wobei \\(ld(1/2) = -1.\\square\\)\n\nBeispiel 4.20 \\(ld(1/2) = -1:\\)\n\nCodelog(.5, base = 2)\n## [1] -1\n\n\n1/2 ist genau ‚Äúminus 1 Verdopplung‚Äù von 1 entfernt, d.h. eine Halbierung.\n\\(ld(1/4) = -2:\\)\n\nCodelog(1/4, base = 2)\n## [1] -2\n\n\n1/4 ist genau ‚Äúminus 2 Verdopplungen‚Äù von 1 entfernt, d.h. zwei Halbierungen.\n\\(ld(1/8) = -3:\\)\n\nCodelog(1/8, base = 2)\n## [1] -3\n\n\n1/8 (0.125) ist 3 Halbierungen von 1 entfernt.\\(\\square\\)\n\n\n4.5.5.2 Simulieren wir eine Binomialverteilung\nDie Binomialverteilung l√§sst sich gut als ‚ÄúM√ºnzwurf-Verteilung‚Äù auffassen.\nWerfen wir eine M√ºnze und sehen wir, was passiert.\n\nCodesample(x = c(0, 1), size = 1)\n## [1] 0\n\n\nMit sample() ziehen wir eine Stichprobe aus dem Ereignisraum x, hier 0 und 1. Dabei vereinbaren wir (willk√ºrlich), dass 0 f√ºr ‚ÄúKopf‚Äù steht und 1 f√ºr ‚ÄúZahl‚Äù. size = 1 bedeutet, wir werfen die M√ºnze ein Mal (d.h. Stichprobengr√∂√üe size ist 1).\nOkay, noch an Bord? Dann werfen wir die M√ºnze 10 Mal:\n\nCodesample(x = c(0, 1), size = 10, replace = TRUE)\n##  [1] 1 0 1 1 0 0 0 0 0 1\n\n\nreplace = TRUE hei√üt, wir legen die M√ºnze wieder zur√ºck auf den Tisch, wenn wir sie geworfen haben. Oder anders ausgedr√ºckt: Ziehen mit Zur√ºcklegen.\nR, mach dich bereit, wirf die M√ºnze 1000 (\\(n=10^3\\) oder 1e3) Mal15:\n\nCoden &lt;- 1e3\n\nmuenze_oft &lt;- \n  sample(x = c(0, 1), size = n, replace = TRUE) \n\n\nmuenze_oft %&gt;% \n  sum()\n## [1] 515\n\n\nMit sum() nach dem Pfeifensymbol %&gt;% haben wir aus dem Vektor muenze_oft, der aus der ersten Zeile resultiert, die Summe ausgerechnet.\nJetzt wissen wir, wie oft die M√ºnze ‚ÄúZahl‚Äù gezeigt hat, n√§mlich 515 Mal.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie einen Zufallsversuch wiederholen, muss nicht jedes Mal das gleiche Ergebnis resultieren. Entsprechend wird bei wiederholten Ausf√ºhrung der Funktion sample() nicht immer das gleiche Ergebnis resultieren. Wundern Sie sich also nicht, wenn bei Ihrem Computer eine √§hnliche, aber nicht gleiche, Zahl herauskommt.\n\n\nVisualisieren wir mal unsere M√ºnzw√ºrfe. Dazu erstellen wir zuerst eine geeignete Tabelle, Tabelle¬†4.5.\n\nCodemuenz_tab &lt;-\n  tibble(\n    id = 1:n,\n    x = muenze_oft,\n    x_cumsum = cumsum(x) / id  # gibt Anteil von \"Zahl\" wieder\n  )\n\n\n\n\n\nTabelle¬†4.5: Die kumulierte Summe beim M√ºnzwurf (nur die ersten paar Zeilen)\n\n\n\n  \n\n\n\n\n\n\nUnd hier der Anteil von ‚ÄúZahl‚Äù im Verlauf unserer M√ºnzw√ºrfe, s. Abbildung¬†4.23.16\n\n\n\n\n\n\n\nAbbildung¬†4.23: Das Gesetz der gro√üen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten M√ºnzwurf\n\n\n\n\nGrob gesagt scheint sich ein M√ºnzwurf nach, naja, vielleicht 500 W√ºrfen ‚Äúeinigerma√üen‚Äù zu stabilisieren.17\n\n\n\n\n\n\nDas Gesetz der gro√üen Zahl\n\n\n\nZieht man (zuf√§llig) immer mehr Werte aus einer Verteilung (mit endlichem Mittelwert), n√§hert sich der Mittelwert der Stichprobe immer mehr mit dem Mittelwert (oft als Erwartungswert bezeichnet) der Verteilung an.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#normalverteilung",
    "href": "0400-Verteilungen.html#normalverteilung",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.6 Normalverteilung",
    "text": "4.6 Normalverteilung\n\n4.6.1 Grundlagen\n\nDefinition 4.12 (Normalverteilung) Normalverteilungen haben eine charakteristische Glockenform; sie sind symmetrisch18. Normalverteilungen k√∂nnen sich unterscheiden in ihrem Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden Gr√∂√üen (‚ÄúParameter‚Äù) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. Abbildung¬†4.24. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\\(\\square\\)\n\nEine normalverteilte Zufallsvariable \\(X\\) mit einem bestimmten Mittelwert und einer bestimmten Streuung schreibt man kurz so:\n\\[X \\sim \\mathcal{N}(\\mu, \\sigma)\\]\n\nDefinition 4.13 (Parameter) Ein Parameter (einer Verteilung) legt die ‚ÄúVarianten‚Äù einer Verteilung fest. Durch die Wahl der Parameterwerte nimmt eine Verteilung eine genaue Form an.\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†4.24: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\n\nBeispiel: Wie gro√ü sind Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die K√∂rpergr√∂√üe der 25% kleinsten Studentis an, analog f√ºr 50%, 75%, vgl. Tabelle¬†4.6.\n\n\n\nTabelle¬†4.6: Quantile der K√∂rpergr√∂√üen von Studentis\n\n\n\n\n\n\nq25\nq50\nq75\n\n\n160.02\n167.64\n175.26\n\n\n\n\n\n\n\n\nAbbildung¬†4.25 zeigt eine Visualisierung der Quantile.\n\n\n\n\n\n\n\nAbbildung¬†4.25: Quantile verschieden visualisiert\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas 25%-Quantil nennt man 1. Quartil, das 50%-Quantil auch 2. Quartil, das 75%-Quantil das 3. Quartil, und das 100%-Quantil (Maximalwert) das 4. Quartil.\n\n\nVerwechseln Sie die Normalverteilung nicht mit der Paranormalverteilung, s. Abbildung¬†4.26.\n\n\n\n\n\nAbbildung¬†4.26: Die Paranormalverteilung\n\n\n\n4.6.2 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. Abbildung¬†4.27:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\n√úbungsaufgabe 4.3 (Wie schlau muss man (nicht) sein?) ¬†\n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu geh√∂ren?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, ‚Ä¶ der Leute nicht √ºberschritten?\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung¬†4.27: Visualisierung der theoretischen IQ-Verteilung\n\n\nQuelle:: John Kruschke.\n\n\nZiehen wir zuf√§llig \\(1e4\\) (10000) Stichproben aus \\(\\mathcal{N}(100,15)\\) und berechnen die Quantile mit dem R-Befehl quantile(), s. Tabelle¬†4.7.\n\nCoded &lt;-\n  tibble(\n  iq = rnorm(n = 1e4, \n             mean = 100, \n             sd = 15))\n\nprobs &lt;- c(0.975, 0.75,.5,.25,.05,.01)\n\nd_summary &lt;- d %&gt;% \n  summarise(p = probs,\n            q = quantile(iq, probs))\n\n\n\n\n\n\nTabelle¬†4.7: Quantile der IQ-Verteilung\n\n\n\n\n\n\np\nq\n\n\n\n0.75\n110\n\n\n0.50\n100\n\n\n0.25\n90\n\n\n0.05\n75\n\n\n0.01\n65\n\n\n\n\n\n\n\n\n\n\n\nDas Quantil \\(q\\) zur kumulierten Wahrscheinlichkeit \\(p=75\\) ist 110, etc.\nUmgekehrt k√∂nnen wir uns auch fragen: Gegeben einer Realisation der Zufallsvariablen (z.B. IQ), was ist die zugeh√∂rige Wahrscheinlichkeit (Wert der Verteilungsfunktion?)\n\n√úbungsaufgabe 4.4 (Wie schlau muss man (nicht) sein, Teil 2) ¬†\n\nWelcher Anteil der Fl√§che unter der Kurve \\(p\\) geh√∂rt zu den IQ-Werten 75, 100, 115, 130?\nAnders gesagt: Welcher Anteil der Wahrscheinlichkeitsmasse der Verteilung liegt unter IQ=75, IQ=100, etc.?\\(\\square\\)\n\n\n\nZiehen wir Stichproben aus \\(\\mathcal{N}(100,15)\\). Was ist die Wahrscheinlichkeit f√ºr eine iq &lt; 100?\n\nCoded &lt;-\n  tibble(\n    iq = rnorm(1e4, \n               mean = 100, \n               sd = 15)) %&gt;% \n  mutate(iq = round(iq))\n\nqs &lt;- c(75,100,115,130)\n\nd %&gt;% \n  count(p_100 = iq &lt; 100) %&gt;% \n  mutate(prop = n / sum(n)) \n\n\nTabelle¬†4.8 zeigt uns die Antwort.\n\n\n\n\n\n\nHinweis\n\n\n\nWir sch√§tzen die wahre, ‚Äútheoretische‚Äù Wahrscheinlichkeit durch einfaches Ausprobieren: Wir f√ºhren das Zufallsexperiment einfach h√§ufig durch. Dann z√§hlen wir den Anteil der Treffer. Nennt man auch ‚ÄúSimulieren‚Äù; klingt cooler als ‚ÄúAusprobieren‚Äù.ü§ì\\(\\square\\)\n\n\n\n\n\nTabelle¬†4.8: Wahrscheinlichkeit f√ºr iq &lt; 100\n\n\n\n\n\n\np_100\nn\nprop\n\n\n\nFALSE\n5059\n0.51\n\n\nTRUE\n4941\n0.49\n\n\n\n\n\n\n\n\n\nAnstelle von iq &lt; 100 kann man iq &lt; 115 einsetzen, etc.\nDie Verteilungsfunktion (der Anteil der Wahrscheinlichkeitsmasse), p, f√ºr IQ-Werte nicht gr√∂√üer als 100, \\(IQ\\le100\\), ist 50%, etc.\n\n4.6.3 Quantile der Normalverteilung\nüí° Zur Erinnerung: Quantile teilen eine Verteilung so ein, dass ein Anteil \\(p\\) kleiner oder gleich und der andere Teil \\(1-p\\) gr√∂√üer dem Quantil \\(q\\) ist.\n\nBeispiel 4.21 ‚Äú50%-Quantil = 100‚Äù meint, dass 50% der Elemente der Verteilung einen Wert kleiner oder gleich als 100 haben. Man schreibt auch: q(.5) = 100.\n\nüí° Zur Erinnerung: Die Verteilungsfunktion F (f√ºr einen Wert \\(x\\) der Zufallsvariable \\(X\\)) gibt die Wahrscheinlichkeit an, dass \\(X\\) einen Wert h√∂chstens so gro√ü wie \\(x\\) annimmt. Sie zeigt also die kumulierte Wahrscheinlichkeit \\([-\\infty, q)\\).\n\nBeispiel 4.22 ‚ÄúF(100) = 50%‚Äù meint: Die Wahrscheinlichkeit f√ºr eine Auspr√§gung von h√∂chstens als 100 betr√§gt 50%.\\(\\square\\)\n\nSchauen wir uns die Quantile der Normalverteilung einmal n√§her an. Wir gehen von einer Normalverteilung aus, wie sie zur Beschreibung von Intelligenz (IQ) verwendet wird, s. Abbildung¬†4.28.\n\n\n\n\n\n\n\nAbbildung¬†4.28: Quantile der IQ-Verteilung (normalverteilt mit MW=100 und SD=15)\n\n\n\n\n\\[IQ \\sim \\mathcal{N}(100, 15)\\] Mit R kann man sich die beiden Gr√∂√üen komfortabel berechnen lassen:\n\nCodeqnorm(.50, mean = 100, sd = 15)  # 50%-Quantil\npnorm(100, mean = 100, sd = 15)  # Verteilungsfunktion f√ºr IQ=100\n\n\nBetrachten wir einige h√§ufig verwendete Quantile f√ºr die IQ-Verteilung, s. Abbildung¬†4.29.\n\n\n\n\n\n\n\nAbbildung¬†4.29: Verschiedene Quantile der Normalverteilung\n\n\n\n\n\n4.6.4 Standardnormalverteilung\nBei einer Standardnormalverteilung gilt, dass der Mittelwert 0 ist und die Standardabweichung 1, s. Theorem¬†4.5.\n\nTheorem 4.5 (Standardnormalverteilung) \\[X \\sim \\mathcal{N}(0, 1)\\quad \\square\\]\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.30: Normalverteilung mit Mittelwert 0 und SD 1, auch Standard-Normalverteilung genannt\n\n\n\n\n\nBei \\(X=0\\) einer Standard-Normalverteilung (s. Abbildung¬†4.30) gilt:\n\nhat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 40% (Wahrscheinlichkeitsdichte)\nsind 50% der Wahrscheinlichkeitsmasse (Fl√§che unter der Kurve) kleiner als dieser Wert (Verteilungsfunktion).\n\nIn Summe liegen 100% der Wahrscheinlichkeitsmasse unter der Kurve.\n\n\nMan kann jeder Normalverteilung in eine Standardnormalverteilung √ºberf√ºhren mit der z-Transformation.\nEin z-Wert ist das Ergebnis einer z-Transformation, die definiert ist als der Abstand in SD-Einheiten,\nden ein Wert vom Mittelwert entfernt ist, s. Theorem¬†4.6.\n\nTheorem 4.6 (z-Transformation) \\[z = \\frac{x - \\mu}{\\sigma}\\quad \\square\\]\n\nTabelle¬†4.9 und Abbildung¬†4.31 zeigen wichtige Werte der Verteilungsfunktion f√ºr die Standardnormalverteilung.\n\n\n\n\n\nTabelle¬†4.9: Ausgew√§hlte Werte der Verteilungsfunktion der Standardnormalverteilung\n\n\n\n\n\n\nz\nF\n\n\n\n-3\n0.001\n\n\n-2\n0.023\n\n\n-1\n0.159\n\n\n0\n0.500\n\n\n1\n0.841\n\n\n2\n0.977\n\n\n3\n0.999\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.31: Die Verteilungsfunktion f√ºr die z-Werte von -3 bis +3\n\n\n\n\n\n\n\n\n\n\n4.6.5 Vertiefung\n\n4.6.5.1 Normal auf dem Fu√üballfeld\nSie und 100 Ihrer besten Freunde stehen auf der Mittellinie eines Fu√üballfelds. Auf Kommando werfen alle jeweils eine M√ºnze; bei Kopf geht man einen Schritt nach links, bei Zahl nach rechts. Das wird 16 Mal wiederholt. Wie wird die Verteilung der Positionen wohl aussehen?\n\n\n\n\n\n\n\n\n(McElreath, 2020)\n\n4.6.5.2 Normal durch Addieren\nDie Summe vieler (gleich starker) Zufallswerte (aus der gleichen Verteilung) erzeugt eine Normalverteilung; egal aus welcher Verteilung die Zufallswerte kommen (Zentraler Grenzwertsatz), vgl. Abbildung¬†4.32.\n\n\n\n\n\n\n\nAbbildung¬†4.32: Entstehen einer Normalverteilung durch Addition vieler unabhg√§ngiger Ereignisse\n\n\n\n\n\n4.6.5.3 Normalverteilung als konservative Wahl\nDem Mathematiker Carl Friedrich Gauss (s. Abbildung¬†4.33) wird die Ehre zuerkannt, die Normalverteilung eingef√ºhrt zu haben.\n\n\n\n\n\n\n\nAbbildung¬†4.33: Zehn-Mark-Geldschein mit Gauss und Normalverteilung\n\n\n\n\nQuelle: Uni Greifswald, Public domain, via Wikimedia Commons\n\n\n\n\n\n\nHinweis\n\n\n\nOntologische Begr√ºndung\n\nWirken viele, gleichstarke Einfl√ºsse additiv zusammen, entsteht eine Normalverteilung (McElreath, 2020), Kap. 4.1.4.\n\nEpistemologische Begr√ºndung\n\nWenn wir nur wissen, dass eine Variable √ºber einen endlichen Mittelwert und eine endliche Varianz verf√ºgt und wir keine weiteren Annahmen treffen bzw. √ºber kein weiteres Vorwissen verf√ºgen, dann ist die Normalverteilung die plausibelste Verteilung (maximale Entropie) (McElreath, 2020), Kap. 7 und 10.\n\n\n\n\n4.6.5.4 Normalverteilung vs.¬†randlastige Verteilungen\nBei randlastigen Verteilungen (‚Äúfat tails‚Äù) kommen Extremereignisse viel h√§ufiger vor als bei Normalverteilungen. Deshalb ist es wichtig sein, zu wissen, ob eine Normalverteilung oder eine randlastige Verteilung vorliegt. Viele statistische Methoden sind nicht zuverl√§ssig bei (stark) randlastigen Methoden. Abbildung¬†4.34 grenzt eine Normalverteilung von einer ‚ÄúFat-Tail-Verteilung‚Äù ab.\n\n\n\n\n\n\n\nAbbildung¬†4.34: Normalverteilung vs.¬†randlastige Verteilungen\n\n\n\n\n\nBeispiel 4.23 (Beispiele f√ºr Normal- und randlastige Verteilungen) ¬†\n\n\nNormal verteilt:\n\nGr√∂√üe\nM√ºnzw√ºrfe\nGewicht\nIQ\nBlutdruck\nAusschuss einer Maschine\n\n\nRandlastig verteilt:\n\nVerm√∂gen\nVerkaufte B√ºcher (Anzahl)\nRuhm (z.B. Anzahl Follower auf Instagram)\nAktienkurse (Kurswert)\nErdbeben (St√§rke)\nAnzahl von Todesopfern in Pandemien\nAnzahl von Todesopfern in Kriege\nErfolg auf Tinder (Anzahl erfolgreicher Matches)\nMeteroritengr√∂√üe (Volumen)\nStadtgr√∂√üen (Einwohnerzahl)\n\n\n\n\n\n4.6.5.5 Formel der Normalverteilung\nVereinfacht ausgedr√ºckt l√§sst die Normalverteilung \\(\\mathcal{N}\\) durch Exponenzieren einer Quadratfunktion beschreiben:\n\\[\\mathcal{N} \\propto e^{-x^2}\\]\nmit \\(e=2.71...\\), der Eulerschen Zahl.19\nWie man sieht (Abbildung¬†4.35) ergibt sich eine Normalverteilung.\n\n\n\n\n\n\n\nAbbildung¬†4.35: Wir basteln uns eine Normalverteilung\n\n\n\n\nEine Normalverteilung mit \\(\\mu=0\\) und \\(\\sigma=1\\) nennt man auch Standardnormalverteilung und man schreibt:\n\\[IQ \\sim \\mathcal{N}(0,1)\\]\nDie Normalverteilung wird auch Gauss-Verteilung oder Glockenkurve genannt.\n\n4.6.5.6 Simulation einer Normalverteilung\nR hat eine Funktion eingebaut zur Erzeugung von Zufallszahlen (Zufallszahlengenerator), z.B. normalverteilte. Man √ºbergibt dieser Funktion den gew√ºnschten Mittelwert und die gew√ºnschte Streuung und die Funktion zieht dann zuf√§llig Werte aus dieser Verteilung.\nDiesen Zufallszahlengenerator kann man mit einem Duschkopf vergleichen, s. Abbildung¬†4.36. An diesem Duschkopf kann man einen Schwenker einstellen, der den Duschkopf ausrichtet, also steuert, ob die Wassertropfen weit in die eine oder die andere Richtugn fallen. Zweitens hat unser Duschkopf noch einen Streuregler, der den Wasserstrahl entweder eng b√ºndelt20 oder weit auseinanderf√§chert. Im ersten Fall f√§llt der Wasserstrahl eng und schmal aus. Im zweiten Fall f√§llt der Wasserstrahl breit aus.\n\n\n\n\n\nAbbildung¬†4.36: Zufallszahlengenerator als Duschkopf\n\n\nQuelle: John Kruschke.\nEine Zufallszahl (random number), die normalverteilt ist, mit \\(\\mu=0\\) und \\(\\sigma=1\\) kann man in R so erzeugen:\n\nCodernorm(n = 1, mean = 0, sd = 1)\n## [1] 0.2664096\n\n\nEin Fallbeispiel: Der Inhalt einer T√ºte mit Zucker, \\(X\\), sei normalverteilt mit \\(\\mu = 10002\\) g und \\(\\sigma=1.5\\) g. Aus vertragsrechtlichen Gr√ºnden darf das F√ºllgewicht von 1000g nicht unterschritten werden, sonst drohen Konventionalstrafen.\nWie gro√ü ist die Wahrscheinlichkeit, dass 1000g unterschritten werden?\nSimulieren wir uns 1e5 (100000) Zuckert√ºten!\n\nCoden &lt;- 1e5\nd &lt;- \n  tibble(\n    id = 1:n,\n    x = rnorm(n = n, mean = 1002, sd = 1.5)\n  )\n\nhead(d)\n\n\n  \n\n\n\nZ√§hlen wir, viele der Zuckert√ºten ein Gewicht von weniger als 1000g aufweisen:\n\nCoded %&gt;% \n  count(x &lt; 1000)\n\n\n  \n\n\n\nEin ziemlich21 kleiner Anteil. Rechnen wir uns noch die Anteile (proportion) aus:\n\nCoded %&gt;% \n  count(x &lt; 1000) %&gt;% \n  mutate(prop = n/1e4)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#vertiefung-2",
    "href": "0400-Verteilungen.html#vertiefung-2",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.7 Vertiefung",
    "text": "4.7 Vertiefung\nBourier (2011), Kap. 6.2 und 7.1 erl√§utert einige (grundlegende) theoretische Hintergr√ºnde zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar f√ºr den Stoff dieses Kapitels ist dabei die Binomialverteilung.\nMittag & Sch√ºller (2020) stellen in Kap. 12 und 13 Zufallsvariablen vor; zum Teil geht die Darstellung dort √ºber die Lernziele bzw. Inhalte dieses Kurses hinaus.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#aufgaben",
    "href": "0400-Verteilungen.html#aufgaben",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.8 Aufgaben",
    "text": "4.8 Aufgaben\nZus√§tzlich zu den Aufgaben in der genannten Literatur sind folgende Aufgaben zu empfehlen.\n\n4.8.1 Paper-Pencil-Aufgaben\n\nalphafehler-inflation3\nalphafehler-inflation4\niq1a\niq2a\niq3a\nsimu-uniform\nsimu-unif2\nsimu-unif3\nQuiz zum Thema Verteilungen\nBsp-Binomial\n\n4.8.2 Aufgaben, f√ºr die man einen Computer braucht\n\nalphafehler-inflation2\nQuiz (Aufgabensammlung) zu Verteilungen\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\niq01\niq02\niq03\niq04\niq05\niq06\niq07\n\niq08  \n\nBus1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#section",
    "href": "0400-Verteilungen.html#section",
    "title": "\n4¬† Verteilungen\n",
    "section": "\n4.9 ‚Äî",
    "text": "4.9 ‚Äî\n\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende Statistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√úbungen: Beschreibende Statistik ‚Äì Wahrscheinlichkeitsrechnung ‚Äì Schlie√üende Statistik (7. Auflage). Springer Gabler.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#footnotes",
    "href": "0400-Verteilungen.html#footnotes",
    "title": "\n4¬† Verteilungen\n",
    "section": "",
    "text": "da einfach und deutlich‚Ü©Ô∏é\nS wie Summe‚Ü©Ô∏é\nMachen Sie das mal ohne Computer, wenn Sie ein Wochenende lang Langeweile haben.‚Ü©Ô∏é\nAlternativ kann man z.B. auch ggplot verwenden: ggplot(x_simu_df, aes(x = x_simu)) +  geom_histogram(bins = 50).‚Ü©Ô∏é\nvon lat. bis ‚Äúzweimal‚Äù‚Ü©Ô∏é\nBei jeder Wiederholung des Zufallexperiments bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die M√ºnze ver√§ndert sich nicht durch die W√ºrfe (Ziehen mit Zur√ºcklegen, ZmZ). Au√üerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc., sog. ‚Äúiid‚Äù: independent and identically distributed.‚Ü©Ô∏é\nIn den Lehrb√ºchern h√§ufig als Urne bezeichnet, was den b√∂sen Spott von ‚ÄúFriedhofstatistik‚Äù nach sich zog.‚Ü©Ô∏é\npraktisch unendlich vielen‚Ü©Ô∏é\nDa sehr viele Lose im K√§stchen liegen, ist es praktisch egal, ob wir das Los wieder zur√ºcklegen. Die Wahrscheinlichkeit f√ºr einen Treffer √§ndert sich (so gut wie) nicht.‚Ü©Ô∏é\nBei Taschenrechnern ist diese Funktion oft als ‚ÄúnCr‚Äù zu finden.‚Ü©Ô∏é\nwobei ‚Äúgering‚Äù subjektiv ist, die Betreiberfirma findet diese Wahrscheinlichkeit, dass 2 Pumpen ausfallen, wohl viel zu hoch.‚Ü©Ô∏é\nwobei gelten muss \\(n \\ge k\\)‚Ü©Ô∏é\nHey, endlich mal was f√ºr echte Leben!‚Ü©Ô∏é\nals ‚ÄúLogarithmus Dualis‚Äù, ld, bezeichnet‚Ü©Ô∏é\nR meckert nicht bei langweiligen Aufgaben.‚Ü©Ô∏é\nlibrary(ggpubr); ggline(muenz_tab, x = \"id\", y = \"x_cumsum\")‚Ü©Ô∏é\nWas ‚Äúeinigerma√üen‚Äù bedeuten soll, ist kein statistischer Begriff, sondern einer, der im echten Leben von den Menschen beantwortet werden muss, die eine Entscheidung zu treffen haben.‚Ü©Ô∏é\nd.h. die Schiefe (skewness) ist 0‚Ü©Ô∏é\nDas Zeichen \\(y \\propto x\\) bedeutet ‚Äúx ist proportional zu y‚Äù, also \\(y = mx\\).‚Ü©Ô∏é\nMassagedusche, behauptet der Hersteller‚Ü©Ô∏é\n‚ÄúZiemlich‚Äù ist nat√ºrlich subjektiv; je nach Situation kann es zu viel oder nicht zu viel sein.‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html",
    "href": "0500-Globusversuch.html",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "",
    "text": "5.1 Lernsteuerung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#lernsteuerung",
    "href": "0500-Globusversuch.html#lernsteuerung",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "",
    "text": "5.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n5.1.2 √úberblick\nIn diesem Kapitel √ºbersetzen wir eine Problemstellung (Forschungsfrage) in ein (mathematisches) Modell, das uns dann mit Hilfe der Bayes-Formel Antworten auf die Problemstellung gibt.\n\n5.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nUnterschiede zwischen Modellen und der Realit√§t erl√§utern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (f√ºr binomial verteilte Zufallsvariablen)\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\ndas Bayes-Modell anhand bekannter Formeln herleiten\nPost-Wahrscheinlichkeiten anhand der Bayesbox berechnen\n\n5.1.4 Begleitliteratur\nDer Stoff dieses Kapitels deckt einen Teil aus McElreath (2020), Kap. 2, ab. McElreath (2020) stellt das Globusmodell mit mehr Erl√§uterung und etwas mehr theoretischem Hintergrund vor, als es in diesem Kapitel der Fall ist.\n\n5.1.5 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. ‚ÄúDaten Einlesen‚Äù\n\n5.1.6 Begleitvideos\n\nüì∫ Globusversuch\n\n\n5.1.7 Ben√∂tigte R-Pakete\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)  # komfortable Visualisierung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#von-welten-und-golems",
    "href": "0500-Globusversuch.html#von-welten-und-golems",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.2 Von Welten und Golems",
    "text": "5.2 Von Welten und Golems\n\n5.2.1 Kleine Welt, gro√üe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein gl√ºcklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb Abbildung¬†5.1.\n\n\n\n\n\nAbbildung¬†5.1: Behaims Globus: Kein Amerika\n\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der gro√üen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel f√ºr, sagen wir, die Komplexit√§t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Gl√ºck geh√∂rt halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die gro√üe Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der gro√üen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schl√ºssen und vermeintlicher Gewissheit.\n\nüèã Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht! \\(\\square\\)\n\n\n5.2.2 Der Golem von Prag\n\n\n\n\n\nAbbildung¬†5.2: Der Golem von Prag\n\n\nQuelle\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle w√∂rtlich ausf√ºhrt, s. Abbildung¬†5.2. Die Geschichte besagt, dass ein Rabbi mit Zauberkr√§ften den Golem aus Lehm erschuf, um die j√ºdische Bev√∂lkerung der Stadt zu sch√§tzen. Bei kluger F√ºhrung kann ein Golem N√ºtzliches vollbringen. Bei un√ºberlegter Verwendung wird er jedoch gro√üen Schaden anrichten.\n\n5.2.3 Wissenschaftliche Modelle sind wie Golems\n\n\n‚ÄúYeah, ich bin ein Golem!‚Äù - Bildquelle: Klara Schaumann\n\n\n\nGolem\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch ‚ÄúWahrheit‚Äù\nM√§chtig\ndumm\nF√ºhrt Befehle w√∂rtlich aus\nMissbrauch leicht m√∂glich\nM√§rchen\n\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal m√§chtig\nsimpler als die Realit√§t\nF√ºhrt Befehle w√∂rtlich aus\nMissbrauch leicht m√∂glich\nNicht einmal falsch\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildung¬†2.5 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen (Tabelle¬†5.1), wie z.B. Behaims Globus, mit der Gro√üen Welt, die Kolumbus und wir befahren.\n\n\nTabelle¬†5.1: Kleine Welt vs.¬†gro√üe Welt\n\n\n\n\n\n\n\nKleine Welt\nGro√üe Welt\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangsl√§ufig) die Wirklichkeit\nentspricht nicht (zwangsl√§ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n5.2.4 Die Bayes-Formel und Lernen\nüèã Bayes-Inferenz √§hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess √§hnelt!\\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.3 Ein erster Versuch: Wir werfen den Globus\n\n5.3.1 Welcher Anteil der Erdoberfl√§che ist mit Wasser bedeckt?\n\nBeispiel 5.1 (Wasseranteil auf der Erdoberfl√§che) Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (Abbildung¬†5.3)? Um m√∂glichst wenig schreiben zu m√ºssen, schreiben wir f√ºr ‚Äúangenommener Wasseranteil auf der Erdoberfl√§che‚Äù kurz \\(p\\) oder \\(\\pi\\) (p wie proportion, Anteil). \\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†5.3: Die Erde. Sch√∂n! Und mit viel Wasser, ca. 70% der Erdoberfl√§che sind mit Wasser bedeckt. Quelle, Lizenz: CC 4.0 BY-NC\n\n\nAnalog k√∂nnen wir uns vorstellen, 11 Wissenschaftlis haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus ‚Ä¶ die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.2\nSo sah mein3 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nAlso \\(W=6\\) (Wasser, d.h. ‚ÄúTreffer‚Äù) und \\(L=3\\) (Land) (\\(n=9\\) Versuche).\n\n√úbungsaufgabe 5.1 (Spin the Globe) üèãÔ∏èÔ∏è Besorgen Sie sich einen Globus (zur Not eine M√ºnze) und stellen Sie den Versuch nach!\\(\\square\\)\n\n\n5.3.2 Bayes-Updates\nDer Golem denkt eigentlich ganz vern√ºnftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugeh√∂rige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung (s. Definition¬†5.1). In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als n√§chstes beschaut sich der Golem die Daten und √ºberlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 50% betr√§gt. Die zugeh√∂rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die4 Likelihood5, s. Definition¬†5.2. Als letztes bildet sich der Golem eine abschlie√üende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung, s. Definition¬†5.3. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder ‚Äúgeupdatet‚Äù, s. Abbildung¬†5.4.\n\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]--&gt;B[Likelihood]--&gt;C[Post-Vert.]--&gt;A\n\n\n\n\nAbbildung¬†5.4: Updating mit Bayes\n\n\n\n\n\nDefinition 5.1 (Priori-Verteilung) F√ºr jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilit√§t der Hypothese angibt: Priori-Verteilung (synonym: Apriori-Verteilung).\\(\\square\\)\n\n\nDefinition 5.2 (Likelihood) F√ºr jede Hypothese (d.h. jeden Parameterwert \\(\\pi\\)) m√∂chten wir wissen, wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Kurz: Wir suchen die Likelihood. Anders gesagt: Die Likelihood sagt uns, wie gut die Daten zu einer bestimmten Hypothese passen.\\(\\square\\)\n\n\nDefinition 5.3 (Posteriori-Verteilung) Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung6 bekommen.\\(\\square\\)\n\n\n√úbungsaufgabe 5.2 (Wie gut passen die Daten zur Hypothese, dass die Erde komplett trocken ist?) Wir haben in unseren Versuch \\(W=6\\) und \\(L=3\\) erzielt. Diese Daten passen √ºberhaupt nicht zur Hypothese, dass die Erdoberfl√§che komplett trocken ist. Die Likelihood, \\(L\\) f√ºr \\(\\pi=0\\) ist also Null. Analog ist die Likelihood f√ºr \\(\\pi=1\\) auch Null.\\(\\square\\)\n\n\n5.3.3 Wie wahrscheinlich ist ein Wasseranteil von 90%?\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer (bei 9 W√ºrfen) zu erhalten, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 90%) annimmt? Diese Wahrscheinlichkeit nennt man die Likelihood, \\(L\\) oder \\(L\\).\n\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabh√§ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich √§ndert 7. Der Wasseranteil der Erde bleibt w√§hrend des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit f√ºr Wasser \\(\\pi\\) betr√§gt, so bezeichnen: \\(Pr(W,L | \\pi))\\) oder auch (synonym) so: \\(Pr(W|\\pi, n)\\). Diese Wahrscheinlichkeit, \\(Pr(W,L | \\pi)\\), kann man im Fall des Globusversuchs mit der Binomialverteilung berechnen.\nM√∂chte man die Wahrscheinlichkeit ansprechen f√ºr das Ereignis ‚Äú6 mal Wasser und 3 mal Land, wenn wir von einem Wasseranteil von 70% ausgehen‚Äù, so w√ºrden wir kurz schreiben: \\(Pr(W=6, L=3 | \\pi=.7)\\). Oder man k√∂nnte (synonym) schreiben: \\(Pr(W=6 | \\pi=.7, n=9)\\).\nZur Erinnerung: Die Binomialverteilung zeigt die Verteilung der Wahrscheinlichkeit der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten M√ºnzwurf (und allen vergleichbaren Zufallsexperimenten): ‚ÄúM√ºnzwurfverteilung‚Äù, s. Kap. Kapitel 4.5.\n\n5.3.4 Likelihood berechnen\nWas ist der Anteil der g√ºltigen Pfade in einem Baumdiagramm (d.h. die Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(n=W+L=3\\) W√ºrfen zu bekommen, wenn wir von \\(\\pi=1/2\\) ausgehen? 8, s. Listing¬†5.1, Abbildung¬†5.5 und Gleichung¬†5.1.\n\n\n\nListing¬†5.1: Binomialverteilung mit R f√ºr x=2, n=3, p=1/2\n\nloesung &lt;- dbinom(x = 2, size = 3, prob = 1/2)\nloesung\n## [1] 0.375\n\n\n\n\nOder von Hand gerechnet:\n\\[\\begin{aligned}\nPr(W=2 | \\pi=1/2, n=3) &=\\\\\n\\tbinom{3}{2} \\cdot (1/2)^2 \\cdot (1/2)^1 &=\\\\\n\\frac{3!}{2!1!} \\cdot (1/2)^3 &= \\\\\n3 \\cdot 1/8 = 3/8 &= 0.375\n\\end{aligned} \\tag{5.1}\\]\nWenn man sich den entsprechenden Baum anschaut (s. Abbildung¬†5.5): Von den 8 Endkonten bzw. Pfaden sind 3 g√ºnstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 W√ºrfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-&gt; B[B - 0]\n  A -. 1/2 .-&gt; C[C - 1]\n  B -. 1/2 .-&gt; D[D - 0]\n  B -. 1/2 .-&gt; E[E - 1]\n  C -. 1/2 .-&gt; F[F - 0]\n  C -. 1/2 .-&gt; G[G - 1]\n  D -. 1/2 .-&gt; H[H - 0]\n  D -. 1/2 .-&gt; J[I - 1]\n  E -. 1/2 .-&gt; K[K - 0]\n  E -. 1/2 .-&gt; L[L - 1]\n  F -. 1/2 .-&gt; M[M - 0]\n  F -. 1/2 .-&gt; N[N - 1]\n  G -. 1/2 .-&gt; O[O - 0]\n  G -. 1/2 .-&gt; P[P - 1]\n\n\n\n\nAbbildung¬†5.5: Wir werfen den Globus (oder eine M√ºnze) 3 Mal. Die Knoten sind der √úbersicht halber mit fortlaufenden Buchstaben (von A bis P) bezeichnet\n\n\n\n\nAbb. Abbildung¬†5.5 stellt einen einfachen Baum f√ºr 3 Globusw√ºrfe mit je zwei m√∂glichen Ereignissen (W vs.¬†L) dar. In der ersten (obersten) Zeile (Knoten A; ‚ÄúStart‚Äù) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) m√∂gliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nF√ºr mehr W√ºrfe w√ºrde das Diagramm irgendwann un√ºbersichtlich werden.\nAbbildung¬†5.6 zeigt die Binomialverteilung \\(X \\sim Bin(9, 1/2)\\): Die jeweilige Wahrscheinlichkeit f√ºr \\(k=0,1,\\ldots, 9\\) Treffer bei \\(n=9\\) Versuchen mit Trefferwahrscheinlichkeit \\(\\pi=1/2\\).\n\n\n\n\n\n\n\nAbbildung¬†5.6: Ein Beispiel f√ºr eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\n\n\n\nAbb Abbildung¬†5.7 ist ein vergeblicher Versuch, so einen gro√üen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum Verst√§ndnis, kommen aber bei gr√∂√üeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\n\n\n\nAbbildung¬†5.7: Wir werfen den Globus (oder eine M√ºnze) 9 Mal, es resultieren 512 Endknoten. Nicht gerade √ºbersichtlich.\n\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 5.2 (Globus mit 6 Treffern bei 9 W√ºrfen, p=1/2) Was ist der Anteil der g√ºltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) W√ºrfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\nCodedbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.1640625\n\n\nOder, synonym, wenn man einen Taschenrechner (oder R als Taschenrechner) benutzt:\n\nCodechoose(9, 6) * (1/2)^6 * (1/2)^3\n## [1] 0.1640625\n\n\n\\(\\square\\)\n\n\nBeispiel 5.3 (Globus mit 9 Treffern bei 9 W√ºrfen, p=1/2) Was ist die Wahrscheinlichkeit, gegeben \\(W=9\\) bei \\(n=9\\) und \\(\\pi=1/2\\)?\n\nCodedbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.001953125\n\n\nDas ist 1 g√ºnstiger Pfad von 512 Pfaden, also \\(Pr(W=9|\\pi=1/2, n=9)=1/512\\).\n\n\nBeispiel 5.4 (Globus mit 6 Treffern bei 9 W√ºrfen, p=70%) Was ist die Wahrscheinlichkeit f√ºr \\(W=6\\), gegeben \\(n=9\\) und \\(p=.7\\)?\n\nCodedbinom(x = 6, size = 9, prob = .7)\n## [1] 0.2668279\n\n\nMit Taschenrechner gerechnet:\n\nCodeanz_pfade &lt;- choose(9,6) \nwskt_pro_pfad &lt;- (.7)^6 * (.3)^3\ngesamt_wkst &lt;- anz_pfade * wskt_pro_pfad\ngesamt_wkst\n## [1] 0.2668279\n\n\n(Fast) von Hand gerechnet, mit R als Taschenrechner:\n\nCodefactorial(9)/(factorial(6)*factorial(3)) * (.7)^6 * (.3)^3\n## [1] 0.2668279\n\n\nAls Formel, s. Gleichung¬†5.2:\n\\[\\begin{aligned}\nPr(W=6 | \\pi=.7, n=9) &=\\\\\n\\tbinom{9}{6} \\cdot (.7)^6 \\cdot (.3)^3 &=\\\\\n\\frac{9!}{6!3!} \\cdot (.7)^6 \\cdot (.3)^3 &=\\\\\n84 \\cdot  .003 = .27.\n\\end{aligned} \\tag{5.2}\\]\n\\(\\square\\)\n\nZur Erinnerung: Die Funktion dbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zur√ºck, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\nEs gibt Taschenrechner(-Apps), die die Binomialverteilung oder den Binomialkoeffizienten berechnen k√∂nnen.9\n\n5.3.5 Unser Modell ist geboren\nEin Modell (in der Bayes-Statistik) besteht aus mind. zwei Komponenten:\n\nDie Likelihood (die Wahrscheinlichkeit der Daten unter Annahme der Hypothese), s. Gleichung¬†5.3\n\nDie Priori-Verteilung(en) (die Wahrscheinlichkeit der Hypothese vor den Daten), a. ?thm-prior-unif-globus\n\nDie Posteriori-Verteilung (die Wahrscheinlichkeit der Hypothese nach den Daten), s. Abbildung¬†6.1\n\n\n5.3.6 Likelihood\nIm Globusversuch verwenden wir die Binomialverteilung zur Berechnung der Likelihood, s. Gleichung¬†5.3.\n\\[W \\sim \\text{Bin}(n,\\pi) \\tag{5.3}\\]\nLies: ‚ÄúW ist binomial verteilt mit den Parametern \\(n\\) und \\(\\pi\\)‚Äù. \\(n\\) gibt die Anzahl der Globusw√ºrfe an: \\(n=W+L\\).\nMit einem konkretes Beispiel: \\(W \\sim \\text{Bin}(9, 0.7)\\) bedeutet, dass wir von 9 W√ºrfen ausgehen und eine Wahrscheinlichkeit f√ºr Wasser von 70% annehmen.\nDie Verwendung der Binomialvertielung ist an einige Annahmen gekn√ºpft:\n\nDie Z√ºge sind unabh√§ngig voneinander (Die W√ºrfe des Globusballs beeinflussen sich einander nicht).\nDer Parameterwert \\(\\pi\\) bleibt konstant (Der Wasseranteil der Erde √§ndert sich nicht w√§hrend des Versuchs).\n\n\n√úbungsaufgabe 5.3 üèã Welche Annahmen w√ºrden Sie √§ndern? Welche k√∂nnte man wegnehmen? Welche hinzuf√ºgen? Was w√§ren die Konsequenzen?\\(\\square\\)\n\n\n5.3.7 Priori-Verteilung\nUnser Vorab- bzw. Apriori-Wissen zu \\(p\\) sei, dass uns alle Werte gleich (‚Äúuniform‚Äù) plausibel erscheinen, s. Gleichung¬†5.4.\n\\[\\pi \\sim \\text{Unif}(0,1). \\tag{5.4}\\]\nLies: ‚Äú\\(\\pi\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1‚Äù.\nMan k√∂nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (apriori) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich, s. Abbildung¬†5.8.\n\n\n\n\n\n\n\nAbbildung¬†5.8: Gleichverteilung mit Parametern min=0 und max=1\n\n\n\n\n\n5.3.8 Posteriori-Verteilung\ndie Posteriori-Verteilung quantifiziert unser Wissen nach Kenntnis der Daten, aufbauend auf unserem Vorwissen (Priori-Wissen). Die Posteriori-Verteilung ist das Ergebnis des Bayes-Updates.\nDie Wahrscheinlichkeit bestimmter Hypothesen nennt man Posteriori-Wahrscheinlichkeit und bezeichnet sie kurz mit \\(Pr(H|D)\\). Lies: ‚ÄúDie Wahrscheinlichkeit der Hypothese H gegeben der Daten D‚Äù. Dabei nimmt man stillschweigend an, dass die Daten anhand eines gewissen Modells generiert wurden.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-theorem",
    "href": "0500-Globusversuch.html#bayes-theorem",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.4 Bayes‚Äô Theorem",
    "text": "5.4 Bayes‚Äô Theorem\n\n5.4.1 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes h√§ufig, wenn man Daten \\(D\\) gesammelt hat, und wissen m√∂chte, wie wahrscheinlich eine Hypothese \\(H\\) ist, im Lichte dieser gesammelten Daten, s. Theorem¬†5.1.\n\n\nTheorem 5.1 (Bayes‚Äô Theorem) \\[Pr(H|D) = \\frac{ Pr(H) \\cdot Pr(D|H) }{Pr(D)}\\quad \\square\\]\n\nBayes‚Äô Theorem (Theorem¬†5.1) fragt nach \\(Pr(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (Theorem¬†5.1):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der Plausibilit√§t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgr√ºnden dividiert man noch die totale Wahrscheinlichkeit der Daten √ºber alle Hypothesen.\n\nF√ºr unser Globusbeispiel:\n\nWie wahrscheinlich ist denn jetzt ein bestimmter Wasseranteil auf der Erde, \\(\\pi\\), (gegeben den Daten, \\(W=6\\) und \\(L=3\\))? Also, wie wahrscheinlich ist z.B. ein Wasseranteil von 70% oder von 50%?\n\n\n5.4.2 Bayes als bedingte Wahrscheinlichkeit\nBayes‚Äô Theorem wird h√§ufig verwendet, um die Wahrscheinlichkeit einer Hypothese, gegeben einer bestimmten Datenlage, zu berechnen, also \\(Pr(H|D)\\). Also zeigt Bayes‚Äô Theorem nichts anderes als eine normale bedingte Wahrscheinlichkeit.\n\\(Pr(H| D)\\) kann man umformen (vgl. Theorem¬†3.5 und Definition¬†3.19), dann erh√§lt man Bayes‚Äô Theorem, s. Theorem¬†5.8.\n\nTheorem 5.2 (Bayes‚Äô Theorem 2) \\[\\begin{aligned}\nPr(H|D) &=\\frac{\\overbrace{ Pr(H\\cap D)}^\\text{umformen}}{Pr(D)} \\\\  &= \\frac{\\overbrace{Pr(H)}^\\text{Apriori-Wahrscheinlichkeit} \\cdot \\overbrace{Pr(D|H)}^\\text{Likelihood}}{\\underbrace{Pr(D)}_\\text{Evidenz}}\n\\end{aligned}\\quad \\square\\]\n\n\n5.4.3 Die Evidenz zur Standardisierung\nDie Aufgabe der Evidenz ist nur daf√ºr zu sorgen, dass der Wert von \\(Pr(H|D)\\) insgesamt nur Werte zwischen 0 und 1 annehmen kann, also eine brave, normale Wahrscheinlichkeit ist. W√ºrde man in Theorem¬†5.8 nicht durch die Evidenz teilen, so w√§re die Posteriori-Wahrscheinlichkeit nicht normiert, d.h. sie k√∂nnte Werte &gt;1 annehmen.\n\nDefinition 5.4 (Evidenz) \\(Pr(D)\\) nennt man die Evidenz. Die Evidenz berechnet sich als Summe der Likelihoods f√ºr alle Parameterwerte \\(H_i\\), d.h. als die totale Wahrscheinlichkeit von \\(D\\), s. Theorem¬†5.3, vgl. auch Definition¬†3.21. \\(\\square\\)\n\n\nTheorem 5.3 (Evidenz) \\[\\begin{aligned}\nPr(D) = \\sum_{i=1}^n Pr(D|H_i) \\cdot Pr(H_i)\n\\end{aligned}\\quad \\square\\]\n\nDie verschiedenen Parameterwerte kann man auch als die verschiedenen Hypothesen \\(H_i\\) auffassen. Falls es nur zwei Hypothesen bzw. Parameterwerte gibt, vereinfacht sich Theorem¬†5.3 zu Theorem¬†5.4.\n\nTheorem 5.4 (Evidenz 2) \\[\\begin{aligned}\nPr(D) = Pr(D|H_1) \\cdot Pr(H_1) + Pr(D|H_2) \\cdot Pr(H_2)\n\\end{aligned}\\quad \\square\\]\n\n\nBeispiel 5.5 In Beispiel¬†5.7 betrug der Wert der Evidenz \\(0.03 + 0.002 + 0.012 = 0.044\\), also ca. 4%. \\(\\square\\)\n\n\n\n\n\n\n5.4.4 Bayes‚Äô Theorem als Formel\n\n\nSchauen wir uns die Bestandteile von Bayes‚Äô Theorem (Theorem¬†5.8) noch etwas n√§her an:\n\n(standardisierte) Posteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nApriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayes‚Äô Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) f√ºttert. Bayes‚Äô Theorem wird verwendet, um die \\(Pr_{Post}\\) zu quantifizieren. Die \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n5.4.5 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Posteriori-Wahrscheinlichkeit \\(Pr_{\\text{unPost}}\\) ist einfach das Produkt von Likelihood und Priori, s. Theorem¬†5.5.\n\nTheorem 5.5 (Unstandardisierte Posteriori-Wahrscheinlichkeit) \\[Pr_{\\text{unPost}} = L \\times \\text{Priori}\\quad \\square\\]\n\nAbb. Abbildung¬†5.9 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\n\n\n\nAbbildung¬†5.9: Prior mal Likelihood = Post\n\n\nStandardisiert man die unstandardisierte Post-Verteilung, so erh√§lt man die standardisierte Post-Verteilung. Das Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung Theorem¬†5.6.\n\nTheorem 5.6 (Standardisierte Posteriori-Verteilung) \\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\quad \\square\\]\n\n\n5.4.6 Wissen updaten: Wir f√ºttern Daten in das Modell\nGolems k√∂nnen lernen?! Abbildung¬†5.10 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. W√ºrfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich f√ºr den Golem (das Modell). Je nach Ergebnis des Wurfes ver√§ndert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung ver√§ndert sich in Abh√§ngigkeit von den Daten.\n\n\n\n\n\nAbbildung¬†5.10: Unser Golem lernt\n\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell n√ºtzlich ist (pr√§zise Vorhersagen liefert), steht auf einem anderen Blatt.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-berechnen-mit-mit-der-bayes-box",
    "href": "0500-Globusversuch.html#bayes-berechnen-mit-mit-der-bayes-box",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.5 Bayes berechnen mit mit der Bayes-Box",
    "text": "5.5 Bayes berechnen mit mit der Bayes-Box\nWir erstellen uns eine kleine Tabelle, die man ‚ÄúBayes-Box‚Äù nennen k√∂nnte.10 Dazu gehen wir so vor:\n\n5.5.1 Die Idee der Bayes-Box\n\nTeile den Wertebereich des Parameters in ein ‚ÄúGitter‚Äù auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\).\nW√§hle den Priori-Wert des Parameters f√ºr jeden Parameterwert, z.B. 1/11 bei einer Gleichverteilung von 0 bis 1.\nBerechne den Likelihood f√ºr jeden Parameterwert.\nBerechne den unstandardisierten Posteriori-Wert f√ºr jeden Parameterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nF√ºr jeden Parameterwert berechnen wir eine (Post-)Wahrscheinlichkeit.11 H√§ufig entspricht eine Hypothese einem Parameterwert, etwa wenn man sagt: ‚ÄúIch glaube, die M√ºnze ist fair‚Äù, was auf einen Parameterwert von 50% herausl√§uft. Dazu geben wir an, f√ºr wie wahrscheinlich wie apriori12 ‚Äì also bevor wir irgendwelche Daten erheben ‚Äì jeden einzelnen Parameterwert halten. Wir machen es uns hier einfach und halten jeden Parameterwert f√ºr gleich wahrscheinlich. Tats√§chlich ist der konkrete Wert hier egal, entscheidend ist das Verh√§ltnis der Apriori-Werte zueinander: Geben wir einigen Parameterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere f√ºr (apriori) doppelt so plausibel wie Letztere. Der Likelihood wird in diesem Beispiel mit der Binomialverteilung berechnet (da wir ein bin√§res Ereignis, \\(W\\) oder \\(L\\), haben). Der Likelihood gibt an, wie wahrscheinlich ein Parameterwert ist gegeben einem bestimmten apriori gew√§hlten Parameterwert. Die ‚ÄúEnd-Wahrscheinlichkeit‚Äù, die unstandardisierte Post-Wahrscheinlichkeit, die ‚Äúhinten rauskommt‚Äù ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet13. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen m√∂chten, teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die Anspr√ºche an eine Wahrscheinlichkeitsverteilung erf√ºllt (vgl. Kapitel 3.3.4).\n\n5.5.2 Bayes-Box in R berechnen\nLegen wir uns ein Gitter mit Parameterwerten (\\(\\pi\\)) an, um deren Posteriori-Wahrscheinlichkeit zu berechnen. Konkret gesprochen: Wir listen jeden f√ºr uns interessanten Wasseranteil (\\(\\pi\\)) auf, also \\(\\pi=0, 0.1, 0.2, ..., 1\\). Diese Parameterwerte sind die Hypothesen, die wir testen wollen, s. Listing¬†5.2.\n\n\n\nListing¬†5.2: Parameterwerte (Gitter) f√ºr Wasseranteile: 0, 0.1, 0.2, ‚Ä¶, 1\n\nwasseranteile &lt;- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte\nwasseranteile\n##  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 W√ºrfen) gegeben jeweils eines Wasseranteils.\n\nCodeLikelihood &lt;- dbinom(6, size = 9, prob = wasseranteile)\nLikelihood\n##  [1] 0.000000000 0.000061236 0.002752512 0.021003948 0.074317824 0.164062500\n##  [7] 0.250822656 0.266827932 0.176160768 0.044641044 0.000000000\n\n\nSchlie√ülich packen wir das alles in eine Tabelle, die ‚ÄúBayes-Box‚Äù, s. Tabelle¬†5.2 und Listing¬†5.3.\n\n\n\nListing¬†5.3: Wir basteln uns eine Bayes-Box\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (die Parameterwerte, p): \n    p = wasseranteile,\n    # Lege den Priori-Wert fest:\n    Priori  = 1/11) |&gt; \n    mutate(\n      # berechne Likelihood f√ºr jeden Wasseranteil (Parameterwert):\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\n\n\n\nDie Bayes-Box (Tabelle¬†5.2) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\nTabelle¬†5.2: Die Bayes-Box f√ºr den Globusversuch, k=6 Treffer, n=9 Versuche, Apriori-Wahrscheinlichkeit Pr(H)=9%, und Wasseranteile p von 0 bis 1\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n1\n0.0\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n2\n0.1\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n3\n0.2\n0.091\n0.003\n0.000\n0.091\n0.003\n\n\n4\n0.3\n0.091\n0.021\n0.002\n0.091\n0.021\n\n\n5\n0.4\n0.091\n0.074\n0.007\n0.091\n0.074\n\n\n6\n0.5\n0.091\n0.164\n0.015\n0.091\n0.164\n\n\n7\n0.6\n0.091\n0.251\n0.023\n0.091\n0.251\n\n\n8\n0.7\n0.091\n0.267\n0.024\n0.091\n0.267\n\n\n9\n0.8\n0.091\n0.176\n0.016\n0.091\n0.176\n\n\n10\n0.9\n0.091\n0.045\n0.004\n0.091\n0.045\n\n\n11\n1.0\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n\n\n\n\n\n\nF√ºr jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood, s. Gleichung¬†5.5.\n\\[\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood} \\tag{5.5}\\]\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Bayesbox (also f√ºr jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten, s. Theorem¬†5.7.\n\nTheorem 5.7 (Posteriori-Verteilung 2) \\[\\text{Post} = \\frac{\\text{Post}_{\\text{unstand}}}{\\text{Evidenz}} = \\frac{Pr(H) \\cdot Pr(H|D)}{Pr(D)}\\quad \\square\\]\n\nDabei haben wir die Priori-Wahrscheinlichkeit f√ºr alle Parameterwerte als gleich angenommen, da wir keinerlei Vorwissen hatten, \\(Pr(H_i) = 1/11\\). Die Evidenz berechnet sich als Summe der unstandardisierten Post-Wahrscheinlichkeiten, \\(Pr(D) = 0.09\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWenn der Priori-Wert f√ºr jeden Parameterwert gleich ist, dann ist der Likelihood gleich der unstandardisierten Post-Wahrscheinlichkeit.\\(\\square\\)\n\n\n\nBeispiel 5.6 (Post-Wahrscheinlichkeit im Globusversuch f√ºr p=.7) In Beispiel¬†5.4 haben wir die Wahrscheinlichkeit f√ºr 6 Treffer bei 9 W√ºrfen gegeben einer Trefferwahrscheinlichkeit von \\(\\pi = .7\\) berechnet. Damit haben wir die Likelihood \\(L = Pr(D|H) =.25\\) berechnet.\nAuf dieser Basis k√∂nnen wir die Posteriori-Wahrscheinlichkeit \\(Pr_{Post}\\) berechnen, zun√§chst die unstandardisierte. Dazu haben wir die Priori-Wahrscheinlichkeit mit der Likelihood multipliziert, s. Gleichung¬†5.6:\n\\[\\text{Post}_{\\text{unstand}} = Pr(H) \\cdot Pr(D|H) = 0.09 \\cdot 0.25 = 0.025 \\tag{5.6}\\]\nJetzt standardisieren wir die unstandardisierte Post-Wahrscheinlichkeit, indem wir durch die Evidenz dividieren, s. Gleichung¬†5.7.\n\\[\\text{Post} = \\frac{\\text{Post}_{\\text{unstand}}}{\\text{Evidenz}} = \\frac{0.025}{0.1} =0.25 \\tag{5.7}\\]\nGleichung¬†5.8 fasst die Schritte der Berechnung zusammen.\n\\[\\begin{aligned}\nPr(H_{\\pi=0.7}|D) =\n\\frac{Pr(D|H) \\cdot Pr(H)}{Pr(D)} &= \\\\\n\\frac{\\text{Likelihood}  \\cdot \\text{Priori-Wahrscheinlichkeit}}{\\text{Evidenz}} &= \\\\\n\\frac{0.25 \\cdot 0.1}{0.1} &= 0.25\n\\end{aligned} \\tag{5.8}\\] \\(\\square\\)\nFazit: Nach dem Versuch, d.h. nachdem wir die Daten in Betracht gezogen haben, hat sich unsere Meinung √ºber den Wasseranteil geupdatet von 0.1 auf 0.25.\\(\\square\\)\n\n\n√úbungsaufgabe 5.4 üèãÔ∏è Was wohl mit Post passiert, wenn wir Priori √§ndern?\\(\\square\\)\n\nAbbildung¬†6.1 zeigt eine Visualisierung der Post-Verteilung mit Hilfe der Funktion ggline(x, y) aus dem Paket ggpubr. Wie man sieht, ist die Post-Wahrscheinlichkeit am h√∂chsten bei \\(\\pi=0.7\\). Wobei der Bereich von 0.6 bis 0.8 auch recht wahrscheinlich ist.\n\n\n\n\n\n\n\nAbbildung¬†5.11: Die Post-Verteilung visualisiert. Die Post-Wahrscheinlichkeit ist am h√∂chsten bei p=0.7\n\n\n\n\n\n5.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: ‚ÄúPost-Verteilung‚Äù, oder ‚ÄúPost‚Äù), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten, jetzt, nachdem wir die Daten des Versuchs kennen. Die Post-Wahrscheinlichkeit updatet unser Apriori-Wissen mit dem Wissen, das wir durch die Daten erhalten haben.\nAbbildung¬†5.12 zeigt die Post-Wahrscheinlichkeit f√ºr 5, 10 und 20 Parameterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben. Man sieht: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\nAbbildung¬†5.12: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen Umst√§nden gilt:\n\nMehr Gitterwerte gl√§tten die Ann√§herung.\nJe gr√∂√üer die Stichprobe (\\(N\\)), desto zuverl√§ssiger wird unsere Berechnung. \\(\\square\\)\n\n\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer Tr√§ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung k√∂nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des n√§chsten Kapitels. \\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#abschluss",
    "href": "0500-Globusversuch.html#abschluss",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.6 Abschluss",
    "text": "5.6 Abschluss\n\n5.6.1 Zusammenfassung\nüì∫ √úbung zum Globusversuch\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der gro√üen Welt n√ºtzlich ist, steht auf einem anderen Blatt.\n\n\n√úbungsaufgabe 5.5 üèãÔ∏è Wenn Sie auf einen Prozentwert f√ºr \\(W\\) tippen m√ºssten, welchen w√ºrden Sie nehmen, laut dem Modell (und gegeben der Daten)? \\(\\square\\)\n\n\n5.6.2 Der Globusversuch als Modell f√ºr zweiwertige Zufallsversuche\nDer Globusversuch ist kein prototypisches Beispiel f√ºr Statistik in der Praxis, zumindest nicht auf dem ersten Blick. Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist. Bei n√§herer Betrachtung ist der Globusversuch prototypisch f√ºr ganz viele Fragestellungen:\n\nVon einem neuen Produkt von von \\(n\\) Exemplaren \\(k\\) verkauft. Auf welchen Wert \\(p\\) kann die Akzeptanzrate dieses Produkts gesch√§tzt werden?\nEin Chat-Bot hat von \\(n\\) Fragen \\(k\\) richtig beantwortet. Wie hoch kann die Verst√§ndnisrate \\(p\\) dieses Programms gesch√§tzt werden?\nEine neue Krebstherapie hat von \\(n\\) ‚Äúaustherapierten‚Äù Patientis \\(k\\) geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie gesch√§tzt werden?\n\nKurz: Der Globusversuch ist ein Muster f√ºr zweiwertige Zufallsversuche. Und solche sind h√§ufig im Leben, im Business und in der Wissenschaft.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#vertiefung",
    "href": "0500-Globusversuch.html#vertiefung",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.7 Vertiefung",
    "text": "5.7 Vertiefung\n\n5.7.1 Bayes-Video von 3b1b\nDas ‚ÄúBayes-Paradox-Video‚Äù von 3b1b pr√§sentiert eine gut verst√§ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber √§hnlichen Darstellung wie in diesem Kapitel.\n\n5.7.2 Bayes als Baum\nBayes‚Äô Theorem kann man sich als als Baumdiagramm vor Augen f√ºhren, Abbildung¬†5.13.\nGesucht sei \\(Pr(M_1|A)\\), also: die Wahrscheinlichkeit, dass das Teil von Maschine 1 produziert wurde, gegeben, dass es Ausschuss ist. Gegeben sind die Wahrscheinlichkeiten, dass Machine \\(i\\) das Teil produziert hat, \\(Pr(M_i)\\). Au√üerdem sind die Wahrscheinlichkeiten, dass das Teil Ausschuss ist, \\(Pr(A|M_i)\\), bekannt.\nDas Diagramm l√∂st die Aufgabe f√ºr uns; es zeigt damit die Anwendung von Bayes‚Äô Theorem auf.\nUm \\(Pr(M_1|A)\\) zu erhalten, setzt man die Wahrscheinlichkeit des g√ºnstigen Asts ins Verh√§ltnis zur Wahrscheinlichkeit aller relevanten √Ñste, \\(Pr(A)\\).\n\nBeispiel 5.7 (Maschine produziert Ausschuss) Die drei Maschinen \\(M_1, M_2, M_3\\) produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. Abbildung¬†5.13.\nAufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde? Berechnen Sie diese Wahrscheinlichkeit.\\(\\square\\)\n\nDer g√ºnstige (gesuchte) Ast, \\(Pr(M1 \\cap A)\\), ist hier fett gedruckt, s. Abbildung¬†5.13. In Abbildung¬†5.13 zeigen die runden K√§stchen am Ende der Pfade die Wahrscheinlichkeiten des jeweiligen Pfades an.\n\n\n\n\n\nflowchart LR\n  A[Start] ==&gt;|0.60|B[M1]\n  A ---&gt;|0.10|C[M2]\n  A ---&gt;|0.30|D[M3]\n  B ==&gt;|0.05|E[A]\n  B --&gt;|0.95|F[Nicht-A]\n  C ---&gt;|0.02|G[A]\n  C ---&gt;|0.98|H[Nicht-A]\n  D ---&gt;|0.04|I[A]\n  D ---&gt;|0.96|J[Nicht-A]\n  E --- K((0.030))\n  F --- L((0.570))\n  G --- M((0.002))\n  H --- N((0.098))\n  I --- O((0.012))\n  J --- P((0.288))\n\n\n\n\nAbbildung¬†5.13: G√ºnstige Pfade\n\n\n\n\n\\[Pr(M1|A) = \\frac{Pr(M1 \\cap A)}{Pr(A)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(Pr(M1|A)\\) betr√§gt also ca. 68%.\nZur Erinnerung: \\(Pr(A)\\) ist die totale Wahrscheinlichkeit (dass ein produziertes Teil Ausschuss ist).\n\n5.7.3 Weitere Herleitung der Bayes-Formel\nMan kann sich Bayes‚Äô Theorem auch wie folgt herleiten:\n\\(Pr(D\\cap H) = Pr(D \\cap H) = Pr(D) \\cdot Pr(H|D) = Pr(H) \\cdot Pr(D|H)\\)\nDann l√∂sen wir nach P\\((H|D)\\) auf, s. Theorem¬†5.8.\n\nTheorem 5.8 (Bayes‚Äô Theorem 3) \\[Pr(H|D) = \\frac{\\overbrace{Pr(H)}^\\text{Apriori-Wahrscheinlichkeit} \\cdot \\overbrace{Pr(D|H)}^\\text{Likelihood}}{\\underbrace{Pr(D)}_\\text{Evidenz}}\\quad \\square\\]\n\n\n5.7.4 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayes‚Äô Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel w√§re: ‚ÄúWas ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?‚Äù.\nDas sieht dann so aus wie in Theorem¬†5.9 gezeigt.\n\nTheorem 5.9 (Bayes‚Äô Theorem f√ºr zusammengesetzte Hypothesen) \\[\n\\begin{aligned}\nPr(R \\cap B |K) &= \\frac{ Pr(R \\cap B) \\cdot Pr(K|R \\cap B) }{Pr(D)} \\\\\n&= \\frac{ Pr(R ) \\cdot Pr(B) \\cdot Pr(K|R \\cap B) }{Pr(D)}\n\\end{aligned}\n\\quad \\square\\]\n\nHier haben wir \\(Pr(R \\cap B)\\) aufgel√∂st in \\(Pr(R) \\cdot Pr(B)\\), das ist nur zul√§ssig, wenn \\(R\\) und \\(B\\) unabh√§ngig sind.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#aufgaben",
    "href": "0500-Globusversuch.html#aufgaben",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\n\n\n\n\n\n\nTipp\n\n\n\nEinige der folgenden Aufgaben sind in englischer Sprache. Wenn Ihnen eine andere Sprache (z.B. Deutsch) lieber ist, nutzen Sie einfach die √úbersetzungsfunktion Ihres Browsers. Das sind meist nur zwei Klicks. \\(\\square\\)\n\n\n\n5.8.1 Papier-und-Bleistift-Aufgaben\n\nVerteilungen-Quiz-01\nglobus1\nglobus2\nglobus3\nglobus-bin\nglobus-bin2\nKrebs1\nkekse01\nkekse03\nbayes2\nBayes-Theorem1\nbayes-ziel1\ntotale-wskt1\nwskt-quiz13\nwskt-quiz12\nwskt-quiz15\n\n5.8.2 Aufgaben, f√ºr die man einen Computer braucht\n\n\nRethink2m1\nRethink2m2\n\nRethink2m3    \n\nkekse02\neuro-bayes\nbath42\nKaefer2\nrethink3m1\nLose-Nieten-Binomial-Grid",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#section",
    "href": "0500-Globusversuch.html#section",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "\n5.9 ‚Äî",
    "text": "5.9 ‚Äî\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#footnotes",
    "href": "0500-Globusversuch.html#footnotes",
    "title": "\n5¬† Bayes-Versuch\n",
    "section": "",
    "text": "wenn auch nicht als Erster‚Ü©Ô∏é\nWarum gerade 9 Mal? Tja, dann hat das Handy geklingelt‚Ä¶ Auch in wissenschaftlichen Versuchen ist (leider?) nicht immer alles genau geregelt.‚Ü©Ô∏é\nIhr Ergebnis kann anders aussehen, schlie√ülich ist es ja Zufall.‚Ü©Ô∏é\noder den?‚Ü©Ô∏é\nzu Deutsch etwa: ‚ÄúMutma√ülichkeit‚Äù‚Ü©Ô∏é\n Anstatt von Priori liest man auch Prior; anstatt Posteriori auch Posterior‚Ü©Ô∏é\nDie sog. ‚Äúiid-Annahme‚Äù, independently and identically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen. Jeder Wurf ist unabh√§ngig von allen anderen: Das Ergebnis eines Wurfes hat keinen (stochastischen) Einfluss auf ein Ergebnis anderer W√ºrfe. Die Wahrscheinlichkeitsverteilung ist bei jedem Wurf identisch.‚Ü©Ô∏é\nAllgemeiner spricht man auch von 2 Treffern bei 3 W√ºrfen (d.h. 1 ‚ÄúNicht-Treffer‚Äù, den wir als ‚ÄúNiete‚Äù bezeichnen). Treffer werden oft mit 1 und Nieten mit 0 bezeichnet‚Ü©Ô∏é\nhttps://www.geogebra.org/scientific?lang=de‚Ü©Ô∏é\nAuch Gitter-Methode oder Grid-Methode genannt.‚Ü©Ô∏é\nEin Parameterwert ist eine m√∂gliche Auspr√§gung des Parameters.‚Ü©Ô∏é\nsynonym: priori‚Ü©Ô∏é\nsynonym: Die Likelihoodwerte werden mit den Apriori-Werten gewichtet.‚Ü©Ô∏é",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0600-Post.html",
    "href": "0600-Post.html",
    "title": "6¬† Die Post befragen",
    "section": "",
    "text": "6.1 Lernsteuerung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "6¬† Die Post befragen",
    "section": "",
    "text": "6.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n6.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n6.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 3.1 und 3.2.\n\n\n6.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúDaten umformen‚Äù\nStatistik1, Kap. ‚ÄúDaten zusammenfassen‚Äù\n\n\n\n6.1.5 Ben√∂tigte R-Pakete\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # optional\n\n\n\n\n6.1.6 Begleitvideos\n\nPlaylist QM2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#zur-erinnerung-gitterwerte-in-r-berechnen",
    "href": "0600-Post.html#zur-erinnerung-gitterwerte-in-r-berechnen",
    "title": "6¬† Die Post befragen",
    "section": "6.2 Zur Erinnerung: Gitterwerte in R berechnen",
    "text": "6.2 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (‚ÄúBayes-Box‚Äù) die Postverteilung f√ºr den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele n√ºtzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) W√ºrfen, bei Apriori-Indifferenz gegen√ºber den Parameterwerten. Und sagen wir \\(k=11\\) Gitterwerten1, also mit 10 Wasseranteilswerten zwischen 0 und 1.\n\n√úbungsaufgabe 6.1 (Welcher Paramterwert hat die h√∂chste Posteriori-Wahrscheinlichkeit?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\nAufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die h√∂chste Wahrscheinlichkeit (d.h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. Listing¬†6.1. \\(\\square\\)\n\n\n\n\n\n\n\n\nListing¬†6.1: Bayes-Box mit 6 Wasser bei 9 Versuchen\n\n\nn_success &lt;- 6          \nn_trials  &lt;- 9\np_grid &lt;- seq(from = 0, to = 1, by = .1)\nL &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\n\nd &lt;-\n  tibble(p_grid = p_grid,prior  = 1) %&gt;% \n  mutate(likelihood = L) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n\n\nSequenz von 0 bis 1 mit Schritten der Gr√∂√üe 0.1.\nLikelihood mit 6 Treffern bei 9 W√ºrfen und das Ganze jeweils f√ºr alle 11 Parameterwerte\nDann packen wir alles in eine Tabelle.\n\n\n\n\n\nCode\nlibrary(ggpubr)\nggline(d, x = \"p_grid\", y = \"post\") \n\n\nAbb. Abbildung¬†6.1 zeigt die resultierende Bayes-Box; vor allem ist die Post-Verteilung wichtig.\n\n\n\n\n\n\n\n\nAbbildung¬†6.1: Die Postverteilung f√ºr W=6, N=9, k=10\n\n\n\n\n\nVoil√†, die Post-Verteilung als Tabelle, auch ‚ÄúBayes-Box‚Äù (oder Bayes-Gitter) genannt: s. Tabelle¬†6.1.\n\n\n\n\nTabelle¬†6.1: Postverteilung mit der Gittermethode berechnet\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.02\n0.02\n0.02\n\n\n0.4\n1\n0.07\n0.07\n0.07\n\n\n0.5\n1\n0.16\n0.16\n0.16\n\n\n0.6\n1\n0.25\n0.25\n0.25\n\n\n0.7\n1\n0.27\n0.27\n0.27\n\n\n0.8\n1\n0.18\n0.18\n0.18\n\n\n0.9\n1\n0.04\n0.04\n0.04\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.1 Bayes-Box automatisiert\n√úbrigens kann man die Berechnung der Bayes-Box auch automatisieren, s. Tabelle¬†6.2 und Listing¬†6.2, z.B. so:2\nEntweder so:\n\n\nCode\nsource(\"https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R\") \nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\nMit source importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code f√ºr die Funktion bayesbox.\nOder Sie starten das R-Paket, wo die Funktion wohnt:\n\n\n\n\nListing¬†6.2: Funktion bayesbox, auch im Paket prada erh√§ltlich\n\n\nlibrary(prada)\nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\n\n\n\n\nTabelle¬†6.2: Eine Bayes-Box ‚Äòautomatisiert‚Äô erstellt, mit Hilfe der Funktion bayesbox\n\n\n\n\n  \n\n\n\n\n\n\n\nDas Paket prada steht nicht im Standard-R-App-Store (‚ÄúCRAN‚Äù), sondern auf Github. Sie k√∂nnnen es so installieren: devtools::install_github(\"sebastiansauer/prada\").\nDie Funktion verh√§lt sich wie eine gew√∂hnliche Bayes-Box: Bei hyps schreibt man die Hypothesen (bzw. Parameterwerte) auf. Bei priors die Priori-Werte und bei liks die Likelihoods der jeweiligen Hypothesn.\n\n\n\n\n\n\n\n\n\n\n\n\nViele n√ºtzliche Fragen (und Antworten) leiten sich ab aus Abb. Abbildung¬†6.1.\n\nBeispiel 6.1 (Beispiele f√ºr Fragen an die Post-Verteilung) ¬†\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die h√∂chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell √ºber die Parameterwerte?\n\netc. \\(\\square\\)\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.2.2 Bayes-Box f√ºr komplexe Modelle\nBisher, f√ºr einfache Fragestellungen hat unsere Bayes-Box, das hei√üt die Gittermethode bestens funktioniert: einfach, robust, formsch√∂n3. Allerdings: Funktioniert sie auch bei komplexeren Modellen? Schlie√ülich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 Pr√§diktor, dann haben wir folgende drei Gr√∂√üen4 zu sch√§tzen: \\(\\beta_0, \\beta_1, \\sigma\\). H√∂rt sich gar nicht so viel an. Aber Moment, wir m√ºssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach m√ºssen wir alle Auspr√§gungen (‚ÄúGitterwerte‚Äù) der Variablen multiplizieren. Puh, das wird eine gro√üe Zahl. Wenn wir f√ºr die drei Gr√∂√üen jeweils 10 Auspr√§gungen annehmen, was wenig ist, k√§men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 Auspr√§gungen w√§ren es schon \\(100^3=10^6\\) Kombinationen. Das w√§re doch eine recht lange Tabelle.5\nBei einer multiplen Regression mit sagen wir 10 Pr√§diktoren mit jeweils 100 Auspr√§gungen rechnet das arme R bis zum j√ºngsten Tag: \\(10^{100}\\).\n\nü§ñ Bitte tue mir das nicht an!\n\n\nüë®‚Äçüè´ Schon gut, das k√∂nnen wir R nicht zumuten. Wir brauchen eine andere L√∂sung!",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6¬† Die Post befragen",
    "section": "6.3 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.3 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.3.1 Wir arbeiten jetzt mit H√§ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle k√∂nnen nicht mehr ‚Äúeinfach mal eben‚Äù ausgerechnet werden; die Mathematik wird zu rechenintensiv. Gl√ºcklicherwei√üe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht. Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit H√§ufigkeiten. Praktischerweise werden wir in K√ºrze einen R-Golem kennenlernen, der das f√ºr uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zur√ºck. Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung mit H√§ufigkeiten (d.h. in Stichprobenform) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen f√ºr Bayes auf Stichproben eingestellt.\n\n\nDie Bayes-Box-Methode6 ist bei gr√∂√üeren Datens√§tzen (oder gr√∂√üeren Modellen) zu unpraktisch. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein.7\n\n\n6.3.2 H√§ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (‚ÄúR-Golems‚Äù) liefern uns die Post-Verteilung in Stichprobenform zur√ºck. Bevor wir uns aber mit diesen R-Werkzeugen besch√§ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform. Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. Listing¬†6.3.\n\n\n\nListing¬†6.3: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\n\n\nsamples &lt;-\n  d %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit Zur√ºcklegen\n  select(p_grid)\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit Zur√ºcklegen h√§lt die Wahrscheinlichkeiten w√§hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird. Wir begn√ºgen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht. Das Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in Ausz√ºgen) in Tabelle¬†6.3 dargestellt.\nWenn Sie jetzt denken: ‚ÄúWarum machen wir das jetzt? Brauchen wir doch gar nicht!‚Äù - Dann haben Sie Recht. K√ºnftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\n\n\nTabelle¬†6.3 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.\n\n\n\n\nTabelle¬†6.3: Stichproben-Post-Verteilung\n\n\n\n\n\n\n\n\n\np_grid\n\n\n\n\n0.600\n\n\n0.500\n\n\n0.700\n\n\n0.700\n\n\n0.600\n\n\n\n\n\n\n\n\n\n\n\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.6 0.5 0.7 0.7 0.6 0.7 0.8 0.8 0.8 0.8 0.6 0.7 0.7 0.7 0.7 0.5 0.4 0.5\n##  [19] 0.8 0.7 0.3 0.9 0.7 0.6 0.7 0.6 0.7 0.7 0.4 0.4 0.5 0.8 0.7 0.6 0.7 0.6\n##  [37] 0.7 0.6 0.8 0.7 0.6 0.6 0.6 0.9 0.9 0.8 0.5 0.4 0.7 0.6 0.8 0.6 0.5 0.7\n##  [55] 0.8 0.7 0.7 0.6 0.6 0.5 0.7 0.4 0.5 0.9 0.5 0.5 0.9 0.6 0.9 0.6 0.6 0.8\n##  [73] 0.7 0.5 0.5 0.5 0.5 0.4 0.7 0.7 0.5 0.6 0.8 0.5 0.6 0.7 0.6 0.6 0.7 0.6\n##  [91] 0.4 0.5 0.6 0.9 0.8 0.5 0.9 0.6 0.8 0.8\n\n\n\nSo sieht unsere ‚ÄúStichproben-Bayesbox‚Äù als Balkendiagramm aus, s. Abbildung¬†6.2.\n\nSyntaxOutput\n\n\n\n\nCode\nsamples |&gt; \n  count(p_grid) |&gt; \n  ggbarplot(x = \"p_grid\", y = \"n\") \n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n\n\nAus Abbildung¬†6.2 k√∂nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% f√ºr am wahrscheinlichsten h√§lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlie√üen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie Abbildung¬†6.2 mit Abbildung¬†5.12: beide sind sehr √§hnlich! Das Stichprobenziehen (Abbildung¬†6.2) n√§hert sich recht gut an die exakte Berechnung an (Abbildung¬†5.12).\nEs ist hilfreich, sich die Stichproben-Posterior-Verteilung einmal anzuschauen, um ein Gef√ºhl daf√ºr zu bekommen, wie die Post-Verteilung aussieht.\n Download samples.xlsx \n\n\n6.3.3 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die Aufl√∂sung auf \\(k=100\\) Gitterwerte (Auspr√§gungen) nach oben.\n\n\nCode\n1k &lt;- 100\n2n_success &lt;- 6\n3n_trials  &lt;- 9\n\nd_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n4                      length.out = k),\n5         prior  = 1) %&gt;%\n6  mutate(likelihood = dbinom(n_success,\n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n7  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n1\n\n\\(k=100\\) Gitterwerte\n\n2\n\n6 Treffer (Wasser)\n\n3\n\n9 Versuche\n\n4\n\nBayes-Box anlegen mit 100 Zeilen, d.h. 100 Parameterwerten\n\n5\n\nApriori indifferent: Alle Hypothesen haben die gleiche Apriori-Plausibilit√§t\n\n6\n\nDie Likelihood ist binomialverteilt.\n\n7\n\nPost-Verteilung berechnen wie gewohnt.\n\n\n\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\n\nCode\nsamples_k100 &lt;-\n  d_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zur√ºcklegen\n\n\nAbbildung¬†6.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen F√§llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der ‚Äútypische‚Äù Wert des Modells zu sein. Au√üerdem erkennt man, dass das Modell durchaus einige Streuung in der Sch√§tzung des Wasseranteils bereith√§lt. Das Modell ist sich nicht sehr sicher, k√∂nnte man sagen.\n\n\n\n\n\n\n\n\nAbbildung¬†6.3: Post-Verteilung mit 100 Gitterwerten, exakt vs.¬†auf Basis von Stichproben\n\n\n\n\n\nDie Stichprobendaten n√§hern sich der ‚Äúechten‚Äù Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt ‚Äúglattere‚Äù R√§nder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte gl√§tten die Verteilung.\n\n\nJetzt die Post-Verteilung noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. Abbildung¬†6.4.\n\n\n\n\n\n\n\n\nAbbildung¬†6.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): sch√∂n ‚Äòglatt‚Äô. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "6¬† Die Post befragen",
    "section": "6.4 Die Post-Verteilung befragen",
    "text": "6.4 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\nüì∫ Die Post-Verteilung auslesen\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir k√∂nnen viele n√ºtzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abbildung¬†6.5 schematisch illustriert.\n\n\n\n\n\n\nAbbildung¬†6.5: Fragen nach p vs.¬†Fragen nach q\n\n\n\nIm linken Teildiagramm von Abbildung¬†6.5 fragen wir: ‚ÄúWie wahrscheinlich ist ein Wasseranteil von h√∂chstens 80%?‚Äù. Im rechten Teildiagramm fragen wir: ‚ÄúWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht √ºberschritten?‚Äù.\n\n6.4.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie gro√ü ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt? Um diese Frage zu beantworten, z√§hlen wir einfach, wie viele Stichproben die Bedingung erf√ºllen, und summieren die Wahrscheinlichkeiten dieser Stichproben. Wir z√§hlen (count) also die Stichproben, die sich f√ºr einen Wasseranteil (p_grid) von weniger als 50% aussprechen.\n\n\nCode\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, k√∂nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) f√ºr einen Wasseranteil kleiner als 50%.\n\nBeispiel 6.2 (Was macht die Funktion count?) Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem Pr√ºfkriterium, Wasseranteil h√∂chstens 50%. Dann z√§hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zur√ºck. \\(\\square\\)\n\n\n\nWir z√§hlen wie oft der Wasseranteil weniger als 50% betr√§gt.\n\n\nCode\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\n\n\n  \n\n\n\n\nNat√ºrlich gibt es verschiedene Wege, die gleiche Frage zu beantworten.\n\n\nCode\nd %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n\n  \n\n\n\n\n\n\nBeispiel 6.3 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\nWir z√§hlen die Stichproben, die diesen Kriterien entsprechen.\n\n\nCode\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n\n  \n\n\n\n\nü§ñ Ich w√ºrde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.\n\n\nüë®‚Äçüè´ Das wollte ich auch gerade sagen‚Ä¶\n\n\n\nCode\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n\n  \n\n\n\nAnteile von count() k√∂nnte man, wenn man m√∂chte, auch filter() verwenden.\n\n\nCode\nsamples %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n\n  \n\n\n\nFertig üòÑ \\(\\square\\)\n\n\nBeispiel 6.4 (Wasseranteil zwischen 90& und 100%?) Noch ein Beispiel f√ºr eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nSyntaxOutput\n\n\n\n\nCode\nsamples %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betr√§gt. \\(\\square\\)\n\n\n√úbungsaufgabe 6.2 (Wasseranteil h√∂chstens 50%?) ¬†\n\nüë©‚Äçüî¨ Mit welcher Wahrscheinlichkeit ist der Planet h√∂chstens zur H√§lfte mit Wasser bedeckt?\n\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples %&gt;% count(p_grid &lt;= .5)\n\n\n\n  \n\n\n\n\n\n\n\nWir k√∂nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem ‚ÄúGipfel‚Äù des Berges, s. Abbildung¬†6.4.\nF√ºr unsere Stichproben-Postverteilung, samples, s. Abbildung¬†6.2, l√§sst sich der Modus so berechnen:\n\n\nCode\nmap_estimate(samples$p_grid)  \n\n\n\n  \n\n\n\nDabei steht map f√ºr Maximum Aposteriori, also das Maximum der Post-Verteilung.\n\n√úbungsaufgabe 6.3 Bei der Gelegenheit k√∂nnten wir folgende, √§hnliche Fragen stellen:\n\nWas ist der mittlere Sch√§tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane Sch√§tzwert (Median)?\n\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n\n  \n\n\n\n\n\n\n\n\n\n6.4.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSch√§tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall8.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht √ºberschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir m√∂chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist9.\n\n\nCode\nsamples %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n\n  \n\n\n\nLaut unserem Modell k√∂nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu f√ºhren, s. Abbildung¬†6.4.\n\n\n\n\n\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enth√§lt, laut dem Modell?\nDaf√ºr ‚Äúschneiden‚Äù wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\n\nCode\nsamples %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n\n  \n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n\n6.4.3 Zur Erinnerung: Quantile\nBeispiel: Wie gro√ü sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die K√∂rpergr√∂√üe der 25% kleinsten Studentis an, analog f√ºr 50%, 75%, in Inches bzw. in Zentimetern10.\n\n\nCode\n# speed_gender_height &lt;- read.csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n1data(\"speed_gender_height\", package = \"openintro\")\n\nheight_summary &lt;- \n  speed_gender_height %&gt;% \n2  mutate(height_cm = height*2.54) %&gt;%\n  select(height_inch = height, height_cm) %&gt;% \n3  drop_na() %&gt;%\n4  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %&gt;%\n5  group_by(Einheit) %&gt;%\n6  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n\n1\n\nDaten importieren\n\n2\n\nInch in Zentimeter umrechnen\n\n3\n\nZeilen mit fehlenden Werten l√∂schen\n\n4\n\nIn die Langform pivotieren\n\n5\n\nGruppieren nach Einheit (Inch, Zentimeter)\n\n6\n\nQuantile berechnen (Q1, Q2, Q3)\n\n\n\n\n\n  \n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildung¬†6.6 visualisiert die Quantile und die H√§ufigkeitsverteilung.\n\n\n\n\n\n\n\n\nAbbildung¬†6.6: Gr√∂√üenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n\n\n√úbungsaufgabe 6.4 (Welcher Parameterwert ist der wahrscheinlich gr√∂√üte?) √úbersetzen wir ‚Äúwahrscheinlich‚Äù gr√∂√üte in ‚Äúmit einer Wahrscheinlichkeit von 99% gibt es keinen gr√∂√üeren‚Äù.\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples |&gt; \n  summarise(quant99 = quantile(p_grid, p = .99))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der h√∂chste zu erwartende Wasseranteil 0.9.\n\n\n\n\n\n√úbungsaufgabe 6.5 (Welcher Parameterwert ist der wahrscheinlich kleinste?) √úbersetzen wir ‚Äúwahrscheinlich‚Äù kleinste in ‚Äúmit einer Wahrscheinlichkeit von 99% gibt es keinen kleineren‚Äù.\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .01))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 ‚Äì immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\n√úbungsaufgabe 6.6 (Welcher Parameterwert ist der ‚Äúvermutlich‚Äù kleinste?) In der ‚Äúwirklichen‚Äù Welt sind Aussagen nicht immer pr√§zise. Sagen wir, die Chefin der Weltraumbeh√∂rde hat in einem Presse-Statement von der ‚Äúvermutlichen Untergrenze‚Äù hinsichtlich des Wasseranteils gesprochen.\n√úbersetzen wir ‚Äúvermutlich‚Äù kleinste in ‚Äúmit einer Wahrscheinlichkeit von 90% gibt es keinen kleineren‚Äù.\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .1))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 ‚Äì immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\n\n6.4.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht √ºberschritten wird. Das k√∂nnen wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% (von 10000) ab (entferne sie).\nSchaue, was der gr√∂√üte verbleibende Wert ist.\n\n\n\nCode\nsamples %&gt;% \n  arrange(p_grid) %&gt;%   # sortiere\n  slice_head(n = 9000) %&gt;%  # nur die ersten 90%\n  summarise(p90 = max(p_grid))\n\n\n\n  \n\n\n\nDas (ann√§hernd) gleiche Ergebnis liefert quantile():\n\n\nCode\nsamples %&gt;% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n\n  \n\n\n\n\n\n6.4.5 Visualisierung der Intervalle\n\nDefinition 6.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die ‚Äúabzuschneidende‚Äù Wahrscheinlichkeitsmasse h√§lftig auf die beiden R√§nder aufteilen, nennen wir Perzentilintervalle (PI) oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. Abbildung¬†6.7, rechtes Teildiagramm.11 \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\n\n\n(b) Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\nAbbildung¬†6.7: Perzintilintervalle\n\n\n\nDas 10%, 20%, ‚Ä¶ 100%-Quantil12 (auf Basis von samples_k100) sind in Abbildung¬†6.8 illustriert.\n\n\n\n\n\n\nAbbildung¬†6.8: Quantile in 10%-Schritenn durch die Verteilung von samples_k100",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#schiefe-posteriori-verteilungen-sind-m√∂glich",
    "href": "0600-Post.html#schiefe-posteriori-verteilungen-sind-m√∂glich",
    "title": "6¬† Die Post befragen",
    "section": "6.5 Schiefe Posteriori-Verteilungen sind m√∂glich",
    "text": "6.5 Schiefe Posteriori-Verteilungen sind m√∂glich\nNoch einmal zum Globusversuch: Gehen wir von 3 W√ºrfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlie√üen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 W√ºrfe), s. Listing¬†6.4.\n\n\n\n\nListing¬†6.4: Schiefe Post-Verteilung in einer Bayes-Box\n\n\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e6, \n                 weight_by = post_33, \n                 replace = T)\n\n\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\n\n\n\n\n0.79\n1\n0.49\n0.49\n\n\n0.77\n1\n0.46\n0.46\n\n\n1.00\n1\n1.00\n1.00\n\n\n0.92\n1\n0.78\n0.78\n\n\n0.63\n1\n0.25\n0.25\n\n\n0.62\n1\n0.24\n0.24\n\n\n\n\n\n\n\nMit dieser ‚Äúschiefen‚Äù Post-Verteilung k√∂nnen wir gut die Auswirkungen auf das Perzentil- und das H√∂chste-Dichte-Intervall anschauen.\n\n6.5.1 Perzentilintervall\nHier z.B. ein 50%-Perzentilintervall, s. Abb. Abbildung¬†6.9.\n\n\n\n\n\n\n\n\nAbbildung¬†6.9: Schiefe Intervalle: Das PI enth√§lt den wahrscheinlichsten Parameterwert nicht, das HDI schon.\n\n\n\n\n\nEin Perzentilintervall kann, wenn es dumm l√§uft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zur√ºckweisen. Das ist nicht so toll.\nEin Highest-Density-Intervall (HDI13) ist schm√§ler als der Perzintilintervall und enth√§lt immer den wahrscheinlichsten Parameterwert.\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. mit dem Befehl eti ausgeben lassen.\n\n\nCode\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)  # Paket `easystats`\n\n\n\n\n\n\n  \n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.5.2 Intervalle h√∂chster Dichte\n\nDefinition 6.2 (Intervalle h√∂chster Dichte (Highest Density Intervals)) Intervalle h√∂chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schm√§lste Intervall, das den gesuchten Parameter enth√§lt (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten R√§nder nicht mehr gleich gro√ü, im Sinne von enthalten nicht (zwangsl√§ufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen R√§ndern hingegen gleich gro√ü.\nJe symmetrischer die Verteilung, desto n√§her liegen die Punktsch√§tzer aneinander (und umgekehrt), s. Abb. Abbildung¬†6.10.\n\n\n\n\n\n\n\n\nAbbildung¬†6.10: Visualisierung der Punktsch√§tzer bei einer schiefen Post-Verteilung\n\n\n\n\n\nMit dem Befehl hdi kann man sich die Grenzwerte eines HDI, z.B. eines 50%-HDI, ausgeben lassen, s. Tabelle¬†6.4.\n\n\nCode\nsamples %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\n\nTabelle¬†6.4: 50%-HDI f√ºr unser Globusmodell\n\n\n\n\n  \n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfl√§che) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI).",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "6¬† Die Post befragen",
    "section": "6.6 Fazit",
    "text": "6.6 Fazit\n\n6.6.1 Intervalle h√∂chster Dichte vs.¬†Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle √§hnlich\nPerzentilintervalle sind verbreiteter\nIntervalle h√∂chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle h√∂chster Dichte sind die schmalsten Intervalle f√ºr eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n6.6.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datensatz samples, s. Listing¬†6.3. Sagen wir, wir haben 6 Treffer bei 9 W√ºrfen erzielt.\nLageparameter: Welchen mittleren Wasseranteil kann man erwarten?\n\n\nCode\nsamples %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n\n  \n\n\n\nStreuungsparameter: Wie unsicher sind wir in der Sch√§tzung des Wasseranteils?\n\n\nCode\nsamples %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler\n\n\n\n  \n\n\n\nAnstelle der Streuungsparameter ist es aber √ºblicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel f√ºr einen Parameter, einer unbekannten Gr√∂√ües eines Modells.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "6¬† Die Post befragen",
    "section": "6.7 Aufgaben",
    "text": "6.7 Aufgaben\n\n6.7.1 Papier-und-Bleistift-Aufgaben\n\n\nkekse03\nbfi10\nKaefer2\nmtcars-post2a\nrethink3e1-7-paper\nmtcars-post3a\nmtcars-post3a\nmtcars-post_paper\nfattails1\nfattails2\neti-hdi\n\n\n\n6.7.2 Aufgaben, bei denen man einen Computer ben√∂tigt\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nReThink3e1-7\nWeinhaendler\nRethink3m1\nRethink3m2\ngroesse2\ngroesse1\nAnteil-Apple\nKung-height\nzwielichter-dozent-bayes",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "6¬† Die Post befragen",
    "section": "6.8 ‚Äî",
    "text": "6.8 ‚Äî\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#footnotes",
    "href": "0600-Post.html#footnotes",
    "title": "6¬† Die Post befragen",
    "section": "",
    "text": "Die Anzahl der Gitterwerte ist nicht Teil des Modells, streng genommen; die Anzahl der Gitterwerte entscheiden nur √ºber die Genauigkeit der Post-Verteilung.‚Ü©Ô∏é\nAlternativ kann man auf die Funktion √ºber das R-Paket {prada} zugreifen.‚Ü©Ô∏é\nnaja, nicht unbedingt formsch√∂n, aber mir fiel kein dritter Vorzug ein.‚Ü©Ô∏é\nModellparameter genannt‚Ü©Ô∏é\nVorsicht beim Ausdrucken.‚Ü©Ô∏é\nauch Grid-Methode genannt‚Ü©Ô∏é\nEine gute Einf√ºhrung in die Hintergr√ºnde findet sich bei McElreath (2020).‚Ü©Ô∏é\nTats√§chlich gibt es eine Vielzahl an Begriffen, die in der Literatur nicht immer konsistent verwendet werden, etwa Kompatibilit√§tsintervall, Ungewissheitsintervall, Passungsbereich.‚Ü©Ô∏é\nVielleicht damit es genug Berge zum Schifahren gibt.‚Ü©Ô∏é\n1 Inch entspricht 2.54cm‚Ü©Ô∏é\nHier auf Basis der Post-Verteilung samples.‚Ü©Ô∏é\nd.h. die Dezile‚Ü©Ô∏é\nAuch als Highest Hensity Posterior Interval (HDPI) bezeichnet.‚Ü©Ô∏é",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html",
    "href": "0800-gauss.html",
    "title": "7¬† Gauss-Modelle",
    "section": "",
    "text": "7.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "7¬† Gauss-Modelle",
    "section": "",
    "text": "7.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n7.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nein Gau√ümodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n7.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.1 bis 4.3.\n\n\n7.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúModellg√ºte‚Äù\nStatistik1, Kap. ‚ÄúPunktmodelle 2‚Äù\nStatistik1, Abschnitt ‚ÄúNormalverteilung‚Äù\n\n\n\n7.1.5 Ben√∂tigte R-Pakete\nF√ºr rstanarm wird ggf. weitere Software ben√∂tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, m√ºssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio m√ºssen Sie die (ben√∂tigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Modelle berechnen\nlibrary(easystats)  # Statistik-Komfort\nlibrary(DataExplorer)  # Daten verbildlichen\nlibrary(ggpubr)  # Daten verbildlichen\nlibrary(hexbin)  # stat_bin_hex ggplot2\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nAb diesem Kapitel ben√∂tigen Sie das R-Paket rstanarm. \\(\\square\\)\n\n\n\n\n7.1.6 Ben√∂tigte Daten\nWir ben√∂tigen den Datensatz !Kung. Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\n\n\nCode\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd &lt;- read.csv(Kung_path) \n\nhead(d)\n\n\n\n  \n\n\n\nDatenquelle\n Download \n\n\n7.1.7 Einstieg\n\nBeispiel 7.1 (Was war noch mal eine Normalverteilung?) In diesem Kapitel ben√∂tigen Sie ein gutes Verst√§ndnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! \\(\\square\\)\n\n\nBeispiel 7.2 (Was war noch mal eine Posteriori-Verteilung?) In diesem Kapitel befragen wir die Post-Verteilung f√ºr ein normalverteilte Zufallsvariable, n√§mlich die K√∂rpergr√∂√üe der !Kung San. Was war noch mal eine Post-Verteilung und wozu ist sie gut? \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-gro√ü-sind-die-kung-san",
    "href": "0800-gauss.html#wie-gro√ü-sind-die-kung-san",
    "title": "7¬† Gauss-Modelle",
    "section": "7.2 Wie gro√ü sind die !Kung San?",
    "text": "7.2 Wie gro√ü sind die !Kung San?\nDieser Abschnitt basiert slee auf McElreath (2020), Kap. 4.3.\n\n7.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. Abbildung¬†7.1.\n\nThe «ÉKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names «ÉKung («ÉXun) and Ju are variant words for ‚Äòpeople‚Äô, preferred by different «ÉKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of «ÉKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\n\n\n\n\n\n\n\n\n\n\n\n(a) Kung People\n\n\n\n\n\n\n\n\n\n\n\n(b) Verbreitung der Kung-Sprachen\n\n\n\n\n\n\n\nAbbildung¬†7.1: Die !Kung im s√ºdlichen Afrika\n\n\n\nQuelle\nQuelle: By Andrewwik.0 - Own work, CC BY-SA 4.0,\nWir interessieren uns f√ºr die Gr√∂√üe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als d2.\n\n\nCode\nd2 &lt;- d %&gt;% \n  filter(age &gt;= 18)\n\nnrow(d2)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tats√§chlich recht easy, s. Tabelle¬†7.1.\n\n\nCode\ndescribe_distribution(d2)\n\n\n\n\n\n\nTabelle¬†7.1: Statistiken der metrischen Variablen im Kung-Datensatz\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\n‚àí0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\n‚àí0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\n‚àí0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\n‚àí2.00\n352.00\n0\n\n\n\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus {DataExplorer}), s. Abbildung¬†7.2.\n\n\nCode\nplot_density(d2)\n\n\n\n\n\n\n\n\nAbbildung¬†7.2: Verteilungen der Variablen im Kung-Datensatz. Gr√∂√üe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n\n\n\n7.2.2 Wir gehen apriori von normalverteilter Gr√∂√üe Der !Kung aus\nForschungsfrage: Wie gro√ü sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also f√ºr den Mittelwert der K√∂rpergr√∂√üe (erwachsener Kung beider Geschlechter), \\(\\mu\\).\n\n\n\nMensch, Wikimedia Commons1\n\n\nWir sind uns √ºber diesen Mittelwert nicht sicher2, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178 cm und Streuung von 20 cm, s. Gleichung¬†7.1.\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{7.1}\\]\nGleichung¬†7.1 definiert ein Modell: Unsere Vorstellung der mittleren (‚Äútypischen‚Äù) K√∂rpergr√∂√üe der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.3 In einer echten Untersuchung sollte man einen inhaltlichen Grund f√ºr einen Priori-Wert haben. Oder man w√§hlt ‚Äúschwach informative‚Äù Prioris, wie das {rstanarm} tut: Damit l√§sst man kaum Vorab-Information in das Modell einflie√üen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern bei der K√∂rpergr√∂√üe).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der K√∂rpergr√∂√üen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. Dar√ºber hinaus ist eine Normalverteilung nicht unplausibel.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#die-exponentialverteilung",
    "href": "0800-gauss.html#die-exponentialverteilung",
    "title": "7¬† Gauss-Modelle",
    "section": "7.3 Die Exponentialverteilung",
    "text": "7.3 Die Exponentialverteilung\n\n7.3.1 Die Apfel-f√§llt-nicht-weit-vom-Stamm-Verteilung\nDarf ich vorstellen ‚Ä¶\nBevor wir unser Kung-Modell spezifizieren k√∂nnen, sollten wir noch √ºberlegen, welches Vorab-Wissen wir zur Streuung um den Mittelwert herum haben. Da wir uns nicht 100% sicher zur gesuchten Gr√∂√üe sind, m√ºssen wir diese Ungewissheit quantifizieren. Wir m√ºssen also angeben, wie gro√ü die Streuung um den Mittelwert unserer Meinung nach ist. Hier werden wir eingestehen, dass wir uns auch nicht 100% sicher sind, wie gro√ü die Streuung exakt ist. Also geben wir eine Verteilung f√ºr die Streuung an, um diese Ungewissheit zu quantifizieren.\nEtwas Wissen √ºber diese Verteilung haben wir:\n\nEine Streuung muss positiv sein (es gibt keine negative Streuung).\nEine Gleichverteilung der Streuung ist vielleicht m√∂glich, aber nicht sehr plausibel.\nWenn wir der Meinung sind, der Mittelwert betrage ‚Äúungef√§hr 178 cm‚Äù, so halten wir 180 cm als K√∂rpergr√∂√üe einer erwachsenen Person f√ºr plausibel, aber 18000 cm f√ºr (praktisch) unm√∂glich und schon 200 cm f√ºr recht unplausibel. Also: Je gr√∂√üer die die Abweichung vom Mittelwert, desto unplausibler der Wert der K√∂rpergr√∂√üe.\n\nDiese Anforderungen4 spiegeln sich in Abbildung¬†7.3 wider; die eine Exponentialverteilung zeigt (mit dem Parameter \\(\\lambda=1\\)), Eine Exponentialverteilung erf√ºllt unsere W√ºnsche ziemlich gut. Au√üerdem zeigt die Abbildung verschiedene Quantile, wie das 95%-Quantil, das bei 3 liegt; 95% der Werte dieser Verteilung sind also nicht gr√∂√üer als 3.\n\n\n\n\n\n\n\n\nAbbildung¬†7.3: Die Exponentialverteilung: Die meisten √Ñpfel fallen nicht weit vom Stamm ‚Ä¶\n\n\n\n\n\nF√ºr eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung. Sie hat einige n√ºtzliche Eigenschaften:\n\nEine Exponentialverteilung ist nur f√ºr positive Werte, \\(x&gt;0\\), definiert.\nSteigt X um eine Einheit, so √§ndert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (‚Äúlambda‚Äù).\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (‚ÄúGestrecktheit‚Äù) der Verteilung an.\nJe gr√∂√üer die Rate \\(\\lambda\\), desto schneller der ‚ÄúVerfall‚Äù der Kurve und desto kleiner die Streuung und der Mittelwert der Verteilung (und umgekehrt: Je gr√∂√üer \\(1/\\lambda\\), desto gr√∂√üer die Streuung und der Mittelwert der Verteilung.)\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren Pl√§nen passt.\n\n\n7.3.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zur√ºckzuf√ºhren, s. Abbildung¬†7.4.\n\n\n\n\nlambda = 2lambda = 1lambda = 1/2lambda = 1/4lambda = 1/8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†7.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWie wir in Abbildung¬†7.4 sehen, k√∂nnte eine Exponentialverteilung mit \\(\\lambda=1/8\\) grob passen f√ºr unser !Kung-Beispiel: Bei einer Exponentialverteilung mit Rate \\(\\lambda=1/8\\) ist der Median bei ca. 5.5 cm, also einer Streuung (\\(\\sigma\\), typischen Abweichung vom Mittelwert) von 5.5 cm. Der Median ist der ‚Äúmittlere Wert‚Äù der Verteilung, also der Wert, bei dem 50% der Werte kleiner und 50% der Werte gr√∂√üer sind. Insofern eignet sich der Median gut als Sch√§tzer f√ºr einen ‚Äútypischen‚Äù Wert der Verteilung.\n\n\n\n\n\n\nHinweis\n\n\n\nDie ‚Äúrichtigen‚Äù Priori-Verteilung zu finden, bzw. die richtigen Parameter f√ºr die Priori-Verteilung zu w√§hlen, ist nicht m√∂glich, denn es gibt nicht die eine, richtige Priori-Verteilung. Eine ‚Äúgut passende‚Äù Verteilung zu finden, ist nicht immer einfach. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu w√§hlen, die einen breiteren Raum an m√∂glichen Werten zul√§sst. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie mehrere Meter K√∂rpergr√∂√üe Streuung, erlauben.\n\n\nMan kann sich die Quantile der Exponentialverteilung mit qexp() ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, f√ºr den man das Quantil haben m√∂chte. (;it pexp() kann man sich analaog die die Verteilungsfunktion ausgeben lassen.) Mit rate wird \\(\\lambda\\) (lambda) bezeichnet.5\nDieser Aufruf zum Beispiel, qexp(p = .5, rate = 1/8), gibt uns das 50%-Quantil einer Exponentialverteilung mit Rate (\\(\\lambda\\)) 1/8 zur√ºck, ca. 5.5: Mit einer Wahrscheinlichkeit von 50% wird ein Wert von 5.5 nicht √ºberschritten bei dieser Verteilung.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich auch ausgeben.\n\n\nCode\nqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2025425 29.5110356\n\n\nDiese Grenzen scheinen hinreichend weit, das wir noch von den Daten √ºberrascht werden k√∂nnen, aber schmal genug, um unsinnige Werte auszuschlie√üen. Ein guter Start! Weiter geht‚Äôs!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "7¬† Gauss-Modelle",
    "section": "7.4 Unser Gauss-Modell der !Kung",
    "text": "7.4 Unser Gauss-Modell der !Kung\nüì∫ Teil 1\n\n7.4.1 Modelldefinition\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr den Parameter \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior f√ºr den Parameter \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn Abbildung¬†7.5 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\n\n\n\nAbbildung¬†7.5: Unser (erstes) Kung-Modell (m41)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDieses Modell hat zwei Parameter, \\(\\mu\\) und \\(\\sigma\\). \\(\\square\\)\n\n\n\n\n7.4.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie K√∂rpergr√∂√üen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})   \\qquad{\\text{Likelihood}}\\]\n\n\n7.4.3 Prioris der Parameter\nDer Mittelwert der K√∂rpergr√∂√üe sei normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)} \\qquad{\\text{Prior}}\\]\nDie Streuung \\(\\sigma\\) der Gr√∂√üen sei exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)} \\qquad{\\text{Prior}}\\]\n\n\n7.4.4 m41: fertig!\nJetzt haben wir unser Modell (m41) definiert!\nWeil es so sch√∂n ist, schreiben/zeichnen wir es hier noch einmal auf, Gleichung¬†7.2, Abbildung¬†7.6.\n\n\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) & \\text{Likelihood}  \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) & \\text{Prior} \\\\\n\\sigma &\\sim \\mathcal{E}(1/8) & \\text{Prior}\n\\end{aligned}\n\\tag{7.2}\\]\n\n\n\n\n\n\n\nAbbildung¬†7.6: Modellschema f√ºr das Modell m41\n\n\n\n\n\nZur Berechnung von m41 nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich kr√§ftig der Bursche, der soll die Arbeit f√ºr uns tun. Der Golem h√∂rt auf den Namen rstanarm6.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#zuf√§llige-motivationsabschnitt",
    "href": "0800-gauss.html#zuf√§llige-motivationsabschnitt",
    "title": "7¬† Gauss-Modelle",
    "section": "7.5 Zuf√§llige Motivationsabschnitt",
    "text": "7.5 Zuf√§llige Motivationsabschnitt\n\n\n\nGut gemacht!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-gr√∂√üen-modells-m41",
    "href": "0800-gauss.html#posteriori-verteilung-des-gr√∂√üen-modells-m41",
    "title": "7¬† Gauss-Modelle",
    "section": "7.6 Posteriori-Verteilung des Gr√∂√üen-Modells, m41",
    "text": "7.6 Posteriori-Verteilung des Gr√∂√üen-Modells, m41\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m417.\n\n\nCode\n1m41 &lt;- stan_glm(height ~ 1, data = d2, refresh = 0)\n2m41_post &lt;- as_tibble(m41)\n3names(m41_post) &lt;- c(\"mu\", \"sigma\")\n\n\n\n1\n\nBayes-Regressionsmodell berechnen\n\n2\n\nModellergebnis in Tabelle umwandeln\n\n3\n\nSch√∂nere Namen f√ºr die Spalten geben\n\n\n\n\nDas Argument refresh = 0 ist nur eine Nebensache, aber es ist praktisch, da es verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdr√ºcke. stan_glm8 ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein ‚Äúrichtiges‚Äù Regressionsmodell. Man k√∂nnte sagen, wir haben eine AV (K√∂rpergr√∂√üe), aber keine UV (keine Pr√§diktoren). Gl√ºcklicherweise k√∂nnen wir auch solche ‚Äúarmen‚Äù Regressionsmodelle formulieren: av ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen m√∂chte, aber keine Pr√§diktoren hat (das soll die 1 symbolisieren). F√ºr das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung (defaults) der Prioris von rstanarm zur√ºck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade w√§re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die gemeinsame Posteriori-Verteilung von m41, s. Abbildung¬†7.7\n\nFliesendiagrammStreudiagrammHistogramm\n\n\nGemeinsame Post-Verteilung von Mittelwert und Streuung\n\n\nCode\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\n\n\n\nAbbildung¬†7.7: Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m42\n\n\n\n\n\nDa das Modell zwei Parameter hat, k√∂nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen k√∂nnen die Parameter korreliert sein.\nAbbildung¬†7.7 erlaubt uns, f√ºr jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\n\n\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m42, s. Abbildung¬†7.8.\n\n\n\n\n\n\n\n\nAbbildung¬†7.8: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\n\n\n\nUnd hier kommt die Post-Verteilung nur des Mittelwerts.\nNat√ºrlich k√∂nnen wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. Abbildung¬†7.9.\n\n\n\n\n\n\n\n\nAbbildung¬†7.9: Die Post-Verteilung von mu in m42; ein Balkendiagramm bietet sich an.\n\n\n\n\n\n\n\n\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung f√ºr \\(\\mu\\) und eine f√ºr \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, f√ºr die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte f√ºr \\(\\mu\\) und \\(\\sigma\\) klein: Die gro√üe Stichprobe hat die Priori-Werte √ºberstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so k√∂nnen wir interessante Fragen stellen.\n\n\n7.6.1 Hallo, Posteriori-Verteilung\n‚Ä¶ wir h√§tten da mal ein paar Fragen an Sie. üïµ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person gr√∂√üer als 1,55m?\nWelche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?\nWas ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der ‚ÄúBest Guess‚Äù?\n\nAntworten folgen etwas weiter unten.\nAbschlie√üend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), Abbildung¬†7.10.\n\n\n\n\n\n\n\n\nAbbildung¬†7.10: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen f√ºr mu und f√ºr sigma\n\n\n\n\n\n\n\n7.6.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() k√∂nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - √§hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zur√ºck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so: stan_glm(AV ~ UV, data = meine_daten).\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum Gr√∂√üenmittelwert (von Stan √ºbernommen)\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der Gr√∂√üen (von Stan √ºbernommen)\n\n\n7.6.3 Ausgabe von stan_glm()\nWir k√∂nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir k√∂nnen es aber auch komfortabler haben ‚Ä¶ Mit dem Befehl parameters kann man sich die gesch√§tzten Parameterwerte einfach ausgeben lassen (s. Abbildung¬†7.7).\n\n\nCode\nm41 &lt;- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.77, 155.40)\n100%\n1.000\n2856.00\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem sch√§tzt den Gr√∂√üenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.77 bis 155.4 sch√§tzt. Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu sp√§ter mehr.\n\n\n\n\n\n\nHinweis\n\n\n\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren ü§ì Wer N√§heres wissen will, findet hier einen Anfang. Au√üerdem sei an McElreath (2020) und Gelman et al. (2021) verwiesen. \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "7¬† Gauss-Modelle",
    "section": "7.7 Wie tickt stan_glm()?",
    "text": "7.7 Wie tickt stan_glm()?\n\n\n\n\n\n\n Quelle\n\nHier ein paar Kerninfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan f√ºr uns bereit.\nstan_glm() ist f√ºr die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) sch√§tzen, so hat man man ‚Ä¶ eine Regression ohne Pr√§diktor.\nEine Regression ohne Pr√§diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also f√ºr die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\n\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n7.7.1 Sch√§tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die Gr√∂√üen, f√ºr die wir eine Priori-Verteilung annehmen. Au√üerdem w√§hlen wir einen einen Likelihood-Funktion, so dass wir die Likelihood berechnen k√∂nnen. Auf dieser Basis sch√§tzen wir dann die Post-Verteilung. Ich sage sch√§tzen, um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren Sch√§tzungen) einfach mit parameters(modellname) auslesen.\n\n\n7.7.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, k√∂nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_m41:\n\n\nCode\npost_m41 &lt;- as_tibble(m41)\nhead(post_m41)\n\n\n\n  \n\n\n\nIn einer Regression ohne Pr√§diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss √ºber unsere Sch√§tzwerte zu \\(\\mu\\) (der K√∂rpergr√∂√üe).\n\n√úbungsaufgabe 7.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\n\nnames(post_m41) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist pr√§gnanter\n\npost_m41 %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlie√üen, dass die Kung im Schnitt gr√∂√üer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. \\(\\square\\)\n\n\n\n\n\n√úbungsaufgabe 7.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nnames(post_m41) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist pr√§gnanter\n\npost_m41 %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nOh, diese Hypothese k√∂nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlie√üen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschlie√üen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\n\n\nBeispiel 7.3 (Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell m41?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\npost_m41 %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n  \n\n\n\n\n\n\n\n\n√úbungsaufgabe 7.3 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\npost_m41 %&gt;% \n  eti()\n\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\n\n\n\n√úbungsaufgabe 7.4 (Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nm41 %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.77, 155.40)\n100%\n1.000\n2856.00\nNormal (154.60 +- 19.36)\n\n\n\n\n\nSeeing is believing, s. Abbildung¬†7.11.\n\n\nCode\nm41 %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nAbbildung¬†7.11: Parameter von m41, nur einer: der Intercept\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren K√∂rpergr√∂√üe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\n\n\n\n√úbungsaufgabe 7.5 (Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der ‚ÄúBest Guess‚Äù?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\nparameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n\n\n\nüèãÔ∏è √Ñhnliche Fragen bleiben als √úbung f√ºr die Lesis. ü§ì\n\n\n7.7.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt f√ºr uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m41)\n## Priors for model 'm41' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden daf√ºr die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage f√ºr die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht ‚Äúpures Bayes‚Äù, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte w√§ren auch denkbar.\n\n\n\n\n\n\nStandardwerte von stan_glm\n\n\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (f√ºr \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals ‚ÄúStreuung‚Äù, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen. \\(\\square\\)\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu w√§hlen, dass man nicht √ºbergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlie√üen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflie√üen zu lassen und eigene Entscheidungen zu begr√ºnden. H√§ufig sind mehrere Entscheidungen m√∂glich. M√∂chte man lieber vorsichtig sein, weil man wenig √ºber den Gegenstand wei√ü, dann k√∂nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die ‚Äúschwachinformativ‚Äù ist, also nur wenig Priori-Information in das Modell einflie√üen l√§sst.\n\n\n\n\n7.7.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund f√ºr Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu z√§hlen hat. Au√üerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister pr√ºfen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier Durchf√ºhrungen (auch ‚ÄúKetten‚Äù engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist ‚Äúdumm gelaufen‚Äù. An dieser Stelle schauen wir uns die Ketten nicht n√§her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. M√∂chte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit.\n\n\nCode\nm41a &lt;- stan_glm(height ~ 1, \n                 data = d2, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m41a)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#modell-m42-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m42-unsere-priori-werte",
    "title": "7¬† Gauss-Modelle",
    "section": "7.8 Modell m42: unsere Priori-Werte",
    "text": "7.8 Modell m42: unsere Priori-Werte\nüì∫ Teil 2\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflie√üen, in unserem zweiten Kung-Modell, m42.\n\n7.8.1 m42\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.9 Dieses Mal geben wir die Priori-Werte explizit an, Tabelle¬†7.2.\n\n\nCode\nm42 &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\n\n\n\n\n\nTabelle¬†7.2: Parameter von m42 mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482.00\nNormal (178 +- 20)\n\n\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in Tabelle¬†7.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige F√§higkeit im Studium. ü§ì\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m41 und m42! Was f√§llt Ihnen auf? Nichts? Gut! Tats√§chlich liefern beide Modelle sehr √§hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigerma√üen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gew√§hlt waren.\n\n\n\n\n7.8.2 Posteriori-Verteilung und Parameter plotten\nLeider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zur√ºck.\n\nüë®‚Äçüè´ B√∂ser Golem!\n\n\nü§ñ Beim n√§chsten Mal strenge ich mich mehr an!\n\nDaher m√ºssen wir die Ausgabe des Stan-Golemns erst in eine sch√∂ne Tabelle umwandeln:\n\n\nCode\nm42_tibble &lt;-\n  as_tibble(m42)\n\nhead(m42_tibble)\n\n\n\n  \n\n\n\nAu√üerdem ist der Name der ersten Spalte eigentlich unzul√§ssig, da Spaltennamen in R nicht mit Sonderzeichen anfangen d√ºrfen (sondern mit Buchstaben). Daher m√ºssen wir den Namen mit ‚ÄúSamthandschuhen‚Äù anpacken. Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln m√ºssen, s. die folgende Syntax.\n\nMit {ggpubr}Mit {ggplot}\n\n\n\n\nCode\nm42_tibble |&gt; \n  gghistogram(x = \"`(Intercept)`\")  # Aus dem Paket \"ggpubr\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nm42_tibble |&gt; \n  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nAls Ausblick: Ein Vergleich mehrerer Priori-Werte w√§re auch n√ºtzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gew√§hlten Priori-Werte zu √ºberzeugen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "7¬† Gauss-Modelle",
    "section": "7.9 Fazit",
    "text": "7.9 Fazit\n\n\n7.9.1 Zusammenfassung\nWir haben die Posteriori-Verteilung f√ºr ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Pr√§diktoren, betrachtet. Die Zielvariable, K√∂rpergr√∂√üe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. F√ºr \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung f√ºr \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n7.9.2 Botschaft von einem Statistiker\n\n\n\nüß° Bleiben Sie dran!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "href": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "title": "7¬† Gauss-Modelle",
    "section": "7.10 Vertiefung: Wahl der Priori-Werte",
    "text": "7.10 Vertiefung: Wahl der Priori-Werte\nüèéÔ∏è Dieser Abschnitt ist eine VERTIEFUNG und nicht pr√ºfungsrelevant. üèé\n\n7.10.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\n\nüí≠ Was denkt der Golem (m41) apriori von der Gr√∂√üe der !Kung?\nü¶æ Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voil√†:\n\n\nCode\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MW¬±3SD\",\n       x = \"Gr√∂√üe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\n\n\n\n\nQuellcode\n\n\n7.10.2 Priori-Werte pr√ºfen mit der Priori-Pr√§diktiv-Verteilung\n\nDie Priori-Pr√§diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo k√∂nnen wir pr√ºfen, ob die Priori-Werte vern√ºnftig sind.\n\nDie Priori-Pr√§diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Gr√∂√üenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\n\nCode\nanteil_gro√üer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_gro√üer_kung\n\n\n\n  \n\n\n\nü§î Sehr gro√üe Buschleute? 17 Prozent sind gr√∂√üer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsl√§ufig ein schlechter Prior sein.\n\n\n7.10.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n\n\n\n\n7.10.4 Extrem vage Priori-Verteilung f√ºr die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\n\n\n\n\nDie Streuung der Gr√∂√üen ist weit:\n\n\nCode\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nü§î Das Modell geht apriori von ein paar Prozent Menschen mit negativer Gr√∂√üe aus. Ein Haufen Riesen üëπ werden auch erwartet.\nü§Ø Vage (flache, informationslose, ‚Äúneutrale‚Äù, ‚Äúobjektive‚Äù) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "7¬† Gauss-Modelle",
    "section": "7.11 Aufgaben",
    "text": "7.11 Aufgaben\n\n7.11.1 Papier-und-Bleistift-Aufgaben\n\n\nexp-tab\nexp-tab2\nnorms-sd\nsmall-wide-normal\nexp1\ndistros\nmtcars-post_paper\ngroesse03\npupil-size2\ngroesse04\nReThink4e2\nPriorwahl1\n\n\n\n7.11.2 Aufgaben, f√ºr die man einen Computer ben√∂tigt\n\nstan_glm01\nReThink4e1\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "7¬† Gauss-Modelle",
    "section": "7.12 ‚Äî",
    "text": "7.12 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#footnotes",
    "href": "0800-gauss.html#footnotes",
    "title": "7¬† Gauss-Modelle",
    "section": "",
    "text": "Bildquelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, 3.0‚Ü©Ô∏é\nDarum machen wir hier ja die ganz Show!‚Ü©Ô∏é\nDer Autor des zugrundeliegenden Fachbuchs, Richard McElreath gibt 178cm als seine K√∂rpergr√∂√üe an.‚Ü©Ô∏é\n‚ÄúDesiderata‚Äù‚Ü©Ô∏é\nEs gibt auch [Online-Apps, die diese Werte ausgeben](https://homepage.divms.uiowa.edu/~mbognar/applets/exp-like.html.‚Ü©Ô∏é\nHey, ich habe ihn diesen Namen nicht gegeben.‚Ü©Ô∏é\nm wie Modell und 4, weil das Modell in Kapitel 4 von McElreath (2020) in √§hnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.‚Ü©Ô∏é\naus dem R-Paket rstanam, das zuvor installiert und gestartet sein muss, bevor Sie den Befehl nutzen k√∂nnen‚Ü©Ô∏é\nHey Stan, los, an die Arbeit!‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html",
    "href": "0900-lineare-modelle.html",
    "title": "8¬† Einfache lineare Modelle",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "8¬† Einfache lineare Modelle",
    "section": "",
    "text": "8.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Post-Verteilung f√ºr einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder Streuungsma√üe und auch Sch√§tzintervalle - aus der Post-Verteilung herauslesen\nk√ºnftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n8.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4.\n\n\n8.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\n\n\n\n8.1.5 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine √úbersicht aller Funktionen des Pakets.1\n\n\n8.1.6 Ben√∂tigte Daten\nIn diesem Kapitel ben√∂tigen wir den Datensatz zu den !Kung-Leuten, Howell1a, McElreath (2020). Sie k√∂nnen ihn hier herunterladen.\n Download \n\n\nCode\n1Kung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\n2d &lt;- read.csv(Kung_path)\n\n3d2 &lt;- d %&gt;% filter(age &gt; 18)\n\n\n\n1\n\nPfad zum Datensatz; Sie m√ºssen online sein, um die Daten herunterzuladen.\n\n2\n\nDaten einlesen\n\n3\n\nAuf Erwachsene Personen begrenzen (d.h. Alter &gt; 18)\n\n\n\n\n\n\n8.1.7 Einstieg\n\nBeispiel 8.1 (Grundkonzepte der linearen Regression) Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! \\(\\square\\)\n\n\nBeispiel 8.2 (Was ist eine Post-Verteilung und wozu ist sie gut?) Erkl√§ren Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. \\(\\square\\)\n\n\n\n8.1.8 √úberblick\nDieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die K√∂rpergr√∂√üe auf das Gewicht zur√ºckgef√ºhrt wird; also ein sehr eing√§ngiges Modell.\nNeu ist dabei lediglich, dass die Parameter des Modells - \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) - jetzt √ºber eine Post-Verteilung verf√ºgen. Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik. Die ‚Äúnormale‚Äù Regression hat uns nur einzelne Werte f√ºr die Modellparameter geliefert (‚ÄúPunktsch√§tzer‚Äù). Mit Bayes haben wir eine ganz Verteilung pro Parameter.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.2 Post-Verteilung der Regression",
    "text": "8.2 Post-Verteilung der Regression\n\n8.2.1 Einfache Regression\nDie (einfache) Regression pr√ºft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenh√§ngen. Je mehr sie zusammenh√§ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). H√§ngen \\(X\\) und \\(Y\\) zusammen, hei√üt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).2\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y), Abbildung¬†8.1.\n\nCode\nd2 %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\nCode\nggscatter(d2,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\") \n\n\n\n\n\n\nMit ggplot2Mit ggpubr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†8.1: Der Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y)\n\n\n\n\n\n8.2.2 Statistiken zum !Kung-Datensatz\nDie Daten k√∂nnen Sie hier herunterladen.\nTabelle¬†8.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path &lt;- \"data/Howell1a.csv\"  \nd &lt;- read_csv(Kung_path)  \n\nd2 &lt;- d %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(d2)\n\n\n\n\n\n\nTabelle¬†8.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus Tabelle¬†8.1 abzulesen ist, betr√§gt das mittlere K√∂rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n\n8.2.3 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n8.2.3.1 Gibt es fehlende Werte?\nNein, s. Abb. Abbildung¬†8.2.\n\n\nCode\nd2 %&gt;% plot_missing()\n\n\n\n\n\n\n\n\nAbbildung¬†8.2: Fehlende Werte - fehlen.\n\n\n\n\n\n\n\n8.2.3.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. Abbildung¬†8.3.\n\n\nCode\nd2 %&gt;% plot_histogram()\n\n\n\n\n\n\n\n\nAbbildung¬†8.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n\n8.2.3.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. Abbildung¬†8.4.\n\n\nCode\nd2 %&gt;% plot_bar()\n\n\n\n\n\n\n\n\nAbbildung¬†8.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n\n8.2.3.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in Abbildung¬†8.5 dargestellt.\n\n\nCode\nd2 %&gt;% plot_correlation()\n\n\n\n\n\n\n\n\nAbbildung¬†8.5: Korrelationsmatrix\n\n\n\n\n\n\n√úbungsaufgabe 8.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(d2). \\(\\square\\)\n\n\n\n\n8.2.4 Pr√§diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor ‚Äúzentrieren‚Äù, engl. to center). Wenn man den Pr√§diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\beta_0\\), einfacher zu verstehen. In einem Modell mit zentriertem Pr√§diktor (weight) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. W√ºrde man weight nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman et al. (2021), Kap. 10.4, 12.2.\nMan zentriert eine Variable \\(X\\), indem man von \\(x_i\\) den Mittelwert \\(\\bar{x}\\) abzieht: \\(x_i - \\bar{x}\\).\n\n\nCode\nd3 &lt;-\n  d2 %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\nMit Hilfe von center() aus {easystats} kann man sich das Zentrieren auch erleichtern.\n\n\nCode\nd3 &lt;- \n  d2 %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\n‚àí9\n\n\n137\n32\n65\n0\n‚àí13\n\n\n\n\n\n\n\nWie man sieht, wird die Verteilung von weight durch die Zentrierung ‚Äúzur Seite geschoben‚Äù: Der Mittelwert von weight_c (das zentrierte Gewicht) liegt jetzt bei 0, s. Abbildung¬†8.6.\n\n\n\n\n\n\n\n\nAbbildung¬†8.6: Das Zentrieren √§ndert die Verteilungsform nicht, sondern ‚Äúschiebt‚Äù die Verteilung nur zur Seite\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem Pr√§diktor ist, nicht d2.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m43-zentrierter-pr√§diktor",
    "href": "0900-lineare-modelle.html#modell-m43-zentrierter-pr√§diktor",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.3 Modell m43: zentrierter Pr√§diktor",
    "text": "8.3 Modell m43: zentrierter Pr√§diktor\nüì∫ Pr√§diktoren zentrieren\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was w√§re wohl die K√∂rpergr√∂√üe? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n8.3.1 Modelldefinition von m43\nF√ºr jede Auspr√§gung des Pr√§diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung f√ºr die abh√§ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte f√ºr die Steigung \\(\\beta_1\\) und den Achsenabschnitt \\(\\beta_0\\) der Regressionsgeraden. Au√üerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Gr√∂√üe (height) angibt; dieser Wert wird als exonentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\). Theorem¬†8.1 stellt die Modelldefinition dar.\n\nTheorem 8.1 (Modelldefinition) \\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}{\\beta_0} & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}{\\beta_1}  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\quad \\square\\]\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnitt (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ü§∑\n\n\n\n\n8.3.2 Likelihood, m43\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m43 ist √§hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines ‚ÄúIndex-i‚Äù am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\n‚ÄúDie Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))‚Äù.\n\n\n\n8.3.3 Regressionsformel, m43\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\beta_0\\) und \\(\\beta_1\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der Pr√§diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\n‚ÄúDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\beta_0\\) und \\(\\beta_1\\) mal \\(\\text{weight}_i\\)‚Äù.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta_1\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\beta_0\\) gibt an, wie gro√ü \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n8.3.4 Priori-Werte des Modells m43\n\\[\\begin{align*}\n\\color{blue}\\beta_1 & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta_1  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen. \\(\\beta_0\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine ‚ÄúRegression ohne Pr√§diktoren‚Äù berechnet haben. \\(\\sigma\\) ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel. Da height nicht zentriert ist, der Mittelwert von \\(\\beta_0\\) bei 178 und nicht 0. \\(\\beta_1\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist. Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.4 Die Post-Verteilung befragen",
    "text": "8.4 Die Post-Verteilung befragen\nüì∫ Post-Verteilung auslesen 1\nüì∫ Post-Verteilung auslesen 2\n\n8.4.1 m43a\nSagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. Gleichung¬†8.1.\nPrioris:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{8.1}\\]\nWir nennen das Modell m43a3, s. Listing¬†8.1.\n\n\n\nListing¬†8.1: Modelldefinition von m43a in R\n\n\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # beta 0\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest f√ºr Reproduzierbarkeit\n    data = d3)\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die Nachpr√ºfbarkeit der Ergebnisse (‚ÄúReproduzierbarkeit‚Äù) sichergestellt4. Welche Wert f√ºr seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung sch√§tzen.\n\n\n\n\n8.4.2 Mittelwerte von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. Tabelle¬†8.2.\n\n\n\nTabelle¬†8.2: Parameter von m43a\n\n\n\nCode\nparameters(m43a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 8.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also gr√∂√üer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) √Ñhnliches wie der p-Wert in der Frequentistischen Statistik (Makowski et al., 2019).\n\nAm besten das Diagramm dazu anschauen, s Abbildung¬†8.7.\n\n\nCode\nplot(p_direction(m43a))\n\n\n\n\n\n\n\n\nAbbildung¬†8.7: Diagramm zur Probability of Direction, Modell m43a\n\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) gr√∂√üer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter besch√§ftigen in diesem Kurs.\n\n\n8.4.3 Visualisieren der ‚Äúmittleren‚Äù Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). √úberzeugen wir uns mit einem Blick in die Post-Verteilung von m43a:\n\n\nCode\nm43a %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n\n  \n\n\n\nWir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die ‚Äúmittlere‚Äù Regressionsgerade zu betrachten.\n\nMit ggplotMit easystats\n\n\n\n\nCode\nd3 %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. Abbildung¬†8.8. Mit ‚Äúexpectation‚Äù sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\nCode\nm43_expect &lt;- estimate_expectation(m43a)   # aus {easystats}\nplot(m43_expect)\n\n\n\n\n\n\n\n\nAbbildung¬†8.8: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n\n\n\n\n\n\n\n\n\n\n8.4.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).5 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.\n\n8.4.4.1 Lagema√üe zu den Parametern\n\nWas ist die mittlere Gr√∂√üe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? (\\(\\beta_1\\))\nWas ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert f√ºr z.B: \\(\\beta_1\\)?\n\nEine n√ºtzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. Tabelle¬†8.2.\n\n\n\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m43a, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm43a_post &lt;- \n  m43a %&gt;% \n  as_tibble()\n\nm43a_post %&gt;% \n  head()\n\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post. Jetzt haben wir wieder eine sch√∂ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen k√∂nnen. Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. Abbildung¬†8.9.\n\n\nCode\nm43a_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung¬†8.9: Postverteilung f√ºr den Parameter Gewicht (zentriert)\n\n\n\n\n\nAbbildung¬†8.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm43a_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. Abbildung¬†8.10.\n\n\nCode\nm43a_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung¬†8.10: Die Post-Verteilung f√ºr den Parameter sigma, m43a\n\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. Abbildung¬†8.11.\n\n\nCode\nm43a_hdi &lt;- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\n\n\n\n\nAbbildung¬†8.11: Die Parameter Gewicht (zentriert) und sigma des Modells m43a\n\n\n\n\n\nErg√§nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n\n\n8.4.5 Streuungsma√üe zu den Parametern\n\nWie unsicher sind wir uns in den Sch√§tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.\n\n\n\n\n8.4.6 Ungewissheit von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung visualisiert\n\n1010001000000\n\n\nDie ersten 10 Stichproben:\n\n\nCode\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\n\n\n\n\n\n\n8.5 100\nDie ersten 100 Stichproben:\n\n\nCode\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\nCode\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 10000006 ‚Ä¶ okay, lassen wir es gut sein7.\n\n\n\nEinfacher ist die Visualisierung mit estimate_expectation, s. Abbildung¬†8.12.\n\n\nCode\nestimate_expectation(m43a, seed = 42) %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildung¬†8.12: Sch√§tzbereich f√ºr die bedingten mittleren K√∂rpergr√∂√üe, also die Regressionsgerade mit Unsicherheitsintervall\n\n\n\n\n\n\n\n8.5.1 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe8.\n\n\n\nWelche mittlere Gr√∂√üe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht √ºberschritten?\nWelche mittlere Gr√∂√üe mit Wahrscheinlichkeit von 95% nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?\n\nQuantile:\n\n\nCode\nm43a_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n  \n\n\n\n50%-PI:\n\n\nCode\nm43a %&gt;% \n  eti(ci = .5)\n\n\n\n  \n\n\n\n\n\n8.5.2 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?\n\n\nCode\nm43a_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?\n\n\nCode\nm43a_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 Typischer Bayes-Nutzer in Aktion\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-1",
    "href": "0900-lineare-modelle.html#section-1",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.5 100",
    "text": "8.5 100\nDie ersten 100 Stichproben:\n\n\nCode\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.6 Post-Verteilung bedingt auf einen Pr√§diktorwert",
    "text": "8.6 Post-Verteilung bedingt auf einen Pr√§diktorwert\n\n8.6.1 Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m42, s. Abbildung¬†8.13.\n\n\n\n\n\n\n\n\nAbbildung¬†8.13: F√ºr jeden beliebigen Pr√§diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgew√§hlten Gewichtswerten. Es ist jeweils die Wahrscheinlichkeitsverteilung f√ºr den vorhergesagten Y-Wert dargestellt (hier sind die Verteilungen zu gro√ü dargestellt zur besseren Sichtbarkeit). B: F√ºr jeden beliebigen Gewichtswert (Y) bekommt man eine (auf den jeweiligen X-Wert bedingten) Post-Verteilung.\n\n\n\n\n\n\n\n8.6.2 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?\nEtwas formaler ausgedr√ºckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 &lt;-\n  m43a_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. Abbildung¬†8.14.\n\n\nCode\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†8.14: Post-Verteilung der Gr√∂√üe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\n\nAnalog k√∂nnen wir fragen, wie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.\n50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. Tabelle¬†8.3.\n\n\nCode\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\nTabelle¬†8.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren Gr√∂√üe bei einem Gewicht von 50kg ist weiter ‚Äúrechts‚Äù (Richtung h√∂here Gr√∂√üe) zentriert, s. Abbildung¬†8.15.\n\n\nCode\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†8.15: Post-Verteilung der mittleren Gr√∂√üe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n\n8.6.3 Lagema√üe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der K√∂rpergr√∂√üe.\nWas ist das 90% PI f√ºr \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %&gt;% \n  eti(mu_at_50, ci = .9)\n\n\n\n  \n\n\n\nDie mittlere Gr√∂√üe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#prior-pr√§diktiv-verteilung",
    "href": "0900-lineare-modelle.html#prior-pr√§diktiv-verteilung",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.7 Prior-Pr√§diktiv-Verteilung",
    "text": "8.7 Prior-Pr√§diktiv-Verteilung\nüèéüèéÔ∏è VERTIEFUNG (nicht pr√ºfungsrelevant ) üèéüèé\n\n8.7.1 Moment\nü§î Moment. Dieser Prior, \\(\\beta_1\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Gr√∂√üe positiv oder negativ ist? Nein, sind wir nicht.\n\n\n8.7.2 Priori-Pr√§diktiv-Verteilung f√ºr m43\nWas denkt wir bzw. unser Golem apriori √ºber den Zusammenhang von Gr√∂√üe und Gewicht? Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also f√ºr \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\).\n\n\nCode\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter f√ºr Prior-Pred-Verteilung\n             data = d3)\n\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n\n\n\na\nb\nsigma\n\n\n\n\n170.3\n15.0\n7.0\n\n\n140.2\n6.0\n6.5\n\n\n155.5\n‚àí4.2\n6.5\n\n\n159.6\n13.3\n20.9\n\n\n178.1\n2.5\n4.0\n\n\n\n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n8.7.3 Prior-Pr√§diktiv-Simulation f√ºr m43 mit stan_glm()\n\n\nCode\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d3)\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n\n\n8.7.4 Visualisieren der Prior-Pr√§diktiv-Verteilung\n\n\nCode\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\nü§Ø Einige dieser Regressionsgeraden sind unsinnig!\n\n\nCode\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die Gr√∂√üe des gr√∂√üten Menschens, Robert Pershing Wadlow, an.\n\n\n8.7.5 Ein positiver Wert f√ºr \\(\\beta_1\\) ist plausibler\n\n8.7.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\n\n\n\n\nüëé \\(\\beta=-20\\) w√§re mit diesem Prior gut m√∂glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n8.7.5.2 Oh yes\nWir br√§uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x&gt;0):\n\n\n\n\n\n\n\n\n\nüëç Vermutlich besser: Ein Gro√üteil der Wahrscheinlichkeitsmasse ist \\(X&gt;0\\). Allerdings gibt‚Äôs keine Gew√§hr, dass unser Prior ‚Äúrichtig‚Äù ist.\n\n\n\n8.7.6 Priori-Pr√§diktiv-Simulation, 2. Versuch\n\n\nCode\nm43a_prior_pred &lt;-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter f√ºr Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d3)\n\n\nm43a_prior_pred_draws &lt;- \n  m43a_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  # Spaltennamen k√ºrzen: \n  rename(a = `(Intercept)`) %&gt;%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n\n\n\na\nb\ns\n\n\n\n\n204.2\n4.1\n14.7\n\n\n175.1\n‚àí0.6\n2.3\n\n\n149.4\n0.3\n1.7\n\n\n172.3\n0.3\n31.2\n\n\n173.7\n1.0\n12.0\n\n\n\n\n\n\n\nDas Argument prior_PD = TRUE sorgt daf√ºr, dass keine Posteriori-Verteilung, sondern eine Prior-Pr√§diktiv-Verteilung berechnet wird.\n\n\n8.7.7 Visualisieren der Prior-Pr√§diktiv-Verteilung, m43a\nUnsere Priori-Werte scheinen einigerma√üen vern√ºnftige Vorhersagen zu t√§tigen. Allerdings erwartet unser Golem einige Riesen.\n\n\nCode\nd3 %&gt;% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %&gt;% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die Gr√∂√üe des gr√∂√üten Menschens, Robert Pershing Wadlow, an.\n\n\n8.7.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p.¬†96.\n\n\n8.7.9 Hier ist unser Modell, m43a\n\\[\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\\]\n\n\nCode\n# Posteriori-Vert. berechnen:\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # Zufallszahlen festlegen\n    data = d3)\n\n\n\n\n8.7.10 Eine Zusammenfassung der Posteriori-Verteilung f√ºr m43a\n\n\nCode\nm43a %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nUnser Modell m43a sch√§tzt die typische K√∂rpergr√∂√üe einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugeh√∂rige 95%-CI keine 20 Zentimenter umfasst.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-ppv-befragen",
    "href": "0900-lineare-modelle.html#die-ppv-befragen",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.8 Die PPV befragen",
    "text": "8.8 Die PPV befragen\nüèéüèéÔ∏è VERTIEFUNG (nicht pr√ºfungsrelevant ) üèéüèé\nDie Posterior-Pr√§diktiv-Verteilung (PPV) gibt uns die M√∂glichkeit, nach der Wahrscheinlichkeit tats√§chlicher K√∂rpergr√∂√üen zu fragen - und nicht nur nach mittleren K√∂rpergr√∂√üen anhand der Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren K√∂rpergr√∂√üe, denn das ist was wir modellieren wollten. M√∂chten wir Aussagen zur Wahrscheinlichkeit tats√§chlicher Gr√∂√üen treffen, brauchen wir die PPV. Allgemeiner gesagt: Die PPV macht Vorhersagen auf Basis eines Modells. F√ºr jede Vorhersage gibt es eine Verteilung, die wir zu einem Punktsch√§tzer (z.B. Median) und einem Sch√§tzbereich (z.B. 89%-HDI) zusammenfassen k√∂nnen.\n\n\nAn dieser Stelle sollten wir uns vor Augen f√ºhren, dass die PPV mehr Ungewissheit beinhaltet, denn sie ber√ºcksichtigt derer zweier Arten:\n\nUngewissheit bzgl. der Modellparameter (Steigung und Achsenabschnitt der Regressionsgeraden)\nUngewissheit der Vorhersagen (das Modell macht keine perfekten Vorhersagen)\n\nDie Post-Verteilung ber√ºcksichtigt nur die Ungewissheit in den Modellparametern, macht also nur Aussagen zur Regressionsgeraden.\nDie PPV macht Aussagen f√ºr konkrete Beobachtungen. Der Unterschied ist in Abbildung¬†8.16 dargestellt; die Funktionen stammen √ºbrigens aus {easystats}.\n\nCode\nestimate_prediction(m43a) %&gt;% plot()\nestimate_relation(m43a) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) PPV mit viel Ungewissheit\n\n\n\n\n\n\n\n\n\n\n\n(b) Post-Verteilung mit wenig(er) Ungewissheit\n\n\n\n\n\n\n\nAbbildung¬†8.16: PPV vs.¬†Post-Verteilung\n\n\n\n\n8.8.1 Perzentil-Intervalle f√ºr bestimmte Pr√§diktor-Werte\n\nWie gro√ü ist ein !Kung-Mann mit mittlerem Gewicht?\n\n\n\nCode\nset.seed(42)\nestimate_prediction(m43a, data = tibble(weight_c = 0), seed = 42)\n\n\n\n  \n\n\n\nUnser Modell, ma43a sch√§tzt ca. 145cm bis 165cm.\nWir k√∂nnen uns auch eine Sequenz an Pr√§diktorwerten, die uns interessieren, erstellen, s. weight_df:\n\n\nCode\nweight_df &lt;- tibble(weight_c = seq(-20,20, by = 5))\n\n\nF√ºr diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\n\nCode\nmus &lt;- \n  estimate_prediction(m43a, data = weight_df) \n\nhead(mus)\n\n\n\n  \n\n\n\nUm die Perzentilintervalle zu erstellen, wird von estimate_prediction() f√ºr jeden Pr√§diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil daf√ºr berechnet. Sie k√∂nnen die Voreinstellung √§ndern mittels des Arguments ci; um ein 89%-PI zu berechnen, w√ºrde man z.B. schreiben ci = .89.\nUm Reproduzierbarkeit sicherzustellen, haben wir mit set.seed(42) die Zufallszahlen fixiert.\nHoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedr√ºckt; die PPV gibt die Ungewissheit tats√§chlicher beobachtbarer K√∂rpergr√∂√üen aus, nicht nur die Ungewissheit zum Mittelwert.\nBerechnen wir die PPV f√ºr die bestehenden Beobachtungen aus m43a:\n\n\nCode\nppv_m43a &lt;- estimate_prediction(\n  m43a,\n  data = weight_df)\n\nmus \n\n\n\n  \n\n\n\n\n\n8.8.2 Perzentilintervalle f√ºr verschiedenen Pr√§diktorwerte visualisiert\nAbbildung¬†8.17 visualisiert die Ungewissheit von Vorhersagen laut der PPV. Die Ungewissheit in Abbildung¬†8.17 ist die Antwort auf die Frage: ‚ÄúWie sicher sind wir uns, zur Gr√∂√üe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?‚Äù Eine Vorhersage bezeichnet man auch als ‚Äúbedingte Verteilung‚Äù, da man den Wert einer Verteilung voraussagt, gegeben einer Bedingung, z.B. weight_c = 10.\n\n\n\n\n\n\n\n\nAbbildung¬†8.17: Visualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV gr√∂√üer als die der Post-Verteilung.\n\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung, s. Abbildung¬†8.18; je dicker die ‚ÄúKatzenaugen‚Äù, desto mehr Stichproben (samples) liegen vor an der Stelle, und umso genauer ist die Sch√§tzung.\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†8.18: Die PPV f√ºr bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\n\n\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu | w_i\\).\n\n\n8.8.3 Die PPV √ºber alle Beobachtungen visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV f√ºr einen bestimmten Pr√§diktorwert, z.B. bei einer Person mittleren Gewichts. Wir k√∂nnen auch den Mittelwert √ºber alle bedingten PPV anschauen, sozusagen die ‚ÄúMaster-PPV‚Äù oder ‚Äúunbedingte PPV‚Äù oder schlicht PPV. Vergleichen wir die echten Werte f√ºr height, \\(y\\), mit den von der PPV simulierten Werten f√ºr height, \\(y_{rep}\\), s. Abbildung¬†8.19.\n\n\nCode\ncheck_predictions(m43a)  # aus easystatss\n\n\n\n\n\n\n\n\n\nAbbildung¬†8.19: Vergleich der Vorhersagen f√ºr y (leichte, blaue Linien) mit der beobachteten Verteilung von y\n\n\n\n\n?check_predictions zeigt Hilfe f√ºr diese Funktion. Die Funktion zeigt die Vorhersagen f√ºr die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n8.8.4 Fragen an die Master-PPV\n\nWie gro√ü sind die !Kung im Schnitt?\nWelche Gr√∂√üe wird von 90% der Personen nicht √ºberschritten?\nWie gro√ü sind die 10% kleinsten?\n\n\n\nCode\nppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\nhead(ppv_m43a)\n\n\n\n  \n\n\n\n\n\nCode\nppv_m43a &lt;-\n  ppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\nhead(ppv_m43a)\n\n\n\n  \n\n\n\n\n\nCode\nppv_m43a %&gt;% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n\n\n  \n\n\n\nWas ist der 50% Bereich der K√∂rpergr√∂√üe?\n\n\nCode\nppv_m43a %&gt;% \n  eti(ci = .5)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#fazit",
    "href": "0900-lineare-modelle.html#fazit",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.9 Fazit",
    "text": "8.9 Fazit\n\n8.9.1 Ausstieg\n\nBeispiel 8.3 (Fassen Sie das Wesentliche zusammen!) Schreiben Sie 5-10 S√§tze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! \\(\\square\\)\n\n\n\n8.9.2 Vertiefung\nMcElreath (2020) bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. Kurz (2021) greift die R-Inhalte von McElreath (2020) auf und setzt sie mit anderen R-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen m√∂chte. Gelman et al. (2021) bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einem frequentistischen als auch aus einer Bayes-Perspektive.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.10 Aufgaben",
    "text": "8.10 Aufgaben\n\n8.10.1 Papier-und-Bleistift-Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nmtcars-post2a\nBed-Post-Wskt1\nmtcars-post3a \nregression1a\nregression1b\nRegression2\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\nLikelihood2\ninterpret-koeff\nbed-post-wskt1\n\n\n\n8.10.2 Computer-Aufgaben\n\nPost-befragen1\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-4",
    "href": "0900-lineare-modelle.html#section-4",
    "title": "8¬† Einfache lineare Modelle",
    "section": "8.11 ‚Äî",
    "text": "8.11 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKurz, S. (2021). Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#footnotes",
    "href": "0900-lineare-modelle.html#footnotes",
    "title": "8¬† Einfache lineare Modelle",
    "section": "",
    "text": "Da es viele Funktionen sind, bietet es sich an mit Strg-F auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.‚Ü©Ô∏é\n Datenquelle, McElreath (2020).‚Ü©Ô∏é\nWer ist hier f√ºr die Namensgebung zust√§ndig? Besoffen oder was?‚Ü©Ô∏é\noder zumindest besser sichergestellt‚Ü©Ô∏é\nIn manchen Lehrb√ºchern wird \\(\\beta_0\\) auch als \\(\\alpha\\) bezeichnet.‚Ü©Ô∏é\n1e6‚Ü©Ô∏é\nIm Standard beschert uns stan_glm() 4000 Stichproben.‚Ü©Ô∏é\n\\(\\mu\\)‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html",
    "href": "1050-Schaetzen-Testen.html",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "9.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen‚Ä¶\n\nden Unterschied zwischen dem Sch√§tzen von Modellparametern und dem Testen von Hypothesen erl√§utern\nVor- und Nachteile des Sch√§tzens und Testens diskutieren\nDas ROPE-Konzept erl√§utern und anwenden\nDie G√ºte von Regressionsmodellen einsch√§tzen und berechnen\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an Kruschke (2018).\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 2‚Äù\n\n9.1.5 R-Pakete\nIn diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n9.1.6 Ben√∂tigte Daten: Pinguine\nWir ben√∂tigen in diesem Kapitel den Datensatz zu Pinguinen: penguins.\nSie k√∂nnen den Datensatz penguins entweder via dem Pfad importieren.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \nOder via dem zugeh√∂rigen R-Paket.\n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\nBeide M√∂glichkeit sind okay.\n\n9.1.7 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\n‚ÄúLernen f√ºr die Klausur bringt etwas!‚Äù\n‚ÄúWie viel bringt Lernen f√ºr die Klausur?‚Äù\n\n\nBeispiel 9.1 Diskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sch√§tzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#sch√§tzen-oder-testen",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n9.2 Sch√§tzen oder Testen?",
    "text": "9.2 Sch√§tzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen pr√ºfend: ‚ÄúDie Daten widerlegen die Hypothese (nicht)‚Äù\n\nParameter sch√§tzend: ‚ÄúDer Effekt von X auf Y liegt zwischen A und B‚Äù.\n\n\n9.2.1 Hypothesen pr√ºfen\nHypothesen pr√ºfende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 9.2 (‚ÄúLernen erh√∂ht den Pr√ºfungserfolg‚Äù) Die Hypothese Lernen erh√∂ht den Pr√ºfungserfolg kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. \\(\\square\\)\n\nDas Pr√ºfen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\nüü• Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.\nüü¢ Die Daten unterst√ºtzen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.\n‚ùì Die Datenlage ist unklar; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen pr√ºfen ist bin√§r in dem Sinne, dass sie zu ‚ÄúSchwarz-Wei√ü-Ergebnissen‚Äù f√ºhren (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine g√§ngige Variante des Hypothesen testen1 ist das Testen der Hypothese ‚Äúkein Effekt‚Äù (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n9.2.2 Beispiele f√ºr Nullhypothesen\n\n‚ÄúLernen bringt nichts‚Äù\n‚ÄúFrauen und M√§nner parken gleich schnell ein‚Äù\n‚ÄúEs gibt keinen Zusammenhang von Babies und St√∂rchen‚Äù\n‚ÄúFr√ºher war es auch nicht besser (sondern gleich gut)‚Äù\n‚ÄúBei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern‚Äù (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterst√ºtzen kann, da es die Komplexit√§t reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht best√§tigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann, hat gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt (Popper, 2013). Schlagend ist das Beispiel zur Hypothese ‚ÄúAlle Schw√§ne sind wei√ü‚Äù. Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. Schlie√ülich ist es m√∂glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben. 2 Umgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverl√§ssiger, repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als auch widerlegt werden k√∂nnen (Kruschke, 2018; Morey & Rouder, 2011). \\(\\square\\)\n\n\n\n9.2.3 Parameter sch√§tzen\nBeim Parameter sch√§tzen untersucht man, wie gro√ü ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein ‚Äúja/nein‚Äù, was beim Hypothesen testen der Fall ist.\nBeim Parameter sch√§tzen gibt es zwei Varianten:\n\n‚ö´Ô∏è Punktsch√§tzung: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein ‚ÄúBest Guess‚Äù\nüìè Bereichssch√§tzung: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Sch√§tzen von Parameterns auch wie einen Hypothesentest verstehen: Ist ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 9.3 (Parametersch√§tzen als Nullhypothesentest) ¬†\n\nForschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nTheorem¬†9.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\nTheorem 9.1 (Nullhypothesentest) \\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0\\quad \\square\\]\n\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nCodem1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\n\nDann z√§hlen wir einfach den Anteil der Stichproben in der Post-Verteilung f√ºr die UV sexmale, die einen Wert gr√∂√üer Null aufweisen:\n\nCodem1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr sexmale, dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht (das weibliche Tiere schwerer w√§ren). Damit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der Parametersch√§tzung ist die Nuanciertheit des Ergebnisses, die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n9.3 ROPE: Bereich von ‚Äúpraktisch Null‚Äù",
    "text": "9.3 ROPE: Bereich von ‚Äúpraktisch Null‚Äù\nüì∫ Teil 2\nNullhypothesen sind fast immer falsch, s. Abbildung¬†9.1.\n\n\n\n\n\n\n\nAbbildung¬†9.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman et al., 2021)\n\n\n9.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest m√∂glich ist.3\nEin anderer Grund ist vermutlich, ‚Ä¶ wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke, 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n9.3.2 ‚ÄúPraktisch‚Äù kein Unterschied: Das Rope-Konzept\nüì∫ ROPE-Video\n\nBeispiel 9.4 (Beispiele f√ºr ROPE) Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens \\(d=100\\)‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als ‚Äúpraktisch gleich‚Äù, ‚Äúpraktisch kein Unterschied‚Äù bzw. vernachl√§ssigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g ‚Äúvernachl√§ssigbar wenig‚Äù ist.\nEine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umssatzunterschied von 100k Euro ‚Äúpraktisch irrelevant‚Äù sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt pr√ºfen wir, ob ein ‚ÄúGro√üteil‚Äù der Posteriori-Stichproben im Rope liegt. Unter ‚ÄúGro√üteil‚Äù wird h√§ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGro√üteil liegt innerhalb von Rope ‚û°Ô∏è Annahme der Nullhypothese ‚Äúpraktisch kein Effekt‚Äù, \\(H_0\\)\n\nGro√üteil liegt au√üerhalb von Rope ‚û°Ô∏è Ablehnung der Nullhypothese ‚Äúpraktisch kein Effekt‚Äù, \\(H_0\\)\n\nAnsonsten ‚û°Ô∏è keine Entscheidung\n\nMit ‚ÄúGro√üteil‚Äù meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n9.3.3 Vernachl√§ssigbarer Regressionseffekt\nKruschke (2018) schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als ‚Äúpraktisch Null‚Äù zu bezeichnen:\nWenn eine Ver√§nderung √ºber ‚Äúpraktisch den ganzen Wertebereich‚Äù von \\(x\\) nur einen vernachl√§ssigbaren Effekt auf \\(y\\) hat. Ein vernachl√§ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der ‚Äúpraktisch ganze Wertebereich‚Äù von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Ver√§nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) f√ºr z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±5% der SD der AV. \\(\\square\\)\n\n\n\n9.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildung¬†9.2: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\n\nAbbildung¬†9.2 illustriert die Entscheidungsregel zum ROPE f√ºr mehrere Situatioenen (Kruschke, 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.\n\n9.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (m10.6).\n\nCodem10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\n\nDen Rope berechnet man mit rope(model).\n\nCoderope(m10.6)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir k√∂nnen daher f√ºr diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.\nAber: Gentoo liegt zu 0% im Rope. F√ºr Gentoo k√∂nnen wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®\n\n9.3.6 Visualisierung unserer Rope-Werte, m10.6\nEin Gro√üteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope. Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. Abbildung¬†9.3.\n\nCoderope(m10.6) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.6) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.6) %&gt;% plot()\n\n\n\n\n\n\nAbbildung¬†9.3: Rope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die ‚ÄúBerge‚Äù der Posteriori-Verteilung f√ºr Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir k√∂nnen das Nullhypothese f√ºr Chinstrap nicht verwerfen, aber auch nicht best√§tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom ‚Äúblauen Fluss‚Äù des Rope: Gentoo liegt au√üerhalb des Rope. Es gibt einen ‚Äúsubstanziellen‚Äù Unterschied, gr√∂√üer als das ROPE. Wir verwerfen die ‚ÄúPraktisch-Null-Hypothese‚Äù in diesem Fall.\n\n9.3.7 Finetuning des Rope\nWir k√∂nnen festlegen, was wir unter ‚Äúpraktischer √Ñquivalenz‚Äù verstehen, also die Grenzen des Ropes ver√§ndern. Sagen wir, 100 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. Abbildung¬†9.4.\n\nCoderope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†9.4: ROPE mit selber eingestellter Grenze von ¬±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:\n\nCoderope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht f√ºr ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n9.3.8 Beantwortung der Forschungsfrage\nF√ºr die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. F√ºr Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellg√ºte",
    "href": "1050-Schaetzen-Testen.html#modellg√ºte",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n9.4 Modellg√ºte",
    "text": "9.4 Modellg√ºte\n\n9.4.1 Wozu Modellg√ºte?\nHat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, m√∂chte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. Diese Kennwerte zielen z.B. darauf ab, wie pr√§zise die Aussagen des Modells sind. Je pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich. Bei einer Parametersch√§tzung erh√§lt man auch Informationen zur Pr√§zision der Sch√§tzung: Ist der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa). Allerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n9.4.2 Modellg√ºte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt. - H√∂here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erkl√§rt. \\(R^2\\) wird normalerweise auf Basis eines Punktsch√§tzers definiert. Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor. Daher ist es w√ºnschenswert, diese Information in \\(R^2\\) einflie√üen zu lassen: Bayes-R-Quadrat.\n\n\n\n\n\nM√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. Abbildung¬†9.5.\n\nCodem10.6_r2 &lt;-\n  m10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung¬†9.5: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n9.4.3 Definition vom ‚Äúklassischen‚Äù \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die ‚Äútypische‚Äù Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist n√ºtzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erkl√§rten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck √§quivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen Ausdr√ºcke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachl√§ssigen Ungewissheit; sie sind √ºbergewiss aus Bayes-Sicht.\n### Bayes‚Äô \\(R^2\\)\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellg√ºte miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erk√§rte Varianz}}{\\text{Erkl√§rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. F√ºr jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erkl√§rten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman et al. (2019), Gelman et al. (2021), Kap. 11.7.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n9.5 Fazit",
    "text": "9.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. M√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n9.6 Aufgaben",
    "text": "9.6 Aufgaben\n\n9.6.1 Papier-und-Bleistift-Aufgaben\n\nrope-luecke\npenguins-rope\nWskt-Schluckspecht2\npenguins-stan-01a\nrope-regr\nrope1\nrope2a\nrope3a\npenguins-stan-04a\nstan_glm01a\npenguins-regr02a\npenguins-stan-02a\npenguins-stan-05a\n\n9.6.2 Computer-Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope2\nrope3\n\n\n\n\n\nGelman, A., Goodrich, B., Gabry, J., & Vehtari, A. (2019). R-Squared for Bayesian Regression Models. The American Statistician, 73(3), 307‚Äì309. https://doi.org/10.1080/00031305.2018.1549100\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter Values in Bayesian Estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270‚Äì280. https://doi.org/10.1177/2515245918771304\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes Factor Approaches for Testing Interval Null Hypotheses. Psychological Methods, 16(4), 406‚Äì419. https://doi.org/10.1037/a0024377\n\n\nPopper, K. (2013). Logik Der Forschung (H. Keuth, Hrsg.). Akademie Verlag. https://doi.org/10.1524/9783050063782",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#footnotes",
    "href": "1050-Schaetzen-Testen.html#footnotes",
    "title": "\n9¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "vor allem in der Frequentistischen Statistik‚Ü©Ô∏é\nTats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan‚Ü©Ô∏é\nMittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.‚Ü©Ô∏é\n89 ist die n√§chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. Damit ist 95 hier eine ‚Äúmagic number‚Äù, ein Defacto-Standard ohne hinreichende Begr√ºndung. Um darauf hinzuweisen, benutzen einige Forschis mit √§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html",
    "href": "1000-metrische-AV.html",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "",
    "text": "10.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen‚Ä¶\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme √ºbersetzen\ntypische Forschungsfragen auswerten\n\n10.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman et al. (2021), Kap. 7 und 10.\n\n10.1.4 Vorbereitung im Eigenstudium\nFrischen Sie Ihr Wissen in den Grundlagen der einfachen und multiplen Regression (inkl. Interaktionseffekte) auf. Dazu sind z.B. folgende Literaturstellen geeignet.\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\nStatistik1, Kap. ‚ÄúGeradenmodelle 2‚Äù\n\n10.1.5 R-Pakete\nIn diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n10.1.6 Ben√∂tigte Daten\nWir ben√∂tigen in diesem Kapitel folgende Datens√§tze: kidiq, penguins.\n\n10.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\nCodedata(\"kidiq\", package = \"rstanarm\")\n\n\nAlternativ k√∂nnen Sie die Daten hier herunterladen.\n Download \n\n10.1.6.2 penguins\n\nSie k√∂nnen den Datensatz penguins entweder via dem Pfad importieren oder via dem zugeh√∂rigen R-Paket. Beide M√∂glichkeit sind okay.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\n\n10.1.7 Einstieg\n\nBeispiel 10.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, m√ºssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 10.2 (Was war noch einmal die Interaktion?) Erk√§ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n10.1.8 √úberblick\nWenn Sie die Skalenniveaus wissen, k√∂nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und √§hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, ‚Ä¶) lernen m√ºssen. Au√üerdem ist die Regressionsanalyse (f√ºr viele Situationen) die beste Heransgehensweise, da sie viele M√∂glichkeiten f√ºr Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels g√§ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. Nat√ºrlich w√ºrzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-K√ºche. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "href": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.2 Taxonomie von Forschungsfragen",
    "text": "10.2 Taxonomie von Forschungsfragen\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus. Im Folgenden sind f√ºr die UV(s) nominale sowie metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind ebenfalls erlaubt.\nWir untersuchen in diesem Kapitel h√§ufig verwendete Arten von Forschungsfragen mittels Regressionsanalysen. F√ºr jede Variante ist zumeist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abh√§ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabh√§ngige Variable (querschnittlich)\n\nb: bin√§re Variable\n\nx: metrische unabh√§ngige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-b",
    "href": "1000-metrische-AV.html#y-b",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.3 y ~ b\n",
    "text": "10.3 y ~ b\n\n\n10.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im √∂ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufw√§ndigen Studie die Intelligenz vieler Kinder gemessen. Zus√§tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, ‚ÄúRisikofaktoren‚Äù f√ºr geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nIst der mittlere IQ-Wert (kid_score) von Kindern, deren jeweilige Mutter √ºber einen Schlusabschluss (mom_hs, \\(x=1\\)) verf√ºgt h√∂her, als bei Kinderen, deren jeweilige Mutter nicht √ºber einen Schulabschluss verf√ºgt (\\(x=0\\))? (ceteris paribus)4.\n\nDie Modellformel zur Forschungsfrage lautet: y ~  b bzw. kid_iq ~ mom_hs.\nFormaler ausgedr√ºckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (Theorem¬†10.1).\n\nTheorem 10.1 (Hypothese f√ºr ungleiche Mittelwerte) \\[\\mu_{x=1|M} \\ne \\mu_{x=0|M}\\quad \\square\\]\n\nIn Worten: ‚ÄúDer mittlere IQ-Wert f√ºr Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen ist h√∂her als in der Gruppe von Kindern, deren M√ºtter √ºber keinen Schulabschluss verf√ºgen‚Äù. Zu beachten ist, dass sich eine Population immer auf Parameterwerte bezieht, also auf die Population, nicht auf die Statistiken der Stichprobe.\n\n10.3.2 Modell\nDie Regressionsformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in Abbildung¬†10.1 dargestellt. Y hat, laut unserem Modell, zwei Ursachen:\n\nmom_hs (b)\nu, das steht f√ºr ‚Äúunbekannt‚Äù5\n\n\n\n\n\n\n\n\n\nAbbildung¬†10.1: DAG f√ºr kid_iq ~ mom_hs\n\n\n\n\n\nCodedata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nDer Einfachheit halber √ºbernehmen wir die Prioriwerte von Stan, s. Listing¬†10.1.\n\n\n\nListing¬†10.1: Standard-Prioriwerte f√ºr m10.1, von Stan vergeben\n\nprior_summary(m10.1)\n## Priors for model 'm10.1' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 87, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 87, scale = 51)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = 0, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 0, scale = 124)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.049)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\n\nDie komplette Modellspezifikation ist in Gleichung¬†10.1 aufgef√ºhrt.\n\\[\\begin{align*}\n\\text{kid score}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{Lineares Modell} \\\\\n\\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{Prior Regressionsgewicht} \\\\\n\\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{Prior Vorhersageg√ºte}\n\\end{align*} \\tag{10.1}\\]\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. Tabelle¬†10.1.\n\n\n\nTabelle¬†10.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt, da meistens nicht von hohem Interesse)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\n\n10.3.3 Interpretation der Koeffizienten\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren M√ºtter √ºber keinen Schulabschluss (mom_hs = 0) verf√ºgen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit M√ºtter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit M√ºtter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die Sch√§tzung (Vorhersage) ist bzw. wie stark Pr√§diktor (UV) und Kriterium (AV) zusammenh√§ngen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tats√§chlichen IQ-Wert des Kindes (\\(y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n10.3.4 y ~ g als Mittelwertsdifferenz\nEin lineares Modell der Art y ~ g kann man als Berechnung des Unterschieds im Mittelwert von y zwischen beiden Gruppen (g0 vs.¬†g1) verstehen.\n\nüë®‚Äçüè´ Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll hei√üen kid_score_avg. An die Arbeit!\n\n\nü§ñ Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nCodekidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von M√ºttern mit Abschluss.\n\n\n\nIn Abbildung¬†10.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt, auf Basis des Datensatzes kidiq.\n\nCodeestimate_expectation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nAbbildung¬†10.2: Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen, haben im Mittel einen h√∂heren Intelligenztestwert, laut dem vorliegenden Modell. Die Regressionsgerade ist als durchgezogene Linie dargestellt. Die Mittelwerte pro Gruppe als Punkte und als gestrichelte, horizontale Linie.\n\n\n\n\n\n10.3.5 Rope\nPr√ºfen wir mit rope(m10.1), ob der Effekt der UV (Unterschied zwischen den Gruppen) ‚Äúpraktisch Null‚Äù ist; dazu nutzen wir das ROPE-Verfahren.\n\nCoderope(m10.1)\n\n\n\n\n\n\n\n\n\n\nDas Ergebnis zeigt uns, dass es 0% √úberlappung vom Rope und dem 95%-HDI (der Posterior-Verteilung) gibt.\nFazit: Wir verwerfen die Praktisch-Null-Hypothese. Adios! Abbildung¬†10.3 visualisiert die Erstreckung der Posteriori-Verteilung (und des 95%-HDI) sowie des Rope.\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.1) %&gt;% plot()\n\n\n\n\n\n\nAbbildung¬†10.3: Rope und HDI √ºberlappen nicht. Wir verwerfen die Praktisch-Null-Hypothese.\n\n\n\n10.3.6 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation - Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das pr√ºft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nAlternativ zum t-Test kann man - unabh√§ngig, ob man Frequentistisch oder Bayesianisch unterwegs ist - mit einer Regression vom Typ y ~ b das in etwa gleiche Ergebnis erreichen.7\n\n10.3.7 Antwort auf die Forschungsfrage\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nCodem10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # sch√∂nere Namen\n\n\n\n\nHier sind die ersten paar Zeilen, s. Tabelle¬†10.2.\n\n\n\nTabelle¬†10.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n75.2\n14.0\n21.1\n\n\n77.5\n14.9\n21.2\n\n\n79.0\n11.3\n19.2\n\n\n80.9\n8.1\n20.4\n\n\n77.9\n11.6\n19.9\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir zur √úbung ein 95%-PI von Hand; komfortabler geht es mit eti(m10.1), s. Tabelle¬†10.1.\n\nCodepi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlie√üend die Posteriori-Verteilung, s. Abbildung¬†10.4.\n\nCodeplot(eti(m10.1))\n\n\n\n\n\n\nAbbildung¬†10.4: Das 95% ETI zum (statistischen) Effekt des m√ºtterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem ‚ÄúEffekt‚Äù zu sprechen, l√§sst in den meisten K√∂pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang. F√ºr eine Kausalaussage braucht man ein Argument, etwa einen Verweis auf bestehende Studien oder eine Theorie.\n\n\n\n\n\n\n\n\n\n\n10.3.8 Vertiefung: Toleranzbereich\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\nBerechnet man ein Regressionsmodell mit stan_glm (ü§ñüòÅ), dann zieht man dabei Zufallszahlen üé≤. Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zuf√§llig. Das erkl√§rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen k√∂nnen.\nUm zu pr√ºfen, ob Ihre Ergebnisse ‚Äú√§hnlich genug‚Äù oder ‚Äúinnerhalb eines Toleranzbereichs‚Äù sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nGr√∂√üe des Toleranzbereichs\n\n\n\nDie Gr√∂√üe des relativen Toleranzbereichs ist in is_in_toleranzce() auf 5% festgelegt. Das hei√üt, ein Unterschied von 5% zwischen einem Referenzwert (dem ‚Äúwahren‚Äù Wert) und Ihrem Wert ist okay, also im Toleranzbereich. Au√üerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der gr√∂√üere der beiden Werte gilt. \\(\\square\\)\n\n\nWenn Sie diese Funktion nutzen wollen, m√ºssen Sie zun√§chst das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN), das geht z.B. so:\n\nCodelibrary(remotes)  # dieses Paket k√∂nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\n\n\nDann starten Sie es wie gewohnt:\n\nCodelibrary(prada)\n\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der ‚Äúrichtige‚Äù oder ‚Äúwahre‚Äù Wert (oder schlicht der Wert einer Musterl√∂sung) f√ºr \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nCodeis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. ‚úÖ",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b",
    "href": "1000-metrische-AV.html#y-x-b",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.4 y ~ x + b\n",
    "text": "10.4 y ~ x + b\n\n\n10.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b bzw. kid_score ~ mom_iq + mom_hs.\nDer Kausalgraph8 zur Modellformel sieht aus in Abbildung¬†10.5 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) Einfl√ºsse, b und u, wobei u f√ºr ‚Äúunbekannt‚Äù steht, also f√ºr alle sonstigen Einfl√ºsse.9\n\n\n\n\n\n\n\nAbbildung¬†10.5: DAG f√ºr y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle Tabelle¬†10.3 dargestellt.\n\nCodedata(\"kidiq\")  # Paket rstanarm, alternativ √ºber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\nTabelle¬†10.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n10.4.2 1 metrischer Pr√§diktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. Tabelle¬†10.4.\n\nCodem10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\n\nTabelle¬†10.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. Abbildung¬†10.6.\n\nCodekidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildung¬†10.6: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. Abbildung¬†10.7.\n\nCodeplot(estimate_expectation(m10.2))\n\n\n\n\n\n\nAbbildung¬†10.7: Die gesch√§tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder f√ºr verschiedene IQ-Werte der M√ºtter. Vergleicht man Teilpopulationen von M√ºttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n10.4.3 Beide Pr√§diktoren, m10.3\n\nBerechnen wir als n√§chstes ein Modell mit beiden Pr√§diktoren: kid_score ~ mom_hs + mom_iq, s. Tabelle¬†10.5.\n\nCodem10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\nTabelle¬†10.5: Parameter des Modells m10.3 (ohne sigma; ETI-Intervalle)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktsch√§tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\nCodecoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nM√∂chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\nCodecoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\n\nAber nat√ºrlich ist es m√∂glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. Abbildung¬†10.8.\n\nCodekidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\nplot(estimate_expectation(m10.3a))\n\n\n\n\n\n\nAbbildung¬†10.8: Der Effekt von sowohl m√ºtterlicher Intelligenz als auch m√ºtterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann sch√§tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum m√ºtterlichen Schulabschluss: Vergleicht man Kinder von M√ºttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur m√ºtterlichen IQ: Vergleicht man Kinder von M√ºttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n10.4.4 Antwort auf die Forschungsfrage\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 1.6 bis 10.1 IQ-Punkten, laut unserem Modell. Der Effekt des m√ºtterlichen IQs wird auf 0.5 bis 0.7 gesch√§tzt (95%-ETI). Da f√ºr beide UV die Null nicht im Intervall plausibler Werte liegt, kann ein Null-Effekt (die exakte Nullhypothese) abgelehnt werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b-xb",
    "href": "1000-metrische-AV.html#y-x-b-xb",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.5 y ~ x + b + x:b\n",
    "text": "10.5 y ~ x + b + x:b\n\n\n10.5.1 Forschungsfrage und Modelldefinition\n\nGibt es einen Interaktionseffekt zwischen m√ºtterlichem Schulabschluss und m√ºtterlichem IQ (auf den IQ-Wert des Kindes)?\n\nAu√üerdem ist man vermutlich auch an den Effekten der beiden UV auf die AV interessiert; diese Fragen haben wir im letzten Abschnitt untersucht (und greifen sie daher nicht noch mal ausf√ºhrlich auf).\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b. Der Einfachheit halber √ºbernehmen wir wieder die Prioris wie vom R-Paket rstanarm bereitgestellt.\nDer DAG zur Modellformel sieht aus in Abbildung¬†10.9 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†10.9: DAG f√ºr y ~ x + b + x:b\n\n\n\n\n\n10.5.2 Interaktion zur Modellformel hinzuf√ºgen\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. Listing¬†10.2, Abbildung¬†10.10 und Tabelle¬†10.6.\n\n\n\nListing¬†10.2: Die Modelldefition von m10.4 mit stanglm\n\nm10.4 &lt;- \n  stan_glm(kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\nIn der Regressionsformel sieht man, dass ein zus√§tzlicher Parametern, eben der Interaktionseffekt, in das Modell aufgenommen wurde.\n\n\n\nTabelle¬†10.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.68\n(-37.44, 15.92)\n77.12%\n1.000\n1338.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.000\n1340.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n50.36\n(21.58, 80.70)\n99.98%\n1.001\n1311.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq:mom_hs\n-0.47\n(-0.79, -0.17)\n99.88%\n1.001\n1293.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_expectation(m10.4) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung¬†10.10.\n\n\n\n\n\n\n\nAbbildung¬†10.10: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt f√ºr diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n10.5.3 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Sch√§tzwerte f√ºr Kinder mit M√ºtter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit M√ºttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten f√ºr mom_iq zwischen M√ºtter mit bzw. ohne Schulabschluss.\nF√ºr beide Gruppen, mom_hs=0 und mom_hs=1 gilt folgende Regressionsformel, s. Gleichung¬†10.2.\n\\[\\text{kid score} = \\beta_0 + \\beta_1 \\cdot \\text{mom hs} + \\beta_2 \\cdot \\text{mom iq} + \\beta_3 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{10.2}\\]\n\\(\\beta_3\\) gibt die St√§rke des Interaktionseffekts an.\nAuf Errisch schreibt mit Gleichung¬†10.2 so (s. Listing¬†10.2):\nkid_score ~ mom_iq + mom_hs + mom_hs:mom_iq.\nDer Doppelpunkt zwischen mom_hs und mom_iq steht f√ºr den Interaktionseffekt der beiden Variablen.\nTr√§gt man die Werte der Koeffizienten (\\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\)) ein, so erh√§lt man Gleichung¬†10.3.\n\\[\\text{kid score} = -10.7 + 50.4 \\cdot \\text{mom hs} + 1  \\cdot \\text{mom iq} + -0.5 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{10.3}\\]\nTeilen wir die Regressionsformel einmal auf die beiden Gruppen (mom_hs=0 bzw. mom_hs=1) auf:\nmom_hs=0:\nkid_score = -10.7 + 50.4*0 + 1*mom_iq  - -0.5*0*mom_iq\n          = -10 + 1.1*mom_iq\nmom_hs=1:\nkid_score = -10.7 + 50.4*mom_hs + 1*mom_iq  - -0.5*mom_hs*mom_iq\n          = -10 + 1.1*mom_iq\nNach der Interpretation von 20 unzentrierten Koeffizienten ‚Ä¶\n\n\n\nvia GIPHY\n\nWir m√ºssen dringend die unzentrierten Pr√§diktoren loswerden ‚Ä¶\n\n10.5.4 Antwort auf die Forschungsfrage\nWie in Tabelle¬†10.6 ersichtlich, kann f√ºr alle drei Effekte (m√ºtterliche IQ, m√ºtterlicher Schulabschluss und Interaktion von m√ºtterlichem IQ mit m√ºtterlichem Schulabschluss) ein Nulleffekt ausgeschlossen werden. Ob die Effekte st√§rker als ‚Äúpraktisch Null‚Äù sind, kann mittels des ROPE-Verfahren untersucht werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "href": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.6 y ~ x_c + b + x_c:b\n",
    "text": "10.6 y ~ x_c + b + x_c:b\n\n\n10.6.1 Zentrieren von Pr√§diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq; die zentrierte Variable kennzeichnen wir durch den Suffix _c, also mom_iq_c.\nMan k√∂nnte auch mom_hs zentrieren, aber f√ºr eine einfache Interpretation ist es meist n√ºtzlich, nur metrische Pr√§diktoren zu zentrieren.\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\n\ncoef(m10.5)  # nur die Punktsch√§tzer f√ºr die Koeffizienten ausgeben\n\n\nTabelle¬†10.7 zeigt die Punktsch√§tzer der Koeffizienten von m10.5.\n\n\n\nTabelle¬†10.7: Punktsch√§tzer von m10.5 (zentrierte UV)\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.34\n\n\nmom_hs\n2.86\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n\n\n\n10.6.2 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den gesch√§tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten f√ºr mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nMit estimate_expectation(m10.5) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung¬†10.11.\n\n\n\n\n\n\n\nAbbildung¬†10.11: m10.5: Mit zentrierten Pr√§diktoren gibt der Achsenabschnitt den Y-Wert f√ºr eine Beobachtung mit mittleren X-Wert an; daher ist der Achsenabschnitt besser zu interpretieren als ohne Zentrierung.\n\n\n\n\n\n10.6.3 Zentrieren √§ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.32635\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5: Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.35988\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren √§ndert auch nicht die zentrierten Regressionskoeffizienten, da die Streuungen dieser Variable nicht ver√§ndert wurden.\n\n10.6.4 Perzentilintervalle aus der Posterori-Verteilung\nTabelle¬†10.8 zeigt die Punktsch√§tzer der Parameter f√ºr m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie daf√ºr parameters(m10.5), s. Tabelle¬†10.8.\n\n\n\nTabelle¬†10.8: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(81.17, 89.61)\n100%\n1.003\n2348.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.80, 7.62)\n87.98%\n1.002\n2470.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.83%\n1.003\n1874.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. Tabelle¬†10.9.\n\nCodeparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelle¬†10.9: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(80.96, 89.39)\n100%\n1.003\n2348.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.64, 7.75)\n87.98%\n1.002\n2470.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.17)\n99.83%\n1.003\n1874.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n10.6.5 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei M√ºttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]); die Befundlage ist unklar. Hingegen fand sich ein Effekt der m√ºtterlichen Intelligenz; pro Punkt Unterschied in m√ºtterlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte beim Kind (95%PI). Au√üerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei M√ºtter mit Schulabschluss war der Regressionskoeffizient zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell hat mittels Abbildung¬†10.12 mutig Kausalaussagen postuliert. Das ist zwar sch√∂n, bedarf aber einer Begr√ºndung mit R√ºckgriff auf die Literatur (was hier nicht getan wurde).",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-g",
    "href": "1000-metrische-AV.html#y-g",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.7 y ~ g\n",
    "text": "10.7 y ~ g\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n10.7.1 Forschungsfrage\nNach Ihrem Studium wurden Sie reich als Unternehmensberaterin; Ihre Kompetenz als Wirtschaftspsychologi war hei√ü begehrt. Von Statistik wollte niemand etwas wissen‚Ä¶ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt f√ºhrte Sie in die Antarktis‚Ä¶ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um Gr√∂√üenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren K√∂rpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in Abbildung¬†10.12 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†10.12: DAG f√ºr y ~ g\n\n\n\n\n\n10.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere K√∂rpergewichte in Abh√§ngigkeit von der Pinguinart?\n\nAlternativ k√∂nnen wir die Hypothese pr√ºfen, ob die Mittelwerte ‚Äúpraktisch‚Äù gleich sind, also sich ‚Äúkaum‚Äù unterscheiden. Der Grenzwert f√ºr ‚Äúpraktisch gleich‚Äù bzw. ‚Äúkaum unterschiedlich‚Äù ist subjektiv. Dazu in Kapitel 9.3 mehr.\n\n10.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, Tabelle¬†10.10.\n\nCodepenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\nTabelle¬†10.10: Die Verteilung des K√∂rpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas f√§llt Ihnen auf?\n\n10.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. Abbildung¬†10.13?\n\n\n\n\n\n\n\nAbbildung¬†10.13: Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.7.5 Gewicht pro Spezies, m10.6\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und Tabelle¬†10.11.\nDie Modellformel f√ºr m10.6 lautet also body_mass_g ~ species.\n\nCodeoptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\n\nTabelle¬†10.11: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3700.62\n(3627.04, 3773.47)\n100%\n0.999\n4057.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.49\n(-104.84, 168.88)\n68.53%\n1.000\n4282.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.43\n(1263.00, 1492.13)\n100%\n1.000\n4454.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n10.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, Auspr√§gungen; hier: Spezies), aber es werden in Tabelle¬†10.11 nur zwei Stufen angezeigt (also eine weniger) zus√§tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedr√ºckt (Intercept). Die Koeffizienten f√ºr species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in Abbildung¬†10.14 verdeutlicht.\n\nCodeplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†10.14: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\n\n10.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich h√∂her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich √§hnlich.\nWie in Abbildung¬†10.14 ersichtlich, √ºberlappt sich der Sch√§tzbereich f√ºr den Parameter von Gentoo nicht mit der Null; hingegen √ºberlappt sich der Sch√§tzbereich des Parameters f√ºr Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise h√§tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis pr√ºfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.\n\n10.7.8 Priori-Werte √§ndern\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. F√ºr Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nf√ºr Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich mit prior_summary(modell) ausgeben lassen.\n\nCodeprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Prioris anpassen wollen. So k√∂nnte man z.B. auf Basis von Fachwissen √ºber das Gewicht von Pinguinen postulieren, dass Adelie-Pinguine im Mittel 3000 g wiegen. Und dass die anderen zwei Pinguin-Arten im Mittel sich nicht unterscheiden vom Mittelwert der Adelie-Pinguine.\n\nCodem10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3704.05651         24.43995       1358.46254\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nCodem10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(3000, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##        3700.3850          29.4747        1375.1336\n\n\nDen Parameter f√ºr die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen.\n\nCodesigma(m10.6b)\n## [1] 463.3178\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die Gr√∂√üe der Konfidenzintervalle.\n√úbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren.12\n\n10.7.9 Vertiefung: Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\nCodepenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern.\n\nCodelevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nCodelibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verf√ºgbar sein muss.\nJetzt haben wir die Referenzkategorie ge√§ndert:\n\nCodelevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell, s. Tabelle¬†10.12.\n\nCodem10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nTabelle¬†10.12: m10.6a mit ge√§nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 4993.36, 5154.95]\n\n\nspeciesAdelie\n[-1490.02, -1267.35]\n\n\nspeciesChinstrap\n[-1471.62, -1207.85]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1-x2",
    "href": "1000-metrische-AV.html#y-x1-x2",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.8 y ~ x1 + x2\n",
    "text": "10.8 y ~ x1 + x2\n\nHier untersuchen wir Forschungsfragen mit zwei metrischen UV (und einer metrischen AV).\n\n10.8.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabh√§ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa ‚ÄúIQ der Mutter ist die Ursache zum IQ des Kindes‚Äù) wird impliziert.\nEs geht in dieser Forschungsfrage rein darum, Zusammenh√§nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. F√ºr solche Fragen ist ein Kausalmodell n√∂tig: Fachlich fundierte Annahmen √ºber Kausalzusammenh√§nge zwischen UV und AV.\n\n10.8.2 Was hei√üt, X h√§ngt mit Y zusammen?\n\nDer Begriff ‚ÄúZusammenhang‚Äù ist nicht exakt.\nH√§ufig wird er (f√ºr metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie gro√ü der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem ‚ÄúEffekt von X auf Y‚Äù √ºbersetzt. Vorsicht: ‚ÄúEffekt‚Äù klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begr√ºndung f√ºr einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der St√§rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugeh√∂rigen Regression im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten, bevor man ein (Regressions-)Modell aufstellt, s. Tabelle¬†10.13.\n\nCodekidiq %&gt;% \n  correlation()\n\n\n\n\n\nTabelle¬†10.13: Korrelation der Variablen im Datensatz kidiq (inkl. frequentistischer Statistiken wie t- und p-Werten, die wir hier ignorieren)\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.166\n\n\nkid_score\nmom_iq_c\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_hs\nmom_iq_c\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\nmom_iq\nmom_iq_c\n1.00\n(1.00, 1.00)\n1.39e+09\n&lt; .001***\n\n\nmom_age\nmom_iq_c\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\n\n\nTabelle¬†10.14 zeigt die Korrelationsmatrix als Korrelationsmatrix.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\n\nTabelle¬†10.14: Die Korrelationen zwischen den Variablen der Tabelle kidiq. Die Sterne geben einen Bereich des p-Werts an (wir ignorieren die Sterne hier).\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_iq_c\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.45***\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.28***\n0.21***\n0.28***\n\n\n\nmom_iq\n1.00***\n0.09\n\n\n\n\nmom_age\n0.09\n\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nN√ºtzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, Abbildung¬†10.15.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung¬†10.15: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n10.8.3 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro Pr√§diktor, also eine f√ºr mom_iq und eine f√ºr mom_age.\n\nCodem10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nTabelle¬†10.15 zeigt die Ergebnisse f√ºr mom_iq.\n\n\n\nTabelle¬†10.15: Parameter f√ºr m10.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.92\n(14.45, 36.83)\n100%\n1.001\n3924.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.72)\n100%\n1.000\n3948.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nTabelle¬†10.16 zeigt die Ergebnisse f√ºr mom_age.\n\n\n\nTabelle¬†10.16: Parameter f√ºr m10.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n71.01\n(54.24, 87.29)\n100%\n0.999\n3832.00\nNormal (86.80 +- 51.03)\n\n\nmom_age\n0.69\n(-8.62e-03, 1.42)\n97.32%\n0.999\n3853.00\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n10.8.4 Visualisierung der univariaten Regressionen\nIn Abbildung¬†10.16 ist die univariate Regression mit jeweils einem der beiden Pr√§diktoren dargestellt.\nm10.7: Die Steigung betr√§gt 0.6. m10.8: Die Steigung betr√§gt 0.7.\n\n\n\n\n\n\n\nAbbildung¬†10.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n10.8.5 Multiples Modell (beide Pr√§diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein Pr√§diktor im Modell aufgenommen ist, s Tabelle¬†10.17.\n\nCodem10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\nparameters(m10.9)\n\n\n\n\n\nTabelle¬†10.17: Parameter f√ºr m10.9\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n17.72\n(-0.31, 35.41)\n97.25%\n1.000\n5338.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.60\n(0.49, 0.72)\n100%\n1.000\n5083.00\nNormal (0.00 +- 3.40)\n\n\nmom_age\n0.40\n(-0.26, 1.05)\n88.58%\n1.000\n5495.00\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich (potenziell) zu den von den jeweiligen univariaten Regressionen.\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils ‚Äúbereinigt‚Äù vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht. Das bedeutet anschaulich, man betrachtet den den Zusammenhang einee UV mit der AV, wobei man gleichzeitig den anderen Pr√§diktor konstant h√§lt.\nIn Abbildung¬†10.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildung¬†10.17: 3D-Visualisierung von m10.9 (zwei Pr√§diktoren)\n\n\n\nAbbildung¬†10.18 zeigt eine Visualisierung von m10.9, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildung¬†10.18: Modell m10.9; die Farbverl√§ufe zeigen der Wert der abh√§ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farb√§nderung) die Ver√§nderung f√ºr die AV (kid_score). Auf der Achse f√ºr mom_age sieht man, dass sich die AV kaum √§ndert, wenn sich mom_age √§ndert.\n\n10.8.6 Visualisierung in 10 Dimensionen\nAbbildung¬†10.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildung¬†10.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schw√§chen, eine gro√üe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y-x1_z-x2_z",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.9 y ~ x1_z + x2_z\n",
    "text": "10.9 y ~ x1_z + x2_z\n\nIn diesem Abschnitt untersuchen wir ein Modell mit zwei z-standardisierten, metrischen Pr√§diktoren (und einer metrischen, nicht-standardisierten UV).\n\n10.9.1 Relevanz der Pr√§diktoren\nWoher wei√ü man, welche UV am st√§rksten mit der AV zusammenh√§ngt? Man k√∂nnte auch sagen: Welcher Pr√§diktor (welche UV) am ‚Äúwichtigsten‚Äù ist oder den ‚Äúst√§rksten Einfluss‚Äù auf die AV aus√ºbt? Bei solchen kausal konnotierten Ausdr√ºcken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann f√ºr sich nur Muster in den Daten, also Zusammenh√§nge bzw. Unterschiede, entdecken, s. Abbildung¬†10.20. M√∂chte man die Relevanz von Pr√§diktoren vergleichen, so ist ein Kausalmodell empfehlenswert.\n\n\n\n\n\nAbbildung¬†10.20: Made at imgflip.com\n\n\nWelcher Pr√§diktor ist nun ‚Äúwichtiger‚Äù oder ‚Äúst√§rker‚Äù in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)? Die Antwort h√§ngt auch von der Streuung bzw. Skalierung der Variablen ab. mom_iq hat den gr√∂√üeren Koeffizienten und viel Streuung; mom_age hat weniger Streuung.\nUm die Relevanz der Pr√§diktoren vergleichen zu k√∂nnen, m√ºsste man vielleicht die Ver√§nderung von kid_score betrachten, wenn man von kleinsten zum gr√∂√üten Pr√§diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die Ver√§nderung in der AV zu betrachten, wenn man den Pr√§diktor von ‚Äúunterdurchschnittlich‚Äù auf ‚Äú√ºberdurchschnittlich‚Äù √§ndert. Das kann man mit z-Standardisierung erreichen, s. ?sec-standardnormalverteilung.\n\n\n\n\nCodekidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;%  # z-Transformation\n  select(mom_iq, mom_iq_z) %&gt;% \n  head()\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit der Effekte von UV, die (zuvor) verschiedene Mittelwerte und Streuungen hatten13. Die Standardisierung ist √§hnlich zur Vergabe von Prozentr√§ngen: ‚ÄúDieser Messwert geh√∂rt zu den Top-3-Prozent‚Äù. Diese Aussage ist bedeutsam f√ºr Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen f√ºr verschiedene Verteilungen m√∂glich.\n\n10.9.2 Statistiken zu den z-transformierten Variablen\nTabelle¬†10.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Auspr√§gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener Pr√§diktoren sind einfacher in ihrer Gr√∂√üe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und √§hnlich gro√üe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (‚ÄúSkalierung‚Äù) mit standardize (aus easystats) durchf√ºhren, s. Tabelle¬†10.18.\n\nCodekidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\n\nTabelle¬†10.18: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nmom_iq_c\npred_m10.9\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_c_z\npred_m10.9_z\n\n\n\n65\n1\n121.12\n27\n21.12\n101.35\n-1.07\n0.52\n1.41\n1.56\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n-10.64\n81.43\n0.55\n0.52\n-0.71\n0.82\n-0.71\n-0.60\n\n\n85\n1\n115.44\n27\n15.44\n97.93\n-0.09\n0.52\n1.03\n1.56\n1.03\n1.19\n\n\n83\n1\n99.45\n25\n-0.55\n87.51\n-0.19\n0.52\n-0.04\n0.82\n-0.04\n0.06\n\n\n115\n1\n92.75\n27\n-7.25\n84.26\n1.38\n0.52\n-0.48\n1.56\n-0.48\n-0.29\n\n\n98\n0\n107.90\n18\n7.90\n89.83\n0.55\n-1.91\n0.53\n-1.77\n0.53\n0.31\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt daf√ºr, dass die urspr√ºnglichen Variablen beim z-Standardisieren nicht √ºberschrieben werden, sondern angeh√§ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nCodekidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. Tabelle¬†10.19. Dazu verwendet man den Befehl scale().\n\nCodekidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\n\nTabelle¬†10.19: Z-Standardisierung ohne Extrapaket‚Äù\n\n\n\n  \n\n\n\n\n\n\n\n10.9.3 Modell\nBerechnen wir das Modell m10.10: y ~ x1_z + x2_z.\n\nCodem10.10 &lt;- stan_glm(kid_score ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\nparameters(m10.10)\n\n\n\n\n\nTabelle¬†10.20: Parameter von m10.12\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n86.81\n(85.05, 88.51)\n100%\n0.999\n4760.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq_z\n9.07\n(7.36, 10.82)\n100%\n1.000\n5044.00\nNormal (0.00 +- 51.03)\n\n\nmom_age_z\n1.03\n(-0.81, 2.79)\n87.40%\n1.000\n5082.00\nNormal (0.00 +- 51.03)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.10 y_z ~ x1_z + x2_z\n",
    "text": "10.10 y_z ~ x1_z + x2_z\n\nIn diese Abschnitt berechnen wir ein Modell (Modell m10.12), in dem sowohl die Pr√§diktoren z-transformiert sind (standardisiert) als auch die AV. Das z-Standardisieren der AV, kid_score ist zwar nicht n√∂tig, um den Effekt der Pr√§diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage dar√ºber, um wie viele SD-Einheiten sich die AV ver√§ndert, wenn sich ein Pr√§diktor um eine SD-Einheit ver√§ndert. Das kann auch eine interessante(re) Aussage sein.\n\n10.10.1 Modell\nBerechnen wir das Modell m10.12: y_z ~ x1_z + x2_z.\n\nCodem10.12 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.12)\n##   (Intercept)      mom_iq_z     mom_age_z \n## -0.0004675098  0.4437853336  0.0506799505\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient f√ºr mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) √§ndert, wenn sich mom_iq um eine SD-Einheit √§ndert.\nDer Koeffizient f√ºr mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) √§ndert, wenn sich mom_age um eine SD-Einheit √§ndert.\n\nJetzt sind die Pr√§diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar. Man sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n10.10.2 95%-PI\nMit parameters k√∂nnen wir uns ein PI f√ºr m10.12 ausgeben lassen, s. Abbildung¬†10.21; im Standard wird ein 95%-ETI berichtet14.\n\nCodeparameters(m10.12) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-4.68e-04\n(-0.08, 0.09)\n50.45%\n0.999\n5373.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n4576.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.04, 0.14)\n88.05%\n1.000\n5284.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nCodeplot(eti(m10.12)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†10.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI f√ºr m10.12\n\n\n\n\n\n10.10.3 Modellg√ºte\n\nCoder2(m10.12)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.142, 0.269])\n\n\nIst dieser Wert von \\(R2\\) ‚Äúgut‚Äù? Diese Frage ist √§hnlich zur Frage ‚ÄúIst das viel Geld?‚Äù; man kann die Frage nur im Kontext beantworten.\nEine einfache L√∂sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erkl√§rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zuf√§llig hohen Werten der Modellg√ºte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine ‚Äúobjektive‚Äù Antwort auf die Frage ‚Äúwie viel ist viel?‚Äù haben wollen, ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage ‚ÄúWieviel ist viel?‚Äù gegeben hat (Cohen, 1992):\n\nCodeinterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n10.10.4 Priori-Verteilung f√ºr m10.12 und Modelldefinition\nDie Prioris f√ºr m10.12 kann man sich mit prior_summary(m10.12) ausgeben lassen. Danke, Stan!\n\nCodeprior_summary(m10.12)  # aus rstanarm\n## Priors for model 'm10.12' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\nü§ñ Nix zu danken!\n\nWie gesagt, Stan nimmt daf√ºr einfach die empirischen Mittelwerte und Streuungen her.15\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. Gleichung¬†10.4.\n\\[\n\\begin{aligned}\n\\text{kidscore}^z_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{momiq}_i^z + \\beta_2\\text{momage}_i^z \\\\\n\\beta_0 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{10.4}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.12. Dadurch, dass nicht nur UV, sondern auch AV z-standardisiert (d.h. zentriert und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuf√ºhren.\n\nBeispiel 10.3 (Anzahl der Modellparameter) Wie viele Modellparameter hat m10.12?16\n\n\n10.10.5 Antwort auf die Forschungsfrage\n\nDas Modell spricht sich klar f√ºr einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erk√§rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al., 2020) zur√ºck (s. Anhang f√ºr Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem ‚Äústatistischen Effekt‚Äù gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenh√§nge, und nicht um kausale Zusammenh√§nge, handelt. Kausale Zusammenh√§nge d√ºrfen wir nur verk√ºnden, wenn wir sie a) explizit untersuchen und b) sich in der Literatur Belege daf√ºr finden oder c) wir ein Experiment fachgerecht durchgef√ºhrt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\n\n10.11.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch, s. Theorem¬†10.2.\n\nTheorem 10.2 (Regression als Korrelation) \\[b = r \\frac{sd_x}{sd_y}\\quad \\square\\]\n\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die Punktsch√§tzer f√ºr die Regressionskoeffizienten, s. m10.12.\n\nCodem10.12 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.12)\n##   (Intercept)      mom_iq_z \n## -0.0001090892  0.4494258316\n\n\nVergleichen Sie diese Werte mit der Korrelation, s. Tabelle¬†10.21.17\n\nCodekidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelle¬†10.21: Correlation Matrix (pearson-method)\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n10.11.2 Pr√ºfen der Linearit√§tsannahme\nZentrale Annahme eines linearen Modells: Die AV ist eine lineare Funktion der einzelnen Pr√§diktoren, $y= _0 + _1x_1 + _2 x_2 + $, vgl. Theorem¬†2.1.\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression h√§ufig normalverteilte Residuen an18, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu sch√§tzen (Gelman et al., 2021).\nIst die Linearit√§tsannahme erf√ºllt, so sollte der Residualplot nur zuf√§llige Streuung um \\(y=0\\) herum zeigen, s. Abbildung¬†10.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tats√§chlichem Wert: \\(e_i = y_i - \\hat{y}_i\\)\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.12_pred = predict(m10.12),  # vorhergesagten Werte\n         m10.12_resid = resid(m10.12))  # Residuen\n\n\n\nCodekidiq %&gt;% \n  ggplot(aes(x = m10.12_pred, y = m10.12_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildung¬†10.22: Die Verteilung der Fehler scheint keinem starken Trend (in Abh√§ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine gr√∂√üeren Auff√§lligkeiten.\n\n10.11.3 Modellpr√ºfung mit der PPV\n\nCodepp_check(m10.12)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht h√§ufig.\n\n10.11.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildung¬†10.23: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildung¬†10.23 zeigt in der oberen Reihe die Regression eines Pr√§diktors auf den anderen Pr√§diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das hei√üt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenh√§ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das hei√üt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenh√§ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n10.11.5 Bayesianisch gleich Frequentistisch?\n√úbrigens liefern stan_glm() und lm oft √§hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nCodestan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n## 36.83948742 -0.01863773 -2.27400905\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch √§hnlich sein k√∂nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.12 Fazit",
    "text": "10.12 Fazit\n\n10.12.1 Austieg: Bayes in f√ºnf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\nüì∫ Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\nüì∫ Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n10.12.2 Ausblick: Bin√§re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\nCodedata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m14: am ~ mpg_z:\n\nCodem14 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m14)\n## (Intercept)       mpg_z \n##   0.4062231   0.2978417\n\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nCodemtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m14)[1],\n              slope = coef(m14)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nCodeneg_am &lt;- predict(m14, newdata = tibble(mpg_z = -1.3))\n\n\nF√ºr kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte f√ºr am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. M√ºssen wir mal bei Gelegenheit besser machen.\n\n10.12.3 Genug f√ºr heute\nWir waren flei√üig ‚Ä¶\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.\n\n\nGenug f√ºr heute. üëç\n\n10.12.4 Weiterf√ºhrende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman et al. (2021), Kap. 10, insbesondere 10.3.\nGelman et al. (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit f√ºhrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig √ºberschaubarem mathematischen Aufwand.\nF√ºr das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.13 Aufgaben",
    "text": "10.13 Aufgaben\n\n10.13.1 Papier-und-Bleistift-Aufgaben\n\nanz-params\nfofrage-regrformel2\nmodelldef-regrformel\nfinde-prior/\nNullhyp-Beispiel\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nzwert-berechnen\nstan_glm_parameterzahl\nkausale-verben\n\n10.13.2 Aufgaben, f√ºr die man einen Computer ben√∂tigt\n\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope4\n\n10.13.3 Vertiefung\n\nAnova-skalenniveau\nttest-skalenniveau\nstan_glm_prioriwerte",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "\n10.14 ‚Äî",
    "text": "10.14 ‚Äî\n\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155‚Äì159.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). Rstanarm: Bayesian Applied Regression Modeling via Stan. https://mc-stan.org/rstanarm\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#footnotes",
    "href": "1000-metrische-AV.html#footnotes",
    "title": "\n10¬† Fallbeispiele\n",
    "section": "",
    "text": "Hier ist eine kurze Erkl√§rung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablen‚Ü©Ô∏é\nHier finden Sie eine kurze Erkl√§rung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktion‚Ü©Ô∏é\nauch DAG genannt, s. Kapitel 11‚Ü©Ô∏é\nH√§ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - ‚Äúgr√∂√üer als/kleiner als‚Äù - zu formulieren, anstelle der ‚Äúempirisch √§rmeren‚Äù einfachen, ungerichteten Ungleichheit‚Ü©Ô∏é\nunknown, sozusagen der unbekannte Gott, also f√ºr alle sonstigen Einfl√ºsse; man kann das ‚Äúu‚Äù ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgef√ºhrt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es g√§be keine anderen Einfl√ºsse als mom_hs auf die IQ des Kindes.‚Ü©Ô∏é\nGenauer gesagt wird gepr√ºft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.‚Ü©Ô∏é\nGenauer gesagt, erlaubt der t-Test in der Form des Welche-Tests auch Abweichungen von der Varianzhomogenit√§t der gestesten Gruppen. Die Regression geht hingegen von Varianzhomogenit√§t (Homoskedastizit√§t) aus. Allerdings ist diese Annahme nicht von besonderer Bedeutung, wenn es um die Regressionskoeffizienten geht.‚Ü©Ô∏é\nDAG, s. Kapitel 11‚Ü©Ô∏é\nDabei nehmen wir an, dass x und u nicht voneinander abh√§ngen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.‚Ü©Ô∏é\nVgl. Abschnitt ‚ÄúUV zentrieren‚Äù im Kursbuch Statistik1.‚Ü©Ô∏é\nauch ETI (Equal Tails Interval) genannt‚Ü©Ô∏é\ns. Details hier.‚Ü©Ô∏é\nam n√ºtzlichsten ist diese Standardisierung bei normal verteilten Variablen.‚Ü©Ô∏é\nZumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen k√∂nnen sich √§ndern. Am besten in der Dokumentation nachlesen: ?parameters.‚Ü©Ô∏é\nNicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Sch√§tzer der echten Parameter sein m√ºssten, wenn die Stichprobe, die wir ihm angeschleppt h√§tten, tats√§chlich gut ist‚Ä¶‚Ü©Ô∏é\n4: \\(\\beta_0, \\beta_1, \\beta_2, \\sigma\\)‚Ü©Ô∏é\nIgnorieren Sie die Zeile mit dem Befehl display(). Dieser Befehl dient nur dazu, die Ausgabe zu versch√∂nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.‚Ü©Ô∏é\nwas auf normal verteilte AV hinauslaufen kann aber nicht muss‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html",
    "href": "1150-konfundierung.html",
    "title": "11¬† Konfundierung",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#lernsteuerung",
    "href": "1150-konfundierung.html#lernsteuerung",
    "title": "11¬† Konfundierung",
    "section": "",
    "text": "11.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 R-Pakete\nF√ºr dieses Kapitel ben√∂tigen Sie folgende R-Pakete:\n\nCodelibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n11.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. Tabelle¬†11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie k√∂nnen ihn entweder √ºber die Webseite herunterladen:\n\nCodeSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\n\nOder aber √ºber das Paket mosaic importieren:\n\nCodedata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # k√ºrzerer Name, das ist leichter zu tippen\n\n\n\n11.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerkl√§ren, was eine Konfundierung ist\nDAGs lesen und zeichen\nKonfundierung in einem DAG erkennen\n\n11.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. √Ñhnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).\n\n11.1.6 √úberblick\nIn diesem Kapitel steigen wir ein in das Themengebiet Kausalanalyse (oder synonym Kausalinferenz). Wir besch√§ftigen uns also mit der f√ºr die Wissenschaft (und den Rest des Universums) zentralen Frage, was die Ursache eines Ph√§nomens ist. In diesem ersten Kapitel zu dem Thema geht es um einen h√§ufigen Fall von ‚ÄúScheinkorrelation‚Äù, also eines Zusammenhangs zwischen UV und AV, der aber gar kein echter kausaler ist, sondern nur Schein. Bei diesem Scheinzusammenhang handelt es sich um die Konfundierung. Im n√§chsten Kapitel schauen wir uns die verbleibenden Grundbausteine der Kausalinferenz an.\n\n11.1.7 Einstieg\n\n11.1.8 Von St√∂rchen und Babies\nKennen Sie die Geschichte von St√∂rchen und Babies? Ich meine nicht die aus dem Biologieunterricht in der f√ºnften Klasse, sondern in einem statistischen Zusammenhang. Was war da noch mal die Moral von der Geschichte?1 \\(\\square\\)\n\n11.1.9 Erlaubt eine Regressionsanalyse Kausalschl√ºsse?\nFindet man in einer Regressionsanalyse einen ‚ÄúEffekt‚Äù, also ein Regressionsgewicht ungleich Null, hei√üt das dann, dass die UV die Ursache der AV ist?2 Erkl√§ren Sie diesen Sachverhalt genauer. \\(\\square\\)",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "href": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "title": "11¬† Konfundierung",
    "section": "\n11.2 Statistik, was soll ich tun?",
    "text": "11.2 Statistik, was soll ich tun?\n\n11.2.1 Studie A: √ñstrogen\n\n11.2.1.1 Medikament einnehmen?\nMit Blick auf Tabelle¬†11.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelle¬†11.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nM√§nner\n81/87 √ºberlebt (93%)\n234/270 √ºberlebt (87%)\n\n\nFrauen\n192/263 √ºberlebt (73%)\n55/80 √ºberlebt (69%)\n\n\nGesamt\n273/350 √ºberlebt (78%)\n289/350 √ºberlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualit√§t (Beobachtungsstudie). Bei M√§nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und M√§nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl et al., 2016)?\n\n11.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (√ñstrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (√ñstrogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in Abbildung¬†11.1 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†11.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender √ºber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige L√∂sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder ‚ÄúSchichten‚Äù (‚ÄúStrata‚Äù).\n\n\n\n11.2.2 Studie B: Blutdruck\n\n11.2.2.1 Medikament einnehmen?\nMit Blick auf Tabelle¬†11.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelle¬†11.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 √ºberlebt (93%)\n234/270 √ºberlebt (87%)\n\n\nhoher Blutdruck\n192/263 √ºberlebt (73%)\n55/80 √ºberlebt (69%)\n\n\nGesamt\n273/350 √ºberlebt (78%)\n289/350 √ºberlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualit√§t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe √ºber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl et al., 2016)?\n\n11.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament sch√§dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in Abbildung¬†11.2 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†11.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer sch√§dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den n√ºtzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren w√§re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar w√§re.\n\n\n\n11.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs Abbildung¬†11.1 und Abbildung¬†11.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen f√ºr Handlungen - war nur m√∂glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n11.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht f√ºr Kausalschl√ºsse. üßü\nStatistik plus Theorie erlaubt Kausalschl√ºsse. üìö‚ûïüìä üü∞ ü§©\n\n\n\n\n\n\nWichtig\n\n\n\nF√ºr Entscheidungen (‚ÄúWas soll ich tun?‚Äù) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n11.2.5 Vertiefung3\n\n\n11.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. √Ñrzte tendieren zu Behandlung A bei gro√üen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die √Ñrzte zu Behandlung B.\nSollte ein Patient, der nicht wei√ü, ob sein Nierenstein gro√ü oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach Steingr√∂√üe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) w√§hlt?\nDie Gr√∂√üe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (‚ÄúKette‚Äù) von Gr√∂√üe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. Dar√ºber hinaus gibt es noch einen Einfluss von Gr√∂√üe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in Abbildung¬†11.3 dargestellt; Abbildung¬†11.4 visualisiert alternativ. Beide Varianten zeigen das Gleiche. Sie k√∂nnen sich einen aussuchen. Hier sind beide Varianten gezeigt, damit Sie wissen, dass verschiedene Darstellungsformen m√∂glich sind.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment sch√§tzen m√∂chte? Oder lieber nicht kontrollieren?\n\n\nDAG links-rechts\nDAG oben-unten\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. W√ºrde man nicht size kontrollieren, bek√§me man den ‚Äúvermengten‚Äù Effekt von size und treatment, also keine (belastbare) Aussage √ºber den Effekt der Behandlung.\n\n11.2.5.2 Mehr Beispiele\n\nBeispiel 11.1 Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erh√∂hen, wenn du heiratest. \\(\\square\\)\n\n\nBeispiel 11.2 Studien zeigen, dass Leute, die sich beeilen, zu sp√§t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu sp√§t zu deiner Besprechung. \\(\\square\\)\n\n\n11.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zus√§tzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht n√∂tig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen daf√ºr, dass es keine Konfundierung gibt.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#konfundierung",
    "href": "1150-konfundierung.html#konfundierung",
    "title": "11¬† Konfundierung",
    "section": "\n11.3 Konfundierung",
    "text": "11.3 Konfundierung\n\n11.3.1 Die Geschichte von Angie und Don\n\n\n\nüßë\n\nDon, Immobilienmogul, Auftraggeber\n\n\nüë©\n\nAngie, Data Scientistin.\n\n\nüßû\n\nWolfie, Post-Nerd, kommt in dieser Geschichte aber nicht vor\n\n\nüì∫ Don und Angie\n\n11.3.2 Datensatz ‚ÄòHauspreise im Saratoga County‚Äô\nImportieren Sie den Datensatz SaratogaHouses, s. Kapitel 11.1.3.\n\n\n\nTabelle¬†11.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n11.3.3 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\n‚ÄúFinden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!‚Äù\n\nüßë Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\nüë© üî¨ Das ist Angie, Data Scientistin.\n\n11.3.4 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\n‚ÄúHey Don! Mehr Zimmer, mehr Kohle!‚Äù üë© üî¨\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. Abbildung¬†11.5.\n\n\n\n\n\n\n\nAbbildung¬†11.5: Modell m1\n\n\n\n\n\n‚ÄúJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.‚Äù\n\nüë©\n\nZu wenig! ü§¨\n\nüßë\nBerechnen wir das Modell m1; der Punktsch√§tzer des Parameters bedroom steht in Tabelle¬†11.4.\n\nCodem1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\n\nTabelle¬†11.4: Parameter f√ºr m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die Punktsch√§tzer der Parameter eines Modells zur√ºck, aber nicht die Sch√§tzbereiche. M√∂chten Sie beides, k√∂nnen Sie die Funktion parameters(modell) nutzen.4\nMit estimate_predictions k√∂nnen wir Vorhersagen berechnen (bzw. sch√§tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist ‚Äúsch√§tzen‚Äù vielleicht das treffendere Wort). Tabelle¬†11.5 zeigt den laut m1 vorhergesagten Hauspreis f√ºr ein Haus mit 2 Zimmern.\n\nCodedons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\n\nTabelle¬†11.5: Vorhersage des Hauspreises f√ºr ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.53e+05\n89682.42\n(-21279.13, 3.27e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.5 Don hat eine Idee\n\n‚ÄúIch bau eine Mauer! Genial! An die Arbeit, Angie!‚Äù üßë\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\n‚ÄúDas ist keine gute Idee, Don.‚Äù\n\nüë©\nBerechnen wir die Vorhersagen f√ºr Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. Tabelle¬†11.6.5\n\nCodedons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\n\nTabelle¬†11.6: Vorhergesagter Hauspreis laut m1 f√ºr ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n89137.61\n(79832.69, 4.25e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, s. Abbildung¬†11.5.\n\n‚ÄúVolltreffer! Jetzt verdien ich 100 Tausend mehr! ü§ë Ich bin der Gr√∂√üte!‚Äù üßë\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: ‚Äú4e+05‚Äù ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n11.3.6 R-Funktionen, um Beobachtungen vorhersagen\npredict(m1, dons_new_house) oder point_estimate(m1, dons_new_house) sagt einen einzelnen Wert vorher (den sog. Punktsch√§tzer der Vorhersage).6 Ein Intervall wird nicht ausgegeben.\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, ber√ºcksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im ‚ÄúStrukturmodell‚Äù: Wenn also z.B. in unserem Modell ein wichtiger Pr√§diktor fehlt, so kann die Vorhersagen nicht pr√§zise sein. Fehler im Strukturmodell schlagen sich in breiten Sch√§tzintervallen (bedingt durch ein gro√ües \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. ber√ºcksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten)\n\nDie Sch√§tzbereiche sind in dem Fall deutlich kleiner, s. Tabelle¬†11.7.\n\nCodeestimate_expectation(m1, dons_new_house)\n\n\n\n\n\nTabelle¬†11.7: Ungewissheit f√ºr die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\nModel-based Expectation\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3109.34\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.7 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. Tabelle¬†11.8 gibt den Punktsch√§tzer f√ºr die Koeffizienten wider.\n\nCodem2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\n\nTabelle¬†11.8: Parameter (Punktsch√§tzer, keine Sch√§tzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36890.16\n\n\nbedrooms\n-14206.16\n\n\nlivingArea\n125.36\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? Tabelle¬†11.9 gibt Aufschluss f√ºr den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 Quadratfu√ü Wohnfl√§che; Tabelle¬†11.10 gibt die Sch√§tzung (laut m2) f√ºr den Preis eines Hauses mit 2 Zimmern (und der gleichen Wohnfl√§che). Die Vorhersage erh√§lt man mit dem Befehl predict():\n\nCodepredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130369.5\n\n\n\n\n\nTabelle¬†11.9: Vorhersage von m2 f√ºr ein Haus mit 4 Zimmern und 1200 Einheiten Wohnfl√§che\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelle¬†11.10: Vorhersage von m2 f√ºr ein Haus mit 2 Zimmern und 1200 Einheiten Wohnfl√§che\n\n\n\n  \n\n\n\n\n\n\nAndere, aber √§hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt √ºber die verschiedenen Gr√∂√üen von livingArea? Stellen Sie sich alle H√§user mit 4 Zimmern vor (also mit verschiedenen Wohnfl√§chen). Wir m√∂chten nur wissen, was so ein Haus ‚Äúim Mittel‚Äù kostet. Wir m√∂chten also die Mittelwerte pro bedroom sch√§tzen, gemittelt f√ºr jeden Wert von bedroom √ºber livingArea. Die Ergebnisse stehen in Tabelle¬†11.11 und sind in Abbildung¬†11.6 visualisiert.\n\nCodeestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelle¬†11.11: Vorhersagen des Preises von H√§usern mit verschiedener Zimmerzahl gemittelt √ºber die verschiedenen Werte der Wohnfl√§che; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\n‚ÄúDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!‚Äù\n\nüë©\n\n‚ÄúVerringert!? Weniger Geld?! Oh nein!‚Äù\n\nüßë\n\n11.3.8 Die Zimmerzahl ist negativ mit dem Preis korreliert\n‚Ä¶ wenn man die Wohnfl√§che (Quadratmeter) kontrolliert, s. Abbildung¬†11.7.\n\n‚ÄúNe-Ga-Tiv!‚Äù\n\nüë©\n\n\n\n\n\nAbbildung¬†11.7: Hauspreis stratifizieren\n\n\nQuellcode\n\n\n\n\n\n\nHinweis\n\n\n\nAussagen, gleich ob sie statistischer, wissenshaftlicher oder sonstiger Couleur sind, k√∂nnen immer nur dann richtig sein, wenn ihre Annahmen richtig sind. Behauptet etwa ein Modell, dass der Wert einer Immobilie steigt, wenn man mehr Zimmer hat, so ist das kein Naturgesetz, sondern eine Aussage, die nur richtig sein kann, wenn das zugrundeliegende Modell richtig ist. \\(\\square\\)\n\n\n\n11.3.9 Kontrollieren von Variablen\nüí° Durch das Aufnehmen von Pr√§diktoren in die multiple Regression werden die Pr√§diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen Pr√§diktors mit \\(y\\), wenn man den (oder die) anderen Pr√§diktoren statistisch konstant h√§lt.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom ‚ÄúNetto-Effekt‚Äù eines Pr√§diktors, oder davon, dass ein Pr√§diktor ‚Äúbereinigt‚Äù wurde vom (linearen) Einfluss der anderen Pr√§diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Pr√§diktors \\(x_1\\) auf \\(y\\) anzeigen unabh√§ngig vom Effekt der anderen Pr√§diktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Pr√§diktors \\(x_1\\) wird f√ºr jede Auspr√§gung (Gruppe) des Pr√§diktors \\(x_2\\) berechnet.\n\n\n\n\n\n\nWichtig\n\n\n\nDas Hinzuf√ºgen von Pr√§diktoren kann die Gewichte der √ºbrigen Pr√§diktoren √§ndern. \\(\\square\\)\n\n\n\nAber welche und wie viele Pr√§diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nüßë\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nüë©\n\nWozu ist sie dann gut?!\n\nüßë\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erkl√§rung der Ursachen heranzuziehen: Die Regressionskoeffizienten k√∂nnen sich wild √§ndern, wenn man Pr√§diktoren hinzuf√ºgt oder wegl√§sst. Es k√∂nnen sich sogar die Vorzeichen der Regressionsgewichte √§ndern; in dem Fall spricht man von einem Simpson-Paradox.\n\n\n\n11.3.10 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, we‚Äôd like to know wheter an effect is ‚Äúreal‚Äù or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical ‚Äútests‚Äù on its way to acceptance.\n\n‚Äì McElreath (2020), S. 139\n\n11.3.11 Kausalmodell f√ºr Konfundierung, km1\n\nDas Kausalmodell km1 ist in Abbildung¬†11.8 dargestellt; vgl. Abbildung¬†11.7.\n\n\n\n\n\n\n\nAbbildung¬†11.8: Kausalmodell km1 - Eine Erkl√§rung (von mehreren) f√ºr m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms. Eine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht. d_connected hei√üt, dass die betreffenden Variablen ‚Äúverbunden‚Äù sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flie√üt üåä. d_separated hei√üt, dass sie nicht d_connected sind.\n\n11.3.12 m2 kontrolliert die Konfundierungsvariable livingArea\n\n\nBeispiel 11.3 In Abbildung¬†11.8 ist living area eine Konfundierungsvariable f√ºr den Zusammenhang von bedrooms und price. \\(\\square\\)\n\n\nDefinition 11.1 (Konfundierungsvariable) Eine Konfundierungsvariable (Konfundierer) ist eine Variable, die den Zusammenhang zwischen UV und AV verzerrt, wenn sie nicht kontrolliert wird (VanderWeele & Shpitser, 2013). \\(\\square\\)\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt blo√ü?! Oh jeh!\n\nüßë\n\nWir m√ºssen die Konfundierungsvariable kontrollieren.\n\nüë©\nAbbildung¬†11.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildung¬†11.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (‚Äúadjustieren‚Äù), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separated.\n\nDefinition 11.2 (Blockieren) Das Kontrollieren eines Konfundierers (wie living_area) ‚Äúblockt‚Äù den betreffenden Pfad, f√ºhrt also dazu, dass √ºber diesen Pfad keine Assoziation (z.B. Korrelation) zwischwen UV (bedrooms) und AV (price) mehr vorhanden ist. UV und AV sind dann d_separated (‚Äúgetrennt‚Äù). \\(\\square\\)\n\n\n11.3.13 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, Abbildung¬†11.10, links: Es wird (f√§lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, Abbildung¬†11.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildung¬†11.10: Konfundierung von y und x!\n\n\nAbbildung¬†11.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. Au√üerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als Pr√§diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\nWichtig\n\n\n\nKontrollieren Sie Konfundierer. \\(\\square\\)\n\n\n\n11.3.14 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 d√ºrfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in Abbildung¬†11.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n11.3.15 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide Pr√§diktoren jeweils einen eigenen Beitrag zur Erkl√§rung der AV haben.\nDaher k√∂nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei Kausaleinfl√ºsse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) √ºber den Mediator (b) zur AV (p) auch Mediation, s. Abbildung¬†11.11.\n\n\n\n\n\n\n\nAbbildung¬†11.11: Der Effekt von livingArea wird √ºber den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n11.3.16 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. Abbildung¬†11.12.\n\n\n\n\n\n\n\nAbbildung¬†11.12: Dons Kausalmodell\n\n\n\n\n\n‚ÄúIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das gr√∂√üte! Alle anderen Kausalmodelle sind ein Disaster!‚Äù\n\nüßë\n\n\n‚ÄúDon, nach deinem Kausalmodell m√ºssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.‚Äù\n\nüßë\nRechne doch selber die Korrelation aus, Don:\n\n‚Äú√Ñh, wie ging das nochmal?‚Äù\n\nüßë\nSo k√∂nntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.B. so:\n\nCodedons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\n\nDie Korrelation liegt also bei 0.66\n\n‚ÄúBitte, gerne hab ich dir geholfen, Don.‚Äù\n\nüë©\n\n11.3.17 Unabh√§ngigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. Abbildung¬†11.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabh√§ngig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zus√§tzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete Unabh√§ngigkeit findet sich nicht in den Daten wieder, s. Tabelle¬†11.8. Also: ‚õàÔ∏è Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. Abbildung¬†11.11.\nDas Kausalmodell km2 postuliert keine Unabh√§ngigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betr√§gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so √§hnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. ü•±\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. Abbildung¬†11.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabh√§ngig von livingArea (a)\n‚õàÔ∏è km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "href": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "title": "11¬† Konfundierung",
    "section": "\n11.4 DAGs: Directed Acyclic Graphs",
    "text": "11.4 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B. Abbildung¬†11.12.\n\nDefinition 11.3 (DAG) DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen. Ein Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden. DAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung). DAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zur√ºckf√ºhren. \\(\\square\\)\n\n\nDefinition 11.4 (Pfad) Ein Pfad ist ein Weg durch den DAG, von Knoten zu Knoten √ºber die Kanten, unabh√§ngig von der Pfeilrichtung. \\(\\square\\)\n\nDer DAG von km1 ist in Abbildung¬†11.8 zu sehen.\n\n11.4.1 Leider passen potenziell viele DAGs zu einer Datenlage\nAuf Basis der in Dons Modell dargestellten (Un-)Abh√§ngigkeiten der Variablen sind noch weitere Kausalmodelle m√∂glich.\nIn Abbildung¬†11.13 sind diesen weiteren, m√∂glichen Kausalmodelle f√ºr Dons Modell dargestellt. Dabei sind folgende Abk√ºrzungen verwendet: b: bedrooms, p: price, a area (living area).\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach w√§re, die Kausalstruktur der Ph√§nomene zu entdecken, w√§ren sie l√§ngst erkannt, und alle Probleme der Menschheit gel√∂st.\n\n\n\n\n\n\n\nAbbildung¬†11.13: Kausalmodelle, die potenziell geeignet sind f√ºr Dons Fragestellung\n\n\n\n\nAlle diese DAgs in Abbildung¬†11.8 haben die gleichen Implikationen hinsichtlich der (Un-)Abh√§ngigkeiten zwischen der Variablen. Wir k√∂nnen also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, br√§uchten wir z.B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n11.4.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als ‚ÄúKausation‚Äù bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWei√ü man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt (McElreath, 2020). \\(\\square\\)\n\n\n\nDefinition 11.5 (Kausale Abh√§ngigkeit) Ist \\(X\\) die Ursache von \\(Y\\), so h√§ngt \\(Y\\) von \\(X\\) ab: \\(Y\\) ist (kausal) abh√§ngig von \\(X\\). \\(\\square\\)\n\nViele Menschen denken - f√§lschlich - dass Korrelation Kausation bedeuten muss, s. Abbildung¬†11.14.\n\n\n\n\n\n\n\nAbbildung¬†11.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und Erkl√§rung\n\nBeispiel 11.4 (Der Schoki-Dag) Der ‚ÄúSchoki-DAG‚Äù in Abbildung¬†11.15 zeigt den DAG f√ºr das Schokoloaden-Nobelpreis-Modell. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung¬†11.15: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#fazit",
    "href": "1150-konfundierung.html#fazit",
    "title": "11¬† Konfundierung",
    "section": "\n11.5 Fazit",
    "text": "11.5 Fazit\n\n11.5.1 Zusammenfassung\nSind zwei Variablen korreliert (abh√§ngig, assoziiert), so kann es daf√ºr zwei Gr√ºnde geben:\n\nKausaler (‚Äúechter‚Äù) Zusammenhang\nNichtkausaler Zusammenhang (‚ÄúScheinkorrelation‚Äù)\n\nMan ist daran interessiert, echten (also kausalen) Zusammenhang aufzudecken7 und Scheinkorrelation auszuschlie√üen.\nEine von zwei m√∂glichen Ursachen einer Scheinkorrelation ist Konfundierung.8\nKonfundierung kann man aufdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Pr√§diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so l√∂st sich der Scheinzusammenhang nach dem Adjustieren auf.\nL√∂st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenh√§nge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine k√∂nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist n√∂tig, um DAGs auszuschlie√üen.\n\n11.5.2 Ausstieg\n\nBeispiel 11.5 (Schoki macht Nobelpreis!?) Eine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen der H√∂he des Schokoladenkonsums eines Landes und der Anzahl der Nobelpreise eines Landes (Messerli, 2012), s. Abbildung¬†11.16.\n\n\n\n\n\n\n\nAbbildung¬†11.16: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle √ºberpr√ºfen, so wie wir das hier tun.\n\n\n\n\n11.5.3 Vertiefung\nEs gibt viel Literatur zu dem Thema Kausalinferenz. Ein Artikel, der einen vertieften Einblick in das Thema Konfundierung liefert z.B. Tennant et al. (2020) oder Suttorp et al. (2015). Allerdings sollte man neben Konfundierung noch die drei anderen ‚ÄúAtome‚Äù der Kausalinferenz - Kollision, Mediation (und Nachfahre) - kennen, um g√§ngige Fragen der Kausalinferenz bearbeiten zu k√∂nnen.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#aufgaben",
    "href": "1150-konfundierung.html#aufgaben",
    "title": "11¬† Konfundierung",
    "section": "\n11.6 Aufgaben",
    "text": "11.6 Aufgaben\n\nSammlung ‚Äúkausal‚Äù",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#section",
    "href": "1150-konfundierung.html#section",
    "title": "11¬† Konfundierung",
    "section": "\n11.7 ‚Äî",
    "text": "11.7 ‚Äî\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562‚Äì1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal Inference in Statistics: A Primer. Wiley.\n\n\nRohrer, J. M. (2018). Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data. Advances in Methods and Practices in Psychological Science, 1(1), 27‚Äì42. https://doi.org/10.1177/2515245917745629\n\n\nSuttorp, M. M., Siegerink, B., Jager, K. J., Zoccali, C., & Dekker, F. W. (2015). Graphical Presentation of Confounding in Directed Acyclic Graphs. Nephrology Dialysis Transplantation, 30(9), 1418‚Äì1423. https://doi.org/10.1093/ndt/gfu325\n\n\nTennant, P. W. G., Murray, E. J., Arnold, K. F., Berrie, L., Fox, M. P., Gadd, S. C., Harrison, W. J., Keeble, C., Ranker, L. R., Textor, J., Tomova, G. D., Gilthorpe, M. S., & Ellison, G. T. H. (2020). Use of Directed Acyclic Graphs (DAGs) to Identify Confounders in Applied Health Research: Review and Recommendations. International Journal of Epidemiology, 50(2), 620‚Äì632. https://doi.org/10.1093/ije/dyaa213\n\n\nVanderWeele, T. J., & Shpitser, I. (2013). On the Definition of a Confounder. Annals of statistics, 41(1), 196‚Äì220. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#footnotes",
    "href": "1150-konfundierung.html#footnotes",
    "title": "11¬† Konfundierung",
    "section": "",
    "text": "Nur weil die Variablen Anzahl_Stoerche und Anzahl_Babies korreliert sind, hei√üt das nicht, dass das eine die Ursache des anderen sein muss.‚Ü©Ô∏é\nNein‚Ü©Ô∏é\nDieser Abschnitt ist pr√ºfungsrelevant, birgt aber nichts Neues.‚Ü©Ô∏é\nIn aller Regel macht es mehr Sinn, die Sch√§tzbereiche der Punktsch√§tzer auch zu betrachten. Nur die Punktsch√§tzer zu betrachten vernachl√§ssigt wesentliche Information.‚Ü©Ô∏é\nAnstelle von estimate_relation() kann man auch (einfacher vielleicht) predict() verwenden: predict(m1, newdata = dons_new_house). Allerdings gibt predict() nur den vorhergesagten Wert aus. estimate_prediction() gibt noch zus√§tzlich das Vorhersageintervall aus, ber√ºcksichtigt also die (doppelte) Ungewissheit der Vorhersage. Mit anderen Worten: estimate_prediction gibt die PPV aus.‚Ü©Ô∏é\nBei predict ist dieser Wert der Median der Post-Verteilung; bei point_estimate kann man sich aussuchen, ob der Median, der Mittelwert oder der wahrscheinlichste Wert der Post-Verteilung als Sch√§tzwert verwendet wird.‚Ü©Ô∏é\nzu ‚Äúidentifizieren‚Äù‚Ü©Ô∏é\nDie andere Ursache ist die Kollisionsverzerrung, s. #sec-kausal.‚Ü©Ô∏é",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html",
    "href": "1180-kausalatome.html",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "",
    "text": "12.1 Lernsteuerung",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#lernsteuerung",
    "href": "1180-kausalatome.html#lernsteuerung",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "",
    "text": "12.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n12.1.2 R-Pakete\nF√ºr dieses Kapitel ben√∂tigen Sie folgende R-Pakete:\n\nCodelibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n12.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. Tabelle¬†11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie k√∂nnen ihn entweder √ºber die Webseite herunterladen:\n\nCodeSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\n\nOder aber √ºber das Paket mosaic importieren:\n\nCodedata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # k√ºrzerer Name, das ist leichter zu tippen\n\n\n\n12.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerkl√§ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\nerkl√§ren, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\ndie ‚ÄúAtome‚Äù der Kausalit√§t eines DAGs benennen\n‚Äúkausale Hintert√ºren‚Äù schlie√üen\n\n12.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. √Ñhnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#kollision",
    "href": "1180-kausalatome.html#kollision",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.2 Kollision",
    "text": "12.2 Kollision\nüì∫ Kollision\n\n12.2.1 Kein Zusammenhang von Intelligenz und Sch√∂nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und Sch√∂nheit (looks), wie Abbildung¬†12.1 illustriert. F√ºr geringe Intelligenzwerte gibt es eine breites Spektrum von Sch√∂nheitswerten und f√ºr hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildung¬†12.1: Kein Zusammenhang von Intelligenz und Sch√∂nheit in den Daten\n\n\n\n\n\n12.2.2 Aber Ihre Dates sind entweder schlau oder sch√∂n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder sch√∂n sind oder schlau - aber seltens beides gleichzeitig (schade), s. Abbildung¬†12.2.\n\n\n\n\n\n\n\nAbbildung¬†12.2: Ihre Datingpartner sind komischerweise entweder schlau oder sch√∂n (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?\n\n12.2.3 DAG zur Rettung\nü¶π ü¶∏\nDer DAG in Abbildung¬†12.3 bietet eine rettende Erkl√§rung.\n\n\n\n\n\n\n\nAbbildung¬†12.3: Date als gemeinsame Wirkung von Sch√∂nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Sch√∂nheit und Intelligenz.\n\n\n\n\nEine √§hnliche Visualisierung des gleichen Sachverhalts zeigt Abbildung¬†12.4.\n\n\n\n\n\n\n\nAbbildung¬†12.4: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n12.2.4 Was ist eine Kollision?\n\nDefinition 12.1 (Kollision) Als Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) (Pearl et al., 2016, p.¬†40). \\(\\square\\)\n\nKontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. Abbildung¬†12.3, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche Pr√§diktoren einer Regression hinzuf√ºgen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nüôÖ‚Äç‚ôÄÔ∏è Kontrollieren Sie keine Kollisionsvariablen. \\(\\square\\)\n\n\n\n12.2.5 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSch√∂ne Menschen ü™û\nReiche Menschen ü§ë\n\nSehen wir davon aus, dass Sch√∂nheit und Reichtum unabh√§ngig voneinander sind.\n\n√úbungsaufgabe 12.1 Wenn ich Ihnen sage, dass Don nicht sch√∂n ist, aber in der Glitzer h√§ufig auftaucht, was lernen wir dann √ºber seine finanzielle Situation?1 \\(\\square\\)\n\n\n‚ÄúIch bin sch√∂n, unglaublich sch√∂n, und gro√ü, gro√üartig, tolle Gene!!!‚Äù üßë\n\n\n12.2.6 Noch ein einfaches Beispiel zur Kollision\n\n‚ÄúSo langsam check ich‚Äôs!‚Äù üßë2\n\nSei Z = X + Y, wobei X und Y unabh√§ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts √ºber Y, da die beiden Variablen unabh√§ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abh√§ngig, gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).3\n\n12.2.7 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildung¬†12.3 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als Pr√§diktor in eine Regression zus√§tzlich zu looks mit talent als Pr√§dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (‚ÄúFluss‚Äù) von Looks √ºber date nach Talent ist blockiert.\nKontrolliert man date, so √∂ffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr ‚Äúblockiert‚Äù, die Korrelation kann ‚Äúflie√üen‚Äù - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n12.2.8 IQ, Fleiss und Eignung f√ºrs Studium\nSagen wir, √ºber die Eignung f√ºr ein Studium w√ºrden nur (die individuellen Auspr√§gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in Abbildung¬†12.5.\n\n\n\n\n\n\n\nAbbildung¬†12.5: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (f√ºrs Studium) sei definiert als die Summe von iq und fleiss, plus etwas Gl√ºck, s. Listing¬†12.1.\n\n\n\nListing¬†12.1: Eignung ist die Summe von Fleiss und Intelligenz, plus ein Quentchen Gl√ºck\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\n\n\n\nLaut unserem Modell setzt sich Eignung zur H√§lfte aus Intelligenz und zur H√§lfte aus Fleiss zusammen, plus etwas Gl√ºck.\n\n12.2.9 Schlagzeile ‚ÄúFlei√ü macht bl√∂d!‚Äù\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Flei√ü (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das ‚ÄúEignungsmodell‚Äù, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. Tabelle¬†12.1.\n\nCodem_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\n\nTabelle¬†12.1: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildung¬†12.6 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildung¬†12.6: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabh√§ngig von Flei√ü in unseren Daten, sondern abh√§ngig. Nichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde √ºber Zusammenh√§nge auf und interpretieren die Zusammenh√§nge ‚Äì oft vorschnell ‚Äì als kausal.4\n\n12.2.10 Kollisionsverzerrung nur bei Stratifizierung\n\nDefinition 12.2 (Stratifizieren) Durch Stratifizieren wird eine Stichprobe in (homogene) Untergruppen unterteilt (sog. Strata). \\(\\square\\)\n\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. Abbildung¬†12.7.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildung¬†12.7: Stratifizierung und Scheinkorrelation. A: Keine Stratifizierung und keine Scheinkorrelation. B: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie n√ºtzen.\nNur Kenntnis des DAGs verr√§t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten Pr√§diktor auf, so ‚Äúkontrolliert‚Äù man diese Variable. Das Regressiongewicht des ersten Pr√§diktors wird ‚Äúbereinigt‚Äù um den Einfluss des zweiten Pr√§diktors; insofern ist der zweite Pr√§diktor dann ‚Äúkontrolliert‚Äù.\n\n\n\n12.2.11 Einfluss von Gro√üeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und Gro√üeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von Gro√üeltern auf ihre Enkel, s. Abbildung¬†12.8, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildung¬†12.8: Der kausale Effekt von Gro√üeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable √ºbersehen haben? (S. n√§chster Abschnitt). üëª\n\n12.2.12 Der Gespenster-DAG\nüëª Es gibt ‚Äúunheilbare‚Äù DAGs, nennen wir sie ‚ÄúGespenster-DAGs‚Äù, in denen es nicht m√∂glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. Abbildung¬†12.9. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: ‚ÄúDeine Theorie ist nicht gut, zur√ºck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.‚Äù\n\n\n\n\n\n\n\nAbbildung¬†12.9: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollst√§ndig) m√∂glich.\n\n\n\n\nU k√∂nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft. Die Gro√üeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie. E ist sowohl f√ºr G als auch f√ºr U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad. Wenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\nDie Sache ist in diesem Fall chancenlos. Wir m√ºssen diesen DAG verloren geben, McElreath (2020), S. 180; ein Gespenster-DAG. üëª",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-hintert√ºr-schlie√üen",
    "href": "1180-kausalatome.html#die-hintert√ºr-schlie√üen",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.3 Die Hintert√ºr schlie√üen",
    "text": "12.3 Die Hintert√ºr schlie√üen\n\nDefinition 12.3 (Hintert√ºr) Eine ‚ÄúHintert√ºr‚Äù ist ein nicht-kausaler Pfad zwischen einer UV und einer AV. Ein Hintert√ºrpfad entsteht, wenn es eine alternative Route √ºber eine oder mehrere Variable gibt, die UV mit der AV verbindet. Dieser Pfad verzerrt die Sch√§tzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. \\(\\square\\)\n\n\n12.3.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie gro√ü ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in Abbildung¬†12.10 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†12.10: Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfl√§che beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund f√ºr die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\leftarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. G√§be es nur nur den zweiten Pfad und wir w√ºrden b √§ndern, so w√ºrde sich p nicht √§ndern.\n\n12.3.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildung¬†12.11 zeigt eine erfreuliche Situation: Die ‚ÄúHintert√ºr‚Äù zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die Hintert√ºr geschlossen - f√ºhren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildung¬†12.11: Unverzerrte Sch√§tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Pr√§diktor im Modell enthalten ist. Da die beiden Pr√§diktoren unkorreliert sind, hat die Aufnahme des einen Pr√§diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie ‚ÄúHintert√ºr‚Äù der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine ber√ºhmte L√∂sung, den kausalen Pfad zu isolieren, ist ein (randomisiertes, kontrolliertes5) Experiment. Wenn wir den H√§usern zuf√§llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen k√∂nnten (unabh√§ngig von ihrer Quadratmeterzahl, a), w√ºrde sich der Graph so √§ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\leftarrow a \\rightarrow p\\) geschlossen (‚Äúblockiert‚Äù).\n\n\n\n\n\n\nWichtig\n\n\n\nDie St√§rke von (gut gemachten) Experimente ist, dass sie kausale Hintert√ºren schlie√üen. Damit erlauben sie (korrekte) Kausalaussagen. \\(\\square\\)\n\n\n\n12.3.3 Hintert√ºr schlie√üen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die Hintert√ºr schlie√üen (backdoor criterion). Wir wollen die Hintert√ºre schlie√üen, da wir sonst nicht den wahren, kausalen Effekt bestimmen k√∂nnen.\nZum Gl√ºck gibt es neben Experimenten noch andere Wege, die Hintert√ºr zu schlie√üen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie Konfundierer, um kausale Hintert√ºren zu schlie√üen. \\(\\square\\)\n\n\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis √ºber b kein zus√§tzliches Wissen √ºber p. Wissen Sie hingegen nichts √ºber a, lernen Sie bei Kenntnis von b auch etwas √ºber p. Konditionieren ist wie ‚Äúgegeben, dass Sie a schon kennen‚Ä¶‚Äù.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "href": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.4 Die vier Atome der Kausalanalyse",
    "text": "12.4 Die vier Atome der Kausalanalyse\nAbbildung¬†12.12 stellt die vier ‚ÄúAtome‚Äù der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so k√∂nnen Sie jedes beliebige Kausalsystem (DAG) entschl√ºsseln.\n\n\n\n\n\n\n\nAbbildung¬†12.12: Die vier Atome der Kausalinferenz\n\n\n\n\n\n12.4.1 Mediation\n\nDefinition 12.4 (Mediator) Einen Pfad mit drei Knoten (Variablen), die √ºber insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man Mediation. Der Mediator ist die Variable zwischen UV und AV [Pearl et al. (2016); p.¬†38]. \\(\\square\\)\n\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. Abbildung¬†12.13. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y ‚Äúvermittelt‚Äù oder √ºbertr√§gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildung¬†12.13: Das Kausalmodell der Mediation mit x als UV, m als Mediator und Y als AV.\n\n\n\n\n\nBeispiel 12.1 (Mediator kontrollieren?) Sollte man den Mediator m in Abbildung¬†12.13 kontrollieren, wenn man den Kausaleffekt von x auf y sch√§tzen m√∂chte?6 \\(\\square\\)\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation ‚Äúflie√üt‚Äù den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlie√üt) die Kette (genau wie bei der Gabel).\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie den Mediator nicht. Der Pfad √ºber den Mediator ist ein ‚Äúechter‚Äù Kausalpfad, keine Scheinkorrelation. \\(\\square\\)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. \\(\\square\\)\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. Abbildung¬†12.14. In Abbildung¬†12.14 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\).\n\nDefinition 12.5 (Effekt) Gibt es eine (von (praktisch) Null verschiedene) kausale Assoziation der UV auf die AV, so h√§ngt die AV von der UV (kausal) ab. Man spricht von einem Effekt (der UV auf die AV). \\(\\square\\)\n\n\nDefinition 12.6 (Totaler Effekt) Die Summe der Effekte aller (kausalen) Pfade von UV zu AV nennt man den totalen (kausalen) Effekt. \\(\\square\\)\n\n\nDefinition 12.7 (Indirekter Effekt) Den (kausalen) Effekt √ºber den Mediatorpfad (von \\(X\\) √ºber \\(M\\) zu \\(Y\\)) nennt man den indirekten (kausalen) Effekt. \\(\\square\\)\n\n\nDefinition 12.8 (Direkter Effekt) Ein Effekt, der nur aus dem Pfad \\(x\\rightarrow y\\) besteht, also ohne keine Zwischenglieder, nennt man in Abgrenzung zum indirekten Effekt, direkten (kausalen) Effekt. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung¬†12.14: Partielle Mediation: Es gibt einen direkten Effekt (X-&gt;Y) und einen indirekten Effekt (X-&gt;M-&gt;Y).\n\n\n\n\n\n12.4.2 Der Nachfahre\n\nDefinition 12.9 (Nachfahre) Ein Nachfahre (engl. descendent) ist eine Variable, die von einer anderen Variable beeinflusst7 wird, s. Abbildung¬†12.15. \\(\\square\\)\n\nKontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet √ºber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise √∂ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildung¬†12.15: Ein Nachfahre verh√§lt sich √§hnlich wie sein Vorfahre‚Ä¶\n\n\n\n\n\n12.4.3 Kochrezept zur Analyse von DAGs üë®‚Äçüç≥\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: üìÑ\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder ge√∂ffnet ist.\nBeurteilen Sie f√ºr jeden Pfad, ob er ein Hintert√ºrpfad ist (Hintert√ºrpfade haben einen Pfeil, der zur UV f√ºhrt).\nWenn es ge√∂ffnete Hinterpfade gibt, pr√ºfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlie√üen (falls m√∂glich).",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#schlie√üen-sie-die-hintert√ºr-wenn-m√∂glich",
    "href": "1180-kausalatome.html#schlie√üen-sie-die-hintert√ºr-wenn-m√∂glich",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.5 Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!",
    "text": "12.5 Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!\nüì∫ Hintert√ºr schlie√üen\n\n12.5.1 Hintert√ºr: ja oder nein?\n\n12.5.1.1 Fall 1: x-&gt;\n\n\\(\\boxed{X \\rightarrow}\\)\nAlle Pfade, die von der UV (X) wegf√ºhren, sind entweder ‚Äúgute‚Äù Kausalpfade oder automatisch geblockte Nicht-Kausal-Pfade. In diesem Fall m√ºssen wir nichts tun.8\n\n12.5.1.2 Fall 2: -&gt;x\n\n\\(\\boxed{\\rightarrow X}\\)\nAlle Pfade, die zur UV hinf√ºhren, sind immer Nicht-Kausal-Pfade, Hintert√ºren. Diese Pfade k√∂nnen offen sein, dann m√ºssen wir sie schlie√üen. Sie k√∂nnen auch geschlossen sein, dann m√ºssen wir nichts tun.\n\n\n\n\n\n\nTipp\n\n\n\nSchlie√üen Sie immer offene Hintert√ºren, um Verzerrungen der Kausaleffekte zu verhinden. \\(\\square\\)\n\n\n\n12.5.2 bsp1\n\nUV: \\(X\\), AV: \\(Y\\), drei Kovariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\n\nAbbildung¬†12.16: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei Hintert√ºrpfade in Abbildung¬†12.16:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlie√üt die offene Hintert√ºr.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n12.5.3 Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, bsp2\n\nS. DAG in Abbildung¬†12.17: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildung¬†12.17: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintert√ºren zu schlie√üen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), S. 188.\n\n12.5.4 Implizierte bedingte Unabh√§ngigkeiten von bsp2\n\n\nAuch wenn die Daten nicht sagen k√∂nnen, welcher DAG der richtige ist, k√∂nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten Unabh√§ngigkeiten geben uns M√∂glichkeiten, zu pr√ºfen, ob wir einen DAG verwerfen (ausschlie√üen) k√∂nnen. Bedingten Unabh√§ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabh√§ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte Unabh√§ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#fazit",
    "href": "1180-kausalatome.html#fazit",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.6 Fazit",
    "text": "12.6 Fazit\n\n12.6.1 Ausstieg\nüì∫ Musterl√∂sung f√ºr eine DAG-Pr√ºfungsaufgabe\nüì∫ Musterl√∂sung f√ºr schwierige DAG-Pr√ºfungsaufgaben\n\nBeispiel 12.2 (PMI zum heutigen Stoff) Der Kreativit√§tsforscher Edward de Bono hat verschiedene ‚ÄúDenkmethoden‚Äù vorgestellt, die helfen sollen, Probleme besser zu l√∂sen. Eine Methode ist die ‚ÄúPMI-Methode‚Äù. PMI steht f√ºr Plus, Minus, Interessant. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anf√ºhren. Bei Interessant verzichtet man aber explizit auf eine Bewertung (im Sinne von ‚Äúgut‚Äù oder ‚Äúschlecht‚Äù) und fokussiert sich auf Interessantes, √úberraschendes, Bemerkenswertes.\nF√ºhren Sie die PMI-Methode zum heutigen Stoff durch!\n\n\nPlus: Was fanden Sie am heutigen Stoff gut, sinnvoll, n√ºtzlich?\n\nMinus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, n√ºtzlich?\n\nInteressant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! \\(\\square\\)\n\n\n12.6.2 Zusammenfassung\nüì∫ Kausalmodelle √ºberpr√ºfen\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren k√∂nnen, h√§ngt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen k√∂nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. ‚ÄúDer Unterschied zwischen beiden Gruppen betr√§gt etwa ‚Ä¶‚Äù. Allerdings ist eine kausale Interpretation nicht zul√§ssig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht m√∂glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen d√ºrfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten √§ndern sich (oft), wenn man Pr√§diktoren zum Modell hinzuf√ºgt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, m√∂glichst viele Pr√§diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der ‚Äúkausalen Atome‚Äù ist Voraussetzung zur Ableitung von Kausalschl√ºsse in Beobachtungsstudien.\n\n12.6.3 Vertiefung\nAn weiterf√ºhrender Literatur sei z.B. Cummiskey et al. (2020), L√ºbke et al. (2020), Pearl et al. (2016) und Dablander (2020) empfohlen. Ein gutes Lehrbuch, das auf Kausalinferenz eingeht, ist Huntington-Klein (2022). Praktischerweise ist es √∂ffentlich lesbar. Das Web-Buch Causal Inference for the Brave and True sieht auch vielversprechend aus. Es gibt viele Literatur zu dem Thema; relevante Google-Suchterme sind z.B. ‚ÄúDAG‚Äù, ‚Äúcausal‚Äù oder ‚Äúcausal inference‚Äù.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#aufgaben",
    "href": "1180-kausalatome.html#aufgaben",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.7 Aufgaben",
    "text": "12.7 Aufgaben\n\nSammlung ‚Äúkausal‚Äù",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#section",
    "href": "1180-kausalatome.html#section",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "\n12.8 ‚Äî",
    "text": "12.8 ‚Äî\n\n\n\n\n\nCummiskey, K., Adams, B., Pleuss, J., Turner, D., Clark, N., & Watts, K. (2020). Causal Inference in Introductory Statistics Courses. Journal of Statistics Education, 28(1), 2‚Äì8. https://doi.org/10.1080/10691898.2020.1713936\n\n\nDablander, F. (2020). An Introduction to Causal Inference [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw\n\n\nHuntington-Klein, N. (2022). The Effect: An Introduction to Research Design and Causality. CRC Press, Taylor & Francis Group. https://theeffectbook.net/\n\n\nKurz, S. (2021). Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/\n\n\nL√ºbke, K., Gehrke, M., Horst, J., & Szepannek, G. (2020). Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Data. Journal of Statistics Education, 1‚Äì17. https://doi.org/10.1080/10691898.2020.1752859\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal Inference in Statistics: A Primer. Wiley.\n\n\nRohrer, J. M. (2018). Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data. Advances in Methods and Practices in Psychological Science, 1(1), 27‚Äì42. https://doi.org/10.1177/2515245917745629",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#footnotes",
    "href": "1180-kausalatome.html#footnotes",
    "title": "12¬† Die Atome des Kausalit√§t",
    "section": "",
    "text": "Don muss reich sein.‚Ü©Ô∏é\nSuper, Don!‚Ü©Ô∏é\nDer horizontale Balken ‚Äú|‚Äù bedeutet ‚Äúgegeben, dass‚Äù. Ein Beispiel lautet \\(Pr(A|B)\\): ‚ÄúDie Wahrscheinlichkeit von A, gegeben dass B der Fall ist.‚Ü©Ô∏é\nEhrlicherweise muss man zugeben, dass auch wissenschaftliche Berichte Daten √ºber Zusammenh√§nge gerne kausal interpretieren, oft vorschnell.‚Ü©Ô∏é\nengl. randomized, controlled trial, RCT‚Ü©Ô∏é\nNein, durch das Kontrollieren von m wird der Kausalpfad von x zu y geschlossen. Es kann keine kausale Assoziation von x auf y mehr ‚Äúflie√üen‚Äù.‚Ü©Ô∏é\nbeeinflussen ist grunds√§tzlich kausal zu verstehen‚Ü©Ô∏é\nDenken Sie daran, dass Sie keine Nachkommen der UV kontrollieren d√ºrfen, da das den Kausalpfad von der UV zur AV blockieren k√∂nnte.‚Ü©Ô∏é",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Die Atome des Kausalit√§t</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html",
    "href": "1200-abschluss.html",
    "title": "13¬† Abschluss",
    "section": "",
    "text": "13.1 Lernsteuerung",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "13¬† Abschluss",
    "section": "",
    "text": "13.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerl√§utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische ‚ÄúLieblingsfehler‚Äù benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik √ºbersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n13.1.2 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\nCodelibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n\n13.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#probeklausur",
    "href": "1200-abschluss.html#probeklausur",
    "title": "13¬† Abschluss",
    "section": "\n13.2 Probeklausur",
    "text": "13.2 Probeklausur\n\n13.2.1 2024\n(Diese Liste ist im Aufbau. Bitte konsultieren Sie f√ºr weitere Aufgaben selbst√§ndig alle relevanten Aufgaben, die in den Kapiteln vorgestellt wurden.)\n\nttest-als-regr\nAdditionssatz1\nNerd-gelockert\nUrne1\ncorona-blutgruppe\nvoll-normal\nalphafehler-inflation3\nverteilungen-quiz-05\nverteilungen-quiz-03\nverteilungen-quiz-04\nKekse03\nglobus-bin2\nglobus2\niq01a\ngem-wskt4\nRethink2m3\nmtcars-post2a\ngroesse03\nbath42\nklausur-raten\nbed-post-wskt1\nmtcars-post3a\nexp-tab\nnorms-sd\nmtcars-post_paper\nbfi10\nrope-luecke\nwskt-schluckspecht2a\npenguins-stan-06\n\n13.2.2 2023\nDieser Tag auf dem Datenwerk stellt Fragen einer Probepr√ºfung (Version 2023) zusammen.\n\n13.2.3 2022\nDieser Tag auf dem Datenwerk stellt Fragen einer Probepr√ºfung (Version 2022) zusammen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "13¬† Abschluss",
    "section": "\n13.3 Lieblinglingsfehler",
    "text": "13.3 Lieblinglingsfehler\nLieblingsfehler im √úberblick ü§∑:\n\nQuantile und Verteilungsfunktion verwechseln\nPr√§diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n13.3.1 Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑\nüèé üèé Vertiefung: Dieser Abschnitt ist nicht pr√ºfungsrelevant. üèéÔ∏è üèé\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nCodem1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle¬†13.1.\n\nCodepost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle¬†13.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. H√§ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und Punktsch√§tzer auszulesen.\nDie Posterior-Pr√§diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n13.3.2 Quantile und Verteilungsfuntion verwechseln ü§∑\n\n13.3.2.1 Quantil f√ºr \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung¬†13.1.\n\n\n\n\n\n\n\nAbbildung¬†13.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betr√§gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist gr√∂√üer oder gleich dem \\(p\\)-Quantil.\n\n13.3.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung¬†13.2.\n\n\n\n\n\n\n\nAbbildung¬†13.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betr√§gt hier 50%, dass \\(x\\) nicht gr√∂√üer ist als 0.\n\n13.3.3 Interaktion falsch interpretieren ü§∑\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber k√ºrzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nCodem2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten, s. Tabelle¬†13.2.\n\nCodeparameters(m2)\n\n\n\n\n\nTabelle¬†13.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.67\n(19.01, 30.20)\n100%\n1.001\n2166.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.70%\n1.001\n2146.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.90\n(4.74, 23.40)\n99.75%\n1.003\n1506.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.03)\n99.28%\n1.003\n1608.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle¬†13.2 zeigt die Visualisierung der Parameter von m2.\n\nCodeplot(parameters(m2))\n\n\n\n\n\n\nAbbildung¬†13.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch üòà Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11.\nRichtig üëº Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11 ‚Äì wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Pr√§diktoren w√§ren hier eine sinnvolle L√∂sung.\nGelman et al. (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "13¬† Abschluss",
    "section": "\n13.4 Kochrezepte üç≤",
    "text": "13.4 Kochrezepte üç≤\n\n13.4.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen √ºber ein Ph√§nomen, \\(y\\), Kausalfrage finden 2. Literatur w√§lzen, um m√∂gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese pr√§zisieren 4. Modell pr√§zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell pr√ºfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n13.4.2 Parameter sch√§tzen vs.¬†Hypothesen pr√ºfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter sch√§tzen. Beispiel Hypothesenpr√ºfung: ‚ÄúFrauen parken im Durchschnitt schneller ein als M√§nner‚Äù. Beispiel Parametersch√§tzung: ‚ÄúWie gro√ü ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und M√§nnern?‚Äù\nJe ausgereifter ein Forschungsfeld, desto k√ºhnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die n√§chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die n√§chste Sonnenfinsternis wird in den n√§chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen f√ºr den Klausurerfolg. K√ºhne Hypothesen sind w√ºnschenswert ü¶π\n\n13.4.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist h√∂her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist gr√∂√üer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "13¬† Abschluss",
    "section": "\n13.5 Kerngedanken Bayes",
    "text": "13.5 Kerngedanken Bayes\nüì∫ Bayes in f√ºnf Minuten\nüì∫ Bayes in zehn Minuten\n\n13.5.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nCodem3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung¬†13.4.\n\n\n\n\n\n\n\nAbbildung¬†13.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist m√∂glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind m√∂glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings √ºbermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n13.5.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "title": "13¬† Abschluss",
    "section": "\n13.6 Beispiele f√ºr Pr√ºfungsaufgaben",
    "text": "13.6 Beispiele f√ºr Pr√ºfungsaufgaben\n\n13.6.1 Geben Sie den korrekten Begriff an!\nüå¨üöôüôãÔ∏èüë®‚¨ÖÔ∏èHans üëß‚¨ÖÔ∏èAnna üë©‚¨ÖÔ∏èLise\nPuh, wie erstelle ich f√ºr alle Studis ein anderes R√§tsel2?\n\n\n\n\n\n13.6.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung¬†13.5.\n\n\n\n\n\n\n\nAbbildung¬†13.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 13.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge f√ºr x und y gibt eine kleinstm√∂gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu ‚Äúidentifizieren‚Äù). \\(\\square\\)\n\n‚ùìGeben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n‚ùó Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n13.6.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung¬†13.6.\n\n\n\n\n\n\n\nAbbildung¬†13.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n13.6.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung¬†13.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung¬†13.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set f√ºr den totalen Kausaleffekt: {AIS, ALN}\n\n13.6.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPr√ºfungsfragen zu Modellen k√∂nnten z.B. sein:\n\nGeben Sie den Punktsch√§tzer (Median) f√ºr den Pr√§diktor X im Modell Y an!\nGeben Sie ein 89%-HDI f√ºr den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris ‚Ä¶\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI f√ºr den Pr√§diktor X im Modell Y?\nWas ver√§ndert sich an den Parametern, wenn Sie die Pr√§diktoren zentrieren/z-standardisieren?\n‚Ä¶",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "13¬† Abschluss",
    "section": "\n13.7 Aufgabensammlungen",
    "text": "13.7 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere ‚ÄúPr√ºfungsn√§he‚Äù k√∂nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#faq",
    "href": "1200-abschluss.html#faq",
    "title": "13¬† Abschluss",
    "section": "\n13.8 FAQ",
    "text": "13.8 FAQ\n\n13.8.1 Probeklausur?\nFRAGE: Wo finde ich eine Probeklausur?\nANTWORT: Dieser Tag stellt Fragen einer Probepr√ºfung zusammen.\n\n13.8.2 Wie bereite ich mich gut auf die Pr√ºfung vor?\nFRAGE: Wie bereite ich mich gut auf die Pr√ºfung vor?\nANTWORT: Hier finden Sie Tipps zur Pr√ºfungsvorbereitung.\n\n13.8.3 Intercept?\nFRAGE: Wenn man ‚Äò(Intercept)‚Äô benutzt, welche Anf√ºhrungszeichen sind die richtigen? Bei verschiedenen Anf√ºhrungszeichen, also ‚Äô oder ` oder ¬¥ kommen entweder keine oder sogar verschiedene Ergebnisse raus.\nANTWORT: Normalerweise ist innerhalb von R-Befehlen aus dem Tidyverse keine Anf√ºhrungsstriche f√ºr Spaltennamen n√∂tig. Wenn es allerdings ein ‚Äúverbotener‚Äù Name ist, muss man aufpassen. (Intercept) ist so ein verbotener Variablenname. Warum verboten? Ein ‚Äúbraver‚Äù Variablenname (in R) muss mit einem Buchstaben beginnen und darf keine Sonderzeichen ((, {, #, etc.) enthalten. Hat man aber einen an sich unerlaubten Variablennamen, so kann man den trotzdem verwenden, wenn man ihn mit Backticks (`) umgibt, also wie in \\(Intercept)\\). Doppelte und einfache Anf√ºhrungsstriche sind in R √ºbrigens beide okay, wenn man etwa einen String (Text) auszeichnen will, aber im Rahmen von Tidyverse nicht n√∂tig f√ºr Variablennamen.\n\n13.8.4 Pr√§diktoren vorher zentrieren?\nFRAGE: Woher wei√ü ich, dass ich die Pr√§diktoren vorher zentrieren muss? Kann man das aus der Aufgabenstellung irgendwie herauslesen? Z.B. wie bei Tutorium Aufgabe 10.1 d).\nANTWORT: Es gibt mehrere Gr√ºnde, Variablen zu zentrieren, dazu z√§hlen 1) bessere Interpretation des Intercepts, 2) bessere Interpretation von Interaktionseffekten, 3) Verringerung von Kollinearit√§t. Die Steigung (beta 1) ver√§ndert sich (fast immer) aber nicht durch das Zentrieren, ebenso wie R-Quadrat.\n\n13.8.5 Dichotomisierung\nFRAGE: Bei der Bearbeitung der Pr√ºfung heute ist ein Fehler aufgekommen, den ich bis jetzt nicht verstehe. Deshalb war es auch f√ºr mich nicht m√∂glich die Aufgabe zu bearbeiten. Die AV high Aufteilung in die Werte 0 und 1 (0 = AV &lt;= median (AV)) (1 =AV &gt; median(AV) hat geklappt. Die UV high Aufteilung in die Werte 0 und 1 (0 = UV &lt;= median (UV)) (1 =UV &gt; median(UV) hat dabei aber nicht geklappt. Anstatt die Werte 0 und 1 bei der neuen UV_high Spalte zu bekommen, kommen nur Nas raus. Auch mit dem Befehl drop_na hat es nicht geklappt. Dies habe ich nicht nur mit dem RStudio auf meinem Computer versucht sondern auch √ºber die Cloud √ºber mein IPad. (Bei beiden Ger√§ten kam es zuvor noch nie zu Problemen) Hier mein R-Code:\n\nCodelibrary(tidyverse)\n#library(easystats)\n#library(rstanarm)\n\ndata(\"msleep\", package = \"ggplot2\")\n\nmsleep1 &lt;-\n  msleep |&gt; \n    mutate(av_high = case_when(awake &gt; median(awake) ~ 1,\n                               awake &lt;= median(awake) ~ 0))\n\nmsleep2 &lt;-\n  msleep1 |&gt; \n    mutate(uv_high = case_when(sleep_rem &gt; median(sleep_rem) ~ 1,\n                               sleep_rem &lt;= median(sleep_rem) ~ 0))\n  \nmsleep2 |&gt; \ncount(uv_high)\n\n\n  \n\n\n\nANTWORT: Sie haben nicht die fehlenden Werte ausgeschlossen. Wenn Sie die fehlenden Wert ausschlie√üen, dann klappt die Dichotomisierung (die Aufteilung einer metrischen Variablen in eine bin√§re):\n\nCodemsleep2 &lt;-\n  msleep1 |&gt; \n  drop_na(sleep_rem) |&gt;  # fehlende Werte aus `sleep_rem` entfernen\n    mutate(uv_high = case_when(sleep_rem &gt; median(sleep_rem) ~ 1,\n                               sleep_rem &lt;= median(sleep_rem) ~ 0))\n  \nmsleep2 |&gt; \ncount(uv_high)\n\n\n  \n\n\n\n\n13.8.6 Bin ich im Toleranzbereich?\nFRAGE: Ich habe meine L√∂sungswege mit Ihren abgeglichen und finde keinen bedeutenden Unterschied. Dennoch erhalte ich andere Ergebnisse, welche nicht im Toleranzbereich liegen. Um das nochmals zu √ºberpr√ºfen, habe ich Ihre L√∂sungswege 1:1 in mein RStudio √ºbertragen, aber auch dann erhalte ich nicht die angegebene L√∂sung.\nANTWORT: Es sollte ein Modell berechnet werden mit z-transformierten Variablen. F√ºr die UV war der ROPE anzugeben. Leider haben Sie vergessen, die Daten zu z-transformieren.\nHier ist das Modell ohne z-Transformation:\n\nCodelibrary(rstanarm)\nlibrary(easystats)\nlibrary(dplyr)\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm1 &lt;- stan_glm(bill_length_mm ~ year, data = penguins, refresh = 0)\n\nrope(m1)\n\n\n  \n\n\n\nHier ist das Modell mit z-Transformation:\n\nCodep2 &lt;- \n  penguins |&gt; \n  select(bill_length_mm, year) |&gt; \n  standardise()\n\nm2 &lt;- stan_glm(bill_length_mm ~ year, data = p2, refresh = 0)\n\nrope(m2)\n\n\n  \n\n\n\nDer Wert von m2 findet sich in der Musterl√∂sung. Man beachte, dass sich die Rope-Werte von m1 und m2 deutlich unterscheiden.\n\n13.8.7 Andere Ergebnisse trotz gleichen Befehls und set.seed?\nFRAGE: ich habe bei fast allen Aufgaben, die ich l√∂se, dass Problem, dass mein Ergebnis stark von der L√∂sung abweicht, selbst bei exakt gleichem Code wie in der Musterl√∂sung. Leider ist die Abweichung so stark, dass ich nicht mal mehr im Toleranzbereich bin. Teilweise kommen extrem andere Ergebnisse raus. Wie ist dieses Problem zu l√∂sen? Ich bearbeite die Aufgaben in der R Cloud und habe die Pakete tidyverse, easystats und rstanarm geladen. Zudem habe ich die Pakete geupdated, sodass ich hier nicht weiter wei√ü.\nMeine L√∂sung:\n\nCodepenguins &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm10.1 &lt;- stan_glm(body_mass_g ~  flipper_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\nparameters(m10.1)\n\n\n\nANTWORT: Tats√§chlich ist es so, dass es trotz gleichem Wert bei set.seed() Abweichungen nicht ausgeschlossen werden k√∂nnen. Hintergrund ist, dass verschiedene Betriebssysteme oder weitere, im Hintergrund involvierte Software in unterschiedlichen Versionen zu Abweichungen f√ºhren k√∂nnen. In Ihrem Fall ist der Wert aber innerhalb des Toleranzbereichs. Im Zweifel werden Sie mit einigem Probieren Ihren Wert nach der Pr√ºfung wiederholen k√∂nnen und so ggf. dem Pr√ºfer nachweisen k√∂nnen, das Ihr Ergebnis statthaft, sogar, wenn es nicht im Toleranzbereich w√§re.\nHier ist die von der Studentin angesprochene Musterl√∂sung:\n\nUnd hier ist der Toleranzbereich (vgl. Kapitel 10.3.8) f√ºr den Intercept (Achsenabschnitt):\n\nCodelibrary(prada)\nis_in_tolerance(asis = 5774.83,  # Ihr Wert\n                tobe = 5787.34917,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(penguins$body_mass_g))\n## [1] TRUE\n\n\nWie man sieht, ist is_in_tolerance gleich TRUE.\nAuch der Punktsch√§tzer f√ºr die UV ist im Toleranzbereich:\n\nCodeis_in_tolerance(asis = 49.66,  # Ihr Wert\n                tobe = 49.71739,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(penguins$body_mass_g))\n## [1] TRUE\n\n\nAlso alles in Ordnung. Sie brauchen sich keine Sorgen zu machen, die Abweichung ist im Toleranzbereich.\n\n13.8.8 RStudio Cloud st√ºrzt ab, was tun?\nFRAGE: Zudem wollte ich sie gerne noch fragen, wie ich in der Klausur verhindern kann, dass mein R Cloud mir diese Fehlermeldung anzeigt. Diese tritt vermehrt auf, wenn ich einige Minuten nichts in der R Cloud bearbeite. Danach erscheint das Fenster sehr oft nacheinander und es ist teilweise nicht mehr m√∂glich weiterzuarbeiten weil die Meldung immer wieder auftritt.\n\nANTWORT: Probieren Sie folgende Ma√ünahmen:\n\nIst der Speicher in RStudio Cloud aufgebraucht? Das kann zu Abst√ºrzen f√ºhren. L√∂schen Sie Objekte und ent-laden Sie R-Pakete, um Speicher freizugeben.\nWenn Sie mehr Speicher ben√∂tigen, k√∂nnten Sie (ggf. nur f√ºr einen Monat) ein kostenpflichtiges Abo abschlie√üen, welches mehr Speicher enth√§lt.\nVerringern Sie die Zeit, in der Sie RStudio Cloud nicht nutzen (die Idle-Time).\nVersuchen Sie, weniger speicherintensive Berechnungen durchzuf√ºhren.\nWeichen Sie auf RStudio Desktop aus.\n\n13.8.9 Welche Themengebiete werden in der Pr√ºfung besonders behandelt?\nFRAGE: Welche Themengebiete werden in der Pr√ºfung besonders behandelt?\nANTWORT: In den Pr√ºfungen werden alle Themengebiete abgefragt, die in der Vorlesungbehandelt wurden. Es gibt keine speziellen Schwerpunkte, die besonders behandelt werden. Es ist ratsam, sich auf alle Themengebiete vorzubereiten. Tipp: Schwerpunkte im Unterricht spiegeln sich oft in den Pr√ºfungen wider.\n\n13.8.10 RStudio in der Pr√ºfung?\nFRAGE: Wird R Studio noch eine Rolle spielen, z. B. indem wir Code oder Pseudocode schreiben m√ºssen, oder liegt der Fokus komplett auf Theorie?\nANTWORT: Bei einer ‚ÄúPapier-und-Kugelschreiber-Klausur‚Äù spielt RStudio keine Rolle. Es wird also kein Code geschrieben. Es wird aber durchaus vorkommen, dass Sie in der Klausur R-Code lesen und interpretieren m√ºssen.\n\n13.8.11 Welche Art von Fragen?\nFRAGE: Welche Art von Fragen k√∂nnen wir erwarten? (z. B. Multiple Choice, offene Fragen oder mathematische Herleitungen)\nANTWORT: Die Pr√ºfung wird zu einem gro√üen Teil aus Multiple-Choice-Fragen bestehen. Es wird aber auch offene Fragen geben. Mathematische Herleitungen sind nicht zu erwarten. Hingegen sind einfache Berechnungen (die mit einem kaufm√§nnischen Taschenrechner durchgef√ºhrt werden k√∂nnen) durchaus m√∂glich.\n\n13.8.12 Vorbereitung?\nFRAGE: Gibt es bestimmte √úbungsaufgaben oder Materialien, die Sie empfehlen, um sich gezielt auf die Theorie-Klausur vorzubereiten?\nATNWORT: Hier finden Sie eine Sammlung von Fragen, die in einer Probepr√ºfung gestellt wurden. Diese Fragen k√∂nnen Ihnen helfen, sich gezielt auf die Pr√ºfung vorzubereiten.\nDar√ºber hinaus sollten Sie die theoretischen Inhalte des Skripts kennen sowie alle Themen, die im Unterricht behandelt wurden.\nZwar ist es formal kein Bestandteil der Pr√ºfung, die Begleitliteratur zu lesen, aber es kann hilfreich sein, um den Stoff besser zu verstehen.\n\n13.8.13 L√ºckenlose Vorbereitung?\nFRAGE: Ich befinde mich gerade mitten in der Vorbereitung f√ºr meinen Drittversuch des Moduls Quantitative Methoden II neben dem Besuchen der Vorlesungen und √úbungen √ºber das Semester arbeite ich bisher haupts√§chlich mit ihrem Skript und den dort gegebenen Pen and Paper Aufgaben. Wenn ich das Skript durchgearbeitet habe m√∂chte ich mich des weiteren den √úbungsaufgaben und Inhalten von Bourier widmen. Da es sich zeitgleich zum Drittversuch um meine letzte Pr√ºfung vor der Bachelorarbeit handelt m√∂chte ich mich m√∂glichst l√ºckenlos auf die Pr√ºfung vorbereiten, damit keine M√∂glichkeit besteht die Pr√ºfung nicht zu bestehen. Nat√ºrlich k√∂nnen sie keine genauen Inhalte der kommenden Pr√ºfung geben, ich wollte mich trotzdem versichern, dass ich keine Aspekte des Kurses auslasse, die ebenfalls pr√ºfungsrelevant sind.\nANTWORT: Die Aufgaben im Skript sind am wichtigsten. Dazu sollten die Inhalte, auf die sich die Aufgaben beziehen, gut erarbeitet sein. Dar√ºber hinaus empfiehlt es es sich, sich Varianten zu den eingestellten Aufgaben zu √ºberlegen, z.B. mit anderen Zahlen oder leichten inhaltlichen Variationen. Wichtig ist, die Aufgabe selber zu l√∂sen und sich dann erst die Musterl√∂sung anzuschauen. Viel Erfolg!",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "title": "13¬† Abschluss",
    "section": "\n13.9 Viel Erfolg bei der Pr√ºfung!",
    "text": "13.9 Viel Erfolg bei der Pr√ºfung!\nü•≥üèÜüçÄüçÄüçÄ",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section-3",
    "href": "1200-abschluss.html#section-3",
    "title": "13¬† Abschluss",
    "section": "\n13.10 ‚Äî",
    "text": "13.10 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nvan Kampen, D. (2014). The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs. European Psychiatry, 29(7), 437‚Äì448. https://doi.org/10.1016/j.eurpsy.2013.11.001",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#footnotes",
    "href": "1200-abschluss.html#footnotes",
    "title": "13¬† Abschluss",
    "section": "",
    "text": "langweiliges‚Ü©Ô∏é\nFahr-Hier-Hans-Anna-Lise: Varianzanalyse‚Ü©Ô∏é\ndas ist keine vollst√§ndige Liste, sondern eine Anregung. Andere Tags k√∂nnten auch relevant sein‚Ü©Ô∏é",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "definitions.html",
    "href": "definitions.html",
    "title": "14¬† Definitionen",
    "section": "",
    "text": "Kausale Abh√§ngigkeit: Definition¬†11.5\nAdditionssatz f√ºr disjunkte Ereignisse: Definition¬†3.15\nAllgemeiner Additionssatz: Definition¬†3.16\nBinomialkoeffizient: Definition¬†4.10\n#Binomialverteilung: Definition¬†4.9\nBlockieren: Definition¬†11.2\nKollision: Definition¬†12.1\nKonfundierungsvariable: Definition¬†11.1\nDAG: Definition¬†11.3\nDeskriptivstatistik: Definition¬†2.1\nDirekter Effekt: Definition¬†12.8\nEffekt: Definition¬†12.5\nElementarereignis: Definition¬†3.5\nEreignis: Definition¬†3.3\nEreignisraum: Definition¬†3.2\nPerzentilintervall (PI): Definition¬†6.1\nEvidenz: Definition¬†5.4\nFunktion: Definition¬†2.4\nGemeinsame Wahrscheinlichkeit: Definition¬†3.19\nIntervalle h√∂chster Dichte (Highest Density Intervals): Definition¬†6.2\nHintert√ºr: Definition¬†12.3\nIndirekter Effekt: Definition¬†12.7\nStochastische Unabh√§ngigkeit: Definition¬†3.22\nIndifferenzprinzip: Definition¬†3.8\nInferenzstatistik: Definition¬†2.2\nKettenregel: Definition¬†3.20\nKonfidenzintervall: Definition¬†2.9\nLikelihood: Definition¬†5.2\nLaplace-Experimt: Definition¬†3.9\nLogarithmus: Definition¬†4.11\nM√§chtigkeit: Definition¬†3.7\nMediator: Definition¬†12.4\nKomplement√§rereignis: Definition¬†3.13\nLogische Differenz: Definition¬†3.14\nSchnittmenge von Ereignissen: Definition¬†3.12\nVereinigung von Ereignissen: Definition¬†3.11\nMinimale Adjustierungsmenge : Definition¬†13.1\nModell: Definition¬†2.3\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse: Definition¬†3.18\nNachfahre: Definition¬†12.9\nNullhypothese: Definition¬†2.11\nNormalverteilung: Definition¬†4.12\n#Parameter: Definition¬†4.13\nEffektwahrscheinlichkeit: Definition¬†8.1\nPfad: Definition¬†11.4\nPosteriori-Verteilung: Definition¬†5.3\nBedingte Wahrscheinlichkeit: Definition¬†3.17\nPriori-Verteilung: Definition¬†5.1\nPunktsch√§tzer: Definition¬†2.7\nRelation: Definition¬†3.10\nIst Null nicht im Konfidenzintervall enthalten, so liegt ein statistisch signifikantes Ergebnis vor. \\(\\square\\): Definition¬†2.10\nStratifizieren: Definition¬†12.2\nTotaler Effekt: Definition¬†12.6\nTotale Wahrscheinlichkeit: Definition¬†3.21\nUnm√∂gliches und sicheres Ereignis: Definition¬†3.4\nVerteilungsfunktion: Definition¬†4.4\nVerteilungsfunktion: Definition¬†4.7\nVollst√§ndiges Ereignissystem: Definition¬†3.6\nVorhersageintervall: Definition¬†2.8\nWahrscheinlichkeitsfunktion: Definition¬†4.3\nWahrscheinlichkeitsdichte: Definition¬†4.6\nWahrscheinlichkeit: Definition¬†2.6\nDiskrete Wahrscheinlichkeitsverteilung: Definition¬†4.2\nStetige Wahrscheinlichkeitsverteilung: Definition¬†4.8\n## Zuf√§lliges Ereignis: Definition¬†3.1\nZufallsvorgang: Definition¬†3.1\nZufallsvariable: Definition¬†4.1\nStetige Zufallsvariable: Definition¬†4.5",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "theorems.html",
    "href": "theorems.html",
    "title": "15¬† Theoreme",
    "section": "",
    "text": "Stochastische Abh√§ngigkeit: Theorem¬†3.8\nStochastische Abh√§ngigkeit 2: Theorem¬†3.9\nAllgemeiner Additionssatz: Theorem¬†3.4\nAdditionssatz f√ºr disjunkte Ereignisse: Theorem¬†3.3\nBayes‚Äô Theorem: Theorem¬†5.1\nBayes‚Äô Theorem 2: Theorem¬†5.8\nBayes‚Äô Theorem 3: Theorem¬†5.8\nBayes‚Äô Theorem f√ºr zusammengesetzte Hypothesen: Theorem¬†5.9\nBinomialkoeffizient: Theorem¬†4.3\nBinomialverteilung: Theorem¬†4.2\nNotation f√ºr eine binomialverteilte Zufallsvariable: Theorem¬†4.1\nRegression als Korrelation: Theorem¬†10.2\nIndifferenzprinzip: Theorem¬†3.1\nEvidenz: Theorem¬†5.3\nEvidenz 2: Theorem¬†5.4\nHypothese f√ºr ungleiche Mittelwerte: Theorem¬†10.1\nGemeinsame Wahrscheinlichkeit: Theorem¬†3.12\nStochastische Unabh√§ngigkeit: Theorem¬†3.6\nSymmetrie der Unabh√§ngigkeit: Theorem¬†3.10\nStochastische Unabh√§ngigkeit 2: Theorem¬†3.7\nKettenregel: Theorem¬†3.13\nLaplace-Experiment: Theorem¬†3.2\nLineares Modell (Regressionsgleichung): Theorem¬†2.1\nLogarithmus: Theorem¬†4.4\nModelldefinition: Theorem¬†8.1\nNullhypothesentest: Theorem¬†9.1\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse: Theorem¬†3.11\nStandardisierte Posteriori-Verteilung: Theorem¬†5.6\nPosteriori-Verteilung 2: Theorem¬†5.7\nBedingte Wahrscheinlichkeit: Theorem¬†3.5\nStandardnormalverteilung: Theorem¬†4.5\nTotale Wahrscheinlichkeit: Theorem¬†3.14\nUnstandardisierte Posteriori-Wahrscheinlichkeit : Theorem¬†5.5\nz-Transformation: Theorem¬†4.6",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoreme</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Badenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A.,\n& Longobardi, C. (2016). Misconceptions of the p-value among\nChilean and Italian Academic Psychologists.\nFrontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende\nStatistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen\n(7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√ºbungen: Beschreibende\nstatistik ‚Äì wahrscheinlichkeitsrechnung ‚Äì schlie√üende statistik (7.\nAuflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of\nModeling, Probability &\nStatistics. Springer.\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155‚Äì159.\n\n\nCummiskey, K., Adams, B., Pleuss, J., Turner, D., Clark, N., &\nWatts, K. (2020). Causal Inference in Introductory\nStatistics Courses. Journal of Statistics Education,\n28(1), 2‚Äì8. https://doi.org/10.1080/10691898.2020.1713936\n\n\nDablander, F. (2020). An Introduction to Causal\nInference [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Goodrich, B., Gabry, J., & Vehtari, A. (2019). R-squared\nfor Bayesian Regression Models. The American\nStatistician, 73(3), 307‚Äì309. https://doi.org/10.1080/00031305.2018.1549100\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020).\nRstanarm: Bayesian applied regression modeling via\nStan. https://mc-stan.org/rstanarm\n\n\nHenze, N. (2019). Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der\nMa√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Springer Berlin\nHeidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157‚Äì1164.\nhttp://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nHuntington-Klein, N. (2022). The effect: An introduction to research\ndesign and causality. CRC Press, Taylor & Francis Group. https://theeffectbook.net/\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability theory:\nThe logic of science. Cambridge University Press.\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter\nValues in Bayesian Estimation. Advances in\nMethods and Practices in Psychological Science, 1(2),\n270‚Äì280. https://doi.org/10.1177/2515245918771304\n\n\nKurz, S. (2021). Statistical Rethinking with\nBrms, Ggplot2, and the Tidyverse:\nSecond Edition. https://bookdown.org/content/4857/\n\n\nL√ºbke, K., Gehrke, M., Horst, J., & Szepannek, G. (2020). Why\nWe Should Teach Causal Inference: Examples in\nLinear Regression with Simulated Data.\nJournal of Statistics Education, 1‚Äì17. https://doi.org/10.1080/10691898.2020.1752859\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D.\n(2019). Indices of Effect Existence and\nSignificance in the Bayesian Framework.\nFrontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd ed.). Taylor and Francis, CRC\nPress.\n\n\nMesserli, F. H. (2012). Chocolate Consumption,\nCognitive Function, and Nobel Laureates.\nNew England Journal of Medicine, 367(16), 1562‚Äì1564.\nhttps://doi.org/10.1056/NEJMon1211064\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes factor approaches for\ntesting interval null hypotheses. Psychological Methods,\n16(4), 406‚Äì419. https://doi.org/10.1037/a0024377\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference\nin statistics: A primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPopper, K. (2013). Logik der Forschung (H. Keuth,\nEd.). Akademie Verlag. https://doi.org/10.1524/9783050063782\n\n\nRohrer, J. M. (2018). Thinking Clearly About Correlations\nand Causation: Graphical Causal Models for\nObservational Data. Advances in Methods and Practices\nin Psychological Science, 1(1), 27‚Äì42. https://doi.org/10.1177/2515245917745629\n\n\nShmueli, G. (2010). To Explain or to Predict?\nStatistical Science, 25(3), 289‚Äì310. https://doi.org/10.1214/10-STS330\n\n\nSuttorp, M. M., Siegerink, B., Jager, K. J., Zoccali, C., & Dekker,\nF. W. (2015). Graphical presentation of confounding in directed acyclic\ngraphs. Nephrology Dialysis Transplantation, 30(9),\n1418‚Äì1423. https://doi.org/10.1093/ndt/gfu325\n\n\nTennant, P. W. G., Murray, E. J., Arnold, K. F., Berrie, L., Fox, M. P.,\nGadd, S. C., Harrison, W. J., Keeble, C., Ranker, L. R., Textor, J.,\nTomova, G. D., Gilthorpe, M. S., & Ellison, G. T. H. (2020). Use of\ndirected acyclic graphs (DAGs) to identify confounders in\napplied health research: Review and recommendations. International\nJournal of Epidemiology, 50(2), 620‚Äì632. https://doi.org/10.1093/ije/dyaa213\n\n\nvan Kampen, D. (2014). The SSQ model of schizophrenic\nprodromal unfolding revised: An analysis of its causal\nchains based on the language of directed graphs. European\nPsychiatry, 29(7), 437‚Äì448. https://doi.org/10.1016/j.eurpsy.2013.11.001\n\n\nVanderWeele, T. J., & Shpitser, I. (2013). On the definition of a\nconfounder. Annals of Statistics, 41(1), 196‚Äì220. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs\nStatement on p-Values: Context,\nProcess, and Purpose. The American\nStatistician, 70(2), 129‚Äì133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Anhang",
      "Literaturverzeichnis"
    ]
  },
  {
    "objectID": "imprint.html",
    "href": "imprint.html",
    "title": "16¬† Impressum",
    "section": "",
    "text": "16.1 Vertreten durch:\nAngaben gem√§√ü ¬ß 5 DDG\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach\nSebastian Sauer",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#kontakt",
    "href": "imprint.html#kontakt",
    "title": "16¬† Impressum",
    "section": "16.2 Kontakt:",
    "text": "16.2 Kontakt:\nTelefon: 0981 4877 0, E-Mail: sebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#aufsichtsbeh√∂rde",
    "href": "imprint.html#aufsichtsbeh√∂rde",
    "title": "16¬† Impressum",
    "section": "16.3 Aufsichtsbeh√∂rde:",
    "text": "16.3 Aufsichtsbeh√∂rde:\nN√ºrnberg",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "href": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "title": "16¬† Impressum",
    "section": "16.4 Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:",
    "text": "16.4 Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#haftungsausschluss",
    "href": "imprint.html#haftungsausschluss",
    "title": "16¬† Impressum",
    "section": "16.5 Haftungsausschluss:",
    "text": "16.5 Haftungsausschluss:\n\n16.5.1 Haftung f√ºr Inhalte\nDie Inhalte unserer Seiten wurden mit gr√∂√üter Sorgfalt erstellt. F√ºr die Richtigkeit, Vollst√§ndigkeit und Aktualit√§t der Inhalte k√∂nnen wir jedoch keine Gew√§hr √ºbernehmen. Als Diensteanbieter sind wir gem√§√ü ¬ß 7 Abs.1 DDG f√ºr eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach ¬ß¬ß 8 bis 10 DDG sind wir als Diensteanbieter jedoch nicht verpflichtet, √ºbermittelte oder gespeicherte fremde Informationen zu √ºberwachen oder nach Umst√§nden zu forschen, die auf eine rechtswidrige T√§tigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unber√ºhrt. Eine diesbez√ºgliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung m√∂glich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\n\n\n16.5.2 Haftung f√ºr Links\nUnser Angebot enth√§lt Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb k√∂nnen wir f√ºr diese fremden Inhalte auch keine Gew√§hr √ºbernehmen. F√ºr die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf m√∂gliche Rechtsverst√∂√üe √ºberpr√ºft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n\n\n16.5.3 Urheberrecht\nDie durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielf√§ltigung, Bearbeitung, Verbreitung und jede Art der Verwertung au√üerhalb der Grenzen des Urheberrechtes bed√ºrfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur f√ºr den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n\n\n16.5.4 Datenschutz\nDie Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten m√∂glich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit m√∂glich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdr√ºckliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Daten√ºbertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitsl√ºcken aufweisen kann. Ein l√ºckenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht m√∂glich. Der Nutzung von im Rahmen der Impressumspflicht ver√∂ffentlichten Kontaktdaten durch Dritte zur √úbersendung von nicht ausdr√ºcklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdr√ºcklich widersprochen. Die Betreiber der Seiten behalten sich ausdr√ºcklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, Fachanw√§lte f√ºr Familienrecht",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "data-privacy.html",
    "href": "data-privacy.html",
    "title": "17¬† Datenschutzhinweise",
    "section": "",
    "text": "17.1 Einleitung\nDiese Datenschutzhinweise informieren Sie √ºber die Art, den Umfang und den Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend ‚ÄúDaten‚Äù) im Rahmen der Nutzung dieser Webseite (nachfolgend ‚ÄúWebseite‚Äù), die auf GitHub gehostet wird.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#einleitung",
    "href": "data-privacy.html#einleitung",
    "title": "17¬† Datenschutzhinweise",
    "section": "",
    "text": "17.1.1 Verantwortliche Person\nProf.¬†Dr.¬†habil. Sebastian Sauer, Residenzstr. 10, 90522 Ansbach, sebastian.sauer@hs-ansbach.de\n\n\n17.1.2 Hosting durch GitHub\nUnsere Webseite wird von GitHub Inc., 88 Colin P. Kelly Jr.¬†St, San Francisco, CA 94107, USA (‚ÄúGitHub‚Äù) gehostet. GitHub verarbeitet in unserem Auftrag Daten von Webseitenbesuchern (z.B. IP-Adressen). Dies ist f√ºr den Betrieb der Webseite und die Bereitstellung von Inhalten erforderlich. GitHub ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europ√§ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC&status=Active).\nWeitere Informationen zum Datenschutz bei GitHub finden Sie in der Datenschutzerkl√§rung von GitHub: https://docs.github.com/de/site-policy/privacy-policies/github-general-privacy-statement",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#datenerhebung-und--verarbeitung",
    "href": "data-privacy.html#datenerhebung-und--verarbeitung",
    "title": "17¬† Datenschutzhinweise",
    "section": "17.2 Datenerhebung und -verarbeitung",
    "text": "17.2 Datenerhebung und -verarbeitung\n\n17.2.1 Server-Log-Dateien\nBei jedem Zugriff auf unsere Webseite erfasst GitHub automatisiert Daten und speichert diese in Server-Log-Dateien. Zu diesen Daten geh√∂ren: IP-Adresse des zugreifenden Ger√§ts Datum und Uhrzeit des Zugriffs Name und URL der abgerufenen Datei Webseite, von der aus der Zugriff erfolgt (Referrer-URL) Verwendeter Browser und ggf. das Betriebssystem des zugreifenden Ger√§ts Name des Access-Providers\nDie Verarbeitung dieser Daten erfolgt, um die Funktionsf√§higkeit der Webseite sicherzustellen, die Nutzung der Webseite zu analysieren und unser Angebot zu verbessern. Rechtsgrundlage f√ºr die Datenverarbeitung ist Art. 6 Abs. 1 lit. f DSGVO (berechtigtes Interesse). Unser berechtigtes Interesse liegt in den oben genannten Zwecken.\n\n\n17.2.2 Cookies\nUnsere Webseite verwendet keine Cookies.\n\n\n17.2.3 Einbindung von Drittinhalten\nEs k√∂nnen Inhalte von Drittanbietern wie Videos, Schriftarten oder Karten eingebunden sein. Beim Abruf dieser Inhalte wird Ihre IP-Adresse m√∂glicherweise an den Drittanbieter √ºbertragen. F√ºr weitere Informationen konsultiere bitte die Datenschutzrichtlinien der jeweiligen Anbieter.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#ihre-rechte",
    "href": "data-privacy.html#ihre-rechte",
    "title": "17¬† Datenschutzhinweise",
    "section": "17.3 Ihre Rechte",
    "text": "17.3 Ihre Rechte\nSie habengegen√ºber uns folgende Rechte hinsichtlich der dich betreffenden personenbezogenen Daten: Recht auf Auskunft (Art. 15 DSGVO) Recht auf Berichtigung (Art. 16 DSGVO) Recht auf L√∂schung (Art. 17 DSGVO) Recht auf Einschr√§nkung der Verarbeitung (Art. 18 DSGVO) Recht auf Daten√ºbertragbarkeit (Art. 20 DSGVO) Recht auf Widerspruch gegen die Verarbeitung (Art. 21 DSGVO)\nSie haben zudem das Recht, sich bei einer Datenschutz-Aufsichtsbeh√∂rde √ºber die Verarbeitung deiner personenbezogenen Daten durch uns zu beschweren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "href": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "title": "17¬† Datenschutzhinweise",
    "section": "17.4 Anwendbare Rechtsgrundlagen",
    "text": "17.4 Anwendbare Rechtsgrundlagen\nNachstehend geben wir Ihnen eine √úbersicht der rechtlichen Grundlagen der DSGVO, auf deren Basis personenbezogene Daten auf dieser Webseite verarbeitet werden. Bitte beachten Sie, dass neben den Regelungen der DSGVO auch nationale Datenschutzvorgaben in Ihrem oder unserem Land relevant sein k√∂nnen. Sofern in Einzelf√§llen spezifische Rechtsgrundlagen gelten, werden diese in der Datenschutzerkl√§rung gesondert erw√§hnt.\n\n17.4.1 Vertragserf√ºllung und vorvertragliche Ma√ünahmen (Art. 6 Abs. 1 S. 1 lit. b) DSGVO)\nDie Verarbeitung personenbezogener Daten ist erforderlich zur Erf√ºllung eines Vertrags, bei dem die betroffene Person Vertragspartei ist, oder zur Durchf√ºhrung vorvertraglicher Ma√ünahmen, die auf Anfrage der betroffenen Person erfolgen.\n\n\n17.4.2 Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO)\nDie Datenverarbeitung erfolgt zur Wahrung berechtigter Interessen des Verantwortlichen oder eines Dritten, sofern keine entgegenstehenden Interessen, Grundrechte oder Grundfreiheiten der betroffenen Person, die den Schutz ihrer personenbezogenen Daten erfordern, √ºberwiegen.\n\n\n17.4.3 Nationale Datenschutzbestimmungen in Deutschland\nNeben der DSGVO gelten in Deutschland nationale Datenschutzvorgaben, insbesondere das Bundesdatenschutzgesetz (BDSG). Das BDSG beinhaltet spezielle Regelungen zum Recht auf Auskunft, L√∂schung, Widerspruch, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung f√ºr andere Zwecke sowie zur Daten√ºbermittlung und zu automatisierten Einzelentscheidungen einschlie√ülich Profiling. In bestimmten F√§llen k√∂nnen auch Datenschutzgesetze der Bundesl√§nder Anwendung finden.\n\n\n17.4.4 Hinweis auf die Geltung von DSGVO und Schweizer DSG\nDiese Datenschutzhinweise ber√ºcksichtigen die Vorgaben sowohl der DSGVO als auch des Schweizer Datenschutzgesetzes (DSG). Zur besseren Verst√§ndlichkeit und zur Vermeidung wiederholter Begriffsdefinitionen werden die Begriffe der DSGVO verwendet. Begriffe wie ‚ÄûVerarbeitung‚Äú, ‚Äûpersonenbezogene Daten‚Äú, ‚Äûberechtigtes Interesse‚Äú und ‚Äûbesondere Kategorien von Daten‚Äú entsprechen inhaltlich den Begriffen ‚ÄûBearbeitung‚Äú, ‚ÄûPersonendaten‚Äú, ‚Äû√ºberwiegendes Interesse‚Äú und ‚Äûbesonders sch√ºtzenswerte Personendaten‚Äú des Schweizer DSG. Die genaue Auslegung und Anwendung erfolgt jedoch gem√§√ü den Vorgaben des Schweizer DSG.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#sicherheitsma√ünahmen",
    "href": "data-privacy.html#sicherheitsma√ünahmen",
    "title": "17¬† Datenschutzhinweise",
    "section": "17.5 Sicherheitsma√ünahmen",
    "text": "17.5 Sicherheitsma√ünahmen\nWir setzen angemessene technische und organisatorische Ma√ünahmen zum Schutz Ihrer Daten entsprechend den gesetzlichen Anforderungen um. Dabei ber√ºcksichtigen wir den aktuellen Stand der Technik, die Implementierungskosten, Art, Umfang, Umst√§nde und Zweck der Verarbeitung sowie die Wahrscheinlichkeit und Schwere m√∂glicher Risiken f√ºr die Rechte und Freiheiten betroffener Personen.\nZu den Schutzma√ünahmen geh√∂ren insbesondere: Sicherstellung der Vertraulichkeit, Integrit√§t und Verf√ºgbarkeit von Daten durch Kontrolle des Zugriffs auf die Daten und die Infrastruktur, der Eingaben, Weitergaben und Trennungen von Daten. Zudem haben wir Verfahren eingerichtet, um die Rechte betroffener Personen zu gew√§hrleisten, Daten zu l√∂schen und angemessen auf Bedrohungen zu reagieren. Bereits in der Entwicklung und Auswahl von Hard- und Software sowie Verfahren ber√ºcksichtigen wir Datenschutzprinzipien wie Datenschutz durch Technikgestaltung und datenschutzfreundliche Voreinstellungen.\nSicherung von Online-Verbindungen mit TLS-/SSL-Verschl√ºsselung (HTTPS) Um die Daten√ºbertragung √ºber unsere Online-Dienste vor unbefugtem Zugriff zu sch√ºtzen, nutzen wir die TLS-/SSL-Verschl√ºsselungstechnologie. Dies gew√§hrleistet eine sichere Daten√ºbertragung zwischen unserem Server und Ihrem Browser, erkennbar an der HTTPS-Kennung in der URL-Leiste.\n\n17.5.1 Internationale Daten√ºbertragungen\nFalls Datenverarbeitungen in Drittl√§ndern (au√üerhalb der EU und des EWR) stattfinden oder personenbezogene Daten an Dritte im Ausland √ºbermittelt werden, erfolgt dies ausschlie√ülich unter Einhaltung gesetzlicher Anforderungen. Sofern ein Angemessenheitsbeschluss der EU-Kommission f√ºr das betreffende Drittland vorliegt (Art. 45 DSGVO), gilt dieser als Grundlage der √úbertragung. Falls kein Angemessenheitsbeschluss vorliegt, sichern Standardvertragsklauseln (Art. 46 Abs. 2 lit. c) DSGVO), eine ausdr√ºckliche Einwilligung oder gesetzliche Erfordernisse die √úbertragung ab (Art. 49 Abs. 1 DSGVO).\nWeitere Informationen zu den Angemessenheitsbeschl√ºssen der EU-Kommission finden Sie auf dieser Seite. Die USA bieten mit dem sogenannten ‚ÄûData Privacy Framework‚Äú (DPF) eine Regelung zur Sicherstellung eines angemessenen Datenschutzniveaus, das durch die EU-Kommission am 10.07.2023 anerkannt wurde. Die Liste der zertifizierten Unternehmen und weitere Informationen finden Sie auf der Webseite des US-Handelsministeriums unter Data Privacy Framework.\nWir informieren Sie in unseren Datenschutzhinweisen, welche Drittanbieter unter diesem Rahmen zertifiziert sind.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#kontakt",
    "href": "data-privacy.html#kontakt",
    "title": "17¬† Datenschutzhinweise",
    "section": "17.6 Kontakt",
    "text": "17.6 Kontakt\nF√ºr Anfragen zum Datenschutz k√∂nnen Sie sich an uns wenden:\nProf.¬†Dr.¬†habil. Sebastian Sauer\nResidenzstr. 10, 90522 Ansbach\nsebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "href": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "title": "17¬† Datenschutzhinweise",
    "section": "17.7 √Ñnderung der Datenschutzhinweise",
    "text": "17.7 √Ñnderung der Datenschutzhinweise\nWir behalten uns vor, diese Datenschutzhinweise jederzeit anzupassen, um sie an ge√§nderte Rechtslagen oder bei √Ñnderungen des Dienstes sowie der Datenverarbeitung anzupassen.\nStand: 15. November 2024",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  }
]