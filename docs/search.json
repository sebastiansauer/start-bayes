[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 EinfÃ¼hrung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage fÃ¼r Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und MÃ¤nner vor eine Einpark-Aufgabe gestellt (natÃ¼rlich alles schÃ¶n standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen kÃ¶nnen schneller einparken als MÃ¤nner, im Durchschnitt. Das hÃ¤tten wir also geklÃ¤rt. Aber haben wir das ganz sicher geklÃ¤rt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich weiÃŸ, das ist jetzt ein harter Schlag fÃ¼r Sieâ€¦ Aber die gute Nachricht ist: Wir kÃ¶nnen angeben, wie (un)sicher wir bei mit einer Aussage (â€œFrauen parken schnellerâ€¦â€) sind. Zum Beispiel kÃ¶nnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie nÃ¤chste Woche ei Fahri fÃ¼r Ihren neuen Rolls Royce anheuern, mÃ¼ssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, mÃ¼ssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen â€œlaut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauenâ€. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es Ã¼blich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den â€œTop 20 job roles in increasing and decreasing demand across industriesâ€ (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 ModulÃ¼berblick\nAbbildungÂ 1.1 gibt einen Ãœberblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n   Wskt --&gt; Bayes --&gt; Regression\n\n\n\n\nAbbildungÂ 1.1: Modulverlauf im Ãœberblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelleÂ 1.1 gibt einen Ãœberblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist nÃ¼tzlich fÃ¼r Sie, die Tabelle TabelleÂ 1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als nÃ¤chstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelleÂ 1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\nNr\nKW\nJahr\nWochenstart\nVL-frei\nThema\nKommentar\n\n\n\n1\n40\n2025\n2025-09-29\nteilweise\nEinstieg und Wiederholung von QM1\nNA\n\n\n2\n41\n2025\n2025-10-06\nnein\nInferenz\nNA\n\n\n3\n42\n2025\n2025-10-13\nnein\nHallo, Wahrscheinlichkeit\nNA\n\n\n4\n43\n2025\n2025-10-20\nnein\nRechnen mit Wahrscheinlichkeit\nNA\n\n\n5\n44\n2025\n2025-10-27\nnein\nVerteilungen\nNA\n\n\n6\n45\n2025\n2025-11-03\nnein\nBayes-Versuch\nNA\n\n\n7\n46\n2025\n2025-11-10\nnein\nDie Post befragen\nNA\n\n\nNA\n47\n2025\n2025-11-17\nja\nNA\nBlockwoche\n\n\n8\n48\n2025\n2025-11-24\nnein\nGauss-Modelle\nNA\n\n\n9\n49\n2025\n2025-11-30\nnein\nEinfache lineare Modelle\nNA\n\n\n10\n50\n2025\n2025-12-08\nnein\nSchÃ¤tzen vs. Testen\nNA\n\n\n11\n51\n2025\n2025-12-15\nnein\nFallbeispiele\nNA\n\n\n12\n52\n2025\n2025-12-22\nnein\nWiederholung und Vertiefung\nNA\n\n\nNA\n1\n2025\n2025-12-29\nja\n-\nWeichnachten\n\n\nNA\n2\n2026\n2026-01-05\nteilweise\n-\nWeichnachten\n\n\n13\n3\n2026\n2026-01-12\nnein\nKlausurvorbereitung\nNA\n\n\n11\n4\n2026\n2026-01-19\nja\nNA\nPrÃ¼fungszeit\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nFÃ¼r dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\n\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.B. im Online-Buch â€œStatistik1â€ vermittelt. Alle Inhalte daraus werden in diesem Kurs benÃ¶tigt.\n\n1.1.6 PDF-Version\nSie kÃ¶nnen die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.\nAlternativ finden Sie hier die Kapitel als PDF-Version. Achtung: Diese PDF-Versionen sind nicht unbedingt aktuell.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#lernhilfen",
    "href": "index.html#lernhilfen",
    "title": "Start:Bayes!",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nHier finden Sie einen Ãœberblick zu Lernhilfen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Start:Bayes!",
    "section": "\n1.3 Software",
    "text": "1.3 Software\nSie benÃ¶tigen R, RStudio und einige R-Pakete insbesondere rstanarm fÃ¼r diesen Kurs.\nHier finden Sie Installationshinweise.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.4 Hinweise",
    "text": "1.4 Hinweise\n\n\n\n\n\n\nHinweis\n\n\n\nAlle formalen Hinweise (PrÃ¼fung, Unterrichtsorganisation, â€¦) sind auf der Seite https://hinweisbuch.netlify.app/ zu finden. \\(\\square\\)\n\n\n\nğŸ“º Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine PrÃ¼fung in diesem Modul ist jedes Semester mÃ¶glich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#tutorium",
    "href": "index.html#tutorium",
    "title": "Start:Bayes!",
    "section": "\n1.5 Tutorium",
    "text": "1.5 Tutorium\nFÃ¼r dieses Modul wird ggf. ein Tutorium angeboten.\nDer Besuch des Tutoriums ist zu empfehlen. Arbeiten Sie auch das Materials auf der Webseite des Tutoriums durch.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#prÃ¼fung",
    "href": "index.html#prÃ¼fung",
    "title": "Start:Bayes!",
    "section": "\n1.6 PrÃ¼fung",
    "text": "1.6 PrÃ¼fung\nDas aktuelle PrÃ¼fungsformat ist: Klausur im Mehrfachwahlverfahren (Multiple Choice).\nHilfsmittel wie Skripte oder Notizen sind nicht zulÃ¤ssig. Die PrÃ¼fung findet (ausschlieÃŸlich) in PrÃ¤senz statt.\n\nAllgemeine PrÃ¼fungshinweise\n\n\nHinweise zu quantitativen PrÃ¼fungen\nHinweise zum Ablauf von Klausuren\nPrÃ¼fungsvorbereitung\n\nIn Kapitel 12 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren kÃ¶nnen:\n@book{sauer_startbayes,\n    title = {Start:Bayes},\n    rights = {CC-BY-NC},\n    url = {https://start-bayes.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2025},\n}\nHier ist die DOI:\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Start:Bayes!",
    "section": "\n1.8 Zum Autor",
    "text": "1.8 Zum Autor\nNÃ¤here Hinweise zum Autor, Sebastian Sauer, finden Sie hier.\n\n\n\n\nForum, W. E. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html",
    "href": "0200-Inferenz.html",
    "title": "\n2Â  Inferenz\n",
    "section": "",
    "text": "2.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#lernsteuerung",
    "href": "0200-Inferenz.html#lernsteuerung",
    "title": "\n2Â  Inferenz\n",
    "section": "",
    "text": "2.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n2.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie drei Zielarten der Statistik nennen und beschreiben kÃ¶nnen\ndie Definition von Inferenzstatistik sowie Beispiele fÃ¼r inferenzstatistische Fragestellungen nennen\nzentrale Begriffe der Inferenzstatistik nennen und in GrundzÃ¼gen erklÃ¤ren\nden Nutzen von Inferenzstatistik nennen\nerlÃ¤utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nanhand von Beispielen erklÃ¤ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen frequentistischer (â€œklassischerâ€) und Bayes-Inferenz benennen\nVor- und Nachteile der frequentistischen vs.Â Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklÃ¤ren\n\n2.1.3 Begleitliteratur\nBei Gelman et al. (2021), Kap. 1 findet sich eine Darstellung Ã¤hnlich zu der in diesem Kapitel. Die Begleitliteratur ist nicht prÃ¼fungsrelevant; sie dient zur Vertiefung und als Grundlage einer ausfÃ¼hrlicheren ErlÃ¤uterung des Stoffes.\n\n2.1.4 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. â€œRahmenâ€\n\nStatistik 1, dort alle Inhalte aller Kapitel zum Thema â€œModellierenâ€ bzw. â€œRegressionâ€\nStatistik 1, Abschnitt zur Normalverteilung\n\n2.1.5 Begleitvideos\n\nVideo zur Inferenz, Teil 1\nVideo zur Inferenz, Teil 2\n\n2.1.6 Wozu ist Statistik Ã¼berhaupt da?\nğŸ“º Ja, wozu ist Statistik eigentlich da?\nJa, diese Frage haben Sie sich auch schon mal gestellt? Abb. AbbildungÂ 2.1 gibt einen Ãœberblick Ã¼ber die Zielarten der statistikbasierten wissenschaftlichen Forschung.1 Nach dieser Einteilung lassen sich drei Arten von Zielen unterscheiden: Beschreiben, Vorhersagen und ErklÃ¤ren (Shmueli, 2010).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#die-drei-zielarten-der-statistik",
    "href": "0200-Inferenz.html#die-drei-zielarten-der-statistik",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.2 Die drei Zielarten der Statistik",
    "text": "2.2 Die drei Zielarten der Statistik\n\n2.2.1 Ãœberblick\n\n2.2.1.1 ğŸ“„ Beschreiben (deskriptiv)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht (bei Erwachsenen) in meiner Stichprobe?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note (im Fach Statistik) in meinem Datensatz?\nHaben unsere Kunden bisher Webshop A oder B bevorzugt, laut unseren Daten?\n\n2.2.1.2 ğŸ”® Vorhersagen (prÃ¤diktiv, prognostisch)\n\nWie schwer ist wohl Herr X? Er ist ein deutscher erwachsener Mann der GrÃ¶ÃŸe 1,80m; mehr wissen wir nicht.\nWelche Note kann man erwarten, wenn man nichts fÃ¼r die Klausur lernt?\nWie viel wird ein Kunde ausgeben, wenn er sich in der Variante A des Webshops aufhÃ¤lt?\n\n2.2.1.3 ğŸ”— ErklÃ¤ren\nKausalinferenz:\n\nIst GrÃ¶ÃŸe eine Ursache von Gewicht (bei deutschen MÃ¤nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\n\nPopulationsinferenz:\n\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note (im Fach Statistik) in der Grundgesamtheit?\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht (bei Erwachsenen) in der Grundgesamtheit?\nBevorzugen unsere Kunden allgemein Webshop A oder B laut unseren Daten?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklÃ¤rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehÃ¶rt. Um das Erkenntnisziel festzustellen, liest man sich die Forschungsfrage oder das Ziel der Studie durch.\n\n\n\nBeispiel 2.1 (Beispiele fÃ¼r die Zielarten statistischer Analysen) Â \n\nBeschreiben: â€œWie groÃŸ ist der Gender-Paygap in der Branche X im Zeitraum Y?â€\nVorhersagen: Wenn eine Person, Mr.Â X, 100 Stunden auf die Statistikklausur lernen, welche Note kann diese Person dann erwarten?\nErklÃ¤ren: Wie viel bringt (mir) das Lernen auf die Statistikklausur?\\(\\square\\)\n\n\n\nFÃ¼r die Wissenschaft ist ErklÃ¤ren das wichtigste Ziel. Bei wenig beackerten Wissenschaftsfeldern ist das Beschreiben ein sinnvoller erster Schritt. Vorhersagen ist mehr fÃ¼r die Praxis als fÃ¼r die Wissenschaft relevant.\n\n\n\n\n\nflowchart TD \n  A{Ziele} --&gt; B(Beschreiben)\n  A --&gt; C(Vorhersagen)\n  A --&gt; D(ErklÃ¤ren)\n  B --&gt; E(Verteilung)\n  B --&gt; F(Zusammenhang)\n  C --&gt; H(PunktschÃ¤tzung)\n  C --&gt; I(BereichsschÃ¤tzung)\n  D --&gt; J(Kausalinferenz)\n  D --&gt; K(Populationsinferenz)\n\n\n\n\nAbbildungÂ 2.1: Eine Einteilung zentraler Ziele von statistischen Analysen\n\n\n\n\n\n2.2.2 Zielart Beschreiben\n\nStatistische Analysen mit dem Ziel zu beschreiben fassen die Daten zusammen (zu mÃ¶glichst aussagekrÃ¤ftigen Kennzahlen). Beschreibende Statistik nennt man auch deskriptive Statistik; Mittelwert, Korrelation und Regressionskoeffizienten sind typische Kennzahlen (â€œStatistikenâ€); s. AbbildungÂ 2.2.\n\n\n\n\n\n\n\n\n\n(a) Die deskriptive Statistik fasst eine Spalte zu einer einzelnen Zahl zusammen.\n\n\n\n\n\n\n\n\n\n(b) Zwei Spalten werden zu einer Zahl zusammengefasst\n\n\n\n\n\n\nAbbildungÂ 2.2: Beschreibende Statistik fasst eine oder mehr Variablen eines Datensatzes zu einer einzelnen Kennzahl zusammen.\n\n\nDer beschreibenden Statistik geht es nicht darum, Erkenntnisse zu ziehen, die Ã¼ber die Daten hinaus gehen. So ist man in der beschreibenden Statistik nicht daran interessiert, Aussagen Ã¼ber die zugrundeliegende Population anzustellen.\n\nBeispiel 2.2 In einem HÃ¶rsaal sitzen 100 Studis. Alle schreiben Ihre KÃ¶rpergrÃ¶ÃŸe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der KÃ¶rpergrÃ¶ÃŸe der anwesenden Studentis aus. VoilÃ : Deskriptive Statistik!\\(\\square\\)\n\n\nDefinition 2.1 (Deskriptivstatistik) Deskriptivstastistik fasst Merkmale aus einer Stichprobe zu Kennzahlen (Statistiken) zusammen.\n\n\n2.2.3 Zielart Vorhersagen\n\nBeim Vorhersagen versucht man, auf Basis von Daten, gegeben bestimmter Werte der UV den Wert einer AV vorherzusagen, s. AbbildungÂ 2.3.\n\nBeispiel 2.3 (Ali lernt fÃ¼r die Klausur) Oh nein, die Klausur im Fach Statistik steht an. Ali lernt ziemlich viel. Wie viel Punkte (von 100 mÃ¶glichen) wird er wohl erzielen? Ziehen wir ein einfaches statistisches Modell zur Rate, um eine Vorhersage fÃ¼r den â€œKlausurerfolgâ€ von Ali zu erhalten. Wir kÃ¶nnen vom Modell eine einzelne Zahl (83) als Punkt-SchÃ¤tzwert bzw. Vorhersagewert erhalten oder einen SchÃ¤tzbereich (80-86 Punkte). \\(\\square\\)\n\nHier ist das Regressionsmodell fÃ¼r Ali (lm_toni), s. ListingÂ 2.1.\n\n\n\nListingÂ 2.1: Regressionsmodell fÃ¼r Klausurerfolg als Funktion der Lernzeit (lm_toni)\n\nCodenoten2 &lt;- read.csv(\"data/noten2.csv\")\nlm_toni &lt;- lm(y ~ x, data = noten2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Regressionsgerade mit Punkt-Vorhersage fÃ¼r Ali\n\n\n\n\n\n\n\n\n\n(b) Regressionsgerade mit Vorhersagebereich (und herangezoomt) fÃ¼r Ali\n\n\n\n\n\n\nAbbildungÂ 2.3: Noten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Die Vorhersage fÃ¼r Ali ist farbig markiert. Ali hat 42 Stunden gelernt fÃ¼r die Klausur; das Modell sagt ihm 83 Punkte (von 100) bzw. einen Bereich von 80 bis 86 Punkten voraus.\n\n\n\n2.2.4 Zielart ErklÃ¤ren â€“ Populationsinferenz\n\n\n\n\n\nğŸ“º Was ist Inferenz?\nPopulationsinferenz ist das SchlieÃŸen von der Stichprobe auf die Grundgesamtheit\nStatistische Populationsinferenz â€“ meist kurz als Inferenz bezeichnet â€“ hat zum Ziel, vom Teil aufs Ganze zu schlieÃŸen, bzw. vom Konkreten auf das Abstrakte. In der Datenanalyse heiÃŸt das: Was sagt meine Datensatz, der auf einer Stichprobe beruht, Ã¼ber die zugrundeliegende Grundgesamtheit aus?\n\nTypischerweise untersuchen im Rahmen einer statistischen Analyse eine Stichprobe, wie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht â€œTolle Studie zu dem Geheimnis des GlÃ¼cks!!!â€ zu klicken. Ihr Freundeskreis ist ein Teil der Menschen (z.B. aus Deutschland), also eine Stichprobe. Schauen wir uns den Unterschied zwischen Stichprobe und Population nÃ¤her an. \\(\\square\\)\n\nStichprobe vs.Â Population\nNehmen wir an, wir mÃ¶chten herausfinden, wie groÃŸ der Anteil der R-Fans in der Grundgesamthit (synonym: Population) aller Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A2.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.\nWir mÃ¼ssen also den Anteil der R-Fans in der Population auf Basis des Anteils in der Stichprobe schlieÃŸen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. AbbildungÂ 2.4.\n\n\n\n\n\n\nPopulation\n\n\n\n\n\nSample\n\n\n\n\n\nAbbildungÂ 2.4: Population vs.Â Stichprobe. Die Stichprobe entnimmt einen Teil der Daten der Population. Autor: Karsten LÃ¼bke. Lizenz: OEM.\n\n\nHÃ¤ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!3. Man schreibt: \\(p = 0.42\\) (p wie proportion, engl. fÃ¼r â€œAnteilâ€). Die Stichprobe sei reprÃ¤sentativ fÃ¼r die Grundgesamtheit aller Studierender. Messerscharf schlieÃŸen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische (\\(\\pi\\)) fÃ¼r Populationen.\\(\\square\\)\n\n\n\nDefinition 2.2 ((Populations-)Inferenzstatistik) Populations-Inferenzstatistik â€“ meist kurz als Inferenzstatistik bezeichnet â€“ ist ein Verfahren zum SchlieÃŸen von Statistiken (eine Kennzahl einer Stichprobe) auf Parameter (eine Kennzahl einer Grundgesamtheit). Inferenz bedeutet SchlieÃŸen bzw. Schlussfolgern: auf Basis von vorliegenden Wissen wird neues Wissen generiert. Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage auf allgemeine Aussagen zu schlieÃŸen. Wir unterscheiden zwei Hauptarten der Inferenzstatistik:\n\nPopulationsinferenz\nKausalinferenz \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 2.1 ğŸ‹ï¸ï¸ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Ãœben Sie jetzt schon mal.\\(\\square\\)\n\nFÃ¼r jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Populationsinferenz verwenden, um den zugehÃ¶rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle TabelleÂ 2.1. Da man die Parameter der Population so gut wie nie sicher kennt (schlieÃŸlich hat man meist nur AuszÃ¼ge, Teile der Population, also Stichproben), muss man sich mit SchÃ¤tzwerten begnÃ¼gen.\n\n\n\nTabelleÂ 2.1: Bezeichnungen fÃ¼r Kennwerte\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit (Aussprache)\nSchÃ¤tzwert\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\n\\(\\mu\\) (mÃ¼)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\n\\(\\sigma\\) (sigma)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\n\\(\\pi\\) (pi)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\n\\(\\rho\\) (rho)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\n\\(\\beta\\) (beta)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n\nFÃ¼r Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; fÃ¼r Parameter (Population) verwendet man griechische Buchstaben.\n\nÃœbungsaufgabe 2.2 ğŸ‹ï¸ Geben Sie die griechischen Buchstaben fÃ¼r typische Statistiken an. Ohne auf die Tabelle zu schauen.ğŸ˜œ\\(\\square\\)!\n\nMeist begnÃ¼gt man sich beim Analysieren von Daten nicht mit Aussagen fÃ¼r eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit SchÃ¤tzungen begnÃ¼gen. SchÃ¤tzwerte werden mit einem â€œDachâ€ Ã¼ber dem Kennwert gekennzeichnet, s. letzte Spalte in TabelleÂ 2.1.\nIn der angewandten Forschung und im praktischen Leben interessieren hÃ¤ufig Fragen wie: â€œWelche Entscheidung ist (wahrscheinlich) besser?â€. Da bekanntlich (fast) keine Aussagen sicher sind, spielt Wahrscheinlichkeit eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinlichkeit wird oft mit Pr oder p abgekÃ¼rzt, fÃ¼r engl. probability.\\(\\square\\)\n\n\n\nBeispiel 2.4 Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.Â V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\). Die Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} &gt; \\bar{X}_{V2}\\). Sind diese Unterschiede â€œzufÃ¤lligâ€ oder â€œsubstanziellâ€? Gilt also \\(\\mu_{V1} &gt; \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)? Wie groÃŸ ist die Wahrscheinlichkeit \\(Pr(\\mu_{V1} &gt; \\mu_{V2})\\)?\n\n\nÃœbungsaufgabe 2.3 ğŸ‹ï¸ VERTIEFUNG Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!\\(\\square\\)\n\n\nÃœbungsaufgabe 2.4 (Peer Instruction: Regressionskoeffizienten) Eine Regressionsgerade wird durch zwei Koeffizienten festgelegt: ihren Achsenabschnitt, \\(\\beta_0\\), sowie ihre Steigung, \\(\\beta_1\\). Berechnet man also eine Regressionsgerade, so verfolgt man damit welche Zielart der Statistik?\n\nBeschreiben\nVorhersagen\nErklÃ¤ren - Kausal\nErklÃ¤ren - Population\nAlle der oben genannten sind mÃ¶glich\nKeine der oben genannten \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-beschreiben",
    "href": "0200-Inferenz.html#zielart-beschreiben",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.3 Zielart Beschreiben\n",
    "text": "2.3 Zielart Beschreiben\n\nStatistische Analysen mit dem Ziel zu beschreiben fassen die Daten zusammen (zu mÃ¶glichst aussagekrÃ¤ftigen Kennzahlen). Beschreibende Statistik nennt man auch deskriptive Statistik; Mittelwert, Korrelation und Regressionskoeffizienten sind typische Kennzahlen (â€œStatistikenâ€); s. AbbildungÂ 2.2.\n\n\n\n\n\n\n\n\n\n(a) Die deskriptive Statistik fasst eine Spalte zu einer einzelnen Zahl zusammen.\n\n\n\n\n\n\n\n\n\n(b) Zwei Spalten werden zu einer Zahl zusammengefasst\n\n\n\n\n\n\nAbbildungÂ 2.2: Beschreibende Statistik fasst eine oder mehr Variablen eines Datensatzes zu einer einzelnen Kennzahl zusammen.\n\n\nDer beschreibenden Statistik geht es nicht darum, Erkenntnisse zu ziehen, die Ã¼ber die Daten hinaus gehen. So ist man in der beschreibenden Statistik nicht daran interessiert, Aussagen Ã¼ber die zugrundeliegende Population anzustellen.\n\nBeispiel 2.2 In einem HÃ¶rsaal sitzen 100 Studis. Alle schreiben Ihre KÃ¶rpergrÃ¶ÃŸe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der KÃ¶rpergrÃ¶ÃŸe der anwesenden Studentis aus. VoilÃ : Deskriptive Statistik!\\(\\square\\)\n\n\nDefinition 2.1 (Deskriptivstatistik) Deskriptivstastistik fasst Merkmale aus einer Stichprobe zu Kennzahlen (Statistiken) zusammen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-vorhersagen",
    "href": "0200-Inferenz.html#zielart-vorhersagen",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.4 Zielart Vorhersagen\n",
    "text": "2.4 Zielart Vorhersagen\n\nBeim Vorhersagen versucht man, auf Basis von Daten, gegeben bestimmter Werte der UV den Wert einer AV vorherzusagen, s. AbbildungÂ 2.3.\n\nBeispiel 2.3 (Ali lernt fÃ¼r die Klausur) Oh nein, die Klausur im Fach Statistik steht an. Ali lernt ziemlich viel. Wie viel Punkte (von 100 mÃ¶glichen) wird er wohl erzielen? Ziehen wir ein einfaches statistisches Modell zur Rate, um eine Vorhersage fÃ¼r den â€œKlausurerfolgâ€ von Ali zu erhalten. Wir kÃ¶nnen vom Modell eine einzelne Zahl (83) als Punkt-SchÃ¤tzwert bzw. Vorhersagewert erhalten oder einen SchÃ¤tzbereich (80-86 Punkte). \\(\\square\\)\n\nHier ist das Regressionsmodell fÃ¼r Ali (lm_toni), s. ListingÂ 2.1.\n\n\n\nListingÂ 2.1: Regressionsmodell fÃ¼r Klausurerfolg als Funktion der Lernzeit (lm_toni)\n\nCodenoten2 &lt;- read.csv(\"data/noten2.csv\")\nlm_toni &lt;- lm(y ~ x, data = noten2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Regressionsgerade mit Punkt-Vorhersage fÃ¼r Ali\n\n\n\n\n\n\n\n\n\n(b) Regressionsgerade mit Vorhersagebereich (und herangezoomt) fÃ¼r Ali\n\n\n\n\n\n\nAbbildungÂ 2.3: Noten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Die Vorhersage fÃ¼r Ali ist farbig markiert. Ali hat 42 Stunden gelernt fÃ¼r die Klausur; das Modell sagt ihm 83 Punkte (von 100) bzw. einen Bereich von 80 bis 86 Punkten voraus.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-erklÃ¤ren-kausalinferenz",
    "href": "0200-Inferenz.html#zielart-erklÃ¤ren-kausalinferenz",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.11 Zielart ErklÃ¤ren â€“ Kausalinferenz",
    "text": "2.11 Zielart ErklÃ¤ren â€“ Kausalinferenz\nMittels Kausalinferenz kÃ¶nnen wir schlieÃŸen, welche Variablen Ursachen und welche Wirkung sind â€“ und welche Variablen Scheinkorrelation erzeugen. Das ist wichtig, denn nur wenn man die Ursache kennt, weiÃŸ man, was man tun muss, um eine Wirkung zu erzielen.\n\n2.11.1 Studie A: Ã–strogen\n\n2.11.1.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 2.3: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 2.3: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nFrauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl et al., 2016)?\n\n2.11.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 2.18 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 2.18: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder â€œSchichtenâ€ (â€œStrataâ€).\n\n\n\n2.11.2 Studie B: Blutdruck\n\n2.11.2.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 2.4: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 2.4: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nhoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl et al., 2016)?\n\n2.11.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in AbbildungÂ 2.19 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 2.19: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n2.11.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 2.18 und AbbildungÂ 2.19, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n2.11.4 Sorry, Statistik: Du allein schaffst es nicht\nDatenanalyse alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ\nDatenanalyse plus Kausalinferenz erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-erklÃ¤ren-populationsinferenz",
    "href": "0200-Inferenz.html#zielart-erklÃ¤ren-populationsinferenz",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.5 Zielart ErklÃ¤ren â€“ Populationsinferenz",
    "text": "2.5 Zielart ErklÃ¤ren â€“ Populationsinferenz\n\n\n\n\n\nğŸ“º Was ist Inferenz?\n\n2.5.1 Populationsinferenz ist das SchlieÃŸen von der Stichprobe auf die Grundgesamtheit\nStatistische Populationsinferenz â€“ meist kurz als Inferenz bezeichnet â€“ hat zum Ziel, vom Teil aufs Ganze zu schlieÃŸen, bzw. vom Konkreten auf das Abstrakte. In der Datenanalyse heiÃŸt das: Was sagt meine Datensatz, der auf einer Stichprobe beruht, Ã¼ber die zugrundeliegende Grundgesamtheit aus?\n\nTypischerweise untersuchen im Rahmen einer statistischen Analyse eine Stichprobe, wie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht â€œTolle Studie zu dem Geheimnis des GlÃ¼cks!!!â€ zu klicken. Ihr Freundeskreis ist ein Teil der Menschen (z.B. aus Deutschland), also eine Stichprobe. Schauen wir uns den Unterschied zwischen Stichprobe und Population nÃ¤her an. \\(\\square\\)\n\n\n2.5.2 Stichprobe vs.Â Population\nNehmen wir an, wir mÃ¶chten herausfinden, wie groÃŸ der Anteil der R-Fans in der Grundgesamthit (synonym: Population) aller Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A2.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.\nWir mÃ¼ssen also den Anteil der R-Fans in der Population auf Basis des Anteils in der Stichprobe schlieÃŸen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. AbbildungÂ 2.4.\n\n\n\n\n\n\nPopulation\n\n\n\n\n\nSample\n\n\n\n\n\nAbbildungÂ 2.4: Population vs.Â Stichprobe. Die Stichprobe entnimmt einen Teil der Daten der Population. Autor: Karsten LÃ¼bke. Lizenz: OEM.\n\n\nHÃ¤ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!3. Man schreibt: \\(p = 0.42\\) (p wie proportion, engl. fÃ¼r â€œAnteilâ€). Die Stichprobe sei reprÃ¤sentativ fÃ¼r die Grundgesamtheit aller Studierender. Messerscharf schlieÃŸen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische (\\(\\pi\\)) fÃ¼r Populationen.\\(\\square\\)\n\n\n\nDefinition 2.2 ((Populations-)Inferenzstatistik) Populations-Inferenzstatistik â€“ meist kurz als Inferenzstatistik bezeichnet â€“ ist ein Verfahren zum SchlieÃŸen von Statistiken (eine Kennzahl einer Stichprobe) auf Parameter (eine Kennzahl einer Grundgesamtheit). Inferenz bedeutet SchlieÃŸen bzw. Schlussfolgern: auf Basis von vorliegenden Wissen wird neues Wissen generiert. Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage auf allgemeine Aussagen zu schlieÃŸen. Wir unterscheiden zwei Hauptarten der Inferenzstatistik:\n\nPopulationsinferenz\nKausalinferenz \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 2.1 ğŸ‹ï¸ï¸ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Ãœben Sie jetzt schon mal.\\(\\square\\)\n\n\n2.5.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFÃ¼r jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Populationsinferenz verwenden, um den zugehÃ¶rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle TabelleÂ 2.1. Da man die Parameter der Population so gut wie nie sicher kennt (schlieÃŸlich hat man meist nur AuszÃ¼ge, Teile der Population, also Stichproben), muss man sich mit SchÃ¤tzwerten begnÃ¼gen.\n\n\n\nTabelleÂ 2.1: Bezeichnungen fÃ¼r Kennwerte\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit (Aussprache)\nSchÃ¤tzwert\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\n\\(\\mu\\) (mÃ¼)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\n\\(\\sigma\\) (sigma)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\n\\(\\pi\\) (pi)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\n\\(\\rho\\) (rho)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\n\\(\\beta\\) (beta)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n\nFÃ¼r Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; fÃ¼r Parameter (Population) verwendet man griechische Buchstaben.\n\nÃœbungsaufgabe 2.2 ğŸ‹ï¸ Geben Sie die griechischen Buchstaben fÃ¼r typische Statistiken an. Ohne auf die Tabelle zu schauen.ğŸ˜œ\\(\\square\\)!\n\n\n2.5.4 SchÃ¤tzen von Parametern einer Grundgesamtheit\nMeist begnÃ¼gt man sich beim Analysieren von Daten nicht mit Aussagen fÃ¼r eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit SchÃ¤tzungen begnÃ¼gen. SchÃ¤tzwerte werden mit einem â€œDachâ€ Ã¼ber dem Kennwert gekennzeichnet, s. letzte Spalte in TabelleÂ 2.1.\nIn der angewandten Forschung interessieren hÃ¤ufig Fragen wie: â€œWelche Entscheidung ist (wahrscheinlich) besser?â€. Da bekanntlich (fast) keine Aussagen sicher sind, spielt Wahrscheinlichkeit eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinlichkeit wird oft mit Pr oder p abgekÃ¼rzt, fÃ¼r engl. probability.\\(\\square\\)\n\n\n\nBeispiel 2.4 Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.Â V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\). Die Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} &gt; \\bar{X}_{V2}\\). Sind diese Unterschiede â€œzufÃ¤lligâ€ oder â€œsubstanziellâ€? Gilt also \\(\\mu_{V1} &gt; \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)? Wie groÃŸ ist die Wahrscheinlichkeit \\(Pr(\\mu_{V1} &gt; \\mu_{V2})\\)?\n\n\nÃœbungsaufgabe 2.3 ğŸ‹ï¸ VERTIEFUNG Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!\\(\\square\\)\n\n\nÃœbungsaufgabe 2.4 (Peer Instruction: Regressionskoeffizienten) Eine Regressionsgerade wird durch zwei Koeffizienten festgelegt: ihren Achsenabschnitt, \\(\\beta_0\\), sowie ihre Steigung, \\(\\beta_1\\). Berechnet man also eine Regressionsgerade, so verfolgt man damit welche Zielart der Statistik?\n\nBeschreiben\nVorhersagen\nErklÃ¤ren - Kausal\nErklÃ¤ren - Population\nKeine der oben \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#modellieren",
    "href": "0200-Inferenz.html#modellieren",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.3 Modellieren",
    "text": "2.3 Modellieren\n\n2.3.1 Modellieren als Grundraster des Erkennens\nIn In der Wissenschaft â€“ wie auch oft in der Technik, Wirtschaft oder im Alltag â€“ betrachtet man einen Teil der Welt nÃ¤her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen. Nun ist die Welt ein weites Feld. Jedes Detail zu berÃ¼cksichtigen ist nicht mÃ¶glich. Wir mÃ¼ssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nÃ¶tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die fÃ¼r unsere Fragestellung zentral sind, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\nDefinition 2.3 (Modell) Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit.\\(\\square\\)\n\nDer Nutzen eines Modells ist, einen (Ã¼bermÃ¤ÃŸig) komplexen Sachverhalt zu vereinfachen oder Ã¼berhaupt erst handhabbar zu machen. Man versucht zu vereinfachen, ohne Wesentliches wegzulassen. Der Speck muss weg, sozusagen. Das Wesentliche bleibt. Auf die Statistik bezogen heiÃŸt das, dass man einen Datensatz dabei so zusammenfasst, damit man das Wesentliche erkennt.\nWas ist das â€œWesentlicheâ€? Oft interessiert man sich fÃ¼r die Ursachen eines PhÃ¤nomens. Etwa: â€œWie kommt es bloÃŸ, dass ich ohne zu lernen die Klausur so gut bestanden habe?â€4 Noch allgemeiner ist man dabei hÃ¤ufig am Zusammenhang von X und Y interessiert, s. AbbildungÂ 2.5, die ein Sinnbild von statistischen Modellen widergibt.\n\n\n\n\n\n\n\nflowchart LR\nX --&gt; Y\n\n\nX1 --&gt; Y2\nX2 --&gt; Y2\n\n\n\n\n\n\n\n\nAbbildungÂ 2.5: oben: Sinnbild eines einfachen statistischen Modellsb (eine UV, eine AV); unten: Sinnbild eines statistischen Modells, mit zwei UV\n\n\nMan kann AbbildungÂ 2.5 als ein Sinnbild einer (mathematischen) Funktion lesen.\n\nDefinition 2.4 (Funktion) Eine mathematische Funktion \\(f\\) setzt zwei GrÃ¶ÃŸen in Beziehung. \\(\\square\\)\n\nIn Mathe-Sprech: \\(f: X \\rightarrow Y\\), lies: â€œ\\(f\\) bildet \\(X\\) auf \\(Y\\) ab.â€\noder: \\(y = f(x)\\), lies: â€œY ist eine Funktion von Xâ€. \\(\\square\\)\nEs hÃ¶rt sich zugespitzt an, aber eigentlich ist fast alles, was man tut, Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst. Die Statistik kann man verstehen als ein Verfahren, dass wissenschaftliche Modelle in statistische Ã¼bersetzt und letztere dann einer empirischen Analyse unterzieht. Alle statistischen Ergebnisse beruhen auf Modelle und sind nur insoweit gÃ¼ltig, wie das zugrundeliegende Modell gÃ¼ltig ist.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#regression",
    "href": "0200-Inferenz.html#regression",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.4 Regression",
    "text": "2.4 Regression\n\n2.4.1 Regression zum Modellieren\nEinflussreiche Leute schwÃ¶ren auf die Regressionsanalyse (AbbildungÂ 2.6).\n\n\n\n\n\nAbbildungÂ 2.6: Eine Regression\n\n\nAbbildungÂ 2.7 zeigt ein interaktives Beispiel einer linearen Funktion. Sie kÃ¶nnen Punkte per Klick/Touch hinzufÃ¼gen.\nCoderesetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\nCodeviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"Kein Fehler\", \"Absoluter Fehler\", \"Quadrierter Fehler\"],\n    { label: \"View\", value: \"Absoluter Fehler\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\nCoderSquaredPlot = RSquaredPlot({ width: width })\nCoderegressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\nCodewidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\nCodeanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\nCodefunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"RÂ²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\nCode// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\nCoded3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelle\n\n\n\nAbbildungÂ 2.7: Interaktives Beispiel fÃ¼r eines lineares Modell. FÃ¼gen Sie Punkte per Klick/Touch hinzu.\n\n\nAlternativ kÃ¶nnen Sie diese App nutzen, Regressionskoeffizienten, Steigung (slope) und Achsenabschnitt (Intercept), zu optimieren. Dabei meint â€œoptimierenâ€, die Abweichungen (Residuen, Residualfehler; die roten Balken in der App) zu minimieren.5\nHier finden Sie eine App, die Ihnen gestattet, selber Hand an eine Regressionsgerade zu legen.\n\nÃœbungsaufgabe 2.5 (VERTIEFUNG Regression mit Animationen erklÃ¤rt) Lesen Sie diesen Post, der Ihnen mit Hilfe von Bildern und Animationen (okay, und etwas) Text die Grundlagen der Regressionsanalyse erklÃ¤rt.\\(\\square\\)\n\nDie Regression ist eine Art Schweizer Taschenmesser der Statistik: FÃ¼r vieles gut einsetzbar. Anstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch mathematisch schÃ¶ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden. Dann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nHinweis\n\n\n\nRegression + Inferenz = ğŸ’–\n\n\nAlternativ zur Regression kÃ¶nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni MÃ¼nster als Ausschnitt (!) aufgefÃ¼hrt. Auf dieser Basis kann man meditieren, welches statistischen Verfahren man fÃ¼r eine bestimmte Fragestellung verwenden sollte, s. AbbildungÂ 2.8 (b). Muss man aber nicht â€“ man kann stattdessen die Regression benutzen.\n\n\n\n\n\n\nHinweis\n\n\n\nEs ist meist einfacher und nÃ¼tzlicher, die Regression zu verwenden, anstelle der Vielzahl von anderen Verfahren (die zumeist SpezialfÃ¤lle der Regression sind). In diesem Kurs werden wir fÃ¼r alle Fragestellungen die Regression verwenden.6\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Die eine Regression\n\n\n\n\n\n\n\n\n\n(b) Wald von anderen Verfahren\n\n\n\n\n\n\nAbbildungÂ 2.8: WÃ¤hle die Regression. Oder den Wahl der Verfahren. Spoiler: Nimm lieber die Regression.\n\n\n\nBeispiel 2.5 Typische SpezialfÃ¤lle der Regression sind\n\nt-Test: UV: zweistufig nominal, AV: metrisch\nANOVA: UV: mehrstufig nominal, AV: metrisch\nKorrelation: Wenn UV und AV z-standardisiert sind (d.h. Mittelwert von 0 und Standardabweichung von 1 haben), dann ist die Korrelation gleich dem Regressionskoeffizienten \\(\\beta_1\\) (bei einer einfachen Regression mit einer einzigen UV). \\(\\square\\)\n\n\n\n\n\n2.4.2 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; s. AbbildungÂ 2.9. Links sieht man eine einfache Regression mit hp als UV (X, auch: PrÃ¤diktor) und mpg als AV (Y). Das rechte Teildiagramm zeigt eine multiple Regression mit den UVs hp und am.7 Im einfachsten Fall sind die vom Modell vorhergesagten (geschÃ¤tzten) Werte, \\(\\hat{y}\\), durch eine einfache Gerade beschrieben, s. AbbildungÂ 2.9, links. In allgemeiner Form schreibt man die Regressionsgleichung als lineare Gleichung, d.h. in Form einer Gerade, s. TheoremÂ 2.1.\n\nTheorem 2.1 (Lineares Modell (Regressionsgleichung)) \\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nMan nennt alle \\(\\beta_0, \\beta_1, \\beta_2, ...\\) die Regressionsgewichte (Koeffizienten oder Parameter) des Modells (Gelman et al., 2021). Dabei ist \\(\\beta_0\\) der Achsenabschnitt (eng. intercept) und \\(\\beta_1\\) die Steigung der Regressiongeraden. \\(\\square\\)\n\nAnhand von TheoremÂ 2.1 erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet.\nEine Regressionsgerade ist durch zwei Parameter festgelegt: den Achsenabschnitt, \\(\\beta_0\\) und die Steigung, \\(\\beta_1\\), s. AbbildungÂ 2.9.\n\n\n\n\n\n\n\n\n\n(a) Einfache Regression (eine UV: hp)\n\n\n\n\n\n\n\n\n\n(b) Multiple Regression (zwei UV: hp und am)\n\n\n\n\n\n\nAbbildungÂ 2.9: Die Regressionsgerade in voller Pracht",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#ungewissheit",
    "href": "0200-Inferenz.html#ungewissheit",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.5 Ungewissheit",
    "text": "2.5 Ungewissheit\n\n2.5.1 Inferenz beinhaltet Ungewissheit\nInferenzstatistische SchlÃ¼sse sind mit Ungewissheit (Unsicherheit Ã¼ber die ZuverlÃ¤ssigkeit der Ergebnisse) behaftet: SchlieÃŸlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), mÃ¶chte aber vom Teil auf das Ganze schlieÃŸen. Aus diesem begrenzten Wissen resultiert notwendig Ungewissheit Ã¼ber die gesamte Population.\n\n\n\n\n\n\nWichtig\n\n\n\nNichts Genaues weiÃŸ man nicht: SchlieÃŸt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man sich auf die Unsicherheit das Wissen Ã¼ber die Genauigkeit des SchlieÃŸens bezieht\n\n\nSchlieÃŸt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit; es ist ungewiss. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind â€“ und nicht etwa etwas mehr oder etwas weniger. SchlieÃŸlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen fÃ¼r die Stichprobe (Messfehler einmal ausgeblendet). Zur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer mÃ¶glich). Die Wahrscheinlichkeitstheorie bzw. -rechnung wird daher auch als die Mathematik des Zufalls bezeichnet.\n\nDefinition 2.5 (ZufÃ¤lliges Ereignis) Unter einem zufÃ¤lligen (engl. random) Ereignis verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nÃ¤chsten WÃ¼rfelwurfs. ZufÃ¤llig bedeutet nicht (zwangslÃ¤ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines WÃ¼rfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\nÃœbungsaufgabe 2.6 ğŸ‹ Welche physikalischen Randbedingungen wirken wohl auf einen MÃ¼nzwurf ein?\\(\\square\\)\n\n\nBeispiel 2.6 (Beispiele zur Quantifizierung von Ungewissheit) Aussagen mit Unsicherheit kÃ¶nnen unterschiedlich prÃ¤zise formuliert sein.\n\nMorgen regnetâ€™s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert von \\(Y\\) fÃ¼r Methode \\(A\\) hÃ¶her als fÃ¼r Methode \\(B\\).\nDie Maschine fÃ¤llt demnÃ¤chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nÃ¤chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n\n\nÃœbungsaufgabe 2.7 ğŸ‹ Geben Sie weitere Beispiele an!\n\n\n2.5.2 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben:\n\nWie (un)gewiss ist man sich Ã¼ber die Regressionsgewichte?\nWie (un)gewiss ist man sich Ã¼ber die Vorhersagegenauigkeit?\n\n\n2.5.2.1 Betas: Ungewissheit zur Regressionsgeraden\nWenn wir von den Daten der Stichproben auf die Grundgesamtheit schlieÃŸen, kÃ¶nnen wir nicht sicher sein, ob die Regressionskoeffizienten (Achsenabschnitt, Steigung der Regressiongeraden) exakt richtig sind, s. AbbildungÂ 2.10.\n\n\n\n\n\n\n\n\n\n(a) Ungewissheit fÃ¼r den Achsenabschnitt: Die Gerade kÃ¶nnte â€˜hÃ¶herâ€™ oder â€˜niedrigerâ€™ aufgehÃ¤ngt sein.\n\n\n\n\n\n\n\n\n\n(b) Ungewissheit fÃ¼r die Steigung der Regressionsgeraden: Die Gerade kÃ¶nnte mehr oder weniger steigen.\n\n\n\n\n\n\nAbbildungÂ 2.10: Wir kÃ¶nnten nicht sicher sein, dass der Achsenabschnitt und die Geradensteigung unseres Modells exakt richtig sind. Diese Werte kÃ¶nnten auch etwas grÃ¶ÃŸer oder kleiner sein.\n\n\nWie man in AbbildungÂ 2.11 sieht, kÃ¶nnen sich die Koeffizienten des Modells (\\(\\beta_0\\), Achsenabschnitt und \\(\\beta_1\\), Steigung) unterscheiden. Woran liegt das?\n\nBeispiel 2.7 (Stichproben der New Yorker FlÃ¼ge) Nehmen wir an, wir ziehen ein paar Zufallstichproben aus der Menge (Population) aller FlÃ¼ge, die in New York im Jahre 2013 gestartet sind. In jeder Stichprobe berechnen wir eine Regression zwischen Flugzeit und VerspÃ¤tung des Flugs am Ankunftsort. Sicherlich werden sich die Stichproben in ihren Kennwerten, z.B. in den Koeffizienten der genannten Regression, unterscheiden.\\(\\square\\)\n\n\nCodelibrary(nycflights13)\ndata(flights)\n\nstipro1 &lt;- sample_n(flights, size = 100)\nstipro2 &lt;- sample_n(flights, size = 100)\nstipro3 &lt;- sample_n(flights, size = 100)\n\n\n\n\n\n\n\n\n\n\n\n(a) Stichprobe 1\n\n\n\n\n\n\n\n\n\n(b) Stichprobe 2\n\n\n\n\n\n\n\n\n\n(c) Stichprobe 3\n\n\n\n\n\n\nAbbildungÂ 2.11: Regressionsanalysen mit verschiedenen Koeffizienten aufgrund der ZufÃ¤lligkeit des Stichprobenziehens\n\n\nDer Grund fÃ¼r die Schwankungen der Modellparameter zwischen den Stichproben ist die ZufÃ¤lligkeit des Stichprobenziehens. Je nachdem, wie es der Zufall (oder sonst wer) will, landen bestimmte FÃ¤lle (FlÃ¼ge in unserem Beispiel) in unserer Stichprobe. Zumeist unterscheiden sich die Stichproben; theoretisch kÃ¶nnten sie aber auch rein zufÃ¤llig gleich sein.\n\n\n\n\n\n\nWichtig\n\n\n\nStichproben-Kennwerte schwanken um den tatsÃ¤chlichen Wert in der Population herum. \\(\\square\\)\n\n\nUm diese Ungewissheit, die sich in den Schwankungen der Stichproben-Regressionskoeffizienten ausdrÃ¼ckt, anzuzeigen, ist ein â€œgrauer Schleierâ€ um die Regressionsgeraden in AbbildungÂ 2.11 gekennzeichnet. Dieser grauer Schleier gibt also eine Spannbreite anderer, plausibler Lagen der Regressionsgeraden an, die sich in einer anderen Stichprobe auch manifestieren kÃ¶nnten.\n\n2.5.2.2 Sigma: Ungewissheit zur Genauigkeit der Vorhersage\nAngenommen, wir sind uns sicher Ã¼ber die Werte der Modellparameter (\\(\\beta_0, \\beta_1\\)). also Ã¼ber die Lage der Regressionsgeraden, anschaulich gesprochen. Dann bliebe immer noch Ungewissheit, wie genau die Vorhersagen sind, wie groÃŸ also die AbstÃ¤nde zwischen vorhergesagten und tatsÃ¤chlichen Werten. Wenn nicht die richtigen UVs im Modell sind (relevante fehlen oder auch irrelevante sind enthalten), dann liegen Vorhersagen und wirkliche Werte weiter auseinander: diese Streuung kann man als â€œRauschenâ€ bezeichnen, s. AbbildungÂ 2.12. Diese Art der Ungewissheit ist dann interessant, wenn man Vorhersagen macht und sich fragt, wie prÃ¤zise diese Vorhersage ist. Die PrÃ¤zision eines Modells kann man mit einem von zwei Kennwerten ausdrÃ¼cken, die die gleiche Aussage machen. Diese zwei Kennwerte sind \\(R^2\\) (R-Quadrat) und \\(\\sigma\\) (sigma).\n\nDefinition 2.6 (Sigma als mittleren Vorhersagefehler) \\(\\sigma\\) gibt (grob gesagt) den mittleren Vorhersagefehler des Modells an. Einfach gesprochen sagt \\(\\sigma\\) wie weit eine Vorhersage im Durchschnitt vom wahren Wert entfernt ist. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Geringer Vorhersagefehler (hohe VorhersagegÃ¼te): Die vertikalen Balken sind kurz.\n\n\n\n\n\n\n\n\n\n(b) Hoher Vorhersagefehler: Die vertikalen Balken sind lang.\n\n\n\n\n\n\n\n\n\n(c) auch hoher Vorhersagefehler\n\n\n\n\n\n\nAbbildungÂ 2.12: Regressionsanalyse mit gleicher Regressionsgerade, aber unterschiedlicher VorhersagegÃ¼te. Die Vorhersagefehler sind mit mit farbigen vertikalen Balken markiert. Je kÃ¼rzer die Balken, desto besser (genauer) die Vorhersage.\n\n\n\n2.5.3 Ich weiÃŸ, was ich nicht weiÃŸ: Ungewissheit angeben\nStreng genommen ist eine Inferenz ohne Angabe der Ungewissheit (Genauigkeit der SchÃ¤tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schÃ¤tzt, lÃ¤sst aber offen wie sicher (prÃ¤zise) die SchÃ¤tzung (der Modellparameter) ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die SchÃ¤tzung schlieÃŸt sogar 41% oder 43% aus.\n\n\n\n\n\n\nWichtig\n\n\n\nSchlieÃŸt man auf eine Population, schÃ¤tzt also die Modellparameter, so sollte stets die (Un-)Genauigkeit der SchÃ¤tzung, also die Ungewissheit des Modells, angegeben sein.\\(\\square\\)\n\n\nIm Rahmen der Regressionsanalyse schlÃ¤gt sich die Ungewissheit an zwei Stellen (und in drei Parametern) nieder:\n\nzur PrÃ¤zision der Regressionsgeraden \\(\\beta_0\\), \\(\\beta_1\\)\n\nzur ModellgÃ¼te (\\(R^2\\)) bzw. zum Vorhersagefehler, \\(\\sigma\\)8\n\n\n2.5.4 Konfidenzintervall\nWir haben gesesehen, dass wir die Werte der Parameter nur mit Ungewissheit angegeben kÃ¶nnen (s. AbbildungÂ 2.10 und AbbildungÂ 2.12). Um dieser Ungewissheit Rechnung zu tragen, gibt man nicht nur einen einzelnen Wert an, einen PunktschÃ¤tzer, sondern man gibt ein SchÃ¤tzbereich an auf Basis der Daten, s. TabelleÂ 2.2.\nMan spricht anstatt von SchÃ¤tzbereich auch von einem Konfidenzintervall.9\n\nCodemodel_parameters(lm_toni) |&gt; \n  print_md()\n\n\nTabelleÂ 2.2: PunktschÃ¤tzer und SchÃ¤tzbereiche fÃ¼r die Modellkoeffizienten von lm_toni\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(98)\np\n\n\n\n(Intercept)\n46.19\n5.14\n(35.99, 56.39)\n8.98\n&lt; .001\n\n\nx\n0.88\n0.10\n(0.68, 1.08)\n8.92\n&lt; .001\n\n\n\n\n\n\n\n\nUnser Modell gibt den 95%-SchÃ¤tzbereich fÃ¼r den Achsenabschnitt an ca. von 36 bis 56 Klausurpunkte Die Steigung wird geschÃ¤tzt auf ca. 0.7 bis 1.1 Klausurpunkte pro Stunde Lernzeit.\n\nDefinition 2.7 (Konfidenzintervall) Ein Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff fÃ¼r SchÃ¤tzbereiche fÃ¼r Parameter wie Regressionskoeffizienten. Die Grenzen eines Konfidenzintervall markieren die Grenzen eines Bereichs plausibler Werte fÃ¼r einen Parameter. \\(\\square\\)\n\nEs gibt verschiedene Arten, Konfidenzintervalle zu berechnen; wir sprechen in spÃ¤teren Kapiteln dazu ausfÃ¼hrlicher. Ein Konfidenzintervall wird hÃ¤ufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse - auf der dieser Kurs aufbaut - ist ein Konfidenzintervall einfach zu interpretieren. Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall fÃ¼r den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt. Dieser Befund lÃ¤sst sich so interpretieren:\n\nâ€œLaut Modell liegt der gesuchte Anteil der R-Fans mit einer Wahrscheinlichkeit von 95% im Bereich von 40 bis 44 Prozentpunkten.â€\n\n\nÃœbungsaufgabe 2.8 Geben Sie Beispiele fÃ¼r Konfidenzintervalle an.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#frequentistische-inferenz-vs.-bayes-inferenz",
    "href": "0200-Inferenz.html#frequentistische-inferenz-vs.-bayes-inferenz",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.6 Frequentistische Inferenz vs.Â Bayes-Inferenz",
    "text": "2.6 Frequentistische Inferenz vs.Â Bayes-Inferenz\nEs gibt zwei Hauptarten von Inferenzstatistik: Frequentistische Inferenz und Bayes-Inferenz.\n\n\nFrequentismus: Klassische Inferenz\n\nZiel ist es, den Anteil von Fehlentscheidungen zu kontrollieren.\nKeine BerÃ¼cksichtigung von Vorwissen zum Sachgegenstand\nWahrscheinlichkeit wird Ã¼ber relative HÃ¤ufigkeiten definiert.\nEs ist nicht mÃ¶glich, die Wahrscheinlichkeit einer Hypothese bzw. eines Werts in der Population (eines Parameters) anzugeben.\nStattdessen wird angegeben, wie hÃ¤ufig eine vergleichbare Datenlage zu erwarten ist, wenn der Versuch sehr hÃ¤ufig (unendlich oft) wiederholt ist.\nEin GroÃŸteil der Forschung (in den Sozialwissenschaften) verwendet (aktuell) diesen Ansatz.\n\n\nBayesianische Inferenz\n\nZiel ist es, die Wahrscheinlichkeit einer Hypothese korrekt zu bemessen.\nVorwissen (Priori-Wissen) flieÃŸt explizit in die Analyse ein (zusammen mit den Daten).\n\nWenn das Vorwissen gut ist, wird die Vorhersage durch das Vorwissen genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen fÃ¼r Hypothesen mÃ¶glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (fÃ¼r gÃ¤ngige Computer) komfortabel geworden.\n\n\n\n\n2.6.1 Frequentistische Inferenz und der p-Wert\nDer zentrale Kennwert der Frequentistische Inferenz (synonym: Frequentismus) ist der p-Wert.\nDer p-Wert ist so definiert, vgl. Wasserstein & Lazar (2016):\n\nWie hoch ist die Wahrscheinlichkeit eines empirischen Befunds (oder noch extremere Werte), vorausgesetzt die Nullhypothese \\(H_0\\) gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufÃ¤llig verschieden und auf Basis unseres Modells)?\n\nEinfacher gesagt:\n\nDer p-Wert ist die Wahrscheinlichkeit, ein Ergebnis zu erhalten, das mindestens so extrem ist wie das beobachtete, unter der Annahme, dass es keinen Effekt gibt.\n\nNoch einfacher:\n\nMan nimmt an, dass es keinen Effekt gibt (z.B. kein Zusammenhang zwischen den untersuchten Variablen)\nDann fragt man: Wie Ã¼berraschend wÃ¤ren meine Daten unter dieser Annahme?\nDer p-Wert gibt genau diese Ãœberraschungs-Wahrscheinlichkeit an.\n\n\nÃœbungsaufgabe 2.9 ğŸ‹ Recherchieren Sie eine Definition des p-Werts und lesen Sie sie einem Freund. Beobachten sie die Reaktionen auf Ihre ErklÃ¤rung.\\(\\square\\)\n\nDer p-Wert wird oft falsch verstanden (Badenes-Ribera et al., 2016). Aber er ist auch nicht leicht zu verstehen, meint Meister Yoda, s. AbbildungÂ 2.13. Hier sind einige FALSCHE Interpretationen zum p-Wert laut der Autoren:\n\nğŸ™…â€â™€ Der p-Wert wÃ¼rde die Wahrscheinlichkeit der Nullhypothese oder der Forschungshypothese angeben. ğŸ™Š FALSCH!\nğŸ™…â€â™€ Der p-Wert wÃ¼rde ein inhaltlich bedeutsames, praktisch signifikantes Ergebnis anzeigen. ğŸ™Š FALSCH!\n\n\n\n\n\n\nAbbildungÂ 2.13: Der p-Wert ist wenig intuitiv, meint Meister Yoda\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nEin frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters). Stattdessen wird eine Aussage Ã¼ber das Ergebnis einer sehr hÃ¤ufig wiederholten Stichprobenziehung berichtet. Ob ein bestimmtes (unseres, Ihres) den wahren Wert enthÃ¤lt, bzw. mit welcher Wahrscheinlichkeit es den wahren Wert enthÃ¤lt, darÃ¼ber macht das frequentistische Konfidenzintervall keine Aussagen. \\(\\square\\)\n\n\n\n2.6.2 Bayes-Inferenz\nDie zentrale Statistik der Bayes-Inferenz bzw. (synonym) Bayes-Statistik ist die Posteriori-Verteilung.\nDie Posteriori-Verteilung beantwortet uns die Frage: â€œWie wahrscheinlich ist die Forschungshypothese (oder Varianten von ihr), jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?â€\nIn der Bayes-Statistik sind Aussagen folgender Art erlaubt:\n\nMit einer Wahrscheinlichkeit von 95% ist der neue Webshop besser als der alte. Mit einer Wahrscheinlichkeit von 89% liegt die Wirksamkeit des neuen Medikaments zwischen 0.1 und 0.4.\n\nIn diesem Post wird fÃ¼r Bayes geworben und (einseitig) Stellung pro Bayes bezogen.\n\n2.6.3 Statistische Signifikanz\nIm Frequentismus spricht man von statistischer Signifikanz, wenn der p-Wert kleiner ist als 5%: \\(p&lt;.05\\) (oder einen anderen Prozentwert als 5%, aber meistens wird 5% hergenommen). Man nimmt diesen Befund als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann. Faktisch entscheidet man sich, die Forschungshypothese weiterhin als â€œvorlÃ¤ufig gÃ¼ltigâ€ oder zumindest als â€œnicht widerlegtâ€ zu betrachten.\nIn der Bayes-Statistik ist der Begriff der Signifikanz nicht einheitlich definiert. Mit Bezug auf Gelman et al. (2021) (S. 57) wird in diesem Buch der Begriff wie folgt definiert - mit GÃ¼ltigkeit sowohl fÃ¼r Bayes-Statistik als auch fÃ¼r Frequentistische Statistik.\n\nDefinition 2.8 (Statistische Signifikanz) Ist der Wert Null nicht im SchÃ¤tzbereich enthalten, so liegt ein statistisch signifikantes Ergebnis vor. \\(\\square\\)\n\nOft werden 95%-Konfidenzintervalle verwendet, obwohl das nur eine Konvention ist. Die Signifikanzaussage bezieht sich immer auf ein SchÃ¤tzbereich bestimmter GrÃ¶ÃŸe, z.B. 95% (und des Modells inklusive Daten).\nLiegt ein statistisch signifikantes Ergebnis vor, so verwirft man die Nullhypothese und akzeptiert die Alternativhypothese (synonym: Effekthypothese).\n\nDefinition 2.9 (Exakte Nullhypothese) Die exakte Nullhypothese (meist kurz nur als Nullhypothese bezeichnet), \\(H_0\\), besagt, dass kein (null) Effekt (keine Abweichung vom Referenzwert, kein Unterschied zwischen Gruppen, kein Zusammenhang zwischen UV und AV, VerÃ¤nderung vor vs.Â nach der Intervention, â€¦) vorliegt. \\(\\square\\)\n\n\nDefinition 2.10 (Alternativhypothese (Effekthypothese)) Eine Hypothese, die besagt, dass es einen (substanziellen) Effekt gibt. Das kann z.B. ein Unterschied zwischen den untersuchten Gruppen sein oder ein Zusammenhang zwischen den untersuchten Variablen. Logisch betrachtet ist die Alternativhypothese meist das Gegenteil der Nullhypothese. \\(\\square\\)\n\n\nBeispiel 2.8 (Beispiele fÃ¼r Effekthypothesen) Â \n\nDie Trefferquote der MÃ¼nze ist \\(\\pi = .7\\) (Kopf), weicht also um 0.2 von 0.5, dem Wert laut Nullhypothese, ab.\nDer Unterschied im mittleren Gewicht zwischen den Gruppen betrÃ¤gt ca. 500-600 g.\nDer Korrelationskoeffizient \\(\\rho\\) liegt bei ca. .5 bis .7, ist also nicht Null.\nDer standardisierte Regressionskoeffizient \\(\\beta\\) liegt bei ca. .1 bis .2, ist also nicht Null.\nDer Unterschied in Gestimmtheit vor vs.Â nach der Induktion von Einsamkeit liegt bei \\(X_d = .3\\), ist also nicht Null. \\(\\square\\)\n\n\n\n\nBeispiel 2.9 (Beispiele fÃ¼r Nullhypothesen) Â \n\nHâ‚€: Î¼ = 100 (Der Populationsmittelwert betrÃ¤gt 100)\nHâ‚€: Î¼â‚ = Î¼â‚‚ (Es gibt keinen Unterschied zwischen den Mittelwerten zweier Gruppen)\nHâ‚€: Ï = 0 (Es besteht kein linearer Zusammenhang zwischen zwei Variablen)\nHâ‚€: Ï€ = 0.5 (Die Wahrscheinlichkeit fÃ¼r â€œErfolgâ€ betrÃ¤gt 50%; die MÃ¼nze ist â€œfairâ€)\nHâ‚€: Î¼â‚ = Î¼â‚‚ = Î¼â‚ƒ = Î¼â‚„ (Alle Gruppenmittelwerte sind gleich; bei ANOVA)\nHâ‚€: Î²â‚ = 0 (Der Regressionskoeffizient ist null; kein Effekt des PrÃ¤diktors)\nHâ‚€: Ïƒâ‚Â² = Ïƒâ‚‚Â² (Die Varianzen zweier Populationen sind gleich) \\(\\square\\)\n\n\n\nStatistische Signifikanz im Frequentismus (nicht in der Bayes-Statistik) ist auch eine Funktion der StichprobengrÃ¶ÃŸe: Wenn die Stichprobe groÃŸ genug ist, wird jeder Test signifikant. Daher hat ein signifikantes Ergebnis zwei mÃ¶gliche Ursachen: Der Effekt ist groÃŸ oder (auch) die Stichprobe ist groÃŸ, s. AbbildungÂ 2.14.\n\n\n\n\n\nflowchart LR\nS[StichprobengrÃ¶ÃŸe]\nE[EffektgrÃ¶ÃŸe]\np[p&lt;0.5]\nS--&gt;p\nE--&gt;p\n\n\n\n\nAbbildungÂ 2.14: Der p-Wert ist nicht nur eine Funktion der EffektgrÃ¶ÃŸe, sondern auch der StichprobengrÃ¶ÃŸe. GroÃŸe Stichproben werden zwangslÃ¤ufig signifikant, sofern der Effekt nicht exakt Null ist.\n\n\n\n\nÃœbrigens sollte man nicht nur von â€œSignifikanzâ€, sondern von â€œstatistischer Signifikanzâ€ sprechen, um klar zu machen, dass man nicht ein AlltagsverstÃ¤ndnis von Signifikanz (â€œgroÃŸâ€, â€œbedeutsamâ€) meint, sondern einen wohl definierten statistischen Begriff. Das ist wichtig, weil es sonst leicht zu Fehlinterpretationen kommt.\nMakowski et al. (2019) schlagen vor, welche Kennwerte der Bayes-Statistik analog zum \\(p\\)-Wert herangezogen werden kÃ¶nnen. Eine MÃ¶glichkeit dafÃ¼r ist der Kennwert pd (probability of direction).\n:::{#exr-stmartphone addiction} ### AbhÃ¤ngigkeit vom Handy\nDie Studie von Kabadayi (2024) untersucht den Zusammenhang von Smartphone-AbhÃ¤ngigkeit mit gesundheitlichen Problemen wie Depression, Stress, Einsamkeit und Schlafschwierigkeiten bei Heranwachsenden.\nLesen Sie den Abstract der Studie und Tabelle 2 (sowie alle Teile, die Sie benÃ¶tigen, um Tabelle 2 zu verstehen).\n\nWas ist der stÃ¤rkste Zusammenhang bzgl. Smartphone-AbhÃ¤ngigkeit? Wie hoch ist er? Wie groÃŸ ist die erklÃ¤rte Varianz des Zusammenhangs?\nZwischen welchen Variablen findet sich ein â€œstatistisch signifikanterâ€ Zusammenhang?\nErklÃ¤ren Sie, was ein â€œstatistisch signifikanter Zusammenhangâ€ hier bedeutet? \\(\\square\\) :::\n\n2.6.4 Frequentist und Bayesianer\nIm Cartoon 1132 von xkcd wird sich Ã¼ber das Nicht-BerÃ¼cksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. AbbildungÂ 2.15.\n\n\n\n\n\nAbbildungÂ 2.15: Frequentist wettet mit Bayesianer\n\n\nQuelle\n\nfrom Imgflip Meme Generator\n\n\nÃœbungsaufgabe 2.10 (Peer Instruction: p-Wert) Der p-Wert ist der zentrale Kennwert der frequentistischen Statistik. Aber er wird immer wieder missverstanden. Welche Aussage zum p-Wert ist korrekt?\n\nEin p-Wert von 0,04 bedeutet, dass die Nullhypothese mit 96 % Wahrscheinlichkeit falsch ist.\nEin p-Wert grÃ¶ÃŸer als 0,05 beweist, dass die Nullhypothese wahr ist.\nEin kleiner p-Wert bedeutet, dass ein groÃŸer Effekt vorliegt.\nEin p-Wert von 0,01 bedeutet, dass sich bei Wiederholung der Studis mit 99% wieder ein signifikantes Ergebnis finden wird.\nKeine der oben genannten. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#fazit",
    "href": "0200-Inferenz.html#fazit",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.8 Fazit",
    "text": "2.8 Fazit\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.\n\n\nWenn Sie an einer (nicht prÃ¼fungsrelevanten) Vertiefung interessiert sind, Lesen Sie die EinfÃ¼hrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#aufgaben",
    "href": "0200-Inferenz.html#aufgaben",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.9 Aufgaben",
    "text": "2.9 Aufgaben\nSchauen Sie sich die Aufgaben mit dem Tag inference auf dem Datenwerk an.\n\n2.9.1 Paper-Pencil-Aufgaben\n\nGriech-Buchstaben-Inferenz\ninferenz-fuer-alle\nttest-als-regr\nttest-skalenniveau\npwert2\ninterpret-ci\ninterpret-ci2\ngruppenvergleich-regression\nWarum-Bayes\nsamples-nyc2\n\nQuiz zu Verteilungen â€“ nur die Aufgaben, die ohne einen Computer bzw. ohne R zu lÃ¶sen sind\nparameter-genau\n\n2.9.2 Aufgaben, fÃ¼r die man einen Computer braucht\n\nkorr-als-regr\npunktschaetzer-reicht-nicht\nungewiss-arten-regr\ninferenz-fuer-alle\nadjustieren1a\nadjustieren2a\nlm-standardfehler\nvorhersageintervall1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#section",
    "href": "0200-Inferenz.html#section",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.10 â€”",
    "text": "2.10 â€”\n\n\n\n\n\nBadenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A., & Longobardi, C. (2016). Misconceptions of the P-Value among Chilean and Italian Academic Psychologists. Frontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust Misinterpretation of Confidence Intervals. Psychonomic bulletin & review, 21(5), 1157â€“1164. http://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nKabadayi, F. (2024). Smartphone Addiction, Depression, Distress, Eustress, Loneliness, and Sleep Deprivation in Adolescents: A Latent Profile and Network Analysis Approach. BMC Psychology, 12(1), 608. https://doi.org/10.1186/s40359-024-02117-6\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & LÃ¼decke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal Inference in Statistics: A Primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nShmueli, G. (2010). To Explain or to Predict? Statistical Science, 25(3), 289â€“310. https://doi.org/10.1214/10-STS330\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASAâ€™s Statement on p-Values: Context, Process, and Purpose. The American Statistician, 70(2), 129â€“133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#footnotes",
    "href": "0200-Inferenz.html#footnotes",
    "title": "\n2Â  Inferenz\n",
    "section": "",
    "text": "Ziele existieren nicht â€œin echtâ€ in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heiÃŸt, dass man sich nach Belieben Ziele ausdenken kann. Allerdings hilft es, wenn man andere Menschen vom Nutzen der eigenen Ideen Ã¼berzeugen kann.â†©ï¸\nMeistens Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?â†©ï¸\nManch einer hÃ¤tte mit mehr gerechnet; andere mit wenigerâ€¦â†©ï¸\nDas ist natÃ¼rlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.â†©ï¸\nhttps://gallery.shinyapps.io/simple_regression/â†©ï¸\nWie Jonas Kristoffer LindelÃ¸v uns erklÃ¤rt, sind viele statistische Verfahren, wie der sog. t-Test SpezialfÃ¤lle der Regression.â†©ï¸\nDer Datensatz mtcars wird gerne als Studienobjekt verwendet, da er einfach ist und fÃ¼r viele Beispiele geeignet. Wenn Sie sich einen Sachverhalt an einem einfachen Datensatz vergegenwÃ¤rtigen wollen, bietet sich auch der Datensatz mtcars an. Zudem ist er â€œfest in R eingebautâ€; mit data(mtcars) kÃ¶nnen Sie ihn verfÃ¼gbar machen.â†©ï¸\n\\(\\sigma\\), das griechische s fÃ¼r Streuung (um die Regressionsgerade herum), manchmal wird auch e wie error verwendetâ†©ï¸\nTatsÃ¤chlich gibt es mehrere Synonyme oder Ã¤hnliche Begriffe fÃ¼r Konfidenzintervall. Wir kommen spÃ¤ter darauf detaillierter zu sprechen.â†©ï¸\nnicht prÃ¼fungsrelevantâ†©ï¸",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html",
    "href": "0300-Wskt.html",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "",
    "text": "3.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#lernsteuerung",
    "href": "0300-Wskt.html#lernsteuerung",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "",
    "text": "3.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\nBayes:Start!\n\n\n3.1.2 Ãœberblick\nDieses Kapitel hat die Wahrscheinlichkeitstheorie (synonym: Wahrscheinlichkeitsrechnung) bzw. das Konzept der Wahrscheinlichkeit zum Thema.1 Es geht sozusagen um die Mathematik des Zufalls.\n\n3.1.3 Wozu brauche ich dieses Kapitel?\nIm wirklichen Leben sind Aussagen (Behauptungen) so gut wie nie sicher.\n\nâ€œWeil sie so schlau ist, ist sie erfolgreich.â€\nâ€œIn Elektroautos liegt die Zukunft.â€\nâ€œDas klappt sicher, meine Meinung.â€\nâ€œDer nÃ¤chste PrÃ¤sident wird XYZ.â€\n\n3.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Grundbegriffe der Wahrscheinlichkeitstheorie erlÃ¤uternd definieren\ndie Definitionen von Wahrscheinlichkeit beschreiben\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nerlÃ¤utern, was eine Zufallsvariable ist\n\n3.1.5 Begleitliteratur\nLesen Sie zur Begleitung dieses Kapitels Bourier (2011), Kap. 2-4.\n\n3.1.6 Eigenstudium\n\n\n\n\n\n\nWichtig\n\n\n\nDieses Kapitel ist selbstÃ¤ndig im Eigenstudium vorzubereiten vor dem Unterricht. Lesen Sie dazu die angegebene Literatur.\\(\\square\\)\n\n\n\n3.1.7 PrÃ¼fungsrelevanter Stoff\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 2-4. Weitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verfÃ¼gbar sein. PrÃ¼fen Sie, ob Ihr Dozent Ihnen weitere Hilfen im geschÃ¼tzten Bereich (Moodle) eingestellt hat.\\(\\square\\)\n\n\n\n3.1.8 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#grundbegriffe",
    "href": "0300-Wskt.html#grundbegriffe",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.2 Grundbegriffe",
    "text": "3.2 Grundbegriffe\n\n3.2.1 Zufallsvorgang\n\nBeispiel 3.1 Klassisches Beispiel fÃ¼r einen Zufallsvorgang ist das (einmalige oder mehrmalige) Werfen einer MÃ¼nze.\\(\\square\\)\nWerfen Sie eine MÃ¼nze! Diese hier zum Beispiel:\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10 Mal.\nDas reicht Ihnen nicht? Okay, wiederholen Sie den Versuch 100, nein 1000, nein: \\(10^6\\) Mal.2\nNotieren Sie als Ergebnis, wie oft die Seite mit der Zahl oben liegen kommt (â€œTrefferâ€).\\(\\square\\)\n\nOder probieren Sie die App der Brown University, wenn Sie keine SehnenscheidenentzÃ¼ndung bekommen wollen.\n\nDefinition 3.1 (Zufallsvorgang) Ein Zufallsvorgang oder Zufallsexperiment ist eine einigermaÃŸen klar beschriebene TÃ¤tigkeit, deren Ergebnis nicht sicher ist. Allerdings ist die Menge mÃ¶glicher Ergebnisse bekannt und die Wahrscheinlichkeit fÃ¼r alle Ergebnisse kann quantifiziert werden. \\(\\square\\)\n\n\nBeispiel 3.2 (Typische ZufallsvorgÃ¤nge) Â \n\n\nWÃ¼rfeln: Das Werfen eines fairen WÃ¼rfels ist ein klassisches Beispiel. Der Ausgang (die Augenzahl) kann 1, 2, 3, 4, 5 oder 6 sein.\n\nMÃ¼nzwurf: Beim Werfen einer MÃ¼nze sind die mÃ¶glichen AusgÃ¤nge â€œKopfâ€ oder â€œZahlâ€.\n\nLottoziehung: Die Ziehung von 6 aus 49 Kugeln ist ein komplexeres Zufallsexperiment. Jeder Ausgang ist eine bestimmte Kombination von 6 Zahlen. - Kartenziehen: Das Ziehen einer Karte aus einem gut gemischten Kartendeck ist ein weiteres Beispiel.\n\nGlÃ¼cksrad: Das Drehen eines GlÃ¼cksrads mit verschiedenen Feldern (z.B. Farben oder Zahlen). Welches Feld am Ende stehenbleibt, ist zufÃ¤llig. \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 3.1 Nennen Sie Beispiele fÃ¼r ZufallsvorgÃ¤nge!3\n\n\n\n\n\n\n\nVorsicht\n\n\n\nZufall heiÃŸt nicht, dass ein Vorgang keine Ursachen hÃ¤tte. So gehorcht der Fall einer MÃ¼nze komplett den Gesetzen der Gravitation. WÃ¼rden wir diese Gesetze und die Ausgangsbedingungen (Luftdruck, FallhÃ¶he, OberflÃ¤chenbeschaffenheit, Gewichtsverteilungen, â€¦) exakt kennen, kÃ¶nnten wir theoretisch sehr genaue Vorhersagen machen. Der â€œZufallâ€ wÃ¼rde aus dem MÃ¼nzwurf verschwinden. Man sollte â€œZufallâ€ also besser verstehen als â€œunbekanntâ€.\\(\\square\\)\n\n\n\nÃœbungsaufgabe 3.2 Mit dieser App kÃ¶nnen Sie WÃ¼rfelwÃ¼rfe simulieren und die AusgÃ¤nge dieses Zufallsexperiments beobachten.\\(\\square\\)\n\n\n3.2.2 Ergebnisraum\n\nDefinition 3.2 (Ergebnisraum) Die mÃ¶glichen Ergebnisse eines Zufallvorgangs fasst man als Menge mit dem Namen Ergebnisraum zusammen. Man verwendet den griechischen Buchstaben \\(\\Omega\\) fÃ¼r diese Menge. Die Elemente \\(\\omega\\) (kleines Omega) von \\(\\Omega\\) nennt man Ergebnisse.\\(\\square\\)\n\n\nBeispiel 3.3 Beobachtet man beim WÃ¼rfelwurf (s. AbbildungÂ 3.10) die oben liegende Augenzahl, so ist\n\\[\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{âš€, âš, âš‚, âšƒ, âš„, âš…\\}\\]\nein natÃ¼rlicher Grundraum (Henze, 2019).\\(\\square\\)\n\n\nBeispiel 3.4 Â \n\n\nMÃ¼nzwurf: \\(\\Omega = \\{ \\text{Kopf, Zahl} \\}\\)\n\n\nLotto: Bei der Ziehung von 6 aus 49 Kugeln ist der Grundraum die Menge aller mÃ¶glichen Kombinationen von sechs Zahlen, das sind ca. 14 Millionen.\n\nKartenziehen: Wenn eine einzelne Karte aus einem 52er-Kartendeck gezogen wird, ist der Grundraum die Menge aller 52 Karten.\n\nGlÃ¼cksrad: Wenn das GlÃ¼cksrad in vier gleich groÃŸe, farbige Felder unterteilt ist (Rot, GrÃ¼n, Blau, Gelb), dann ist der Grundraum die Menge der mÃ¶glichen Farben: \\(\\Omega = \\{ \\text{Rot, GrÃ¼n, Blau, Gelg} \\}\\) \\(\\square\\)\n\n\n\nDie Wahrscheinlichkeitsrechnung baut auf der Mengenlehre auf, daher wird die Notation der Mengenlehre hier verwendet.\n\n\n\n\n\nAbbildungÂ 3.1: Ein (sechsseitiger) WÃ¼rfel, Bildquelle: Peter Steinberg, Wikipedia, CC-BY-SA 3.0\n\n\n\n3.2.3 Ereignis\n\nDefinition 3.3 (Ereignis) Jede Teilmenge4 von \\(\\Omega\\) heiÃŸt Ereignis; \\(A \\subseteq \\Omega\\) .\\(\\square\\)\n\n\nBeispiel 3.5 Beim Mensch-Ã¤rger-dich-nicht Spielen habe ich eine 6 geworfen.5 Das Nennen wir das Ereignis \\(A\\): â€œAugenzahl 6 liegt obenâ€ und schreiben in Kurzform:\n\\(A= \\{6\\}\\square\\)\n\n\nBeispiel 3.6 Sie werfen eine MÃ¼nze (Sie haben keinen Grund, an ihrer Fairness zu zweifeln). â€œSoll ich jetzt lernen fÃ¼r die Klausur (Kopf) oder lieber zur Party gehen (Zahl)?â€\nAbbildungÂ 3.2 zeigt die mÃ¶glichen AusgÃ¤nge (T wie Treffer (Party) und N (Niete, Lernen)) dieses Zufallexperiments.\n\n\n\n\n\nflowchart LR\n M[Sie werfen die MÃ¼nze] --&gt; T[\"T (Treffer) ğŸ¥³\"]\n  M --&gt; N[\"N (Niete) ğŸ“š\"]\n\n\n\n\nAbbildungÂ 3.2: Sie werfen eine MÃ¼nze. Party oder Lernen???\n\n\n\n\nDas Ereignis Zahl ist eingetreten! Treffer! GlÃ¼ck gehabt!6\\(\\square\\)\n\n\n3.2.4 UnmÃ¶gliches und sicheres Ereignis\n\nDefinition 3.4 (UnmÃ¶gliches und sicheres Ereignis) Die leere Menge \\(\\varnothing\\) heiÃŸt das umÃ¶gliche, der Grundraum \\(\\Omega\\) heiÃŸt das sichere Ereignis. \\(\\square\\)\n\n\nBeispiel 3.7 (UnmÃ¶gliches Ereignis) Alois behauptet, er habe mit seinem WÃ¼rfel eine 7 geworfen. Schorsch ergÃ¤nzt, sein WÃ¼rfel liege auf einer Ecke, so dass keine Augenzahl oben liegt. Draco hat seinen WÃ¼rfel runtergeschluckt. Dracos und Aloisâ€™ Ereignisse sind unmÃ¶gliche Ereignisse, zumindest nach unserer Vorstellung des Zufallsexperiments.\\(\\square\\)\n\n\nBeispiel 3.8 (Sicheres Ereignis) Nach dem der WÃ¼rfel geworfen wurde, liegt eine Augenzahl zwischen 1 und 6 oben.\\(\\square\\)\n\n\n3.2.5 Elementarereignis\n\nDefinition 3.5 (Elementarereignis) Jede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) heiÃŸt Elementarereignis (hÃ¤ufig mit \\(A\\) bezeichnet). 7 \\(\\square\\)\n\n\nBeispiel 3.9 Â \n\nSie spielen Mensch-Ã¤rger-dich-nicht. Und brauchen dringend eine 6. Sie wÃ¼rfeln. Das Ereignis \\(A = \\{1\\}\\) tritt ein.8\n\nSie schreiben eine Statistik-Klausur. Irgendwie haben Sie das GefÃ¼hl, das Ergebnis sei ein Zufallsexperimentâ€¦ Jedenfalls kÃ¶nnen nach Adam Riese zwei Dinge passieren: \\(\\Omega= \\{\\text{bestehen, nicht bestehen}\\}\\). Das erste der beiden Elementarereignisse tritt ein. Yeah!\nSie fÃ¼hren eine Studie durch zur Wirksamkeit einer Lern-App. Es ist nicht klar, ob die App wirklich was bringt fÃ¼r den Lernerfolg. Vereinfacht gesprochen ist der Grundraum dieses Experiments: \\(\\Omega = \\{\\text{schadet, bringt nichts, nÃ¼tzt}\\}\\). Die Daten sprechen fÃ¼r das Ereignis \\(A = \\{\\text{bringt nichts}\\}\\).\n\n\n\nÃœbungsaufgabe 3.3 Welche Ereignisse beim WÃ¼rfelwurf sind keine Elementarereignisse? \\(\\square\\)\n\n\n3.2.6 VollstÃ¤ndiges Ereignissystem\n\nDefinition 3.6 (VollstÃ¤ndiges Ereignissystem) Wird der Grundraum \\(\\Omega\\) vollstÃ¤ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollstÃ¤ndiges Ereignissystem, s. AbbildungÂ 3.3.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 3.3: Zerlegung des Grundraums in ein vollstÃ¤ndiges Ereignissystem\n\n\n\nBeispiel 3.10 Sei \\(\\Omega\\) der typische Ergebnisraum des WÃ¼rfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) â€œgerade Zahlenâ€, und \\(B\\) â€œungerade Zahlenâ€. Damit haben wir ein vollstÃ¤ndiges Ereignissystem erstellt, s. AbbildungÂ 3.4.\n\n\n\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\}  \\qquad  \\hfill \\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6 }\n\n\\end{align}\\]\n\n\n\nAbbildungÂ 3.4\n\n\nEin Beispiel fÃ¼r ein vollstÃ¤ndiges Ereignissystem\n\n\nBeispiel 3.11 Sei \\(\\Omega\\) der typische Ergebnisraum des WÃ¼rfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) â€œ1,2,3â€, und \\(B\\) â€œ4,5,6â€. Damit haben wir ein vollstÃ¤ndiges Ereignissystem erstellt, s. AbbildungÂ 3.4.\n\n\n\n\\[\\begin{align}\nA = \\{1,2,3\\} \\qquad \\qquad \\hfill  \\boxed{\\boxed{ \\color{black}{1\\; 2\\; 3}}\\; \\color{gray}{4\\; 5\\; 6}} \\\\\nB = \\{4,5, 6\\} \\qquad \\qquad  \\hfill \\boxed{\\color{gray}{1 \\; 2 \\; 3}\\; \\boxed{\\color{black}{4\\; 5 \\; 6}}} \\\\\n\n\\newline\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\} \\qquad \\qquad \\hfill  \\boxed{1\\; 2\\; 3\\; 4\\; 5\\;6}\n\\end{align}\\]\n\n\n\nAbbildungÂ 3.5: Noch ein Beispiel fÃ¼r ein vollstÃ¤ndiges Ereignissystem\n\n\n\n\n3.2.7 MÃ¤chtigkeit\n\nDefinition 3.7 (MÃ¤chtigkeit) Die Anzahl der Elementarereignisse eines Ereignismraums nennt man die MÃ¤chtigkeit (des Ergebnisraums).9\\(\\square\\)\n\nDie MÃ¤chtigkeit von \\(\\Omega\\) bezeichnet man mit dem Symbol \\(|\\Omega|\\).\n\nBeispiel 3.12 Beim Wurf eines WÃ¼rfels mit \\(\\Omega=\\{1,2,3,4,5,6\\}\\) gibt es 6 Elementarereignisse. Die MÃ¤chtigkeit ist also 6: \\(|\\Omega|=6\\).\\(\\square\\)\n\n\n3.2.8 Disjunkte Ereignisse\nSeien \\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\).\n\\(A\\) und \\(B\\) sind disjunkt10: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. AbbildungÂ 3.6.\n\n\n\n\n\nAbbildungÂ 3.6: Zwei disjunkte Ereignisse, dargestellt noch Ã¼berlappungsfreie Kreise\n\n\nQuelle: rither.de\n\nBeispiel 3.13 Das Ereignis \\(A\\) â€œGerade Augenzahl beim WÃ¼rfelwurfâ€, \\(A={2,4,6}\\) und das Ereignis \\(B\\) â€œUngerade Augenzahl beim WÃ¼rfelwurfâ€, \\(B={1,3,5}\\) sind disjunkt, s. AbbildungÂ 3.7.\n\n\n\n\\[\\begin{align}\nA = \\{2,4, 6\\} \\qquad \\hfill \\boxed{2\\; 4\\; 6} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{1\\; 3\\; 5} \\\\\n\\hline \\\\\nA \\cap B = \\qquad  \\hfill  \\emptyset\n\\end{align}\\]\n\n\n\nAbbildungÂ 3.7: Beispiel fÃ¼r disjunkte Ereignisse\n\n\n\n\nDie Ereignisse â€œnormaler Wochentagâ€ und â€œSonntagâ€ sind disjunkt. \\(\\square\\)\n\n\nÃœbungsaufgabe 3.4 (Peer Instruction: Elementarereignis) Welche der folgenden Ereignisse zeigt ein Elementarereignis des WÃ¼rfelwurfs (wobei die Augenzahl 1,2,â€¦,6 die Ergebnisse sind).\n\nGerade Zahl gewÃ¼rfelt\nUngereade Zahl gewÃ¼rfelt\nKeine 6 gewÃ¼rfelt\n\n1 gewÃ¼rfelt\nKeine der genannten \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#was-ist-wahrscheinlichkeit",
    "href": "0300-Wskt.html#was-ist-wahrscheinlichkeit",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.3 Was ist Wahrscheinlichkeit?",
    "text": "3.3 Was ist Wahrscheinlichkeit?\nDie â€œklassischeâ€ Logik der Wissenschaft beruht auf SchlÃ¼ssen (Syllogismen) wie diesem: â€œAlle SchwÃ¤ne sind weiÃŸ.â€ \\(\\rightarrow\\) â€œDies ist ein Schwan.â€ \\(\\rightarrow\\) â€œDieser Schwan ist weiÃŸ.â€\nMit dem Konzept von Wahrscheinlichkeit kÃ¶nnen wir jetzt auch folgende Logik anwenden: â€œDie meisten SchwÃ¤ne sind weiÃŸ.â€ \\(\\rightarrow\\) â€œDies ist ein Schwan.â€ \\(\\rightarrow\\) â€œDieser Schwan ist wahrscheinlich weiÃŸ.â€ Das ist ein groÃŸer Fortschritt, der die Denkweise der Wissenschaft gut widerspiegelt und dafÃ¼r eine logisch-mathematische Grundlage bereitstellt, s. AbbildungÂ 3.8.\n\nDefinition 3.8 (Einfache Definition von Wahrscheinlichkeit) Die Wahrscheinlichkeit ist ein MaÃŸ fÃ¼r die PlausibilitÃ¤t einer Aussage \\(A\\), gegeben gewisser Hintergrundinformationen (Daten, \\(D\\)): \\(Pr(A|D)\\). Die Wahrscheinlichkeit eines Ereignisses wird (sofern berechenbar) als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unmÃ¶glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. Je nÃ¤her die Wahrscheinlichkeit bei 1 (0) liegt, desto sicherer ist jemand, dass das Ereignis (nicht) der Fall ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsrechnung ist die typische Methode, um Ungewissheit zu prÃ¤zisieren, d.h. zu quantifizieren.\nWir haben schon mit DefinitionÂ 3.9 eine erste Definition von Wahrscheinlichkeit versucht. Jetzt gehen wir die Sache noch etwas nÃ¤her an und vergleichen verschiedene Ideen (Definitionen) von Wahrscheinlichkeit.\n\n3.3.1 Formallogische Definitition\n\n3.3.1.1 Wahrscheinlichkeit als Erweiterung der Logik\nDie formallogische Konzeption von Wahrscheinlichkeit sieht Wahrscheinlichkeit als Erweiterung der formalen Logik (Jaynes & Bretthorst, 2003). 11 In der formalen Logik ist ein Ereignis entweder falsch oder wahr. In der formallogischen Konzeption wird der Platz zwischen â€œfalschâ€ (0) und â€œrichtigâ€ (1) als die Wahrscheinlichkeit \\(0&lt;p&lt;1\\), gesehen (Briggs, 2016), s. AbbildungÂ 3.8. GrÃ¶ÃŸere Werte stehen fÃ¼r grÃ¶ÃŸere Wahrscheinlichkeit und umgekehrt.\n\n\n\n\n\nAbbildungÂ 3.8: Wahrscheinlichkeit als Erweiterung der Logik\n\n\nNach dieser â€œWahrscheinlichkeitslogikâ€ kann man ein Ereignis, von dessen Eintreten man â€œwenig Ã¼berzeugtâ€ ist, z.B. mit 0.2 quantifizieren. Hingegen einem Ereignis, von man â€œrecht sicherâ€ ist, mit 0.8 quantifizieren, s. AbbildungÂ 3.9.\n\n\n\n\n\nAbbildungÂ 3.9: Ein Ereignis von dessen Eintreten man gering bzw. stark Ã¼berzeugt ist\n\n\n\n3.3.1.2 Wahrscheinlichkeit als Ungewissheit\nWahrscheinlichkeit existiert nicht in dem Sinne, wie ein Stein oder ein Mensch existiert. Wahrscheinlichkeit ist stattdessen eine Art von Wissen. Daher ist es (nach Jaynes & Bretthorst (2003)) falsch, zu sagen: â€œDie Wahrscheinlichkeit fÃ¼r Zahl bei dieser MÃ¼nze ist 50%.â€ Richtig wÃ¤re fÃ¼r einen unbedarften Spieler: â€œIch habe keinen Grund, nicht an der Fairness der MÃ¼nze zu glauben, also gehe ich von 50% Wahrscheinlichkeit fÃ¼r Zahl aus.â€ Der BetrÃ¼ger, der diese MÃ¼nze in der Hand hat, geht allerdings von einer Wahrscheinlichkeit von 75% fÃ¼r Zahl aus (er kennt die MÃ¼nze besser als Sie).\nDas Beispiel zeigt: Wahrscheinlichkeit ist kein Ding der Welt, sondern ein Wissenszustand.\nFormaler ausgedrÃ¼ckt: Sei \\(Pr\\) die Wahrscheinlichkeit des Ereignis \\(Z\\) (Zahl) angibt, gegeben meiner Annahme, dass die MÃ¼nze fair ist (\\(F\\)), also eine Wahrscheinlichkeit von 50% (1/2 = .5) hat fÃ¼r \\(Z\\). Dann kann man kurz schreiben:\n\\[Pr(Z|F) = 0.5\\] Gegeben des Wissens des BetrÃ¼gers \\(B\\) wÃ¤re die Wahrscheinlichkeit fÃ¼r \\(Z\\) anders:\n\\[Pr(Z|B) = 0.75\\]\nIn Worten: â€œDie Wahrscheinlichkeit von Zahl (\\(Z\\)) gegeben das Wissen des BetrÃ¼gers Ã¼ber die MÃ¼nze (\\(B\\)) liegt bei 75%.\nDas Beispiel zeigt auch, dass die Wahrscheinlichkeit eines Ereignissens (wie \\(Z\\)) von Hintergrundinformationen (Annahmen, Daten, Evidenz, â€¦) abhÃ¤ngt. Ohne zu sagen, auf welche Hintergrundinterformationen wir uns beziehen (die des unbedarften Spielers oder die des BetrÃ¼gers), ist es sinnvoll, eine Wahrscheinlichkeit anzugeben. Daher ist \\(Pr(Z) = 0.5\\) unvollstÃ¤ndig. Allerdings wird die Hintergrundinformation oft weggelassen, wenn es klar ist, welche Hintergrundinformation vorliegt. So wird hÃ¤ufig vorausgesetzt, dass eine MÃ¼nze fair ist.\n\nBeispiel 3.14 (Morgen regnetâ€™s) Es ist daher unvollstÃ¤ndig zu sagen: â€œMorgen wir es mit einer Wahrscheinlichkeit von 70% regnen.â€\nMan mÃ¼sste Hintergrundinformation (Evidenz, \\(E\\)) ergÃ¤nzen, z.B. â€œauf Basis des Wettermodell Xâ€.\nAlso: Anstelle von \\(Pr(\\text{Regen}) = .7\\) besser sagen: \\(Pr(\\text{Regen|Wettermodell X})\\). \\(\\square\\)\n\n\nBeispiel 3.15 (Wahrscheinlichkeit fÃ¼r Krebs) Jemand beobachtet bei sich Symptome, die fÃ¼r eine eine Hautkrebserkrankung \\(K\\) typisch sind. Die Person sagt sich: â€œAch, die Wahrscheinlichkeit fÃ¼r Hautkrebs liegt bei einem Promill. Kein Grund fÃ¼r Sorge.â€ Formal: \\(Pr(K) = 0.001\\). Aber wenn die Person relevante Symptome \\(S\\) hat, gilt: \\(Pr(\\text{K} \\mid \\text{S}) \\gg 0.001\\). \\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nSagt jemand: â€œDie Wahrscheinlichkeit von A ist x%â€, frag immer: â€œgegeben welcher Annahmen, welcher Evidenz?â€\n\n\n\nDefinition 3.9 (Wahrscheinlichkeit unter formallogischer Sichtweise) Die Wahrscheinlichkeit ist ein MaÃŸ fÃ¼r unsere Gewissheitt einer Aussage \\(A\\), gegeben gewisser Hintergrundinformationen (Daten, \\(D\\)): \\(Pr(A|D)\\). Die Wahrscheinlichkeit eines Ereignisses wird (sofern berechenbar) als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unmÃ¶glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. Je nÃ¤her die Wahrscheinlichkeit bei 1 (0) liegt, desto sicherer ist jemand, dass das Ereignis (nicht) der Fall ist.\\(\\square\\)\n\n\nDefinition 3.10 (Indifferenzprinzip) Das Indifferenzprinzip (synonym: Prinzip des unzureichenden Grundes) besagt, dass in Abwesenheit jeglicher Informationen, die bestimmte Ereignisse bevorzugen oder benachteiligen wÃ¼rden, alle mÃ¶glichen Ereignisse als gleich wahrscheinlich angesehen werden sollten. \\(\\square\\)\n\nVor uns liegt ein WÃ¼rfel. Schlicht, ruhig, unbesonders. Wir haben keinen Grund anzunehmen, dass eine seiner \\(n=6\\) Seiten bevorzugt nach oben zu liegen kommt. Jedes der sechs Elementarereignisse ist uns gleich plausibel; der WÃ¼rfel erscheint uns fair. In Ermangelung weiteres Wissens zu unserem WÃ¼rfel gehen wir schlicht davon aus, dass jedes der \\(n\\) Elementarereignis gleich wahrscheinlich ist. Es gibt keinerlei Notwendigkeit, den WÃ¼rfel in die Hand zu nehmen, um zu einer Wahrscheinlichkeitsaussage auf diesem Weg zu kommen. NatÃ¼rlich kÃ¶nnten wir unsere Auffassung eines fairen WÃ¼rfels testen, aber auch ohne das Testen kÃ¶nnen wir eine stringente Aussage (basierend auf dem Indifferenzprinzip (s. DefinitionÂ 3.10) der \\(n\\) Elementarereignisse) zur Wahrscheinlichkeit eines bestimmten (Elementar-)Ereignisses \\(A\\) kommen (Briggs, 2016), s. TheoremÂ 3.1.\n\nTheorem 3.1 (Indifferenzprinzip) \\[Pr(A) = \\frac{1}{n}= \\frac{1}{|\\Omega|} \\quad \\square\\]\n\n\nBeispiel 3.16 Sei \\(A\\) = â€œDer WÃ¼rfel wird beim nÃ¤chsten Wurf eine 6 zeigen.â€ Die Wahrscheinlichkeit fÃ¼r \\(A\\) ist \\(1/6. \\square\\)\n\n\nDefinition 3.11 (Laplace-Experimt) Ein Zufallsexperiment, bei dem alle Elementarereignisse dieselbe Wahrscheinlichkeit haben, nennt man man ein Laplace-Experiment, s. TheoremÂ 3.2. \\(\\square\\)\n\nIn Erweiterung von TheoremÂ 3.1 kÃ¶nnen wir fÃ¼r ein Laplace-Experiment schreiben, s. TheoremÂ 3.2.\n\nTheorem 3.2 (Laplace-Experiment) \\[Pr(A)=\\frac{\\text{Anzahl Treffer}}{\\text{Anzahl mÃ¶glicher Ergebnisse}} \\quad \\square\\]\n\n\nBeispiel 3.17 (Kann Sophia (Einhorn) fliegen?) Sei \\(A\\): â€œSophia ist ein Einhornâ€. Und sei \\(B\\): â€œEinhÃ¶rner mit FlÃ¼geln kÃ¶nnen fliegen und die HÃ¤lfte aller EinhÃ¶rner hat FlÃ¼gelâ€. Dann ist \\(Pr(A|B) = 1/2\\). \\(\\square\\)\n\n\nBeispiel 3.18 (Ich werfe Zahl beim nÃ¤chsten MÃ¼nzwurf) \\(B\\) â€œIch habe keinen Grund an der Fairness der MÃ¼nze zu zweifelnâ€. \\(A\\): â€œEs wird Zahl geworfen beim nÃ¤chsten Wurf dieser MÃ¼nzeâ€. Es gilt: \\(Pr(A|B) = 1/2\\). \\(\\square\\)\n\n\n3.3.2 Frequentistische Definition\nIn Ermangelung einer Theorie zum Verhalten eines (uns) unbekannten Zufallsvorgangs und unter der Vermutung, dass die Elementarereignisse nicht gleichwahrscheinlich sind, bleibt uns ein einfacher (aber aufwÃ¤ndiger und manchmal unmÃ¶glicher) Weg, um die Wahrscheinlichkeit eines Ereignisses zu bestimmen: Ausprobieren.\nAngenommen, ein Statistik-Dozent, bekannt fÃ¼r seine Vorliebe zum GlÃ¼cksspiel und mit scheinbar endlosen GlÃ¼cksstrÃ¤hnen (er wirft andauernd eine 6), hat seinen LieblingswÃ¼rfel versehentlich liegen gelassen. Das ist die Gelegenheit! Sie greifen sich den WÃ¼rfel, und â€¦ Ja, was jetzt? Nach kurzer Ãœberlegung kommen Sie zum Entschluss, den WÃ¼rfel einem â€œPraxistestâ€ zu unterziehen: Sie werfen ihn 1000 Mal (Puh!) und zÃ¤hlen den Anteil der 6. Falls der WÃ¼rfel fair ist, mÃ¼sste gelten \\(Pr(A=6)=1/6\\approx .17\\). Schauen wir mal!\nUnd hier der Anteil von 6 im Verlauf unserer WÃ¼rfe, s. AbbildungÂ 3.10.\n\n\n\n\n\n\n\nAbbildungÂ 3.10: Das Gesetz der groÃŸen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten WÃ¼rfelwurf\n\n\n\n\nHm, auf den ersten Blick ist kein (starkes) Anzeichen fÃ¼r Schummeln bzw. einen gezinkten WÃ¼rfel zu finden.\n\n3.3.3 Kolmogorovs Definition\nKolmogorov richtet eine Reihe von Forderungen an eine Definition von bzw. an das Rechnen mit Wahrscheinlichkeiten, die direkt plausibel erscheinen:\n\n\nNichtnegativitÃ¤t: Die Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein.\n\nNormierung: Das sichere Ereignis hat die Wahrscheinlichkeit 1 bzw. 100%: \\(Pr(\\Omega)=1\\); das unmÃ¶gliche Ereignis hat die Wahrscheinlichkeit 0: \\(Pr(\\emptyset)=0\\).\n\nAdditivitÃ¤t. Sind \\(A\\) und \\(B\\) disjunkt, dann ist die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt (\\(A\\cup B\\)) gleich der Summe der beiden Einzelwahrscheinlichkeiten von \\(A\\) und \\(B\\).\n\n\nÃœbungsaufgabe 3.5 (Peer Instruction: Ist der Schmockulator im Zustand alpha?) \\(B\\): â€œLocuratoren und Schmockulatoren kommen in zwei ZustÃ¤nden vor, alpha und beta. Und zwar gleich hÃ¤ufigâ€. Leider wissen wir nichts Weiteres Ã¼ber Locuratoren und Schmockulatoren. Vor Ihnen steht ein Schmockulator. Welche mÃ¶glichst prÃ¤zise Aussage kÃ¶nnen wir Ã¼ber den Zustand des Schmockulator treffen?\n\nDer Schmockulator ist sicher im Zustand alpha.\nDer Schmockulator ist in einem der beiden ZustÃ¤nde.\nDer Schmockulator ist vermutlich im Zustand alpha.\nDer Schmockulator ist mÃ¶glicherweise im Zustand alpha.\nDer Schmockulator ist mit einer Wahrscheinlichkeit von 50% im Zustand alpha.\nKeine der genannten. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#relationen-von-ereignissen",
    "href": "0300-Wskt.html#relationen-von-ereignissen",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.4 Relationen von Ereignissen",
    "text": "3.4 Relationen von Ereignissen\nFÃ¼r das Rechnen mit Wahrscheinlichkeiten ist es hilfreich, ein paar Werkzeuge zu kennen, die wir uns im Folgenden anschauen.\n\nDefinition 3.12 (Relation) Eine Relation (zweier Ereignisse) bezeichnet die Beziehung, in der die beiden Ereignisse zueinander stehen. \\(\\square\\)\n\nTypische Relationen sind Gleichheit, Ungleichheit, Vereinigung, Schnitt.\n\n3.4.1 Ãœberblick\nWir gehen von Grundraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge von \\(\\Omega\\): \\(A \\subset \\Omega\\).\nDa wir Ereignisse als Mengen auffassen, verwenden wir im Folgenden die beiden Begriffe synonym.\nDabei nutzen wir u.a. Venn-Diagramme. Venn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren. Die folgenden Venn-Diagramme stammen von Wikipedia (En).\n\n\n\n\n\n\nWozu sind die Venn-Diagramme gut? Warum soll ich die lernen?\n\n\n\nVenn-Diagramme zeigen Kreise und ihre Ã¼berlappenden Teile; daraus lassen sich RÃ¼ckschlÃ¼sse auf Rechenregeln fÃ¼r Wahrscheinlichkeiten ableiten. Viele Menschen tun sich leichter, Rechenregeln visuell aufzufassen als mit Formeln und Zahlen alleine. Aber entscheiden Sie selbst!\\(\\square\\)\n\n\nDiese App versinnbildlicht das Rechnen mit Relationen von Ereignissen anhand von Venn-Diagrammen.12\n\n3.4.2 Vereinigung von Ereignissen\n\nDefinition 3.13 (Vereinigung von Ereignissen) Vereinigt man zwei Ereignisse \\(A\\) und \\(B\\), dann besteht das neue Ereignis \\(C\\) genau aus den Elementarereignissen der vereinigten Ereignisse. Man schreibt \\(C = A \\cup B\\), lies: â€œC ist A vereinigt mit Bâ€.\\(\\square\\)\n\nAbbildungÂ 3.11 zeigt ein Venn-Diagramm zur Verdeutlichung der Vereinigung von Ereignissen.\n\n\n\n\n\nAbbildungÂ 3.11: \\(A \\cup B\\): Vereinigung\n\n\n\nBeispiel 3.19 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem nÃ¤chsten Wurf mindestens eines der beiden Ereignisse \\(A= {1,2}\\) oder \\(B={2,3}\\) eintreten, s. AbbildungÂ 3.12.\n\n\n\n\\[\\begin{aligned}\nA = \\{1,2\\} \\qquad \\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}} \\\\\nB = \\{2,3\\} \\qquad  \\boxed{1\\; \\boxed{2\\; 3}\\; \\color{gray}{ 4\\; 5\\; 6}} \\\\\n\\newline\n\\hline \\\\\nA \\cup B = \\{1,2,3\\} \\qquad \\boxed{\\boxed{1\\; 2\\; 3}\\; \\color{gray}{4\\; 5\\; \\boxed{6}}}\n\\end{aligned}\\]\n\n\n\nAbbildungÂ 3.12: Beispiel zur Vereinigung zweier Mengen\n\n\n\nZur besseren Verbildlichung betrachten Sie mal diese Animation zur Vereinigung von Mengen; Quelle.\nIn R heiÃŸt die Vereinigung von Mengen union(). Praktisch zum Ausprobieren:\n\nCodeA &lt;- c(1, 2)\nB &lt;- c(2, 3)\n\nunion(A, B)\n## [1] 1 2 3\n\n\n\n3.4.3 (Durch-)Schnitt von Ereignissen\n\nDefinition 3.14 (Schnittmenge von Ereignissen) Die Schnittmenge zweier Ereignisse \\(A\\) und \\(B\\) umfasst genau die Elementarereignisse, die Teil beider Ereignisse sind. Man schreibt: \\(A \\cap B.\\)13 Lies: â€œA geschnitten Bâ€. \\(\\square\\)\n\nAbbildungÂ 3.13 zeigt ein Sinnbild zur Schnittmenge zweier Ereignisse.\n\n\n\n\n\nAbbildungÂ 3.13: \\(A \\cap B\\): Schnitt zweier Mengen\n\n\n\nBeispiel 3.20 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem nÃ¤chsten Wurf sowohl das Ereignis \\(A\\) = â€œgerade Augenzahlâ€ als auch \\(B\\) = â€œAugenzahl grÃ¶ÃŸer 4â€, s. AbbildungÂ 3.14.\n\n\n\n\\[\\begin{align}\n& A = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n& B = \\{5,6\\} \\qquad \\qquad \\hfill  \\boxed{ \\color{gray}{1\\; 2\\; 3\\; 4\\;} \\boxed{\\color{black}{5\\; 6}}} \\\\\n\\newline\n\\hline \\\\\n& A \\cap B = \\{6\\} \\qquad \\qquad \\hfill  \\boxed{\\color{gray}{1\\; 2\\; 3\\; 4\\; 5\\;} \\color{black}{6}}\n\\end{align}\\]\n\n\n\nAbbildungÂ 3.14: Beispiel zum Schnitt zweier Mengen\n\n\n\n\nCodeA &lt;- c(2, 4, 6)\nB &lt;- c(5, 6)\nintersect(A, B)\n## [1] 6\n\n\n\n\n\n\n\n\nEselsbrÃ¼cke zur Vereinigungs- und Schnittmenge\n\n\n\nDas Zeichen fÃ¼r eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen fÃ¼r einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine EselbrÃ¼cke gelesen, s. AbbildungÂ 3.15.\n\n\n\n\n\nAbbildungÂ 3.15: EselsbrÃ¼cke fÃ¼r Vereinigungs- und Schnittmenge\n\n\n\n\n\n3.4.4 KomplementÃ¤rereignis\n\nDefinition 3.15 (KomplementÃ¤rereignis) Ein Ereignis \\(A\\) ist genau dann ein KomplementÃ¤rereignis zu \\(B\\), wenn es genau die Elementarereignisse von \\(\\Omega\\) umfasst, die nicht Elementarereignis des anderen Ereignisses sind, s. AbbildungÂ 3.17.\\(\\square\\)\n\nMan schreibt fÃ¼r das KomplementÃ¤rereignis14 von \\(A\\) oft \\(\\bar{A}\\) oder \\(\\neg A\\)15; lies â€œNicht-Aâ€ oder â€œA-querâ€.\n\nBeispiel 3.21 Beim normalen WÃ¼rfelwurf sei \\(A\\) das Ereignis â€œgerade Augenzahlâ€; das KomplementÃ¤rereignis16 ist dann \\(\\neg A\\) â€œungerade Augenzahlâ€, s. AbbildungÂ 3.16.\n\n\n\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n\\hline \\\\\n\\neg A = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\end{align}\\]\n\n\n\nAbbildungÂ 3.16: Ein Beispiel fÃ¼r ein Komplement\n\n\n\n\n\n\n\n\nAbbildungÂ 3.17: \\(\\bar{A}\\): Komplement\n\n\n\n3.4.5 Logische Differenz\n\nDefinition 3.16 (Logische Differenz) Die logische Differenz der Ereignisse \\(A\\) und \\(B\\) ist das Ereignis, das genau aus den Elementarereignissen besteht von \\(A\\) besteht, die nicht zugleich Elementarereignis von \\(B\\) sind, s. AbbildungÂ 3.18.\\(\\square\\)\n\nDie logische Differenz von \\(A\\) zu \\(B\\) schreibt man hÃ¤ufig so: \\(A \\setminus B\\); lies â€œA minus Bâ€.\n\n\n\n\n\nAbbildungÂ 3.18: \\(A \\setminus B\\)\n\n\n\nBeispiel 3.22 Sei \\(A\\) die Menge â€œgroÃŸe Zahlenâ€ mit \\(A = \\{4,5,6 \\}\\). Sei \\(B\\) die Menge â€œgerade Zahlenâ€ mit \\(B = \\{2,4,6\\}\\). Wir suchen die logische Differenz, \\(A \\setminus B\\), s. AbbildungÂ 3.19.\n\n\n\n\\[\\begin{align}\nA = \\{4,5, 6\\} \\qquad \\hfill \\boxed{\\color{red}{4}\\; \\color{green}{5}\\; \\color{red}{6}} \\\\\nB = \\{2,4,6\\} \\qquad  \\hfill \\boxed{\\color{grey}{2}\\; \\color{red}{4}\\; \\color{red}{6}} \\\\\n\\hline \\\\\nA \\setminus B \\qquad \\hfill \\boxed{\\color{green}{5}}\n\\end{align}\\]\n\n\n\nAbbildungÂ 3.19: Beispiel fÃ¼r die logische Differenz\n\n\n\nIn R gibt es die Funktion setdiff(), die eine Mengendifferenz ausgibt.\n\nCodeA &lt;- c(4, 5, 6)\nB &lt;- c(2, 4, 6)\n\nsetdiff(A, B)\n## [1] 5\n\n\nğŸ¤¯ Von der Menge \\(A\\) die Menge \\(B\\) abzuziehen, ist etwas anderes, als von \\(B\\) die Menge \\(A\\) abzuziehen.\n\n\n\n\n\n\nVorsicht\n\n\n\n\\(A \\setminus B \\ne B \\setminus A\\).\n\n\n\nCodesetdiff(B, A)\n## [1] 2\n\n\n\n3.4.6 Vertiefung\nAnimation zu Mengenoperationen\n\nÃœbungsaufgabe 3.6 (Peer Instruction: Das KomplementÃ¤rereignis von der Bestnote) Sie haben eine Statistikklausur bestanden. Mit Bestnote. Genauer gesagt, haben Sie 100 von 100 Punkten erzielt. Was ist das KomplementÃ¤rereignis dazu?\n\n99 Punkte\n0 Punkte\n0-99 Punkte\n0-100 Punkte\ndurchgefallen\nkeines der genannten \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#zufallsvariable",
    "href": "0300-Wskt.html#zufallsvariable",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.5 Zufallsvariable",
    "text": "3.5 Zufallsvariable\n\n3.5.1 Grundlagen\n\nBeispiel 3.23 Schorsch sucht eine Betreuerin fÃ¼r seine Abschlussarbeit. An die ideale Betreuerin setzt er 4 Kriterien an: a) klare, schriftliche fixierte Rahmenbedingungen, b) viel Erfahrung, c) guten Ruf und d) interessante Forschungsinteressen. Je mehr dieser 4 Kriterien erfÃ¼llt sind, desto besser. Schorsch geht davon aus, dass die 4 Kriterien voneinander unabhÃ¤ngig sind (ob eines erfÃ¼llt ist oder nicht, Ã¤ndert nichts an der Wahrscheinlichkeit, dass ein anderes Kriterium erfÃ¼llt ist). Schorsch interessiert sich also fÃ¼r die Anzahl der erfÃ¼llten Kriterien, also eine Zahl von 0 bis 4. Er schÃ¤tzt die Wahrscheinlichkeit fÃ¼r einen â€œTrefferâ€ in jedem seiner 4 Kriterien auf 50%. Viel GlÃ¼ck, Schorsch! Sein Zufallsexperiment hat 16 AusgÃ¤nge (Knoten 16 bis 31), s. AbbildungÂ 3.20 und TabelleÂ 3.1. Ganz schÃ¶n komplex. Eigentlich wÃ¼rden ihm ja eine Darstellung mit 5 Ergebnissen, also der â€œGutachter-Scoreâ€ von 0 bis 4 ja reichen. Wie kÃ¶nnen wir die Sache Ã¼bersichtlicher fÃ¼r Schorsch machen? AbbildungÂ 3.20 ist ein Versuch. \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 3.20: Ein Baumdiagramm mit 16 AusgÃ¤ngen, analog zur 4 MÃ¼nzwÃ¼rfen. T: Treffer (Kriterium erfÃ¼llt). N: Niete (Kriterium nicht erfÃ¼llt). NNNT wÃ¤re zum Beispiel eine Gutachterin ohne klar fixierte Rahmenbedingungen, ohne viel Erfahrung, mit schlechem Ruf aber mit interessanten Forschungsinteressen.\n\n\n\n\n\nTabelleÂ 3.1: Schorschs Zufallsexperiment, Auszug der Elementarereignisse (EE)\n\n\n\n\n\n\ni\nElementarereignis\nPr(EE)\nTrefferzahl\n\n\n\n1\nNNNN\n1/16\n0\n\n\n2\nNNNT\n1/16\n1\n\n\n3\nNNTN\n1/16\n1\n\n\n4\nNTNN\n1/16\n1\n\n\n5\nTNNN\n1/16\n1\n\n\n6\nNNTT\n1/16\n2\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\n\n\n\n\n\n\nSchorsch braucht also eine Ã¼bersichtlichere Darstellung; die Zahl der Treffer und ihre Wahrscheinlichkeit wÃ¼rde ihm ganz reichen. In vielen Situationen ist man an der Anzahl der Treffer interessiert. Die Wahrscheinlichkeit fÃ¼r eine bestimmte Trefferanzahl bekommt man einfach durch Addieren der Wahrscheinlichkeiten der zugehÃ¶rigen Elementarereignisse, s. TabelleÂ 3.1. Hier kommt die Zufallsvariable ins Spiel. Wir nutzen sie, um die Anzahl der Treffer in einem Zufallsexperiment zu zÃ¤hlen.\n\nDefinition 3.17 (Zufallsvariable) Die Zuordnung der Elementarereignisse eines Zufallsexperiments zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable.\\(\\square\\)\n\nDie den Elementarereignissen zugewiesenen Zahlen nennt man Realisationen oder AusprÃ¤gungen der Zufallsvariablen.\n\nBeispiel 3.24 (Lotto) Ein Lottospiel hat ca. 14 Millionen Elementarereignisse. Die Zufallsvariable â€œAnzahl der Trefferâ€ hat nur 7 Realisationen: 0,1,â€¦,6.\\(\\square\\)\n\nEs hat sich eingebÃ¼rgert, Zufallszahlen mit \\(X\\) zu bezeichnen (oder anderen Buchstaben weit hinten aus dem Alphabet).\nMan schreibt fÃ¼r eine Zufallsvariable kurz: \\(X: \\Omega \\rightarrow \\mathbb{R}\\). â€œX ist eine Zufallsvariable, die jedem Elementarereignis \\(\\omega\\) eine reelle Zahl zuordnet.â€ Um die Vorschrift der Zuordnung genauer zu bestimmen, kann man folgende Kurzschreibweise nutzen:\n\\({\\displaystyle X(\\omega )={\\begin{cases}1,&{\\text{wenn }}\\omega ={\\text{Kopf}},\\\\[6pt]0,&{\\text{wenn }}\\omega ={\\text{Zahl}}.\\end{cases}}}\\)\nAbbildungÂ 3.21 stellt diese Abbildung dar.\n\n\n\n\n\nAbbildungÂ 3.21: Eine Zufallsvariable ist eine Zuordnung der Ereignisse zu einer reellen Zahl (nach einer bestimmten Regel\n\n\nZufallsverteilungen kann im zwei Arten einteilen:\n\ndiskrete Zufallsvariablen\nstetige Zufallsvariablen\n\n3.5.2 Diskrete Zufallsvariable\n\n3.5.2.1 Grundlagen\nEine diskrete Zufallsvariable ist dadurch gekennzeichnet, dass nur bestimmte Realisationen mÃ¶glich sind, zumeist natÃ¼rliche Zahlen, wie 0, 1, 2,â€¦, . AbbildungÂ 3.22 versinnbildlicht die Zufallsvariable des â€œGutachter-Scoresâ€, s. BeispielÂ 3.23.\n\n\n\n\n\n\n\nAbbildungÂ 3.22: Sinnbild einer diskreten Zufallsvariablen X fÃ¼r Schorschs Suche nach einer Betreuerin seiner Abschlussarbeit. X gibt den Score der Gutachterin wider.\n\n\n\n\n\nBeispiel 3.25 (Diskrete Zufallsvariablen) Â \n\nAnzahl der Bewerbungen bis zum ersten Job-Interview\nAnzahl AnlÃ¤ufe bis zum Bestehen der Statistik-Klausur\nAnzahl der Absolventen an der HS Ansbach pro Jahr\nAnzahl Treffer beim Kauf von Losen\nAnzahl BetriebsunfÃ¤lle\nAnzahl der Produkte in der Produktpalette\\(\\square\\)\n\n\n\n\nBeispiel 3.26 Der zweifache WÃ¼rfelwurf ist ein typisches Lehrbuchbeispiel fÃ¼r eine diskrete Zufallsvariable. 17 Hier ist \\(S\\)18 die Augensumme des zweifachen WÃ¼rfelwurfs und \\(S\\) ist eine Zahl zwischen 2 und 12. FÃ¼r jede Realisation \\(X=x\\) kann man die Wahrscheinlichkeit berechnen, AbbildungÂ 3.23 versinnbildlicht die Wahrscheinlichkeit fÃ¼r jede Realisation von \\(X\\).\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 3.23: Augensumme des zweifachen WÃ¼rfelwurfs; fÃ¼r jede Realisation von S ist die zugehÃ¶rige Wahrscheinlichkeit dargestellt. Bildquelle: Tim Stellmach, Wikipedia, PD\n\n\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariablen eine Wahrscheinlichkeit zuzuordnen.\n\nDefinition 3.18 (Diskrete Wahrscheinlichkeitsverteilung) Eine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) AusprÃ¤gungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu.\\(\\square\\)\n\n\nBeispiel 3.27 (Wahrscheinlichkeit des Geschlechts bei der Geburt) So hat die Variable Geschlecht eines Babies die beiden AusprÃ¤gungen MÃ¤dchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\), laut einer Studie (Gelman et al., 2021).\\(\\square\\)\n\nZwischen der deskriptiven Statistik und der Wahrscheinlichkeitstheorie bestehen enge Parallelen, TabelleÂ 3.2 stellt einige zentrale Konzepte gegenÃ¼ber. Bei einer guten Stichproben kann man die Kennwerte der deskriptiven Statistik als SchÃ¤tzwerte fÃ¼r die zugrundeliegende Wahrscheinlichkeit verwenden.\n\n\n\nTabelleÂ 3.2: GegenÃ¼berstellung von Wahrscheinlichkeitstheorie und deskriptiver Statistik\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDeskriptive Statistik\n\n\n\nZufallsvariable\nMerkmal\n\n\nWahrscheinlichkeit\nrelative HÃ¤ufigkeit, Anteil\n\n\nWahrscheinlichkeitsverteilung\neinfache relative HÃ¤ufigkeitsverteilung\n\n\nVerteilungsfunktion\nkumulierte relative HÃ¤ufigkeitsverteilung\n\n\nErwartungswert\nMittelwert\n\n\nVarianz\nVarianz\n\n\n\n\n\n\n\n\n\nEine Verteilung zeigt, welche AusprÃ¤gungen eine Variable aufweist und wie hÃ¤ufig bzw. wahrscheinlich diese sind. Einfach gesprochen veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet HÃ¤ufigkeitsverteilungen (s. Abb. AbbildungÂ 3.25) von Wahrscheinlichkeitsverteilungen (Abb. AbbildungÂ 3.24).\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.24: Wahrscheinlichkeitsverteilung der Zufallsvariable â€œAugenzahl im zweifachen WÃ¼rfelwurfâ€\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.25: (relative und absolute) HÃ¤ufigkeiten des zweifachen WÃ¼rfelwurfs, 1000 Mal wiederholt\n\n\n\n\n\n\n\nBeispiel 3.28 (Wahrscheinlichkeitsverteilung eines WÃ¼rfels) AbbildungÂ 3.26 zeigt die Wahrscheinlichkeitsverteilung eines einfachen WÃ¼rfelwurfs.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 3.26: Wahrscheinlichkeitsverteilung eines einfachen WÃ¼rfelwurfs, Bildrechte: Olex Alexandrov, Wikipedia, PD\n\n\n\nBeispiel 3.29 Die Wahrscheinlichkeitsverteilung fÃ¼r \\(X\\) â€œAugensumme im zweifachen WÃ¼rfelwurfâ€ ist in AbbildungÂ 3.24 visualisiert.\\(\\square\\)\n\n\n3.5.2.2 Vertiefung: Verteilungsfunktion\n\nDefinition 3.19 (Verteilungsfunktion) Die Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist.\\(\\square\\)\n\nDie Berechnung von \\(F(x)\\) erfolgt, indem die Wahrscheinlichkeiten aller mÃ¶glichen Realisationen \\(x_i\\), die kleiner oder gleich dem vorgegebenen Realisationswert \\(x\\) sind, addiert werden:\n\\(F(x) = \\sum_{x_ \\le x} Pr(X=x_i).\\)\nDie Verteilungsfunktion ist das Pendant zur kumulierten HÃ¤ufigkeitsverteilung, vgl. AbbildungÂ 3.27 und AbbildungÂ 3.28: Was die kumulierte HÃ¤ufigkeitsverteilung fÃ¼r HÃ¤ufigkeiten ist, ist die Verteilungsfunktion fÃ¼r Wahrscheinlichkeiten.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.27: Verteilungsfunktion \\(F(X \\le x_i)\\) fÃ¼r die Zufallsvariable â€œAugenzahl im zweifachen WÃ¼rfelwurfâ€\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.28: Empirische Verteilungsfunktion (kumulierte HÃ¤ufigkeitsverteilung) \\(F(X \\le x_i)\\) von 1000 zweifachen MÃ¼nzwÃ¼rfen\n\n\n\n\n\n\n\n3.5.3 Stetige Zufallsvariablen\n\n3.5.3.1 Grundlagen\nğŸ“º Verteilungen metrischer Zufallsvariablen\nAbbildungÂ 3.29 versinnbildlicht die stetige Zufallsvariable â€œKÃ¶rpergrÃ¶ÃŸeâ€, die (theoretisch, in AnnÃ¤herung) jeden beliebigen Wert zwischen 0 und (vielleicht) 2 Meter annehmen kann.\n\n\n\n\n\n\n\nAbbildungÂ 3.29: Sinnbild fÃ¼r eine stetige Zufallsvariable X â€œKÃ¶rpergrÃ¶ÃŸeâ€\n\n\n\n\n\nDefinition 3.20 (Stetige Zufallsvariable) Eine stetige Zufallsvariable gleicht einer diskreten, nur dass alle Werte im Intervall erlaubt sind.\\(\\square\\)\n\n\nBeispiel 3.30 Â \n\nSpritverbrauch\nKÃ¶rpergewicht von Professoren\nSchnabellÃ¤ngen von Pinguinen\nGeschwindigkeit beim Geblitztwerden\\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 3.7 (Warten auf den Bus, 42 Sekunden) Sie stehen an der Bushaltestellen und warten auf den Bus. Langweilig. Da kommt Ihnen ein Gedanken in den Sinn: Wie hoch ist wohl die Wahrscheinlichkeit, dass Sie exakt 42 Sekunden auf den Bus warten mÃ¼ssen, s. AbbildungÂ 3.31? Weiterhin Ã¼berlegen Sie, dass davon auszugehen ist, dass jede Wartezeit zwischen 0 und 10 Minuten gleich wahrscheinlich ist. SpÃ¤testens nach 10 Minuten kommt der Bus, so ist die Taktung (extrem zuverlÃ¤ssig). Exakt heiÃŸt exakt, also nicht 42.1s, nicht 42.01s, nicht 42.001s, etc. bis zur x-ten Dezimale.\\(\\square\\)\n\nNicht so einfach (?). Hingegen ist die Frage, wie hoch die Wahrscheinlichkeit ist, zwischen 0 und 5 Minuten auf den Bus zu warten (\\(0&lt;x&lt;5\\)), einfach: Sie betrÃ¤gt 50%, wie man in AbbildungÂ 3.30 gut sehen kann.\n\n\n\n\n\n\n\nAbbildungÂ 3.30: Wie groÃŸ ist die Wahrscheinlichkeit, zwischen 0 und 5 Minuten auf den Bus zu warten? 50 Prozent!\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.31: Wie groÃŸ ist die Wahrscheinlichkeit, genau 42 Sekunden auf den Bus zu warten? Hm.\n\n\n\n\n\n\nVergleicht man AbbildungÂ 3.31 und AbbildungÂ 3.30 kommt man (vielleicht) zu dem Schluss, dass die Wahrscheinlichkeit exakt 42s auf den Bus zu warten, praktisch Null ist. Der Grund ist, dass die FlÃ¤che des Intervalls gegen Null geht, wenn das Intervall immer schmÃ¤ler wird. Aus diesem Grund kann man bei stetigen Zufallszahlen nicht von einer Wahrscheinlichkeit eines bestimmten Punktes \\(X=x\\) sprechen. FÃ¼r einen bestimmten Punkt \\(X=x\\) kann man aber die Dichte der Wahrscheinlichkeit angeben.\nWas gleich ist in beiden Situationen (\\(Pr(X=.42)\\) und \\(Pr(0&lt;x&lt;0.5)\\)) ist die Wahrscheinlichkeitsdichte, \\(f\\). In AbbildungÂ 3.31 und AbbildungÂ 3.30 ist die Wahrscheinlichkeitsdichte gleich, \\(f=1/10=0.1\\).\n\nDefinition 3.21 (Wahrscheinlichkeitsdichte) Die Wahrscheinlichkeitsdichte \\(f(x)\\) gibt an, wie viel Wahrscheinlichkeitsmasse pro Einheit von \\(X\\) an an der Stelle \\(x\\) ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsdichte zeigt an, an welchen Stellen \\(x\\) die Wahrscheinlichkeit besonders â€œgeballtâ€ oder â€œdichtâ€ sind, s. AbbildungÂ 3.32.\n\n\n\n\n\nAbbildungÂ 3.32: Die Wahrscheinlichkeit, dass eine Zufallsvariable einen Wert zwischen und annimmt, entspricht dem Inhalt der FlÃ¤che unter dem Graph der Wahrscheinlichkeitsdichtefunktion. Bildrechte: 4C, Wikipedia, CC-BY-SA .\n\n\nBei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen AusprÃ¤gungen aus; die Wahrscheinlichkeit einer bestimmten AusprÃ¤gung ist Null: $Pr(X=x_j)=0, j=1,â€¦,+\n\nBeispiel 3.31 (Wahrscheinlichkeitsverteilung fÃ¼r die KÃ¶rpergrÃ¶ÃŸe) So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666â€¦ cm groÃŸ ist, ist (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\).\\(\\square\\)\n\nFÃ¼r praktische Fragen berechnet man zumeist die Wahrscheinlichkeit von Intervallen, s. AbbildungÂ 3.32.\n\n3.5.3.2 Vertiefung: Verteilungsfunktion\n\n\n\nDefinition 3.22 (Verteilungsfunktion) Die Verteilungsfunktion einer stetigen Zufallsvariablen gibt wie im diskreten Fall an, wie groÃŸ die Wahrscheinlichkeit fÃ¼r eine Realisation kleiner oder gleich einem vorgegebenen Realisationswert \\(x\\) ist.\\(\\square\\)\nDie Verteilungsfunktion \\(F(x)\\) ist analog zur kumulierten HÃ¤ufigkeitsverteilung zu verstehen, vgl. AbbildungÂ 3.33. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.33: Verteilungsfunktion F fÃ¼r X=â€œWartezeit auf den Busâ€\n\n\n\n\n\n\n\nÃœbungsaufgabe 3.8 (Peer Instruction: Wieder auf den Bus warten) Sie warten wieder auf den Bus, s. AbbildungÂ 3.30. Welche Aussage dazu ist falsch?\n\nDie Wahrscheinlichkeit, genau 5 Minuten zu warten, ist am hÃ¶chsten.\nDie Wahrscheinlichkeit, genau 10 Minuten zu warten, ist Null.\nMit 100% Wahrscheinlichkeit betrÃ¤gt die Wartezeit zwischen 0 und 10 Minuten.\nDie Wahrscheinlichkeit 1 Minute zu warten, betrÃ¤gt 10%.\nKeine der genannten. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#aufgaben",
    "href": "0300-Wskt.html#aufgaben",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.6 Aufgaben",
    "text": "3.6 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen.\n\n3.6.1 Paper-Pencil-Aufgaben\n\nprob-voll-esystem\nprob-disjunkt\nprob-disjunkt2\nprob-elementarereignis\nprob-vereinigung\nprob-ereignisraum\nprob-sicher-unmÃ¶glich\nindifferenz-p\n\n3.6.2 Aufgaben, fÃ¼r die man einen Computer braucht\n\npenguins-relationen\npenguins-relationen2\nverteilungsfunktion-penguins",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#literatur",
    "href": "0300-Wskt.html#literatur",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.7 Literatur",
    "text": "3.7 Literatur\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlieÃŸende Statistik: praxisorientierte EinfÃ¼hrung mit Aufgaben und LÃ¶sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik (7. Auflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of Modeling, Probability & Statistics. Springer.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHenze, N. (2019). Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der MaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability Theory: The Logic of Science. Cambridge University Press.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#footnotes",
    "href": "0300-Wskt.html#footnotes",
    "title": "\n3Â  Hallo, Wahrscheinlichkeit\n",
    "section": "",
    "text": "Die Wahrscheinlichkeitstheorie bildet zusammen mit der Statistik das Fachgebiet der Stochastik.â†©ï¸\n\\(10^6 = 1000000\\)â†©ï¸\nBeispiele fÃ¼r Zufallsexperimente das Messen eines UmweltphÃ¤nomens wie der Temperatur oder die Anzahl der Kunden, die einen Laden betreten. In jedem dieser FÃ¤lle sind die mÃ¶glichen Ergebnisse nicht im Voraus bekannt und hÃ¤ngen von nicht komplett bekannten Faktoren ab.â†©ï¸\n\\(A\\) ist eine Teilmenge von \\(B\\), wenn alle Elemente von \\(A\\) auch Teil von \\(B\\) sind.â†©ï¸\nSchon wieder.â†©ï¸\n?â†©ï¸\nEin Ergebnis ist ein Element von \\(\\Omega\\). Elementarereignisse sind die einelementigen Teilmengen von \\(\\Omega\\). Konzeptionell sind die beiden Begriffe sehr Ã¤hnlich, vgl. https://de.wikipedia.org/wiki/Ergebnis_(Stochastik). Wir werden uns hier auf den Begriff Elementarereignis konzentrieren und den Begriff Ergebnis nicht weiter verwenden.â†©ï¸\nNa toll.â†©ï¸\nDie Menge aller Teilmengen einer Menge \\(A\\) nennt man die Potenzmenge \\(\\mathcal{P}(A)\\), vgl. hier.â†©ï¸\nengl. disjointâ†©ï¸\nManchmal wird diese Art der Wahrscheinlichkeit auch epistemologische Wahrscheinlichkeit genannt.â†©ï¸\nhttps://www.geogebra.org/m/QZvCMSDsâ†©ï¸\nSynonym und kÃ¼rzer: \\(AB\\) anstelle von \\(A \\cap B\\).â†©ï¸\nsynonym: Komplementâ†©ï¸\nmanchmal auch \\(A^C\\); C wie complementary eventâ†©ï¸\ndas â€œKomplementâ€, nicht zu verwechseln mit â€œKomplimentâ€â†©ï¸\nda einfach und deutlichâ†©ï¸\nS wie Summeâ†©ï¸",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html",
    "href": "0350-wskt2.html",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "",
    "text": "4.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#lernsteuerung",
    "href": "0350-wskt2.html#lernsteuerung",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "",
    "text": "4.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n4.1.2 Ãœberblick\nDieses Kapitel stellt uns einige grundlegenden Rechengesetze fÃ¼r Wahrscheinlichkeiten vor: Wann man die Wahrscheinlichkeiten zweier Ereignisse addiert oder multipliziert. AuÃŸerdem lernen wir den Begriff der UnabhÃ¤ngkeit kennen.\n\n4.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erlÃ¤uternd definieren\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n4.1.4 Begleitliteratur\nLesen Sie zur Begleitung dieses Kapitels Bourier (2011), Kap. 2-4.\n\n4.1.5 PrÃ¼fungsrelevanter Stoff\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 2-4. Weitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verfÃ¼gbar sein. PrÃ¼fen Sie, ob Ihr Dozent Ihnen weitere Hilfen im geschÃ¼tzten Bereich (Moodle) eingestellt hat.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#Ã¼berblick-1",
    "href": "0350-wskt2.html#Ã¼berblick-1",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.2 Ãœberblick",
    "text": "4.2 Ãœberblick\nDie Rechenregeln der Wahrscheinlichkeit erlauben es, fÃ¼r bestimmte Situationen eine Wahrscheinlichkeit hzu berechnen. Das hÃ¶rt sich vielleicht wild an, ist aber oft ganz einfach.\n\nBeispiel 4.1 (Wahrscheinlichkeit fÃ¼r eine gerade Zahl beim WÃ¼rfelwurf) Ein (normaler) WÃ¼rfel wird geworfen. Was ist die Wahrscheinlichkeit fÃ¼r eine gerade Zahl, also fÃ¼r das Ereignis \\(A=\\{2, 4, 6\\}\\)? Diese Wahrscheinlichkeit betrÃ¤gt \\(Pr(\\text{gerade Zahl}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2\\). \\(\\square\\)\n\n\nBeispiel 4.2 (Gezinkter WÃ¼rfel) Ein gezinkter WÃ¼rfel hat eine erhÃ¶hte Wahrscheinlichkeit fÃ¼r das Ereignis \\(A=\\)â€œ6 liegt obenâ€, und zwar gelte \\(Pr(A)=1/3\\). Was ist die Wahrscheinlichkeit, keine 6 zu wÃ¼rfeln? \\(\\square\\)1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#additionssatz",
    "href": "0350-wskt2.html#additionssatz",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.3 Additionssatz",
    "text": "4.3 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse A und B eintritt. â€œMindestens eines der Ereignisse A undâ€ schreibt man \\(A \\cup B\\) und sagt â€œA vereinigt Bâ€.\n\n4.3.1 Addition disjunkter Ereignisse\nGegeben sei \\(\\Omega = {1,2,3,4,5,6}\\) beim normalen WÃ¼rfelwurf. Als Sinnbild: \\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\). Gesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\), das also eine 1 oder\neine 2 geworfen wird. Man beachte, dass die beiden Ergebnisse disjunkt sind, s. AbbildungÂ 3.6: Wenn man eine 1 wirft, hat man keine 2 geworfen.\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\nDie Wahrscheinlichkeit fÃ¼r \\(A\\) ist die Summe der Wahrscheinlichkeiten der einzelnen Ereignisse (1 und 2):\n\\(Pr(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\nDefinition 4.1 (Additionssatz fÃ¼r disjunkte Ereignisse) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt, ist die Summe der Einzelwahrscheinlichkeiten, s. TheoremÂ 4.1.\n\n\nTheorem 4.1 (Additionssatz fÃ¼r disjunkte Ereignisse) \\[Pr(A \\cup B) = P(A) + P(B) \\square\\]\n\n\nBeispiel 4.3 Was ist die Wahrscheinlichkeit, an einem Samstag oder Sonntag geboren zu sein? Unter der (vereinfachten) Annahme, dass alle Jahre zu gleichen Teilen aus allen Wochentagen bestehen und dass an allen Tagen gleich viele Babies geworden werden2, ist die Antwort \\(Pr(A)=1/7 + 1/7 = 2/7\\).\\(\\square\\)\n\n\n4.3.2 Addition allgemeiner Ereignisse\nUnter allgemeinen Ereignissen verstehen wir hier sowohl disjunkte als auch nicht disjunkte. Bei der Addition der Wahrscheinlichkeiten fÃ¼r \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) (der Ãœberlappungsbereich) doppelt erfasst â€“ sofern sie nicht disjunkt sind, aber wenn sie disjunkt sind, so ist der Schnitt gleich Null und wir machen auch dann nichts falsch. Der Ãœberlappungsbereich muss daher noch abgezogen werden, s. AbbildungÂ 4.1.\n\nDefinition 4.2 (Allgemeiner Additionssatz) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse \\(A\\) und \\(B\\) eintritt, ist gleich der Summe ihrer Wahrscheinlichkeiten minus ihrer gemeinsamen Wahrscheinlichkeit, s. TheoremÂ 4.2 und AbbildungÂ 4.1. \\(\\square\\)\n\n\nTheorem 4.2 (Allgemeiner Additionssatz) \\[Pr(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\square\\]\n\n\n\n\n\n\nAbbildungÂ 4.1: Der allgemeine Additionssatz gibt die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt.\n\n\n\n\n\n\n\n\n\nBeispiel 4.4 (Lernen und Klausur bestehen) In einem Psychologie-Studiengang sind die Studis verdonnert, zwei Statistik-Module (\\(S1, S2\\)) zu belegen. Die meisten bestehen (\\(B\\)), einige leider nicht (\\(N\\)), s. TabelleÂ 4.1.\nEreignis \\(S_1B\\) sei â€œKlausur Statistik 1 bestandenâ€ Ereignis \\(S_2B\\) ist analog fÃ¼r â€œKlausur Statistik 2â€.\nWir suchen die Wahrscheinlichkeit des Ereignisses A, d.h. mindestens eine der beiden Klausuren zu bestehen: \\(Pr(A) = Pr(S_1B \\cup S_2B)\\).\n\n\n\nTabelleÂ 4.1: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n\n\n.\nS1_B\nS1_NB\nSumme\n\n\n\nS2_B\n85\n9\n94\n\n\nS2_NB\n5\n1\n6\n\n\nSumme\n90\n10\n100\n\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(A) &= Pr(S_1B \\cup S_2B) \\\\\n&= Pr(S1_B) + Pr(S_2B) - Pr(S_1B \\cap S_2B)  \\\\\n&= (90 + 94 - 85) / 100 = 99 / 100\\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen liegt bei 99%.\n\nÃœbungsaufgabe 4.1 (Peer Instruction: Keine Klausur bestanden) Wie hoch ist die Wahrscheinlichkeit, keine der beiden Klausuren zu bestehen?\n\n1%\n5%\n6%\n9%\n10%\n16% \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#bedingte-wahrscheinlichkeit",
    "href": "0350-wskt2.html#bedingte-wahrscheinlichkeit",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.4 Bedingte Wahrscheinlichkeit",
    "text": "4.4 Bedingte Wahrscheinlichkeit\n\n4.4.1 Illustration zur bedingten Wahrscheinlichkeit\n\nDefinition 4.3 (Bedingte Wahrscheinlichkeit) Die bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit, dass \\(A\\) eintritt, gegeben dass \\(B\\) schon eingetreten ist. \\(\\square\\)\n\nMan schreibt: \\(Pr(A|B).\\) Lies: â€œA gegeben Bâ€ oder â€œA wenn Bâ€.\n\nÃœbungsaufgabe 4.2 Schauen Sie sich mal diese Animation von Victor Powell an zu bedingten Wahrscheinlichkeiten an. Sehenswert.\n\nAbbildungÂ 4.2 illustriert unbedingte Wahrscheinlichkeit, \\(Pr(A), Pr(B)\\), gemeinsame Wahrscheinlichkeit \\(Pr(A \\cap B)\\), und bedingte Wahrscheinlichkeit, \\(Pr(A|B)\\).\n\n\n\n\n\\(Pr(A)\\)\n\\(Pr(B)\\)\n\\(Pr(B|A)\\)\n\\(Pr(A \\cap B)\\)\n\n\n\n\n\n\n\n\n\n\n(a) Unbedingte Wahrscheinlichkeit fÃ¼r Ereignis A: 50%=1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Unbedingte Wahrscheinlichkeit fÃ¼r Ereignis B: 50%=1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Wahrscheinlichkeit fÃ¼r Ereignis B gegeben A, \\(Pr(B|A)=1/2\\)\n\n\n\n\n\n\n\\(Pr(A \\cap B)\\) wird auch hÃ¤ufig (synonym) geschrieben als \\(Pr(AB)\\).\n\n\n\n\n\n\n\n(d) Wahrscheinlichkeit fÃ¼r das gemeinsame Eintreten von A und B: \\(Pr(AB)=1/4\\)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.2: Illustration von unbedingter, gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\nBeispiel 4.5 (Bedingte Wahrscheinlichkeit) Sei \\(A\\) â€œSchÃ¶nes Wetterâ€ und \\(B\\) â€œKlausur steht anâ€. Dann meint \\(Pr(A|B)\\) die Wahrscheinlichkeit, dass das Wetter schÃ¶n ist, wenn gerade eine Klausur ansteht.\\(\\square\\)\n\n\nBeispiel 4.6 (Von PÃ¤psten und MÃ¤nnern) Man(n) beachte, dass die Wahrscheinlichkeit, Papst \\(P\\) zu sein, wenn man Mann \\(M\\) ist etwas anderes ist, als die Wahrscheinlichkeit, Mann zu sein, wenn man Papst ist: \\(Pr(P|M) \\ne Pr(M|P)\\). Das hÃ¶rt sich erst verwirrend an, aber wenn man darÃ¼ber nachdenkt, wird es plausibel.\\(\\square\\)\n\n\nBeispiel 4.7 Gustav GroÃŸ-GÃ¼tz verkauft eine Tinktur3, die schlau machen soll, â€œGÃ¼tzis Gehirn GrÃ¼tzeâ€.4 Gustav trinkt die GrÃ¼tze und sagt schlaue Dinge. Was schlieÃŸen wir daraus? Sei \\(H\\) (wie Hypothese) â€œGÃ¼tzis GrÃ¼tze macht schlauâ€; sei \\(D\\) (wie Daten) die Beobachtung, dass Gustav schlaue Dinge gesagt hat. Ohne exakte Zahlen zu suchen, wie hoch ist wohl \\(Pr(D|H)\\)? In Worten: â€œWie wahrscheinlich ist es, schlaue Dinge gesagt zu haben, wenn die GrÃ¼tze wirklich schlau macht?â€. Vermutlich ist diese Wahrscheinlichkeit sehr hoch. Aber wie hoch ist wohl \\(Pr(H|D)\\)? In Worten: â€œWie wahrscheinlich ist es, dass die GrÃ¼tze wirklich schlau macht, gegeben, dass wir gesehen hat, dass jemand etwas schlaues gesagt hat, nachdem er besagte GrÃ¼tze getrunken hat?â€ Skeptische Geister werden der Meinung sein, \\(Pr(H|D)\\) ist gering. Das Beispiel zeigt u.a. \\(Pr(H|D) \\ne Pr(D|H).\\square\\)\n\n\n4.4.2 Bedingte Wahrscheinlichkeit als Filtern einer Tabelle\n\nBetrachten wir TabelleÂ 4.2. Dort sind sind vier Tage aufgelistet, mit jeweils Regen (oder kein Regen) bzw. an denen es kalt ist (oder nicht). Filtern wir z.B. die Tabelle so, dass nur kalte Tage Ã¼brig bleiben, dann gibt der Anteil der Zeilen, die â€œRegenâ€ anzeigen, die bedingte Wahrscheinlichkeit \\(Pr(\\text{Regen}|\\text{kalt})\\) an.\n\n\n\nTabelleÂ 4.2: Die Tabelle zeigt vier Tage, an denen es jeweils kalt ist (oder nicht) bzw. regnet (oder nicht). Die bedingte Wahrscheinlichkeit \\(Pr(\\text{Regen}|\\text{kalt})\\) entspricht dem Anteil der Zeilen mit Regen, wenn fÃ¼r â€˜kaltâ€™ ein Filter in der Tabelle gesetzt ist.\n\n\n\n\n\n\n\n\n\n\nAlso: Das Berechnen einer bedingten Wahrscheinlichkeit, \\(Pr(A|B)\\), ist vergleichbar zum Filtern einer Tabelle, s. TabelleÂ 4.3.\n\n\n\nTabelleÂ 4.3: Eine bedingte Wahrscheinlichkeit kann man als gefilterte Tabelle verstehen\n\n\n\n\nid\nkalt\nRegen\n\n\n\n1\n0\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n1\n1\n\n\nSUMME\n2\n2\n\n\n\n\n\n\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(Pr(A) = 2/4; Pr(B) = 2/4; Pr(A \\cap B) = 1/4; Pr(A|B) = 1/2\\)\nDie Wahrscheinlichkeit fÃ¼r \\(A\\), wenn \\(B\\) schon eingetreten ist, berechnet sich so, s. TheoremÂ 4.3 und AbbildungÂ 4.2 (c).\n\nTheorem 4.3 (Bedingte Wahrscheinlichkeit) \\[Pr(A|B) = \\frac{Pr(A \\cap B)}{Pr(B)}\\]\nAuÃŸerdem gilt analog\n\\[Pr(B|A) = \\frac{Pr(B \\cap A)}{Pr(A)} \\quad \\square\\]\n\n\nBeispiel 4.8 (Lernen und Klausur bestehen) Sie bereiten sich gerade auf die Klausur bei Prof.Â SÃ¼ÃŸ vor. Das heiÃŸt: Sie Ã¼berlegen, ob Sie sich auf die Klausur vorbereiten sollten. Vielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr groÃŸ? Aber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen kÃ¶nnen, s. TabelleÂ 4.4. In der Tabelle sind die Daten von 100 Studis ausgewiesen. Ein Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die â€œLernerâ€. Ein anderer Teil hat nicht gelernt, \\(NL\\) bzw. \\(\\neg L\\). Ein Teil hat bestanden, \\(B\\), ein Teil nicht \\(NB\\) oder \\(\\neg B\\).\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: \\(Pr(B |\\neg L)\\).\n\n\n\nTabelleÂ 4.4: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n.\nL\nNL\nSumme\n\n\n\nB\n80\n1\n81\n\n\nNB\n5\n14\n19\n\n\nSumme\n85\n15\n100\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(B |\\neg L) &= \\frac{Pr(B \\cap \\neg L)}{Pr(\\neg L)} \\\\\n&=\\frac{1/100}{15/100} = 1/15 \\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat, liegt bei 1 von 15, also ca. 7%.5 \\(\\square\\)\n\n\nBeispiel 4.9 (Kalt und Regen) Die Wahrscheinlichkeit, dass es kalt ist, wenn es regnet, ist gleich der Wahrscheinlichkeit, dass es gleichzeitig kalt ist und regnet, geteilt durch die Wahrscheinlichkeit, dass es regnet.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#stochastische-un-abhÃ¤ngigkeit",
    "href": "0350-wskt2.html#stochastische-un-abhÃ¤ngigkeit",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.5 Stochastische (Un-)AbhÃ¤ngigkeit",
    "text": "4.5 Stochastische (Un-)AbhÃ¤ngigkeit\n\n4.5.1 UnabhÃ¤ngigkeit\nStochastische UnabhÃ¤ngigkeit ist ein Spezialfall von AbhÃ¤ngigkeit: Es gibt sehr viele AusprÃ¤gungen fÃ¼r AbhÃ¤ngigkeit, aber nur eine fÃ¼r UnabhÃ¤ngigkeit. KÃ¶nnen wir UnabhÃ¤ngigkeit nachweisen, haben wir also eine starke Aussage getÃ¤tigt.\n\nDefinition 4.4 (Stochastische UnabhÃ¤ngigkeit) Zwei Ereignisse sind (stochastisch) unabhÃ¤ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abhÃ¤ngt, ob \\(B\\) der Fall ist, s. TheoremÂ 4.4. Anders gesagt:6\n\n\n\nTheorem 4.4 (Stochastische UnabhÃ¤ngigkeit) \\[ Pr(A) = Pr(A|B) =Pr(A|\\neg B) \\square\\]\nIn Worten: Wenn die Wahrscheinlichkeit von A sich nicht Ã¤ndert, wenn B eingetreten ist, so ist A von B (stochastisch) unabhÃ¤ngig.\nDie UnabhÃ¤ngigkeit von \\(A\\) und \\(B\\) wird manchmal so in Kurzschreibweise ausgedrÃ¼ckt: \\(\\perp \\!\\!\\! \\perp(A, B) \\square\\).\n\n\nTheorem 4.5 (Stochastische UnabhÃ¤ngigkeit 2) Setzt man TheoremÂ 4.3 in TheoremÂ 4.4 (linke Seite) ein, so folgt7\n\\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B).\\quad \\square\\]\n\nIn Worten: Die Wahrscheinlichkeit, dass A und B beide der Fall sind, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten.\n\nBeispiel 4.10 (Augenfarbe und Statistikliebe) Ich vermute, dass die Ereignisse \\(A\\), â€œAugenfarbe ist blauâ€, und \\(B\\), â€œIch liebe Statistikâ€, voneinander unabhÃ¤ngig sind.\\(\\square\\)8\n\n\nBeispiel 4.11 (Ãœberleben auf der Titanic) S. AbbildungÂ 4.3, links: Ãœberleben (Ãœ) auf der Titanic ist offenbar abhÃ¤ngig von der Passagierklasse (\\(K_1, K_2, K_3\\)). In AbbildungÂ 4.3, links gilt also \\(Pr(Ãœ|K_1) \\ne Pr(Ãœ|K_2) \\ne Pr(Ãœ|K_3) \\ne Pr(Ãœ)\\).\nAuf der anderen Seite: Das Ereignis Ãœberleben (Ãœ) auf der Titanic ist unabhÃ¤ngig vom Ereignis Alter ist eine Primzahl (P), s. AbbildungÂ 4.3, rechts. Also: \\(Pr(Ãœ|P) = Pr(Ãœ|\\neg P) = Pr(Ãœ)\\), vgl. TabelleÂ 4.5.\n\n\n\nTabelleÂ 4.5: Kontingenztablle (HÃ¤ufigkeiten) fÃ¼r â€˜Ãœberleben auf der Titanicâ€™ und â€˜Alter ist Primzahlâ€™. Wie man sieht, gibt es keine stochastische AbhÃ¤ngigkeit.\n\n\n\n\n\n\nAge_prime\nn\nprop\n\n\n\n0\n\n\nnon-prime\n96\n0.17\n\n\nprime\n453\n0.83\n\n\n1\n\n\nnon-prime\n58\n0.17\n\n\nprime\n282\n0.83\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ãœberleben und Passagierklasse sind abhÃ¤ngig\n\n\n\n\n\n\n\n\n\n(b) Ãœberleben und â€˜Geburstag ist eine Primzahlâ€™ sind nicht abhÃ¤ngig\n\n\n\n\n\n\nAbbildungÂ 4.3: AbhÃ¤ngigkeit und UnabhÃ¤ngigkeit zweier Ereignisse\n\n\n\n4.5.2 Stochastische AbhÃ¤ngigkeit\nLiegt keine UnabhÃ¤ngigkeit vor, so spricht man von (stochastistischer) AbhÃ¤ngigkeit, s. TheoremÂ 4.6. In diesem Fall verÃ¤ndert sich unser Wissen Ã¼ber die Wahrscheinlichkeit von \\(A\\), wenn wir wissen, dass \\(B\\) eingetroffen ist, s. TheoremÂ 4.6.\n\nTheorem 4.6 (Stochastische AbhÃ¤ngigkeit) \\[Pr(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B) \\quad \\square\\]\nIn Worten: Ã„ndert sich die Wahrscheinlichkeit von A, wenn B der Fall ist, so sind A und B voneinander (stochastich) abhÃ¤ngig.\nTheoremÂ 4.6 gilt natÃ¼rlich in dieser Form fÃ¼r alle anderen Variablen ebenso, s. z.B. TheoremÂ 4.7. \\(\\square\\)\n\n\nTheorem 4.7 (Stochastische AbhÃ¤ngigkeit 2) \\[Pr(B|A) \\ne Pr(B) \\ne Pr(B|\\neg A) \\quad \\square\\]\n\n\nBeispiel 4.12 Die Ereignisse â€œLernenâ€ und â€œKlausur bestehenâ€ seien voneinander abhÃ¤ngig. Unsere EinschÃ¤tzung zur Wahrscheinlichkeit von K Ã¤ndert sich, wenn wir wissen, dass L vorliegt. Genauso wird sich unsere EinschÃ¤tzung zur Wahrscheinlichkeit von K Ã¤ndern, wenn wir wissen, dass L nicht vorliegt. \\(\\square\\)\n\n\nBeispiel 4.13 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land9 (\\(B\\)) voneinander abhÃ¤ngig (s. AbbildungÂ 4.4)?\n\n\n\n\n\n\n\n\n\n(a) Impfquote und Land sind voneinander abhÃ¤ngig\n\n\n\n\n\n\n\n\n\n(b) Anteil Corona-Tote und Land sind voneinander abhÃ¤ngig\n\n\n\n\n\n\nAbbildungÂ 4.4: Impfquote und Sterblichkeit sind voneinander abhÃ¤ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\nJa, die beiden Ereignisse sind abhÃ¤ngig, da in beiden Diagrammen gilt: \\(Pr(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\\(\\square\\)10\n\n\n4.5.3 UnabhÃ¤ngigkeit ist symmetrisch\nStochastische UnabhÃ¤ngigkeit ist symmetrisch: Wenn \\(A\\) unabhÃ¤ngig zu \\(B\\) ist auch \\(B\\) unabhÃ¤ngig zu \\(A\\), s. TheoremÂ 4.8.\n\nTheorem 4.8 (Symmetrie der UnabhÃ¤ngigkeit) \\[Pr(A|B) = Pr(A) \\leftrightarrow Pr(B|A) = Pr(B)\\]\nMan beachte, dass stochastische UnabhÃ¤ngigkeit und kausale UnabhÃ¤ngigkeit unterschiedliche Dinge sind (Henze, 2019): Stochastische UnabhÃ¤ngigkeit impliziert nicht kausale UnabhÃ¤ngigkeit. \\(\\square\\)\n\n\nÃœbungsaufgabe 4.3 (Peer Instruction: Welche Aussagen Ã¼ber stochastische UnabhÃ¤ngigkeit ist korrekt?) Â \n\nWenn X und Y unabhÃ¤ngig sind, dann hat X keinen Einfluss auf Y im Alltag.\n\nZwei Ereignisse A und B sind unabhÃ¤ngig, wenn sie sich nicht Ã¼berschneiden.\n\nWenn X und Y unkorreliert sind, dann sind sie unabhÃ¤ngig.\nWenn X und Y abhÃ¤ngig sind, dann kÃ¶nnen sie nicht gleichzeitig positive Korrelation haben.\n\nWenn X und Y unabhÃ¤ngig sind, sind sie auch unkorreliert.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#multiplikationssatz",
    "href": "0350-wskt2.html#multiplikationssatz",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.6 Multiplikationssatz",
    "text": "4.6 Multiplikationssatz\nGegeben seien die Ereignisse \\(A\\) und \\(B\\). Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass beide Ereignisse \\(A\\) und \\(B\\) der Fall sind; AbbildungÂ 4.2 (d) verdeutlicht dies fÃ¼r zwei unabhÃ¤ngige Ereignisse. Man schreibt â€œA und Bâ€ als \\(A \\cap B\\) (lies â€œA geschnitten Bâ€ oder â€œA und Bâ€) oder kurz \\(AB\\), um anzuzeigen, dass sowohl \\(A\\) als auch \\(B\\) eingetreten sind.\n\n\n\n\n\n\n\nBeide Ereignisse A und B sind eingetreten\n\n\n\n\nBeispiel 4.14 (Wieder kalt und Regen) Es ist eine Sache, zu fragen, wie wahrscheinlich ist ist, dass es kalt ist (bei KÃ¤lte), wenn es regnet (bei Regen): \\(Pr(K|R)\\). Anders gesagt: â€œWie groÃŸ ist die Wahrscheinlichkeit fÃ¼r KÃ¤lte, gegeben dass es regnet?â€ Eine andere Sache ist es, nach der Wahrscheinlichkeit zu fragen, dass es gleichzeitig kalt ist und regnet, dass also beide Ereignisse (kalt und Regen) eintreten: \\(Pr(K \\cap R), Pr(KR)\\). \\(\\square\\)\n\n\n4.6.1 Gemeinsame Wahrscheinlichkeit unabhÃ¤ngiger Ereignisse\n\nBeispiel 4.15 Wir fÃ¼hren das Zufallsexperiment â€œWurf einer fairen MÃ¼nzeâ€ zwei Mal aus (AbbildungÂ 4.5). Wie groÃŸ ist die Wahrscheinlichkeit, 2 Mal Kopf zu werfen? Dabei vereinbaren wir, dass â€œKopfâ€ als â€œTrefferâ€ zÃ¤hlt (und â€œZahlâ€ als â€œNieteâ€).\\(\\square\\)\n\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B1[T]\n    A --&gt; B2[N]\n\n    %% Zweiter Wurf\n    B1 --&gt; C1[TT]\n    B1 --&gt; C2[TN]\n    B2 --&gt; C3[NT]\n    B2 --&gt; C4[NN]\n\n\n\n\n\nAbbildungÂ 4.5: Wir werfen zwei faire MÃ¼nzen: Zweifach wiederholtes Zufallsexperiment\n\n\n\n\nAbbildungÂ 4.5 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis des Zufallexperiments. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom â€œStartâ€ (schwarzer Kreis) fÃ¼hren zwei mÃ¶gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch BlÃ¤tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen MÃ¼nzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der BlÃ¤tter. In diesen Diagramm gibt es vier Pfade (und BlÃ¤tter).\nDen Wurf der ersten MÃ¼nze nennen wir in gewohnter Manier \\(A\\); den Wurf der zweiten MÃ¼nze \\(B\\).\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in TabelleÂ 4.6.\n\n\n\nTabelleÂ 4.6: Wahrscheinlichkeiten der Ereignisse im zweimaligen MÃ¼nzwurf\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\n\n\n\nSei \\(K_1\\) das Ereignis, mit der 1. MÃ¼nze Kopf zu werfen; sei \\(K_2\\) das Ereignis, mit der 2. MÃ¼nze Kopf zu werfen.\nWir suchen \\(Pr(K_1 \\cap K_2)\\). Aufgrund der stochastischen UnabhÃ¤ngigkeit der beiden Ereignisse gilt: \\(Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)\\).\n\nCodePr_K1K2 &lt;- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n\n\n\nDefinition 4.5 (Multiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse) Die Wahrscheinlichkeit, dass zwei (oder mehr) unabhÃ¤ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. TheoremÂ 4.9. \\(\\square\\)\n\n\nTheorem 4.9 (Multiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B)\\]\nMan beachte, dass es egal ist, ob \\(A\\) gemeinsam mit \\(B\\) oder \\(B\\) gemeinsam mit \\(A\\) eintreten: \\(Pr(A \\cap B) = Pr(B \\cap A)\\). Man spricht in diesem Zusammenhang von der Symmetrie der Multiplikation. \\(\\square\\)\n\nMit dieser App kÃ¶nnen Sie das Baumdiagramm fÃ¼r den zweifachen MÃ¼nzwurf nÃ¤her erkunden.\nWir fÃ¼hren das Zufallsexperiment â€œWurf einer fairen MÃ¼nzeâ€ drei Mal aus (AbbildungÂ 4.6). Dabei vereinbaren wir wieder, dass â€œKopfâ€ (K) als â€œTrefferâ€ gilt und â€œZahlâ€ (Z) als â€œNieteâ€.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B1[T]\n    A --&gt; B2[N]\n\n    %% Zweiter Wurf\n    B1 --&gt; C1[TT]\n    B1 --&gt; C2[TN]\n    B2 --&gt; C3[NT]\n    B2 --&gt; C4[NN]\n\n    %% Dritter Wurf\n    C1 --&gt; D1[TTT]\n    C1 --&gt; D2[TTN]\n    C2 --&gt; D3[TNT]\n    C2 --&gt; D4[TNN]\n    C3 --&gt; D5[NTT]\n    C3 --&gt; D6[NTN]\n    C4 --&gt; D7[NNT]\n    C4 --&gt; D8[NNN]\n\n\n\n\nAbbildungÂ 4.6: Wir werfen drei faire MÃ¼nzen: Das dreifach wiederholte binÃ¤re Zufallexperiment\n\n\n\n\nBeim Wurf von â€œfairenâ€ MÃ¼nzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere EinschÃ¤tzung des Ergebnis des 2. Wurfes nicht verÃ¤ndert etc. Anders gesagt: Wir gehen von (stochastischer) UnabhÃ¤ngigkeit aus.\nFÃ¼r z.B. das Ereignis \\(A=\\{ZZZ\\}\\) gilt: \\(Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3\\). Da jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jedes Endknotens gleich.\nAllgemeiner gilt: FÃ¼r ein Zufallsexperiment, das aus \\(k\\) Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit \\(Pr(X)=p\\) ist, so ist die Wahrscheinlichkeit fÃ¼r einen Endkonten \\(Pr(X^k)=p^k\\).\n\n\n\nTabelleÂ 4.7: AusgewÃ¤hlte Wahrscheinlichkeiten von Ereignissen im dreifachen MÃ¼nzwurf\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n1K\n1/8 + 1/8 + 1/8 = 3/8\n\n\n2K\n3 * 1/8 = 3/8\n\n\n3K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n\n\n\n\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. TabelleÂ 4.7.\nAbbildungÂ 4.2 versinnbildlicht nicht nur die Bedingtheit zweier Ereignisse, sondern auch die (Un-)AbhÃ¤ngigkeit zweier Ereignisse, \\(A\\) und \\(B\\). In diesem Fall ist die Wahrscheinlichkeit von \\(A\\) gleich \\(B\\): \\(Pr(A)=Pr(B)=.5\\). Man sieht, dass die Wahrscheinlichkeit von \\(A\\) bzw. von \\(B\\) jeweils die HÃ¤lfte der FlÃ¤che (der GesamtflÃ¤che, d.h von \\(Pr(\\Omega)=1\\)) ausmacht. Die Schnittmenge der FlÃ¤che von \\(A\\) und \\(B\\) entspricht einem Viertel der FlÃ¤che: \\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.\\) In diesem Fall sind \\(A\\) und \\(B\\) unabhÃ¤ngig. AbbildungÂ 4.2 zeigt weiterhin, dass gilt: \\(Pr(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\). Man beachte, dass diese Formel nur bei UnabhÃ¤ngigkeit (von A und B) gilt.\n\n4.6.2 Gemeinsame Wahrscheinlichkeit allgemeiner Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung allgemeiner abhÃ¤ngiger Ereignisse an, s. AbbildungÂ 4.7.\n\nBeispiel 4.16 In einer Urne befinden sich fÃ¼nf Kugeln, von denen vier rot sind und eine blau ist.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nWie groÃŸ ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne ZurÃ¼cklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier, 2011), S. 47. Ereignis A: â€œKugel im 1. Zug hat die Farbe Rotâ€. Ereignis B: â€œKugel im 2. Zug hat die Farbe Rotâ€.\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. AbbildungÂ 4.7.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|4/5|B[Zug 1 - A]\n  A --&gt;|1/5|C[Zug 1 - nA]\n  B --&gt;|3/4|D[Zug 2 - B]\n  B --&gt;|1/4|E[Zug 2 -  nB]\n  D --- H[Fazit: AB - 4/5*3/4 = 12/20]\n  E --- I[Fazit: AnB - 4/5*1/4 = 4/20]\n  C --&gt;|4/4|F[Zug 2 - B]\n  C --&gt;|0/4|G[Zug 2 - nB]\n  F --- J[Fazit: nAB - 1/5*4/4 = 4/20]\n  G --- K[Fazit: nAnB - 1/5*0/4 = 0/20]\n  \n  \n\n\n\n\nAbbildungÂ 4.7: Baumdiagramm fÃ¼r ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abhÃ¤ngig ist vom 1. Zug.\n\n\n\n\nWie man in AbbildungÂ 4.7 nachrechnen kann gilt also: \\(Pr(A\\cap B) = P(A) \\cdot P(B|A) = 4/5 \\cdot 3/4 = 12/20 = 3/5 \\quad \\square\\)\n\n\nDefinition 4.6 (Gemeinsame Wahrscheinlichkeit) Die Wahrscheinlichkeit, dass zwei abhÃ¤ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt der Wahrscheinlichkeit von \\(A\\) und der bedingten Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\), s. TheoremÂ 4.10. \\(\\square\\)\n\n\nTheorem 4.10 (Gemeinsame Wahrscheinlichkeit) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B|A) \\quad \\square\\]\n\n\nBeispiel 4.17 (Kalt und Regen) Von McElreath (2020) stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit. Was ist die Wahrscheinlichkeit fÃ¼r das gemeinsame Auftreten von kalt â„ und Regen â›ˆï¸? Die Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von Regen â›ˆ, wennâ€™s kalt â„ ist mal die Wahrscheinlichkeit von KÃ¤lte â„.\nEbenfalls gilt: Die Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von KÃ¤lte â„, wennâ€™s regnet â›ˆï¸ mal die Wahrscheinlichkeit von Regen â›ˆï¸.\nDas Gesagte als Emoji-Gleichung ist in GleichungÂ 4.1 dargestellt.\n\\[Pr(â„ï¸ \\text{ und } â›ˆï¸) = P(â›ˆï¸ |â„ï¸ ) \\cdot P(â„ï¸) =  P(â„ï¸ |â›ˆï¸ ) \\cdot P(â›ˆï¸) \\tag{4.1}\\]\nMan kann die â€œGleichung drehenâ€11, s. GleichungÂ 4.2.\n\\[Pr(â„ï¸ \\text{ und } â›ˆï¸) = P(â›ˆï¸ \\text{ und } â„ï¸) \\tag{4.2}\\] \\(\\square\\)\n\n\nBeispiel 4.18 (Bertie Botts Bohnen jeder Geschmacksrichtung) Â \n\nSei bloÃŸ vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gewÃ¶hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.â€œ\n\nâ€” Ron Weasley zu Harry Potter12\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=2\\) furchtbar scheuÃŸliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erklÃ¤rt, \\(k=2\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt heiÃŸt es tapfer sein. Ziehen und runter damit!\nWie groÃŸ ist die Wahrscheinlichkeit, genau eine scheuÃŸliche Bohne zu erwischen?\nEs gibt 2 Pfade fÃ¼r 1 Treffer bei 2 Wiederholungen (ZÃ¼ge aus dem Beutel), s. AbbildungÂ 4.8: Man kann im ersten Zug eine scheuÃŸliche Bohne erwischen, aber nicht im zweiten Zug. Oder man man im zweiten Zug Pech haben (aber nicht im ersten). Die Summe der Wahrscheinlichkeiten beider Pfade ist die Wahrscheinlichkeit fÃ¼r genau eine scheuÃŸliche Bohne, das sind 19%.\n\n\n\n\n\ngraph LR\n    A[Start: 20 Bohnen] --&gt; B1[Bohne 1 gut = 18/20]\n    A --&gt; B2[Bohne 1 schlecht = 2/20]\n    \n    B1 --&gt; C1[Bohne 2 gut = 17/19]\n    B1 --&gt; C2[Bohne 2 schlecht = 2/19]\n    \n    B2 --&gt; C3[Bohne 2 gut = 18/19]\n    B2 --&gt; C4[Bohne 2 schlecht = 1/19]\n    \n    C1 --&gt; D1[Ergebnis: gut, gut]\n    C2 --&gt; D2[Ergebnis: gut, schlecht]\n    C3 --&gt; D3[Ergebnis: schlecht, gut]\n    C4 --&gt; D4[Ergebnis: schlecht, schlecht]\n\n\n\n\n\nAbbildungÂ 4.8: Baumdiagramm fÃ¼r ein ein zweistufiges Zufallsereignis: Bertie Botts Bohnen.\n\n\n\n\n\nCodePfad1 &lt;- 2/20 * 18/19  # scheuÃŸliche Bohne im 1. Zug\nPfad2 &lt;- 18/20 * 2/19  # scheuÃŸliche Bohne im 2. Zug\n\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 \nGesamt_Pr\n## [1] 0.19\n\n\nNutzen Sie diese App, um das auszuprobieren. Sie mÃ¼ssen in der App noch die Zahl der Bohnen (\\(n\\)) und die Zahl der scheuÃŸlichen Bohnen (\\(x\\)) einstellen.\\(\\square\\)\n\n\n4.6.3 Kettenregel\n\nDefinition 4.7 (Kettenregel) Allgemein gesagt, spricht man von der Kettenregel der Wahrscheinlichkeitsrechnung, wenn man die gemeinsame Wahrscheinlichkeit auf die bedingte zurÃ¼ckfÃ¼hrt, s. TheoremÂ 4.11. \\(\\square\\)\n\n\nTheorem 4.11 (Kettenregel) \\[Pr(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B) \\square\\]\nIn Worten: Die Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) ist gleich der Wahrscheinlichkeit von \\(A\\) mal der Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\).\n\n\nÃœbungsaufgabe 4.4 (Baumdiagramm sucht Problem) Ãœberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit dieser Baumdiagramm-App gelÃ¶st werden kann.\\(\\square\\)\n\n\nÃœbungsaufgabe 4.5 (Peer Instruction: Dreifacher MÃ¼nzwurf) FÃ¼nf Studierende unterhalten sich, wie man einen dreifachen MÃ¼nzwurf verstehen kann mit dem Ergebnis von drei Treffern. Welcher Studierende liegt falsch? Gehen Sie von einer faire MÃ¼nze aus und UnabhÃ¤ngigkeit der WÃ¼rfe.\n\nWirft man die MÃ¼nze drei Mal, so gibt es 6 Ergebnisse, die alle gleich wahrscheinlich sind. Aber nur ein Ergebnis ist gesucht, nÃ¤mlich 3 von 3 Treffern. Also ist die Wahrscheinlichkeit 1/6, ca. 17%.\nMan kann einfach einen Computer fragen, z.B. R mit dbinom(x = 3, size = 3, prob = 1/2), da kommt ungefÃ¤hr 12% raus.\nWirft man die MÃ¼nze drei Mal, so gibt es 8 Ergebnisse, die alle gleich wahrscheinlich sind. Aber nur ein Ergebnis ist gesucht, nÃ¤mlich 3 von 3 Treffern. Also ist die Wahrscheinlichkeit 1/8, ca. 12,5%.\nWer rechnen kann, ist klar im Vorteil \\(\\left( \\frac{1}{2} \\right)^3 = \\left( \\frac{1}{2^3} \\right) = \\left( \\frac{1}{8} \\right)\\)\n\nHolt mich hier raus! \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#totale-wahrscheinlichkeit",
    "href": "0350-wskt2.html#totale-wahrscheinlichkeit",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.7 Totale Wahrscheinlichkeit",
    "text": "4.7 Totale Wahrscheinlichkeit\n\nBeispiel 4.19 (Gesamter Ausschussanteil) Die folgende Aufgabe bezieht sich auf Bourier (2011), S. 56. Drei Maschinen (\\(M_1, M_2, M_3\\)) produzieren einen Artikel. Die Maschinen haben einen Anteil an der Produktion von 60, 10 bzw. 30% und eine Ausschussquote von 5,2 bzw. 4%. Sei \\(M\\) das Ereignis, dass ein Artikel von Maschine \\(M\\) stammt, und \\(S\\) (Schrott) das Ereignis, dass ein Artikel Ausschuss (Schrott) ist. Gesucht ist ist der Ausschussanteil insgesamt (Ã¼ber alle drei Maschinen). Anders gesagt: Wie hoch ist die Wahrscheinlichkeit \\(Pr(S')\\), dass ein zufÃ¤llig gezogener Artikel Ausschuss ist? AbbildungÂ 4.9 zeigt das Baumdiagramm fÃ¼r die Aufgabe. \\(\\square\\)\n\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[M1]\n  A --&gt;|0.1|C[M2]\n  A --&gt;|0.3|D[M3]\n  B --&gt;|0.05|E[S]\n  B -.-&gt;|0.95|F[Nicht-S]\n  C --&gt;|0.02|G[S]\n  C -.-&gt;|0.98|H[Nicht-S]\n  D --&gt;|0.04|I[S]\n  D -.-&gt;|0.96|J[Nicht-S]\n\n\n\n\nAbbildungÂ 4.9: Totale Wahrscheinlichkeit\n\n\n\n\nDie Anteile an der Produktion und vom Ausschluss sind in AbbildungÂ 4.10 verdeutlicht.\n\nCodesource(\"R-code/plot_maschine_schrott.R\")\nplot_maschine_schrott\n\n\n\n\n\n\nAbbildungÂ 4.10: Anteile von Produktion und Ausschuss\n\n\n\n\nDazu addieren wir die Wahrscheinlichkeiten der relevanten Ã„ste. Jeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse \\(M_i\\) und \\(S\\) dar.\n\nCodeW_Ast1 &lt;- 0.6 * 0.05  # Wahrscheinlichkeit fÃ¼r Ast 1\nW_Ast2 &lt;- 0.1 * 0.02  # ... Ast 2\nW_Ast3 &lt;- 0.3 * 0.04  # ... Ast 3\nW_total &lt;- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n\n\nDie totale Wahrscheinlichkeit (fÃ¼r Ausschuss) betrÃ¤gt in diesem Beispiel also \\(Pr(B') = 0.044 = 4.4\\%\\).13\n\nDefinition 4.8 (Totale Wahrscheinlichkeit) Bilden die Ereignisse \\(M_1, M_2, ..., M_n\\) ein vollstÃ¤ndiges Ereignissystem und ist \\(S\\) ein beliebiges Ereignis dann gilt TheoremÂ 4.12. \\(\\square\\)\n\n\nTheorem 4.12 (Totale Wahrscheinlichkeit) \\[Pr(S') = \\sum_{i=1}^n Pr(M_i) \\cdot Pr(S|M_i).\\square\\]\n\nIn Worten: Die totale Wahrscheinlichkeit ist die Summe der gewichteten Teil-Wahrscheinlichkeiten.\n\nIn AbbildungÂ 4.9 (BeispielÂ 4.19) gilt \\(Pr(S') = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot  0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square\\)\n\n\nÃœbungsaufgabe 4.6 (Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2) Es ist die gleich Aufgabe wie BeispielÂ 4.18, aber jetzt lautet die Frage: Wie groÃŸ ist die Wahrscheinlichkeit, mindestens eine scheuÃŸliche Bohne bei 3 ZÃ¼gen zu erwischen?14 \\(\\square\\)\n\n\n4.7.1 Baumsammlung\nBaumdiagramme sind ein hilfreiches Werkzeug fÃ¼r wiederholte Zufallsexperimente. Daher ist hier eine â€œBaumsammlungâ€15 zusammengestellt.\n\nSie werfen 1 MÃ¼nze, AbbildungÂ 3.2.\nSie werfen 2 MÃ¼nzen, AbbildungÂ 4.5.\nSie werfen 3 MÃ¼nzen, AbbildungÂ 4.6.\nSie werfen 4 MÃ¼nzen, AbbildungÂ 3.20.\nSie werfen 9 MÃ¼nzen, ğŸ¤¯ AbbildungÂ 6.7.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#vertiefung",
    "href": "0350-wskt2.html#vertiefung",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.8 Vertiefung",
    "text": "4.8 Vertiefung\nBei Henze (2019) findet sich eine anspruchsvollere EinfÃ¼hrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes der Kapitel 2 und 3 von Henze (2019).\nMit dieser App, die ein zweistufiges Baumdiagramm zeigt, kÃ¶nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\nDiese App lÃ¤sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\nMittag & SchÃ¼ller (2020) stellen in Kap. 11 die Grundlagen der Wahrscheinlichkeitstheorie vor. Ã„hnliche Darstellungen finden sich in einer groÃŸen Zahl an LehrbÃ¼chern.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#aufgaben",
    "href": "0350-wskt2.html#aufgaben",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.9 Aufgaben",
    "text": "4.9 Aufgaben\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\n4.9.1 Paper-Pencil-Aufgaben\n\nAdditionssatz1\nNerd-gelockert\nUrne1\nUrne2\nk-coins-k-hits\nsicherheit\nsicherheit2\nKlausuren-bestehen\nGem-Wskt1\nGem-Wskt2\nGem-Wskt3\nGem-Wskt4\nwuerfel05\nwuerfel06\nBed-Wskt1\nBed-Wskt2\nBed-Wskt3\nvoll-normal\ncorona-blutgruppe\ntotale-Wskt1\nwskt-quiz14\nwskt-quiz09\nprob-vereinigung\nbestehen_ohne_lernen\n\n4.9.2 Aufgaben, fÃ¼r die man einen Computer braucht\n\nmtcars-abhaengig\nmtcars-abhaengig-var2\nmtcars-abhaengig_var3a\nwskt-df-r",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#section",
    "href": "0350-wskt2.html#section",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.10 â€”",
    "text": "4.10 â€”\n\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlieÃŸende Statistik: praxisorientierte EinfÃ¼hrung mit Aufgaben und LÃ¶sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik (7. Auflage). Springer Gabler.\n\n\nHenze, N. (2019). Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der MaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#footnotes",
    "href": "0350-wskt2.html#footnotes",
    "title": "\n4Â  Rechnen mit Wahrscheinlichkeiten\n",
    "section": "",
    "text": "Die Wahrscheinlichkeit, keine 6 zu wÃ¼rfeln, liegt bei \\(2/3\\).â†©ï¸\nvermutlich gibt es noch mehr Annahmen, die wir uns explizit machen sollten.â†©ï¸\ngenauer besehen sieht sie eher aus wie eine GrÃ¼tze oder ein Breiâ†©ï¸\nSie schmeckt scheuÃŸlich.â†©ï¸\n\\(Pr(L).85; Pr(\\neg L) = .15; Pr(B) =.81; Pr(\\neg B) = .19\\)â†©ï¸\nExakte Gleichheit ist in dieser Welt empirisch schwer zu finden. Daher kann man vereinbaren, dass UnabhÃ¤ngigkeit erfÃ¼llt ist, wenn die Gleichheit â€œeinigermaÃŸenâ€ oder â€œziemlichâ€ gilt, die Gleichheit gewissermaÃŸen â€œpraktisch bedeutsamâ€ ist.â†©ï¸\nVgl. TheoremÂ 4.9â†©ï¸\nWer Daten dazu hat oder eine Theorie, der melde sich bitte bei mir.â†©ï¸\nhier mit den zwei AusprÃ¤gungen DEU und USAâ†©ï¸\n Daten von Our World in Data, https://ourworldindata.org/covid-deaths.â†©ï¸\nDer Multiplikationssatz ist symmetrischâ†©ï¸\nQuelle: https://harrypotter.fandom.com/de/wiki/Bertie_Botts_Bohnen_jeder_Geschmacksrichtungâ†©ï¸\nEinfacher als das Rechnen mit Wahrscheinlichkeiten ist es in solchen FÃ¤llen, wenn man anstelle von Wahrscheinlichkeiten absolute HÃ¤ufigkeiten zum Rechnen verwendet.â†©ï¸\nDie Wahrscheinlichkeit keine scheuÃŸliche Bohne zu ziehen ist \\(17/20 \\cdot 16/19 \\cdot 15/18) \\approx 0.6\\). Daher ist die gesuchte Wahrscheinlichkeit (mindestens eine scheuÃŸliche Bohne) das Komplement davon: \\(0.4\\).â†©ï¸\nWald?â†©ï¸",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html",
    "href": "0400-Verteilungen.html",
    "title": "\n5Â  Verteilungen\n",
    "section": "",
    "text": "5.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#lernsteuerung",
    "href": "0400-Verteilungen.html#lernsteuerung",
    "title": "\n5Â  Verteilungen\n",
    "section": "",
    "text": "5.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n5.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nden Begriff der Zufallsvariablen erlÃ¤utern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erlÃ¤utern\nden Begriff einer Gleichverteilung erlÃ¤utern\nden Begriff einer Binomialverteilung erlÃ¤utern\nBen Begriff einer halben Normalverteilung erlÃ¤utern\nden Begriff einer Exponentialverteilung erlÃ¤utern\nzentrale Konzepte in R umsetzen\n\n5.1.3 Begleitliteratur\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 6.1 und 6.3 sowie 7.1 und und 7.2.\n\n5.1.4 Vorbereitung im Eigenstudium\nDieses Kapitel setzt einige Grundbegriffe voraus, wie im Buch Statistik1 vorgestellt, insbesondere im Kapitel â€œRahmenâ€. BenÃ¶tigt wird auch der Begriff der Normalverteilung sowie der Begriff der Quantile.\nLesen Sie selbstÃ¤ndig, zusÃ¤tzlich zum Stoff dieses Kapitels, noch in Bourier (2011) folgende Abschnitte:\n\n\n\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung)\nKap. 7.2.3 (Normalverteilung)\n\nLÃ¶sen Sie auch die Ãœbungsaufgaben dazu.\nWeitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n5.1.5 PrÃ¼fungsrelevanter Stoff\nBeachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff prÃ¼fungsrelevant ist.\n\n5.1.6 BenÃ¶tigte R-Pakete\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)  # fÃ¼r Plots\n\n\n\n5.1.7 Zentrale Begriffe\n\n5.1.7.1 Eigenschaften von Zufallsvariablen\n\nZufallsvariable (random variable)\nDiskret vs.Â stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n5.1.7.2 Verteilungen\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n5.1.8 Begleitvideos\n\nÃœberblick zu Verteilungen\nGleichverteilung\nBinomialverteilung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#wichtige-verteilungen",
    "href": "0400-Verteilungen.html#wichtige-verteilungen",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.2 Wichtige Verteilungen",
    "text": "5.2 Wichtige Verteilungen\nIm Folgenden sind einige wichtige Verteilungen aufgefÃ¼hrt, die in diesem Skript (und in der Statistik und Wahrscheinlichkeitstheorie) eine zentrale Rolle spielen.\nğŸ“º Einstieg in Verteilungen",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#gleichverteilung",
    "href": "0400-Verteilungen.html#gleichverteilung",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.3 Gleichverteilung",
    "text": "5.3 Gleichverteilung\n\n5.3.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jede AusprÃ¤gung der zugehÃ¶rigen Zufallsvariablen gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine bestimmte AusprÃ¤gung einer Zufallsvariablen fÃ¼r plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. AbbildungÂ 5.1 zeigt ein Beispiel fÃ¼r eine (stetige) Gleichverteilung.\n\n\n\n\n\n\n\n\n\n(a) Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2\n\n\n\n\n\n\n\n\n\n(b) Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3\n\n\n\n\n\n\nAbbildungÂ 5.1: Stetige Gleichverteilung; man beachte jeweils die Y-Achse\n\n\nAbbildungÂ 5.1, (a): Bei \\(X=0\\) hat eine Einheit von \\(X\\) (z.B. von -1 bis 0) die Wahrscheinlichkeitsmasse von 50%, da der Bereich \\([-1, 0]\\) die HÃ¤lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte identisch. AbbildungÂ 5.1, (b): Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von ca. 33%, da der Bereich \\([0, 1]\\) ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte identisch Definierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#sec-bin-distrib",
    "href": "0400-Verteilungen.html#sec-bin-distrib",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.4 Binomialverteilung",
    "text": "5.4 Binomialverteilung\n\n5.4.1 Grundlagen\n\nDefinition 5.1 (Binomialverteilung) Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines \\(n\\)-fach wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei1 Ergebnissen bzw. Elementarereignissen also. Dabei interessiert uns nur die Anzahl der \\(k\\) Treffer, aber nicht die Reihenfolge. Bei jeder Wiederholung liegt die Wahrscheinlichkeit eines Treffers bei \\(p\\). bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die MÃ¼nze verÃ¤ndert sich nicht durch die WÃ¼rfe (Ziehen mit ZurÃ¼cklegen, ZmZ). AuÃŸerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc., sog. â€œiidâ€: independent and identically distributed.] \\(\\square\\)\n\n\\[\\overbrace{X}^{\\text{Unsere Zufallsvariable}} \\underbrace{\\sim}_{\\text{ist verteilt nach der}} \\underbrace{\\overbrace{\\text{Bin}(n, p)}^{\\text{Binomialverteilung}}}_{\\text{mit den Parametern n, p}} \\tag{5.1}\\]\n\nFÃ¼r eine binomialverteilte Zufallsvariable \\(X\\) schreibt man kurz wie in TheoremÂ 5.1 gezeigt.\n\nTheorem 5.1 (Notation fÃ¼r eine binomialverteilte Zufallsvariable) \\[X \\sim \\text{Bin}(n, k) \\quad \\square\\]\n\n\nBeispiel 5.1 Anwendungsbeispiele: Wie viele defekte Teile sind in einer Stichprobe von produzierten Schrauben zu erwarten? Wie wahrscheinlich ist es, dass das neue Blutdruck-Medikament einer bestimmten Anzahl von Menschen hilft? Wie viele Personen stimmen in einer Umfrage der Frage â€œIch halte die Ã¶ffentlich-rechtlichen Sender fÃ¼r wichtig.â€ zu? Was ist die Wahrscheinlichkeit, 6 mal hintereinander eine 6 zu wÃ¼rfeln bei einem fairen WÃ¼rfel? Eine MÃ¼nze, die in 7 von 10 WÃ¼rfen â€œKopfâ€ zeigt â€“ sollte sie als â€œunfairâ€ eingeschÃ¤tzt werden? \\(\\square\\)\n\nStellen wir uns eine Kistchen2 mit sehr vielen3 Losen vor, darunter 2/5 Treffer (Gewinn) und 3/5 Nieten, s. Abb. AbbildungÂ 5.2. Der Versuch lÃ¤uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zurÃ¼ck und ziehen erneut. Da sehr viele Lose im KÃ¤stchen liegen, ist es praktisch egal, ob wir das Los wieder zurÃ¼cklegen. Die Wahrscheinlichkeit fÃ¼r einen Treffer Ã¤ndert sich (so gut wie) nicht. Jetzt ziehen wir z.B. drei Lose. Wie groÃŸ ist die Wahrscheinlichkeit, davon 2 Treffer zu erzielen (egal in welcher Reihenfolge)?\n\n\n\n\n\n\n\nAbbildungÂ 5.2: Ein LoskÃ¤stchen mit 2/5 Treffer und 3/5 Nieten\n\n\n\n\nPraktischerweise ist die Binomialverteilung in R eingebaut,\nhier ist Pseudocode fÃ¼r Ihre Anwendung, s. ListingÂ 5.1.\n\n\n\nListingÂ 5.1: R-Pseudocode fÃ¼r die Binomialverteilung\n\nCodedbinom(x = &lt;Anzahl der Treffer&gt;, \n       size = &lt;Anzahl der WÃ¼rfe&gt;, \n       prob = &lt;Wahrscheinlichkeit eines Treffers&gt;)\n\n\n\n\n\n\n5.4.2 MÃ¶glichkeiten zÃ¤hlen\n\nBeispiel 5.2 (Drei Lose gekauft, davon zwei Treffer?) Wie groÃŸ ist die Wahrscheinlichkeit \\(p\\) bei \\(n=3\\) ZÃ¼gen \\(k=2\\) Treffer zu erzielen (und \\(n-k=1\\) Niete)? (Nennen wir dieses gesuchte Ereignis der KÃ¼rze halber \\(A^{\\prime}\\)). Die Trefferwahrscheinlichkeit ist (bei jedem Zug) \\(p=2/5\\) und die Nietenwahrscheinlichkeit \\(1-p=3/5 \\quad \\square\\), s. AbbildungÂ 5.3. AbbildungÂ 4.6 zeigt den entsprechenden Baum; TabelleÂ 5.1 zeigt die Ergebnisse dieses Zufallsexperiments.\n\n\n\n\n\n\n\n\nAbbildungÂ 5.3: Wie viele MÃ¶glichkeiten gibt es, 3 Lose zu sortieren, von denen 2 Treffer sind und 1 Niete?\n\n\n\n\n\n\nTabelleÂ 5.1: Alle acht Ergebnisse des Zufallsexperiment (binÃ¤r, 3-fach wiederholt) mit ihren Wahrscheinlichkeiten im Ãœberblick\n\n\n\n\n\n\n\n\nPfad (Ereignis)\nAnzahl Treffer\nWahrscheinlichkeit\n\n\n\nTTT\n3\n\\(p^3 = \\left(\\tfrac{2}{5}\\right)^3 = \\tfrac{8}{125} \\approx 0.064\\)\n\n\nTTN\n2\n\\(p^2 q = \\tfrac{4}{25}\\cdot\\tfrac{3}{5} = \\tfrac{12}{125} \\approx 0.096\\)\n\n\nTNT\n2\n\\(p^2 q = \\tfrac{12}{125} \\approx 0.096\\)\n\n\nNTT\n2\n\\(p^2 q = \\tfrac{12}{125} \\approx 0.096\\)\n\n\nTNN\n1\n\\(p q^2 = \\tfrac{2}{5}\\cdot\\tfrac{9}{25} = \\tfrac{18}{125} \\approx 0.144\\)\n\n\nNTN\n1\n\\(p q^2 = \\tfrac{18}{125} \\approx 0.144\\)\n\n\nNNT\n1\n\\(p q^2 = \\tfrac{18}{125} \\approx 0.144\\)\n\n\nNNN\n0\n\\(q^3 = \\left(\\tfrac{3}{5}\\right)^3 = \\tfrac{27}{125} \\approx 0.216\\)\n\n\n\n\n\n\nMit Blick auf BeispielÂ 5.2: Wir kÃ¶nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz, TheoremÂ 4.9), vgl. AbbildungÂ 4.6. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit (Additionssatz, TheoremÂ 4.1). Diagramme zeichnen ist einfach, dauert aber.\nBeachtet man die verschiedenen Reihenfolgen nicht, so zÃ¤hlt man 3 gÃ¼nstige Pfade (T: Treffer; N: Niete), s. AbbildungÂ 4.6:\n\nTTN\nTNT\nNTT.\n\nWir haben also die MÃ¶glichkeiten (2 Treffer und 1 Niete zu erhalten)\n\n\nohne Beachtung der Reihenfolge und\n\nohne ZurÃ¼cklegen (der MÃ¶glichkeiten)\n\ngezÃ¤hlt.\nSchneller geht es, wenn man rechnet. Wir kÃ¶nnten auch R auffordern, die Anzahl der gÃ¼nstigen Pfade zu berechnen, s. TheoremÂ 5.3 mit choose(3,2), was die Antwort 3 liefert.\n\n5.4.3 Anzahl Pfade mal Pfad-Wahrscheinlichkeit\nIn diesem Fall ist die Wahrscheinlichkeit eines (gÃ¼nstigen) Pfades, \\(A\\):\n\\(Pr(A) = Pr(T)^2 \\cdot Pr(N)^1 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right)^1 \\approx 0.096\\).\n\nCodep_a = (2/5)^2 * (3/5)^1\np_a\n## [1] 0.096\n\n\nDamit ist die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 3 ZÃ¼gen) gleich der Anzahl der gÃ¼nstigen \\(k\\) Pfade (3) mal der Wahrscheinlichkeit eines Pfades (0.1):\n\\(Pr(A^{\\prime}) = k \\cdot Pr(A) = 3 \\cdot 0.096 = 0.29\\).\n\nCodep_a_strich = 3 * p_a\np_a_strich\n## [1] 0.29\n\n\nDie Wahrscheinlichkeit, bei 3 ZÃ¼gen 2 Treffer zu erzielen, betrÃ¤gt also ca. 29%.\nDabei steht \\(k\\) fÃ¼r die Anzahl der gÃ¼nstigen Pfade und \\(Pr(A)\\) fÃ¼r die Wahrscheinlichkeit eines gÃ¼nstigen Pfades (d.h. 2 Treffer und 1 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\n\n5.4.4 Formel der Binomialverteilung\nTheoremÂ 5.2 zeigt die mathematische Definition der Binomialverteilung. Dabei liegt immer ein Zufallsversuch mit \\(n\\) DurchgÃ¤ngen und \\(k\\) Treffern zugrunde. Jeder Durchgang hat die Trefferwahrscheinlichkeit \\(p\\) und jeder Durchgang ist unabhÃ¤ngig von allen anderen.\n\nTheorem 5.2 (Binomialverteilung) \\[Pr(X=k|p,n) = \\frac{n}{k!(n-k)!}p^k(1-p)^{n-k}\\quad \\square\\]\n\nTheoremÂ 5.2 kann wie folgt auf Deutsch Ã¼bersetzen:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis \\(X\\) gegeben \\(p\\) und \\(n\\) berechnet als Produkt von zwei Termen. Der erste Term ist der Quotient von der FakultÃ¤t von n im ZÃ¤hler und im Nenner das Produkt von erstens der FakultÃ¤t von k mit zweitens der FakultÃ¤t von (n-k). Der zweite Term ist das Produkt von p hoch k mal der komplementÃ¤ren Wahrscheinlichkeit von p hoch (n-k).\n\nOder noch kÃ¼rzer:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œXâ€ gegeben p und k berechnet als Produkt von zwei Termen. Erstens der Anzahl der gÃ¼nstigen Pfade, k und zweitens der Wahrscheinlichkeit fÃ¼r einen gÃ¼nstigen Pfad, P(A).\n\nDie Anzahl der (gÃ¼nstigen) Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt, s. TheoremÂ 5.3.4\n\nDefinition 5.2 (Binomialkoeffizient) Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von \\(n\\) verschiedenen Objekten \\(k\\) Objekte ziehen kann (ohne ZurÃ¼cklegen und ohne Beachtung der Reihenfolge). \\(\\square\\)\n\n\nTheorem 5.3 (Binomialkoeffizient) \\[\\tbinom{n}{k}= \\frac{n!}{k!(n-k)!} \\quad \\square\\]\nLies: â€œWÃ¤hle aus \\(n\\) mÃ¶glichen Ereignissen (Pfade im Baum) \\(k\\) gÃ¼nstige Ereignisse (gÃ¼nstige Pfade) oder kÃ¼rzerâ€k aus nâ€.\n\nUm den Binomialkoeffizient zu berechnen, muss man die FakultÃ¤t berechnen. Die FakultÃ¤t ist eine Rechenvorschrift fÃ¼r natÃ¼rliche Zahlen. Man schreibt sie mit einem Ausrufezeichen hinter der Zahl, also zum Beispiel \\(3!\\). Dabei multipliziert man alle natÃ¼rlichen Zahlen von der gegebenen Zahl bis hinunter zur 1.\n\nBeispiel 5.3 Â \n\n\\(3! = 3 \\cdot 2 \\cdot 1\\)\n\\(4! = 4 \\cdot 3 \\cdot 2 \\cdot 1\\)\n\n\\(0! = 1\\) (per Definition) \\(\\square\\)\n\n\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange Ãœbersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und fÃ¼r uns ausrechnen.\n\nBeispiel 5.4 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?5\n\nCode# Wskt fÃ¼r genau 15 Treffer bei 20 Versuchen mit einer fairen MÃ¼nze:\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.015\n\n\nDie Wahrscheinlichkeit liegt bei ca 1%.\nUm hÃ¶chstens 15 Treffer zu erzielen, mÃ¼ssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern aufsummieren.\nPraktischerweise gibt es einen R-Befehl, der das Aufsummieren fÃ¼r uns Ã¼bernimmt: pbinom.\n\nCodepbinom(q = 15, size = 20, prob = .5)\n## [1] 0.99\n\n\nDie Wahrscheinlichkeit hÃ¶chstens 15 Treffer (d.h. 0, 1, 2, â€¦ 15 Treffer) zu erzielen, liegt fÃ¼r prob = .5 laut Binomialverteilung mit pbinom bei gut 99%.\n\n\nBeispiel 5.5 (3 MÃ¼nzwÃ¼rfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen, s. AbbildungÂ 5.4, links?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\nCodedbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.12\n\n\nDie LÃ¶sung lautet also \\(p=1/8 = .125.\\qquad \\square\\)\nMan kann sich auch vor Augen fÃ¼hren, dass es genau 1 gÃ¼nstigen Pfad gibt, nÃ¤mlich TTT. Nach dem Multiplikationssatz gilt also: \\(Pr(X=3) = 1 \\cdot \\left( \\frac{1}{2} \\right)^3 = \\frac{1}{8} = .125\\).\n\nCodeloesung &lt;- (1/2)^3\nloesung\n## [1] 0.125\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) n=3, p=1/2\n\n\n\n\n\n\n\n\n\n(b) n=9, p=.7\n\n\n\n\n\n\nAbbildungÂ 5.4: Verschiedene Binomialverteilungen\n\n\n\nÃœbungsaufgabe 5.1 ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear?\n\n\nÃœbungsaufgabe 5.2 Was ist die Wahrscheinlichkeit fÃ¼r 0, 1, 2, â€¦, 9 Treffern bei 9 WÃ¼rfen, wenn die Trefferwahrscheinlichkeit 70% betrÃ¤gt? AbbildungÂ 5.4, rechts, zeigt die Antwort.\n\n\n5.4.5 Rechnen mit der Binomialverteilung\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen: z.B. dbinom(x = 2, size = 3, prob = 2/5). Das ist komfortabler als selber rechnen. Mit diesem Befehl rechnet R aus, wie hoch die Wahrscheinlichkeit ist, bei size = 3 â€œMÃ¼nzwÃ¼rfenâ€, x = 2 Treffer zu erzielen, wobei die Trefferwahrscheinlichkeit jeweils prob = 2/5 betrÃ¤gt.\n\nBeispiel 5.6 (Lotto) Wie viele Zahlenkombinationen gibt es im Lotto fÃ¼r 6 Richtige? Der Binomialkoeffizient verrÃ¤t es uns: \\(\\tbinom{49}{6}= 13\\,983\\,816\\square\\) Ander gesagt: Der Binomialkoeffizient sagt uns, wie viele MÃ¶glichkeiten es gibt, aus z.B. 46 BÃ¤llen 6 zu ziehen (ohne Beachtung der Reihenfolge und ohne ZurÃ¼cklegen). \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeispiel 5.7 Wie viele MÃ¶glichkeiten gibt es, 2 Treffer bei 4 ZÃ¼gen zu erzielen?\nDas sind folgende Ergebnisse: 1. TTNN, 2. TNTN, 3. TNNT, 4. NTTN, 5. NTNT, 6. NNTT.\n\\(\\tbinom{4}{2} = \\frac{4!}{2! \\cdot (4-2)!} \\overset{\\text{kÃ¼rzen}}= \\frac{2\\cdot 3}{1}=6\\)\nEs sind also 6 MÃ¶glichkeiten.\n\nIn R kann man sich die FakultÃ¤t mit dem Befehl factorial ausrechnen lassen. Der R-Befehl choose berechnet den Binomialkoeffizienten.6\n\nCodeanzahl_pfade_2_aus_4 &lt;- \n  factorial(4) / (factorial(2) * factorial(4-2))\nanzahl_pfade_2_aus_4\n## [1] 6\n\nchoose(4, 2)\n## [1] 6\n\n\n\\(\\square\\)\n\nBeispiel 5.8 Hier sind die 10 Kombinationen, um aus 5 Losen genau 2 Treffer und 3 Nieten zu ziehen:\nTTNNN, TNTNN, TNNTN, TNNNT, NTTNN, NTNTN, NTNNT, NNTTN, NNTNT, NNNTT\n\nCodechoose(5, 2)\n## [1] 10\n\nanzahl_pfade_2_aus_5 &lt;- \n  factorial(5) / (factorial(2) * factorial(5-2))\nanzahl_pfade_2_aus_5\n## [1] 10\n\n\n\\(\\square\\)\n\n\nBeispiel 5.9 (BefÃ¶rderung) Aus einem Team mit 25 Personen sollen 11 Personen befÃ¶rdert werden. Wie viele mÃ¶gliche Kombinationen (von befÃ¶rderten Personen) kÃ¶nnen gebildet werden?\n\\(\\tbinom{25}{11} = \\frac{25!}{11!\\cdot(25-11)!} = 4\\,457\\,400\\)\n\nCodechoose(n = 25, k = 11)\n## [1] 4457400\n\n\nEs gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht berÃ¼cksichtigt.\\(\\square\\)\n\n\n5.4.6 Pumpstation-Beispiel zur Binomialverteilung\nIn einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% fÃ¤llt ein Motor aus und ist fÃ¼r den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie groÃŸ ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb fÃ¤llt?\n\\(Pr(X=k)\\) (oder kurz: \\(Pr(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an fÃ¼r das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(Pr(X=5)\\) ausrechnen.\n\nCodedbinom(x = 5, size = 7, prob = .95)\n## [1] 0.041\n\n\nEs gilt also \\(Pr(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist demnach relativ gering â€“ wobei â€œgeringâ€ subjektiv ist, die Betreiberfirma findet diese Wahrscheinlichkeit, dass 2 Pumpen ausfallen, wohl viel zu hoch. Die Wahrscheinlichkeit, dass \\(k=0 \\ldots 7\\) Motoren laufen, ist in AbbildungÂ 5.5 dargestellt.\ndbinom() steht fÃ¼r die Wahrscheinlichkeitsdichte (im diskreten Fall, wie hier, Wahrscheinlichkeitsfunktion genannt) und binom fÃ¼r die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die StichprobengrÃ¶ÃŸe an (hier 7 Motoren).\nDamit gilt:\n\\(Pr(X\\ge 5) = Pr(X=5) + Pr(X=6) + Pr(X=7)\\)\nBerechnen wir zunÃ¤chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen mit Hilfe der Binomialverteilung.\n\nCodep_5 &lt;- dbinom(x = 5, size = 7, prob = .95)\np_6 &lt;- dbinom(x = 6, size = 7, prob = .95)\np_7 &lt;- dbinom(x = 7, size = 7, prob = .95)\n\np_5\n## [1] 0.041\np_6\n## [1] 0.26\np_7\n## [1] 0.7\n\n\nDas sind 0.04, 0.26, 0.7. Die gesuchte Wahrscheinlichkeit, p_mind_5, ist die Summe der drei Einzelwahrscheinlichkeiten.\n\nCodep_mind_5 &lt;- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 1\n\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betrÃ¤gt also 1.\nDas komplementÃ¤re Ereignis zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also hÃ¶chstens 4 und es daher zu einem Ausfall kommt. Es gilt also \\(Pr(\\bar{X}) = 1- Pr(X)\\).\n\nCodep_weniger_als_4 &lt;- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.0038\n\n\nDas sind also 0 also0.38 % Wahrscheinlichkeit, dass die Pumpstation ausfÃ¤llt.\n\n\n\n\n\n\n\nAbbildungÂ 5.5: Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen\n\n\n\n\nAlternativ kann man mit der Verteilungsfunktion pbinom() rechnen, die \\(Pr(X \\le 4)\\) berechnet.\nIn R kann man die Funktion pbinom() nutzen (p fÃ¼r (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen.\n\nCodepbinom(q = 4, size = 7, prob = .95)\n## [1] 0.0038\n\n\nq = 4 steht fÃ¼r \\(X \\le 4\\), also fÃ¼r hÃ¶chstens 4 Treffer (arbeitende Motoren); size = 7 meint die StichprobengrÃ¶ÃŸe, hier 7 Motoren; prob gibt die Trefferwahrscheinlichkeit an. \\(\\square\\)\n\nÃœbungsaufgabe 5.3 (Peer-Instruction: QualitÃ¤tskontrolle in einer Fabrik) Eine Fabrik produziert USB-Sticks. Die Wahrscheinlichkeit, dass ein USB-Stick defekt ist, betrÃ¤gt 2%. Aus der laufenden Produktion werden regelmÃ¤ÃŸig 10 USB-Sticks zufÃ¤llig ausgewÃ¤hlt und getestet. Sei \\(X\\) die Anzahl defekter USB-Sticks in dieser Stichprobe.\nWelche Aussage ist richtig bzw. passt am besten?\n\nMit 98% sind alle 10 USB-Sticks in Ordnung.\nMit 82% sind alle 10 USB-Sticks in Ordnung.\nMit 2% sind alle 10 USB-Sticks defekt.\nEs ist unmÃ¶glich, dass alle 10 USB-Sticks defekt sind.\nEs ist unmÃ¶glihc, dass alle 10 USB-Sticks in Ordnung sind. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#die-halbe-normalverteilung",
    "href": "0400-Verteilungen.html#die-halbe-normalverteilung",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.5 Die halbe Normalverteilung",
    "text": "5.5 Die halbe Normalverteilung\nGrundlagen Ã¼ber die Normalverteilung kÃ¶nnen in Sauer (2025) nachgelesen werden.\nEin Spezialfall der Normalverteilung ist die halbe (oder halbseitige) Normalverteilung, s. AbbildungÂ 5.6.\n\nCodedf &lt;- data.frame(x = seq(-4, 4, length.out = 500))\ndf$y &lt;- dnorm(df$x)\n\n# Separate shading regions\ndf_left  &lt;- subset(df, x &lt;= 0) \ndf_right &lt;- subset(df, x &gt;= 0)\n\nggplot(df, aes(x, y)) +\n  geom_area(data = df_left, aes(x, y), fill = \"grey90\") +\n  geom_area(data = df_right, aes(x, y), fill = \"grey80\") +\n  #geom_line(size = 1) +\n  theme_minimal() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.text.y  = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line.y  = element_blank()\n  ) +\n  scale_x_continuous(limits = c(0, 4))\n\n\n\n\n\n\nAbbildungÂ 5.6: Die halbe Normalverteilung\n\n\n\n\n\nDefinition 5.3 (Halbe Normalverteilung) Wenn man die (negativen) Vorzeichen bei den Werten der Normalverteilung ignoriert, erhÃ¤lt man die halbe Normalverteilung. Man â€œspiegeltâ€ die negative Seite auf die positive. \\(\\square\\)\n\nMan kann sie verwenden, wenn man von normalverteilten Werten ausgeht, die grÃ¶ÃŸer als Null sein mÃ¼ssen. Sie hat zwei Parameter, Mittelwert und SD, analog zur Normalverteilung.\n\nBeispiel 5.10 (Halbe Normalverteilungen) Â \n\nDie Entfernung Ihres Dart-Pfeiles zur Mitte der Zielscheibe\nDie Entfernung des vom Baum gefallenen Apfels zum Stamm\nDie Abweichung des Gewichts eines Produktionsgegenstands (z.B. einer Schraube) vom Soll-Gewicht\nDie Reaktionszeiten einer Versuchsperson in einer Reaktionszeitaufgabe \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#die-exponentialverteilung",
    "href": "0400-Verteilungen.html#die-exponentialverteilung",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.6 Die Exponentialverteilung",
    "text": "5.6 Die Exponentialverteilung\n\n5.6.1 Die Apfel-fÃ¤llt-nicht-weit-vom-Stamm-Verteilung\n\n\n\nAnstelle der halben Normalverteilung man auch die Exponentialverteilung verwenden. Die beiden Verteilungen haben einen Ã¤hnlichen Verlauf, nur dass bei Exponentialverteilung Extremwerte wahrscheinlicher sind. Das kann vorteilhaft sein, wenn man ein PhÃ¤nomen darstellen will, dessen Skalierung man nicht genau kennt. Die Normalverteilung setzt dem Streuung der Werte deutlich engere Grenzen als die Exponentialverteilung. AbbildungÂ 5.7 stellt die beiden Verteilungen nebeneinander.\n\n\n\n\n\n\n\nAbbildungÂ 5.7: Exponentialverteilung (blau, Rate = 1) vs.Â halbe Normalverteilung (sd = 1)\n\n\n\n\nFÃ¼r eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung. Sie hat einige nÃ¼tzliche Eigenschaften:\n\nEine Exponentialverteilung ist nur fÃ¼r positive Werte, \\(x&gt;0\\), definiert.\nSteigt X um eine Einheit, so Ã¤ndert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (â€œlambdaâ€).\n\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (â€œGestrecktheitâ€) der Verteilung an.\nJe grÃ¶ÃŸer die Rate \\(\\lambda\\), desto schneller der â€œVerfallâ€ der Kurve und desto kleiner die Streuung und der Mittelwert der Verteilung (und umgekehrt: Je grÃ¶ÃŸer \\(1/\\lambda\\), desto grÃ¶ÃŸer die Streuung und der Mittelwert der Verteilung.)\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren PlÃ¤nen passt.\n\n5.6.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zurÃ¼ckzufÃ¼hren, s. AbbildungÂ 5.8.\n\n\n\n\nlambda = 2\nlambda = 1\nlambda = 1/2\nlambda = 1/4\nlambda = 1/8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.8\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEine â€œgut passendeâ€ oder gar die â€œrichtigeâ€ Verteilung zu finden, ist nicht immer einfach, wenn nicht unmÃ¶glich. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu wÃ¤hlen, die einen breiteren Raum an mÃ¶glichen Werten zulÃ¤sst. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie etwa mehrere Kilometer KÃ¶rpergrÃ¶ÃŸe, besser verbieten.\n\n\nMan kann sich den Median und andere Quantile der Exponentialverteilung mit qexp ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, fÃ¼r den man das Quantil haben mÃ¶chte, z.B. p = .5 fÃ¼r den Mediaan (mit pexp() kann man sich analog die die Verteilungsfunktion ausgeben lassen.) Mit rate wird \\(\\lambda\\) (lambda) bezeichnet.7\nDieser Aufruf zum Beispiel, qexp(p = .5, rate = 1/8), gibt uns das 50%-Quantil einer Exponentialverteilung mit Rate (\\(\\lambda\\)) 1/8 zurÃ¼ck, ca. 5.5: Mit einer Wahrscheinlichkeit von 50% wird ein Wert von 5.5 nicht Ã¼berschritten bei dieser Verteilung.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich auch ausgeben.\n\nCodeqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2 29.5\n\n\nTabelle ?tbl-exp zeigt die Mediane einiger Exponentialverteilungen, d.h. Exponentialverteilungen mit verschiedenen Werten fÃ¼r \\(\\lambda\\).\n\nDie Median-Werte von Exponentialverteilungen mit verschiedenen Werten fÃ¼r \\(\\lambda\\).\n\nÎ»\nMedian\n\n\n\n100\n0.01\n\n\n50\n0.01\n\n\n8\n0.09\n\n\n4\n0.17\n\n\n2\n0.35\n\n\n1\n0.69\n\n\n1/2\n1.39\n\n\n1/4\n2.77\n\n\n1/8\n5.55\n\n\n1/50\n34.66\n\n\n1/100\n69.31",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#vertiefung",
    "href": "0400-Verteilungen.html#vertiefung",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.7 Vertiefung",
    "text": "5.7 Vertiefung\nBourier (2011), Kap. 6.2 und 7.1 erlÃ¤utert einige (grundlegende) theoretische HintergrÃ¼nde zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar fÃ¼r den Stoff dieses Kapitels ist dabei die Binomialverteilung.\nMittag & SchÃ¼ller (2020) stellen in Kap. 12 und 13 Zufallsvariablen vor; zum Teil geht die Darstellung dort Ã¼ber die Lernziele bzw. Inhalte dieses Kurses hinaus.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#aufgaben",
    "href": "0400-Verteilungen.html#aufgaben",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\nZusÃ¤tzlich zu den Aufgaben in der genannten Literatur sind folgende Aufgaben zu empfehlen.\n\n5.8.1 Paper-Pencil-Aufgaben\n\nalphafehler-inflation3\nalphafehler-inflation4\niq1a\niq2a\niq3a\nsimu-uniform\nsimu-unif2\nsimu-unif3\nQuiz zum Thema Verteilungen\nBsp-Binomial\ndistros\nbfi10\nwskt-quiz10\nSchiefe1\nexp-tab\nexp1\nsmall-wide-normal\nlikelihood-nv\nschmalstepost\n\n5.8.2 Aufgaben, fÃ¼r die man einen Computer braucht\n\nalphafehler-inflation2\nQuiz (Aufgabensammlung) zu Verteilungen\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\niq01\niq02\niq03\niq04\niq05\niq06\niq07\n\niq08  \n\nBus1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#section",
    "href": "0400-Verteilungen.html#section",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.9 â€”",
    "text": "5.9 â€”\n\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlieÃŸende Statistik: praxisorientierte EinfÃ¼hrung mit Aufgaben und LÃ¶sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik (7. Auflage). Springer Gabler.\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nSauer, S. (2025). Statistik1. Independently published via Amazon. https://www.amazon.de/Statistik1-Einf%C3%BChrung-Statistik-Schwerpunkt-Prognose-Modellierung/dp/B0F673WGG5",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#footnotes",
    "href": "0400-Verteilungen.html#footnotes",
    "title": "\n5Â  Verteilungen\n",
    "section": "",
    "text": "von lat. bis â€œzweimalâ€â†©ï¸\nIn den LehrbÃ¼chern hÃ¤ufig als Urne bezeichnet, was den bÃ¶sen Spott von â€œFriedhofstatistikâ€ nach sich zog.â†©ï¸\npraktisch unendlich vielenâ†©ï¸\nwobei gelten muss \\(n \\ge k\\)â†©ï¸\nHey, endlich mal was fÃ¼r echte Leben!â†©ï¸\nBei Taschenrechnern ist diese Funktion oft als â€œnCrâ€ zu finden.â†©ï¸\nEs gibt auch [Online-Apps, die diese Werte ausgeben](https://homepage.divms.uiowa.edu/~mbognar/applets/exp-like.html.â†©ï¸",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html",
    "href": "0500-Globusversuch.html",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "",
    "text": "6.1 Lernsteuerung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#lernsteuerung",
    "href": "0500-Globusversuch.html#lernsteuerung",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "",
    "text": "6.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n6.1.2 Ãœberblick\nIn diesem Kapitel Ã¼bersetzen wir eine Problemstellung (Forschungsfrage) in ein (mathematisches) Modell, das uns dann mit Hilfe der Bayes-Formel Antworten auf die Problemstellung gibt.\n\n6.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nUnterschiede zwischen Modellen und der RealitÃ¤t erlÃ¤utern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (fÃ¼r binomial verteilte Zufallsvariablen)\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\ndas Bayes-Modell anhand bekannter Formeln herleiten\nPost-Wahrscheinlichkeiten anhand der Bayesbox berechnen\n\n6.1.4 Begleitliteratur\nDer Stoff dieses Kapitels deckt einen Teil aus McElreath (2020), Kap. 2, ab. McElreath (2020) stellt das Globusmodell mit mehr ErlÃ¤uterung und etwas mehr theoretischem Hintergrund vor, als es in diesem Kapitel der Fall ist.\n\n6.1.5 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. â€œDaten Einlesenâ€\n\n6.1.6 Begleitvideos\n\nğŸ“º Globusversuch\n\n\n6.1.7 BenÃ¶tigte R-Pakete\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)  # komfortable Visualisierung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#von-welten-und-golems",
    "href": "0500-Globusversuch.html#von-welten-und-golems",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.2 Von Welten und Golems",
    "text": "6.2 Von Welten und Golems\n\n6.2.1 Kleine Welt, groÃŸe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb AbbildungÂ 6.1.\n\n\n\n\n\nAbbildungÂ 6.1: Behaims Globus: Kein Amerika\n\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der groÃŸen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die groÃŸe Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.\n\nğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht! \\(\\square\\)\n\n\n6.2.2 Der Golem von Prag\n\n\n\n\n\nAbbildungÂ 6.2: Der Golem von Prag\n\n\nBildquelle: MikolÃ¡Å¡ AleÅ¡, Wikimedia, Gemeinfrei\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt, s. AbbildungÂ 6.2. Die Geschichte besagt, dass ein Rabbi mit ZauberkrÃ¤ften den Golem aus Lehm erschuf, um die jÃ¼dische BevÃ¶lkerung der Stadt zu schÃ¤tzen. Bei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen. Bei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.\n\n6.2.3 Wissenschaftliche Modelle sind wie Golems\n\n\nâ€œYeah, ich bin ein Golem!â€ - Bildquelle: Klara Schaumann\n\n\n\nGolem\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch â€œWahrheitâ€\nMÃ¤chtig\ndumm\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nMÃ¤rchen\n\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mÃ¤chtig\nsimpler als die RealitÃ¤t\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nNicht einmal falsch\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildungÂ 2.7 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen (TabelleÂ 6.1), wie z.B. Behaims Globus, mit der GroÃŸen Welt, die Kolumbus und wir befahren.\n\n\nTabelleÂ 6.1: Kleine Welt vs.Â groÃŸe Welt\n\n\n\n\n\n\n\nKleine Welt\nGroÃŸe Welt\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit\nentspricht nicht (zwangslÃ¤ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n6.2.4 Die Bayes-Formel und Lernen\nğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!\\(\\square\\)\n\nBeispiel 6.1 (Ein Regressionsmodell ist aus der kleinen Welt) Ein wissenschaftliches Modell, etwa auf Basis eines Regressionsmodell ist Teil der kleinen Welt. Man muss sich bei der Interpretation eines Regressionsmodell vor Augen halten: â€œDie Ergebnisse des Modell sind nur richtig unter der Annahme, dass sich der Zusammenhang X und Y durch eine Gerade beschreiben lasssen und unter der Annahme, dass meine Daten in Ordnung sind.â€ \\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "6.3 Ein erster Versuch: Wir werfen den Globus\n\n6.3.1 Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?\n\nBeispiel 6.2 (Wasseranteil auf der ErdoberflÃ¤che) Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (AbbildungÂ 6.3)? Um mÃ¶glichst wenig schreiben zu mÃ¼ssen, schreiben wir fÃ¼r â€œangenommener Wasseranteil auf der ErdoberflÃ¤cheâ€ kurz \\(p\\) oder \\(\\pi\\) (p wie proportion, Anteil). \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 6.3: Die Erde. SchÃ¶n! Und mit viel Wasser, ca. 70% der ErdoberflÃ¤che sind mit Wasser bedeckt. Quelle, Lizenz: CC 4.0 BY-NC\n\n\nAnalog kÃ¶nnen wir uns vorstellen, 11 Wissenschaftler haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus â€¦ die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.2\nSo sah mein3 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nAlso \\(W=6\\) (Wasser, d.h. â€œTrefferâ€) und \\(L=3\\) (Land) (\\(n=9\\) Versuche).\n\nÃœbungsaufgabe 6.1 (Spin the Globe) ğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!\\(\\square\\)\n\n\n6.3.2 Bayes-Updates\nDer Bayes-Golem denkt eigentlich ganz vernÃ¼nftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugehÃ¶rige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung (s. DefinitionÂ 6.1). In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als nÃ¤chstes beschaut sich der Golem die Daten und Ã¼berlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 50% betrÃ¤gt. Die zugehÃ¶rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die4 Likelihood5, s. DefinitionÂ 6.2. Als letztes bildet sich der Golem eine abschlieÃŸende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung, s. DefinitionÂ 6.3. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder â€œgeupdatetâ€, s. AbbildungÂ 6.4.\n\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]--&gt;B[Likelihood]--&gt;C[Post-Vert.]--&gt;A\n\n\n\n\nAbbildungÂ 6.4: Updating mit Bayes\n\n\n\n\n\nDefinition 6.1 (Priori-Verteilung) FÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: Priori-Verteilung (synonym: Apriori-Verteilung).\\(\\square\\)\n\n\nDefinition 6.2 (Likelihood) FÃ¼r jede Hypothese (d.h. jeden Parameterwert \\(\\pi\\)) mÃ¶chten wir wissen, wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Kurz: Wir suchen die Likelihood. Anders gesagt: Die Likelihood sagt uns, wie gut die Daten zu einer bestimmten Hypothese passen.\\(\\square\\)\n\n\nDefinition 6.3 (Posteriori-Verteilung) Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung6 bekommen.\\(\\square\\)\n\n\nÃœbungsaufgabe 6.2 (Wie gut passen die Daten zur Hypothese, dass die Erde komplett trocken ist?) Wir haben in unseren Versuch \\(W=6\\) und \\(L=3\\) erzielt. Diese Daten passen Ã¼berhaupt nicht zur Hypothese, dass die ErdoberflÃ¤che komplett trocken ist. Die Likelihood, \\(L\\) fÃ¼r \\(\\pi=0\\) ist also Null. Analog ist die Likelihood fÃ¼r \\(\\pi=1\\) auch Null.\\(\\square\\)\n\n\n6.3.3 Was ist die Wahrscheinlichkeit von 6 mal Wasser bei 9 WÃ¼rfen?\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer (bei 9 WÃ¼rfen) zu erhalten, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 90%) annimmt? Diese Wahrscheinlichkeit nennt man die Likelihood, \\(L\\).\n\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert 7. Der Wasseranteil der Erde bleibt wÃ¤hrend des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser \\(\\pi\\) betrÃ¤gt, so bezeichnen: \\(Pr(W|\\pi, n)\\). Diese Wahrscheinlichkeit kann man im Fall des Globusversuchs mit der Binomialverteilung berechnen.\nMÃ¶chte man die Wahrscheinlichkeit ansprechen fÃ¼r das Ereignis â€œ6 mal Wasser und 3 mal Land, wenn wir von einem Wasseranteil von 70% ausgehenâ€, so wÃ¼rden wir kurz schreiben: \\(Pr(W=6 | \\pi=.7, n=9)\\).\nZur Erinnerung: Die Binomialverteilung zeigt die Verteilung der Wahrscheinlichkeit der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten): â€œMÃ¼nzwurfverteilungâ€, s. Kap. Kapitel 5.4.\n\n6.3.4 Likelihood berechnen\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (d.h. die Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(n=W+L=3\\) WÃ¼rfen zu bekommen, wenn wir von \\(\\pi=1/2\\) ausgehen? 8, s. ListingÂ 6.1, AbbildungÂ 6.5 und GleichungÂ 6.1.\n\n\n\nListingÂ 6.1: Binomialverteilung mit R fÃ¼r x=2, n=3, p=1/2\n\nCodeloesung &lt;- dbinom(x = 2, size = 3, prob = 1/2)\nloesung\n## [1] 0.38\n\n\n\n\n\nOder von Hand gerechnet:\n\\[\\begin{aligned}\nPr(W=2 | \\pi=1/2, n=3) &=\\\\\n\\tbinom{3}{2} \\cdot (1/2)^2 \\cdot (1/2)^1 &=\\\\\n\\frac{3!}{2!1!} \\cdot (1/2)^3 &= \\\\\n3 \\cdot 1/8 = 3/8 &= 0.375\n\\end{aligned} \\tag{6.1}\\]\nWenn man sich den entsprechenden Baum anschaut (s. AbbildungÂ 6.5): Von den 8 Endkonten bzw. Pfaden sind 3 gÃ¼nstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 WÃ¼rfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-&gt; B[B - 0]\n  A -. 1/2 .-&gt; C[C - 1]\n  B -. 1/2 .-&gt; D[D - 0]\n  B -. 1/2 .-&gt; E[E - 1]\n  C -. 1/2 .-&gt; F[F - 0]\n  C -. 1/2 .-&gt; G[G - 1]\n  D -. 1/2 .-&gt; H[H - 0]\n  D -. 1/2 .-&gt; J[I - 1]\n  E -. 1/2 .-&gt; K[K - 0]\n  E -. 1/2 .-&gt; L[L - 1]\n  F -. 1/2 .-&gt; M[M - 0]\n  F -. 1/2 .-&gt; N[N - 1]\n  G -. 1/2 .-&gt; O[O - 0]\n  G -. 1/2 .-&gt; P[P - 1]\n\n\n\n\nAbbildungÂ 6.5: Wir werfen den Globus (oder eine MÃ¼nze) 3 Mal. Die Knoten sind der Ãœbersicht halber mit fortlaufenden Buchstaben (von A bis P) bezeichnet. Das Ergebnis â€˜Wasserâ€™ ist 1 und das Ergebnis â€˜Landâ€™ mit 0 abgekÃ¼rzt dargestellt.\n\n\n\n\nAbb. AbbildungÂ 6.5 stellt einen einfachen Baum fÃ¼r 3 GlobuswÃ¼rfe mit je zwei mÃ¶glichen Ereignissen (W vs.Â L) dar. In der ersten (obersten) Zeile (Knoten A; â€œStartâ€) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) mÃ¶gliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nFÃ¼r mehr WÃ¼rfe wÃ¼rde das Diagramm irgendwann unÃ¼bersichtlich werden.\nAbbildungÂ 6.6 zeigt die Binomialverteilung \\(X \\sim Bin(n=9, \\pi = 1/2)\\): Die jeweilige Wahrscheinlichkeit fÃ¼r \\(k=0,1,\\ldots, 9\\) Treffer bei \\(n=9\\) Versuchen mit Trefferwahrscheinlichkeit \\(\\pi=1/2\\).\n\n\n\n\n\n\n\nAbbildungÂ 6.6: Ein Beispiel fÃ¼r eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\n\n\n\nAbb AbbildungÂ 6.7 ist ein vergeblicher Versuch, so einen groÃŸen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum VerstÃ¤ndnis, kommen aber bei grÃ¶ÃŸeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.7: Wir werfen den Globus (oder eine MÃ¼nze) 9 Mal, es resultieren 512 Endknoten. Nicht gerade Ã¼bersichtlich.\n\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 6.3 (Globus mit 6 Treffern bei 9 WÃ¼rfen, p=1/2) Was ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\nCodedbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.16\n\n\nOder, synonym, wenn man einen Taschenrechner (oder R als Taschenrechner) benutzt:\n\nCodechoose(9, 6) * (1/2)^6 * (1/2)^3\n## [1] 0.16\n\n\n\\(\\square\\)\n\n\nBeispiel 6.4 (Globus mit 9 Treffern bei 9 WÃ¼rfen, p=1/2) Was ist die Wahrscheinlichkeit, gegeben \\(W=9\\) bei \\(n=9\\) und \\(\\pi=1/2\\)?\n\nCodedbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.002\n\n\nDas ist 1 gÃ¼nstiger Pfad von 512 Pfaden, also \\(Pr(W=9|\\pi=1/2, n=9)=1/512\\).\n\n\nBeispiel 6.5 (Globus mit 6 Treffern bei 9 WÃ¼rfen, p=70%) Was ist die Wahrscheinlichkeit fÃ¼r \\(W=6\\), gegeben \\(n=9\\) und \\(p=.7\\)?\n\nCodedbinom(x = 6, size = 9, prob = .7)\n## [1] 0.27\n\n\nMit Taschenrechner gerechnet:\n\nCodeanz_pfade &lt;- choose(9,6) \nwskt_pro_pfad &lt;- (.7)^6 * (.3)^3\ngesamt_wkst &lt;- anz_pfade * wskt_pro_pfad\ngesamt_wkst\n## [1] 0.27\n\n\n(Fast) von Hand gerechnet, mit R als Taschenrechner:\n\nCodefactorial(9)/(factorial(6)*factorial(3)) * (.7)^6 * (.3)^3\n## [1] 0.27\n\n\nAls Formel, s. GleichungÂ 6.2:\n\\[\\begin{aligned}\nPr(W=6 | \\pi=.7, n=9) &=\\\\\n\\tbinom{9}{6} \\cdot (.7)^6 \\cdot (.3)^3 &=\\\\\n\\frac{9!}{6!3!} \\cdot (.7)^6 \\cdot (.3)^3 &=\\\\\n84 \\cdot  .003 = .27.\n\\end{aligned} \\tag{6.2}\\]\n\\(\\square\\)\n\nZur Erinnerung: Die Funktion dbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zurÃ¼ck, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\nEs gibt Taschenrechner(-Apps), die die Binomialverteilung oder den Binomialkoeffizienten berechnen kÃ¶nnen.9\n\nÃœbungsaufgabe 6.3 (Peer Instruction: Welche Anzahl von Wasser ist am plausibelsten?) Wir fÃ¼hren wieder den Globusversuch durch (\\(\\pi=.7\\)), mit 9 WÃ¼rfen. Welches Ergebnis ist am plausibelsten?\n\n0 Wasser\n1 Wasser\n3 Wasser\n6 Wasser\n9 Wasser \\(\\square\\)\n\n\n\n\n6.3.5 Unser Modell ist geboren\nEin Modell (in der Bayes-Statistik) besteht aus mind. drei Komponenten:\n\nDie Likelihood (die Wahrscheinlichkeit der Daten unter Annahme der Hypothese), s. GleichungÂ 6.3\n\nDie Priori-Verteilung(en) (die Wahrscheinlichkeit der Hypothese vor den Daten), a. GleichungÂ 6.4\n\nDie Posteriori-Verteilung (die Wahrscheinlichkeit der Hypothese nach den Daten), s. AbbildungÂ 6.11\n\n\n6.3.6 Likelihood\nIm Globusversuch verwenden wir die Binomialverteilung zur Berechnung der Likelihood, s. GleichungÂ 6.3.\n\\[W \\sim \\text{Bin}(n,\\pi) \\tag{6.3}\\]\nLies: â€œW ist binomial verteilt mit den Parametern \\(n\\) und \\(\\pi\\)â€. \\(n\\) gibt die Anzahl der GlobuswÃ¼rfe an: \\(n=W+L\\).\nMit einem konkretes Beispiel: \\(W \\sim \\text{Bin}(9, 0.7)\\) bedeutet, dass wir von 9 WÃ¼rfen ausgehen und eine Wahrscheinlichkeit fÃ¼r Wasser von 70% annehmen.\nDie Verwendung der Binomialvertielung ist an einige Annahmen geknÃ¼pft:\n\nDie ZÃ¼ge sind unabhÃ¤ngig voneinander (Die WÃ¼rfe des Globusballs beeinflussen sich einander nicht).\nDer Parameterwert \\(\\pi\\) bleibt konstant (Der Wasseranteil der Erde Ã¤ndert sich nicht wÃ¤hrend des Versuchs).\n\n\nÃœbungsaufgabe 6.4 ğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?\\(\\square\\)\n\n\n6.3.7 Priori-Verteilung\nUnser Vorab- bzw. Apriori-Wissen zu \\(p\\) sei, dass uns alle Werte gleich (â€œuniformâ€) plausibel erscheinen, s. GleichungÂ 6.4.\n\\[\\pi \\sim \\text{Unif}(0,1). \\tag{6.4}\\]\nLies: â€œ\\(\\pi\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1â€.\nMan kÃ¶nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (apriori) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich, s. AbbildungÂ 6.8.\n\n\n\n\n\n\n\nAbbildungÂ 6.8: Gleichverteilung mit Parametern min=0 und max=1\n\n\n\n\n\n6.3.8 Posteriori-Verteilung\ndie Posteriori-Verteilung quantifiziert unser Wissen nach Kenntnis der Daten, aufbauend auf unserem Vorwissen (Priori-Wissen). Die Posteriori-Verteilung ist das Ergebnis des Bayes-Updates.\nDie Wahrscheinlichkeit bestimmter Hypothesen nennt man Posteriori-Wahrscheinlichkeit und bezeichnet sie kurz mit \\(Pr(H|D)\\). Lies: â€œDie Wahrscheinlichkeit der Hypothese H gegeben der Daten Dâ€. Dabei nimmt man stillschweigend an, dass die Daten anhand eines gewissen Modells generiert wurden.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-theorem",
    "href": "0500-Globusversuch.html#bayes-theorem",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.4 Bayesâ€™ Theorem",
    "text": "6.4 Bayesâ€™ Theorem\n\n6.4.1 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes hÃ¤ufig, wenn man Daten \\(D\\) gesammelt hat, und wissen mÃ¶chte, wie wahrscheinlich eine Hypothese \\(H\\) ist, im Lichte dieser gesammelten Daten, s. TheoremÂ 6.1. Anders gesagt: Die Likelihood ist relativ einfach zu bestimmen, \\(Pr(D|H)\\), aber nicht so interessant. Die Posteriori-Wahrscheinlichkeit, \\(Pr(H|D)\\), ist schwerer zu bestimmen, aber interessanter. Man kÃ¶nnte also sinnbildlich sagen, das Bayes-Theorem ist eine â€œMaschineâ€, die die Priori-Wahrscheinlichkeit zusammen mit der Likelihood zur Posteriori-Wahrscheinlichkeit â€œumbautâ€.\n\n\nTheorem 6.1 (Bayesâ€™ Theorem) \\[Pr(H|D) = \\frac{ Pr(H) \\cdot Pr(D|H) }{Pr(D)}\\quad \\square\\]\n\nBayesâ€™ Theorem (TheoremÂ 6.1) fragt nach \\(Pr(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (TheoremÂ 6.1):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der PlausibilitÃ¤t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus StandardisierungsgrÃ¼nden dividiert man noch die totale Wahrscheinlichkeit der Daten Ã¼ber alle Hypothesen.\n\nFÃ¼r unser Globusbeispiel:\n\nWie wahrscheinlich ist denn jetzt ein bestimmter Wasseranteil auf der Erde, \\(\\pi\\), (gegeben den Daten, \\(W=6\\) und \\(L=3\\))? Also, wie wahrscheinlich ist z.B. ein Wasseranteil von 70% oder von 50%?\n\n\n6.4.2 Bayes als bedingte Wahrscheinlichkeit\nBayesâ€™ Theorem wird hÃ¤ufig verwendet, um die Wahrscheinlichkeit einer Hypothese, gegeben einer bestimmten Datenlage, zu berechnen, also \\(Pr(H|D)\\). Also zeigt Bayesâ€™ Theorem nichts anderes als eine normale bedingte Wahrscheinlichkeit.\n\\(Pr(H| D)\\) kann man umformen (vgl. TheoremÂ 4.3 und DefinitionÂ 4.6), dann erhÃ¤lt man Bayesâ€™ Theorem, s. TheoremÂ 6.8.\n\nTheorem 6.2 (Bayesâ€™ Theorem 2) \\[\\begin{aligned}\nPr(H|D) &=\\frac{\\overbrace{ Pr(H\\cap D)}^\\text{umformen}}{Pr(D)} \\\\  &= \\frac{\\overbrace{Pr(H)}^\\text{Apriori-Wahrscheinlichkeit} \\cdot \\overbrace{Pr(D|H)}^\\text{Likelihood}}{\\underbrace{Pr(D)}_\\text{Evidenz}}\n\\end{aligned}\\quad \\square\\]\n\n\n6.4.3 Die Evidenz zur Standardisierung\nDie Aufgabe der Evidenz ist nur dafÃ¼r zu sorgen, dass der Wert von \\(Pr(H|D)\\) insgesamt nur Werte zwischen 0 und 1 annehmen kann, also eine brave, normale Wahrscheinlichkeit ist. WÃ¼rde man in TheoremÂ 6.8 nicht durch die Evidenz teilen, so wÃ¤re die Posteriori-Wahrscheinlichkeit nicht normiert, d.h. sie kÃ¶nnte Werte &gt;1 annehmen.\n\nDefinition 6.4 (Evidenz) \\(Pr(D)\\) nennt man die Evidenz. Die Evidenz berechnet sich als Summe der Likelihoods fÃ¼r alle Parameterwerte \\(H_i\\), d.h. als die totale Wahrscheinlichkeit von \\(D\\), s. TheoremÂ 6.3, vgl. auch DefinitionÂ 4.8. \\(\\square\\)\n\n\nTheorem 6.3 (Evidenz) \\[\\begin{aligned}\nPr(D) = \\sum_{i=1}^n Pr(D|H_i) \\cdot Pr(H_i)\n\\end{aligned}\\quad \\square\\]\n\nDie verschiedenen Parameterwerte kann man auch als die verschiedenen Hypothesen \\(H_i\\) auffassen. Falls es nur zwei Hypothesen bzw. Parameterwerte gibt, vereinfacht sich TheoremÂ 6.3 zu TheoremÂ 6.4.\n\nTheorem 6.4 (Evidenz 2) \\[\\begin{aligned}\nPr(D) = Pr(D|H_1) \\cdot Pr(H_1) + Pr(D|H_2) \\cdot Pr(H_2)\n\\end{aligned}\\quad \\square\\]\n\n\nBeispiel 6.6 In BeispielÂ 6.8 betrug der Wert der Evidenz \\(0.03 + 0.002 + 0.012 = 0.044\\), also ca. 4%. \\(\\square\\)\n\n\n\n\n\n\n6.4.4 Bayesâ€™ Theorem als Formel\n\n\nSchauen wir uns die Bestandteile von Bayesâ€™ Theorem (TheoremÂ 6.8) noch etwas nÃ¤her an:\n\n(standardisierte) Posteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nApriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayesâ€™ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) fÃ¼ttert. Bayesâ€™ Theorem wird verwendet, um die \\(Pr_{Post}\\) zu quantifizieren. Die \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n6.4.5 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Posteriori-Wahrscheinlichkeit \\(Pr_{\\text{unPost}}\\) ist einfach das Produkt von Likelihood und Priori, s. TheoremÂ 6.5.\n\nTheorem 6.5 (Unstandardisierte Posteriori-Wahrscheinlichkeit) \\[Pr_{\\text{unPost}} = L \\times \\text{Priori}\\quad \\square\\]\n\nAbb. AbbildungÂ 6.9 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\n\n\n\nAbbildungÂ 6.9: Prior mal Likelihood = Post\n\n\nStandardisiert man die unstandardisierte Post-Verteilung, so erhÃ¤lt man die standardisierte Post-Verteilung. Das Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung TheoremÂ 6.6.\n\nTheorem 6.6 (Standardisierte Posteriori-Verteilung) \\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\quad \\square\\]\n\n\n6.4.6 Wissen updaten: Wir fÃ¼ttern Daten in das Modell\nGolems kÃ¶nnen lernen?! AbbildungÂ 6.10 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. WÃ¼rfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich fÃ¼r den Golem (das Modell). Je nach Ergebnis des Wurfes verÃ¤ndert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung verÃ¤ndert sich in AbhÃ¤ngigkeit von den Daten.\n\n\n\n\n\nAbbildungÂ 6.10: Unser Golem lernt\n\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-berechnen-mit-mit-der-bayesbox",
    "href": "0500-Globusversuch.html#bayes-berechnen-mit-mit-der-bayesbox",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.5 Bayes berechnen mit mit der Bayesbox",
    "text": "6.5 Bayes berechnen mit mit der Bayesbox\nWir erstellen uns eine kleine Tabelle, die man â€œBayesboxâ€ nennen kÃ¶nnte.10 Dazu gehen wir so vor:\n\n6.5.1 Die Idee der Bayesbox\n\nTeile den Wertebereich des Parameters in ein â€œGitterâ€ auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\).\nWÃ¤hle den Priori-Wert des Parameters fÃ¼r jeden Parameterwert, z.B. 1/11 bei einer Gleichverteilung von 0 bis 1.\nBerechne den Likelihood fÃ¼r jeden Parameterwert.\nBerechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Parameterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nFÃ¼r jeden Parameterwert berechnen wir eine (Post-)Wahrscheinlichkeit.11 HÃ¤ufig entspricht eine Hypothese einem Parameterwert, etwa wenn man sagt: â€œIch glaube, die MÃ¼nze ist fairâ€, was auf einen Parameterwert von 50% herauslÃ¤uft. Dazu geben wir an, fÃ¼r wie wahrscheinlich wie apriori12 â€“ also bevor wir irgendwelche Daten erheben â€“ jeden einzelnen Parameterwert halten. Wir machen es uns hier einfach und halten jeden Parameterwert fÃ¼r gleich wahrscheinlich. TatsÃ¤chlich ist der konkrete Wert hier egal, entscheidend ist das VerhÃ¤ltnis der Apriori-Werte zueinander: Geben wir einigen Parameterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere fÃ¼r (apriori) doppelt so plausibel wie Letztere. Der Likelihood wird in diesem Beispiel mit der Binomialverteilung berechnet (da wir ein binÃ¤res Ereignis, \\(W\\) oder \\(L\\), haben). Der Likelihood gibt an, wie wahrscheinlich ein Parameterwert ist gegeben einem bestimmten apriori gewÃ¤hlten Parameterwert. Die â€œEnd-Wahrscheinlichkeitâ€, die unstandardisierte Post-Wahrscheinlichkeit, die â€œhinten rauskommtâ€ ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet13. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen mÃ¶chten, teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die AnsprÃ¼che an eine Wahrscheinlichkeitsverteilung erfÃ¼llt (vgl. Kapitel 3.3.3).\n\n6.5.2 Bayesbox in R berechnen\nLegen wir uns ein Gitter mit Parameterwerten (\\(\\pi\\)) an, um deren Posteriori-Wahrscheinlichkeit zu berechnen. Konkret gesprochen: Wir listen jeden fÃ¼r uns interessanten Wasseranteil (\\(\\pi\\)) auf, also \\(\\pi=0, 0.1, 0.2, ..., 1\\). Diese Parameterwerte sind die Hypothesen, die wir testen wollen, s. ListingÂ 6.2.\n\n\n\nListingÂ 6.2: Parameterwerte (Gitter) fÃ¼r Wasseranteile: 0, 0.1, 0.2, â€¦, 1\n\nCodewasseranteile &lt;- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte\nwasseranteile\n##  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 WÃ¼rfen) gegeben jeweils eines Wasseranteils.\n\nCodeLikelihood &lt;- dbinom(6, size = 9, prob = wasseranteile)\nLikelihood\n##  [1] 0.0e+00 6.1e-05 2.8e-03 2.1e-02 7.4e-02 1.6e-01 2.5e-01 2.7e-01 1.8e-01\n## [10] 4.5e-02 0.0e+00\n\n\nSchlieÃŸlich packen wir das alles in eine Tabelle, die â€œBayesboxâ€, s. TabelleÂ 6.2 und ListingÂ 6.3.\n\n\n\nListingÂ 6.3: Wir basteln uns eine Bayesbox\n\nCoded &lt;-\n  tibble(\n    # definiere die Hypothesen (die Parameterwerte, p): \n    p = wasseranteile,\n    # Lege den Priori-Wert fest:\n    Priori  = 1/11) |&gt; \n    mutate(\n      # berechne Likelihood fÃ¼r jeden Wasseranteil (Parameterwert):\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\n\n\n\n\nDie Bayesbox (TabelleÂ 6.2) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\nTabelleÂ 6.2: Die Bayesbox fÃ¼r den Globusversuch, k=6 Treffer, n=9 Versuche, Apriori-Wahrscheinlichkeit Pr(H)=9%, und Wasseranteile p von 0 bis 1\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n1\n0.0\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n2\n0.1\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n3\n0.2\n0.091\n0.003\n0.000\n0.091\n0.003\n\n\n4\n0.3\n0.091\n0.021\n0.002\n0.091\n0.021\n\n\n5\n0.4\n0.091\n0.074\n0.007\n0.091\n0.074\n\n\n6\n0.5\n0.091\n0.164\n0.015\n0.091\n0.164\n\n\n7\n0.6\n0.091\n0.251\n0.023\n0.091\n0.251\n\n\n8\n0.7\n0.091\n0.267\n0.024\n0.091\n0.267\n\n\n9\n0.8\n0.091\n0.176\n0.016\n0.091\n0.176\n\n\n10\n0.9\n0.091\n0.045\n0.004\n0.091\n0.045\n\n\n11\n1.0\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n\n\n\n\n\n\nFÃ¼r jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood, s. GleichungÂ 6.5.\n\\[\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood} = Pr(H) \\cdot Pr(H|D) \\tag{6.5}\\]\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Bayesbox (also fÃ¼r jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten, s. TheoremÂ 6.7.\n\nTheorem 6.7 (Posteriori-Verteilung 2) \\[\\text{Post} = \\frac{\\text{Post}_{\\text{unstand}}}{\\text{Evidenz}} = \\frac{Pr(H) \\cdot Pr(H|D)}{Pr(D)}\\quad \\square\\]\n\nDabei haben wir die Priori-Wahrscheinlichkeit fÃ¼r alle Parameterwerte als gleich angenommen, da wir keinerlei Vorwissen hatten, \\(Pr(H_i) = 1/11\\). Die Evidenz berechnet sich als Summe der unstandardisierten Post-Wahrscheinlichkeiten, \\(Pr(D) = 0.09\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWenn der Priori-Wert fÃ¼r jeden Parameterwert gleich ist, dann ist der Likelihood gleich der unstandardisierten Post-Wahrscheinlichkeit.\\(\\square\\)\n\n\n\nBeispiel 6.7 (Post-Wahrscheinlichkeit im Globusversuch fÃ¼r p=.7) In BeispielÂ 6.5 haben wir die Wahrscheinlichkeit fÃ¼r 6 Treffer bei 9 WÃ¼rfen gegeben einer Trefferwahrscheinlichkeit von \\(\\pi = .7\\) berechnet. Damit haben wir die Likelihood \\(L = Pr(D|H) =.25\\) berechnet.\nAuf dieser Basis kÃ¶nnen wir die Posteriori-Wahrscheinlichkeit \\(Pr_{Post}\\) berechnen, zunÃ¤chst die unstandardisierte. Dazu haben wir die Priori-Wahrscheinlichkeit mit der Likelihood multipliziert, s. GleichungÂ 6.6:\n\\[\\text{Post}_{\\text{unstand}} = Pr(H) \\cdot Pr(D|H) = 0.09 \\cdot 0.25 = 0.025 \\tag{6.6}\\]\nJetzt standardisieren wir die unstandardisierte Post-Wahrscheinlichkeit, indem wir durch die Evidenz dividieren, s. GleichungÂ 6.7.\n\\[\\text{Post} = \\frac{\\text{Post}_{\\text{unstand}}}{\\text{Evidenz}} = \\frac{0.025}{0.1} =0.25 \\tag{6.7}\\]\nGleichungÂ 6.8 fasst die Schritte der Berechnung zusammen.\n\\[\\begin{aligned}\nPr(H_{\\pi=0.7}|D) =\n\\frac{Pr(D|H) \\cdot Pr(H)}{Pr(D)} &= \\\\\n\\frac{\\text{Likelihood}  \\cdot \\text{Priori}}{\\text{Evidenz}} &= \\\\\n\\frac{0.25 \\cdot 0.1}{0.1} &= 0.25\n\\end{aligned} \\tag{6.8}\\] \\(\\square\\)\nFazit: Nach dem Versuch, d.h. nachdem wir die Daten in Betracht gezogen haben, hat sich unsere Meinung Ã¼ber den Wasseranteil geupdatet von 0.1 auf 0.25.\\(\\square\\)\n\n\nÃœbungsaufgabe 6.5 ğŸ‹ï¸ Was wohl mit Post passiert, wenn wir Priori Ã¤ndern?\\(\\square\\)\n\nAbbildungÂ 6.11 zeigt eine Visualisierung der Post-Verteilung mit Hilfe der Funktion ggline(x, y) aus dem Paket ggpubr. Wie man sieht, ist die Post-Wahrscheinlichkeit am hÃ¶chsten bei \\(\\pi=0.7\\). Wobei der Bereich von 0.6 bis 0.8 auch recht wahrscheinlich ist.\n\n\n\n\n\n\n\nAbbildungÂ 6.11: Die Post-Verteilung visualisiert. Die Post-Wahrscheinlichkeit ist am hÃ¶chsten bei p=0.7\n\n\n\n\n\n6.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: â€œPost-Verteilungâ€, oder â€œPostâ€), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten, jetzt, nachdem wir die Daten des Versuchs kennen. Die Post-Wahrscheinlichkeit updatet unser Apriori-Wissen mit dem Wissen, das wir durch die Daten erhalten haben.\nAbbildungÂ 6.12 zeigt die Post-Wahrscheinlichkeit fÃ¼r 5, 10 und 20 Parameterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben. Man sieht: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\nAbbildungÂ 6.12: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen UmstÃ¤nden gilt:\n\nMehr Gitterwerte glÃ¤tten die AnnÃ¤herung.\nJe grÃ¶ÃŸer die Stichprobe (\\(N\\)), desto zuverlÃ¤ssiger wird unsere Berechnung. \\(\\square\\)\n\n\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer TrÃ¤ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung kÃ¶nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nÃ¤chsten Kapitels. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.6 (Peer Instruction: SchlÃ¼sse ziehen mit dem Bayes-Modell) Auf einer Party: Unterhalten sich fÃ¼nf Studis Ã¼ber das Bayesmodell. Einer hat Unrecht, die anderen Recht.\n\nWenn eine Hypothese \\(A\\) apriori doppelt so wahrscheinlich ist wie die anderen und die Likelihoods fÃ¼r alle Hypothesen gleich ist, dann ist \\(A\\) aposteriori auch doppelt so wahrscheinlich wie die anderen Hypothesen.\nSind alle Hypothesen apriori gleich wahrscheinlich, dann hat die Hypothese mit dem hÃ¶chsten Likelihood aposteriori auch die hÃ¶chste Wahrscheinlichkeit.\nHat eine Hypothese apriori die Wahrscheinlichkeit Null, so hat sie automatisch aposteriori auch die Wahrscheinlichkeit Null, unabhÃ¤ngig von ihrer Likelihood.\nDie unstandardisierte Posteriori-Wahrscheinlichkeit ist gleich der standardisierten mal einen Faktor \\(k\\).\nHat eine Hypothese die hÃ¶chste Likelihood, so hat sie automatisch auch die hÃ¶chste Wahrscheinlichkeit aposteriori. \\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#abschluss",
    "href": "0500-Globusversuch.html#abschluss",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.6 Abschluss",
    "text": "6.6 Abschluss\n\n6.6.1 Zusammenfassung\nğŸ“º Ãœbung zum Globusversuch\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.\n\n\nÃœbungsaufgabe 6.7 ğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r \\(W\\) tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)? \\(\\square\\)\n\n\n6.6.2 Der Globusversuch als Modell fÃ¼r zweiwertige Zufallsversuche\nDer Globusversuch ist kein prototypisches Beispiel fÃ¼r Statistik in der Praxis, zumindest nicht auf dem ersten Blick. Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist. Bei nÃ¤herer Betrachtung ist der Globusversuch prototypisch fÃ¼r ganz viele Fragestellungen:\n\nVon einem neuen Produkt von von \\(n\\) Exemplaren \\(k\\) verkauft. Auf welchen Wert \\(p\\) kann die Akzeptanzrate dieses Produkts geschÃ¤tzt werden?\nEin Chat-Bot hat von \\(n\\) Fragen \\(k\\) richtig beantwortet. Wie hoch kann die VerstÃ¤ndnisrate \\(p\\) dieses Programms geschÃ¤tzt werden?\nEine neue Krebstherapie hat von \\(n\\) â€œaustherapiertenâ€ Patientis \\(k\\) geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie geschÃ¤tzt werden?\n\nKurz: Der Globusversuch ist ein Muster fÃ¼r zweiwertige Zufallsversuche. Und solche sind hÃ¤ufig im Leben, im Business und in der Wissenschaft.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#vertiefung",
    "href": "0500-Globusversuch.html#vertiefung",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\n6.7.1 Bayes-Video von 3b1b\nDas â€œBayes-Paradox-Videoâ€ von 3b1b prÃ¤sentiert eine gut verstÃ¤ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber Ã¤hnlichen Darstellung wie in diesem Kapitel.\n\n6.7.2 Bayes als Baum\nBayesâ€™ Theorem kann man sich als als Baumdiagramm vor Augen fÃ¼hren, AbbildungÂ 6.13.\nGesucht sei \\(Pr(M_1|A)\\), also: die Wahrscheinlichkeit, dass das Teil von Maschine 1 produziert wurde, gegeben, dass es Ausschuss ist. Gegeben sind die Wahrscheinlichkeiten, dass Machine \\(i\\) das Teil produziert hat, \\(Pr(M_i)\\). AuÃŸerdem sind die Wahrscheinlichkeiten, dass das Teil Ausschuss ist, \\(Pr(A|M_i)\\), bekannt.\nDas Diagramm lÃ¶st die Aufgabe fÃ¼r uns; es zeigt damit die Anwendung von Bayesâ€™ Theorem auf.\nUm \\(Pr(M_1|A)\\) zu erhalten, setzt man die Wahrscheinlichkeit des gÃ¼nstigen Asts ins VerhÃ¤ltnis zur Wahrscheinlichkeit aller relevanten Ã„ste, \\(Pr(A)\\).\n\nBeispiel 6.8 (Maschine produziert Ausschuss) Die drei Maschinen \\(M_1, M_2, M_3\\) produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. AbbildungÂ 6.13.\nAufgabe: Wie groÃŸ ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde? Berechnen Sie diese Wahrscheinlichkeit.\\(\\square\\)\n\nDer gÃ¼nstige (gesuchte) Ast, \\(Pr(M1 \\cap A)\\), ist hier fett gedruckt, s. AbbildungÂ 6.13. In AbbildungÂ 6.13 zeigen die runden KÃ¤stchen am Ende der Pfade die Wahrscheinlichkeiten des jeweiligen Pfades an.\n\n\n\n\n\nflowchart LR\n  A[Start] ==&gt;|0.60|B[M1]\n  A ---&gt;|0.10|C[M2]\n  A ---&gt;|0.30|D[M3]\n  B ==&gt;|0.05|E[A]\n  B --&gt;|0.95|F[Nicht-A]\n  C ---&gt;|0.02|G[A]\n  C ---&gt;|0.98|H[Nicht-A]\n  D ---&gt;|0.04|I[A]\n  D ---&gt;|0.96|J[Nicht-A]\n  E --- K((0.030))\n  F --- L((0.570))\n  G --- M((0.002))\n  H --- N((0.098))\n  I --- O((0.012))\n  J --- P((0.288))\n\n\n\n\nAbbildungÂ 6.13: GÃ¼nstige Pfade\n\n\n\n\n\\[Pr(M1|A) = \\frac{Pr(M1 \\cap A)}{Pr(A)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(Pr(M1|A)\\) betrÃ¤gt also ca. 68%.\nZur Erinnerung: \\(Pr(A)\\) ist die totale Wahrscheinlichkeit (dass ein produziertes Teil Ausschuss ist).\n\n6.7.3 Weitere Herleitung der Bayes-Formel\nMan kann sich Bayesâ€™ Theorem auch wie folgt herleiten:\n\\(Pr(D\\cap H) = Pr(D \\cap H) = Pr(D) \\cdot Pr(H|D) = Pr(H) \\cdot Pr(D|H)\\)\nDann lÃ¶sen wir nach P\\((H|D)\\) auf, s. TheoremÂ 6.8.\n\nTheorem 6.8 (Bayesâ€™ Theorem 3) \\[Pr(H|D) = \\frac{\\overbrace{Pr(H)}^\\text{Apriori-Wahrscheinlichkeit} \\cdot \\overbrace{Pr(D|H)}^\\text{Likelihood}}{\\underbrace{Pr(D)}_\\text{Evidenz}}\\quad \\square\\]\n\n\n6.7.4 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayesâ€™ Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel wÃ¤re: â€œWas ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?â€.\nDas sieht dann so aus wie in TheoremÂ 6.9 gezeigt.\n\nTheorem 6.9 (Bayesâ€™ Theorem fÃ¼r zusammengesetzte Hypothesen) \\[\n\\begin{aligned}\nPr(R \\cap B |K) &= \\frac{ Pr(R \\cap B) \\cdot Pr(K|R \\cap B) }{Pr(D)} \\\\\n&= \\frac{ Pr(R ) \\cdot Pr(B) \\cdot Pr(K|R \\cap B) }{Pr(D)}\n\\end{aligned}\n\\quad \\square\\]\n\nHier haben wir \\(Pr(R \\cap B)\\) aufgelÃ¶st in \\(Pr(R) \\cdot Pr(B)\\), das ist nur zulÃ¤ssig, wenn \\(R\\) und \\(B\\) unabhÃ¤ngig sind.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#aufgaben",
    "href": "0500-Globusversuch.html#aufgaben",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\n\n\n\n\n\n\nTipp\n\n\n\nEinige der folgenden Aufgaben sind in englischer Sprache. Wenn Ihnen eine andere Sprache (z.B. Deutsch) lieber ist, nutzen Sie einfach die Ãœbersetzungsfunktion Ihres Browsers. Das sind meist nur zwei Klicks. \\(\\square\\)\n\n\n\n6.8.1 Papier-und-Bleistift-Aufgaben\n\nVerteilungen-Quiz-01\nglobus1\nglobus2\nglobus3\nglobus-bin\nglobus-bin2\nKrebs1\nkekse01\nkekse03\nbayes2\nBayes-Theorem1\nbayes-ziel1\ntotale-wskt1\nwskt-quiz13\nwskt-quiz12\nwskt-quiz15\n\n6.8.2 Aufgaben, fÃ¼r die man einen Computer braucht\n\n\nRethink2m1\nRethink2m2\n\nRethink2m3    \n\nkekse02\neuro-bayes\nbath42\nKaefer2\nrethink3m1\nLose-Nieten-Binomial-Grid",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#section",
    "href": "0500-Globusversuch.html#section",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "\n6.9 â€”",
    "text": "6.9 â€”\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#footnotes",
    "href": "0500-Globusversuch.html#footnotes",
    "title": "\n6Â  Bayes-Versuch\n",
    "section": "",
    "text": "wenn auch nicht als Ersterâ†©ï¸\nWarum gerade 9 Mal? Tja, dann hat das Handy geklingeltâ€¦ Auch in wissenschaftlichen Versuchen ist (leider?) nicht immer alles genau geregelt.â†©ï¸\nIhr Ergebnis kann anders aussehen, schlieÃŸlich ist es ja Zufall.â†©ï¸\noder den?â†©ï¸\nzu Deutsch etwa: â€œMutmaÃŸlichkeitâ€â†©ï¸\n Anstatt von Priori liest man auch Prior; anstatt Posteriori auch Posteriorâ†©ï¸\nDie sog. â€œiid-Annahmeâ€, independently and identically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen. Jeder Wurf ist unabhÃ¤ngig von allen anderen: Das Ergebnis eines Wurfes hat keinen (stochastischen) Einfluss auf ein Ergebnis anderer WÃ¼rfe. Die Wahrscheinlichkeitsverteilung ist bei jedem Wurf identisch.â†©ï¸\nAllgemeiner spricht man auch von 2 Treffern bei 3 WÃ¼rfen (d.h. 1 â€œNicht-Trefferâ€, den wir als â€œNieteâ€ bezeichnen). Treffer werden oft mit 1 und Nieten mit 0 bezeichnetâ†©ï¸\nhttps://www.geogebra.org/scientific?lang=deâ†©ï¸\nAuch Gitter-Methode oder Grid-Methode genannt.â†©ï¸\nEin Parameterwert ist eine mÃ¶gliche AusprÃ¤gung des Parameters.â†©ï¸\nsynonym: prioriâ†©ï¸\nsynonym: Die Likelihoodwerte werden mit den Apriori-Werten gewichtet.â†©ï¸",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0600-Post.html",
    "href": "0600-Post.html",
    "title": "7Â  Die Post befragen",
    "section": "",
    "text": "7.1 Lernsteuerung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "7Â  Die Post befragen",
    "section": "",
    "text": "7.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n7.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n7.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 3.1 und 3.2.\n\n\n7.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œDaten umformenâ€\nStatistik1, Kap. â€œDaten zusammenfassenâ€\nStatistik1, Kap, 6.4 â€œQuantile\n\n\n\n7.1.5 BenÃ¶tigte R-Pakete\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # optional\n\n\n\n\n7.1.6 Begleitvideos\n\nPlaylist QM2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#zur-erinnerung-bayesbox-in-r-berechnen",
    "href": "0600-Post.html#zur-erinnerung-bayesbox-in-r-berechnen",
    "title": "7Â  Die Post befragen",
    "section": "7.2 Zur Erinnerung: Bayesbox in R berechnen",
    "text": "7.2 Zur Erinnerung: Bayesbox in R berechnen\nBerechnen wir mit der Bayesbox (â€œGittermethodeâ€) die Postverteilung fÃ¼r den Globusversuch. Die Bayesbox ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen. Sie ist das zentrale Ergebnis einer Bayes-Analyse.\nBetrachten wir wieder das Globusmodell mit folgendem Ergebnis: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen, bei Apriori-Indifferenz gegenÃ¼ber den Parameterwerten. Und sagen wir \\(k=11\\) Gitterwerten1, also mit 10 Wasseranteilswerten zwischen 0 und 1.\n\nÃœbungsaufgabe 7.1 (Welcher Paramterwert hat die hÃ¶chste Posteriori-Wahrscheinlichkeit?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\nAufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die hÃ¶chste Wahrscheinlichkeit (d.h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. ListingÂ 7.1. \\(\\square\\)\n\n\n\n\n\n\n\n\nListingÂ 7.1: Bayesbox mit 6 Wasser bei 9 Versuchen\n\n\n\nCode\nn_success &lt;- 6          \nn_trials  &lt;- 9\n1p_grid &lt;- seq(from = 0, to = 1, by = .1)\n2L &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\n\n3bayesbox_6w_9v &lt;-\n  tibble(p_grid = p_grid,prior  = 1) %&gt;% \n  mutate(likelihood = L) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n\n\n\n1\n\nSequenz von 0 bis 1 mit Schritten der GrÃ¶ÃŸe 0.1.\n\n2\n\nLikelihood mit 6 Treffern bei 9 WÃ¼rfen und das Ganze jeweils fÃ¼r alle 11 Parameterwerte\n\n3\n\nDann packen wir alles in eine Tabelle.\n\n\n\n\n\n\nAbb. AbbildungÂ 6.11 zeigt die resultierende Bayesbox; vor allem ist die Post-Verteilung wichtig.\n\n\nCode\nlibrary(ggpubr)\nggline(bayesbox_6w_9v , x = \"p_grid\", y = \"post\") \n\n\n\n\n\n\n\n\n\n\n\n\nVoilÃ , die Post-Verteilung als Tabelle, auch â€œBayesboxâ€ (oder Bayes-Gitter) genannt: s. TabelleÂ 7.1.\n\n\n\n\nTabelleÂ 7.1: Postverteilung mit der Gittermethode berechnet\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.02\n0.02\n0.02\n\n\n0.4\n1\n0.07\n0.07\n0.07\n\n\n0.5\n1\n0.16\n0.16\n0.16\n\n\n0.6\n1\n0.25\n0.25\n0.25\n\n\n0.7\n1\n0.27\n0.27\n0.27\n\n\n0.8\n1\n0.18\n0.18\n0.18\n\n\n0.9\n1\n0.04\n0.04\n0.04\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.1 Bayesbox automatisiert\nÃœbrigens kann man die Berechnung der Bayesbox auch automatisieren, s. TabelleÂ 7.2 und ListingÂ 7.2, z.B. so:2\nEntweder so:\n\n\nCode\nsource(\"https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R\") \nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\nMit source importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code fÃ¼r die Funktion bayesbox.\nOder Sie starten das R-Paket, wo die Funktion wohnt:\n\n\n\n\nListingÂ 7.2: Funktion bayesbox, auch im Paket prada erhÃ¤ltlich\n\n\n\nCode\n1library(prada)\nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\n\n\n\n\n1\n\nDas Paket prada steht nicht im Standard-R-App-Store (â€œCRANâ€), sondern auf Github. Sie kÃ¶nnnen es so installieren: devtools::install_github(\"sebastiansauer/prada\").\n\n\n\n\n\n\nTabelleÂ 7.2: Eine Bayesbox â€˜automatisiertâ€™ erstellt, mit Hilfe der Funktion bayesbox\n\n\n\n\n  \n\n\n\n\n\n\nViele nÃ¼tzliche Fragen (und Antworten) leiten sich ab aus Abb. AbbildungÂ 6.11.\n\nBeispiel 7.1 (Beispiele fÃ¼r Fragen an die Post-Verteilung) Â \n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\netc. \\(\\square\\)\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n7.2.2 Bayesbox geht nicht fÃ¼r komplexe Modelle\nBisher, fÃ¼r einfache Fragestellungen, hat unsere Bayesbox gut funktioniert. Allerdings: Funktioniert sie auch bei komplexeren Modellen? SchlieÃŸlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 PrÃ¤diktor, dann haben wir folgende drei GrÃ¶ÃŸen3 zu schÃ¤tzen: \\(\\beta_0, \\beta_1, \\sigma\\). HÃ¶rt sich gar nicht so viel an. Aber Moment, wir mÃ¼ssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach mÃ¼ssen wir alle AusprÃ¤gungen (â€œGitterwerteâ€) der Variablen multiplizieren, um die Wahrscheinlichkeiten aller Kombinationen zu bestimmen. Puh, das wird eine groÃŸe Zahl. Wenn wir fÃ¼r die drei GrÃ¶ÃŸen jeweils 10 AusprÃ¤gungen annehmen, was wenig ist, kÃ¤men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 AusprÃ¤gungen und 3 Parametern wÃ¤ren es schon \\(100^3=10^6\\) Kombinationen. Das wÃ¤re doch eine recht lange Tabelle.4 Bei einer multiplen Regression mit sagen wir 10 Parametern mit jeweils 100 AusprÃ¤gungen rechnet das arme R bis zum jÃ¼ngsten Tag: \\(10^{100}\\).\n\nğŸ¤– Bitte tue mir das nicht an!\n\n\nğŸ‘¨â€ğŸ« Schon gut, das kÃ¶nnen wir R nicht zumuten. Wir brauchen eine andere LÃ¶sung!",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "7Â  Die Post befragen",
    "section": "7.3 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "7.3 Mit Stichproben die Post-Verteilung zusammenfassen\n\n7.3.1 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Mathematik wird zu rechenintensiv. GlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht. Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten. Praktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der das fÃ¼r uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck. Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung mit HÃ¤ufigkeiten (d.h. in Stichprobenform) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Bayesbox-Methode5 ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu unpraktisch. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein.6\n\n\n7.3.2 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck. Bevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform. Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle bayesbox_6w_9v), s. ListingÂ 7.3.\n\n\n\nListingÂ 7.3: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\n\n\n\nsamples_6w_9v &lt;-\n  bayesbox_6w_9v %&gt;%  # nimm die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit ZurÃ¼cklegen\n  select(p_grid)\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle bayesbox_6w_9v zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird. Wir begnÃ¼gen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht. Das Ergebnis, Tabelle samples_6w_9v, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 7.3 dargestellt.\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\n\n\nTabelleÂ 7.3 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.\n\n\n\n\nTabelleÂ 7.3: Stichproben-Post-Verteilung\n\n\n\n\n\n\n\n\n\np_grid\n\n\n\n\n0.500\n\n\n0.900\n\n\n0.700\n\n\n0.600\n\n\n0.900\n\n\n\n\n\n\n\n\n\n\n\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.5 0.9 0.7 0.6 0.9 0.3 0.7 0.6 0.8 0.4 0.7 0.3 0.9 0.7 0.6 0.6 0.4 0.6\n##  [19] 0.5 0.5 0.5 0.6 0.8 0.7 0.5 0.7 0.7 0.4 0.8 0.6 0.6 0.7 0.9 0.6 0.9 0.4\n##  [37] 0.8 0.9 0.8 0.6 0.6 0.6 0.5 0.7 0.5 0.8 0.7 0.7 0.6 0.8 0.3 0.5 0.8 0.5\n##  [55] 0.7 0.6 0.5 0.8 0.7 0.7 0.7 0.7 0.6 0.7 0.5 0.7 0.6 0.6 0.7 0.8 0.7 0.6\n##  [73] 0.8 0.5 0.8 0.7 0.7 0.7 0.6 0.8 0.7 0.7 0.9 0.4 0.5 0.6 0.6 0.5 0.8 0.8\n##  [91] 0.7 0.7 0.6 0.9 0.9 0.5 0.5 0.8 0.7 0.8\n\n\n\nSo sieht unsere â€œStichproben-Bayesboxâ€ als Balkendiagramm aus, s. AbbildungÂ 7.1.\n\nSyntaxOutput\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  count(p_grid) |&gt; \n  ggbarplot(x = \"p_grid\", y = \"n\") \n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 7.1: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n\n\nAus AbbildungÂ 7.1 kÃ¶nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% fÃ¼r am wahrscheinlichsten hÃ¤lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlieÃŸen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie AbbildungÂ 7.1 mit AbbildungÂ 6.12: beide sind sehr Ã¤hnlich! Das Stichprobenziehen (AbbildungÂ 7.1) nÃ¤hert sich recht gut an die exakte Berechnung an (AbbildungÂ 6.12).\nEs ist hilfreich, sich die Stichproben-Posterior-Verteilung einmal anzuschauen, um ein GefÃ¼hl dafÃ¼r zu bekommen, wie die Post-Verteilung aussieht.\n Download samples_6w_9v.xlsx \n\n\n7.3.3 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) Gitterwerte (AusprÃ¤gungen) nach oben.\n\n\nCode\n1k &lt;- 100\n2n_success &lt;- 6\n3n_trials  &lt;- 9\n\nbayesbox_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n4                      length.out = k),\n5         prior  = 1) %&gt;%\n6  mutate(likelihood = dbinom(n_success,\n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n7  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n1\n\n\\(k=100\\) Gitterwerte\n\n2\n\n6 Treffer (Wasser)\n\n3\n\n9 Versuche\n\n4\n\nBayesbox anlegen mit 100 Zeilen, d.h. 100 Parameterwerten\n\n5\n\nApriori indifferent: Alle Hypothesen haben die gleiche Apriori-PlausibilitÃ¤t\n\n6\n\nDie Likelihood ist binomialverteilt.\n\n7\n\nPost-Verteilung berechnen wie gewohnt.\n\n\n\n\nbayesbox_k100 ist eine Bayesbox mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\n\nCode\nsamples_k100 &lt;-\n  bayesbox_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\n\nAbbildungÂ 7.2 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen FÃ¤llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der â€œtypischeâ€ Wert des Modells zu sein. AuÃŸerdem erkennt man, dass das Modell durchaus einige Streuung in der SchÃ¤tzung des Wasseranteils bereithÃ¤lt. Das Modell ist sich nicht sehr sicher, kÃ¶nnte man sagen.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.2: Post-Verteilung mit 100 Gitterwerten, exakt vs.Â auf Basis von Stichproben\n\n\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder. Die Stichproben-Post-Verteilung ist sehr Ã¤hnlich zur echten, exakten Post-Verteilung. Das Stichproben-Verfahren zur Berechnung der Post-Verteilung funktioniert also! Das ist gut, denn wir werden in Zukunft nur noch mit dem Stichproben-Verfahren (zur Erstellung der Post-Verteilung) arbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt die Post-Verteilung noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. AbbildungÂ 7.3.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.3: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schÃ¶n â€˜glattâ€™. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "7Â  Die Post befragen",
    "section": "7.4 Die Post-Verteilung befragen",
    "text": "7.4 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\nğŸ“º Die Post-Verteilung auslesen\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in AbbildungÂ 7.4 schematisch illustriert.\n\n\n\n\n\n\nAbbildungÂ 7.4: Fragen nach p vs.Â Fragen nach q\n\n\n\nIm linken Teildiagramm von AbbildungÂ 7.4 fragen wir: â€œWie wahrscheinlich ist ein Wasseranteil von hÃ¶chstens 80%?â€. Im rechten Teildiagramm fragen wir: â€œWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht Ã¼berschritten?â€.\n\n7.4.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt? Um diese Frage zu beantworten, zÃ¤hlen wir einfach, wie viele Stichproben die Bedingung erfÃ¼llen, und summieren die Wahrscheinlichkeiten dieser Stichproben. Wir zÃ¤hlen (count) also die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen.\n\n\nCode\nsamples_6w_9v %&gt;%\n  count(p_grid &lt; .5) \n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.\n\nÃœbungsaufgabe 7.2 (Was macht die Funktion count?) Zur Erinnerung: Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem PrÃ¼fkriterium, Wasseranteil hÃ¶chstens 50%. Dann zÃ¤hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurÃ¼ck. \\(\\square\\)\n\n\n\nWir zÃ¤hlen, wie oft der Wasseranteil weniger als 50% betrÃ¤gt.\n\n\nCode\nsamples_6w_9v %&gt;%\n  count(p_grid &lt; .5) \n\n\n\n  \n\n\n\n\nNatÃ¼rlich gibt es verschiedene Wege, die gleiche Frage zu beantworten.\n\n\nCode\nbayesbox_6w_9v %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n\n  \n\n\n\n\n\n\nBeispiel 7.2 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\nWir zÃ¤hlen die Stichproben, die diesen Kriterien entsprechen.\n\n\nCode\nsamples_6w_9v %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n\n  \n\n\n\n\nğŸ¤– Ich wÃ¼rde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.\n\n\nğŸ‘¨â€ğŸ« Das wollte ich auch gerade sagenâ€¦\n\n\n\nCode\nsamples_6w_9v %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n\n  \n\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden.\n\n\nCode\nsamples_6w_9v %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n\n  \n\n\n\nFertig ğŸ˜„ \\(\\square\\)\n\n\nBeispiel 7.3 (Wasseranteil zwischen 90& und 100%?) Noch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nSyntaxOutput\n\n\n\n\nCode\nsamples_6w_9v %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt. \\(\\square\\)\n\n\nÃœbungsaufgabe 7.3 (Wasseranteil hÃ¶chstens 50%?) Â \n\nğŸ‘©â€ğŸ”¬ Mit welcher Wahrscheinlichkeit ist der Planet hÃ¶chstens zur HÃ¤lfte mit Wasser bedeckt?\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v %&gt;% count(p_grid &lt;= .5)\n\n\n\n  \n\n\n\n\n\n\n\nWir kÃ¶nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem â€œGipfelâ€ des Berges, s. AbbildungÂ 7.3.\nFÃ¼r unsere Stichproben-Postverteilung, samples_6w_9v, s. AbbildungÂ 7.1, lÃ¤sst sich der Modus so berechnen:\n\n\nCode\nmap_estimate(samples_6w_9v$p_grid)  \n\n\n\n  \n\n\n\nDabei steht map fÃ¼r Maximum Aposteriori, also das Maximum der Post-Verteilung.\n\nÃœbungsaufgabe 7.4 Bei der Gelegenheit kÃ¶nnten wir folgende, Ã¤hnliche Fragen stellen:\n\nWas ist der mittlere SchÃ¤tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane SchÃ¤tzwert (Median)?\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n\n  \n\n\n\n\n\n\n\n\n\n7.4.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervalle7.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit.) Wir mÃ¶chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist. Diese Frage kÃ¶nnen wir mit dem Befehl quantile beantworten.\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n\n  \n\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren, s. AbbildungÂ 7.3.\n\n\n\n\n\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n\n  \n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\nÃœbungsaufgabe 7.5 (Welcher Parameterwert ist der wahrscheinlich grÃ¶ÃŸte?) Ãœbersetzen wir â€œwahrscheinlichâ€ grÃ¶ÃŸte in â€œmit einer Wahrscheinlichkeit von 99% gibt es keinen grÃ¶ÃŸerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  summarise(quant99 = quantile(p_grid, p = .99))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der hÃ¶chste zu erwartende Wasseranteil 0.9.\n\n\n\n\n\nÃœbungsaufgabe 7.6 (Welcher Parameterwert ist der wahrscheinlich kleinste?) Ãœbersetzen wir â€œwahrscheinlichâ€ kleinste in â€œmit einer Wahrscheinlichkeit von 99% gibt es keinen kleinerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .01))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 â€“ immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\nÃœbungsaufgabe 7.7 (Welcher Parameterwert ist der â€œvermutlichâ€ kleinste?) In der â€œwirklichenâ€ Welt sind Aussagen nicht immer prÃ¤zise. Sagen wir, die Chefin der WeltraumbehÃ¶rde hat in einem Presse-Statement von der â€œvermutlichen Untergrenzeâ€ hinsichtlich des Wasseranteils gesprochen.\nÃœbersetzen wir â€œvermutlichâ€ kleinste in â€œmit einer Wahrscheinlichkeit von 90% gibt es keinen kleinerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .1))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 â€“ immer auf Basis unserer beobachteten Daten und der Vorannahmen.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#visualisierung-der-verteilungen",
    "href": "0600-Post.html#visualisierung-der-verteilungen",
    "title": "7Â  Die Post befragen",
    "section": "7.5 Visualisierung der Verteilungen",
    "text": "7.5 Visualisierung der Verteilungen\n\n7.5.1 Perzentilintervalle\n\nDefinition 7.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die â€œabzuschneidendeâ€ Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle (PI) oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. AbbildungÂ 7.5, rechtes Teildiagramm.8 \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\n\n\n(b) Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\nAbbildungÂ 7.5: Perzintilintervalle\n\n\n\nDas 10%, 20%, â€¦ 100%-Quantil9 (auf Basis von samples_k100) sind in AbbildungÂ 7.6 illustriert.\n\n\n\n\n\n\nAbbildungÂ 7.6: Quantile in 10%-Schritenn durch die Verteilung von samples_k100\n\n\n\n\n\n7.5.2 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nNoch einmal zum Globusversuch: Gehen wir von 3 WÃ¼rfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe), s. ListingÂ 7.4 mit dem Objekt d_33.\n\n\n\n\nListingÂ 7.4: Schiefe Post-Verteilung in einer Bayesbox\n\n\n\nCode\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e6, \n                 weight_by = post_33, \n                 replace = T)\n\n\n\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\n\n\n\n\n0.99\n1\n0.97\n0.97\n\n\n0.63\n1\n0.25\n0.25\n\n\n1.00\n1\n1.00\n1.00\n\n\n0.94\n1\n0.83\n0.83\n\n\n0.27\n1\n0.02\n0.02\n\n\n0.73\n1\n0.39\n0.39\n\n\n\n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\nHier z.B. ein 50%-Perzentilintervall, s. Abb. AbbildungÂ 7.7, a).\n\n\n\n\n\n\n\n\n\n\n\n(a) Perentilintervall (PI)\n\n\n\n\n\n\n\n\n\n\n\n(b) HÃ¶chste-Dichte-Intervall (HDI)\n\n\n\n\n\n\n\nAbbildungÂ 7.7: Schiefe Intervalle: Das PI enthÃ¤lt den wahrscheinlichsten Parameterwert nicht, das HDI schon.\n\n\n\nEin Perzentilintervall kann, wenn es dumm lÃ¤uft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zurÃ¼ckweisen. Das ist nicht so toll.\nEin Highest-Density-Intervall (HDI10) ist schmÃ¤ler als der Perzintilintervall und enthÃ¤lt immer den wahrscheinlichsten Parameterwert.\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. mit dem Befehl eti ausgeben lassen.\n\n\nCode\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)  # Paket `easystats`\n\n\n\n\n\n\n  \n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n7.5.3 Intervalle hÃ¶chster Dichte\n\nDefinition 7.2 (Intervalle hÃ¶chster Dichte (Highest Density Intervals)) Intervalle hÃ¶chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schmÃ¤lste Intervall, das den gesuchten Parameter enthÃ¤lt (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht, s. AbbildungÂ 7.7. Bei einem HDI sind die abgeschnitten RÃ¤nder nicht mehr gleich groÃŸ, im Sinne von enthalten nicht (zwangslÃ¤ufig) die gleiche Wahrscheinlichkeitsmasse. Beim PI ist die Wahrscheinlichkeitsmasse in diesen RÃ¤ndern hingegen gleich groÃŸ.\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt), s. Abb. AbbildungÂ 7.8.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.8: Visualisierung der PunktschÃ¤tzer bei einer schiefen Post-Verteilung\n\n\n\n\n\nMit dem Befehl hdi kann man sich die Grenzwerte eines HDI, z.B. eines 50%-HDI, ausgeben lassen, s. TabelleÂ 7.4.\n\n\nCode\nsamples_6w_9v %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\n\nTabelleÂ 7.4: 50%-HDI fÃ¼r unser Globusmodell (samples_6w_9v)\n\n\n\n\n  \n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI).",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "7Â  Die Post befragen",
    "section": "7.6 Fazit",
    "text": "7.6 Fazit\n\n7.6.1 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich oder identisch\nPerzentilintervalle sind verbreiteter\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n7.6.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datensatz samples_6w_9v, s. ListingÂ 7.3. Sagen wir, wir haben 6 Treffer bei 9 WÃ¼rfen erzielt.\nLageparameter: Welchen mittleren Wasseranteil kann man erwarten?\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n\n  \n\n\n\nStreuungsparameter: Wie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler\n\n\n\n  \n\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel fÃ¼r einen Parameter, einer unbekannten GrÃ¶ÃŸes eines Modells.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "7Â  Die Post befragen",
    "section": "7.7 Aufgaben",
    "text": "7.7 Aufgaben\n\n7.7.1 Papier-und-Bleistift-Aufgaben\n\n\nkekse03\nbfi10\nKaefer2\nmtcars-post2a\nrethink3e1-7-paper\nmtcars-post3a\nmtcars-post3a\nmtcars-post_paper\nfattails1\nfattails2\neti-hdi\n\n\n\n7.7.2 Aufgaben, bei denen man einen Computer benÃ¶tigt\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nReThink3e1-7\nWeinhaendler\nRethink3m1\nRethink3m2\ngroesse2\ngroesse1\nAnteil-Apple\nKung-height\nzwielichter-dozent-bayes",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "7Â  Die Post befragen",
    "section": "7.8 -",
    "text": "7.8 -\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#footnotes",
    "href": "0600-Post.html#footnotes",
    "title": "7Â  Die Post befragen",
    "section": "",
    "text": "Die Anzahl der Gitterwerte ist nicht Teil des Modells, streng genommen; die Anzahl der Gitterwerte entscheiden nur Ã¼ber die Genauigkeit der Post-Verteilung.â†©ï¸\nAlternativ kann man auf die Funktion Ã¼ber das R-Paket {prada} zugreifen.â†©ï¸\nModellparameter genanntâ†©ï¸\nVorsicht beim Ausdrucken.â†©ï¸\nauch Grid-Methode genanntâ†©ï¸\nEine gute EinfÃ¼hrung in die HintergrÃ¼nde findet sich bei McElreath (2020).â†©ï¸\nTatsÃ¤chlich gibt es eine Vielzahl an Begriffen, die in der Literatur nicht immer konsistent verwendet werden, etwa KompatibilitÃ¤tsintervall, Ungewissheitsintervall, Passungsbereich.â†©ï¸\nHier auf Basis der Post-Verteilung samples_6w_9v.â†©ï¸\nd.h. die Dezileâ†©ï¸\nAuch als Highest Hensity Posterior Interval (HDPI) bezeichnet.â†©ï¸",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html",
    "href": "0800-gauss.html",
    "title": "8Â  Gauss-Modelle",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "8Â  Gauss-Modelle",
    "section": "",
    "text": "8.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nein GauÃŸmodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n8.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.1 bis 4.3.\n\n\n8.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œModellgÃ¼teâ€\nStatistik1, Kap. â€œPunktmodelle 2â€\nStatistik1, Abschnitt â€œNormalverteilungâ€\n\n\n\n8.1.5 BenÃ¶tigte R-Pakete\nFÃ¼r rstanarm wird ggf. weitere Software benÃ¶tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, mÃ¼ssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio mÃ¼ssen Sie die (benÃ¶tigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Modelle berechnen\nlibrary(easystats)  # Statistik-Komfort\nlibrary(DataExplorer)  # Daten verbildlichen\nlibrary(ggpubr)  # Daten verbildlichen\nlibrary(hexbin)  # stat_bin_hex ggplot2\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nAb diesem Kapitel benÃ¶tigen Sie das R-Paket rstanarm. \\(\\square\\)\n\n\n\n\n8.1.6 BenÃ¶tigte Daten\nWir benÃ¶tigen den Datensatz !Kung. Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\n\n\nCode\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nkung &lt;- read.csv(Kung_path) \n\nhead(kung)\n\n\n\n  \n\n\n\nDatenquelle\n Download \n\n\n8.1.7 Einstieg\n\nBeispiel 8.1 (Was war noch mal eine Normalverteilung?) In diesem Kapitel benÃ¶tigen Sie ein gutes VerstÃ¤ndnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! \\(\\square\\)\n\n\nBeispiel 8.2 (Was war noch mal eine Posteriori-Verteilung?) In diesem Kapitel befragen wir die Post-Verteilung fÃ¼r ein normalverteilte Zufallsvariable, nÃ¤mlich die KÃ¶rpergrÃ¶ÃŸe der !Kung San. Was war noch mal eine Post-Verteilung und wozu ist sie gut? \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-groÃŸ-sind-die-kung-san",
    "href": "0800-gauss.html#wie-groÃŸ-sind-die-kung-san",
    "title": "8Â  Gauss-Modelle",
    "section": "8.2 Wie groÃŸ sind die !Kung San?",
    "text": "8.2 Wie groÃŸ sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. ?fig-kungs.\n\nThe ÇƒKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names ÇƒKung (ÇƒXun) and Ju are variant words for â€˜peopleâ€™, preferred by different ÇƒKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of ÇƒKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\nWir interessieren uns fÃ¼r die GrÃ¶ÃŸe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als kung_erwachsen.\n\n\nCode\nkung_erwachsen &lt;- kung %&gt;% \n  filter(age &gt;= 18)\n\nnrow(kung_erwachsen)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tatsÃ¤chlich recht easy, s. TabelleÂ 8.1.\n\n\nCode\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelleÂ 8.1: Statistiken der metrischen Variablen im Kung-Datensatz\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\nâˆ’0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\nâˆ’0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\nâˆ’0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\nâˆ’2.00\n352.00\n0\n\n\n\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus {DataExplorer}), s. AbbildungÂ 8.1.\n\n\nCode\nplot_density(kung_erwachsen)\n\n\n\n\n\n\n\n\nAbbildungÂ 8.1: Verteilungen der Variablen im Kung-Datensatz. GrÃ¶ÃŸe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n\n\n\n8.2.2 Wir gehen apriori von normalverteilter GrÃ¶ÃŸe Der !Kung aus\nForschungsfrage: Wie groÃŸ sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also fÃ¼r den Mittelwert der KÃ¶rpergrÃ¶ÃŸe (erwachsene Person1), \\(\\mu\\).\n\n\n\nMensch, Wikimedia Commons2\n\n\nWir sind uns Ã¼ber diesen Mittelwert in der Population nicht sicher3, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178 cm und Streuung von 20 cm, s. GleichungÂ 8.1.\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{8.1}\\]\nGleichungÂ 8.1 definiert ein Modell: Unsere Vorstellung der mittleren (â€œtypischenâ€) KÃ¶rpergrÃ¶ÃŸe der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.4 In einer echten Untersuchung sollte man einen inhaltlichen Grund fÃ¼r einen Priori-Wert haben. Oder man wÃ¤hlt â€œschwach informativeâ€ Prioris, wie das {rstanarm} tut: Damit lÃ¤sst man kaum Vorab-Information in das Modell einflieÃŸen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern bei der KÃ¶rpergrÃ¶ÃŸe).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der KÃ¶rpergrÃ¶ÃŸen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. DarÃ¼ber hinaus ist eine Normalverteilung nicht unplausibel.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "8Â  Gauss-Modelle",
    "section": "8.3 Unser Gauss-Modell der !Kung",
    "text": "8.3 Unser Gauss-Modell der !Kung\nğŸ“º Teil 1\n\n8.3.1 Modelldefinition\nWir nehmen an, dass die mittleren GrÃ¶ÃŸen, \\(\\mu\\), und die tatsÃ¤chlichen GrÃ¶ÃŸen, \\(h_i\\), normalverteilt sind und \\(\\sigma\\) exponentialverteilt ist (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior fÃ¼r den Parameter \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior fÃ¼r den Parameter \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn AbbildungÂ 8.2 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\n\n\n\n\n\n\n(a) Priori der mittleren KÃ¶rpergrÃ¶ÃŸe\n\n\n\n\n\n\n\n\n\n\n\n(b) Priori der SchÃ¤tzungenauigkeit\n\n\n\n\n\n\nAbbildungÂ 8.2: Prioris unseres (ersten) Kung-Modells (m_kung)\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDieses Modell hat zwei Parameter, \\(\\mu\\) und \\(\\sigma\\). \\(\\square\\)\n\n\n\n\n8.3.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie KÃ¶rpergrÃ¶ÃŸen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})   \\qquad{\\text{Likelihood}}\\]\n\n\n8.3.3 Prioris der Parameter\nDer Mittelwert der KÃ¶rpergrÃ¶ÃŸe sei normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)} \\qquad{\\text{Prior}}\\]\nDie Streuung \\(\\sigma\\) der GrÃ¶ÃŸen sei exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)} \\qquad{\\text{Prior}}\\]\n\n\n8.3.4 m_kung: fertig!\nJetzt haben wir unser Modell (m_kung) definiert!\nWeil es so schÃ¶n ist, schreiben/zeichnen wir es hier noch einmal auf, GleichungÂ 8.2, AbbildungÂ 8.3.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) & \\text{Likelihood}  \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) & \\text{Prior} \\\\\n\\sigma &\\sim \\mathcal{E}(1/8) & \\text{Prior}\n\\end{aligned}\n\\tag{8.2}\\]\n\n\n\n\n\n\nAbbildungÂ 8.3: Modellschema fÃ¼r das Modell m_kung\n\n\n\nZur Berechnung von m_kung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich krÃ¤ftig der Bursche, der soll die Arbeit fÃ¼r uns tun. Der Golem hÃ¶rt auf den Namen rstanarm5.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#zufÃ¤llige-motivationsabschnitt",
    "href": "0800-gauss.html#zufÃ¤llige-motivationsabschnitt",
    "title": "8Â  Gauss-Modelle",
    "section": "8.4 ZufÃ¤llige Motivationsabschnitt",
    "text": "8.4 ZufÃ¤llige Motivationsabschnitt\n\n\n\nGut gemacht!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m_kung",
    "href": "0800-gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m_kung",
    "title": "8Â  Gauss-Modelle",
    "section": "8.5 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m_kung",
    "text": "8.5 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m_kung\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m_kung6.\n\n\nCode\n1m_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)\n2m41_post &lt;- as_tibble(m_kung)\n3names(m41_post) &lt;- c(\"mu\", \"sigma\")\n\n\n\n1\n\nBayes-Regressionsmodell berechnen\n\n2\n\nModellergebnis in Tabelle umwandeln\n\n3\n\nSchÃ¶nere Namen fÃ¼r die Spalten geben\n\n\n\n\nDas Argument refresh = 0 ist nur eine Nebensache, aber es ist praktisch, da es verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrÃ¼cke. stan_glm7 ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein â€œrichtigesâ€ Regressionsmodell. Man kÃ¶nnte sagen, wir haben eine AV (KÃ¶rpergrÃ¶ÃŸe), aber keine UV (keine PrÃ¤diktoren). GlÃ¼cklicherweise kÃ¶nnen wir auch solche â€œarmenâ€ Regressionsmodelle formulieren: av ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen mÃ¶chte, aber keine PrÃ¤diktoren hat (das soll die 1 symbolisieren). FÃ¼r das Modell m_kung haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung (defaults) der Prioris von rstanarm zurÃ¼ck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wÃ¤re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die gemeinsame Posteriori-Verteilung von m_kung, s. AbbildungÂ 8.4\n\nFliesendiagrammStreudiagrammHistogramm\n\n\nGemeinsame Post-Verteilung von Mittelwert und Streuung\n\n\nCode\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\n\n\n\nAbbildungÂ 8.4: Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m_kung_neue_prioris\n\n\n\n\n\nDa das Modell zwei Parameter hat, kÃ¶nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen kÃ¶nnen die Parameter korreliert sein.\nAbbildungÂ 8.4 erlaubt uns, fÃ¼r jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\n\n\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m_kung_neue_prioris, s. AbbildungÂ 8.5.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.5: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\n\n\n\nUnd hier kommt die Post-Verteilung nur des Mittelwerts.\nNatÃ¼rlich kÃ¶nnen wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. AbbildungÂ 8.6.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.6: Die Post-Verteilung von mu in m_kung_neue_prioris; ein Balkendiagramm bietet sich an.\n\n\n\n\n\n\n\n\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung fÃ¼r \\(\\mu\\) und eine fÃ¼r \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, fÃ¼r die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte fÃ¼r \\(\\mu\\) und \\(\\sigma\\) klein: Die groÃŸe Stichprobe hat die Priori-Werte Ã¼berstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so kÃ¶nnen wir interessante Fragen stellen.\n\n\n8.5.1 Hallo, Posteriori-Verteilung\nâ€¦ wir hÃ¤tten da mal ein paar Fragen an Sie. ğŸ•µ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person grÃ¶ÃŸer als 1,55m?\nWelche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?\nWas ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?\n\nAntworten folgen etwas weiter unten.\nAbschlieÃŸend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), AbbildungÂ 8.7.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.7: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen fÃ¼r mu und fÃ¼r sigma\n\n\n\n\n\n\n\n8.5.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() kÃ¶nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - Ã¤hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurÃ¼ck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so: stan_glm(AV ~ UV, data = meine_daten).\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum GrÃ¶ÃŸenmittelwert (von Stan Ã¼bernommen)\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der GrÃ¶ÃŸen (von Stan Ã¼bernommen)\n\n\n8.5.3 Ausgabe von stan_glm()\nWir kÃ¶nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir kÃ¶nnen es aber auch komfortabler haben â€¦ Mit dem Befehl parameters kann man sich die geschÃ¤tzten Parameterwerte einfach ausgeben lassen (s. AbbildungÂ 8.4).\n\n\nCode\nm_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)  # aus Paket rstanarm\n\nparameters(m_kung)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem schÃ¤tzt den GrÃ¶ÃŸenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.76 bis 155.41 schÃ¤tzt. Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu spÃ¤ter mehr.\n\n\n\n\n\n\nHinweis\n\n\n\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren ğŸ¤“ Wer NÃ¤heres wissen will, findet hier einen Anfang. AuÃŸerdem sei an McElreath (2020) und Gelman et al. (2021) verwiesen. \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "8Â  Gauss-Modelle",
    "section": "8.6 Wie tickt stan_glm()?",
    "text": "8.6 Wie tickt stan_glm()?\n\n\n Quelle\n\nHier ein paar Kerninfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan fÃ¼r uns bereit.\nstan_glm() ist fÃ¼r die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schÃ¤tzen, so hat man man â€¦ eine Regression ohne PrÃ¤diktor.\nEine Regression ohne PrÃ¤diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also fÃ¼r die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\n\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n8.6.1 SchÃ¤tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die GrÃ¶ÃŸen, fÃ¼r die wir eine Priori-Verteilung annehmen. AuÃŸerdem wÃ¤hlen wir einen einen Likelihood-Funktion, so dass wir die Likelihood berechnen kÃ¶nnen. Auf dieser Basis schÃ¤tzen wir dann die Post-Verteilung. Ich sage schÃ¤tzen, um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren SchÃ¤tzungen) einfach mit parameters(modellname) auslesen.\n\n\n8.6.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, kÃ¶nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_kung:\n\n\nCode\npost_kung &lt;- as_tibble(m_kung)\nhead(post_kung)\n\n\n\n  \n\n\n\nIn einer Regression ohne PrÃ¤diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss Ã¼ber unsere SchÃ¤tzwerte zu \\(\\mu\\) (der KÃ¶rpergrÃ¶ÃŸe).\n\nÃœbungsaufgabe 8.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\n\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_kung %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlieÃŸen, dass die Kung im Schnitt grÃ¶ÃŸer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. \\(\\square\\)\n\n\n\n\n\nÃœbungsaufgabe 8.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_kung %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nOh, diese Hypothese kÃ¶nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlieÃŸen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschlieÃŸen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\n\n\nBeispiel 8.3 (Welche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell m_kung?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n  \n\n\n\n\n\n\n\n\nÃœbungsaufgabe 8.3 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  eti()\n\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\n\n\n\nÃœbungsaufgabe 8.4 (Mit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nCode\nm_kung %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nSeeing is believing, s. AbbildungÂ 8.8.\n\n\nCode\nm_kung %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nAbbildungÂ 8.8: Parameter von m_kung, nur einer: der Intercept\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren KÃ¶rpergrÃ¶ÃŸe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\n\n\n\nÃœbungsaufgabe 8.5 (Was ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\nparameters(m_kung) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n\n\n\nğŸ‹ï¸ Ã„hnliche Fragen bleiben als Ãœbung fÃ¼r die Lesis. ğŸ¤“\n\n\n8.6.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt fÃ¼r uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m_kung)\n## Priors for model 'm_kung' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden dafÃ¼r die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage fÃ¼r die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht â€œpures Bayesâ€, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte wÃ¤ren auch denkbar.\n\n\n\n\n\n\nStandardwerte von stan_glm\n\n\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (fÃ¼r \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals â€œStreuungâ€, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen. \\(\\square\\)\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wÃ¤hlen, dass man nicht Ã¼bergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlieÃŸen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflieÃŸen zu lassen und eigene Entscheidungen zu begrÃ¼nden. HÃ¤ufig sind mehrere Entscheidungen mÃ¶glich. MÃ¶chte man lieber vorsichtig sein, weil man wenig Ã¼ber den Gegenstand weiÃŸ, dann kÃ¶nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die â€œschwachinformativâ€ ist, also nur wenig Priori-Information in das Modell einflieÃŸen lÃ¤sst.\n\n\n\n\n8.6.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund fÃ¼r Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu zÃ¤hlen hat. AuÃŸerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister prÃ¼fen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier DurchfÃ¼hrungen (auch â€œKettenâ€ engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist â€œdumm gelaufenâ€. An dieser Stelle schauen wir uns die Ketten nicht nÃ¤her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. MÃ¶chte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit, s. m_kung_1kette.\n\n\nCode\nm_kung_1kette &lt;- stan_glm(height ~ 1, \n                 data = kung_erwachsen, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m_kung_1kette)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "title": "8Â  Gauss-Modelle",
    "section": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte",
    "text": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte\nğŸ“º Teil 2\nIm Modell m_kung haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflieÃŸen, in unserem zweiten Kung-Modell, m_kung_neue_prioris.\n\n8.7.1 m_kung_neue_prioris\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.8 Dieses Mal geben wir die Priori-Werte explizit an, TabelleÂ 8.2.\n\n\nCode\nm_kung_neue_prioris &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = kung_erwachsen)\nparameters(m_kung_neue_prioris)\n\n\n\n\n\n\nTabelleÂ 8.2: Parameter von m_kung_neue_prioris mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482\nNormal (178 +- 20)\n\n\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in TabelleÂ 8.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige FÃ¤higkeit im Studium. ğŸ¤“\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m_kung und m_kung_neue_prioris! Was fÃ¤llt Ihnen auf? Nichts? Gut! TatsÃ¤chlich liefern beide Modelle sehr Ã¤hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigermaÃŸen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gewÃ¤hlt waren.\n\n\n\n\n8.7.2 Posteriori-Verteilung und Parameter plotten\nLeider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zurÃ¼ck.\n\nğŸ‘¨â€ğŸ« BÃ¶ser Golem!\n\n\nğŸ¤– Beim nÃ¤chsten Mal strenge ich mich mehr an!\n\nDaher mÃ¼ssen wir die Ausgabe des Stan-Golemns erst in eine schÃ¶ne Tabelle umwandeln:\n\n\nCode\nm_kung_neue_prioris_tibble &lt;-\n  as_tibble(m_kung_neue_prioris)\n\nhead(m_kung_neue_prioris_tibble)\n\n\n\n  \n\n\n\nAuÃŸerdem ist der Name der ersten Spalte eigentlich unzulÃ¤ssig, da Spaltennamen in R nicht mit Sonderzeichen anfangen dÃ¼rfen (sondern mit Buchstaben). Daher mÃ¼ssen wir den Namen mit â€œSamthandschuhenâ€ anpacken. Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln mÃ¼ssen, s. die folgende Syntax.\n\nMit {ggpubr}Mit {ggplot}\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  gghistogram(x = \"`(Intercept)`\")  # Aus dem Paket \"ggpubr\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nAls Ausblick: Ein Vergleich mehrerer Priori-Werte wÃ¤re auch nÃ¼tzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewÃ¤hlten Priori-Werte zu Ã¼berzeugen.\n\n\n8.7.3 Welche KÃ¶rpergrÃ¶ÃŸen erwartet unser Modell\nBisher haben wir untersucht, wie die Verteilung der mittleren KÃ¶rpergrÃ¶ÃŸen, \\(\\mu\\), laut unserem Modell aussehen kÃ¶nnte; wir haben uns also mit der Post-Verteilung von \\(\\mu\\) beschÃ¤ftigt. Wir kÃ¶nnten aber auch an der Frage der Verteilung der tatsÃ¤chlichen KÃ¶rpergrÃ¶ÃŸen, \\(h_i\\), laut Modell, interessiert sein: Wie groÃŸ sind sie denn, die !Kung, laut unserem Modell?\nWie wir wissen, liefert unser Stan-Golem eine Stichproben-Postverteilung. Wenn wir das Ergebnisobjekt unserer Analyse, m_kung in eine Tabelle (Tibble) umwandeln und (die ersten paar Zeilen) betrachen, sehen wir diese Stichproben:\n\n\nCode\nm_kung |&gt; as_tibble() |&gt; head()\n\n\n\n  \n\n\n\nLaut unserem Modell sind die KÃ¶rpergrÃ¶ÃŸen, \\(h_i\\), normalverteilt mit \\(\\mu\\) und \\(\\sigma\\). \\(\\mu\\) wird von Stan, der in Begriffen der Regressionsanalyse denkt, schnÃ¶de als (Intercept) bezeichnet. Wir kÃ¶nnten jetzt also fÃ¼r jede Zeile eine Normalverteilung berechnen. Und daraus zufÃ¤llig eine Zahl ziehen. Damit hÃ¤tten wir dann unsere Verteilung von KÃ¶rpergrÃ¶ÃŸen laut Modell. Diese Verteilung nennt man auch Posterior-PrÃ¤diktiv-Verteilung. PrÃ¤diktiv daher, weil sie die Werte der KÃ¶rpergrÃ¶ÃŸen â€œvorhersagtâ€.\nWir kÃ¶nnen uns diese Verteilung auch komfortabel von R ausgeben lassen, s. AbbildungÂ 8.9.\n\nCode\npp_check(m_kung)\npp_check(m_kung, \"stat\")\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Die dunkle, dicke Dichtekurve zeigt die tatsÃ¤chliche Verteilung der KÃ¶rpergrÃ¶ÃŸen im Datensatz. Die hellen, leichten Dichtekurven zeigen die Verteilungen laut der Post-Verteilung unseres Modells.\n\n\n\n\n\n\n\n\n\n\n\n(b) Der wahre Wert einer Test-Statistik (T), hier der Mittelwert der KÃ¶rpergrÃ¶ÃŸen, wird mit der Verteilung der KÃ¶rpergrÃ¶ÃŸen in Bezug gesetzt.\n\n\n\n\n\n\n\nAbbildungÂ 8.9: Die Posterior-PrÃ¤diktiv-Verteilung: Die Verteilung der tatsÃ¤chlichen KÃ¶rpergrÃ¶ÃŸen auf Basis der Post-Verteilung. Unser Modell stellt die tatsÃ¤chliche Verteilung ganz gut nach.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "8Â  Gauss-Modelle",
    "section": "8.8 Fazit",
    "text": "8.8 Fazit\n\n\n8.8.1 Zusammenfassung\nWir haben die Posteriori-Verteilung fÃ¼r ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne PrÃ¤diktoren, betrachtet. Die Zielvariable, KÃ¶rpergrÃ¶ÃŸe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. FÃ¼r \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung fÃ¼r \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n8.8.2 Botschaft von einem Statistiker\n\n\n\nğŸ§¡ Bleiben Sie dran!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "href": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "title": "8Â  Gauss-Modelle",
    "section": "8.9 Vertiefung: Wahl der Priori-Werte",
    "text": "8.9 Vertiefung: Wahl der Priori-Werte\nğŸï¸ Dieser Abschnitt ist eine VERTIEFUNG und nicht prÃ¼fungsrelevant. ğŸ\n\n8.9.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\n\nğŸ’­ Was denkt der Golem (m_kung) apriori von der GrÃ¶ÃŸe der !Kung?\nğŸ¦¾ Ziehen wir mal ein paar Stichproben auf Basis des Modells. VoilÃ :\n\n\nCode\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MWÂ±3SD\",\n       x = \"GrÃ¶ÃŸe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\n\n\n\n\nQuellcode\n\n\n8.9.2 Priori-Werte prÃ¼fen mit der Priori-PrÃ¤diktiv-Verteilung\n\nDie Priori-PrÃ¤diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo kÃ¶nnen wir prÃ¼fen, ob die Priori-Werte vernÃ¼nftig sind.\n\nDie Priori-PrÃ¤diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an GrÃ¶ÃŸenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\n\nCode\nanteil_groÃŸer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_groÃŸer_kung\n\n\n\n  \n\n\n\nğŸ¤” Sehr groÃŸe Buschleute? 17 Prozent sind grÃ¶ÃŸer als 2 Meter. Das ist diskutabel, muss aber nicht zwangslÃ¤ufig ein schlechter Prior sein.\n\n\n8.9.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n\n\n\n\n8.9.4 Extrem vage Priori-Verteilung fÃ¼r die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\n\n\n\n\nDie Streuung der GrÃ¶ÃŸen ist weit:\n\n\nCode\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nğŸ¤” Das Modell geht apriori von ein paar Prozent Menschen mit negativer GrÃ¶ÃŸe aus. Ein Haufen Riesen ğŸ‘¹ werden auch erwartet.\nğŸ¤¯ Vage (flache, informationslose, â€œneutraleâ€, â€œobjektiveâ€) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "8Â  Gauss-Modelle",
    "section": "8.10 Aufgaben",
    "text": "8.10 Aufgaben\n\n8.10.1 Papier-und-Bleistift-Aufgaben\n\n\nexp-tab\nexp-tab2\nnorms-sd\nsmall-wide-normal\nexp1\ndistros\nmtcars-post_paper\ngroesse03\npupil-size2\ngroesse04\nReThink4e2\nPriorwahl1\n\n\n\n8.10.2 Aufgaben, fÃ¼r die man einen Computer benÃ¶tigt\n\nstan_glm01\nReThink4e1\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "8Â  Gauss-Modelle",
    "section": "8.11 â€”",
    "text": "8.11 â€”\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#footnotes",
    "href": "0800-gauss.html#footnotes",
    "title": "8Â  Gauss-Modelle",
    "section": "",
    "text": "Der Einfachheit halber gehen wir davon aus, dass MÃ¤nner und Frauen im Schnitt gleich groÃŸ sind.â†©ï¸\nBildquelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, 3.0â†©ï¸\nDarum machen wir hier ja die ganz Show!â†©ï¸\nDer Autor des zugrundeliegenden Lehrbuchs, Richard McElreath, gibt 178cm als seine KÃ¶rpergrÃ¶ÃŸe an.â†©ï¸\nHey, ich habe ihn diesen Namen nicht gegeben.â†©ï¸\nm wie Modell und 4, weil das Modell in Kapitel 4 von McElreath (2020) in Ã¤hnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.â†©ï¸\naus dem R-Paket rstanam, das zuvor installiert und gestartet sein muss, bevor Sie den Befehl nutzen kÃ¶nnenâ†©ï¸\nHey Stan, los, an die Arbeit!â†©ï¸",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html",
    "href": "0900-lineare-modelle.html",
    "title": "9Â  Einfache lineare Modelle",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "9Â  Einfache lineare Modelle",
    "section": "",
    "text": "9.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung fÃ¼r einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder StreuungsmaÃŸe und auch SchÃ¤tzintervalle - aus der Post-Verteilung herauslesen\nkÃ¼nftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4.\n\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 1â€\n\n\n\n9.1.5 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine Ãœbersicht aller Funktionen des Pakets.1\n\n\n9.1.6 BenÃ¶tigte Daten\nIn diesem Kapitel benÃ¶tigen wir den Datensatz zu den !Kung-Leuten, Howell1a, McElreath (2020). Sie kÃ¶nnen ihn hier herunterladen.\n Download \n\n\nCode\n1Kung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\n2kung &lt;- read.csv(Kung_path)\n\n3kung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\n\n\n1\n\nPfad zum Datensatz; Sie mÃ¼ssen online sein, um die Daten herunterzuladen.\n\n2\n\nDaten einlesen\n\n3\n\nAuf Erwachsene Personen begrenzen (d.h. Alter &gt; 18)\n\n\n\n\n\n\n9.1.7 Einstieg\n\nBeispiel 9.1 (Grundkonzepte der linearen Regression) Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! \\(\\square\\)\n\n\nBeispiel 9.2 (Was ist eine Post-Verteilung und wozu ist sie gut?) ErklÃ¤ren Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. \\(\\square\\)\n\n\n\n9.1.8 Ãœberblick\nDieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die KÃ¶rpergrÃ¶ÃŸe auf das Gewicht zurÃ¼ckgefÃ¼hrt wird; also ein sehr eingÃ¤ngiges Modell.\nNeu ist dabei lediglich, dass die Parameter des Modells - \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) - jetzt Ã¼ber eine Post-Verteilung verfÃ¼gen. Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik. Die â€œnormaleâ€ Regression hat uns nur einzelne Werte fÃ¼r die Modellparameter geliefert (â€œPunktschÃ¤tzerâ€). Mit Bayes haben wir eine ganz Verteilung pro Parameter.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\nDie (einfache) Regression prÃ¼ft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhÃ¤ngen. Je mehr sie zusammenhÃ¤ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). HÃ¤ngen \\(X\\) und \\(Y\\) zusammen, heiÃŸt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).2\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X, UV) und GrÃ¶ÃŸe (Y, AV), AbbildungÂ 9.1.\n\nCode\nkung_erwachsen %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\nCode\nggscatter(kung_erwachsen,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\") \n\n\n\n\n\n\nMit ggplot2Mit ggpubr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.1: Der Zusammenhang zwischen Gewicht (X) und GrÃ¶ÃŸe (Y)\n\n\n\n\n\n9.2.2 Statistiken zum !Kung-Datensatz\nDie Daten kÃ¶nnen Sie hier herunterladen.\nTabelleÂ 9.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path &lt;- \"data/Howell1a.csv\"  \nkung &lt;- read_csv(Kung_path)  \n\nkung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelleÂ 9.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus TabelleÂ 9.1 abzulesen ist, betrÃ¤gt das mittlere KÃ¶rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n\n9.2.3 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n9.2.3.1 Gibt es fehlende Werte?\nNein, s. Abb. AbbildungÂ 9.2.\n\n\nCode\nkung_erwachsen %&gt;% plot_missing()\n\n\n\n\n\n\n\n\nAbbildungÂ 9.2: Fehlende Werte - fehlen.\n\n\n\n\n\n\n\n9.2.3.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. AbbildungÂ 9.3.\n\n\nCode\nkung_erwachsen %&gt;% plot_histogram()\n\n\n\n\n\n\n\n\nAbbildungÂ 9.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. AbbildungÂ 9.4.\n\n\nCode\nkung_erwachsen %&gt;% plot_bar()\n\n\n\n\n\n\n\n\nAbbildungÂ 9.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in AbbildungÂ 9.5 dargestellt.\n\n\nCode\nkung_erwachsen %&gt;% plot_correlation()\n\n\n\n\n\n\n\n\nAbbildungÂ 9.5: Korrelationsmatrix\n\n\n\n\n\n\nÃœbungsaufgabe 9.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(kung_erwachsen). \\(\\square\\)\n\n\n\n\n9.2.4 PrÃ¤diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (PrÃ¤diktor â€œzentrierenâ€, engl. to center). Wenn man den PrÃ¤diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\beta_0\\), einfacher zu verstehen. In einem Modell mit zentriertem PrÃ¤diktor (weight) gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit durchschnittlichem Gewicht an. WÃ¼rde man weight nicht zentrieren, gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman et al. (2021), Kap. 10.4, 12.2.\nMan zentriert eine Variable \\(X\\), indem man von \\(x_i\\) den Mittelwert \\(\\bar{x}\\) abzieht: \\(x_i - \\bar{x}\\).\n\n\nCode\nkung_zentriert &lt;-\n  kung_erwachsen %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\nMit Hilfe von center() aus {easystats} kann man sich das Zentrieren auch erleichtern.\n\n\nCode\nkung_zentriert &lt;- \n  kung_erwachsen %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\nâˆ’9\n\n\n137\n32\n65\n0\nâˆ’13\n\n\n\n\n\n\n\nWie man sieht, wird die Verteilung von weight durch die Zentrierung â€œzur Seite geschobenâ€: Der Mittelwert von weight_c (das zentrierte Gewicht) liegt jetzt bei 0, s. AbbildungÂ 9.6.\n\n\n\n\n\n\n\n\nAbbildungÂ 9.6: Das Zentrieren Ã¤ndert die Verteilungsform nicht, sondern â€œschiebtâ€ die Verteilung nur zur Seite\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass kung_zentriert die Tabelle mit zentriertem PrÃ¤diktor ist, nicht kung_erwachsen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-prÃ¤diktor",
    "href": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-prÃ¤diktor",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.3 Modell m_kung_gewicht_c: zentrierter PrÃ¤diktor",
    "text": "9.3 Modell m_kung_gewicht_c: zentrierter PrÃ¤diktor\nğŸ“º PrÃ¤diktoren zentrieren\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wÃ¤re wohl die KÃ¶rpergrÃ¶ÃŸe? Hm, Philosophie steht heute nicht auf der Tagesordnung. Da wÃ¤re es schÃ¶n, wenn wir die Daten so umformen kÃ¶nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum GlÃ¼ck geht das leicht: Wir zentrieren den PrÃ¤diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m_kung_gewicht_c\nFÃ¼r jede AusprÃ¤gung des PrÃ¤diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung fÃ¼r die abhÃ¤ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) fÃ¼r jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte fÃ¼r die Steigung \\(\\beta_1\\) und den Achsenabschnitt \\(\\beta_0\\) der Regressionsgeraden. AuÃŸerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der GrÃ¶ÃŸe (height) angibt; dieser Wert wird als exponentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\). TheoremÂ 9.1 stellt die Modelldefinition dar. ?fig-kruschke_regr_one_predctor zeigt, wie die drei Parameter zusammen die Likelihood definieren.\n\n\nTheorem 9.1 (Modelldefinition m_kung_gewicht_c) \\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}{\\beta_0} & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}{\\beta_1}  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\quad \\square\\]\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnitt (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ğŸ¤·\n\n\n\n\n9.3.2 Likelihood, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m_kung_gewicht_c ist Ã¤hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines â€œIndex-iâ€ am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern fÃ¼r jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\nâ€œDie Wahrscheinlichkeit, eine bestimmte GrÃ¶ÃŸe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))â€.\n\n\n\n9.3.3 Regressionsformel, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschÃ¤tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\beta_0\\) und \\(\\beta_1\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der PrÃ¤diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\nâ€œDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\beta_0\\) und \\(\\beta_1\\) mal \\(\\text{weight}_i\\)â€.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta_1\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\beta_0\\) gibt an, wie groÃŸ \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n9.3.4 Priori-Werte des Modells m_kung_gewicht_c\n\\[\\begin{align*}\n\\color{blue}\\beta_1 & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta_1  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen. \\(\\beta_0\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine â€œRegression ohne PrÃ¤diktorenâ€ berechnet haben. \\(\\sigma\\) ist uns schon als Parameter bekannt und behÃ¤lt seine Bedeutung aus dem letzten Kapitel. Da height nicht zentriert ist, der Mittelwert von \\(\\beta_0\\) bei 178 und nicht 0. \\(\\beta_1\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und GrÃ¶ÃŸe positiv (gleichsinnig) ist. Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.\n\n\n9.3.5 Prioris plus Daten gleich Post\n![Parameter ]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.4 Die Post-Verteilung befragen",
    "text": "9.4 Die Post-Verteilung befragen\nğŸ“º Post-Verteilung auslesen 1\nğŸ“º Post-Verteilung auslesen 2\n\n9.4.1 m_kung_starkes_beta1\nSagen wir, auf Basis gut geprÃ¼fter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. GleichungÂ 9.1. Dabei haben wir folgende Prioris gewÃ¤hlt:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{9.1}\\]\nWir nennen das Modell m_kung_starkes_beta13, s. ListingÂ 9.1.\n\n\n\nListingÂ 9.1: Modelldefinition von m_kung_starkes_beta1 in R\n\n\n\n\nCode\nm_kung_starkes_beta1 &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # beta 0\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = kung_zentriert)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die NachprÃ¼fbarkeit der Ergebnisse (â€œReproduzierbarkeitâ€) sichergestellt4. Welche Wert fÃ¼r seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung schÃ¤tzen.\n\n\n\n\n9.4.2 Mittelwerte von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. TabelleÂ 9.2.\n\n\n\nTabelleÂ 9.2: Parameter von m_kung_starkes_beta1\n\n\n\nCode\nparameters(m_kung_starkes_beta1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 9.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also grÃ¶ÃŸer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) Ã„hnliches wie der p-Wert in der Frequentistischen Statistik (Makowski et al., 2019).\n\nAm besten das Diagramm dazu anschauen, s AbbildungÂ 9.7.\n\n\nCode\nplot(p_direction(m_kung_starkes_beta1))\n\n\n\n\n\n\n\n\nAbbildungÂ 9.7: Diagramm zur Probability of Direction, Modell m_kung_starkes_beta1\n\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) grÃ¶ÃŸer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschÃ¤ftigen in diesem Kurs.\n\n\n9.4.3 Visualisieren der â€œmittlerenâ€ Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). Ãœberzeugen wir uns mit einem Blick in die Post-Verteilung von m_kung_starkes_beta1:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n\n  \n\n\n\nWir kÃ¶nnen z.B. ein LagemaÃŸ wie den Median hernehmen, um die â€œmittlereâ€ Regressionsgerade zu betrachten, s. AbbildungÂ 9.8.\n\nCode\nkung_zentriert %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") |&gt; plot()  # aus {easystats}\n\n\n\n\n\nMit ggplotMit easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. AbbildungÂ 9.8 (a). Mit â€œexpectationâ€ sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\n\n\n\n\n\n\n(a) Erwartete Werte des Modell m_kung_starkes_beta1, sprich, die Regressionsgerade\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.8\n\n\n\n\n\n9.4.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).5 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen kÃ¶nnen.\n\n9.4.4.1 LagemaÃŸe zu den Parametern\n\nWas ist die mittlere GrÃ¶ÃŸe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der SchÃ¤tzwert fÃ¼r den Zusammenhang von Gewicht und GrÃ¶ÃŸe? (\\(\\beta_1\\))\nWas ist der SchÃ¤tzwert fÃ¼r Ungewissheit in der SchÃ¤tzung der GrÃ¶ÃŸe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert fÃ¼r z.B: \\(\\beta_1\\)?\n\nEine nÃ¼tzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. TabelleÂ 9.2.\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m_kung_starkes_beta1, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm_kung_starkes_beta1_post &lt;- \n  m_kung_starkes_beta1 %&gt;% \n  as_tibble()\n\nm_kung_starkes_beta1_post %&gt;% \n  head()\n\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m_kung_starkes_beta1_post. Jetzt haben wir wieder eine schÃ¶ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen kÃ¶nnen. Eine Visualisierung zeigt gut sowohl Lage- als auch StreuungsmaÃŸe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. AbbildungÂ 9.9.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildungÂ 9.9: Die Postverteilung fÃ¼r den Parameter Gewicht (zentriert); die plausiblen Werte liegen zwischen 0.8 und 1.0 cm pro Kilogramm Gewicht\n\n\n\n\n\nAbbildungÂ 9.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den hÃ¤ufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. AbbildungÂ 9.10.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildungÂ 9.10: Die Post-Verteilung fÃ¼r den Parameter sigma, m_kung_starkes_beta1; die plausiblen Werte liegen zwischen 4.7 cm und 5.5 cm.\n\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. AbbildungÂ 9.11.\n\n\nCode\nm_kung_starkes_beta1_hdi &lt;- hdi(m_kung_starkes_beta1_post)  # analog mit eti(m_kung_starkes_beta1)\n\nplot(m_kung_starkes_beta1_hdi)\n\n\n\n\n\n\n\n\nAbbildungÂ 9.11: Die Parameter Gewicht (zentriert) und sigma des Modells m_kung_starkes_beta1\n\n\n\n\n\nErgÃ¤nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt. Den Parameter der Vorhersage-Genauigkeit, \\(\\sigma\\) bekommt man mit get_sigma:\n\n\nCode\nget_sigma(m_kung_starkes_beta1)\n## [1] 5.1\n## attr(,\"class\")\n## [1] \"insight_aux\" \"numeric\"\n\n\n\n\n\n9.4.5 StreuungsmaÃŸe zu den Parametern\n\nWie unsicher sind wir uns in den SchÃ¤tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebrÃ¤uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen StabilitÃ¤t.\n\n\n\n\n9.4.6 Ungewissheit von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung visualisiert\nAbbildungÂ 9.12 stellt die Ungewissheit der Post-Verteilung dar, in dem einige Stichproben aus der Post-Verteilung visualisiert werden.\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\n1010010001000000\n\n\nDie ersten 10 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 100 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 10000006 â€¦ okay, lassen wir es gut sein7.\n\n\n\n\n\nAbbildungÂ 9.12\n\n\n\nEinfacher ist die Visualisierung mit estimate_expectation, s. AbbildungÂ 9.13.\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildungÂ 9.13: SchÃ¤tzbereich fÃ¼r die bedingten mittleren KÃ¶rpergrÃ¶ÃŸe, also die Regressionsgerade mit Unsicherheitsintervall\n\n\n\n\n\n\n\n9.4.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten PrÃ¤diktor misst der Achsenabschnitt die mittlere GrÃ¶ÃŸe8.\n\n\n\nWelche mittlere GrÃ¶ÃŸe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht Ã¼berschritten?\nWelche mittlere GrÃ¶ÃŸe mit Wahrscheinlichkeit von 95% nicht unterschritten?\nVon wo bis wo reicht der innere 50%-SchÃ¤tzbereich der mittleren GrÃ¶ÃŸe?\n\nQuantile:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n  \n\n\n\n50%-PI:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  eti(ci = .5)\n\n\n\n  \n\n\n\n\n\n9.4.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe bei mind. 155 cm liegt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe hÃ¶chstens 154.5 cm betrÃ¤gt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.29.\n\n\n9.4.9 Typischer Bayes-Nutzer in Aktion\n\n\n\n\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.5 Post-Verteilung bedingt auf einen PrÃ¤diktorwert",
    "text": "9.5 Post-Verteilung bedingt auf einen PrÃ¤diktorwert\n\n9.5.1 Bei jedem PrÃ¤diktorwert eine Post-Verteilung fÃ¼r \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns fÃ¼r jeden beliebigen Wert des PrÃ¤diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m_kung_post, s. AbbildungÂ 9.14.\n\n\n\n\n\n\n\n\nAbbildungÂ 9.14: FÃ¼r jeden beliebigen PrÃ¤diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgewÃ¤hlten Gewichtswerten. Es ist jeweils die Wahrscheinlichkeitsverteilung fÃ¼r den vorhergesagten Y-Wert dargestellt (hier sind die Verteilungen zu groÃŸ dargestellt zur besseren Sichtbarkeit). B: FÃ¼r jeden beliebigen Gewichtswert (Y) bekommt man eine (auf den jeweiligen X-Wert bedingten) Post-Verteilung.\n\n\n\n\n\n\n\n9.5.2 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der KÃ¶rpergrÃ¶ÃŸe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche KÃ¶rpergrÃ¶ÃŸe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns Ã¼ber diesen Mittelwert?\nEtwas formaler ausgedrÃ¼ckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten PrÃ¤diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 &lt;-\n  m_kung_gewicht_c_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. AbbildungÂ 9.15.\n\n\nCode\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.15: Post-Verteilung der GrÃ¶ÃŸe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\n\nAnalog kÃ¶nnen wir fragen, wie groÃŸ wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns Ã¼ber diesen Mittelwert sind.\n50 kg, das sind 5 Ã¼ber dem Mittelwert, in zentrierten Einheiten ausgedrÃ¼ckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. TabelleÂ 9.3.\n\n\nCode\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\nTabelleÂ 9.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren GrÃ¶ÃŸe bei einem Gewicht von 50kg ist weiter â€œrechtsâ€ (Richtung hÃ¶here GrÃ¶ÃŸe) zentriert, s. AbbildungÂ 9.16.\n\n\nCode\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.16: Post-Verteilung der mittleren GrÃ¶ÃŸe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n\n9.5.3 LagemaÃŸe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der KÃ¶rpergrÃ¶ÃŸe.\nWas ist das 90% PI fÃ¼r \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %&gt;% \n  eti(ci = .9)\n\n\n\n  \n\n\n\nDie mittlere GrÃ¶ÃŸe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere GrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#fazit",
    "href": "0900-lineare-modelle.html#fazit",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.6 Fazit",
    "text": "9.6 Fazit\n\n9.6.1 Ausstieg\n\nBeispiel 9.3 (Fassen Sie das Wesentliche zusammen!) Schreiben Sie 5-10 SÃ¤tze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! \\(\\square\\)\n\n\n\n9.6.2 Vertiefung\nMcElreath (2020) bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. Kurz (2021) greift die R-Inhalte von McElreath (2020) auf und setzt sie mit Tidyverse-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen mÃ¶chte. Gelman et al. (2021) bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einer frequentistischen als auch aus einer Bayes-Perspektive.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.7 Aufgaben",
    "text": "9.7 Aufgaben\n\n9.7.1 Papier-und-Bleistift-Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nmtcars-post2a\nBed-Post-Wskt1\nmtcars-post3a \nregression1a\nregression1b\nRegression2\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\nLikelihood2\ninterpret-koeff\nbed-post-wskt1\n\n\n\n9.7.2 Computer-Aufgaben\n\nPost-befragen1\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-4",
    "href": "0900-lineare-modelle.html#section-4",
    "title": "9Â  Einfache lineare Modelle",
    "section": "9.8 â€”",
    "text": "9.8 â€”\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKurz, S. (2021). Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & LÃ¼decke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#footnotes",
    "href": "0900-lineare-modelle.html#footnotes",
    "title": "9Â  Einfache lineare Modelle",
    "section": "",
    "text": "Da es viele Funktionen sind, bietet es sich an mit Strg-F auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.â†©ï¸\n Datenquelle, McElreath (2020).â†©ï¸\nWer ist hier fÃ¼r die Namensgebung zustÃ¤ndig? Besoffen oder was?â†©ï¸\noder zumindest besser sichergestelltâ†©ï¸\nIn manchen LehrbÃ¼chern wird \\(\\beta_0\\) auch als \\(\\alpha\\) bezeichnet.â†©ï¸\n1e6â†©ï¸\nIm Standard beschert uns stan_glm() 4000 Stichproben.â†©ï¸\n\\(\\mu\\)â†©ï¸",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html",
    "href": "1050-Schaetzen-Testen.html",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "",
    "text": "10.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\nden Unterschied zwischen dem SchÃ¤tzen von Modellparametern und dem Testen von Hypothesen erlÃ¤utern\nVor- und Nachteile des SchÃ¤tzens und Testens diskutieren\nDas ROPE-Konzept erlÃ¤utern und anwenden\nDie GÃ¼te von Regressionsmodellen einschÃ¤tzen und berechnen\n\n10.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an Kruschke (2018).\n\n10.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 2â€\n\n10.1.5 R-Pakete\nIn diesem Kapitel werden die Ã¼blichen R-Pakete benÃ¶tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n10.1.6 BenÃ¶tigte Daten: Pinguine\nWir benÃ¶tigen in diesem Kapitel den Datensatz zu Pinguinen: penguins.\nSie kÃ¶nnen den Datensatz penguins entweder via dem Pfad importieren.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \nOder via dem zugehÃ¶rigen R-Paket.\n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\nBeide MÃ¶glichkeit sind okay.\n\n10.1.7 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\nâ€œLernen fÃ¼r die Klausur bringt etwas!â€\nâ€œWie viel bringt Lernen fÃ¼r die Klausur?â€\n\n\nBeispiel 10.1 Diskutieren Sie die epistemologische Ausrichtung sowie mÃ¶gliches FÃ¼r und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#schÃ¤tzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#schÃ¤tzen-oder-testen",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n10.2 SchÃ¤tzen oder Testen?",
    "text": "10.2 SchÃ¤tzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen testen: â€œDie Daten widerlegen die Hypothese (nicht)â€\n\nParameter schÃ¤tzen: â€œDer Effekt von X auf Y liegt zwischen A und Bâ€.\n\n\n10.2.1 Hypothesen testen\nHypothesen testende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann natÃ¼rlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 10.2 (â€œLernen erhÃ¶ht den PrÃ¼fungserfolgâ€) Die Hypothese Lernen erhÃ¶ht den PrÃ¼fungserfolg kann durch eine Studie und eine entsprechende Analyse grundsÃ¤tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts fÃ¼r den Klausurerfolg. 2) Die Daten unterstÃ¼tzen die Hypothese: Lernen erhÃ¶ht den PrÃ¼fungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den PrÃ¼fungserfolg mÃ¶glich. \\(\\square\\)\n\nDas Testen einer Hypothese kann zu drei Arten von Ergebnissen fÃ¼hren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\nğŸŸ¥ Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die GlaubwÃ¼rdigkeit der Hypothese gelitten.\nğŸŸ¢ Die Daten unterstÃ¼tzen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an GlaubwÃ¼rdigkeit gewonnen.\nâ“ Die Datenlage ist unklar; zum Teil unterstÃ¼tzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum SchlÃ¼sse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen prÃ¼fen ist binÃ¤r in dem Sinne, dass sie zu â€œSchwarz-WeiÃŸ-Ergebnissenâ€ fÃ¼hren (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine gÃ¤ngige Variante des Hypothesen testen1 ist das Testen der Hypothese â€œkein Effektâ€ (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n10.2.2 Beispiele fÃ¼r Nullhypothesen\n\nâ€œLernen bringt nichtsâ€\nâ€œFrauen und MÃ¤nner parken gleich schnell einâ€\nâ€œEs gibt keinen Zusammenhang von Babies und StÃ¶rchenâ€\nâ€œFrÃ¼her war es auch nicht besser (sondern gleich gut)â€\nâ€œBei Frauen ist der Anteil, derer, die Statistik mÃ¶gen gleich hoch wie bei MÃ¤nnernâ€ (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterstÃ¼tzen kann, da es die KomplexitÃ¤t reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht bestÃ¤tigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht bestÃ¤tigen (verifizieren) kann, hat groÃŸen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausgeÃ¼bt (Popper, 2013). Schlagend ist das Beispiel zur Hypothese â€œAlle SchwÃ¤ne sind weiÃŸâ€. Auch eine groÃŸe Stichprobe an weiÃŸen SchwÃ¤nen kann die Wahrheit der Hypothese nicht beweisen. SchlieÃŸlich ist es mÃ¶glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben. 2 Umgekehrt reicht die (zuverlÃ¤ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im bestÃ¤tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverlÃ¤ssiger, reprÃ¤sentativer Daten erscheint plausibel, dass Hypothesen sowohl bestÃ¤tigt als auch widerlegt werden kÃ¶nnen (Kruschke, 2018; Morey & Rouder, 2011). \\(\\square\\)\n\n\n\n10.2.3 Parameter schÃ¤tzen\nBeim Parameter schÃ¤tzen untersucht man, wie groÃŸ ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein â€œja/neinâ€, was beim Hypothesen testen der Fall ist.\nBeim Parameter schÃ¤tzen gibt es zwei Varianten:\n\nâš«ï¸ PunktschÃ¤tzung: Das SchÃ¤tzen eines einzelnen Parameterwerts, sozusagen ein â€œBest Guessâ€\nğŸ“ BereichsschÃ¤tzung: Das SchÃ¤tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das SchÃ¤tzen von Parameterns auch wie einen Hypothesentest verstehen: Ist ein bestimmter Wert, etwa die Null, nicht im SchÃ¤tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 10.3 Wie groÃŸ ist der SchÃ¤tzbereich fÃ¼r den Effekt des Parameter â€œGeschlechtâ€ auf das Gewicht von Pinguinen? Anders gefragt: Um welchen Wert sind mÃ¤nnliche Tiere im Schnitt schwerer als weibliche Tiere?\n\nCodedata(penguins, package = \"palmerpenguins\")\npenguins_nona &lt;-\n  penguins |&gt; drop_na(sex, body_mass_g)  # keine fehlenden Werte\n\nm_penguins_sex &lt;- \n  stan_glm(body_mass_g ~ sex, data = penguins_nona)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3862.94\n(3757.82, 3969.47)\n100%\n1.000\n4246\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n682.94\n(528.12, 833.63)\n100%\n1.000\n4468\nNormal (0.00 +- 4020.19)\n\n\n\n\n\nGrob gesagt sind mÃ¤nnliche Tiere ca. 500 g bis 800 g schwerer als weibliche Tiere im Schnitt, laut unserem Modell. \\(\\square\\)\n\n\nBeispiel 10.4 (ParameterschÃ¤tzen als Nullhypothesentest) Â \n\nForschungsfrage: Sind mÃ¤nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nTheoremÂ 10.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\nTheorem 10.1 (Nullhypothesentest) \\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0\\quad \\square\\]\n\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nCodem1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\n\nDann zÃ¤hlen wir einfach den Anteil der Stichproben in der Post-Verteilung fÃ¼r die UV sexmale, die einen Wert grÃ¶ÃŸer Null aufweisen:\n\nCodem1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert grÃ¶ÃŸer Null fÃ¼r sexmale, dass also weibliche Tiere leichter bzw. mÃ¤nnliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der fÃ¼r das Gegenteil spricht (das weibliche Tiere schwerer wÃ¤ren). Damit resÃ¼mieren wir, dass unser Modell 100% Wahrscheinlichkeit fÃ¼r die Hypothese einrÃ¤umt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der ParameterschÃ¤tzung ist die Nuanciertheit des Ergebnisses, die der KomplexitÃ¤t echter Systeme besser Rechnung trÃ¤gt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n10.3 ROPE: Bereich von â€œpraktisch Nullâ€",
    "text": "10.3 ROPE: Bereich von â€œpraktisch Nullâ€\nğŸ“º Teil 2\nNullhypothesen sind fast immer falsch, s. AbbildungÂ 10.1.\n\n\n\n\n\n\n\nAbbildungÂ 10.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman et al., 2021)\n\n\n10.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist.3\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht. ğŸ¤·â€â™€ï¸\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke, 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n10.3.2 â€œPraktischâ€ kein Unterschied: Das Rope-Konzept\nğŸ“º ROPE-Video\n\nBeispiel 10.5 (Beispiele fÃ¼r ROPE) Sagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g â€œvernachlÃ¤ssigbar wenigâ€ ist.\nEine findige GeschÃ¤ftsfrau entscheidet fÃ¼r ihre Firma, dass ein Umsatzunterschied von 100k Euro â€œpraktisch irrelevantâ€ sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese (bzw. â€œPraktisch-Null-Hypotheseâ€): \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt. Unter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroÃŸteil liegt innerhalb von Rope \\(\\rightarrow\\) Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nGroÃŸteil liegt auÃŸerhalb von Rope \\(\\rightarrow\\) Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nAnsonsten \\(\\rightarrow\\) keine Entscheidung\n\nMit â€œGroÃŸteilâ€ meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n10.3.3 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat. Ein vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die GrÃ¶ÃŸe des ROPE Â±5% der SD der AV. \\(\\square\\)\n\n\n\n10.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildungÂ 10.2: Die Entscheidungsregeln zum ROPE illustiert (Kruschke, 2018).\n\n\n\n\nAbbildungÂ 10.2 illustriert die Entscheidungsregel zum ROPE fÃ¼r mehrere Situationen (Kruschke, 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett auÃŸerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung mÃ¶glich; die Datenlage ist unklar.\n\n10.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erklÃ¤rt (m_penguins_species).\n\nCodem_penguins_species &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\n\nDen Rope berechnet man mit rope(model).\n\nCoderope(m_penguins_species)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir kÃ¶nnen daher fÃ¼r diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschlieÃŸende Entscheidung Ã¼ber die Hypothese mÃ¶glich.\nAber: Gentoo liegt zu 0% im Rope. FÃ¼r Gentoo kÃ¶nnen wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. ğŸ¨\n\n10.3.6 Visualisierung unserer Rope-Werte, m_penguins_species\nEin GroÃŸteil der Posteriori-Masse von m_penguins_species liegt nicht innerhalb des Rope. Aber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut, s. AbbildungÂ 10.3.\n\nCoderope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\nAbbildungÂ 10.3: Rope und HDI Ã¼berlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung fÃ¼r Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir kÃ¶nnen das Nullhypothese fÃ¼r Chinstrap nicht verwerfen, aber auch nicht bestÃ¤tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom â€œblauen Flussâ€ des Rope: Gentoo liegt auÃŸerhalb des Rope. Es gibt einen â€œsubstanziellenâ€ Unterschied, grÃ¶ÃŸer als das ROPE. Wir verwerfen die â€œPraktisch-Null-Hypotheseâ€ in diesem Fall.\n\n10.3.7 Finetuning des Rope\nWir kÃ¶nnen festlegen, was wir unter â€œpraktischer Ã„quivalenzâ€ verstehen, also die Grenzen des Ropes verÃ¤ndern. Sagen wir, 100 Gramm sind unsere Grenze fÃ¼r einen vernachlÃ¤ssigbaren Effekt, s. AbbildungÂ 10.4.\n\nCoderope(m_penguins_species, range = c(-100, 100))\nplot(rope(m_penguins_species, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 10.4: ROPE mit selber eingestellter Grenze von Â±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\nCoderope(m_penguins_species, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht fÃ¼r ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n10.3.8 Beantwortung der Forschungsfrage\nFÃ¼r die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. FÃ¼r Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellgÃ¼te",
    "href": "1050-Schaetzen-Testen.html#modellgÃ¼te",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n10.4 ModellgÃ¼te",
    "text": "10.4 ModellgÃ¼te\n\n10.4.1 Wozu ModellgÃ¼te?\nHat man ein Modell aufgestellt und geprÃ¼ft und Ergebnisse erhalten, mÃ¶chte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der ModellgÃ¼te. Diese Kennwerte zielen z.B. darauf ab, wie prÃ¤zise die Aussagen des Modells sind. Je prÃ¤ziser die Aussagen eines Modells, desto nÃ¼tzlicher ist es natÃ¼rlich. Bei einer ParameterschÃ¤tzung erhÃ¤lt man auch Informationen zur PrÃ¤zision der SchÃ¤tzung: Ist der SchÃ¤tzbereich schmal, so ist die SchÃ¤tzung prÃ¤zise (und vice versa). Allerdings kÃ¶nnte ein Modell aus mehreren ParameterschÃ¤tzungen bestehen, die unterschiedlich prÃ¤zise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur PrÃ¤zision, oder allgemeiner zur GÃ¼te des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebrÃ¤uchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n10.4.2 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt. - HÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt. \\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert. Solch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor. Daher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R^22\\) ausgeben lassen, s. AbbildungÂ 10.5.\n\nCodem_penguins_species_r2 &lt;-\n  m_penguins_species %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m_penguins_species_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 10.5: Die Verteilung von R-Quadrat im Modell m_penguins_species\n\n\n\n\n\\(R^2\\) und \\(\\sigma\\) sind negativ assoziert: In einem Datensatz mit mit hohem \\(R^2\\) ist \\(\\sigma\\) gering und umgekehrt. Beide Koeffizienten berechen sich auf Basis der Vorhersagefehler.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n10.5 Fazit",
    "text": "10.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der VorzÃ¼ge der ParameterschÃ¤tzung. MÃ¶chte man aber, um sich bestimmter bestehender Forschung anzunÃ¤hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n10.6 Aufgaben",
    "text": "10.6 Aufgaben\n\n10.6.1 Papier-und-Bleistift-Aufgaben\n\nrope-luecke\npenguins-rope\nWskt-Schluckspecht2\npenguins-stan-01a\nrope-regr\nrope1\nrope2a\nrope3a\npenguins-stan-04a\nstan_glm01a\npenguins-regr02a\npenguins-stan-02a\npenguins-stan-05a\n\n10.6.2 Computer-Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope2\nrope3\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter Values in Bayesian Estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270â€“280. https://doi.org/10.1177/2515245918771304\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes Factor Approaches for Testing Interval Null Hypotheses. Psychological Methods, 16(4), 406â€“419. https://doi.org/10.1037/a0024377\n\n\nPopper, K. (2013). Logik Der Forschung (H. Keuth, Hrsg.). Akademie Verlag. https://doi.org/10.1524/9783050063782",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#footnotes",
    "href": "1050-Schaetzen-Testen.html#footnotes",
    "title": "\n10Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "",
    "text": "vor allem in der Frequentistischen Statistikâ†©ï¸\nTatsÃ¤chlich gibt es schwarze SchwÃ¤ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swanâ†©ï¸\nMittlerweile gibt es neue Frequentistische AnsÃ¤tze fÃ¼r ein Verfahren Ã¤hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.â†©ï¸\n89 ist die nÃ¤chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert fÃ¼r SchÃ¤tzbereiche verwendet. Damit ist 95 hier eine â€œmagic numberâ€, ein Defacto-Standard ohne hinreichende BegrÃ¼ndung. Um darauf hinzuweisen, benutzen einige Forschis mit Ã¤hem subtilen Humor lieber die 89 als die 95. ğŸ¤·â€â™‚ï¸ â†©ï¸",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html",
    "href": "1000-metrische-AV.html",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "",
    "text": "11.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme Ã¼bersetzen\ntypische Forschungsfragen auswerten\n\n11.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman et al. (2021), Kap. 7 und 10.\n\n11.1.4 Vorbereitung im Eigenstudium\nFrischen Sie Ihr Wissen in den Grundlagen der einfachen und multiplen Regression (inkl. Interaktionseffekte) auf. Dazu sind z.B. folgende Literaturstellen geeignet.\n\nStatistik1, Kap. â€œGeradenmodelle 1â€\nStatistik1, Kap. â€œGeradenmodelle 2â€\n\n11.1.5 R-Pakete\nIn diesem Kapitel werden die Ã¼blichen R-Pakete benÃ¶tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n11.1.6 BenÃ¶tigte Daten\nWir benÃ¶tigen in diesem Kapitel folgende DatensÃ¤tze: kidiq, penguins.\n\n11.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\nCodedata(\"kidiq\", package = \"rstanarm\")\n\n\nAlternativ kÃ¶nnen Sie die Daten hier herunterladen.\n Download \n\n11.1.6.2 penguins\n\nSie kÃ¶nnen den Datensatz penguins entweder via dem Pfad importieren oder via dem zugehÃ¶rigen R-Paket. Beide MÃ¶glichkeit sind okay.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\n\n11.1.7 Einstieg\n\nBeispiel 11.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, mÃ¼ssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 11.2 (Was war noch einmal die Interaktion?) ErkÃ¤ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n11.1.8 Ãœberblick\nWenn Sie die Skalenniveaus wissen, kÃ¶nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und Ã¤hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, â€¦) lernen mÃ¼ssen. AuÃŸerdem ist die Regressionsanalyse (fÃ¼r viele Situationen) die beste Heransgehensweise, da sie viele MÃ¶glichkeiten fÃ¼r Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels gÃ¤ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. NatÃ¼rlich wÃ¼rzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-KÃ¼che. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "href": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.2 Taxonomie von Forschungsfragen",
    "text": "11.2 Taxonomie von Forschungsfragen\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus. Im Folgenden sind fÃ¼r die UV(s) nominale sowie metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind ebenfalls erlaubt.\nWir untersuchen in diesem Kapitel hÃ¤ufig verwendete Arten von Forschungsfragen mittels Regressionsanalysen. FÃ¼r jede Variante ist zumeist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abhÃ¤ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabhÃ¤ngige Variable (querschnittlich)\n\nb: binÃ¤re Variable\n\nx: metrische unabhÃ¤ngige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-b",
    "href": "1000-metrische-AV.html#y-b",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.3 y ~ b\n",
    "text": "11.3 y ~ b\n\n\n11.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im Ã¶ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwÃ¤ndigen Studie die Intelligenz vieler Kinder gemessen. ZusÃ¤tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, â€œRisikofaktorenâ€ fÃ¼r geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nIst der mittlere IQ-Wert (kid_score) von Kindern, deren jeweilige Mutter Ã¼ber einen Schlusabschluss (mom_hs, \\(x=1\\)) verfÃ¼gt hÃ¶her, als bei Kinderen, deren jeweilige Mutter nicht Ã¼ber einen Schulabschluss verfÃ¼gt (\\(x=0\\))? (ceteris paribus)4.\n\nDie Modellformel zur Forschungsfrage lautet: y ~  b bzw. kid_iq ~ mom_hs.\nFormaler ausgedrÃ¼ckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (TheoremÂ 11.1).\n\nTheorem 11.1 (Hypothese fÃ¼r ungleiche Mittelwerte) \\[H_A: \\mu_{x=0|M} \\ne \\mu_{x=1|M}\\quad \\square\\]\n\nIn Worten: â€œDer mittlere IQ-Wert fÃ¼r Kinder, deren MÃ¼tter Ã¼ber einen Schulabschluss verfÃ¼gen ist hÃ¶her als in der Gruppe von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss verfÃ¼genâ€. Zu beachten ist, dass sich eine Population immer auf Parameterwerte bezieht, also auf die Population, nicht auf die Statistiken der Stichprobe.\nDie zugehÃ¶rige Nullhypothese lautet:\n\\[H_0: \\mu_{x=1|M} = \\mu_{x=0|M}\\quad \\square\\]\n\n11.3.2 Modell\nDie Regressionsformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in AbbildungÂ 11.1 dargestellt. Y hat, laut unserem Modell, zwei Ursachen:\n\nmom_hs (b)\nu, das steht fÃ¼r â€œunbekanntâ€5\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.1: DAG fÃ¼r kid_iq ~ mom_hs\n\n\n\n\n\nCodedata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nDer Einfachheit halber Ã¼bernehmen wir die Prioriwerte von Stan, s. ListingÂ 11.1.\n\n\n\nListingÂ 11.1: Standard-Prioriwerte fÃ¼r m10.1, von Stan vergeben\n\nCodeprior_summary(m10.1)\n## Priors for model 'm10.1' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 87, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 87, scale = 51)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = 0, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 0, scale = 124)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.049)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\n\n\nDie komplette Modellspezifikation ist in GleichungÂ 11.1 aufgefÃ¼hrt.\n\\[\\begin{align*}\n\\text{kid score}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{Lineares Modell} \\\\\n\\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{Prior Regressionsgewicht} \\\\\n\\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{Prior VorhersagegÃ¼te}\n\\end{align*} \\tag{11.1}\\]\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. TabelleÂ 11.1.\n\n\n\nTabelleÂ 11.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt, da meistens nicht von hohem Interesse)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\n\n11.3.3 Interpretation der Koeffizienten\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss (mom_hs = 0) verfÃ¼gen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit MÃ¼tter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit MÃ¼tter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die SchÃ¤tzung (Vorhersage) ist bzw. wie stark PrÃ¤diktor (UV) und Kriterium (AV) zusammenhÃ¤ngen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tatsÃ¤chlichen IQ-Wert des Kindes (\\(y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n11.3.4 y ~ g als Mittelwertsdifferenz\nEin lineares Modell der Art y ~ g kann man als Berechnung des Unterschieds im Mittelwert von y zwischen beiden Gruppen (g0 vs.Â g1) verstehen.\n\nğŸ‘¨â€ğŸ« Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heiÃŸen kid_score_avg. An die Arbeit!\n\n\nğŸ¤– Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nCodekidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von MÃ¼ttern mit Abschluss.\n\n\n\nIn AbbildungÂ 11.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt, auf Basis des Datensatzes kidiq.\n\nCodeestimate_relation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.2: Kinder, deren MÃ¼tter Ã¼ber einen Schulabschluss verfÃ¼gen, haben im Mittel einen hÃ¶heren Intelligenztestwert, laut dem vorliegenden Modell. Die Regressionsgerade ist als durchgezogene Linie dargestellt. Die Mittelwerte pro Gruppe als Punkte und als gestrichelte, horizontale Linie.\n\n\n\n\n\n11.3.5 Rope\nPrÃ¼fen wir mit rope(m10.1), ob der Effekt der UV (Unterschied zwischen den Gruppen) â€œpraktisch Nullâ€ ist; dazu nutzen wir das ROPE-Verfahren.\n\nCoderope(m10.1)\n\n\n\n\n\n\n\n\n\n\nDas Ergebnis zeigt uns, dass es 0% Ãœberlappung vom Rope und dem 95%-HDI (der Posterior-Verteilung) gibt.\nFazit: Wir verwerfen die Praktisch-Null-Hypothese. Adios! AbbildungÂ 11.3 visualisiert die Erstreckung der Posteriori-Verteilung (und des 95%-HDI) sowie des Rope.\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.1) %&gt;% plot()\n\n\n\n\n\n\nAbbildungÂ 11.3: Rope und HDI Ã¼berlappen nicht. Wir verwerfen die Praktisch-Null-Hypothese.\n\n\n\n11.3.6 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation â€“ Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das prÃ¼ft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nAlternativ zum t-Test kann man â€“ unabhÃ¤ngig, ob man Frequentistisch oder Bayesianisch unterwegs ist â€“ mit einer Regression vom Typ y ~ b das in etwa gleiche Ergebnis erreichen.7\n\n11.3.7 Antwort auf die Forschungsfrage\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nCodem10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schÃ¶nere Namen\n\n\n\n\nHier sind die ersten paar Zeilen, s. TabelleÂ 11.2.\n\n\n\nTabelleÂ 11.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n76.1\n12.8\n19.7\n\n\n72.9\n17.5\n20.5\n\n\n79.0\n11.7\n20.5\n\n\n75.7\n13.7\n20.6\n\n\n77.0\n12.6\n20.0\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir zur Ãœbung ein 95%-PI von Hand; komfortabler geht es mit eti(m10.1), s. TabelleÂ 11.1.\n\nCodepi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlieÃŸend die Posteriori-Verteilung, s. AbbildungÂ 11.4.\n\nCodeplot(eti(m10.1))\n\n\n\n\n\n\nAbbildungÂ 11.4: Das 95% ETI zum (statistischen) Effekt des mÃ¼tterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem â€œEffektâ€ zu sprechen, lÃ¤sst in den meisten KÃ¶pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang. FÃ¼r eine Kausalaussage braucht man ein Argument, etwa einen Verweis auf bestehende Studien oder eine Theorie.\n\n\n\n\n\n\n\n\n\n\n11.3.8 Vertiefung: Toleranzbereich\nğŸï¸VERTIEFUNG, nicht prÃ¼fungsrelevantğŸï¸\nBerechnet man ein Regressionsmodell mit stan_glm (ğŸ¤–ğŸ˜), dann zieht man dabei Zufallszahlen ğŸ². Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zufÃ¤llig. Das erklÃ¤rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen kÃ¶nnen.\nUm zu prÃ¼fen, ob Ihre Ergebnisse â€œÃ¤hnlich genugâ€ oder â€œinnerhalb eines Toleranzbereichsâ€ sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nGrÃ¶ÃŸe des Toleranzbereichs\n\n\n\nDie GrÃ¶ÃŸe des relativen Toleranzbereichs ist in is_in_toleranzce() auf 5% festgelegt. Das heiÃŸt, ein Unterschied von 5% zwischen einem Referenzwert (dem â€œwahrenâ€ Wert) und Ihrem Wert ist okay, also im Toleranzbereich. AuÃŸerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der grÃ¶ÃŸere der beiden Werte gilt. \\(\\square\\)\n\n\nWenn Sie diese Funktion nutzen wollen, mÃ¼ssen Sie zunÃ¤chst das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN) und dann wie gewohnt starten.\n\nCodelibrary(remotes)  # dieses Paket kÃ¶nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\nlibrary(prada)\n\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der â€œrichtigeâ€ oder â€œwahreâ€ Wert (oder schlicht der Wert einer MusterlÃ¶sung) fÃ¼r \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nCodeis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. âœ…",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b",
    "href": "1000-metrische-AV.html#y-x-b",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.4 y ~ x + b\n",
    "text": "11.4 y ~ x + b\n\n\n11.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b bzw. kid_score ~ mom_iq + mom_hs.\nDie Hypothesen lauten:\n\nDer Schulabschluss der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momhs} &gt; 0\\).\nDer IQ der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momiq} &gt; 0\\).\n\nDer Kausalgraph8 zur Modellformel sieht aus in AbbildungÂ 11.5 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) EinflÃ¼sse, b und u, wobei u fÃ¼r â€œunbekanntâ€ steht, also fÃ¼r alle sonstigen EinflÃ¼sse.9\n\n\n\n\n\n\n\nAbbildungÂ 11.5: DAG fÃ¼r y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle TabelleÂ 11.3 dargestellt.\n\nCodedata(\"kidiq\")  # Paket rstanarm, alternativ Ã¼ber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\nTabelleÂ 11.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n11.4.2 1 metrischer PrÃ¤diktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. TabelleÂ 11.4.\n\nCodem10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\n\nTabelleÂ 11.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. AbbildungÂ 11.6.\n\nCodekidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildungÂ 11.6: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. AbbildungÂ 11.7.\n\nCodeplot(estimate_relation(m10.2))\n\n\n\n\n\n\nAbbildungÂ 11.7: Die geschÃ¤tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder fÃ¼r verschiedene IQ-Werte der MÃ¼tter. Vergleicht man Teilpopulationen von MÃ¼ttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n11.4.3 Beide PrÃ¤diktoren, m10.3\n\nBerechnen wir als nÃ¤chstes ein Modell mit beiden PrÃ¤diktoren: kid_score ~ mom_hs + mom_iq, s. TabelleÂ 11.5.\n\nCodem10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\nTabelleÂ 11.5: Parameter des Modells m10.3 (ohne sigma; ETI-Intervalle)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. PunktschÃ¤tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\nCodecoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##       25.74        0.57        6.04\n\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nMÃ¶chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\nCodecoef(m10.3)[3]\n## mom_hs \n##      6\n\n\nAber natÃ¼rlich ist es mÃ¶glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. AbbildungÂ 11.8.\n\nCodekidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\npred &lt;- estimate_relation(m10.3a)\nplot(pred)\n\n\n\n\n\n\nAbbildungÂ 11.8: Der Effekt von sowohl mÃ¼tterlicher Intelligenz als auch mÃ¼tterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schÃ¤tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum mÃ¼tterlichen Schulabschluss: Vergleicht man Kinder von MÃ¼ttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur mÃ¼tterlichen IQ: Vergleicht man Kinder von MÃ¼ttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n11.4.4 Antwort auf die Forschungsfrage\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 1.6 bis 10.1 IQ-Punkten, laut unserem Modell. Der Effekt des mÃ¼tterlichen IQs wird auf 0.5 bis 0.7 geschÃ¤tzt (95%-ETI). Da fÃ¼r beide UV die Null nicht im Intervall plausibler Werte liegt, kann ein Null-Effekt (die exakte Nullhypothese) abgelehnt werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b-xb",
    "href": "1000-metrische-AV.html#y-x-b-xb",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.5 y ~ x + b + x:b\n",
    "text": "11.5 y ~ x + b + x:b\n\n\n11.5.1 Forschungsfrage und Modelldefinition\n\nGibt es einen Interaktionseffekt zwischen mÃ¼tterlichem Schulabschluss und mÃ¼tterlichem IQ (auf den IQ-Wert des Kindes)?\n\nAuÃŸerdem ist man vermutlich auch an den Effekten der beiden UV auf die AV interessiert; diese Fragen haben wir im letzten Abschnitt untersucht (und greifen sie daher nicht noch mal ausfÃ¼hrlich auf).\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b. Der Einfachheit halber Ã¼bernehmen wir wieder die Prioris wie vom R-Paket rstanarm bereitgestellt.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 11.9 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.9: DAG fÃ¼r y ~ x + b + x:b\n\n\n\n\n\n11.5.2 Interaktion zur Modellformel hinzufÃ¼gen\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. ListingÂ 11.2, AbbildungÂ 11.10 und TabelleÂ 11.6.\n\n\n\nListingÂ 11.2: Die Modelldefition von m10.4 mit stanglm\n\nCodem10.4 &lt;- \n  stan_glm(kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\nIn der Regressionsformel sieht man, dass ein zusÃ¤tzlicher Parametern, eben der Interaktionseffekt, in das Modell aufgenommen wurde.\n\n\n\nTabelleÂ 11.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.68\n(-37.44, 15.92)\n77.12%\n1.000\n1338\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.000\n1340\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n50.36\n(21.58, 80.70)\n99.98%\n1.001\n1311\nNormal (0.00 +- 124.21)\n\n\nmom_iq:mom_hs\n-0.47\n(-0.79, -0.17)\n99.88%\n1.001\n1293\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_relation(m10.4) |&gt; plot() kann man sich das Modell visualisieren, s. AbbildungÂ 11.10.\n\n\n\n\n\n\n\nAbbildungÂ 11.10: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt fÃ¼r diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n11.5.3 Interpretation von m10.4\n\nAchsenabschnitt: IQ-SchÃ¤tzwerte fÃ¼r Kinder mit MÃ¼tter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit MÃ¼ttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten fÃ¼r mom_iq zwischen MÃ¼tter mit bzw. ohne Schulabschluss.\nFÃ¼r beide Gruppen, mom_hs=0 und mom_hs=1 gilt folgende Regressionsformel, s. GleichungÂ 11.2.\n\\[\\text{kid score} = \\beta_0 + \\beta_1 \\cdot \\text{mom hs} + \\beta_2 \\cdot \\text{mom iq} + \\beta_3 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.2}\\]\n\\(\\beta_3\\) gibt die StÃ¤rke des Interaktionseffekts an.\nAuf Errisch schreibt mit GleichungÂ 11.2 so (s. ListingÂ 11.2):\nkid_score ~ mom_iq + mom_hs + mom_hs:mom_iq.\nDer Doppelpunkt zwischen mom_hs und mom_iq steht fÃ¼r den Interaktionseffekt der beiden Variablen.\nTrÃ¤gt man die Werte der Koeffizienten (\\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\)) ein, so erhÃ¤lt man GleichungÂ 11.3.\n\\[\\text{kid score} = -10.7 + 50.4 \\cdot \\text{mom hs} + 1  \\cdot \\text{mom iq} + -0.5 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.3}\\]\nTeilen wir die Regressionsformel einmal auf die beiden Gruppen (mom_hs=0 bzw. mom_hs=1) auf:\nmom_hs=0:\nkid_score = -10.7 + 50.4*0 + 1*mom_iq  - -0.5*0*mom_iq\n          = -10 + 1.1*mom_iq\nmom_hs=1:\nkid_score = -10.7 + 50.4*mom_hs + 1*mom_iq  - -0.5*mom_hs*mom_iq\n          = -10 + 1.1*mom_iq\nNach der Interpretation von 20 unzentrierten Koeffizienten â€¦\n\n\n\nvia GIPHY\n\nWir mÃ¼ssen dringend die unzentrierten PrÃ¤diktoren loswerden â€¦\n\n11.5.4 Antwort auf die Forschungsfrage\nWie in TabelleÂ 11.6 ersichtlich, kann fÃ¼r alle drei Effekte (mÃ¼tterliche IQ, mÃ¼tterlicher Schulabschluss und Interaktion von mÃ¼tterlichem IQ mit mÃ¼tterlichem Schulabschluss) ein Nulleffekt ausgeschlossen werden. Ob die Effekte stÃ¤rker als â€œpraktisch Nullâ€ sind, kann mittels des ROPE-Verfahren untersucht werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "href": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.6 y ~ x_c + b + x_c:b\n",
    "text": "11.6 y ~ x_c + b + x_c:b\n\n\n11.6.1 Zentrieren von PrÃ¤diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq; die zentrierte Variable kennzeichnen wir durch den Suffix _c, also mom_iq_c.\nMan kÃ¶nnte auch mom_hs zentrieren, aber fÃ¼r eine einfache Interpretation ist es meist nÃ¼tzlich, nur metrische PrÃ¤diktoren zu zentrieren.\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\n\ncoef(m10.5)  # nur die PunktschÃ¤tzer fÃ¼r die Koeffizienten ausgeben\n\n\nTabelleÂ 11.7 zeigt die PunktschÃ¤tzer der Koeffizienten von m10.5.\n\n\n\nTabelleÂ 11.7: PunktschÃ¤tzer von m10.5 (zentrierte UV)\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.34\n\n\nmom_hs\n2.86\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n\n\n\n11.6.2 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den geschÃ¤tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten fÃ¼r mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nMit estimate_relation(m10.5) |&gt; plot() kann man sich das Modell visualisieren, s. AbbildungÂ 11.11.\n\n\n\n\n\n\n\nAbbildungÂ 11.11: m10.5: Mit zentrierten PrÃ¤diktoren gibt der Achsenabschnitt den Y-Wert fÃ¼r eine Beobachtung mit mittleren X-Wert an; daher ist der Achsenabschnitt besser zu interpretieren als ohne Zentrierung.\n\n\n\n\n\n11.6.3 Zentrieren Ã¤ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5: Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren Ã¤ndert auch nicht die zentrierten Regressionskoeffizienten, da die Streuungen dieser Variable nicht verÃ¤ndert wurden.\n\n11.6.4 Perzentilintervalle aus der Posterori-Verteilung\nTabelleÂ 11.8 zeigt die PunktschÃ¤tzer der Parameter fÃ¼r m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie dafÃ¼r parameters(m10.5), s. TabelleÂ 11.8.\n\n\n\nTabelleÂ 11.8: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(81.17, 89.61)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.80, 7.62)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. TabelleÂ 11.9.\n\nCodeparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelleÂ 11.9: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(80.96, 89.39)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.64, 7.75)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.17)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n11.6.5 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei MÃ¼ttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]); die Befundlage ist unklar. Hingegen fand sich ein Effekt der mÃ¼tterlichen Intelligenz; pro Punkt Unterschied in mÃ¼tterlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte beim Kind (95%PI). AuÃŸerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei MÃ¼tter mit Schulabschluss war der Regressionskoeffizient zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell hat mittels AbbildungÂ 11.12 mutig Kausalaussagen postuliert. Das ist zwar schÃ¶n, bedarf aber einer BegrÃ¼ndung mit RÃ¼ckgriff auf die Literatur (was hier nicht getan wurde).",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#sec-yg",
    "href": "1000-metrische-AV.html#sec-yg",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.7 y ~ g\n",
    "text": "11.7 y ~ g\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n11.7.1 Forschungsfrage\nNach Ihrem Studium wurden Sie reich als Unternehmensberaterin; Ihre Kompetenz als Wirtschaftspsychologi war heiÃŸ begehrt. Von Statistik wollte niemand etwas wissenâ€¦ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt fÃ¼hrte Sie in die Antarktisâ€¦ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um GrÃ¶ÃŸenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren KÃ¶rpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 11.12 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.12: DAG fÃ¼r y ~ g\n\n\n\n\n\n11.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ğŸ¤” Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere KÃ¶rpergewichte in AbhÃ¤ngigkeit von der Pinguinart?\n\nAlternativ kÃ¶nnen wir die Hypothese prÃ¼fen, ob die Mittelwerte â€œpraktischâ€ gleich sind, also sich â€œkaumâ€ unterscheiden. Der Grenzwert fÃ¼r â€œpraktisch gleichâ€ bzw. â€œkaum unterschiedlichâ€ ist subjektiv. Dazu in Kapitel 10.3 mehr.\n\n11.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, TabelleÂ 11.10.\n\nCodepenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\nTabelleÂ 11.10: Die Verteilung des KÃ¶rpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas fÃ¤llt Ihnen auf?\n\n11.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. AbbildungÂ 11.13?\n\n\n\n\n\n\n\nAbbildungÂ 11.13: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.7.5 Gewicht pro Spezies, m10.6\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und TabelleÂ 11.11.\nDie Modellformel fÃ¼r m10.6 lautet also body_mass_g ~ species.\n\nCodeoptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\n\nTabelleÂ 11.11: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3700.62\n(3627.04, 3773.47)\n100%\n0.999\n4057\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.49\n(-104.84, 168.88)\n68.53%\n1.000\n4282\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.43\n(1263.00, 1492.13)\n100%\n1.000\n4454\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n11.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, AusprÃ¤gungen; hier: Spezies), aber es werden in TabelleÂ 11.11 nur zwei Stufen angezeigt (also eine weniger) zusÃ¤tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrÃ¼ckt (Intercept). Die Koeffizienten fÃ¼r species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in AbbildungÂ 11.14 verdeutlicht.\n\nCodeplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 11.14: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\n\n11.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich hÃ¶her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich Ã¤hnlich.\nWie in AbbildungÂ 11.14 ersichtlich, Ã¼berlappt sich der SchÃ¤tzbereich fÃ¼r den Parameter von Gentoo nicht mit der Null; hingegen Ã¼berlappt sich der SchÃ¤tzbereich des Parameters fÃ¼r Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hÃ¤tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prÃ¼fen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primÃ¤r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.\n\n11.7.8 Priori-Werte Ã¤ndern\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. FÃ¼r Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfÃ¼r Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich mit prior_summary(modell) ausgeben lassen.\n\nCodeprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man Ã¼ber mehr inhaltliches Wissen verfÃ¼gt, so wird man die Prioris anpassen wollen. So kÃ¶nnte man z.B. auf Basis von Fachwissen Ã¼ber das Gewicht von Pinguinen postulieren, dass Adelie-Pinguine im Mittel 3000 g wiegen. Und dass die anderen zwei Pinguin-Arten im Mittel sich nicht unterscheiden vom Mittelwert der Adelie-Pinguine.\n\nCodem10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3704               24             1358\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nCodem10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(3000, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3700               29             1375\n\n\nDen Parameter fÃ¼r die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen.\n\nCodesigma(m10.6b)\n## [1] 463\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die GrÃ¶ÃŸe der Konfidenzintervalle.\nÃœbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren.12\n\n11.7.9 Vertiefung: Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\nCodepenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge Ã¤ndern.\n\nCodelevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nCodelibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verfÃ¼gbar sein muss.\nJetzt haben wir die Referenzkategorie geÃ¤ndert:\n\nCodelevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie Ã¤ndert nichts Wesentliches am Modell, s. TabelleÂ 11.12.\n\nCodem10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nTabelleÂ 11.12: m10.6a mit geÃ¤nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 4988.13, 5155.48]\n\n\nspeciesAdelie\n[-1486.15, -1260.32]\n\n\nspeciesChinstrap\n[-1474.66, -1198.00]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1-x2",
    "href": "1000-metrische-AV.html#y-x1-x2",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.8 y ~ x1 + x2\n",
    "text": "11.8 y ~ x1 + x2\n\nHier untersuchen wir Forschungsfragen mit zwei metrischen UV (und einer metrischen AV).\n\n11.8.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhÃ¤ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa â€œIQ der Mutter ist die Ursache zum IQ des Kindesâ€) wird impliziert.\nEs geht in dieser Forschungsfrage rein darum, ZusammenhÃ¤nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. FÃ¼r solche Fragen ist ein Kausalmodell nÃ¶tig: Fachlich fundierte Annahmen Ã¼ber KausalzusammenhÃ¤nge zwischen UV und AV.\n\n11.8.2 Was heiÃŸt, X hÃ¤ngt mit Y zusammen?\n\nDer Begriff â€œZusammenhangâ€ ist nicht exakt.\nHÃ¤ufig wird er (fÃ¼r metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groÃŸ der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem â€œEffekt von X auf Yâ€ Ã¼bersetzt. Vorsicht: â€œEffektâ€ klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende BegrÃ¼ndung fÃ¼r einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der StÃ¤rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehÃ¶rigen Regression im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten, bevor man ein (Regressions-)Modell aufstellt, s. TabelleÂ 11.13.\n\nCodekidiq %&gt;% \n  correlation()\n\n\n\n\n\nTabelleÂ 11.13: Korrelation der Variablen im Datensatz kidiq (inkl. frequentistischer Statistiken wie t- und p-Werten, die wir hier ignorieren)\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.166\n\n\nkid_score\nmom_iq_c\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_hs\nmom_iq_c\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\nmom_iq\nmom_iq_c\n1.00\n(1.00, 1.00)\n1.39e+09\n&lt; .001***\n\n\nmom_age\nmom_iq_c\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\n\n\nTabelleÂ 11.14 zeigt die Korrelationsmatrix als Korrelationsmatrix.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\n\nTabelleÂ 11.14: Die Korrelationen zwischen den Variablen der Tabelle kidiq. Die Sterne geben einen Bereich des p-Werts an (wir ignorieren die Sterne hier).\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_iq_c\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.45***\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.28***\n0.21***\n0.28***\n\n\n\nmom_iq\n1.00***\n0.09\n\n\n\n\nmom_age\n0.09\n\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nNÃ¼tzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, AbbildungÂ 11.15.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 11.15: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n11.8.3 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro PrÃ¤diktor, also eine fÃ¼r mom_iq und eine fÃ¼r mom_age.\n\nCodem10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nTabelleÂ 11.15 zeigt die Ergebnisse fÃ¼r mom_iq.\n\n\n\nTabelleÂ 11.15: Parameter fÃ¼r m10.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.79\n(14.59, 37.16)\n100%\n1.000\n4452\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.72)\n100%\n1.000\n4436\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nTabelleÂ 11.16 zeigt die Ergebnisse fÃ¼r mom_age.\n\n\n\nTabelleÂ 11.16: Parameter fÃ¼r m10.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n71.39\n(54.39, 87.44)\n100%\n0.999\n3923\nNormal (86.80 +- 51.03)\n\n\nmom_age\n0.68\n(-0.02, 1.41)\n96.92%\n0.999\n3917\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n11.8.4 Visualisierung der univariaten Regressionen\nIn AbbildungÂ 11.16 ist die univariate Regression mit jeweils einem der beiden PrÃ¤diktoren dargestellt.\nm10.7: Die Steigung betrÃ¤gt 0.6. m10.8: Die Steigung betrÃ¤gt 0.7.\n\n\n\n\n\n\n\nAbbildungÂ 11.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n11.8.5 Multiples Modell (beide PrÃ¤diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein PrÃ¤diktor im Modell aufgenommen ist, s TabelleÂ 11.17.\n\nCodem10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\nparameters(m10.9)\n\n\n\n\n\nTabelleÂ 11.17: Parameter fÃ¼r m10.9\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n17.61\n(-0.06, 35.67)\n97.42%\n1.000\n6102\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.60\n(0.48, 0.72)\n100%\n1.000\n5162\nNormal (0.00 +- 3.40)\n\n\nmom_age\n0.39\n(-0.23, 1.02)\n88.22%\n1.000\n4952\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich (potenziell) zu den von den jeweiligen univariaten Regressionen.\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils â€œbereinigtâ€ vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht. Das bedeutet anschaulich, man betrachtet den den Zusammenhang einee UV mit der AV, wobei man gleichzeitig den anderen PrÃ¤diktor konstant hÃ¤lt.\nIn AbbildungÂ 11.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildungÂ 11.17: 3D-Visualisierung von m10.9 (zwei PrÃ¤diktoren)\n\n\n\nAbbildungÂ 11.18 zeigt eine Visualisierung von m10.9, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildungÂ 11.18: Modell m10.9; die FarbverlÃ¤ufe zeigen der Wert der abhÃ¤ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der FarbÃ¤nderung) die VerÃ¤nderung fÃ¼r die AV (kid_score). Auf der Achse fÃ¼r mom_age sieht man, dass sich die AV kaum Ã¤ndert, wenn sich mom_age Ã¤ndert.\n\n11.8.6 Visualisierung in 10 Dimensionen\nAbbildungÂ 11.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildungÂ 11.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere SchwÃ¤chen, eine groÃŸe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y-x1_z-x2_z",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.9 y ~ x1_z + x2_z\n",
    "text": "11.9 y ~ x1_z + x2_z\n\nIn diesem Abschnitt untersuchen wir ein Modell mit zwei z-standardisierten, metrischen PrÃ¤diktoren (und einer metrischen, nicht-standardisierten AV).\n\n11.9.1 Relevanz der PrÃ¤diktoren\nWoher weiÃŸ man, welche UV am stÃ¤rksten mit der AV zusammenhÃ¤ngt? Man kÃ¶nnte auch sagen: Welcher PrÃ¤diktor (welche UV) am â€œwichtigstenâ€ ist oder den â€œstÃ¤rksten Einflussâ€ auf die AV ausÃ¼bt? Bei solchen kausal konnotierten AusdrÃ¼cken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann fÃ¼r sich nur Muster in den Daten, also ZusammenhÃ¤nge bzw. Unterschiede, entdecken, s. AbbildungÂ 11.20. MÃ¶chte man die Relevanz von PrÃ¤diktoren vergleichen, so ist ein Kausalmodell empfehlenswert.\n\n\n\n\n\nAbbildungÂ 11.20: Made at imgflip.com\n\n\nWelcher PrÃ¤diktor ist nun â€œwichtigerâ€ oder â€œstÃ¤rkerâ€ in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)? Die Antwort hÃ¤ngt auch von der Streuung bzw. Skalierung der Variablen ab. mom_iq hat den grÃ¶ÃŸeren Koeffizienten und viel Streuung; mom_age hat weniger Streuung.\nUm die Relevanz der PrÃ¤diktoren vergleichen zu kÃ¶nnen, mÃ¼sste man vielleicht die VerÃ¤nderung von kid_score betrachten, wenn man von kleinsten zum grÃ¶ÃŸten PrÃ¤diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die VerÃ¤nderung in der AV zu betrachten, wenn man den PrÃ¤diktor von â€œunterdurchschnittlichâ€ auf â€œÃ¼berdurchschnittlichâ€ Ã¤ndert. Das kann man mit z-Standardisierung erreichen, s. ?sec-standardnormalverteilung.\n\n\n\n\nCodekidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;%  # z-Transformation\n  select(mom_iq, mom_iq_z) \n\nkidiq2 %&gt;% \n  head()\n\n\n  \n\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit der Effekte von UV, die (zuvor) verschiedene Mittelwerte und Streuungen hatten13. Die Standardisierung ist Ã¤hnlich zur Vergabe von ProzentrÃ¤ngen: â€œDieser Messwert gehÃ¶rt zu den Top-3-Prozentâ€. Diese Aussage ist bedeutsam fÃ¼r Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen fÃ¼r verschiedene Verteilungen mÃ¶glich.\n\n11.9.2 Statistiken zu den z-transformierten Variablen\nTabelleÂ 11.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer AusprÃ¤gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener PrÃ¤diktoren sind einfacher in ihrer GrÃ¶ÃŸe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und Ã¤hnlich groÃŸe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (â€œSkalierungâ€) mit standardize (aus easystats) durchfÃ¼hren, s. TabelleÂ 11.18.\n\nCodekidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\n\nTabelleÂ 11.18: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nmom_iq_c\npred_m10.9\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_c_z\npred_m10.9_z\n\n\n\n65\n1\n121.12\n27\n21.12\n101.14\n-1.07\n0.52\n1.41\n1.56\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n-10.64\n81.22\n0.55\n0.52\n-0.71\n0.82\n-0.71\n-0.60\n\n\n85\n1\n115.44\n27\n15.44\n97.72\n-0.09\n0.52\n1.03\n1.56\n1.03\n1.19\n\n\n83\n1\n99.45\n25\n-0.55\n87.30\n-0.19\n0.52\n-0.04\n0.82\n-0.04\n0.06\n\n\n115\n1\n92.75\n27\n-7.25\n84.04\n1.38\n0.52\n-0.48\n1.56\n-0.48\n-0.30\n\n\n98\n0\n107.90\n18\n7.90\n89.67\n0.55\n-1.91\n0.53\n-1.77\n0.53\n0.32\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafÃ¼r, dass die ursprÃ¼nglichen Variablen beim z-Standardisieren nicht Ã¼berschrieben werden, sondern angehÃ¤ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nCodekidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. TabelleÂ 11.19. Dazu verwendet man den Befehl scale().\n\nCodekidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\n\nTabelleÂ 11.19: Z-Standardisierung ohne Extrapaketâ€\n\n\n\n  \n\n\n\n\n\n\n\n11.9.3 Modell\nBerechnen wir das Modell m10.10: y ~ x1_z + x2_z.\n\nCodem10.10 &lt;- stan_glm(kid_score ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\nparameters(m10.10)\n\n\n\n\n\nTabelleÂ 11.20: Parameter von m10.12\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n86.77\n(85.05, 88.48)\n100%\n1.000\n4917\nNormal (86.80 +- 51.03)\n\n\nmom_iq_z\n9.04\n(7.34, 10.83)\n100%\n1.000\n4719\nNormal (0.00 +- 51.03)\n\n\nmom_age_z\n1.04\n(-0.73, 2.78)\n88.02%\n0.999\n4786\nNormal (0.00 +- 51.03)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.10 y_z ~ x1_z + x2_z\n",
    "text": "11.10 y_z ~ x1_z + x2_z\n\nIn diese Abschnitt berechnen wir ein Modell (Modell m10.12), in dem sowohl die PrÃ¤diktoren z-transformiert sind (standardisiert) als auch die AV. Das z-Standardisieren der AV, kid_score ist zwar nicht nÃ¶tig, um den Effekt der PrÃ¤diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darÃ¼ber, um wie viele SD-Einheiten sich die AV verÃ¤ndert, wenn sich ein PrÃ¤diktor um eine SD-Einheit verÃ¤ndert. Das kann auch eine interessante(re) Aussage sein.\n\n11.10.1 Modell y_z ~ x1_z + x2_z\n\nBerechnen wir das Modell m10.12: y_z ~ x1_z + x2_z.\n\nCodem10.12 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z   mom_age_z \n##    -0.00014     0.44384     0.05072\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient fÃ¼r mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_iq um eine SD-Einheit Ã¤ndert.\nDer Koeffizient fÃ¼r mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_age um eine SD-Einheit Ã¤ndert.\n\nJetzt sind die PrÃ¤diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar. Man sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n11.10.2 95%-PI\nMit parameters kÃ¶nnen wir uns ein PI fÃ¼r m10.12 ausgeben lassen, s. AbbildungÂ 11.21; im Standard wird ein 95%-ETI berichtet14.\n\nCodeparameters(m10.12) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-1.38e-04\n(-0.08, 0.08)\n50.20%\n1.000\n5259\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n4713\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.85%\n0.999\n4990\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nCodeplot(eti(m10.12)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 11.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI fÃ¼r m10.12\n\n\n\n\n\n11.10.3 ModellgÃ¼te\n\nCoder2(m10.12)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.144, 0.271])\n\n\nIst dieser Wert von \\(R2\\) â€œgutâ€? Diese Frage ist Ã¤hnlich zur Frage â€œIst das viel Geld?â€; man kann die Frage nur im Kontext beantworten.\nEine einfache LÃ¶sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklÃ¤rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufÃ¤llig hohen Werten der ModellgÃ¼te im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine â€œobjektiveâ€ Antwort auf die Frage â€œwie viel ist viel?â€ haben wollen, ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage â€œWieviel ist viel?â€ gegeben hat (Cohen, 1992):\n\nCodeinterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n11.10.4 Priori-Verteilung fÃ¼r m10.12 und Modelldefinition\nDie Prioris fÃ¼r m10.12 kann man sich mit prior_summary(m10.12) ausgeben lassen. Danke, Stan!\n\nCodeprior_summary(m10.12)  # aus rstanarm\n## Priors for model 'm10.12' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\nğŸ¤– Nix zu danken!\n\nWie gesagt, Stan nimmt dafÃ¼r einfach die empirischen Mittelwerte und Streuungen her.15\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. GleichungÂ 11.4.\n\\[\n\\begin{aligned}\n\\text{kidscore}^z_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{momiq}_i^z + \\beta_2\\text{momage}_i^z \\\\\n\\beta_0 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{11.4}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.12. Dadurch, dass nicht nur UV, sondern auch AV z-standardisiert (d.h. zentriert und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzufÃ¼hren.\n\nBeispiel 11.3 (Anzahl der Modellparameter) Wie viele Modellparameter hat m10.12?16\n\n\n11.10.5 Antwort auf die Forschungsfrage\n\nDas Modell spricht sich klar fÃ¼r einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Pro Einheit Standardabweichung in der UV (Intelligenz der Mutter) Ã¤ndert sich die AV um ca. 0.44 Standardabweichungseinheiten. Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkÃ¤rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al., 2020) zurÃ¼ck (s. Anhang fÃ¼r Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem â€œstatistischen Effektâ€ gesprochen, um klar zu machen, dass es sich lediglich um assoziative ZusammenhÃ¤nge, und nicht um kausale ZusammenhÃ¤nge, handelt. Kausale ZusammenhÃ¤nge dÃ¼rfen wir nur verkÃ¼nden, wenn wir sie a) explizit untersuchen und b) sich in der Literatur Belege dafÃ¼r finden oder c) wir ein Experiment fachgerecht durchgefÃ¼hrt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.11 Vertiefung",
    "text": "11.11 Vertiefung\nğŸï¸VERTIEFUNG, nicht prÃ¼fungsrelevantğŸï¸\n\n11.11.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch, s. TheoremÂ 11.2.\n\nTheorem 11.2 (Regression als Korrelation) \\[b = r \\frac{sd_x}{sd_y}\\quad \\square\\]\n\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die PunktschÃ¤tzer fÃ¼r die Regressionskoeffizienten, s. m10.12.\n\nCodem10.12 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z \n##    -0.00033     0.44993\n\n\nVergleichen Sie diese Werte mit der Korrelation, s. TabelleÂ 11.21.17\n\nCodekidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelleÂ 11.21: Correlation Matrix (pearson-method)\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n11.11.2 PrÃ¼fen der LinearitÃ¤tsannahme\nZentrale Annahme eines linearen Modells: Die AV ist eine lineare Funktion der einzelnen PrÃ¤diktoren, $y= _0 + _1x_1 + _2 x_2 + $, vgl. TheoremÂ 2.1.\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression hÃ¤ufig normalverteilte Residuen an18, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schÃ¤tzen (Gelman et al., 2021).\nIst die LinearitÃ¤tsannahme erfÃ¼llt, so sollte der Residualplot nur zufÃ¤llige Streuung um \\(y=0\\) herum zeigen, s. AbbildungÂ 11.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsÃ¤chlichem Wert: \\(e_i = y_i - \\hat{y}_i\\)\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.12_pred = predict(m10.12),  # vorhergesagten Werte\n         m10.12_resid = resid(m10.12))  # Residuen\n\n\n\nCodekidiq %&gt;% \n  ggplot(aes(x = m10.12_pred, y = m10.12_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildungÂ 11.22: Die Verteilung der Fehler scheint keinem starken Trend (in AbhÃ¤ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine grÃ¶ÃŸeren AuffÃ¤lligkeiten.\n\n11.11.3 ModellprÃ¼fung mit der PPV\n\nCodepp_check(m10.12)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht hÃ¤ufig.\n\n11.11.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildungÂ 11.23: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildungÂ 11.23 zeigt in der oberen Reihe die Regression eines PrÃ¤diktors auf den anderen PrÃ¤diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n11.11.5 Bayesianisch gleich Frequentistisch?\nÃœbrigens liefern stan_glm() und lm oft Ã¤hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nCodestan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.911      -0.019      -2.285\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.908      -0.019      -2.265\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch Ã¤hnlich sein kÃ¶nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.12 Fazit",
    "text": "11.12 Fazit\n\n11.12.1 Austieg: Bayes in fÃ¼nf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\nğŸ“º MusterlÃ¶sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\nğŸ“º MusterlÃ¶sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n11.12.2 Ausblick: BinÃ¤re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\nCodedata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m14: am ~ mpg_z:\n\nCodem14 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m14)\n## (Intercept)       mpg_z \n##         0.4         0.3\n\n\nAb mpg_z = 0.4, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nCodemtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m14)[1],\n              slope = coef(m14)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nCodeneg_am &lt;- predict(m14, newdata = tibble(mpg_z = -1.3))\n\n\nFÃ¼r kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte fÃ¼r am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. MÃ¼ssen wir mal bei Gelegenheit besser machen.\n\n11.12.3 Genug fÃ¼r heute\nWir waren fleiÃŸig â€¦\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.\n\n\nGenug fÃ¼r heute. ğŸ‘\n\n11.12.4 WeiterfÃ¼hrende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman et al. (2021), Kap. 10, insbesondere 10.3.\nGelman et al. (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit fÃ¼hrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig Ã¼berschaubarem mathematischen Aufwand.\nFÃ¼r das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.13 Aufgaben",
    "text": "11.13 Aufgaben\n\n11.13.1 Papier-und-Bleistift-Aufgaben\n\nanz-params\nfofrage-regrformel2\nmodelldef-regrformel\nfinde-prior/\nNullhyp-Beispiel\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nzwert-berechnen\nstan_glm_parameterzahl\nkausale-verben\n\n11.13.2 Aufgaben, fÃ¼r die man einen Computer benÃ¶tigt\n\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope4\n\n11.13.3 Vertiefung\n\nAnova-skalenniveau\nttest-skalenniveau\nstan_glm_prioriwerte",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "\n11.14 â€”",
    "text": "11.14 â€”\n\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155â€“159.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). Rstanarm: Bayesian Applied Regression Modeling via Stan. https://mc-stan.org/rstanarm\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#footnotes",
    "href": "1000-metrische-AV.html#footnotes",
    "title": "\n11Â  Fallbeispiele\n",
    "section": "",
    "text": "Hier ist eine kurze ErklÃ¤rung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablenâ†©ï¸\nHier finden Sie eine kurze ErklÃ¤rung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktionâ†©ï¸\nauch DAG genannt, s. ?sec-kausalâ†©ï¸\nHÃ¤ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - â€œgrÃ¶ÃŸer als/kleiner alsâ€ - zu formulieren, anstelle der â€œempirisch Ã¤rmerenâ€ einfachen, ungerichteten Ungleichheitâ†©ï¸\nunknown, sozusagen der unbekannte Gott, also fÃ¼r alle sonstigen EinflÃ¼sse; man kann das â€œuâ€ ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgefÃ¼hrt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es gÃ¤be keine anderen EinflÃ¼sse als mom_hs auf die IQ des Kindes.â†©ï¸\nGenauer gesagt wird geprÃ¼ft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.â†©ï¸\nGenauer gesagt, erlaubt der t-Test in der Form des Welche-Tests auch Abweichungen von der VarianzhomogenitÃ¤t der gestesten Gruppen. Die Regression geht hingegen von VarianzhomogenitÃ¤t (HomoskedastizitÃ¤t) aus. Allerdings ist diese Annahme nicht von besonderer Bedeutung, wenn es um die Regressionskoeffizienten geht.â†©ï¸\nDAG, s. ?sec-kausalâ†©ï¸\nDabei nehmen wir an, dass x und u nicht voneinander abhÃ¤ngen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.â†©ï¸\nVgl. Abschnitt â€œUV zentrierenâ€ im Kursbuch Statistik1.â†©ï¸\nauch ETI (Equal Tails Interval) genanntâ†©ï¸\ns. Details hier.â†©ï¸\nam nÃ¼tzlichsten ist diese Standardisierung bei normal verteilten Variablen.â†©ï¸\nZumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen kÃ¶nnen sich Ã¤ndern. Am besten in der Dokumentation nachlesen: ?parameters.â†©ï¸\nNicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute SchÃ¤tzer der echten Parameter sein mÃ¼ssten, wenn die Stichprobe, die wir ihm angeschleppt hÃ¤tten, tatsÃ¤chlich gut istâ€¦â†©ï¸\n4: \\(\\beta_0, \\beta_1, \\beta_2, \\sigma\\)â†©ï¸\nIgnorieren Sie die Zeile mit dem Befehl display(). Dieser Befehl dient nur dazu, die Ausgabe zu verschÃ¶nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.â†©ï¸\nwas auf normal verteilte AV hinauslaufen kann aber nicht mussâ†©ï¸",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html",
    "href": "1200-abschluss.html",
    "title": "12Â  Abschluss",
    "section": "",
    "text": "12.1 Lernsteuerung",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "12Â  Abschluss",
    "section": "",
    "text": "12.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische â€œLieblingsfehlerâ€ benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik Ã¼bersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n12.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nCodelibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n\n12.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#probeklausur",
    "href": "1200-abschluss.html#probeklausur",
    "title": "12Â  Abschluss",
    "section": "\n12.2 Probeklausur",
    "text": "12.2 Probeklausur\n\n12.2.1 2024\n(Diese Liste ist im Aufbau. Bitte konsultieren Sie fÃ¼r weitere Aufgaben selbstÃ¤ndig alle relevanten Aufgaben, die in den Kapiteln vorgestellt wurden.)\n\nttest-als-regr\nAdditionssatz1\n\nNerd-gelockert q\nUrne1\ncorona-blutgruppe\nvoll-normal\nalphafehler-inflation3\nverteilungen-quiz-05\nverteilungen-quiz-03\nverteilungen-quiz-04\nKekse03\nglobus-bin2\nglobus2\niq01a\ngem-wskt4\nRethink2m3\nmtcars-post2a\ngroesse03\nbath42\nklausur-raten\nbed-post-wskt1\nmtcars-post3a\nexp-tab\nnorms-sd\nmtcars-post_paper\nbfi10\nrope-luecke\nwskt-schluckspecht2a\npenguins-stan-06\n\n12.2.2 2023\nDieser Tag auf dem Datenwerk stellt Fragen einer ProbeprÃ¼fung (Version 2023) zusammen.\n\n12.2.3 2022\nDieser Tag auf dem Datenwerk stellt Fragen einer ProbeprÃ¼fung (Version 2022) zusammen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "12Â  Abschluss",
    "section": "\n12.3 Lieblinglingsfehler",
    "text": "12.3 Lieblinglingsfehler\nLieblingsfehler im Ãœberblick ğŸ¤·:\n\nQuantile und Verteilungsfunktion verwechseln\nPrÃ¤diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n12.3.1 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·\nğŸ ğŸ Vertiefung: Dieser Abschnitt ist nicht prÃ¼fungsrelevant. ğŸï¸ ğŸ\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nCodem1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. TabelleÂ 12.1.\n\nCodepost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelleÂ 12.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. HÃ¤ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und PunktschÃ¤tzer auszulesen.\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n12.3.2 Quantile und Verteilungsfuntion verwechseln ğŸ¤·\n\n12.3.2.1 Quantil fÃ¼r \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. AbbildungÂ 12.1.\n\n\n\n\n\n\n\nAbbildungÂ 12.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betrÃ¤gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist grÃ¶ÃŸer oder gleich dem \\(p\\)-Quantil.\n\n12.3.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. AbbildungÂ 12.2.\n\n\n\n\n\n\n\nAbbildungÂ 12.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betrÃ¤gt hier 50%, dass \\(x\\) nicht grÃ¶ÃŸer ist als 0.\n\n12.3.3 Interaktion falsch interpretieren ğŸ¤·\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kÃ¼rzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nCodem2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten, s. TabelleÂ 12.2.\n\nCodeparameters(m2)\n\n\n\n\n\nTabelleÂ 12.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.68\n(18.99, 30.27)\n100%\n1.000\n2120.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.75%\n1.000\n2200.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.80\n(4.96, 22.96)\n99.78%\n1.000\n1573.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.19, -0.03)\n99.52%\n1.000\n1837.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelleÂ 12.2 zeigt die Visualisierung der Parameter von m2.\n\nCodeplot(parameters(m2))\n\n\n\n\n\n\nAbbildungÂ 12.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch ğŸ˜ˆ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11.\nRichtig ğŸ‘¼ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11 â€“ wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte PrÃ¤diktoren wÃ¤ren hier eine sinnvolle LÃ¶sung.\nGelman et al. (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "12Â  Abschluss",
    "section": "\n12.4 Kochrezepte ğŸ²",
    "text": "12.4 Kochrezepte ğŸ²\n\n12.4.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen Ã¼ber ein PhÃ¤nomen, \\(y\\), Kausalfrage finden 2. Literatur wÃ¤lzen, um mÃ¶gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese prÃ¤zisieren 4. Modell prÃ¤zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prÃ¼fen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n12.4.2 Parameter schÃ¤tzen vs.Â Hypothesen prÃ¼fen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schÃ¤tzen. Beispiel HypothesenprÃ¼fung: â€œFrauen parken im Durchschnitt schneller ein als MÃ¤nnerâ€. Beispiel ParameterschÃ¤tzung: â€œWie groÃŸ ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und MÃ¤nnern?â€\nJe ausgereifter ein Forschungsfeld, desto kÃ¼hnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nÃ¤chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nÃ¤chste Sonnenfinsternis wird in den nÃ¤chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen fÃ¼r den Klausurerfolg. KÃ¼hne Hypothesen sind wÃ¼nschenswert ğŸ¦¹\n\n12.4.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist hÃ¶her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist grÃ¶ÃŸer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "12Â  Abschluss",
    "section": "\n12.5 Kerngedanken Bayes",
    "text": "12.5 Kerngedanken Bayes\nğŸ“º Bayes in fÃ¼nf Minuten\nğŸ“º Bayes in zehn Minuten\n\n12.5.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nCodem3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. AbbildungÂ 12.4.\n\n\n\n\n\n\n\nAbbildungÂ 12.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist mÃ¶glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind mÃ¶glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings Ã¼bermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n12.5.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "href": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "title": "12Â  Abschluss",
    "section": "\n12.6 Beispiele fÃ¼r PrÃ¼fungsaufgaben",
    "text": "12.6 Beispiele fÃ¼r PrÃ¼fungsaufgaben\n\n12.6.1 Geben Sie den korrekten Begriff an!\nğŸŒ¬ğŸš™ğŸ™‹ï¸ğŸ‘¨â¬…ï¸Hans ğŸ‘§â¬…ï¸Anna ğŸ‘©â¬…ï¸Lise\nPuh, wie erstelle ich fÃ¼r alle Studis ein anderes RÃ¤tsel2?\n\n\n\n\n\n12.6.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. AbbildungÂ 12.5.\n\n\n\n\n\n\n\nAbbildungÂ 12.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 12.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge fÃ¼r x und y gibt eine kleinstmÃ¶gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu â€œidentifizierenâ€). \\(\\square\\)\n\nâ“Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\nâ— Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n12.6.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. AbbildungÂ 12.6.\n\n\n\n\n\n\n\nAbbildungÂ 12.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n12.6.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildungÂ 12.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildungÂ 12.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set fÃ¼r den totalen Kausaleffekt: {AIS, ALN}\n\n12.6.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrÃ¼fungsfragen zu Modellen kÃ¶nnten z.B. sein:\n\nGeben Sie den PunktschÃ¤tzer (Median) fÃ¼r den PrÃ¤diktor X im Modell Y an!\nGeben Sie ein 89%-HDI fÃ¼r den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris â€¦\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI fÃ¼r den PrÃ¤diktor X im Modell Y?\nWas verÃ¤ndert sich an den Parametern, wenn Sie die PrÃ¤diktoren zentrieren/z-standardisieren?\nâ€¦",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "12Â  Abschluss",
    "section": "\n12.7 Aufgabensammlungen",
    "text": "12.7 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere â€œPrÃ¼fungsnÃ¤heâ€ kÃ¶nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "title": "12Â  Abschluss",
    "section": "\n12.8 Viel Erfolg bei der PrÃ¼fung!",
    "text": "12.8 Viel Erfolg bei der PrÃ¼fung!\nğŸ¥³ğŸ†ğŸ€ğŸ€ğŸ€",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section-3",
    "href": "1200-abschluss.html#section-3",
    "title": "12Â  Abschluss",
    "section": "\n12.9 â€”",
    "text": "12.9 â€”\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nvan Kampen, D. (2014). The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs. European Psychiatry, 29(7), 437â€“448. https://doi.org/10.1016/j.eurpsy.2013.11.001",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#footnotes",
    "href": "1200-abschluss.html#footnotes",
    "title": "12Â  Abschluss",
    "section": "",
    "text": "langweiligesâ†©ï¸\nFahr-Hier-Hans-Anna-Lise: Varianzanalyseâ†©ï¸\ndas ist keine vollstÃ¤ndige Liste, sondern eine Anregung. Andere Tags kÃ¶nnten auch relevant seinâ†©ï¸",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "definitions.html",
    "href": "definitions.html",
    "title": "13Â  Definitionen",
    "section": "",
    "text": "Kausale AbhÃ¤ngigkeit: ?def-abh\nAdditionssatz fÃ¼r disjunkte Ereignisse: DefinitionÂ 4.1\nAllgemeiner Additionssatz: DefinitionÂ 4.2\nAlternativhypothese (Effekthypothese): DefinitionÂ 2.10\n#Binomialkoeffizient: DefinitionÂ 5.2\nBinomialverteilung: DefinitionÂ 5.1\nBlockieren: ?def-blocking\nKollision: ?def-collision\nKonfundierungsvariable: ?def-confound\nDAG: ?def-dag\nElementarereignis: DefinitionÂ 3.5\nDeskriptivstatistik: DefinitionÂ 2.1\nDirekter Effekt: ?def-dir-eff\nEffekt: ?def-effekt\nEreignis: DefinitionÂ 3.3\nErgebnisraum: DefinitionÂ 3.2\nPerzentilintervall (PI): DefinitionÂ 7.1\nEvidenz: DefinitionÂ 6.4\nFunktion: DefinitionÂ 2.4\nGemeinsame Wahrscheinlichkeit: DefinitionÂ 4.6\nHalbe Normalverteilung: DefinitionÂ 5.3\nIntervalle hÃ¶chster Dichte (Highest Density Intervals): DefinitionÂ 7.2\nHintertÃ¼r: ?def-hintertuer\nIndirekter Effekt: ?def-ind-eff\nStochastische UnabhÃ¤ngigkeit: DefinitionÂ 4.4\nIndifferenzprinzip: DefinitionÂ 3.10\n(Populations-)Inferenzstatistik: DefinitionÂ 2.2\nKettenregel: DefinitionÂ 4.7\nKonfidenzintervall: DefinitionÂ 2.7\nLikelihood: DefinitionÂ 6.2\nLaplace-Experimt: DefinitionÂ 3.11\nMÃ¤chtigkeit: DefinitionÂ 3.7\nMediator: ?def-mediator\nKomplementÃ¤rereignis: DefinitionÂ 3.15\nLogische Differenz: DefinitionÂ 3.16\nSchnittmenge von Ereignissen: DefinitionÂ 3.14\nVereinigung von Ereignissen: DefinitionÂ 3.13\nMinimale Adjustierungsmenge : DefinitionÂ 12.1\nModell: DefinitionÂ 2.3\nMultiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse: DefinitionÂ 4.5\nNachfahre: ?def-Nachfahre\nExakte Nullhypothese: DefinitionÂ 2.9\nEffektwahrscheinlichkeit: DefinitionÂ 9.1\nPfad: ?def-pfad\nPosteriori-Verteilung: DefinitionÂ 6.3\nBedingte Wahrscheinlichkeit: DefinitionÂ 4.3\nPriori-Verteilung: DefinitionÂ 6.1\nRelation: DefinitionÂ 3.12\nSigma als mittleren Vorhersagefehler: DefinitionÂ 2.6\nStatistische Signifikanz: DefinitionÂ 2.8\nStratifizieren: ?def-stratifizieren\nTotaler Effekt: ?def-tce\nTotale Wahrscheinlichkeit: DefinitionÂ 4.8\nUnmÃ¶gliches und sicheres Ereignis: DefinitionÂ 3.4\nVerteilungsfunktion: DefinitionÂ 3.19\nVerteilungsfunktion: DefinitionÂ 3.22\nVollstÃ¤ndiges Ereignissystem: DefinitionÂ 3.6\nWahrscheinlichkeitsdichte: DefinitionÂ 3.21\nEinfache Definition von Wahrscheinlichkeit: DefinitionÂ 3.9\nWahrscheinlichkeit unter formallogischer Sichtweise: DefinitionÂ 3.9\nDiskrete Wahrscheinlichkeitsverteilung: DefinitionÂ 3.18\nZufÃ¤lliges Ereignis: DefinitionÂ 3.1\nZufallsvorgang: DefinitionÂ 3.1\nZufallsvariable: DefinitionÂ 3.17\nStetige Zufallsvariable: DefinitionÂ 3.20",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "theorems.html",
    "href": "theorems.html",
    "title": "14Â  Theoreme",
    "section": "",
    "text": "Stochastische AbhÃ¤ngigkeit: TheoremÂ 4.6\nStochastische AbhÃ¤ngigkeit 2: TheoremÂ 4.7\nAllgemeiner Additionssatz: TheoremÂ 4.2\nAdditionssatz fÃ¼r disjunkte Ereignisse: TheoremÂ 4.1\nBayesâ€™ Theorem: TheoremÂ 6.1\nBayesâ€™ Theorem 2: TheoremÂ 6.8\nBayesâ€™ Theorem 3: TheoremÂ 6.8\nBayesâ€™ Theorem fÃ¼r zusammengesetzte Hypothesen: TheoremÂ 6.9\n#Binomialkoeffizient: TheoremÂ 5.3\n#Binomialverteilung: TheoremÂ 5.2\nNotation fÃ¼r eine binomialverteilte Zufallsvariable: TheoremÂ 5.1\nRegression als Korrelation: TheoremÂ 11.2\nIndifferenzprinzip: TheoremÂ 3.1\nEvidenz: TheoremÂ 6.3\nEvidenz 2: TheoremÂ 6.4\nHypothese fÃ¼r ungleiche Mittelwerte: TheoremÂ 11.1\nGemeinsame Wahrscheinlichkeit: TheoremÂ 4.10\nStochastische UnabhÃ¤ngigkeit: TheoremÂ 4.4\nSymmetrie der UnabhÃ¤ngigkeit: TheoremÂ 4.8\nStochastische UnabhÃ¤ngigkeit 2: TheoremÂ 4.5\nKettenregel: TheoremÂ 4.11\nLaplace-Experiment: TheoremÂ 3.2\nLineares Modell (Regressionsgleichung): TheoremÂ 2.1\nModelldefinition m_kung_gewicht_c: TheoremÂ 9.1\nNullhypothesentest: TheoremÂ 10.1\nMultiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse: TheoremÂ 4.9\nStandardisierte Posteriori-Verteilung: TheoremÂ 6.6\nPosteriori-Verteilung 2: TheoremÂ 6.7\nBedingte Wahrscheinlichkeit: TheoremÂ 4.3\nTotale Wahrscheinlichkeit: TheoremÂ 4.12\nUnstandardisierte Posteriori-Wahrscheinlichkeit : TheoremÂ 6.5",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Theoreme</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Badenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A.,\n& Longobardi, C. (2016). Misconceptions of the p-value among\nChilean and Italian Academic Psychologists.\nFrontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlieÃŸende\nStatistik: praxisorientierte EinfÃ¼hrung mit Aufgaben und LÃ¶sungen\n(7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-Ã¼bungen: Beschreibende\nstatistik â€“ wahrscheinlichkeitsrechnung â€“ schlieÃŸende statistik (7.\nAuflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of\nModeling, Probability &\nStatistics. Springer.\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155â€“159.\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020).\nRstanarm: Bayesian applied regression modeling via\nStan. https://mc-stan.org/rstanarm\n\n\nHenze, N. (2019). Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der\nMaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Springer Berlin\nHeidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157â€“1164.\nhttp://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability theory:\nThe logic of science. Cambridge University Press.\n\n\nKabadayi, F. (2024). Smartphone addiction, depression, distress,\neustress, loneliness, and sleep deprivation in adolescents: A latent\nprofile and network analysis approach. BMC Psychology,\n12(1), 608. https://doi.org/10.1186/s40359-024-02117-6\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter\nValues in Bayesian Estimation. Advances in\nMethods and Practices in Psychological Science, 1(2),\n270â€“280. https://doi.org/10.1177/2515245918771304\n\n\nKurz, S. (2021). Statistical Rethinking with\nBrms, Ggplot2, and the Tidyverse:\nSecond Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & LÃ¼decke, D.\n(2019). Indices of Effect Existence and\nSignificance in the Bayesian Framework.\nFrontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd ed.). Taylor and Francis, CRC\nPress.\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes factor approaches for\ntesting interval null hypotheses. Psychological Methods,\n16(4), 406â€“419. https://doi.org/10.1037/a0024377\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference\nin statistics: A primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPopper, K. (2013). Logik der Forschung (H. Keuth,\nEd.). Akademie Verlag. https://doi.org/10.1524/9783050063782\n\n\nSauer, S. (2025). Statistik1. Independently published via\nAmazon. https://www.amazon.de/Statistik1-Einf%C3%BChrung-Statistik-Schwerpunkt-Prognose-Modellierung/dp/B0F673WGG5\n\n\nShmueli, G. (2010). To Explain or to Predict?\nStatistical Science, 25(3), 289â€“310. https://doi.org/10.1214/10-STS330\n\n\nvan Kampen, D. (2014). The SSQ model of schizophrenic\nprodromal unfolding revised: An analysis of its causal\nchains based on the language of directed graphs. European\nPsychiatry, 29(7), 437â€“448. https://doi.org/10.1016/j.eurpsy.2013.11.001\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASAâ€™s\nStatement on p-Values: Context,\nProcess, and Purpose. The American\nStatistician, 70(2), 129â€“133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Anhang",
      "Literaturverzeichnis"
    ]
  },
  {
    "objectID": "imprint.html",
    "href": "imprint.html",
    "title": "15Â  Impressum",
    "section": "",
    "text": "15.1 Vertreten durch:\nAngaben gemÃ¤ÃŸ Â§ 5 DDG\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach\nSebastian Sauer",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#kontakt",
    "href": "imprint.html#kontakt",
    "title": "15Â  Impressum",
    "section": "15.2 Kontakt:",
    "text": "15.2 Kontakt:\nTelefon: 0981 4877 0, E-Mail: sebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#aufsichtsbehÃ¶rde",
    "href": "imprint.html#aufsichtsbehÃ¶rde",
    "title": "15Â  Impressum",
    "section": "15.3 AufsichtsbehÃ¶rde:",
    "text": "15.3 AufsichtsbehÃ¶rde:\nNÃ¼rnberg",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#verantwortlich-fÃ¼r-den-inhalt-nach-55-abs.-2-rstv",
    "href": "imprint.html#verantwortlich-fÃ¼r-den-inhalt-nach-55-abs.-2-rstv",
    "title": "15Â  Impressum",
    "section": "15.4 Verantwortlich fÃ¼r den Inhalt nach Â§ 55 Abs. 2 RStV:",
    "text": "15.4 Verantwortlich fÃ¼r den Inhalt nach Â§ 55 Abs. 2 RStV:\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#haftungsausschluss",
    "href": "imprint.html#haftungsausschluss",
    "title": "15Â  Impressum",
    "section": "15.5 Haftungsausschluss:",
    "text": "15.5 Haftungsausschluss:\n\n15.5.1 Haftung fÃ¼r Inhalte\nDie Inhalte unserer Seiten wurden mit grÃ¶ÃŸter Sorgfalt erstellt. FÃ¼r die Richtigkeit, VollstÃ¤ndigkeit und AktualitÃ¤t der Inhalte kÃ¶nnen wir jedoch keine GewÃ¤hr Ã¼bernehmen. Als Diensteanbieter sind wir gemÃ¤ÃŸ Â§ 7 Abs.1 DDG fÃ¼r eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach Â§Â§ 8 bis 10 DDG sind wir als Diensteanbieter jedoch nicht verpflichtet, Ã¼bermittelte oder gespeicherte fremde Informationen zu Ã¼berwachen oder nach UmstÃ¤nden zu forschen, die auf eine rechtswidrige TÃ¤tigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unberÃ¼hrt. Eine diesbezÃ¼gliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung mÃ¶glich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\n\n\n15.5.2 Haftung fÃ¼r Links\nUnser Angebot enthÃ¤lt Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb kÃ¶nnen wir fÃ¼r diese fremden Inhalte auch keine GewÃ¤hr Ã¼bernehmen. FÃ¼r die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mÃ¶gliche RechtsverstÃ¶ÃŸe Ã¼berprÃ¼ft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n\n\n15.5.3 Urheberrecht\nDie durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die VervielfÃ¤ltigung, Bearbeitung, Verbreitung und jede Art der Verwertung auÃŸerhalb der Grenzen des Urheberrechtes bedÃ¼rfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur fÃ¼r den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n\n\n15.5.4 Datenschutz\nDie Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten mÃ¶glich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit mÃ¶glich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdrÃ¼ckliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die DatenÃ¼bertragung im Internet (z.B. bei der Kommunikation per E-Mail) SicherheitslÃ¼cken aufweisen kann. Ein lÃ¼ckenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht mÃ¶glich. Der Nutzung von im Rahmen der Impressumspflicht verÃ¶ffentlichten Kontaktdaten durch Dritte zur Ãœbersendung von nicht ausdrÃ¼cklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdrÃ¼cklich widersprochen. Die Betreiber der Seiten behalten sich ausdrÃ¼cklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, FachanwÃ¤lte fÃ¼r Familienrecht",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "data-privacy.html",
    "href": "data-privacy.html",
    "title": "16Â  Datenschutzhinweise",
    "section": "",
    "text": "16.1 Einleitung\nDiese Datenschutzhinweise informieren Sie Ã¼ber die Art, den Umfang und den Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend â€œDatenâ€) im Rahmen der Nutzung dieser Webseite (nachfolgend â€œWebseiteâ€), die auf GitHub gehostet wird.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#einleitung",
    "href": "data-privacy.html#einleitung",
    "title": "16Â  Datenschutzhinweise",
    "section": "",
    "text": "16.1.1 Verantwortliche Person\nProf.Â Dr.Â habil. Sebastian Sauer, Residenzstr. 10, 90522 Ansbach, sebastian.sauer@hs-ansbach.de\n\n\n16.1.2 Hosting durch GitHub\nUnsere Webseite wird von GitHub Inc., 88 Colin P. Kelly Jr.Â St, San Francisco, CA 94107, USA (â€œGitHubâ€) gehostet. GitHub verarbeitet in unserem Auftrag Daten von Webseitenbesuchern (z.B. IP-Adressen). Dies ist fÃ¼r den Betrieb der Webseite und die Bereitstellung von Inhalten erforderlich. GitHub ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europÃ¤ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC&status=Active).\nWeitere Informationen zum Datenschutz bei GitHub finden Sie in der DatenschutzerklÃ¤rung von GitHub: https://docs.github.com/de/site-policy/privacy-policies/github-general-privacy-statement",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#datenerhebung-und--verarbeitung",
    "href": "data-privacy.html#datenerhebung-und--verarbeitung",
    "title": "16Â  Datenschutzhinweise",
    "section": "16.2 Datenerhebung und -verarbeitung",
    "text": "16.2 Datenerhebung und -verarbeitung\n\n16.2.1 Server-Log-Dateien\nBei jedem Zugriff auf unsere Webseite erfasst GitHub automatisiert Daten und speichert diese in Server-Log-Dateien. Zu diesen Daten gehÃ¶ren: IP-Adresse des zugreifenden GerÃ¤ts Datum und Uhrzeit des Zugriffs Name und URL der abgerufenen Datei Webseite, von der aus der Zugriff erfolgt (Referrer-URL) Verwendeter Browser und ggf. das Betriebssystem des zugreifenden GerÃ¤ts Name des Access-Providers\nDie Verarbeitung dieser Daten erfolgt, um die FunktionsfÃ¤higkeit der Webseite sicherzustellen, die Nutzung der Webseite zu analysieren und unser Angebot zu verbessern. Rechtsgrundlage fÃ¼r die Datenverarbeitung ist Art. 6 Abs. 1 lit. f DSGVO (berechtigtes Interesse). Unser berechtigtes Interesse liegt in den oben genannten Zwecken.\n\n\n16.2.2 Cookies\nUnsere Webseite verwendet keine Cookies.\n\n\n16.2.3 Einbindung von Drittinhalten\nEs kÃ¶nnen Inhalte von Drittanbietern wie Videos, Schriftarten oder Karten eingebunden sein. Beim Abruf dieser Inhalte wird Ihre IP-Adresse mÃ¶glicherweise an den Drittanbieter Ã¼bertragen. FÃ¼r weitere Informationen konsultiere bitte die Datenschutzrichtlinien der jeweiligen Anbieter.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#ihre-rechte",
    "href": "data-privacy.html#ihre-rechte",
    "title": "16Â  Datenschutzhinweise",
    "section": "16.3 Ihre Rechte",
    "text": "16.3 Ihre Rechte\nSie habengegenÃ¼ber uns folgende Rechte hinsichtlich der dich betreffenden personenbezogenen Daten: Recht auf Auskunft (Art. 15 DSGVO) Recht auf Berichtigung (Art. 16 DSGVO) Recht auf LÃ¶schung (Art. 17 DSGVO) Recht auf EinschrÃ¤nkung der Verarbeitung (Art. 18 DSGVO) Recht auf DatenÃ¼bertragbarkeit (Art. 20 DSGVO) Recht auf Widerspruch gegen die Verarbeitung (Art. 21 DSGVO)\nSie haben zudem das Recht, sich bei einer Datenschutz-AufsichtsbehÃ¶rde Ã¼ber die Verarbeitung deiner personenbezogenen Daten durch uns zu beschweren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "href": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "title": "16Â  Datenschutzhinweise",
    "section": "16.4 Anwendbare Rechtsgrundlagen",
    "text": "16.4 Anwendbare Rechtsgrundlagen\nNachstehend geben wir Ihnen eine Ãœbersicht der rechtlichen Grundlagen der DSGVO, auf deren Basis personenbezogene Daten auf dieser Webseite verarbeitet werden. Bitte beachten Sie, dass neben den Regelungen der DSGVO auch nationale Datenschutzvorgaben in Ihrem oder unserem Land relevant sein kÃ¶nnen. Sofern in EinzelfÃ¤llen spezifische Rechtsgrundlagen gelten, werden diese in der DatenschutzerklÃ¤rung gesondert erwÃ¤hnt.\n\n16.4.1 VertragserfÃ¼llung und vorvertragliche MaÃŸnahmen (Art. 6 Abs. 1 S. 1 lit. b) DSGVO)\nDie Verarbeitung personenbezogener Daten ist erforderlich zur ErfÃ¼llung eines Vertrags, bei dem die betroffene Person Vertragspartei ist, oder zur DurchfÃ¼hrung vorvertraglicher MaÃŸnahmen, die auf Anfrage der betroffenen Person erfolgen.\n\n\n16.4.2 Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO)\nDie Datenverarbeitung erfolgt zur Wahrung berechtigter Interessen des Verantwortlichen oder eines Dritten, sofern keine entgegenstehenden Interessen, Grundrechte oder Grundfreiheiten der betroffenen Person, die den Schutz ihrer personenbezogenen Daten erfordern, Ã¼berwiegen.\n\n\n16.4.3 Nationale Datenschutzbestimmungen in Deutschland\nNeben der DSGVO gelten in Deutschland nationale Datenschutzvorgaben, insbesondere das Bundesdatenschutzgesetz (BDSG). Das BDSG beinhaltet spezielle Regelungen zum Recht auf Auskunft, LÃ¶schung, Widerspruch, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung fÃ¼r andere Zwecke sowie zur DatenÃ¼bermittlung und zu automatisierten Einzelentscheidungen einschlieÃŸlich Profiling. In bestimmten FÃ¤llen kÃ¶nnen auch Datenschutzgesetze der BundeslÃ¤nder Anwendung finden.\n\n\n16.4.4 Hinweis auf die Geltung von DSGVO und Schweizer DSG\nDiese Datenschutzhinweise berÃ¼cksichtigen die Vorgaben sowohl der DSGVO als auch des Schweizer Datenschutzgesetzes (DSG). Zur besseren VerstÃ¤ndlichkeit und zur Vermeidung wiederholter Begriffsdefinitionen werden die Begriffe der DSGVO verwendet. Begriffe wie â€Verarbeitungâ€œ, â€personenbezogene Datenâ€œ, â€berechtigtes Interesseâ€œ und â€besondere Kategorien von Datenâ€œ entsprechen inhaltlich den Begriffen â€Bearbeitungâ€œ, â€Personendatenâ€œ, â€Ã¼berwiegendes Interesseâ€œ und â€besonders schÃ¼tzenswerte Personendatenâ€œ des Schweizer DSG. Die genaue Auslegung und Anwendung erfolgt jedoch gemÃ¤ÃŸ den Vorgaben des Schweizer DSG.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#sicherheitsmaÃŸnahmen",
    "href": "data-privacy.html#sicherheitsmaÃŸnahmen",
    "title": "16Â  Datenschutzhinweise",
    "section": "16.5 SicherheitsmaÃŸnahmen",
    "text": "16.5 SicherheitsmaÃŸnahmen\nWir setzen angemessene technische und organisatorische MaÃŸnahmen zum Schutz Ihrer Daten entsprechend den gesetzlichen Anforderungen um. Dabei berÃ¼cksichtigen wir den aktuellen Stand der Technik, die Implementierungskosten, Art, Umfang, UmstÃ¤nde und Zweck der Verarbeitung sowie die Wahrscheinlichkeit und Schwere mÃ¶glicher Risiken fÃ¼r die Rechte und Freiheiten betroffener Personen.\nZu den SchutzmaÃŸnahmen gehÃ¶ren insbesondere: Sicherstellung der Vertraulichkeit, IntegritÃ¤t und VerfÃ¼gbarkeit von Daten durch Kontrolle des Zugriffs auf die Daten und die Infrastruktur, der Eingaben, Weitergaben und Trennungen von Daten. Zudem haben wir Verfahren eingerichtet, um die Rechte betroffener Personen zu gewÃ¤hrleisten, Daten zu lÃ¶schen und angemessen auf Bedrohungen zu reagieren. Bereits in der Entwicklung und Auswahl von Hard- und Software sowie Verfahren berÃ¼cksichtigen wir Datenschutzprinzipien wie Datenschutz durch Technikgestaltung und datenschutzfreundliche Voreinstellungen.\nSicherung von Online-Verbindungen mit TLS-/SSL-VerschlÃ¼sselung (HTTPS) Um die DatenÃ¼bertragung Ã¼ber unsere Online-Dienste vor unbefugtem Zugriff zu schÃ¼tzen, nutzen wir die TLS-/SSL-VerschlÃ¼sselungstechnologie. Dies gewÃ¤hrleistet eine sichere DatenÃ¼bertragung zwischen unserem Server und Ihrem Browser, erkennbar an der HTTPS-Kennung in der URL-Leiste.\n\n16.5.1 Internationale DatenÃ¼bertragungen\nFalls Datenverarbeitungen in DrittlÃ¤ndern (auÃŸerhalb der EU und des EWR) stattfinden oder personenbezogene Daten an Dritte im Ausland Ã¼bermittelt werden, erfolgt dies ausschlieÃŸlich unter Einhaltung gesetzlicher Anforderungen. Sofern ein Angemessenheitsbeschluss der EU-Kommission fÃ¼r das betreffende Drittland vorliegt (Art. 45 DSGVO), gilt dieser als Grundlage der Ãœbertragung. Falls kein Angemessenheitsbeschluss vorliegt, sichern Standardvertragsklauseln (Art. 46 Abs. 2 lit. c) DSGVO), eine ausdrÃ¼ckliche Einwilligung oder gesetzliche Erfordernisse die Ãœbertragung ab (Art. 49 Abs. 1 DSGVO).\nWeitere Informationen zu den AngemessenheitsbeschlÃ¼ssen der EU-Kommission finden Sie auf dieser Seite. Die USA bieten mit dem sogenannten â€Data Privacy Frameworkâ€œ (DPF) eine Regelung zur Sicherstellung eines angemessenen Datenschutzniveaus, das durch die EU-Kommission am 10.07.2023 anerkannt wurde. Die Liste der zertifizierten Unternehmen und weitere Informationen finden Sie auf der Webseite des US-Handelsministeriums unter Data Privacy Framework.\nWir informieren Sie in unseren Datenschutzhinweisen, welche Drittanbieter unter diesem Rahmen zertifiziert sind.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#kontakt",
    "href": "data-privacy.html#kontakt",
    "title": "16Â  Datenschutzhinweise",
    "section": "16.6 Kontakt",
    "text": "16.6 Kontakt\nFÃ¼r Anfragen zum Datenschutz kÃ¶nnen Sie sich an uns wenden:\nProf.Â Dr.Â habil. Sebastian Sauer\nResidenzstr. 10, 90522 Ansbach\nsebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#Ã¤nderung-der-datenschutzhinweise",
    "href": "data-privacy.html#Ã¤nderung-der-datenschutzhinweise",
    "title": "16Â  Datenschutzhinweise",
    "section": "16.7 Ã„nderung der Datenschutzhinweise",
    "text": "16.7 Ã„nderung der Datenschutzhinweise\nWir behalten uns vor, diese Datenschutzhinweise jederzeit anzupassen, um sie an geÃ¤nderte Rechtslagen oder bei Ã„nderungen des Dienstes sowie der Datenverarbeitung anzupassen.\nStand: 15. November 2024",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#vertiefung",
    "href": "0200-Inferenz.html#vertiefung",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.7 Vertiefung",
    "text": "2.7 Vertiefung\n\n2.7.1 Vertiefung â€“ Frequentistische Konfidenzintervalle werden oft falsch verstanden (Vertiefung10)\nFrequentistische Konfidenzintervalle werden oft falsch verstanden, wie die folgende Studie zeigt. Das liegt aber nicht daran, dass die Menschen zu dumm sind, sondern dass frequentistische Konfidenzintervalle fÃ¼r viele Menschen kontraintuitiv sind.\nHoekstra et al. (2014) berichten von einer Studie, in der \\(n=442\\) Bachelor-Studentis, \\(n=34\\) Master-Studentis und \\(n=120\\) Forschende befragt wurden.\nDen Versuchpersonen wurde folgender Fragebogen vorgelegt, s. AbbildungÂ 2.16.\n\n\n\n\n\nAbbildungÂ 2.16: Frageobgen zu Konfidenzintervallen\n\n\nKurz gesagt war die Frage, die die Befragten beantworten sollten:\n\nIn einem Experiment wird ein 95%-Konfidenzintervall mit dem Bereich von 0.1 bis 0.4 beichtet. Welcher der folgenden sechs Aussagen sind richtig bzw. falsch?\n\nMit â€œKonfidenzintervallâ€ meinen die Forschenden ein frequentistisches Konfidenzintervall.\nAlle diese sechs Aussagen sind FALSCH. Die Aussagen lauten:\n\nDie Wahrscheinlichkeit, dass der wahre Mittelwert grÃ¶ÃŸer als 0 ist, betrÃ¤gt mindestens 95 %.\nDie Wahrscheinlichkeit, dass der wahre Mittelwert gleich 0 ist, ist kleiner als 5 %.\nDie â€Nullhypotheseâ€œ, dass der wahre Mittelwert gleich 0 ist, ist wahrscheinlich falsch.\nEs gibt eine 95%ige Wahrscheinlichkeit, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\nWir kÃ¶nnen mit 95%iger Sicherheit sagen, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\nWenn wir das Experiment immer wieder wiederholen wÃ¼rden, dann liegt der wahre Mittelwert in 95 % der FÃ¤lle zwischen 0,1 und 0,4.\n\nAussagen 1-4 weisen den Hypothesen bzw. den Parametern eine Wahrscheinlichkeit zu, was im Frequentismus nicht erlaubt ist. Aussagen 5-6 spezifizieren die Grenzen des SchÃ¤tzintervalls, allerdings kann das Konfidenzintervall nur Aussagen zu den zugrundeliegenden Stichproben, nicht zum SchÃ¤tzintervall, machen.\nDie Ergebnisse zeigen, dass die Aussagen mehrheitlich falsch verstanden wurden, also mit â€œstimmtâ€ angekreuzt wurden, s. AbbildungÂ 2.17.\n\n\n\n\n\nAbbildungÂ 2.17: Eine hohe Zustimmung zu den sechs falschen Aussagen\n\n\n\n2.7.2 Zielart ErklÃ¤ren â€“ Kausalinferenz\nMittels Kausalinferenz kÃ¶nnen wir schlieÃŸen, welche Variablen Ursachen und welche Wirkung sind â€“ und welche Variablen Scheinkorrelation erzeugen. Das ist wichtig, denn nur wenn man die Ursache kennt, weiÃŸ man, was man tun muss, um eine Wirkung zu erzielen.\n\n2.7.2.1 Studie A: Ã–strogen\nMedikament einnehmen? Oder lieber nicht? Mit Blick auf TabelleÂ 2.3: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 2.3: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nFrauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 2.18 zeigt die Daten aus TabelleÂ 2.3 in einem Balkendiagram.\n\n\n\n\n\n\n\nAbbildungÂ 2.18: Daten zur Studie A in einem Balkendiagram\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Kann das sein? Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl et al., 2016)?!\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen positiven (+) Einfluss auf Einnahme des Medikaments und negativen Einfluss (-) auf Heilung. Das Medikament hat einen positiven (+) Einfluss auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 2.19 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 2.19: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nAufteilen in Teilgruppen (MÃ¤nner bzw. Frauen) ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder â€œSchichtenâ€ (â€œStrataâ€). WÃ¼rde man die Gesamzahl an Patienten mit vs.Â ohne Medikatment vergleichen, kÃ¤me man zu einem falschen Schluss.\n\n\n\n2.7.3 Studie B: Blutdruck\nMedikament einnehmen? Oder lieber nicht?\nMit Blick auf TabelleÂ 2.4: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 2.4: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nhoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl et al., 2016)?\nKausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in AbbildungÂ 2.20 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 2.20: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n2.7.4 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 2.19 und AbbildungÂ 2.20, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht (bei Beobachtungsstudien).\n\n2.7.5 Sorry, Statistik: Du allein schaffst es nicht\nDatenanalyse alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ\nKausalinferenz ğŸ“š plus Datenanalyse ğŸ“Š erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  }
]