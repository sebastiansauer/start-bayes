[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 Einf√ºhrung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie ‚Ä¶\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden k√∂nnen\ng√§ngige einschl√§gige Forschungsfragen in statistische Modelle √ºbersetzen und mit R auswerten k√∂nnen\nkausale Forschungsfragen in statistische Modelle √ºbersetzen und pr√ºfen k√∂nnen\ndie G√ºte und Grenze von statistischen Modellen einsch√§tzen k√∂nnen\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage f√ºr Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und M√§nner vor eine Einpark-Aufgabe gestellt (nat√ºrlich alles sch√∂n standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen k√∂nnen schneller einparken als M√§nner, im Durchschnitt. Das h√§tten wir also gekl√§rt. Aber haben wir das ganz sicher gekl√§rt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich wei√ü, das ist jetzt ein harter Schlag f√ºr Sie‚Ä¶ Aber die gute Nachricht ist: Wir k√∂nnen angeben, wie (un)sicher wir bei mit einer Aussage (‚ÄúFrauen parken schneller‚Ä¶‚Äù) sind. Zum Beispiel k√∂nnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie n√§chste Woche ei Fahri f√ºr Ihren neuen Rolls Royce anheuern, m√ºssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, m√ºssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen ‚Äúlaut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauen‚Äù. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es √ºblich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den ‚ÄúTop 20 job roles in increasing and decreasing demand across industries‚Äù (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 Modul√ºberblick\nAbbildung¬†1.1 gibt einen √úberblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n   Wskt --&gt; Bayes --&gt; Regression\n\n\n\n\nAbbildung¬†1.1: Modulverlauf im √úberblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelle¬†1.1 gibt einen √úberblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist n√ºtzlich f√ºr Sie, die Tabelle Tabelle¬†1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als n√§chstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelle¬†1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\nNr\nKW\nJahr\nWochenstart\nVL-frei\nThema\nKommentar\n\n\n\n1\n40\n2025\n2025-09-29\nteilweise\nEinstieg und Wiederholung von QM1\nNA\n\n\n2\n41\n2025\n2025-10-06\nnein\nInferenz\nNA\n\n\n3\n42\n2025\n2025-10-13\nnein\nHallo, Wahrscheinlichkeit\nNA\n\n\n4\n43\n2025\n2025-10-20\nnein\nRechnen mit Wahrscheinlichkeit\nNA\n\n\n5\n44\n2025\n2025-10-27\nnein\nVerteilungen\nNA\n\n\n6\n45\n2025\n2025-11-03\nnein\nBayes-Versuch\nNA\n\n\n7\n46\n2025\n2025-11-10\nnein\nDie Post befragen\nNA\n\n\nNA\n47\n2025\n2025-11-17\nja\nNA\nBlockwoche\n\n\n8\n48\n2025\n2025-11-24\nnein\nGauss-Modelle\nNA\n\n\n9\n49\n2025\n2025-11-30\nnein\nEinfache lineare Modelle\nNA\n\n\n10\n50\n2025\n2025-12-08\nnein\nSch√§tzen vs. Testen\nNA\n\n\n11\n51\n2025\n2025-12-15\nnein\nFallbeispiele\nNA\n\n\n12\n52\n2025\n2025-12-22\nnein\nWiederholung und Vertiefung\nNA\n\n\nNA\n1\n2025\n2025-12-29\nja\n-\nWeichnachten\n\n\nNA\n2\n2026\n2026-01-05\nteilweise\n-\nWeichnachten\n\n\n13\n3\n2026\n2026-01-12\nnein\nKlausurvorbereitung\nNA\n\n\n11\n4\n2026\n2026-01-19\nja\nNA\nPr√ºfungszeit\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nF√ºr dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, m√∂glichst auch mit dem tidyverse\n\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.B. im Online-Buch ‚ÄúStatistik1‚Äù vermittelt. Alle Inhalte daraus werden in diesem Kurs ben√∂tigt.\n\n1.1.6 PDF-Version\nSie k√∂nnen die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.\nAlternativ finden Sie hier die Kapitel als PDF-Version. Achtung: Diese PDF-Versionen sind nicht unbedingt aktuell.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#lernhilfen",
    "href": "index.html#lernhilfen",
    "title": "Start:Bayes!",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nHier finden Sie einen √úberblick zu Lernhilfen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Start:Bayes!",
    "section": "\n1.3 Software",
    "text": "1.3 Software\nSie ben√∂tigen R, RStudio und einige R-Pakete insbesondere rstanarm f√ºr diesen Kurs.\nHier finden Sie Installationshinweise.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.4 Hinweise",
    "text": "1.4 Hinweise\n\n\n\n\n\n\nHinweis\n\n\n\nAlle formalen Hinweise (Pr√ºfung, Unterrichtsorganisation, ‚Ä¶) sind auf der Seite https://hinweisbuch.netlify.app/ zu finden. \\(\\square\\)\n\n\n\nüì∫ Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine Pr√ºfung in diesem Modul ist jedes Semester m√∂glich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#tutorium",
    "href": "index.html#tutorium",
    "title": "Start:Bayes!",
    "section": "\n1.5 Tutorium",
    "text": "1.5 Tutorium\nF√ºr dieses Modul wird ggf. ein Tutorium angeboten.\nDer Besuch des Tutoriums ist zu empfehlen. Arbeiten Sie auch das Materials auf der Webseite des Tutoriums durch.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#pr√ºfung",
    "href": "index.html#pr√ºfung",
    "title": "Start:Bayes!",
    "section": "\n1.6 Pr√ºfung",
    "text": "1.6 Pr√ºfung\nDas aktuelle Pr√ºfungsformat ist: Klausur im Mehrfachwahlverfahren (Multiple Choice).\nHilfsmittel wie Skripte oder Notizen sind nicht zul√§ssig. Die Pr√ºfung findet (ausschlie√ülich) in Pr√§senz statt.\n\nAllgemeine Pr√ºfungshinweise\n\n\nHinweise zu quantitativen Pr√ºfungen\nHinweise zum Ablauf von Klausuren\nPr√ºfungsvorbereitung\n\nIn Kapitel 12 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren k√∂nnen:\n@book{sauer_startbayes,\n    title = {Start:Bayes},\n    rights = {CC-BY-NC},\n    url = {https://start-bayes.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2025},\n}\nHier ist die DOI:\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Start:Bayes!",
    "section": "\n1.8 Zum Autor",
    "text": "1.8 Zum Autor\nN√§here Hinweise zum Autor, Sebastian Sauer, finden Sie hier.\n\n\n\n\nForum, W. E. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html",
    "href": "0200-Inferenz.html",
    "title": "\n2¬† Inferenz\n",
    "section": "",
    "text": "2.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#lernsteuerung",
    "href": "0200-Inferenz.html#lernsteuerung",
    "title": "\n2¬† Inferenz\n",
    "section": "",
    "text": "2.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n2.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie drei Zielarten der Statistik nennen und beschreiben k√∂nnen\ndie Definition von Inferenzstatistik sowie Beispiele f√ºr inferenzstatistische Fragestellungen nennen\nzentrale Begriffe der Inferenzstatistik nennen und in Grundz√ºgen erkl√§ren\nden Nutzen von Inferenzstatistik nennen\nerl√§utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nanhand von Beispielen erkl√§ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen frequentistischer (‚Äúklassischer‚Äù) und Bayes-Inferenz benennen\nVor- und Nachteile der frequentistischen vs.¬†Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erkl√§ren\n\n2.1.3 Begleitliteratur\nBei Gelman et al. (2021), Kap. 1 findet sich eine Darstellung √§hnlich zu der in diesem Kapitel. Die Begleitliteratur ist nicht pr√ºfungsrelevant; sie dient zur Vertiefung und als Grundlage einer ausf√ºhrlicheren Erl√§uterung des Stoffes.\n\n2.1.4 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. ‚ÄúRahmen‚Äù\n\nStatistik 1, dort alle Inhalte aller Kapitel zum Thema ‚ÄúModellieren‚Äù bzw. ‚ÄúRegression‚Äù\nStatistik 1, Kap. zur Normalverteilung\n\n2.1.5 Begleitvideos\n\nVideo zur Inferenz, Teil 1\nVideo zur Inferenz, Teil 2\n\n2.1.6 Wozu ist Statistik √ºberhaupt da?\nüì∫ Ja, wozu ist Statistik eigentlich da?\nJa, diese Frage haben Sie sich auch schon mal gestellt? Abb. Abbildung¬†2.1 gibt einen √úberblick √ºber die Zielarten der statistikbasierten wissenschaftlichen Forschung.1 Nach dieser Einteilung lassen sich drei Arten von Zielen unterscheiden: Beschreiben, Vorhersagen und Erkl√§ren (Shmueli, 2010).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#die-drei-zielarten-der-statistik",
    "href": "0200-Inferenz.html#die-drei-zielarten-der-statistik",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.2 Die drei Zielarten der Statistik",
    "text": "2.2 Die drei Zielarten der Statistik\n\n2.2.1 √úberblick\n\n2.2.1.1 üìÑ Beschreiben (deskriptiv)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von Gr√∂√üe und Gewicht (bei Erwachsenen) in meiner Stichprobe?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note (im Fach Statistik) in meinem Datensatz?\nHaben unsere Kunden bisher Webshop A oder B laut unseren Daten?\n\n2.2.1.2 üîÆ Vorhersagen (pr√§diktiv, prognostisch)\n\nWie schwer ist ein deutscher Mann der Gr√∂√üe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts f√ºr die Klausur lernt?\nWie viel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufh√§lt?\n\n2.2.1.3 üîó Erkl√§ren\nKausalinferenz:\n\nIst Gr√∂√üe eine Ursache von Gewicht (bei deutschen M√§nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\n\nPopulationsinferenz:\n\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note (im Fach Statistik) in der Grundgesamtheit?\nWie stark ist der (lineare) Zusammenhang \\(r\\) von Gr√∂√üe und Gewicht (bei Erwachsenen) in der Grundgesamtheit?\nBevorzugen unsere Kunden allgemein Webshop A oder B laut unseren Daten?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erkl√§rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie geh√∂rt. Um das Erkenntnisziel festzustellen, liest man sich die Forschungsfrage oder das Ziel der Studie durch.\n\n\n\nBeispiel 2.1 (Beispiele f√ºr die Zielarten statistischer Analysen) ¬†\n\nBeschreiben: ‚ÄúWie gro√ü ist der Gender-Paygap in der Branche X im Zeitraum Y?‚Äù\nVorhersagen: Wenn eine Person, Mr.¬†X, 100 Stunden auf die Statistikklausur lernen, welche Note kann diese Person dann erwarten?\nErkl√§ren: Wie viel bringt (mir) das Lernen auf die Statistikklausur?\\(\\square\\)\n\n\n\nF√ºr die Wissenschaft ist Erkl√§ren das wichtigste Ziel. Bei wenig beackerten Wissenschaftsfeldern ist das Beschreiben ein sinnvoller erster Schritt. Vorhersagen ist mehr f√ºr die Praxis als f√ºr die Wissenschaft relevant.\n\n\n\n\n\nflowchart TD \n  A{Ziele} --&gt; B(Beschreiben)\n  A --&gt; C(Vorhersagen)\n  A --&gt; D(Erkl√§ren)\n  B --&gt; E(Verteilung)\n  B --&gt; F(Zusammenhang)\n  C --&gt; H(Punktsch√§tzung)\n  C --&gt; I(Bereichssch√§tzung)\n  D --&gt; J(Kausalinferenz)\n  D --&gt; K(Populationsinferenz)\n\n\n\n\nAbbildung¬†2.1: Eine Einteilung zentraler Ziele von statistischen Analysen",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-beschreiben",
    "href": "0200-Inferenz.html#zielart-beschreiben",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.3 Zielart Beschreiben\n",
    "text": "2.3 Zielart Beschreiben\n\nStatistische Analysen mit dem Ziel zu beschreiben fassen die Daten zusammen (zu m√∂glichst aussagekr√§ftigen Kennzahlen). Beschreibende Statistik nennt man auch deskriptive Statistik; Mittelwert, Korrelation und Regressionskoeffizienten sind typische Kennzahlen (‚ÄúStatistiken‚Äù); s. Abbildung¬†2.2.\n\n\n\n\n\n\n\n\n\n(a) Die deskriptive Statistik fasst eine Spalte zu einer einzelnen Zahl zusammen.\n\n\n\n\n\n\n\n\n\n(b) Zwei Spalten werden zu einer Zahl zusammengefasst\n\n\n\n\n\n\nAbbildung¬†2.2: Beschreibende Statistik fasst eine oder mehr Variablen eines Datensatzes zu einer einzelnen Kennzahl zusammen.\n\n\nDer beschreibenden Statistik geht es nicht darum, Erkenntnisse zu ziehen, die √ºber die Daten hinaus gehen. So ist man in der beschreibenden Statistik nicht daran interessiert, Aussagen √ºber die zugrundeliegende Population anzustellen.\n\nBeispiel 2.2 In einem H√∂rsaal sitzen 100 Studis. Alle schreiben Ihre K√∂rpergr√∂√üe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der K√∂rpergr√∂√üe der anwesenden Studentis aus. Voil√†: Deskriptive Statistik!\\(\\square\\)\n\n\nDefinition 2.1 (Deskriptivstatistik) Deskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-vorhersagen",
    "href": "0200-Inferenz.html#zielart-vorhersagen",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.4 Zielart Vorhersagen\n",
    "text": "2.4 Zielart Vorhersagen\n\nBeim Vorhersagen versucht man, auf Basis von Daten, gegeben bestimmter Werte der UV den Wert einer AV vorherzusagen, s. Abbildung¬†2.3.\n\nBeispiel 2.3 (Toni lernt f√ºr die Klausur) Oh nein, die Klausur im Fach Statistik steht an. Toni lernt ziemlich viel. Wie viel Punkte (von 100 m√∂glichen) wird er wohl erzielen? Ziehen wir ein einfaches statistisches Modell zur Rate, um eine Vorhersage f√ºr den ‚ÄúKlausurerfolg‚Äù von Toni zu erhalten. Wir k√∂nnen vom Modell eine einzelne Zahl (83) als Punkt-Sch√§tzwert bzw. Vorhersagewert erhalten oder einen Sch√§tzbereich (80-80 Punkte). \\(\\square\\)\n\nHier ist das Regressionsmodell f√ºr Toni (lm_toni), s. Listing¬†2.1.\n\n\n\nListing¬†2.1: Regressionsmodell f√ºr Klausurerfolg als Funktion der Lernzeit (lm_toni)\n\nCodenoten2 &lt;- read.csv(\"data/noten2.csv\")\nlm_toni &lt;- lm(y ~ x, data = noten2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Regressionsgerade mit Punkt-Vorhersage f√ºr Toni\n\n\n\n\n\n\n\n\n\n(b) Regressionsgerade mit Vorhersagebereich (und herangezoomt) f√ºr Toni\n\n\n\n\n\n\nAbbildung¬†2.3: Noten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Die Vorhersage f√ºr Toni ist farbig markiert. Toni hat 42 Stunden gelernt f√ºr die Klausur; das Modell sagt ihm 83 Punkte (von 100) bzw. einen Bereich von 80 bis 86 Punkten voraus.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-erkl√§ren-kausalinferenz",
    "href": "0200-Inferenz.html#zielart-erkl√§ren-kausalinferenz",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.5 Zielart Erkl√§ren ‚Äì Kausalinferenz",
    "text": "2.5 Zielart Erkl√§ren ‚Äì Kausalinferenz\nMittels Kausalinferenz k√∂nnen wir schlie√üen, welche Variablen Ursachen und welche Wirkung sind ‚Äì und welche Variablen Scheinkorrelation erzeugen. Das ist wichtig, denn nur wenn man die Ursache kennt, wei√ü man, was man tun muss, um eine Wirkung zu erzielen.\n\n2.5.1 Studie A: √ñstrogen\n\n2.5.1.1 Medikament einnehmen?\nMit Blick auf Tabelle¬†2.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelle¬†2.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nM√§nner\n81/87 √ºberlebt (93%)\n234/270 √ºberlebt (87%)\n\n\nFrauen\n192/263 √ºberlebt (73%)\n55/80 √ºberlebt (69%)\n\n\nGesamt\n273/350 √ºberlebt (78%)\n289/350 √ºberlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualit√§t (Beobachtungsstudie). Bei M√§nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und M√§nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl et al., 2016)?\n\n2.5.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (√ñstrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (√ñstrogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in Abbildung¬†2.4 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†2.4: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender √ºber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige L√∂sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder ‚ÄúSchichten‚Äù (‚ÄúStrata‚Äù).\n\n\n\n2.5.2 Studie B: Blutdruck\n\n2.5.2.1 Medikament einnehmen?\nMit Blick auf Tabelle¬†2.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelle¬†2.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 √ºberlebt (93%)\n234/270 √ºberlebt (87%)\n\n\nhoher Blutdruck\n192/263 √ºberlebt (73%)\n55/80 √ºberlebt (69%)\n\n\nGesamt\n273/350 √ºberlebt (78%)\n289/350 √ºberlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualit√§t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe √ºber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl et al., 2016)?\n\n2.5.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament sch√§dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in Abbildung¬†2.5 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†2.5: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer sch√§dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den n√ºtzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren w√§re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar w√§re.\n\n\n\n2.5.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs Abbildung¬†2.4 und Abbildung¬†2.5, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen f√ºr Handlungen - war nur m√∂glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n2.5.4 Sorry, Statistik: Du allein schaffst es nicht\nDatenanalyse alleine reicht nicht f√ºr Kausalschl√ºsse. üßü\nDatenanalyse plus Kausalinferenz erlaubt Kausalschl√ºsse. üìö‚ûïüìä üü∞ ü§©\n\n\n\n\n\n\nWichtig\n\n\n\nF√ºr Entscheidungen (‚ÄúWas soll ich tun?‚Äù) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#zielart-erkl√§ren-populationsinferenz",
    "href": "0200-Inferenz.html#zielart-erkl√§ren-populationsinferenz",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.6 Zielart Erkl√§ren ‚Äì Populationsinferenz",
    "text": "2.6 Zielart Erkl√§ren ‚Äì Populationsinferenz\n\n\n\n\n\nüì∫ Was ist Inferenz?\n\n2.6.1 Populationsinferenz ist das Schlie√üen von der Stichprobe auf die Grundgesamtheit\nStatistische Populationsinferenz ‚Äì meist kurz als Inferenz bezeichnet ‚Äì hat zum Ziel, vom Teil aufs Ganze zu schlie√üen, bzw. vom Konkreten auf das Abstrakte. In der Datenanalyse hei√üt das: Was sagt meine Datensatz, der auf einer Stichprobe beruht, √ºber die zugrundeliegende Grundgesamtheit aus?\n\nTypischerweise untersuchen im Rahmen einer statistischen Analyse eine Stichprobe, wie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht ‚ÄúTolle Studie zu dem Geheimnis des Gl√ºcks!!!‚Äù zu klicken. Ihr Freundeskreis ist ein Teil der Menschen (z.B. aus Deutschland), also eine Stichprobe. Schauen wir uns den Unterschied zwischen Stichprobe und Population n√§her an. \\(\\square\\)\n\n\n2.6.2 Stichprobe vs.¬†Population\nNehmen wir an, wir m√∂chten herausfinden, wie gro√ü der Anteil der R-Fans in der Grundgesamthit (synonym: Population) aller Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A2.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.\nWir m√ºssen also den Anteil der R-Fans in der Population auf Basis des Anteils in der Stichprobe schlie√üen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. Abbildung¬†2.6.\n\n\n\n\n\n\nPopulation\n\n\n\n\n\nSample\n\n\n\n\n\nAbbildung¬†2.6: Population vs.¬†Stichprobe. Die Stichprobe entnimmt einen Teil der Daten der Population. Autor: Karsten L√ºbke. Lizenz: OEM.\n\n\nH√§ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!3. Man schreibt: \\(p = 0.42\\) (p wie proportion, engl. f√ºr ‚ÄúAnteil‚Äù). Die Stichprobe sei repr√§sentativ f√ºr die Grundgesamtheit aller Studierender. Messerscharf schlie√üen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische (\\(\\pi\\)) f√ºr Populationen.\\(\\square\\)\n\n\n\nDefinition 2.2 ((Populations-)Inferenzstatistik) Populations-Inferenzstatistik ‚Äì meist kurz als Inferenzstatistik bezeichnet ‚Äì ist ein Verfahren zum Schlie√üen von Statistiken (eine Kennzahl einer Stichprobe) auf Parameter (eine Kennzahl einer Grundgesamtheit). Inferenz bedeutet Schlie√üen bzw. Schlussfolgern: auf Basis von vorliegenden Wissen wird neues Wissen generiert. Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage auf allgemeine Aussagen zu schlie√üen. Wir unterscheiden zwei Hauptarten der Inferenzstatistik:\n\nPopulationsinferenz\nKausalinferenz \\(\\square\\)\n\n\n\n\n√úbungsaufgabe 2.1 üèãÔ∏èÔ∏è Heute Nacht vor dem Schlafen wiederholen Sie die Definition. √úben Sie jetzt schon mal.\\(\\square\\)\n\n\n2.6.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nF√ºr jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Populationsinferenz verwenden, um den zugeh√∂rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle Tabelle¬†2.3. Da man die Parameter der Population so gut wie nie sicher kennt (schlie√ülich hat man meist nur Ausz√ºge, Teile der Population, also Stichproben), muss man sich mit Sch√§tzwerten begn√ºgen.\n\n\n\nTabelle¬†2.3: Bezeichnungen f√ºr Kennwerte\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit (Aussprache)\nSch√§tzwert\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\n\\(\\mu\\) (m√º)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\n\\(\\sigma\\) (sigma)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\n\\(\\pi\\) (pi)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\n\\(\\rho\\) (rho)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\n\\(\\beta\\) (beta)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n\nF√ºr Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; f√ºr Parameter (Population) verwendet man griechische Buchstaben.\n\n√úbungsaufgabe 2.2 üèãÔ∏è Geben Sie die griechischen Buchstaben f√ºr typische Statistiken an. Ohne auf die Tabelle zu schauen.üòú\\(\\square\\)!\n\n\n2.6.4 Sch√§tzen von Parametern einer Grundgesamtheit\nMeist begn√ºgt man sich beim Analysieren von Daten nicht mit Aussagen f√ºr eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit Sch√§tzungen begn√ºgen. Sch√§tzwerte werden mit einem ‚ÄúDach‚Äù √ºber dem Kennwert gekennzeichnet, s. letzte Spalte in Tabelle¬†2.3.\nIn der angewandten Forschung interessieren h√§ufig Fragen wie: ‚ÄúWelche Entscheidung ist (wahrscheinlich) besser?‚Äù. Da bekanntlich (fast) keine Aussagen sicher sind, spielt Wahrscheinlichkeit eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinlichkeit wird oft mit Pr oder p abgek√ºrzt, f√ºr engl. probability.\\(\\square\\)\n\n\n\nBeispiel 2.4 Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.¬†V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\). Die Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} &gt; \\bar{X}_{V2}\\). Sind diese Unterschiede ‚Äúzuf√§llig‚Äù oder ‚Äúsubstanziell‚Äù? Gilt also \\(\\mu_{V1} &gt; \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)? Wie gro√ü ist die Wahrscheinlichkeit \\(Pr(\\mu_{V1} &gt; \\mu_{V2})\\)?\n\n\n√úbungsaufgabe 2.3 üèãÔ∏è VERTIEFUNG Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!\\(\\square\\)\n\n\n√úbungsaufgabe 2.4 (Peer Instruction: Regressionskoeffizienten) Eine Regressionsgerade wird durch zwei Koeffizienten festgelegt: ihren Achsenabschnitt, \\(\\beta_0\\), sowie ihre Steigung, \\(\\beta_1\\). Berechnet man also eine Regressionsgerade, so verfolgt man damit welche Zielart der Statistik?\n\nBeschreiben\nVorhersagen\nErkl√§ren - Kausal\nErkl√§ren - Population\nKeine der oben \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#modellieren",
    "href": "0200-Inferenz.html#modellieren",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.7 Modellieren",
    "text": "2.7 Modellieren\n\n2.7.1 Modellieren als Grundraster des Erkennens\nIn In der Wissenschaft ‚Äì wie auch oft in der Technik, Wirtschaft oder im Alltag ‚Äì betrachtet man einen Teil der Welt n√§her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen. Nun ist die Welt ein weites Feld. Jedes Detail zu ber√ºcksichtigen ist nicht m√∂glich. Wir m√ºssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend n√∂tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die f√ºr unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\nDefinition 2.3 (Modell) Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit.\\(\\square\\)\n\nDer Nutzen eines Modells ist, einen (√ºberm√§√üig) komplexen Sachverhalt zu vereinfachen oder √ºberhaupt erst handhabbar zu machen. Man versucht zu vereinfachen, ohne Wesentliches wegzulassen. Der Speck muss weg, sozusagen. Das Wesentliche bleibt.\nAuf die Statistik bezogen hei√üt das, dass man einen Datensatz dabei so zusammenfasst, damit man das Wesentliche erkennt.\nWas ist das ‚ÄúWesentliche‚Äù? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. Etwa: ‚ÄúWie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?‚Äù4 Noch allgemeiner ist man dabei h√§ufig am Zusammenhang von X und Y interessiert, s. Abbildung¬†2.7, die ein Sinnbild von statistischen Modellen widergibt.\nWas ist das ‚ÄúWesentliche‚Äù? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. Etwa: ‚ÄúWie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?‚Äù5 Noch allgemeiner ist man dabei h√§ufig am Zusammenhang von X und Y interessiert, s. Abbildung¬†2.7, die ein Sinnbild von statistischen Modellen widergibt.\n\n\n\n\n\n\n\nflowchart LR\nX --&gt; Y\n\n\nX1 --&gt; Y2\nX2 --&gt; Y2\n\n\n\n\n\n\n\n\nAbbildung¬†2.7: oben: Sinnbild eines einfachen statistischen Modellsb (eine UV, eine AV); unten: Sinnbild eines statistischen Modells, mit zwei UV\n\n\nMan kann Abbildung¬†2.7 als ein Sinnbild einer (mathematischen) Funktion lesen.\n\nDefinition 2.4 (Funktion) Eine mathematische Funktion \\(f\\) setzt zwei Gr√∂√üen in Beziehung. \\(\\square\\)\n\nIn Mathe-Sprech: \\(f: X \\rightarrow Y\\), lies: ‚Äú\\(f\\) bildet \\(X\\) auf \\(Y\\) ab.‚Äù\noder: \\(y = f(x)\\), lies: ‚ÄúY ist eine Funktion von X‚Äù. \\(\\square\\)\nEs h√∂rt sich zugespitzt an, aber eigentlich ist fast alles, was man tut, Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst. Die Statistik kann man verstehen als ein Verfahren, dass wissenschaftliche Modelle in statistische √ºbersetzt und letztere dann einer empirischen Analyse unterzieht. Alle statistischen Ergebnisse beruhen auf Modelle und sind nur insoweit g√ºltig, wie das zugrundeliegende Modell g√ºltig ist.\n\n\n\n\n\n\nHinweis\n\n\n\nNutzen Sie die √úbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#regression",
    "href": "0200-Inferenz.html#regression",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.8 Regression",
    "text": "2.8 Regression\n\n2.8.1 Regression zum Modellieren\nEinflussreiche Leute schw√∂ren auf die Regressionsanalyse (Abbildung¬†2.8).\n\n\n\n\n\nAbbildung¬†2.8: Eine Regression\n\n\nAbbildung¬†2.9 zeigt ein interaktives Beispiel einer linearen Funktion. Sie k√∂nnen Punkte per Klick/Touch hinzuf√ºgen.\nCoderesetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\nCodeviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"Kein Fehler\", \"Absoluter Fehler\", \"Quadrierter Fehler\"],\n    { label: \"View\", value: \"Absoluter Fehler\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\nCoderSquaredPlot = RSquaredPlot({ width: width })\nCoderegressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\nCodewidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\nCodeanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\nCodefunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R¬≤\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\nCode// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\nCoded3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelle\n\n\n\nAbbildung¬†2.9: Interaktives Beispiel f√ºr eines lineares Modell. F√ºgen Sie Punkte per Klick/Touch hinzu.\n\n\nAlternativ k√∂nnen Sie diese App nutzen, Regressionskoeffizienten, Steigung (slope) und Achsenabschnitt (Intercept), zu optimieren. Dabei meint ‚Äúoptimieren‚Äù, die Abweichungen (Residuen, Residualfehler; die roten Balken in der App) zu minimieren.6\nHier finden Sie eine App, die Ihnen gestattet, selber Hand an eine Regressionsgerade zu legen.\n\n√úbungsaufgabe 2.5 (VERTIEFUNG Regression mit Animationen erkl√§rt) Lesen Sie diesen Post, der Ihnen mit Hilfe von Bildern und Animationen (okay, und etwas) Text die Grundlagen der Regressionsanalyse erkl√§rt.\\(\\square\\)\n\nDie Regression ist eine Art Schweizer Taschenmesser der Statistik: F√ºr vieles gut einsetzbar. Anstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch sch√∂ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden. Dann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nHinweis\n\n\n\nRegression + Inferenz = üíñ\n\n\nAlternativ zur Regression k√∂nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni M√ºnster als Ausschnitt (!) aufgef√ºhrt. Auf dieser Basis kann man meditieren, welches statistischen Verfahren man f√ºr eine bestimmte Fragestellung verwenden sollte, s. Abbildung¬†2.10 (b). Muss man aber nicht ‚Äì man kann stattdessen die Regression benutzen.\n\n\n\n\n\n\nHinweis\n\n\n\nEs ist meist einfacher und n√ºtzlicher, die Regression zu verwenden, anstelle der Vielzahl von anderen Verfahren (die zumeist Spezialf√§lle der Regression sind). In diesem Kurs werden wir f√ºr alle Fragestellungen die Regression verwenden.7\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Die eine Regression\n\n\n\n\n\n\n\n\n\n(b) Wald von anderen Verfahren\n\n\n\n\n\n\nAbbildung¬†2.10: W√§hle die Regression. Oder den Wahl der Verfahren. Spoiler: Nimm lieber die Regression.\n\n\n\nBeispiel 2.5 Typische Spezialf√§lle der Regression sind\n\nt-Test: UV: zweistufig nominal, AV: metrisch\nANOVA: UV: mehrstufig nominal, AV: metrisch\nKorrelation: Wenn UV und AV z-standardisiert sind (d.h. Mittelwert von 0 und Standardabweichung von 1 haben), dann ist die Korrelation gleich dem Regressionskoeffizienten \\(\\beta_1\\) (bei einer einfachen Regression mit einer einzigen UV). \\(\\square\\)\n\n\n\n\n\n2.8.2 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; s. Abbildung¬†2.11. Links sieht man eine einfache Regression mit hp als UV (X, auch: Pr√§diktor) und mpg als AV (Y). Das rechte Teildiagramm zeigt eine multiple Regression mit den UVs hp und am.8\nIm einfachsten Fall sind die vom Modell vorhergesagten (gesch√§tzten) Werte, \\(\\hat{y}\\), durch eine einfache Gerade beschrieben, s. Abbildung¬†2.11, links.\n\nIn allgemeiner Form schreibt man die Regressionsgleichung als lineare Gleichung, d.h. in Form einer Gerade, s. Theorem¬†2.1. \\(\\square\\)\n\n\nTheorem 2.1 (Lineares Modell (Regressionsgleichung)) \\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nMan nennt alle \\(\\beta_0, \\beta_1, \\beta_2, ...\\) die Koeffizienten, Regressionsgewichte oder Parameter des Modells (Gelman et al., 2021). Dabei ist \\(\\beta_0\\) der Achsenabschnitt (eng. intercept) und \\(\\beta_1\\) die Steigung der Regressiongeraden. \\(\\square\\)\n\nAnhand von Theorem¬†2.1 erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet.\nEine Regressionsgerade ist durch zwei Parameter festgelegt: den Achsenabschnitt, \\(\\beta_0\\) und die Steigung, \\(\\beta_1\\), s. Abbildung¬†2.11.\n\n\n\n\n\n\n\n\n\n(a) Einfache Regression (eine UV: hp)\n\n\n\n\n\n\n\n\n\n(b) Multiple Regression (zwei UV: hp und am)\n\n\n\n\n\n\nAbbildung¬†2.11: Die Regressionsgerade in voller Pracht",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#ungewissheit",
    "href": "0200-Inferenz.html#ungewissheit",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.9 Ungewissheit",
    "text": "2.9 Ungewissheit\n\n2.9.1 Inferenz beinhaltet Ungewissheit\nInferenzstatistische Schl√ºsse sind mit Ungewissheit (Unsicherheit √ºber die Zuverl√§ssigkeit der Ergebnisse) behaftet: Schlie√ülich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), m√∂chte aber vom Teil auf das Ganze schlie√üen. Aus diesem begrenzten Wissen resultiert notwendig Ungewissheit √ºber die gesamte Population.\n\n\n\n\n\n\nWichtig\n\n\n\nNichts Genaues wei√ü man nicht: Schlie√üt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man sich auf die Unsicherheit das Wissen √ºber die Genauigkeit des Schlie√üens bezieht\n\n\nSchlie√üt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit; es ist ungewiss. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger.\nSchlie√ülich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen f√ºr die Stichprobe (Messfehler einmal ausgeblendet). Zur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer m√∂glich). Die Wahrscheinlichkeitstheorie bzw. -rechnung wird daher auch als die Mathematik des Zufalls bezeichnet.\n\nDefinition 2.5 (Zuf√§lliges Ereignis) Unter einem zuf√§lligen (engl. random) Ereignis verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres n√§chsten W√ºrfelwurfs. Zuf√§llig bedeutet nicht (zwangsl√§ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines W√ºrfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\n√úbungsaufgabe 2.6 üèã Welche physikalischen Randbedingungen wirken wohl auf einen M√ºnzwurf ein?\\(\\square\\)\n\n\nBeispiel 2.6 (Beispiele zur Quantifizierung von Ungewissheit) Aussagen mit Unsicherheit k√∂nnen unterschiedlich pr√§zise formuliert sein.\n\nMorgen regnet‚Äôs \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert von \\(Y\\) f√ºr Methode \\(A\\) h√∂her als f√ºr Methode \\(B\\).\nDie Maschine f√§llt demn√§chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den n√§chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n\n\n√úbungsaufgabe 2.7 üèã Geben Sie weitere Beispiele an!\n\n\n2.9.2 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben:\n\nWie (un)gewiss ist man sich √ºber die Regressionsgewichte?\nWie (un)gewiss ist man sich √ºber die Vorhersagegenauigkeit?\n\n\n2.9.2.1 Betas: Ungewissheit zur Regressionsgeraden\nWenn wir von den Daten der Stichproben auf die Grundgesamtheit schlie√üen, k√∂nnen wir nicht sicher sein, ob die Regressionskoeffizienten (Achsenabschnitt, Steigung der Regressiongeraden) exakt richtig sind, s. Abbildung¬†2.12.\n\n\n\n\n\n\n\n\n\n(a) Ungewissheit f√ºr den Achsenabschnitt\n\n\n\n\n\n\n\n\n\n(b) Ungewissheit f√ºr die Steigung der Regressionsgeraden\n\n\n\n\n\n\nAbbildung¬†2.12: Wir k√∂nnten nicht sicher sein, dass der Achsenabschnitt und die Geradensteigung unseres Modells exakt richtig sind. Diese Werte k√∂nnten auch etwas gr√∂√üer oder kleiner sein.\n\n\nWie man in Abbildung¬†2.13 sieht, k√∂nnen sich die Koeffizienten des Modells (\\(\\beta_0\\), Achsenabschnitt und \\(\\beta_1\\), Steigung) unterscheiden. Woran liegt das?\n\nBeispiel 2.7 (Stichproben der New Yorker Fl√ºge) Nehmen wir an, wir ziehen ein paar Zufallstichproben aus der Menge (Population) aller Fl√ºge, die in New York im Jahre 2013 gestartet sind. In jeder Stichprobe berechnen wir eine Regression zwischen Flugzeit und Versp√§tung des Flugs am Ankunftsort. Sicherlich werden sich die Stichproben in ihren Kennwerten, z.B. in den Koeffizienten der genannten Regression, unterscheiden.\\(\\square\\)\n\n\nCodelibrary(nycflights13)\ndata(flights)\n\nstipro1 &lt;- sample_n(flights, size = 100)\nstipro2 &lt;- sample_n(flights, size = 100)\nstipro3 &lt;- sample_n(flights, size = 100)\n\n\n\n\n\n\n\n\n\n\n\n(a) Stichprobe 1\n\n\n\n\n\n\n\n\n\n(b) Stichprobe 2\n\n\n\n\n\n\n\n\n\n(c) Stichprobe 3\n\n\n\n\n\n\nAbbildung¬†2.13: Regressionsanalysen mit verschiedenen Koeffizienten aufgrund der Zuf√§lligkeit des Stichprobenziehens\n\n\nDer Grund f√ºr die Schwankungen der Modellparameter zwischen den Stichproben ist die Zuf√§lligkeit des Stichprobenziehens. Je nachdem, wie es der Zufall (oder sonst wer) will, landen bestimmte F√§lle (Fl√ºge in unserem Beispiel) in unserer Stichprobe. Zumeist unterscheiden sich die Stichproben; theoretisch k√∂nnten sie aber auch rein zuf√§llig gleich sein.\n\n\n\n\n\n\nWichtig\n\n\n\nStichproben-Kennwerte schwanken um den tats√§chlichen Wert in der Population herum. \\(\\square\\)\n\n\nUm diese Ungewissheit, die sich in den Schwankungen der Stichproben-Regressionskoeffizienten ausdr√ºckt, anzuzeigen, ist ein ‚Äúgrauer Schleier‚Äù um die Regressionsgeraden in Abbildung¬†2.13 gekennzeichnet. Dieser grauer Schleier gibt also eine Spannbreite anderer, plausibler Ergebnisse an, die sich in einer anderen Stichprobe auch manifestieren k√∂nnten.\n\n2.9.2.2 Sigma: Ungewissheit zur Genauigkeit der Vorhersage\nAngenommen, wir sind uns sicher √ºber die Werte der Modellparameter (\\(\\beta_0, \\beta_1\\)). also √ºber die Lage der Regressionsgeraden, anschaulich gesprochen. Dann bliebe immer noch Ungewissheit, wie genau die Vorhersagen sind, wie gro√ü also die Abst√§nde zwischen vorhergesagten und tats√§chlichen Werten. Wenn nicht die richtigen UVs im Modell sind (relevante fehlen oder auch irrelevante sind enthalten), dann liegen Vorhersagen und wirkliche Werte weiter auseinander: diese Streuung kann man als ‚ÄúRauschen‚Äù bezeichnen, s. Abbildung¬†2.14.\nDiese Art der Ungewissheit ist dann interessant, wenn man Vorhersagen macht und sich fragt, wie pr√§zise diese Vorhersage ist.\nDie Pr√§zision eines Modells kann man mit einem von zwei Kennwerten ausdr√ºcken, die die gleiche Aussage machen. Diese zwei Kennwerte sind \\(R^2\\) (R-Quadrat) und \\(\\sigma\\) (sigma).\n\nDefinition 2.6 (Sigma als mittleren Vorhersagefehler) \\(\\sigma\\) gibt (grob gesagt) den mittleren Vorhersagefehler des Modells an. Einfach gesprochen sagt \\(\\sigma\\) wie weit eine Vorhersage im Durchschnitt vom wahren Wert entfernt ist. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) geringer Vorhersagefehler (hohe Vorhersageg√ºte)\n\n\n\n\n\n\n\n\n\n(b) hoher Vorhersagefehler\n\n\n\n\n\n\n\n\n\n(c) auch hoher Vorhersagefehler\n\n\n\n\n\n\nAbbildung¬†2.14: Regressionsanalyse mit gleicher Regressionsgerade, aber unterschiedlicher Vorhersageg√ºte. Die Vorhersagefehler sind mit mit farbigen vertikalen Balken markiert. Je k√ºrzer die Balken, desto besser (genauer) die Vorhersage.\n\n\n\n2.9.3 Ich wei√ü, was ich nicht wei√ü: Ungewissheit angeben\nStreng genommen ist eine Inferenz ohne Angabe der Ungewissheit (Genauigkeit der Sch√§tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% sch√§tzt, l√§sst aber offen wie sicher (pr√§zise) die Sch√§tzung (der Modellparameter) ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Sch√§tzung schlie√üt sogar 41% oder 43% aus.\n\n\n\n\n\n\nWichtig\n\n\n\nSchlie√üt man auf eine Population, sch√§tzt also die Modellparameter, so sollte stets die (Un-)Genauigkeit der Sch√§tzung, also die Ungewissheit des Modells, angegeben sein.\\(\\square\\)\n\n\nIm Rahmen der Regressionsanalyse schl√§gt sich die Ungewissheit an zwei Stellen (und in drei Parametern) nieder:\n\nzur Pr√§zision der Regressionsgeraden \\(\\beta_0\\), \\(\\beta_1\\)\n\nzur Modellg√ºte (\\(R^2\\)) bzw. zum Vorhersagefehler, \\(\\sigma\\)9\n\n\n2.9.4 Konfidenzintervall\nWir haben gesesehen, dass wir die Werte der Parameter nur mit Ungewissheit angegeben k√∂nnen (s. Abbildung¬†2.12 und Abbildung¬†2.14). Um dieser Ungewissheit Rechnung zu tragen, gibt man nicht nur einen einzelnen Wert an, einen Punktsch√§tzer, sondern man gibt ein Sch√§tzbereich an auf Basis der Daten, s. Tabelle¬†2.4.\n\nCodemodel_parameters(lm_toni) |&gt; \n  print_md()\n\n\nTabelle¬†2.4: Punktsch√§tzer und Sch√§tzbereiche f√ºr die Modellkoeffizienten von lm_toni\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(98)\np\n\n\n\n(Intercept)\n46.19\n5.14\n(35.99, 56.39)\n8.98\n&lt; .001\n\n\nx\n0.88\n0.10\n(0.68, 1.08)\n8.92\n&lt; .001\n\n\n\n\n\n\n\n\nUnser Modell gibt den 95%-Sch√§tzbereich f√ºr den Achsenabschnitt an ca. von 36 bis 56 Klausurpunkte Die Steigung wird gesch√§tzt auf ca. 0.7 bis 1.1 Klausurpunkte pro Stunde Lernzeit.\nMan spricht anstatt von Sch√§tzbereich auch von einem Konfidenzintervall.10\n\nDefinition 2.7 (Konfidenzintervall) Ein Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff f√ºr Sch√§tzbereiche f√ºr Parameter wie Regressionskoeffizienten. Die Grenzen eines Konfidenzintervall markieren die Grenzen eines Bereichs plausibler Werte f√ºr einen Parameter.\n\nEs gibt verschiedene Arten, Konfidenzintervalle zu berechnen; wir sprechen in sp√§teren Kapiteln dazu ausf√ºhrlicher. Ein Konfidenzintervall wird h√§ufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse - auf der dieser Kurs aufbaut - ist ein Konfidenzintervall einfach zu interpretieren. Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall f√ºr den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt. Dieser Befund l√§sst sich so interpretieren:\n\n‚ÄúLaut Modell liegt der gesuchte Anteil der R-Fans mit einer Wahrscheinlichkeit von 95% im Bereich von 40 bis 44 Prozentpunkten.‚Äù\n\nDiese (einfache) Interpretation ist im Frequentismus nicht m√∂glich.\n\n√úbungsaufgabe 2.8 Geben Sie Beispiele f√ºr Konfidenzintervalle an.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#frequentistische-inferenz-vs.-bayes-inferenz",
    "href": "0200-Inferenz.html#frequentistische-inferenz-vs.-bayes-inferenz",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.10 Frequentistische Inferenz vs.¬†Bayes-Inferenz",
    "text": "2.10 Frequentistische Inferenz vs.¬†Bayes-Inferenz\nEs gibt zwei Hauptarten von Inferenzstatistik: Frequentistische Inferenz und Bayes-Inferenz.\n\n\nFrequentismus: Klassische Inferenz\n\nDie Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zur√ºckgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein, keine Vorannahmen.\nWahrscheinlichkeit wird √ºber relative H√§ufigkeiten definiert.\nEs ist nicht m√∂glich, die Wahrscheinlichkeit einer Hypothese bzw. eines Werts in der Population (eines Parameters) anzugeben.\nStattdessen wird angegeben, wie h√§ufig eine vergleichbare Datenlage zu erwarten ist, wenn der Versuch sehr h√§ufig (unendlich oft) wiederholt ist.\nEin Gro√üteil der Forschung (in den Sozialwissenschaften) verwendet (aktuell) diesen Ansatz.\n\n\nBayesianische Inferenz\n\nVorwissen (Priori-Wissen) flie√üt explizit in die Analyse ein (zusammen mit den Daten).\n\nWenn das Vorwissen gut ist, wird die Vorhersage durch das Vorwissen genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen f√ºr Hypothesen m√∂glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (f√ºr g√§ngige Computer) komfortabel geworden.\n\n\n\n\n2.10.1 Frequentistische Inferenz und der p-Wert\nDer zentrale Kennwert der Frequentistische Inferenz (synonym: Frequentismus) ist der p-Wert.\nDer p-Wert ist so definiert, vgl. Wasserstein & Lazar (2016):\n\nWie hoch ist die Wahrscheinlichkeit eines empirischen Befunds (oder noch extremere Werte), vorausgesetzt die Nullhypothese \\(H_0\\) gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zuf√§llig verschieden und auf Basis unseres Modells)?\n\nEinfacher gesagt:\n\nDer p-Wert ist die Wahrscheinlichkeit, ein Ergebnis zu erhalten, das mindestens so extrem ist wie das beobachtete, unter der Annahme, dass es keinen Effekt gibt.\n\nNoch einfacher:\n\nMan nimmt an, dass es keinen Effekt gibt (z.B. kein Zusammenhang zwischen den untersuchten Variablen)\nDann fragt man: Wie √ºberraschend w√§ren meine Daten unter dieser Annahme?\nDer p-Wert gibt genau diese √úberraschungs-Wahrscheinlichkeit an.\n\n\n√úbungsaufgabe 2.9 üèã Recherchieren Sie eine Definition des p-Werts und lesen Sie sie einem Freund. Beobachten sie die Reaktionen auf Ihre Erkl√§rung.\\(\\square\\)\n\nDer p-Wert wird oft falsch verstanden (Badenes-Ribera et al., 2016). Aber er ist auch nicht leicht zu verstehen, meint Meister Yoda, s. Abbildung¬†2.15. Hier sind einige FALSCHE Interpretationen zum p-Wert laut der Autoren:\n\nüôÖ‚Äç‚ôÄ Der p-Wert w√ºrde die Wahrscheinlichkeit der Nullhypothese oder der Forschungshypothese angeben. üôä FALSCH!\nüôÖ‚Äç‚ôÄ Der p-Wert w√ºrde ein inhaltlich bedeutsames, praktisch signifikantes Ergebnis anzeigen. üôä FALSCH!\n\n\n\n\n\n\nAbbildung¬†2.15: Der p-Wert ist wenig intuitiv, meint Meister Yoda\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nEin frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters). Stattdessen wird eine Aussage √ºber das Ergebnis einer sehr h√§ufig wiederholten Stichprobenziehung berichtet. Ob ein bestimmtes (unseres, Ihres) den wahren Wert enth√§lt, bzw. mit welcher Wahrscheinlichkeit es den wahren Wert enth√§lt, dar√ºber macht das frequentistische Konfidenzintervall keine Aussagen. \\(\\square\\)\n\n\n\n2.10.2 Bayes-Inferenz\nDie zentrale Statistik der Bayes-Inferenz bzw. (synonym) Bayes-Statistik ist die Posteriori-Verteilung.\nDie Posteriori-Verteilung beantwortet uns die Frage: ‚ÄúWie wahrscheinlich ist die Forschungshypothese (oder Varianten von ihr), jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?‚Äù\nIn der Bayes-Statistik sind Aussagen folgender Art erlaubt:\n\nMit einer Wahrscheinlichkeit von 95% ist der neue Webshop besser als der alte. Mit einer Wahrscheinlichkeit von 89% liegt die Wirksamkeit des neuen Medikaments zwischen 0.1 und 0.4.\n\nIn diesem Post wird f√ºr Bayes geworben und (einseitig) Stellung pro Bayes bezogen.\n\n2.10.3 Statistische Signifikanz\nIm Frequentismus spricht man von statistischer Signifikanz, wenn der p-Wert kleiner ist als 5%: \\(p&lt;.05\\) (oder einen anderen Prozentwert als 5%, aber meistens wird 5% hergenommen). Man nimmt diesen Befund als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann. Faktisch entscheidet man sich, die Forschungshypothese weiterhin als ‚Äúvorl√§ufig g√ºltig‚Äù oder zumindest als ‚Äúnicht widerlegt‚Äù zu betrachten.\nIn der Bayes-Statistik ist der Begriff der Signifikanz nicht einheitlich definiert. Mit Bezug auf Gelman et al. (2021) (S. 57) wird in diesem Buch der Begriff wie folgt definiert - mit G√ºltigkeit sowohl f√ºr Bayes-Statistik als auch f√ºr Frequentistische Statistik.\n\nDefinition 2.8 (Statistische Signifikanz) Ist der Wert Null nicht im Sch√§tzbereich enthalten, so liegt ein statistisch signifikantes Ergebnis vor. \\(\\square\\)\n\nOft werden 95%-Konfidenzintervalle verwendet, obwohl das nur eine Konvention ist. Die Signifikanzaussage bezieht sich immer auf ein Sch√§tzbereich bestimmter Gr√∂√üe, z.B. 95% (und des Modells inklusive Daten).\nLiegt ein statistisch signifikantes Ergebnis vor, so verwirft man die Nullhypothese und akzeptiert die Alternativhypothese (synonym: Effekthypothese).\n\nDefinition 2.9 (Exakte Nullhypothese) Die exakte Nullhypothese (meist kurz nur als Nullhypothese bezeichnet), \\(H_0\\), besagt, dass kein (null) Effekt (keine Abweichung vom Referenzwert, kein Unterschied zwischen Gruppen, kein Zusammenhang zwischen UV und AV, Ver√§nderung vor vs.¬†nach der Intervention, ‚Ä¶) vorliegt. \\(\\square\\)\n\n\nDefinition 2.10 (Alternativhypothese (Effekthypothese)) Eine Hypothese, die besagt, dass es einen (substanziellen) Effekt gibt. Das kann z.B. ein Unterschied zwischen den untersuchten Gruppen sein oder ein Zusammenhang zwischen den untersuchten Variablen. Logisch betrachtet ist die Alternativhypothese meist das Gegenteil der Nullhypothese. \\(\\square\\)\n\n\nBeispiel 2.8 (Beispiele f√ºr Effekthypothesen) ¬†\n\nDie Trefferquote der M√ºnze ist \\(\\pi = .7\\) (Kopf), weicht also um 0.2 von 0.5, dem Wert laut Nullhypothese, ab.\nDer Unterschied im mittleren Gewicht zwischen den Gruppen betr√§gt ca. 500-600 g.\nDer Korrelationskoeffizient \\(\\rho\\) liegt bei ca. .5 bis .7, ist also nicht Null.\nDer standardisierte Regressionskoeffizient \\(\\beta\\) liegt bei ca. .1 bis .2, ist also nicht Null.\nDer Unterschied in Gestimmtheit vor vs.¬†nach der Induktion von Einsamkeit liegt bei \\(X_d = .3\\), ist also nicht Null. \\(\\square\\)\n\n\n\n\nBeispiel 2.9 (Beispiele f√ºr Nullhypothesen) ¬†\n\nH‚ÇÄ: Œº = 100 (Der Populationsmittelwert betr√§gt 100)\nH‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ (Es gibt keinen Unterschied zwischen den Mittelwerten zweier Gruppen)\nH‚ÇÄ: œÅ = 0 (Es besteht kein linearer Zusammenhang zwischen zwei Variablen)\nH‚ÇÄ: œÄ = 0.5 (Die Wahrscheinlichkeit f√ºr ‚ÄúErfolg‚Äù betr√§gt 50%; die M√ºnze ist ‚Äúfair‚Äù)\nH‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ = Œº‚ÇÑ (Alle Gruppenmittelwerte sind gleich; bei ANOVA)\nH‚ÇÄ: Œ≤‚ÇÅ = 0 (Der Regressionskoeffizient ist null; kein Effekt des Pr√§diktors)\nH‚ÇÄ: œÉ‚ÇÅ¬≤ = œÉ‚ÇÇ¬≤ (Die Varianzen zweier Populationen sind gleich) \\(\\square\\)\n\n\n\nStatistische Signifikanz im Frequentismus (nicht in der Bayes-Statistik) ist auch eine Funktion der Stichprobengr√∂√üe: Wenn die Stichprobe gro√ü genug ist, wird jeder Test signifikant. Daher hat ein signifikantes Ergebnis zwei m√∂gliche Ursachen: Der Effekt ist gro√ü oder (auch) die Stichprobe ist gro√ü, s. Abbildung¬†2.16.\n\n\n\n\n\nflowchart LR\nS[Stichprobengr√∂√üe]\nE[Effektgr√∂√üe]\np[p&lt;0.5]\nS--&gt;p\nE--&gt;p\n\n\n\n\nAbbildung¬†2.16: Der p-Wert ist nicht nur eine Funktion der Effektgr√∂√üe, sondern auch der Stichprobengr√∂√üe. Gro√üe Stichproben werden zwangsl√§ufig signifikant, sofern der Effekt nicht exakt Null ist.\n\n\n\n\n√úbrigens sollte man nicht nur von ‚ÄúSignifikanz‚Äù, sondern von ‚Äústatistischer Signifikanz‚Äù sprechen, um klar zu machen, dass man nicht ein Alltagsverst√§ndnis von Signifikanz (‚Äúgro√ü‚Äù, ‚Äúbedeutsam‚Äù) meint, sondern einen wohl definierten statistischen Begriff. Das ist wichtig, weil es sonst leicht zu Fehlinterpretationen kommt.\nMakowski et al. (2019) schlagen vor, welche Kennwerte der Bayes-Statistik analog zum \\(p\\)-Wert herangezogen werden k√∂nnen. Eine M√∂glichkeit daf√ºr ist der Kennwert pd (probability of direction).\n:::{#exr-stmartphone addiction} ### Abh√§ngigkeit vom Handy\nDie Studie von Kabadayi (2024) untersucht den Zusammenhang von Smartphone-Abh√§ngigkeit mit gesundheitlichen Problemen wie Depression, Stress, Einsamkeit und Schlafschwierigkeiten bei Heranwachsenden.\nLesen Sie den Abstract der Studie und Tabelle 2 (sowie alle Teile, die Sie ben√∂tigen, um Tabelle 2 zu verstehen).\n\nWas ist der st√§rkste Zusammenhang bzgl. Smartphone-Abh√§ngigkeit? Wie hoch ist er? Wie gro√ü ist die erkl√§rte Varianz des Zusammenhangs?\nZwischen welchen Variablen findet sich ein ‚Äústatistisch signifikanter‚Äù Zusammenhang?\nErkl√§ren Sie, was ein ‚Äústatistisch signifikanter Zusammenhang‚Äù hier bedeutet? \\(\\square\\) :::\n\n2.10.4 Vertiefung ‚Äì Frequentistische Konfidenzintervalle werden oft falsch verstanden (Vertiefung11)\nFrequentistische Konfidenzintervalle werden oft falsch verstanden, wie die folgende Studie zeigt. Das liegt aber nicht daran, dass die Menschen zu dumm sind, sondern dass frequentistische Konfidenzintervalle f√ºr viele Menschen kontraintuitiv sind.\nHoekstra et al. (2014) berichten von einer Studie, in der \\(n=442\\) Bachelor-Studentis, \\(n=34\\) Master-Studentis und \\(n=120\\) Forschende befragt wurden.\nDen Versuchpersonen wurde folgender Fragebogen vorgelegt, s. Abbildung¬†2.17.\n\n\n\n\n\nAbbildung¬†2.17: Frageobgen zu Konfidenzintervallen\n\n\nKurz gesagt war die Frage, die die Befragten beantworten sollten:\n\nIn einem Experiment wird ein 95%-Konfidenzintervall mit dem Bereich von 0.1 bis 0.4 beichtet. Welcher der folgenden sechs Aussagen sind richtig bzw. falsch?\n\nMit ‚ÄúKonfidenzintervall‚Äù meinen die Forschenden ein frequentistisches Konfidenzintervall.\nAlle diese sechs Aussagen sind FALSCH. Die Aussagen lauten:\n\nDie Wahrscheinlichkeit, dass der wahre Mittelwert gr√∂√üer als 0 ist, betr√§gt mindestens 95 %.\nDie Wahrscheinlichkeit, dass der wahre Mittelwert gleich 0 ist, ist kleiner als 5 %.\nDie ‚ÄûNullhypothese‚Äú, dass der wahre Mittelwert gleich 0 ist, ist wahrscheinlich falsch.\nEs gibt eine 95%ige Wahrscheinlichkeit, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\nWir k√∂nnen mit 95%iger Sicherheit sagen, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\nWenn wir das Experiment immer wieder wiederholen w√ºrden, dann liegt der wahre Mittelwert in 95 % der F√§lle zwischen 0,1 und 0,4.\n\nAussagen 1-4 weisen den Hypothesen bzw. den Parametern eine Wahrscheinlichkeit zu, was im Frequentismus nicht erlaubt ist. Aussagen 5-6 spezifizieren die Grenzen des Sch√§tzintervalls, allerdings kann das Konfidenzintervall nur Aussagen zu den zugrundeliegenden Stichproben, nicht zum Sch√§tzintervall, machen.\nDie Ergebnisse zeigen, dass die Aussagen mehrheitlich falsch verstanden wurden, also mit ‚Äústimmt‚Äù angekreuzt wurden, s. Abbildung¬†2.18.\n\n\n\n\n\nAbbildung¬†2.18: Eine hohe Zustimmung zu den sechs falschen Aussagen\n\n\n\n2.10.5 Frequentist und Bayesianer\nIm Cartoon 1132 von xkcd wird sich √ºber das Nicht-Ber√ºcksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. Abbildung¬†2.19.\n\n\n\n\n\nAbbildung¬†2.19: Frequentist wettet mit Bayesianer\n\n\nQuelle\n\nfrom Imgflip Meme Generator\n\n\n√úbungsaufgabe 2.10 (Peer Instruction: p-Wert) Der p-Wert ist der zentrale Kennwert der frequentistischen Statistik. Aber er wird immer wieder missverstanden. Welche Aussage zum p-Wert ist korrekt?\n\nEin p-Wert von 0,04 bedeutet, dass die Nullhypothese mit 96 % Wahrscheinlichkeit falsch ist.\nEin p-Wert gr√∂√üer als 0,05 beweist, dass die Nullhypothese wahr ist.\nEin kleiner p-Wert bedeutet, dass ein gro√üer Effekt vorliegt.\nEin p-Wert von 0,01 bedeutet, dass sich bei Wiederholung der Studis mit 99% wieder ein signifikantes Ergebnis finden wird.\nKeine der oben genannten. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#fazit",
    "href": "0200-Inferenz.html#fazit",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.11 Fazit",
    "text": "2.11 Fazit\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.\n\n\nWenn Sie an einer (nicht pr√ºfungsrelevanten) Vertiefung interessiert sind, Lesen Sie die Einf√ºhrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#aufgaben",
    "href": "0200-Inferenz.html#aufgaben",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.12 Aufgaben",
    "text": "2.12 Aufgaben\nSchauen Sie sich die Aufgaben mit dem Tag inference auf dem Datenwerk an.\n\n2.12.1 Paper-Pencil-Aufgaben\n\nGriech-Buchstaben-Inferenz\ninferenz-fuer-alle\nttest-als-regr\nttest-skalenniveau\npwert2\ninterpret-ci\ninterpret-ci2\ngruppenvergleich-regression\nWarum-Bayes\nsamples-nyc2\n\nQuiz zu Verteilungen ‚Äì nur die Aufgaben, die ohne einen Computer bzw. ohne R zu l√∂sen sind\nparameter-genau\n\n2.12.2 Aufgaben, f√ºr die man einen Computer braucht\n\nkorr-als-regr\npunktschaetzer-reicht-nicht\nungewiss-arten-regr\ninferenz-fuer-alle\nadjustieren1a\nadjustieren2a\nlm-standardfehler\nvorhersageintervall1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#section",
    "href": "0200-Inferenz.html#section",
    "title": "\n2¬† Inferenz\n",
    "section": "\n2.13 ‚Äî",
    "text": "2.13 ‚Äî\n\n\n\n\n\nBadenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A., & Longobardi, C. (2016). Misconceptions of the P-Value among Chilean and Italian Academic Psychologists. Frontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust Misinterpretation of Confidence Intervals. Psychonomic bulletin & review, 21(5), 1157‚Äì1164. http://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nKabadayi, F. (2024). Smartphone Addiction, Depression, Distress, Eustress, Loneliness, and Sleep Deprivation in Adolescents: A Latent Profile and Network Analysis Approach. BMC Psychology, 12(1), 608. https://doi.org/10.1186/s40359-024-02117-6\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal Inference in Statistics: A Primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nShmueli, G. (2010). To Explain or to Predict? Statistical Science, 25(3), 289‚Äì310. https://doi.org/10.1214/10-STS330\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs Statement on p-Values: Context, Process, and Purpose. The American Statistician, 70(2), 129‚Äì133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#footnotes",
    "href": "0200-Inferenz.html#footnotes",
    "title": "\n2¬† Inferenz\n",
    "section": "",
    "text": "Ziele existieren nicht ‚Äúin echt‚Äù in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das hei√üt, dass man sich nach Belieben Ziele ausdenken kann. Allerdings hilft es, wenn man andere Menschen vom Nutzen der eigenen Ideen √ºberzeugen kann.‚Ü©Ô∏é\nMeistens Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?‚Ü©Ô∏é\nManch einer h√§tte mit mehr gerechnet; andere mit weniger‚Ä¶‚Ü©Ô∏é\nDas ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.‚Ü©Ô∏é\nDas ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.‚Ü©Ô∏é\nhttps://gallery.shinyapps.io/simple_regression/‚Ü©Ô∏é\nWie Jonas Kristoffer Lindel√∏v uns erkl√§rt, sind viele statistische Verfahren, wie der sog. t-Test Spezialf√§lle der Regression.‚Ü©Ô∏é\nDer Datensatz mtcars wird gerne als Studienobjekt verwendet, da er einfach ist und f√ºr viele Beispiele geeignet. Wenn Sie sich einen Sachverhalt an einem einfachen Datensatz vergegenw√§rtigen wollen, bietet sich auch der Datensatz mtcars an. Zudem ist er ‚Äúfest in R eingebaut‚Äù; mit data(mtcars) k√∂nnen Sie ihn verf√ºgbar machen.‚Ü©Ô∏é\n\\(\\sigma\\), das griechische s f√ºr Streuung (um die Regressionsgerade herum), manchmal wird auch e wie error verwendet‚Ü©Ô∏é\nTats√§chlich gibt es mehrere Synonyme oder √§hnliche Begriffe f√ºr Konfidenzintervall. Wir kommen sp√§ter darauf detaillierter zu sprechen.‚Ü©Ô∏é\nnicht pr√ºfungsrelevant‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html",
    "href": "0300-Wskt.html",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "",
    "text": "3.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#lernsteuerung",
    "href": "0300-Wskt.html#lernsteuerung",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "",
    "text": "3.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\nBayes:Start!\n\n\n3.1.2 √úberblick\nDieses Kapitel hat die Wahrscheinlichkeitstheorie (synonym: Wahrscheinlichkeitsrechnung) bzw. das Konzept der Wahrscheinlichkeit zum Thema.1 Es geht sozusagen um die Mathematik des Zufalls.\n\n3.1.3 Wozu brauche ich dieses Kapitel?\nIm wirklichen Leben sind Aussagen (Behauptungen) so gut wie nie sicher.\n\n‚ÄúWeil sie so schlau ist, ist sie erfolgreich.‚Äù\n‚ÄúIn Elektroautos liegt die Zukunft.‚Äù\n‚ÄúDas klappt sicher, meine Meinung.‚Äù\n‚ÄúDer n√§chste Pr√§sident wird XYZ.‚Äù\n\n3.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Grundbegriffe der Wahrscheinlichkeitstheorie erl√§uternd definieren\ndie Definitionen von Wahrscheinlichkeit beschreiben\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nerl√§utern, was eine Zufallsvariable ist\n\n3.1.5 Begleitliteratur\nLesen Sie zur Begleitung dieses Kapitels Bourier (2011), Kap. 2-4.\n\n3.1.6 Eigenstudium\n\n\n\n\n\n\nWichtig\n\n\n\nDieses Kapitel ist selbst√§ndig im Eigenstudium vorzubereiten vor dem Unterricht. Lesen Sie dazu die angegebene Literatur.\\(\\square\\)\n\n\n\n3.1.7 Pr√ºfungsrelevanter Stoff\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 2-4. Weitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verf√ºgbar sein. Pr√ºfen Sie, ob Ihr Dozent Ihnen weitere Hilfen im gesch√ºtzten Bereich (Moodle) eingestellt hat.\\(\\square\\)\n\n\n\n3.1.8 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#grundbegriffe",
    "href": "0300-Wskt.html#grundbegriffe",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.2 Grundbegriffe",
    "text": "3.2 Grundbegriffe\n\n3.2.1 Zufallsvorgang\n\nBeispiel 3.1 Klassisches Beispiel f√ºr einen Zufallsvorgang ist das (einmalige oder mehrmalige) Werfen einer M√ºnze.\\(\\square\\)\nWerfen Sie eine M√ºnze! Diese hier zum Beispiel:\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10 Mal.\nDas reicht Ihnen nicht? Okay, wiederholen Sie den Versuch 100, nein 1000, nein: \\(10^6\\) Mal.2\nNotieren Sie als Ergebnis, wie oft die Seite mit der Zahl oben liegen kommt (‚ÄúTreffer‚Äù).\\(\\square\\)\n\nOder probieren Sie die App der Brown University, wenn Sie keine Sehnenscheidenentz√ºndung bekommen wollen.\n\nDefinition 3.1 (Zufallsvorgang) Ein Zufallsvorgang oder Zufallsexperiment ist eine einigerma√üen klar beschriebene T√§tigkeit, deren Ergebnis nicht sicher ist. Allerdings ist die Menge m√∂glicher Ergebnisse bekannt und die Wahrscheinlichkeit f√ºr alle Ergebnisse kann quantifiziert werden. \\(\\square\\)\n\n\nBeispiel 3.2 (Typische Zufallsvorg√§nge) ¬†\n\n\nW√ºrfeln: Das Werfen eines fairen W√ºrfels ist ein klassisches Beispiel. Der Ausgang (die Augenzahl) kann 1, 2, 3, 4, 5 oder 6 sein.\n\nM√ºnzwurf: Beim Werfen einer M√ºnze sind die m√∂glichen Ausg√§nge ‚ÄúKopf‚Äù oder ‚ÄúZahl‚Äù.\n\nLottoziehung: Die Ziehung von 6 aus 49 Kugeln ist ein komplexeres Zufallsexperiment. Jeder Ausgang ist eine bestimmte Kombination von 6 Zahlen. - Kartenziehen: Das Ziehen einer Karte aus einem gut gemischten Kartendeck ist ein weiteres Beispiel.\n\nGl√ºcksrad: Das Drehen eines Gl√ºcksrads mit verschiedenen Feldern (z.B. Farben oder Zahlen). Welches Feld am Ende stehenbleibt, ist zuf√§llig. \\(\\square\\)\n\n\n\n\n√úbungsaufgabe 3.1 Nennen Sie Beispiele f√ºr Zufallsvorg√§nge!3\n\n\n\n\n\n\n\nVorsicht\n\n\n\nZufall hei√üt nicht, dass ein Vorgang keine Ursachen h√§tte. So gehorcht der Fall einer M√ºnze komplett den Gesetzen der Gravitation. W√ºrden wir diese Gesetze und die Ausgangsbedingungen (Luftdruck, Fallh√∂he, Oberfl√§chenbeschaffenheit, Gewichtsverteilungen, ‚Ä¶) exakt kennen, k√∂nnten wir theoretisch sehr genaue Vorhersagen machen. Der ‚ÄúZufall‚Äù w√ºrde aus dem M√ºnzwurf verschwinden. Man sollte ‚ÄúZufall‚Äù also besser verstehen als ‚Äúunbekannt‚Äù.\\(\\square\\)\n\n\n\n√úbungsaufgabe 3.2 Mit dieser App k√∂nnen Sie W√ºrfelw√ºrfe simulieren und die Ausg√§nge dieses Zufallsexperiments beobachten.\\(\\square\\)\n\n\n3.2.2 Ergebnisraum\n\nDefinition 3.2 (Ergebnisraum) Die m√∂glichen Ergebnisse eines Zufallvorgangs fasst man als Menge mit dem Namen Ergebnisraum zusammen. Man verwendet den griechischen Buchstaben \\(\\Omega\\) f√ºr diese Menge. Die Elemente \\(\\omega\\) (kleines Omega) von \\(\\Omega\\) nennt man Ergebnisse.\\(\\square\\)\n\n\nBeispiel 3.3 Beobachtet man beim W√ºrfelwurf (s. Abbildung¬†3.10) die oben liegende Augenzahl, so ist\n\\[\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{‚öÄ, ‚öÅ, ‚öÇ, ‚öÉ, ‚öÑ, ‚öÖ\\}\\]\nein nat√ºrlicher Grundraum (Henze, 2019).\\(\\square\\)\n\n\nBeispiel 3.4 ¬†\n\n\nM√ºnzwurf: \\(\\Omega = \\{ \\text{Kopf, Zahl} \\}\\)\n\n\nLotto: Bei der Ziehung von 6 aus 49 Kugeln ist der Grundraum die Menge aller m√∂glichen Kombinationen von sechs Zahlen, das sind ca. 14 Millionen.\n\nKartenziehen: Wenn eine einzelne Karte aus einem 52er-Kartendeck gezogen wird, ist der Grundraum die Menge aller 52 Karten.\n\nGl√ºcksrad: Wenn das Gl√ºcksrad in vier gleich gro√üe, farbige Felder unterteilt ist (Rot, Gr√ºn, Blau, Gelb), dann ist der Grundraum die Menge der m√∂glichen Farben: \\(\\Omega = \\{ \\text{Rot, Gr√ºn, Blau, Gelg} \\}\\) \\(\\square\\)\n\n\n\nDie Wahrscheinlichkeitsrechnung baut auf der Mengenlehre auf, daher wird die Notation der Mengenlehre hier verwendet.\n\n\n\n\n\nAbbildung¬†3.1: Ein (sechsseitiger) W√ºrfel, Bildquelle: Peter Steinberg, Wikipedia, CC-BY-SA 3.0\n\n\n\n3.2.3 Ereignis\n\nDefinition 3.3 (Ereignis) Jede Teilmenge4 von \\(\\Omega\\) hei√üt Ereignis; \\(A \\subseteq \\Omega\\) .\\(\\square\\)\n\n\nBeispiel 3.5 Beim Mensch-√§rger-dich-nicht Spielen habe ich eine 6 geworfen.5 Das Nennen wir das Ereignis \\(A\\): ‚ÄúAugenzahl 6 liegt oben‚Äù und schreiben in Kurzform:\n\\(A= \\{6\\}\\square\\)\n\n\nBeispiel 3.6 Sie werfen eine M√ºnze (Sie haben keinen Grund, an ihrer Fairness zu zweifeln). ‚ÄúSoll ich jetzt lernen f√ºr die Klausur (Kopf) oder lieber zur Party gehen (Zahl)?‚Äù\nAbbildung¬†3.2 zeigt die m√∂glichen Ausg√§nge (T wie Treffer (Party) und N (Niete, Lernen)) dieses Zufallexperiments.\n\n\n\n\n\nflowchart LR\n M[Sie werfen die M√ºnze] --&gt; T[\"T (Treffer) ü•≥\"]\n  M --&gt; N[\"N (Niete) üìö\"]\n\n\n\n\nAbbildung¬†3.2: Sie werfen eine M√ºnze. Party oder Lernen???\n\n\n\n\nDas Ereignis Zahl ist eingetreten! Treffer! Gl√ºck gehabt!6\\(\\square\\)\n\n\n3.2.4 Unm√∂gliches und sicheres Ereignis\n\nDefinition 3.4 (Unm√∂gliches und sicheres Ereignis) Die leere Menge \\(\\varnothing\\) hei√üt das um√∂gliche, der Grundraum \\(\\Omega\\) hei√üt das sichere Ereignis. \\(\\square\\)\n\n\nBeispiel 3.7 (Unm√∂gliches Ereignis) Alois behauptet, er habe mit seinem W√ºrfel eine 7 geworfen. Schorsch erg√§nzt, sein W√ºrfel liege auf einer Ecke, so dass keine Augenzahl oben liegt. Draco hat seinen W√ºrfel runtergeschluckt. Dracos und Alois‚Äô Ereignisse sind unm√∂gliche Ereignisse, zumindest nach unserer Vorstellung des Zufallsexperiments.\\(\\square\\)\n\n\nBeispiel 3.8 (Sicheres Ereignis) Nach dem der W√ºrfel geworfen wurde, liegt eine Augenzahl zwischen 1 und 6 oben.\\(\\square\\)\n\n\n3.2.5 Elementarereignis\n\nDefinition 3.5 (Elementarereignis) Jede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) hei√üt Elementarereignis (h√§ufig mit \\(A\\) bezeichnet). 7 \\(\\square\\)\n\n\nBeispiel 3.9 ¬†\n\nSie spielen Mensch-√§rger-dich-nicht. Und brauchen dringend eine 6. Sie w√ºrfeln. Das Ereignis \\(A = \\{1\\}\\) tritt ein.8\n\nSie schreiben eine Statistik-Klausur. Irgendwie haben Sie das Gef√ºhl, das Ergebnis sei ein Zufallsexperiment‚Ä¶ Jedenfalls k√∂nnen nach Adam Riese zwei Dinge passieren: \\(\\Omega= \\{\\text{bestehen, nicht bestehen}\\}\\). Das erste der beiden Elementarereignisse tritt ein. Yeah!\nSie f√ºhren eine Studie durch zur Wirksamkeit einer Lern-App. Es ist nicht klar, ob die App wirklich was bringt f√ºr den Lernerfolg. Vereinfacht gesprochen ist der Grundraum dieses Experiments: \\(\\Omega = \\{\\text{schadet, bringt nichts, n√ºtzt}\\}\\). Die Daten sprechen f√ºr das Ereignis \\(A = \\{\\text{bringt nichts}\\}\\).\n\n\n\n√úbungsaufgabe 3.3 Welche Ereignisse beim W√ºrfelwurf sind keine Elementarereignisse? \\(\\square\\)\n\n\n3.2.6 Vollst√§ndiges Ereignissystem\n\nDefinition 3.6 (Vollst√§ndiges Ereignissystem) Wird der Grundraum \\(\\Omega\\) vollst√§ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollst√§ndiges Ereignissystem, s. Abbildung¬†3.3.\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.3: Zerlegung des Grundraums in ein vollst√§ndiges Ereignissystem\n\n\n\nBeispiel 3.10 Sei \\(\\Omega\\) der typische Ergebnisraum des W√ºrfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) ‚Äúgerade Zahlen‚Äù, und \\(B\\) ‚Äúungerade Zahlen‚Äù. Damit haben wir ein vollst√§ndiges Ereignissystem erstellt, s. Abbildung¬†3.4.\n\n\n\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\}  \\qquad  \\hfill \\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6 }\n\n\\end{align}\\]\n\n\n\nAbbildung¬†3.4\n\n\nEin Beispiel f√ºr ein vollst√§ndiges Ereignissystem\n\n\nBeispiel 3.11 Sei \\(\\Omega\\) der typische Ergebnisraum des W√ºrfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) ‚Äú1,2,3‚Äù, und \\(B\\) ‚Äú4,5,6‚Äù. Damit haben wir ein vollst√§ndiges Ereignissystem erstellt, s. Abbildung¬†3.4.\n\n\n\n\\[\\begin{align}\nA = \\{1,2,3\\} \\qquad \\qquad \\hfill  \\boxed{\\boxed{ \\color{black}{1\\; 2\\; 3}}\\; \\color{gray}{4\\; 5\\; 6}} \\\\\nB = \\{4,5, 6\\} \\qquad \\qquad  \\hfill \\boxed{\\color{gray}{1 \\; 2 \\; 3}\\; \\boxed{\\color{black}{4\\; 5 \\; 6}}} \\\\\n\n\\newline\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\} \\qquad \\qquad \\hfill  \\boxed{1\\; 2\\; 3\\; 4\\; 5\\;6}\n\\end{align}\\]\n\n\n\nAbbildung¬†3.5: Noch ein Beispiel f√ºr ein vollst√§ndiges Ereignissystem\n\n\n\n\n3.2.7 M√§chtigkeit\n\nDefinition 3.7 (M√§chtigkeit) Die Anzahl der Elementarereignisse eines Ereignismraums nennt man die M√§chtigkeit (des Ergebnisraums).9\\(\\square\\)\n\nDie M√§chtigkeit von \\(\\Omega\\) bezeichnet man mit dem Symbol \\(|\\Omega|\\).\n\nBeispiel 3.12 Beim Wurf eines W√ºrfels mit \\(\\Omega=\\{1,2,3,4,5,6\\}\\) gibt es 6 Elementarereignisse. Die M√§chtigkeit ist also 6: \\(|\\Omega|=6\\).\\(\\square\\)\n\n\n3.2.8 Disjunkte Ereignisse\nSeien \\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\).\n\\(A\\) und \\(B\\) sind disjunkt10: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. Abbildung¬†3.6.\n\n\n\n\n\nAbbildung¬†3.6: Zwei disjunkte Ereignisse, dargestellt noch √ºberlappungsfreie Kreise\n\n\nQuelle: rither.de\n\nBeispiel 3.13 Das Ereignis \\(A\\) ‚ÄúGerade Augenzahl beim W√ºrfelwurf‚Äù, \\(A={2,4,6}\\) und das Ereignis \\(B\\) ‚ÄúUngerade Augenzahl beim W√ºrfelwurf‚Äù, \\(B={1,3,5}\\) sind disjunkt, s. Abbildung¬†3.7.\n\n\n\n\\[\\begin{align}\nA = \\{2,4, 6\\} \\qquad \\hfill \\boxed{2\\; 4\\; 6} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{1\\; 3\\; 5} \\\\\n\\hline \\\\\nA \\cap B = \\qquad  \\hfill  \\emptyset\n\\end{align}\\]\n\n\n\nAbbildung¬†3.7: Beispiel f√ºr disjunkte Ereignisse\n\n\n\n\nDie Ereignisse ‚Äúnormaler Wochentag‚Äù und ‚ÄúSonntag‚Äù sind disjunkt. \\(\\square\\)\n\n\n√úbungsaufgabe 3.4 (Peer Instruction: Elementarereignis) Welche der folgenden Ereignisse zeigt ein Elementarereignis des W√ºrfelwurfs (wobei die Augenzahl 1,2,‚Ä¶,6 die Ergebnisse sind).\n\nGerade Zahl gew√ºrfelt\nUngereade Zahl gew√ºrfelt\nKeine 6 gew√ºrfelt\n\n1 gew√ºrfelt\nKeine der genannten \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#was-ist-wahrscheinlichkeit",
    "href": "0300-Wskt.html#was-ist-wahrscheinlichkeit",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.3 Was ist Wahrscheinlichkeit?",
    "text": "3.3 Was ist Wahrscheinlichkeit?\nDie ‚Äúklassische‚Äù Logik der Wissenschaft beruht auf Schl√ºssen (Syllogismen) wie diesem: ‚ÄúAlle Schw√§ne sind wei√ü.‚Äù \\(\\rightarrow\\) ‚ÄúDies ist ein Schwan.‚Äù \\(\\rightarrow\\) ‚ÄúDieser Schwan ist wei√ü.‚Äù\nMit dem Konzept von Wahrscheinlichkeit k√∂nnen wir jetzt auch folgende Logik anwenden: ‚ÄúDie meisten Schw√§ne sind wei√ü.‚Äù \\(\\rightarrow\\) ‚ÄúDies ist ein Schwan.‚Äù \\(\\rightarrow\\) ‚ÄúDieser Schwan ist wahrscheinlich wei√ü.‚Äù Das ist ein gro√üer Fortschritt, der die Denkweise der Wissenschaft gut widerspiegelt und daf√ºr eine logisch-mathematische Grundlage bereitstellt, s. Abbildung¬†3.8.\n\nDefinition 3.8 (Einfache Definition von Wahrscheinlichkeit) Die Wahrscheinlichkeit ist ein Ma√ü f√ºr die Plausibilit√§t einer Aussage \\(A\\), gegeben gewisser Hintergrundinformationen (Daten, \\(D\\)): \\(Pr(A|D)\\). Die Wahrscheinlichkeit eines Ereignisses wird (sofern berechenbar) als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unm√∂glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. Je n√§her die Wahrscheinlichkeit bei 1 (0) liegt, desto sicherer ist jemand, dass das Ereignis (nicht) der Fall ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsrechnung ist die typische Methode, um Ungewissheit zu pr√§zisieren, d.h. zu quantifizieren.\nWir haben schon mit Definition¬†3.9 eine erste Definition von Wahrscheinlichkeit versucht. Jetzt gehen wir die Sache noch etwas n√§her an und vergleichen verschiedene Ideen (Definitionen) von Wahrscheinlichkeit.\n\n3.3.1 Formallogische Definitition\n\n3.3.1.1 Wahrscheinlichkeit als Erweiterung der Logik\nDie formallogische Konzeption von Wahrscheinlichkeit sieht Wahrscheinlichkeit als Erweiterung der formalen Logik (Jaynes & Bretthorst, 2003). 11 In der formalen Logik ist ein Ereignis entweder falsch oder wahr. In der formallogischen Konzeption wird der Platz zwischen ‚Äúfalsch‚Äù (0) und ‚Äúrichtig‚Äù (1) als die Wahrscheinlichkeit \\(0&lt;p&lt;1\\), gesehen (Briggs, 2016), s. Abbildung¬†3.8. Gr√∂√üere Werte stehen f√ºr gr√∂√üere Wahrscheinlichkeit und umgekehrt.\n\n\n\n\n\nAbbildung¬†3.8: Wahrscheinlichkeit als Erweiterung der Logik\n\n\nNach dieser ‚ÄúWahrscheinlichkeitslogik‚Äù kann man ein Ereignis, von dessen Eintreten man ‚Äúwenig √ºberzeugt‚Äù ist, z.B. mit 0.2 quantifizieren. Hingegen einem Ereignis, von man ‚Äúrecht sicher‚Äù ist, mit 0.8 quantifizieren, s. Abbildung¬†3.9.\n\n\n\n\n\nAbbildung¬†3.9: Ein Ereignis von dessen Eintreten man gering bzw. stark √ºberzeugt ist\n\n\n\n3.3.1.2 Wahrscheinlichkeit als Ungewissheit\nWahrscheinlichkeit existiert nicht in dem Sinne, wie ein Stein oder ein Mensch existiert. Wahrscheinlichkeit ist stattdessen eine Art von Wissen. Daher ist es (nach Jaynes & Bretthorst (2003)) falsch, zu sagen: ‚ÄúDie Wahrscheinlichkeit f√ºr Zahl bei dieser M√ºnze ist 50%.‚Äù Richtig w√§re f√ºr einen unbedarften Spieler: ‚ÄúIch habe keinen Grund, nicht an der Fairness der M√ºnze zu glauben, also gehe ich von 50% Wahrscheinlichkeit f√ºr Zahl aus.‚Äù Der Betr√ºger, der diese M√ºnze in der Hand hat, geht allerdings von einer Wahrscheinlichkeit von 75% f√ºr Zahl aus (er kennt die M√ºnze besser als Sie).\nDas Beispiel zeigt: Wahrscheinlichkeit ist kein Ding der Welt, sondern ein Wissenszustand.\nFormaler ausgedr√ºckt: Sei \\(Pr\\) die Wahrscheinlichkeit des Ereignis \\(Z\\) (Zahl) angibt, gegeben meiner Annahme, dass die M√ºnze fair ist (\\(F\\)), also eine Wahrscheinlichkeit von 50% (1/2 = .5) hat f√ºr \\(Z\\). Dann kann man kurz schreiben:\n\\[Pr(Z|F) = 0.5\\] Gegeben des Wissens des Betr√ºgers \\(B\\) w√§re die Wahrscheinlichkeit f√ºr \\(Z\\) anders:\n\\[Pr(Z|B) = 0.75\\]\nIn Worten: ‚ÄúDie Wahrscheinlichkeit von Zahl (\\(Z\\)) gegeben das Wissen des Betr√ºgers √ºber die M√ºnze (\\(B\\)) liegt bei 75%.\nDas Beispiel zeigt auch, dass die Wahrscheinlichkeit eines Ereignissens (wie \\(Z\\)) von Hintergrundinformationen (Annahmen, Daten, Evidenz, ‚Ä¶) abh√§ngt. Ohne zu sagen, auf welche Hintergrundinterformationen wir uns beziehen (die des unbedarften Spielers oder die des Betr√ºgers), ist es sinnvoll, eine Wahrscheinlichkeit anzugeben. Daher ist \\(Pr(Z) = 0.5\\) unvollst√§ndig. Allerdings wird die Hintergrundinformation oft weggelassen, wenn es klar ist, welche Hintergrundinformation vorliegt. So wird h√§ufig vorausgesetzt, dass eine M√ºnze fair ist.\n\nBeispiel 3.14 (Morgen regnet‚Äôs) Es ist daher unvollst√§ndig zu sagen: ‚ÄúMorgen wir es mit einer Wahrscheinlichkeit von 70% regnen.‚Äù\nMan m√ºsste Hintergrundinformation (Evidenz, \\(E\\)) erg√§nzen, z.B. ‚Äúauf Basis des Wettermodell X‚Äù.\nAlso: Anstelle von \\(Pr(\\text{Regen}) = .7\\) besser sagen: \\(Pr(\\text{Regen|Wettermodell X})\\). \\(\\square\\)\n\n\nBeispiel 3.15 (Wahrscheinlichkeit f√ºr Krebs) Jemand beobachtet bei sich Symptome, die f√ºr eine eine Hautkrebserkrankung \\(K\\) typisch sind. Die Person sagt sich: ‚ÄúAch, die Wahrscheinlichkeit f√ºr Hautkrebs liegt bei einem Promill. Kein Grund f√ºr Sorge.‚Äù Formal: \\(Pr(K) = 0.001\\). Aber wenn die Person relevante Symptome \\(S\\) hat, gilt: \\(Pr(\\text{K} \\mid \\text{S}) \\gg 0.001\\). \\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nSagt jemand: ‚ÄúDie Wahrscheinlichkeit von A ist x%‚Äù, frag immer: ‚Äúgegeben welcher Annahmen, welcher Evidenz?‚Äù\n\n\n\nDefinition 3.9 (Wahrscheinlichkeit unter formallogischer Sichtweise) Die Wahrscheinlichkeit ist ein Ma√ü f√ºr unsere Gewissheitt einer Aussage \\(A\\), gegeben gewisser Hintergrundinformationen (Daten, \\(D\\)): \\(Pr(A|D)\\). Die Wahrscheinlichkeit eines Ereignisses wird (sofern berechenbar) als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unm√∂glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. Je n√§her die Wahrscheinlichkeit bei 1 (0) liegt, desto sicherer ist jemand, dass das Ereignis (nicht) der Fall ist.\\(\\square\\)\n\n\nDefinition 3.10 (Indifferenzprinzip) Das Indifferenzprinzip (synonym: Prinzip des unzureichenden Grundes) besagt, dass in Abwesenheit jeglicher Informationen, die bestimmte Ereignisse bevorzugen oder benachteiligen w√ºrden, alle m√∂glichen Ereignisse als gleich wahrscheinlich angesehen werden sollten. \\(\\square\\)\n\nVor uns liegt ein W√ºrfel. Schlicht, ruhig, unbesonders. Wir haben keinen Grund anzunehmen, dass eine seiner \\(n=6\\) Seiten bevorzugt nach oben zu liegen kommt. Jedes der sechs Elementarereignisse ist uns gleich plausibel; der W√ºrfel erscheint uns fair. In Ermangelung weiteres Wissens zu unserem W√ºrfel gehen wir schlicht davon aus, dass jedes der \\(n\\) Elementarereignis gleich wahrscheinlich ist. Es gibt keinerlei Notwendigkeit, den W√ºrfel in die Hand zu nehmen, um zu einer Wahrscheinlichkeitsaussage auf diesem Weg zu kommen. Nat√ºrlich k√∂nnten wir unsere Auffassung eines fairen W√ºrfels testen, aber auch ohne das Testen k√∂nnen wir eine stringente Aussage (basierend auf dem Indifferenzprinzip (s. Definition¬†3.10) der \\(n\\) Elementarereignisse) zur Wahrscheinlichkeit eines bestimmten (Elementar-)Ereignisses \\(A\\) kommen (Briggs, 2016), s. Theorem¬†3.1.\n\nTheorem 3.1 (Indifferenzprinzip) \\[Pr(A) = \\frac{1}{n}= \\frac{1}{|\\Omega|} \\quad \\square\\]\n\n\nBeispiel 3.16 Sei \\(A\\) = ‚ÄúDer W√ºrfel wird beim n√§chsten Wurf eine 6 zeigen.‚Äù Die Wahrscheinlichkeit f√ºr \\(A\\) ist \\(1/6. \\square\\)\n\n\nDefinition 3.11 (Laplace-Experimt) Ein Zufallsexperiment, bei dem alle Elementarereignisse dieselbe Wahrscheinlichkeit haben, nennt man man ein Laplace-Experiment, s. Theorem¬†3.2. \\(\\square\\)\n\nIn Erweiterung von Theorem¬†3.1 k√∂nnen wir f√ºr ein Laplace-Experiment schreiben, s. Theorem¬†3.2.\n\nTheorem 3.2 (Laplace-Experiment) \\[Pr(A)=\\frac{\\text{Anzahl Treffer}}{\\text{Anzahl m√∂glicher Ergebnisse}} \\quad \\square\\]\n\n\nBeispiel 3.17 (Kann Sophia (Einhorn) fliegen?) Sei \\(A\\): ‚ÄúSophia ist ein Einhorn‚Äù. Und sei \\(B\\): ‚ÄúEinh√∂rner mit Fl√ºgeln k√∂nnen fliegen und die H√§lfte aller Einh√∂rner hat Fl√ºgel‚Äù. Dann ist \\(Pr(A|B) = 1/2\\). \\(\\square\\)\n\n\nBeispiel 3.18 (Ich werfe Zahl beim n√§chsten M√ºnzwurf) \\(B\\) ‚ÄúIch habe keinen Grund an der Fairness der M√ºnze zu zweifeln‚Äù. \\(A\\): ‚ÄúEs wird Zahl geworfen beim n√§chsten Wurf dieser M√ºnze‚Äù. Es gilt: \\(Pr(A|B) = 1/2\\). \\(\\square\\)\n\n\n3.3.2 Frequentistische Definition\nIn Ermangelung einer Theorie zum Verhalten eines (uns) unbekannten Zufallsvorgangs und unter der Vermutung, dass die Elementarereignisse nicht gleichwahrscheinlich sind, bleibt uns ein einfacher (aber aufw√§ndiger und manchmal unm√∂glicher) Weg, um die Wahrscheinlichkeit eines Ereignisses zu bestimmen: Ausprobieren.\nAngenommen, ein Statistik-Dozent, bekannt f√ºr seine Vorliebe zum Gl√ºcksspiel und mit scheinbar endlosen Gl√ºcksstr√§hnen (er wirft andauernd eine 6), hat seinen Lieblingsw√ºrfel versehentlich liegen gelassen. Das ist die Gelegenheit! Sie greifen sich den W√ºrfel, und ‚Ä¶ Ja, was jetzt? Nach kurzer √úberlegung kommen Sie zum Entschluss, den W√ºrfel einem ‚ÄúPraxistest‚Äù zu unterziehen: Sie werfen ihn 1000 Mal (Puh!) und z√§hlen den Anteil der 6. Falls der W√ºrfel fair ist, m√ºsste gelten \\(Pr(A=6)=1/6\\approx .17\\). Schauen wir mal!\nUnd hier der Anteil von 6 im Verlauf unserer W√ºrfe, s. Abbildung¬†3.10.\n\n\n\n\n\n\n\nAbbildung¬†3.10: Das Gesetz der gro√üen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten W√ºrfelwurf\n\n\n\n\nHm, auf den ersten Blick ist kein (starkes) Anzeichen f√ºr Schummeln bzw. einen gezinkten W√ºrfel zu finden.\n\n3.3.3 Kolmogorovs Definition\nKolmogorov richtet eine Reihe von Forderungen an eine Definition von bzw. an das Rechnen mit Wahrscheinlichkeiten, die direkt plausibel erscheinen:\n\n\nNichtnegativit√§t: Die Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein.\n\nNormierung: Das sichere Ereignis hat die Wahrscheinlichkeit 1 bzw. 100%: \\(Pr(\\Omega)=1\\); das unm√∂gliche Ereignis hat die Wahrscheinlichkeit 0: \\(Pr(\\emptyset)=0\\).\n\nAdditivit√§t. Sind \\(A\\) und \\(B\\) disjunkt, dann ist die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt (\\(A\\cup B\\)) gleich der Summe der beiden Einzelwahrscheinlichkeiten von \\(A\\) und \\(B\\).\n\n\n√úbungsaufgabe 3.5 (Peer Instruction: Ist der Schmockulator im Zustand alpha?) \\(B\\): ‚ÄúLocuratoren und Schmockulatoren kommen in zwei Zust√§nden vor, alpha und beta. Und zwar gleich h√§ufig‚Äù. Leider wissen wir nichts Weiteres √ºber Locuratoren und Schmockulatoren. Vor Ihnen steht ein Schmockulator. Welche m√∂glichst pr√§zise Aussage k√∂nnen wir √ºber den Zustand des Schmockulator treffen?\n\nDer Schmockulator ist sicher im Zustand alpha.\nDer Schmockulator ist in einem der beiden Zust√§nde.\nDer Schmockulator ist vermutlich im Zustand alpha.\nDer Schmockulator ist m√∂glicherweise im Zustand alpha.\nDer Schmockulator ist mit einer Wahrscheinlichkeit von 50% im Zustand alpha.\nKeine der genannten. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#relationen-von-ereignissen",
    "href": "0300-Wskt.html#relationen-von-ereignissen",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.4 Relationen von Ereignissen",
    "text": "3.4 Relationen von Ereignissen\nF√ºr das Rechnen mit Wahrscheinlichkeiten ist es hilfreich, ein paar Werkzeuge zu kennen, die wir uns im Folgenden anschauen.\n\nDefinition 3.12 (Relation) Eine Relation (zweier Ereignisse) bezeichnet die Beziehung, in der die beiden Ereignisse zueinander stehen. \\(\\square\\)\n\nTypische Relationen sind Gleichheit, Ungleichheit, Vereinigung, Schnitt.\n\n3.4.1 √úberblick\nWir gehen von Grundraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge von \\(\\Omega\\): \\(A \\subset \\Omega\\).\nDa wir Ereignisse als Mengen auffassen, verwenden wir im Folgenden die beiden Begriffe synonym.\nDabei nutzen wir u.a. Venn-Diagramme. Venn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren. Die folgenden Venn-Diagramme stammen von Wikipedia (En).\n\n\n\n\n\n\nWozu sind die Venn-Diagramme gut? Warum soll ich die lernen?\n\n\n\nVenn-Diagramme zeigen Kreise und ihre √ºberlappenden Teile; daraus lassen sich R√ºckschl√ºsse auf Rechenregeln f√ºr Wahrscheinlichkeiten ableiten. Viele Menschen tun sich leichter, Rechenregeln visuell aufzufassen als mit Formeln und Zahlen alleine. Aber entscheiden Sie selbst!\\(\\square\\)\n\n\nDiese App versinnbildlicht das Rechnen mit Relationen von Ereignissen anhand von Venn-Diagrammen.12\n\n3.4.2 Vereinigung von Ereignissen\n\nDefinition 3.13 (Vereinigung von Ereignissen) Vereinigt man zwei Ereignisse \\(A\\) und \\(B\\), dann besteht das neue Ereignis \\(C\\) genau aus den Elementarereignissen der vereinigten Ereignisse. Man schreibt \\(C = A \\cup B\\), lies: ‚ÄúC ist A vereinigt mit B‚Äù.\\(\\square\\)\n\nAbbildung¬†3.11 zeigt ein Venn-Diagramm zur Verdeutlichung der Vereinigung von Ereignissen.\n\n\n\n\n\nAbbildung¬†3.11: \\(A \\cup B\\): Vereinigung\n\n\n\nBeispiel 3.19 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem n√§chsten Wurf mindestens eines der beiden Ereignisse \\(A= {1,2}\\) oder \\(B={2,3}\\) eintreten, s. Abbildung¬†3.12.\n\n\n\n\\[\\begin{aligned}\nA = \\{1,2\\} \\qquad \\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}} \\\\\nB = \\{2,3\\} \\qquad  \\boxed{1\\; \\boxed{2\\; 3}\\; \\color{gray}{ 4\\; 5\\; 6}} \\\\\n\\newline\n\\hline \\\\\nA \\cup B = \\{1,2,3\\} \\qquad \\boxed{\\boxed{1\\; 2\\; 3}\\; \\color{gray}{4\\; 5\\; \\boxed{6}}}\n\\end{aligned}\\]\n\n\n\nAbbildung¬†3.12: Beispiel zur Vereinigung zweier Mengen\n\n\n\nZur besseren Verbildlichung betrachten Sie mal diese Animation zur Vereinigung von Mengen; Quelle.\nIn R hei√üt die Vereinigung von Mengen union(). Praktisch zum Ausprobieren:\n\nCodeA &lt;- c(1, 2)\nB &lt;- c(2, 3)\n\nunion(A, B)\n## [1] 1 2 3\n\n\n\n3.4.3 (Durch-)Schnitt von Ereignissen\n\nDefinition 3.14 (Schnittmenge von Ereignissen) Die Schnittmenge zweier Ereignisse \\(A\\) und \\(B\\) umfasst genau die Elementarereignisse, die Teil beider Ereignisse sind. Man schreibt: \\(A \\cap B.\\)13 Lies: ‚ÄúA geschnitten B‚Äù. \\(\\square\\)\n\nAbbildung¬†3.13 zeigt ein Sinnbild zur Schnittmenge zweier Ereignisse.\n\n\n\n\n\nAbbildung¬†3.13: \\(A \\cap B\\): Schnitt zweier Mengen\n\n\n\nBeispiel 3.20 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem n√§chsten Wurf sowohl das Ereignis \\(A\\) = ‚Äúgerade Augenzahl‚Äù als auch \\(B\\) = ‚ÄúAugenzahl gr√∂√üer 4‚Äù, s. Abbildung¬†3.14.\n\n\n\n\\[\\begin{align}\n& A = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n& B = \\{5,6\\} \\qquad \\qquad \\hfill  \\boxed{ \\color{gray}{1\\; 2\\; 3\\; 4\\;} \\boxed{\\color{black}{5\\; 6}}} \\\\\n\\newline\n\\hline \\\\\n& A \\cap B = \\{6\\} \\qquad \\qquad \\hfill  \\boxed{\\color{gray}{1\\; 2\\; 3\\; 4\\; 5\\;} \\color{black}{6}}\n\\end{align}\\]\n\n\n\nAbbildung¬†3.14: Beispiel zum Schnitt zweier Mengen\n\n\n\n\nCodeA &lt;- c(2, 4, 6)\nB &lt;- c(5, 6)\nintersect(A, B)\n## [1] 6\n\n\n\n\n\n\n\n\nEselsbr√ºcke zur Vereinigungs- und Schnittmenge\n\n\n\nDas Zeichen f√ºr eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen f√ºr einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine Eselbr√ºcke gelesen, s. Abbildung¬†3.15.\n\n\n\n\n\nAbbildung¬†3.15: Eselsbr√ºcke f√ºr Vereinigungs- und Schnittmenge\n\n\n\n\n\n3.4.4 Komplement√§rereignis\n\nDefinition 3.15 (Komplement√§rereignis) Ein Ereignis \\(A\\) ist genau dann ein Komplement√§rereignis zu \\(B\\), wenn es genau die Elementarereignisse von \\(\\Omega\\) umfasst, die nicht Elementarereignis des anderen Ereignisses sind, s. Abbildung¬†3.17.\\(\\square\\)\n\nMan schreibt f√ºr das Komplement√§rereignis14 von \\(A\\) oft \\(\\bar{A}\\) oder \\(\\neg A\\)15; lies ‚ÄúNicht-A‚Äù oder ‚ÄúA-quer‚Äù.\n\nBeispiel 3.21 Beim normalen W√ºrfelwurf sei \\(A\\) das Ereignis ‚Äúgerade Augenzahl‚Äù; das Komplement√§rereignis16 ist dann \\(\\neg A\\) ‚Äúungerade Augenzahl‚Äù, s. Abbildung¬†3.16.\n\n\n\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n\\hline \\\\\n\\neg A = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\end{align}\\]\n\n\n\nAbbildung¬†3.16: Ein Beispiel f√ºr ein Komplement\n\n\n\n\n\n\n\n\nAbbildung¬†3.17: \\(\\bar{A}\\): Komplement\n\n\n\n3.4.5 Logische Differenz\n\nDefinition 3.16 (Logische Differenz) Die logische Differenz der Ereignisse \\(A\\) und \\(B\\) ist das Ereignis, das genau aus den Elementarereignissen besteht von \\(A\\) besteht, die nicht zugleich Elementarereignis von \\(B\\) sind, s. Abbildung¬†3.18.\\(\\square\\)\n\nDie logische Differenz von \\(A\\) zu \\(B\\) schreibt man h√§ufig so: \\(A \\setminus B\\); lies ‚ÄúA minus B‚Äù.\n\n\n\n\n\nAbbildung¬†3.18: \\(A \\setminus B\\)\n\n\n\nBeispiel 3.22 Sei \\(A\\) die Menge ‚Äúgro√üe Zahlen‚Äù mit \\(A = \\{4,5,6 \\}\\). Sei \\(B\\) die Menge ‚Äúgerade Zahlen‚Äù mit \\(B = \\{2,4,6\\}\\). Wir suchen die logische Differenz, \\(A \\setminus B\\), s. Abbildung¬†3.19.\n\n\n\n\\[\\begin{align}\nA = \\{4,5, 6\\} \\qquad \\hfill \\boxed{\\color{red}{4}\\; \\color{green}{5}\\; \\color{red}{6}} \\\\\nB = \\{2,4,6\\} \\qquad  \\hfill \\boxed{\\color{grey}{2}\\; \\color{red}{4}\\; \\color{red}{6}} \\\\\n\\hline \\\\\nA \\setminus B \\qquad \\hfill \\boxed{\\color{green}{5}}\n\\end{align}\\]\n\n\n\nAbbildung¬†3.19: Beispiel f√ºr die logische Differenz\n\n\n\nIn R gibt es die Funktion setdiff(), die eine Mengendifferenz ausgibt.\n\nCodeA &lt;- c(4, 5, 6)\nB &lt;- c(2, 4, 6)\n\nsetdiff(A, B)\n## [1] 5\n\n\nü§Ø Von der Menge \\(A\\) die Menge \\(B\\) abzuziehen, ist etwas anderes, als von \\(B\\) die Menge \\(A\\) abzuziehen.\n\n\n\n\n\n\nVorsicht\n\n\n\n\\(A \\setminus B \\ne B \\setminus A\\).\n\n\n\nCodesetdiff(B, A)\n## [1] 2\n\n\n\n3.4.6 Vertiefung\nAnimation zu Mengenoperationen\n\n√úbungsaufgabe 3.6 (Peer Instruction: Das Komplement√§rereignis von der Bestnote) Sie haben eine Statistikklausur bestanden. Mit Bestnote. Genauer gesagt, haben Sie 100 von 100 Punkten erzielt. Was ist das Komplement√§rereignis dazu?\n\n99 Punkte\n0 Punkte\n0-99 Punkte\n0-100 Punkte\ndurchgefallen\nkeines der genannten \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#zufallsvariable",
    "href": "0300-Wskt.html#zufallsvariable",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.5 Zufallsvariable",
    "text": "3.5 Zufallsvariable\n\n3.5.1 Grundlagen\n\nBeispiel 3.23 Schorsch sucht eine Betreuerin f√ºr seine Abschlussarbeit. An die ideale Betreuerin setzt er 4 Kriterien an: a) klare, schriftliche fixierte Rahmenbedingungen, b) viel Erfahrung, c) guten Ruf und d) interessante Forschungsinteressen. Je mehr dieser 4 Kriterien erf√ºllt sind, desto besser. Schorsch geht davon aus, dass die 4 Kriterien voneinander unabh√§ngig sind (ob eines erf√ºllt ist oder nicht, √§ndert nichts an der Wahrscheinlichkeit, dass ein anderes Kriterium erf√ºllt ist). Schorsch interessiert sich also f√ºr die Anzahl der erf√ºllten Kriterien, also eine Zahl von 0 bis 4. Er sch√§tzt die Wahrscheinlichkeit f√ºr einen ‚ÄúTreffer‚Äù in jedem seiner 4 Kriterien auf 50%. Viel Gl√ºck, Schorsch! Sein Zufallsexperiment hat 16 Ausg√§nge (Knoten 16 bis 31), s. Abbildung¬†3.20 und Tabelle¬†3.1. Ganz sch√∂n komplex. Eigentlich w√ºrden ihm ja eine Darstellung mit 5 Ergebnissen, also der ‚ÄúGutachter-Score‚Äù von 0 bis 4 ja reichen. Wie k√∂nnen wir die Sache √ºbersichtlicher f√ºr Schorsch machen? Abbildung¬†3.20 ist ein Versuch. \\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.20: Ein Baumdiagramm mit 16 Ausg√§ngen, analog zur 4 M√ºnzw√ºrfen. T: Treffer (Kriterium erf√ºllt). N: Niete (Kriterium nicht erf√ºllt). NNNT w√§re zum Beispiel eine Gutachterin ohne klar fixierte Rahmenbedingungen, ohne viel Erfahrung, mit schlechem Ruf aber mit interessanten Forschungsinteressen.\n\n\n\n\n\nTabelle¬†3.1: Schorschs Zufallsexperiment, Auszug der Elementarereignisse (EE)\n\n\n\n\n\n\ni\nElementarereignis\nPr(EE)\nTrefferzahl\n\n\n\n1\nNNNN\n1/16\n0\n\n\n2\nNNNT\n1/16\n1\n\n\n3\nNNTN\n1/16\n1\n\n\n4\nNTNN\n1/16\n1\n\n\n5\nTNNN\n1/16\n1\n\n\n6\nNNTT\n1/16\n2\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\n\n\n\n\n\n\nSchorsch braucht also eine √ºbersichtlichere Darstellung; die Zahl der Treffer und ihre Wahrscheinlichkeit w√ºrde ihm ganz reichen. In vielen Situationen ist man an der Anzahl der Treffer interessiert. Die Wahrscheinlichkeit f√ºr eine bestimmte Trefferanzahl bekommt man einfach durch Addieren der Wahrscheinlichkeiten der zugeh√∂rigen Elementarereignisse, s. Tabelle¬†3.1. Hier kommt die Zufallsvariable ins Spiel. Wir nutzen sie, um die Anzahl der Treffer in einem Zufallsexperiment zu z√§hlen.\n\nDefinition 3.17 (Zufallsvariable) Die Zuordnung der Elementarereignisse eines Zufallsexperiments zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable.\\(\\square\\)\n\nDie den Elementarereignissen zugewiesenen Zahlen nennt man Realisationen oder Auspr√§gungen der Zufallsvariablen.\n\nBeispiel 3.24 (Lotto) Ein Lottospiel hat ca. 14 Millionen Elementarereignisse. Die Zufallsvariable ‚ÄúAnzahl der Treffer‚Äù hat nur 7 Realisationen: 0,1,‚Ä¶,6.\\(\\square\\)\n\nEs hat sich eingeb√ºrgert, Zufallszahlen mit \\(X\\) zu bezeichnen (oder anderen Buchstaben weit hinten aus dem Alphabet).\nMan schreibt f√ºr eine Zufallsvariable kurz: \\(X: \\Omega \\rightarrow \\mathbb{R}\\). ‚ÄúX ist eine Zufallsvariable, die jedem Elementarereignis \\(\\omega\\) eine reelle Zahl zuordnet.‚Äù Um die Vorschrift der Zuordnung genauer zu bestimmen, kann man folgende Kurzschreibweise nutzen:\n\\({\\displaystyle X(\\omega )={\\begin{cases}1,&{\\text{wenn }}\\omega ={\\text{Kopf}},\\\\[6pt]0,&{\\text{wenn }}\\omega ={\\text{Zahl}}.\\end{cases}}}\\)\nAbbildung¬†3.21 stellt diese Abbildung dar.\n\n\n\n\n\nAbbildung¬†3.21: Eine Zufallsvariable ist eine Zuordnung der Ereignisse zu einer reellen Zahl (nach einer bestimmten Regel\n\n\nZufallsverteilungen kann im zwei Arten einteilen:\n\ndiskrete Zufallsvariablen\nstetige Zufallsvariablen\n\n3.5.2 Diskrete Zufallsvariable\n\n3.5.2.1 Grundlagen\nEine diskrete Zufallsvariable ist dadurch gekennzeichnet, dass nur bestimmte Realisationen m√∂glich sind, zumeist nat√ºrliche Zahlen, wie 0, 1, 2,‚Ä¶, . Abbildung¬†3.22 versinnbildlicht die Zufallsvariable des ‚ÄúGutachter-Scores‚Äù, s. Beispiel¬†3.23.\n\n\n\n\n\n\n\nAbbildung¬†3.22: Sinnbild einer diskreten Zufallsvariablen X f√ºr Schorschs Suche nach einer Betreuerin seiner Abschlussarbeit. X gibt den Score der Gutachterin wider.\n\n\n\n\n\nBeispiel 3.25 (Diskrete Zufallsvariablen) ¬†\n\nAnzahl der Bewerbungen bis zum ersten Job-Interview\nAnzahl Anl√§ufe bis zum Bestehen der Statistik-Klausur\nAnzahl der Absolventen an der HS Ansbach pro Jahr\nAnzahl Treffer beim Kauf von Losen\nAnzahl Betriebsunf√§lle\nAnzahl der Produkte in der Produktpalette\\(\\square\\)\n\n\n\n\nBeispiel 3.26 Der zweifache W√ºrfelwurf ist ein typisches Lehrbuchbeispiel f√ºr eine diskrete Zufallsvariable. 17 Hier ist \\(S\\)18 die Augensumme des zweifachen W√ºrfelwurfs und \\(S\\) ist eine Zahl zwischen 2 und 12. F√ºr jede Realisation \\(X=x\\) kann man die Wahrscheinlichkeit berechnen, Abbildung¬†3.23 versinnbildlicht die Wahrscheinlichkeit f√ºr jede Realisation von \\(X\\).\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.23: Augensumme des zweifachen W√ºrfelwurfs; f√ºr jede Realisation von S ist die zugeh√∂rige Wahrscheinlichkeit dargestellt. Bildquelle: Tim Stellmach, Wikipedia, PD\n\n\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariablen eine Wahrscheinlichkeit zuzuordnen.\n\nDefinition 3.18 (Diskrete Wahrscheinlichkeitsverteilung) Eine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) Auspr√§gungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu.\\(\\square\\)\n\n\nBeispiel 3.27 (Wahrscheinlichkeit des Geschlechts bei der Geburt) So hat die Variable Geschlecht eines Babies die beiden Auspr√§gungen M√§dchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\), laut einer Studie (Gelman et al., 2021).\\(\\square\\)\n\nZwischen der deskriptiven Statistik und der Wahrscheinlichkeitstheorie bestehen enge Parallelen, Tabelle¬†3.2 stellt einige zentrale Konzepte gegen√ºber. Bei einer guten Stichproben kann man die Kennwerte der deskriptiven Statistik als Sch√§tzwerte f√ºr die zugrundeliegende Wahrscheinlichkeit verwenden.\n\n\n\nTabelle¬†3.2: Gegen√ºberstellung von Wahrscheinlichkeitstheorie und deskriptiver Statistik\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDeskriptive Statistik\n\n\n\nZufallsvariable\nMerkmal\n\n\nWahrscheinlichkeit\nrelative H√§ufigkeit, Anteil\n\n\nWahrscheinlichkeitsverteilung\neinfache relative H√§ufigkeitsverteilung\n\n\nVerteilungsfunktion\nkumulierte relative H√§ufigkeitsverteilung\n\n\nErwartungswert\nMittelwert\n\n\nVarianz\nVarianz\n\n\n\n\n\n\n\n\n\nEine Verteilung zeigt, welche Auspr√§gungen eine Variable aufweist und wie h√§ufig bzw. wahrscheinlich diese sind. Einfach gesprochen veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet H√§ufigkeitsverteilungen (s. Abb. Abbildung¬†3.25) von Wahrscheinlichkeitsverteilungen (Abb. Abbildung¬†3.24).\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.24: Wahrscheinlichkeitsverteilung der Zufallsvariable ‚ÄúAugenzahl im zweifachen W√ºrfelwurf‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.25: (relative und absolute) H√§ufigkeiten des zweifachen W√ºrfelwurfs, 1000 Mal wiederholt\n\n\n\n\n\n\n\nBeispiel 3.28 (Wahrscheinlichkeitsverteilung eines W√ºrfels) Abbildung¬†3.26 zeigt die Wahrscheinlichkeitsverteilung eines einfachen W√ºrfelwurfs.\\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†3.26: Wahrscheinlichkeitsverteilung eines einfachen W√ºrfelwurfs, Bildrechte: Olex Alexandrov, Wikipedia, PD\n\n\n\nBeispiel 3.29 Die Wahrscheinlichkeitsverteilung f√ºr \\(X\\) ‚ÄúAugensumme im zweifachen W√ºrfelwurf‚Äù ist in Abbildung¬†3.24 visualisiert.\\(\\square\\)\n\n\n3.5.2.2 Vertiefung: Verteilungsfunktion\n\nDefinition 3.19 (Verteilungsfunktion) Die Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist.\\(\\square\\)\n\nDie Berechnung von \\(F(x)\\) erfolgt, indem die Wahrscheinlichkeiten aller m√∂glichen Realisationen \\(x_i\\), die kleiner oder gleich dem vorgegebenen Realisationswert \\(x\\) sind, addiert werden:\n\\(F(x) = \\sum_{x_ \\le x} Pr(X=x_i).\\)\nDie Verteilungsfunktion ist das Pendant zur kumulierten H√§ufigkeitsverteilung, vgl. Abbildung¬†3.27 und Abbildung¬†3.28: Was die kumulierte H√§ufigkeitsverteilung f√ºr H√§ufigkeiten ist, ist die Verteilungsfunktion f√ºr Wahrscheinlichkeiten.\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.27: Verteilungsfunktion \\(F(X \\le x_i)\\) f√ºr die Zufallsvariable ‚ÄúAugenzahl im zweifachen W√ºrfelwurf‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.28: Empirische Verteilungsfunktion (kumulierte H√§ufigkeitsverteilung) \\(F(X \\le x_i)\\) von 1000 zweifachen M√ºnzw√ºrfen\n\n\n\n\n\n\n\n3.5.3 Stetige Zufallsvariablen\n\n3.5.3.1 Grundlagen\nüì∫ Verteilungen metrischer Zufallsvariablen\nAbbildung¬†3.29 versinnbildlicht die stetige Zufallsvariable ‚ÄúK√∂rpergr√∂√üe‚Äù, die (theoretisch, in Ann√§herung) jeden beliebigen Wert zwischen 0 und (vielleicht) 2 Meter annehmen kann.\n\n\n\n\n\n\n\nAbbildung¬†3.29: Sinnbild f√ºr eine stetige Zufallsvariable X ‚ÄúK√∂rpergr√∂√üe‚Äù\n\n\n\n\n\nDefinition 3.20 (Stetige Zufallsvariable) Eine stetige Zufallsvariable gleicht einer diskreten, nur dass alle Werte im Intervall erlaubt sind.\\(\\square\\)\n\n\nBeispiel 3.30 ¬†\n\nSpritverbrauch\nK√∂rpergewicht von Professoren\nSchnabell√§ngen von Pinguinen\nGeschwindigkeit beim Geblitztwerden\\(\\square\\)\n\n\n\n\n√úbungsaufgabe 3.7 (Warten auf den Bus, 42 Sekunden) Sie stehen an der Bushaltestellen und warten auf den Bus. Langweilig. Da kommt Ihnen ein Gedanken in den Sinn: Wie hoch ist wohl die Wahrscheinlichkeit, dass Sie exakt 42 Sekunden auf den Bus warten m√ºssen, s. Abbildung¬†3.31? Weiterhin √ºberlegen Sie, dass davon auszugehen ist, dass jede Wartezeit zwischen 0 und 10 Minuten gleich wahrscheinlich ist. Sp√§testens nach 10 Minuten kommt der Bus, so ist die Taktung (extrem zuverl√§ssig). Exakt hei√üt exakt, also nicht 42.1s, nicht 42.01s, nicht 42.001s, etc. bis zur x-ten Dezimale.\\(\\square\\)\n\nNicht so einfach (?). Hingegen ist die Frage, wie hoch die Wahrscheinlichkeit ist, zwischen 0 und 5 Minuten auf den Bus zu warten (\\(0&lt;x&lt;5\\)), einfach: Sie betr√§gt 50%, wie man in Abbildung¬†3.30 gut sehen kann.\n\n\n\n\n\n\n\nAbbildung¬†3.30: Wie gro√ü ist die Wahrscheinlichkeit, zwischen 0 und 5 Minuten auf den Bus zu warten? 50 Prozent!\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.31: Wie gro√ü ist die Wahrscheinlichkeit, genau 42 Sekunden auf den Bus zu warten? Hm.\n\n\n\n\n\n\nVergleicht man Abbildung¬†3.31 und Abbildung¬†3.30 kommt man (vielleicht) zu dem Schluss, dass die Wahrscheinlichkeit exakt 42s auf den Bus zu warten, praktisch Null ist. Der Grund ist, dass die Fl√§che des Intervalls gegen Null geht, wenn das Intervall immer schm√§ler wird. Aus diesem Grund kann man bei stetigen Zufallszahlen nicht von einer Wahrscheinlichkeit eines bestimmten Punktes \\(X=x\\) sprechen. F√ºr einen bestimmten Punkt \\(X=x\\) kann man aber die Dichte der Wahrscheinlichkeit angeben.\nWas gleich ist in beiden Situationen (\\(Pr(X=.42)\\) und \\(Pr(0&lt;x&lt;0.5)\\)) ist die Wahrscheinlichkeitsdichte, \\(f\\). In Abbildung¬†3.31 und Abbildung¬†3.30 ist die Wahrscheinlichkeitsdichte gleich, \\(f=1/10=0.1\\).\n\nDefinition 3.21 (Wahrscheinlichkeitsdichte) Die Wahrscheinlichkeitsdichte \\(f(x)\\) gibt an, wie viel Wahrscheinlichkeitsmasse pro Einheit von \\(X\\) an an der Stelle \\(x\\) ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsdichte zeigt an, an welchen Stellen \\(x\\) die Wahrscheinlichkeit besonders ‚Äúgeballt‚Äù oder ‚Äúdicht‚Äù sind, s. Abbildung¬†3.32.\n\n\n\n\n\nAbbildung¬†3.32: Die Wahrscheinlichkeit, dass eine Zufallsvariable einen Wert zwischen und annimmt, entspricht dem Inhalt der Fl√§che unter dem Graph der Wahrscheinlichkeitsdichtefunktion. Bildrechte: 4C, Wikipedia, CC-BY-SA .\n\n\nBei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen Auspr√§gungen aus; die Wahrscheinlichkeit einer bestimmten Auspr√§gung ist Null: $Pr(X=x_j)=0, j=1,‚Ä¶,+\n\nBeispiel 3.31 (Wahrscheinlichkeitsverteilung f√ºr die K√∂rpergr√∂√üe) So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666‚Ä¶ cm gro√ü ist, ist (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\).\\(\\square\\)\n\nF√ºr praktische Fragen berechnet man zumeist die Wahrscheinlichkeit von Intervallen, s. Abbildung¬†3.32.\n\n3.5.3.2 Vertiefung: Verteilungsfunktion\n\n\n\nDefinition 3.22 (Verteilungsfunktion) Die Verteilungsfunktion einer stetigen Zufallsvariablen gibt wie im diskreten Fall an, wie gro√ü die Wahrscheinlichkeit f√ºr eine Realisation kleiner oder gleich einem vorgegebenen Realisationswert \\(x\\) ist.\\(\\square\\)\nDie Verteilungsfunktion \\(F(x)\\) ist analog zur kumulierten H√§ufigkeitsverteilung zu verstehen, vgl. Abbildung¬†3.33. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildung¬†3.33: Verteilungsfunktion F f√ºr X=‚ÄúWartezeit auf den Bus‚Äù\n\n\n\n\n\n\n\n√úbungsaufgabe 3.8 (Peer Instruction: Wieder auf den Bus warten) Sie warten wieder auf den Bus, s. Abbildung¬†3.30. Welche Aussage dazu ist falsch?\n\nDie Wahrscheinlichkeit, genau 5 Minuten zu warten, ist am h√∂chsten.\nDie Wahrscheinlichkeit, genau 10 Minuten zu warten, ist Null.\nMit 100% Wahrscheinlichkeit betr√§gt die Wartezeit zwischen 0 und 10 Minuten.\nDie Wahrscheinlichkeit 1 Minute zu warten, betr√§gt 10%.\nKeine der genannten. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#aufgaben",
    "href": "0300-Wskt.html#aufgaben",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.6 Aufgaben",
    "text": "3.6 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. Sie k√∂nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen.\n\n3.6.1 Paper-Pencil-Aufgaben\n\nprob-voll-esystem\nprob-disjunkt\nprob-disjunkt2\nprob-elementarereignis\nprob-vereinigung\nprob-ereignisraum\nprob-sicher-unm√∂glich\nindifferenz-p\n\n3.6.2 Aufgaben, f√ºr die man einen Computer braucht\n\npenguins-relationen\npenguins-relationen2\nverteilungsfunktion-penguins",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#literatur",
    "href": "0300-Wskt.html#literatur",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "\n3.7 Literatur",
    "text": "3.7 Literatur\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende Statistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√úbungen: Beschreibende Statistik ‚Äì Wahrscheinlichkeitsrechnung ‚Äì Schlie√üende Statistik (7. Auflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of Modeling, Probability & Statistics. Springer.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHenze, N. (2019). Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der Ma√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability Theory: The Logic of Science. Cambridge University Press.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#footnotes",
    "href": "0300-Wskt.html#footnotes",
    "title": "\n3¬† Hallo, Wahrscheinlichkeit\n",
    "section": "",
    "text": "Die Wahrscheinlichkeitstheorie bildet zusammen mit der Statistik das Fachgebiet der Stochastik.‚Ü©Ô∏é\n\\(10^6 = 1000000\\)‚Ü©Ô∏é\nBeispiele f√ºr Zufallsexperimente das Messen eines Umweltph√§nomens wie der Temperatur oder die Anzahl der Kunden, die einen Laden betreten. In jedem dieser F√§lle sind die m√∂glichen Ergebnisse nicht im Voraus bekannt und h√§ngen von nicht komplett bekannten Faktoren ab.‚Ü©Ô∏é\n\\(A\\) ist eine Teilmenge von \\(B\\), wenn alle Elemente von \\(A\\) auch Teil von \\(B\\) sind.‚Ü©Ô∏é\nSchon wieder.‚Ü©Ô∏é\n?‚Ü©Ô∏é\nEin Ergebnis ist ein Element von \\(\\Omega\\). Elementarereignisse sind die einelementigen Teilmengen von \\(\\Omega\\). Konzeptionell sind die beiden Begriffe sehr √§hnlich, vgl. https://de.wikipedia.org/wiki/Ergebnis_(Stochastik). Wir werden uns hier auf den Begriff Elementarereignis konzentrieren und den Begriff Ergebnis nicht weiter verwenden.‚Ü©Ô∏é\nNa toll.‚Ü©Ô∏é\nDie Menge aller Teilmengen einer Menge \\(A\\) nennt man die Potenzmenge \\(\\mathcal{P}(A)\\), vgl. hier.‚Ü©Ô∏é\nengl. disjoint‚Ü©Ô∏é\nManchmal wird diese Art der Wahrscheinlichkeit auch epistemologische Wahrscheinlichkeit genannt.‚Ü©Ô∏é\nhttps://www.geogebra.org/m/QZvCMSDs‚Ü©Ô∏é\nSynonym und k√ºrzer: \\(AB\\) anstelle von \\(A \\cap B\\).‚Ü©Ô∏é\nsynonym: Komplement‚Ü©Ô∏é\nmanchmal auch \\(A^C\\); C wie complementary event‚Ü©Ô∏é\ndas ‚ÄúKomplement‚Äù, nicht zu verwechseln mit ‚ÄúKompliment‚Äù‚Ü©Ô∏é\nda einfach und deutlich‚Ü©Ô∏é\nS wie Summe‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Hallo, Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html",
    "href": "0350-wskt2.html",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "",
    "text": "4.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#lernsteuerung",
    "href": "0350-wskt2.html#lernsteuerung",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "",
    "text": "4.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n4.1.2 √úberblick\nDieses Kapitel stellt uns einige grundlegenden Rechengesetze f√ºr Wahrscheinlichkeiten vor: Wann man die Wahrscheinlichkeiten zweier Ereignisse addiert oder multipliziert. Au√üerdem lernen wir den Begriff der Unabh√§ngkeit kennen.\n\n4.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erl√§uternd definieren\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n4.1.4 Begleitliteratur\nLesen Sie zur Begleitung dieses Kapitels Bourier (2011), Kap. 2-4.\n\n4.1.5 Pr√ºfungsrelevanter Stoff\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 2-4. Weitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verf√ºgbar sein. Pr√ºfen Sie, ob Ihr Dozent Ihnen weitere Hilfen im gesch√ºtzten Bereich (Moodle) eingestellt hat.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#√ºberblick-1",
    "href": "0350-wskt2.html#√ºberblick-1",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.2 √úberblick",
    "text": "4.2 √úberblick\nDie Rechenregeln der Wahrscheinlichkeit erlauben es, f√ºr bestimmte Situationen eine Wahrscheinlichkeit hzu berechnen. Das h√∂rt sich vielleicht wild an, ist aber oft ganz einfach.\n\nBeispiel 4.1 (Wahrscheinlichkeit f√ºr eine gerade Zahl beim W√ºrfelwurf) Ein (normaler) W√ºrfel wird geworfen. Was ist die Wahrscheinlichkeit f√ºr eine gerade Zahl, also f√ºr das Ereignis \\(A=\\{2, 4, 6\\}\\)? Diese Wahrscheinlichkeit betr√§gt \\(Pr(\\text{gerade Zahl}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2\\). \\(\\square\\)\n\n\nBeispiel 4.2 (Gezinkter W√ºrfel) Ein gezinkter W√ºrfel hat eine erh√∂hte Wahrscheinlichkeit f√ºr das Ereignis \\(A=\\)‚Äú6 liegt oben‚Äù, und zwar gelte \\(Pr(A)=1/3\\). Was ist die Wahrscheinlichkeit, keine 6 zu w√ºrfeln? \\(\\square\\)1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#additionssatz",
    "href": "0350-wskt2.html#additionssatz",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.3 Additionssatz",
    "text": "4.3 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse A und B eintritt. ‚ÄúMindestens eines der Ereignisse A und‚Äù schreibt man \\(A \\cup B\\) und sagt ‚ÄúA vereinigt B‚Äù.\n\n4.3.1 Addition disjunkter Ereignisse\nGegeben sei \\(\\Omega = {1,2,3,4,5,6}\\) beim normalen W√ºrfelwurf. Als Sinnbild: \\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\). Gesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\), das also eine 1 oder\neine 2 geworfen wird. Man beachte, dass die beiden Ergebnisse disjunkt sind, s. Abbildung¬†3.6: Wenn man eine 1 wirft, hat man keine 2 geworfen.\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\nDie Wahrscheinlichkeit f√ºr \\(A\\) ist die Summe der Wahrscheinlichkeiten der einzelnen Ereignisse (1 und 2):\n\\(Pr(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\nDefinition 4.1 (Additionssatz f√ºr disjunkte Ereignisse) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt, ist die Summe der Einzelwahrscheinlichkeiten, s. Theorem¬†4.1.\n\n\nTheorem 4.1 (Additionssatz f√ºr disjunkte Ereignisse) \\[Pr(A \\cup B) = P(A) + P(B) \\square\\]\n\n\nBeispiel 4.3 Was ist die Wahrscheinlichkeit, an einem Samstag oder Sonntag geboren zu sein? Unter der (vereinfachten) Annahme, dass alle Jahre zu gleichen Teilen aus allen Wochentagen bestehen und dass an allen Tagen gleich viele Babies geworden werden2, ist die Antwort \\(Pr(A)=1/7 + 1/7 = 2/7\\).\\(\\square\\)\n\n\n4.3.2 Addition allgemeiner Ereignisse\nUnter allgemeinen Ereignissen verstehen wir hier sowohl disjunkte als auch nicht disjunkte. Bei der Addition der Wahrscheinlichkeiten f√ºr \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) (der √úberlappungsbereich) doppelt erfasst ‚Äì sofern sie nicht disjunkt sind, aber wenn sie disjunkt sind, so ist der Schnitt gleich Null und wir machen auch dann nichts falsch. Der √úberlappungsbereich muss daher noch abgezogen werden, s. Abbildung¬†4.1.\n\nDefinition 4.2 (Allgemeiner Additionssatz) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse \\(A\\) und \\(B\\) eintritt, ist gleich der Summe ihrer Wahrscheinlichkeiten minus ihrer gemeinsamen Wahrscheinlichkeit, s. Theorem¬†4.2 und Abbildung¬†4.1. \\(\\square\\)\n\n\nTheorem 4.2 (Allgemeiner Additionssatz) \\[Pr(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\square\\]\n\n\n\n\n\n\nAbbildung¬†4.1: Der allgemeine Additionssatz gibt die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse eintritt.\n\n\n\n\n\n\n\n\n\nBeispiel 4.4 (Lernen und Klausur bestehen) In einem Psychologie-Studiengang sind die Studis verdonnert, zwei Statistik-Module (\\(S1, S2\\)) zu belegen. Die meisten bestehen (\\(B\\)), einige leider nicht (\\(N\\)), s. Tabelle¬†4.1.\nEreignis \\(S_1B\\) sei ‚ÄúKlausur Statistik 1 bestanden‚Äù Ereignis \\(S_2B\\) ist analog f√ºr ‚ÄúKlausur Statistik 2‚Äù.\nWir suchen die Wahrscheinlichkeit des Ereignisses A, d.h. mindestens eine der beiden Klausuren zu bestehen: \\(Pr(A) = Pr(S_1B \\cup S_2B)\\).\n\n\n\nTabelle¬†4.1: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n\n\n.\nS1_B\nS1_NB\nSumme\n\n\n\nS2_B\n85\n9\n94\n\n\nS2_NB\n5\n1\n6\n\n\nSumme\n90\n10\n100\n\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(A) &= Pr(S_1B \\cup S_2B) \\\\\n&= Pr(S1_B) + Pr(S_2B) - Pr(S_1B \\cap S_2B)  \\\\\n&= (90 + 94 - 85) / 100 = 99 / 100\\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen liegt bei 99%.\n\n√úbungsaufgabe 4.1 (Peer Instruction: Keine Klausur bestanden) Wie hoch ist die Wahrscheinlichkeit, keine der beiden Klausuren zu bestehen?\n\n1%\n5%\n6%\n9%\n10%\n16% \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#bedingte-wahrscheinlichkeit",
    "href": "0350-wskt2.html#bedingte-wahrscheinlichkeit",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.4 Bedingte Wahrscheinlichkeit",
    "text": "4.4 Bedingte Wahrscheinlichkeit\n\n4.4.1 Illustration zur bedingten Wahrscheinlichkeit\n\nDefinition 4.3 (Bedingte Wahrscheinlichkeit) Die bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit, dass \\(A\\) eintritt, gegeben dass \\(B\\) schon eingetreten ist. \\(\\square\\)\n\nMan schreibt: \\(Pr(A|B).\\) Lies: ‚ÄúA gegeben B‚Äù oder ‚ÄúA wenn B‚Äù.\n\n√úbungsaufgabe 4.2 Schauen Sie sich mal diese Animation von Victor Powell an zu bedingten Wahrscheinlichkeiten an. Sehenswert.\n\nAbbildung¬†4.2 illustriert unbedingte Wahrscheinlichkeit, \\(Pr(A), Pr(B)\\), gemeinsame Wahrscheinlichkeit \\(Pr(A \\cap B)\\), und bedingte Wahrscheinlichkeit, \\(Pr(A|B)\\).\n\n\n\n\n\\(Pr(A)\\)\n\\(Pr(B)\\)\n\\(Pr(B|A)\\)\n\\(Pr(A \\cap B)\\)\n\n\n\n\n\n\n\n\n\n\n(a) Unbedingte Wahrscheinlichkeit f√ºr Ereignis A: 50%=1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Unbedingte Wahrscheinlichkeit f√ºr Ereignis B: 50%=1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Wahrscheinlichkeit f√ºr Ereignis B gegeben A, \\(Pr(B|A)=1/2\\)\n\n\n\n\n\n\n\\(Pr(A \\cap B)\\) wird auch h√§ufig (synonym) geschrieben als \\(Pr(AB)\\).\n\n\n\n\n\n\n\n(d) Wahrscheinlichkeit f√ºr das gemeinsame Eintreten von A und B: \\(Pr(AB)=1/4\\)\n\n\n\n\n\n\n\n\n\nAbbildung¬†4.2: Illustration von unbedingter, gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\nBeispiel 4.5 (Bedingte Wahrscheinlichkeit) Sei \\(A\\) ‚ÄúSch√∂nes Wetter‚Äù und \\(B\\) ‚ÄúKlausur steht an‚Äù. Dann meint \\(Pr(A|B)\\) die Wahrscheinlichkeit, dass das Wetter sch√∂n ist, wenn gerade eine Klausur ansteht.\\(\\square\\)\n\n\nBeispiel 4.6 (Von P√§psten und M√§nnern) Man(n) beachte, dass die Wahrscheinlichkeit, Papst \\(P\\) zu sein, wenn man Mann \\(M\\) ist etwas anderes ist, als die Wahrscheinlichkeit, Mann zu sein, wenn man Papst ist: \\(Pr(P|M) \\ne Pr(M|P)\\). Das h√∂rt sich erst verwirrend an, aber wenn man dar√ºber nachdenkt, wird es plausibel.\\(\\square\\)\n\n\nBeispiel 4.7 Gustav Gro√ü-G√ºtz verkauft eine Tinktur3, die schlau machen soll, ‚ÄúG√ºtzis Gehirn Gr√ºtze‚Äù.4 Gustav trinkt die Gr√ºtze und sagt schlaue Dinge. Was schlie√üen wir daraus? Sei \\(H\\) (wie Hypothese) ‚ÄúG√ºtzis Gr√ºtze macht schlau‚Äù; sei \\(D\\) (wie Daten) die Beobachtung, dass Gustav schlaue Dinge gesagt hat. Ohne exakte Zahlen zu suchen, wie hoch ist wohl \\(Pr(D|H)\\)? In Worten: ‚ÄúWie wahrscheinlich ist es, schlaue Dinge gesagt zu haben, wenn die Gr√ºtze wirklich schlau macht?‚Äù. Vermutlich ist diese Wahrscheinlichkeit sehr hoch. Aber wie hoch ist wohl \\(Pr(H|D)\\)? In Worten: ‚ÄúWie wahrscheinlich ist es, dass die Gr√ºtze wirklich schlau macht, gegeben, dass wir gesehen hat, dass jemand etwas schlaues gesagt hat, nachdem er besagte Gr√ºtze getrunken hat?‚Äù Skeptische Geister werden der Meinung sein, \\(Pr(H|D)\\) ist gering. Das Beispiel zeigt u.a. \\(Pr(H|D) \\ne Pr(D|H).\\square\\)\n\n\n4.4.2 Bedingte Wahrscheinlichkeit als Filtern einer Tabelle\n\nBetrachten wir Tabelle¬†4.2. Dort sind sind vier Tage aufgelistet, mit jeweils Regen (oder kein Regen) bzw. an denen es kalt ist (oder nicht). Filtern wir z.B. die Tabelle so, dass nur kalte Tage √ºbrig bleiben, dann gibt der Anteil der Zeilen, die ‚ÄúRegen‚Äù anzeigen, die bedingte Wahrscheinlichkeit \\(Pr(\\text{Regen}|\\text{kalt})\\) an.\n\n\n\nTabelle¬†4.2: Die Tabelle zeigt vier Tage, an denen es jeweils kalt ist (oder nicht) bzw. regnet (oder nicht). Die bedingte Wahrscheinlichkeit \\(Pr(\\text{Regen}|\\text{kalt})\\) entspricht dem Anteil der Zeilen mit Regen, wenn f√ºr ‚Äòkalt‚Äô ein Filter in der Tabelle gesetzt ist.\n\n\n\n\n\n\n\n\n\n\nAlso: Das Berechnen einer bedingten Wahrscheinlichkeit, \\(Pr(A|B)\\), ist vergleichbar zum Filtern einer Tabelle, s. Tabelle¬†4.3.\n\n\n\nTabelle¬†4.3: Eine bedingte Wahrscheinlichkeit kann man als gefilterte Tabelle verstehen\n\n\n\n\nid\nkalt\nRegen\n\n\n\n1\n0\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n1\n1\n\n\nSUMME\n2\n2\n\n\n\n\n\n\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(Pr(A) = 2/4; Pr(B) = 2/4; Pr(A \\cap B) = 1/4; Pr(A|B) = 1/2\\)\nDie Wahrscheinlichkeit f√ºr \\(A\\), wenn \\(B\\) schon eingetreten ist, berechnet sich so, s. Theorem¬†4.3 und Abbildung¬†4.2 (c).\n\nTheorem 4.3 (Bedingte Wahrscheinlichkeit) \\[Pr(A|B) = \\frac{Pr(A \\cap B)}{Pr(B)}\\]\nAu√üerdem gilt analog\n\\[Pr(B|A) = \\frac{Pr(B \\cap A)}{Pr(A)} \\quad \\square\\]\n\n\nBeispiel 4.8 (Lernen und Klausur bestehen) Sie bereiten sich gerade auf die Klausur bei Prof.¬†S√º√ü vor. Das hei√üt: Sie √ºberlegen, ob Sie sich auf die Klausur vorbereiten sollten. Vielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr gro√ü? Aber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen k√∂nnen, s. Tabelle¬†4.4. In der Tabelle sind die Daten von 100 Studis ausgewiesen. Ein Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die ‚ÄúLerner‚Äù. Ein anderer Teil hat nicht gelernt, \\(NL\\) bzw. \\(\\neg L\\). Ein Teil hat bestanden, \\(B\\), ein Teil nicht \\(NB\\) oder \\(\\neg B\\).\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: \\(Pr(B |\\neg L)\\).\n\n\n\nTabelle¬†4.4: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n.\nL\nNL\nSumme\n\n\n\nB\n80\n1\n81\n\n\nNB\n5\n14\n19\n\n\nSumme\n85\n15\n100\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(B |\\neg L) &= \\frac{Pr(B \\cap \\neg L)}{Pr(\\neg L)} \\\\\n&=\\frac{1/100}{15/100} = 1/15 \\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat, liegt bei 1 von 15, also ca. 7%.5 \\(\\square\\)\n\n\nBeispiel 4.9 (Kalt und Regen) Die Wahrscheinlichkeit, dass es kalt ist, wenn es regnet, ist gleich der Wahrscheinlichkeit, dass es gleichzeitig kalt ist und regnet, geteilt durch die Wahrscheinlichkeit, dass es regnet.\\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#stochastische-un-abh√§ngigkeit",
    "href": "0350-wskt2.html#stochastische-un-abh√§ngigkeit",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.5 Stochastische (Un-)Abh√§ngigkeit",
    "text": "4.5 Stochastische (Un-)Abh√§ngigkeit\n\n4.5.1 Unabh√§ngigkeit\nStochastische Unabh√§ngigkeit ist ein Spezialfall von Abh√§ngigkeit: Es gibt sehr viele Auspr√§gungen f√ºr Abh√§ngigkeit, aber nur eine f√ºr Unabh√§ngigkeit. K√∂nnen wir Unabh√§ngigkeit nachweisen, haben wir also eine starke Aussage get√§tigt.\n\nDefinition 4.4 (Stochastische Unabh√§ngigkeit) Zwei Ereignisse sind (stochastisch) unabh√§ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abh√§ngt, ob \\(B\\) der Fall ist, s. Theorem¬†4.4. Anders gesagt:6\n\n\n\nTheorem 4.4 (Stochastische Unabh√§ngigkeit) \\[ Pr(A) = Pr(A|B) =Pr(A|\\neg B) \\square\\]\nIn Worten: Wenn die Wahrscheinlichkeit von A sich nicht √§ndert, wenn B eingetreten ist, so ist A von B (stochastisch) unabh√§ngig.\nDie Unabh√§ngigkeit von \\(A\\) und \\(B\\) wird manchmal so in Kurzschreibweise ausgedr√ºckt: \\(\\perp \\!\\!\\! \\perp(A, B) \\square\\).\n\n\nTheorem 4.5 (Stochastische Unabh√§ngigkeit 2) Setzt man Theorem¬†4.3 in Theorem¬†4.4 (linke Seite) ein, so folgt7\n\\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B).\\quad \\square\\]\n\nIn Worten: Die Wahrscheinlichkeit, dass A und B beide der Fall sind, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten.\n\nBeispiel 4.10 (Augenfarbe und Statistikliebe) Ich vermute, dass die Ereignisse \\(A\\), ‚ÄúAugenfarbe ist blau‚Äù, und \\(B\\), ‚ÄúIch liebe Statistik‚Äù, voneinander unabh√§ngig sind.\\(\\square\\)8\n\n\nBeispiel 4.11 (√úberleben auf der Titanic) S. Abbildung¬†4.3, links: √úberleben (√ú) auf der Titanic ist offenbar abh√§ngig von der Passagierklasse (\\(K_1, K_2, K_3\\)). In Abbildung¬†4.3, links gilt also \\(Pr(√ú|K_1) \\ne Pr(√ú|K_2) \\ne Pr(√ú|K_3) \\ne Pr(√ú)\\).\nAuf der anderen Seite: Das Ereignis √úberleben (√ú) auf der Titanic ist unabh√§ngig vom Ereignis Alter ist eine Primzahl (P), s. Abbildung¬†4.3, rechts. Also: \\(Pr(√ú|P) = Pr(√ú|\\neg P) = Pr(√ú)\\), vgl. Tabelle¬†4.5.\n\n\n\nTabelle¬†4.5: Kontingenztablle (H√§ufigkeiten) f√ºr ‚Äò√úberleben auf der Titanic‚Äô und ‚ÄòAlter ist Primzahl‚Äô. Wie man sieht, gibt es keine stochastische Abh√§ngigkeit.\n\n\n\n\n\n\nAge_prime\nn\nprop\n\n\n\n0\n\n\nnon-prime\n96\n0.17\n\n\nprime\n453\n0.83\n\n\n1\n\n\nnon-prime\n58\n0.17\n\n\nprime\n282\n0.83\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) √úberleben und Passagierklasse sind abh√§ngig\n\n\n\n\n\n\n\n\n\n(b) √úberleben und ‚ÄòGeburstag ist eine Primzahl‚Äô sind nicht abh√§ngig\n\n\n\n\n\n\nAbbildung¬†4.3: Abh√§ngigkeit und Unabh√§ngigkeit zweier Ereignisse\n\n\n\n4.5.2 Stochastische Abh√§ngigkeit\nLiegt keine Unabh√§ngigkeit vor, so spricht man von (stochastistischer) Abh√§ngigkeit, s. Theorem¬†4.6. In diesem Fall ver√§ndert sich unser Wissen √ºber die Wahrscheinlichkeit von \\(A\\), wenn wir wissen, dass \\(B\\) eingetroffen ist, s. Theorem¬†4.6.\n\nTheorem 4.6 (Stochastische Abh√§ngigkeit) \\[Pr(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B) \\quad \\square\\]\nIn Worten: √Ñndert sich die Wahrscheinlichkeit von A, wenn B der Fall ist, so sind A und B voneinander (stochastich) abh√§ngig.\nTheorem¬†4.6 gilt nat√ºrlich in dieser Form f√ºr alle anderen Variablen ebenso, s. z.B. Theorem¬†4.7. \\(\\square\\)\n\n\nTheorem 4.7 (Stochastische Abh√§ngigkeit 2) \\[Pr(B|A) \\ne Pr(B) \\ne Pr(B|\\neg A) \\quad \\square\\]\n\n\nBeispiel 4.12 Die Ereignisse ‚ÄúLernen‚Äù und ‚ÄúKlausur bestehen‚Äù seien voneinander abh√§ngig. Unsere Einsch√§tzung zur Wahrscheinlichkeit von K √§ndert sich, wenn wir wissen, dass L vorliegt. Genauso wird sich unsere Einsch√§tzung zur Wahrscheinlichkeit von K √§ndern, wenn wir wissen, dass L nicht vorliegt. \\(\\square\\)\n\n\nBeispiel 4.13 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land9 (\\(B\\)) voneinander abh√§ngig (s. Abbildung¬†4.4)?\n\n\n\n\n\n\n\n\n\n(a) Impfquote und Land sind voneinander abh√§ngig\n\n\n\n\n\n\n\n\n\n(b) Anteil Corona-Tote und Land sind voneinander abh√§ngig\n\n\n\n\n\n\nAbbildung¬†4.4: Impfquote und Sterblichkeit sind voneinander abh√§ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\nJa, die beiden Ereignisse sind abh√§ngig, da in beiden Diagrammen gilt: \\(Pr(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\\(\\square\\)10\n\n\n4.5.3 Unabh√§ngigkeit ist symmetrisch\nStochastische Unabh√§ngigkeit ist symmetrisch: Wenn \\(A\\) unabh√§ngig zu \\(B\\) ist auch \\(B\\) unabh√§ngig zu \\(A\\), s. Theorem¬†4.8.\n\nTheorem 4.8 (Symmetrie der Unabh√§ngigkeit) \\[Pr(A|B) = Pr(A) \\leftrightarrow Pr(B|A) = Pr(B)\\]\nMan beachte, dass stochastische Unabh√§ngigkeit und kausale Unabh√§ngigkeit unterschiedliche Dinge sind (Henze, 2019): Stochastische Unabh√§ngigkeit impliziert nicht kausale Unabh√§ngigkeit. \\(\\square\\)\n\n\n√úbungsaufgabe 4.3 (Peer Instruction: Welche Aussagen √ºber stochastische Unabh√§ngigkeit ist korrekt?) ¬†\n\nWenn X und Y unabh√§ngig sind, dann hat X keinen Einfluss auf Y im Alltag.\n\nZwei Ereignisse A und B sind unabh√§ngig, wenn sie sich nicht √ºberschneiden.\n\nWenn X und Y unkorreliert sind, dann sind sie unabh√§ngig.\nWenn X und Y abh√§ngig sind, dann k√∂nnen sie nicht gleichzeitig positive Korrelation haben.\n\nWenn X und Y unabh√§ngig sind, sind sie auch unkorreliert.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#multiplikationssatz",
    "href": "0350-wskt2.html#multiplikationssatz",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.6 Multiplikationssatz",
    "text": "4.6 Multiplikationssatz\nGegeben seien die Ereignisse \\(A\\) und \\(B\\). Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass beide Ereignisse \\(A\\) und \\(B\\) der Fall sind; Abbildung¬†4.2 (d) verdeutlicht dies f√ºr zwei unabh√§ngige Ereignisse. Man schreibt ‚ÄúA und B‚Äù als \\(A \\cap B\\) (lies ‚ÄúA geschnitten B‚Äù oder ‚ÄúA und B‚Äù) oder kurz \\(AB\\), um anzuzeigen, dass sowohl \\(A\\) als auch \\(B\\) eingetreten sind.\n\n\n\n\n\n\n\nBeide Ereignisse A und B sind eingetreten\n\n\n\n\nBeispiel 4.14 (Wieder kalt und Regen) Es ist eine Sache, zu fragen, wie wahrscheinlich ist ist, dass es kalt ist (bei K√§lte), wenn es regnet (bei Regen): \\(Pr(K|R)\\). Anders gesagt: ‚ÄúWie gro√ü ist die Wahrscheinlichkeit f√ºr K√§lte, gegeben dass es regnet?‚Äù Eine andere Sache ist es, nach der Wahrscheinlichkeit zu fragen, dass es gleichzeitig kalt ist und regnet, dass also beide Ereignisse (kalt und Regen) eintreten: \\(Pr(K \\cap R), Pr(KR)\\). \\(\\square\\)\n\n\n4.6.1 Gemeinsame Wahrscheinlichkeit unabh√§ngiger Ereignisse\n\nBeispiel 4.15 Wir f√ºhren das Zufallsexperiment ‚ÄúWurf einer fairen M√ºnze‚Äù zwei Mal aus (Abbildung¬†4.5). Wie gro√ü ist die Wahrscheinlichkeit, 2 Mal Kopf zu werfen? Dabei vereinbaren wir, dass ‚ÄúKopf‚Äù als ‚ÄúTreffer‚Äù z√§hlt (und ‚ÄúZahl‚Äù als ‚ÄúNiete‚Äù).\\(\\square\\)\n\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B1[T]\n    A --&gt; B2[N]\n\n    %% Zweiter Wurf\n    B1 --&gt; C1[TT]\n    B1 --&gt; C2[TN]\n    B2 --&gt; C3[NT]\n    B2 --&gt; C4[NN]\n\n\n\n\n\nAbbildung¬†4.5: Wir werfen zwei faire M√ºnzen: Zweifach wiederholtes Zufallsexperiment\n\n\n\n\nAbbildung¬†4.5 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis des Zufallexperiments. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom ‚ÄúStart‚Äù (schwarzer Kreis) f√ºhren zwei m√∂gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch Bl√§tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen M√ºnzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der Bl√§tter. In diesen Diagramm gibt es vier Pfade (und Bl√§tter).\nDen Wurf der ersten M√ºnze nennen wir in gewohnter Manier \\(A\\); den Wurf der zweiten M√ºnze \\(B\\).\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in Tabelle¬†4.6.\n\n\n\nTabelle¬†4.6: Wahrscheinlichkeiten der Ereignisse im zweimaligen M√ºnzwurf\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\n\n\n\nSei \\(K_1\\) das Ereignis, mit der 1. M√ºnze Kopf zu werfen; sei \\(K_2\\) das Ereignis, mit der 2. M√ºnze Kopf zu werfen.\nWir suchen \\(Pr(K_1 \\cap K_2)\\). Aufgrund der stochastischen Unabh√§ngigkeit der beiden Ereignisse gilt: \\(Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)\\).\n\nCodePr_K1K2 &lt;- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n\n\n\nDefinition 4.5 (Multiplikationssatz f√ºr unabh√§ngige Ereignisse) Die Wahrscheinlichkeit, dass zwei (oder mehr) unabh√§ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. Theorem¬†4.9. \\(\\square\\)\n\n\nTheorem 4.9 (Multiplikationssatz f√ºr unabh√§ngige Ereignisse) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B)\\]\nMan beachte, dass es egal ist, ob \\(A\\) gemeinsam mit \\(B\\) oder \\(B\\) gemeinsam mit \\(A\\) eintreten: \\(Pr(A \\cap B) = Pr(B \\cap A)\\). Man spricht in diesem Zusammenhang von der Symmetrie der Multiplikation. \\(\\square\\)\n\nMit dieser App k√∂nnen Sie das Baumdiagramm f√ºr den zweifachen M√ºnzwurf n√§her erkunden.\nWir f√ºhren das Zufallsexperiment ‚ÄúWurf einer fairen M√ºnze‚Äù drei Mal aus (Abbildung¬†4.6). Dabei vereinbaren wir wieder, dass ‚ÄúKopf‚Äù (K) als ‚ÄúTreffer‚Äù gilt und ‚ÄúZahl‚Äù (Z) als ‚ÄúNiete‚Äù.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B1[T]\n    A --&gt; B2[N]\n\n    %% Zweiter Wurf\n    B1 --&gt; C1[TT]\n    B1 --&gt; C2[TN]\n    B2 --&gt; C3[NT]\n    B2 --&gt; C4[NN]\n\n    %% Dritter Wurf\n    C1 --&gt; D1[TTT]\n    C1 --&gt; D2[TTN]\n    C2 --&gt; D3[TNT]\n    C2 --&gt; D4[TNN]\n    C3 --&gt; D5[NTT]\n    C3 --&gt; D6[NTN]\n    C4 --&gt; D7[NNT]\n    C4 --&gt; D8[NNN]\n\n\n\n\nAbbildung¬†4.6: Wir werfen drei faire M√ºnzen: Das dreifach wiederholte bin√§re Zufallexperiment\n\n\n\n\nBeim Wurf von ‚Äúfairen‚Äù M√ºnzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere Einsch√§tzung des Ergebnis des 2. Wurfes nicht ver√§ndert etc. Anders gesagt: Wir gehen von (stochastischer) Unabh√§ngigkeit aus.\nF√ºr z.B. das Ereignis \\(A=\\{ZZZ\\}\\) gilt: \\(Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3\\). Da jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jedes Endknotens gleich.\nAllgemeiner gilt: F√ºr ein Zufallsexperiment, das aus \\(k\\) Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit \\(Pr(X)=p\\) ist, so ist die Wahrscheinlichkeit f√ºr einen Endkonten \\(Pr(X^k)=p^k\\).\n\n\n\nTabelle¬†4.7: Ausgew√§hlte Wahrscheinlichkeiten von Ereignissen im dreifachen M√ºnzwurf\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n1K\n1/8 + 1/8 + 1/8 = 3/8\n\n\n2K\n3 * 1/8 = 3/8\n\n\n3K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n\n\n\n\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. Tabelle¬†4.7.\nAbbildung¬†4.2 versinnbildlicht nicht nur die Bedingtheit zweier Ereignisse, sondern auch die (Un-)Abh√§ngigkeit zweier Ereignisse, \\(A\\) und \\(B\\). In diesem Fall ist die Wahrscheinlichkeit von \\(A\\) gleich \\(B\\): \\(Pr(A)=Pr(B)=.5\\). Man sieht, dass die Wahrscheinlichkeit von \\(A\\) bzw. von \\(B\\) jeweils die H√§lfte der Fl√§che (der Gesamtfl√§che, d.h von \\(Pr(\\Omega)=1\\)) ausmacht. Die Schnittmenge der Fl√§che von \\(A\\) und \\(B\\) entspricht einem Viertel der Fl√§che: \\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.\\) In diesem Fall sind \\(A\\) und \\(B\\) unabh√§ngig. Abbildung¬†4.2 zeigt weiterhin, dass gilt: \\(Pr(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\). Man beachte, dass diese Formel nur bei Unabh√§ngigkeit (von A und B) gilt.\n\n4.6.2 Gemeinsame Wahrscheinlichkeit allgemeiner Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung allgemeiner abh√§ngiger Ereignisse an, s. Abbildung¬†4.7.\n\nBeispiel 4.16 In einer Urne befinden sich f√ºnf Kugeln, von denen vier rot sind und eine blau ist.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nWie gro√ü ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zur√ºcklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier, 2011), S. 47. Ereignis A: ‚ÄúKugel im 1. Zug hat die Farbe Rot‚Äù. Ereignis B: ‚ÄúKugel im 2. Zug hat die Farbe Rot‚Äù.\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. Abbildung¬†4.7.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|4/5|B[Zug 1 - A]\n  A --&gt;|1/5|C[Zug 1 - nA]\n  B --&gt;|3/4|D[Zug 2 - B]\n  B --&gt;|1/4|E[Zug 2 -  nB]\n  D --- H[Fazit: AB - 4/5*3/4 = 12/20]\n  E --- I[Fazit: AnB - 4/5*1/4 = 4/20]\n  C --&gt;|4/4|F[Zug 2 - B]\n  C --&gt;|0/4|G[Zug 2 - nB]\n  F --- J[Fazit: nAB - 1/5*4/4 = 4/20]\n  G --- K[Fazit: nAnB - 1/5*0/4 = 0/20]\n  \n  \n\n\n\n\nAbbildung¬†4.7: Baumdiagramm f√ºr ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abh√§ngig ist vom 1. Zug.\n\n\n\n\nWie man in Abbildung¬†4.7 nachrechnen kann gilt also: \\(Pr(A\\cap B) = P(A) \\cdot P(B|A) = 4/5 \\cdot 3/4 = 12/20 = 3/5 \\quad \\square\\)\n\n\nDefinition 4.6 (Gemeinsame Wahrscheinlichkeit) Die Wahrscheinlichkeit, dass zwei abh√§ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt der Wahrscheinlichkeit von \\(A\\) und der bedingten Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\), s. Theorem¬†4.10. \\(\\square\\)\n\n\nTheorem 4.10 (Gemeinsame Wahrscheinlichkeit) \\[Pr(A \\cap B) = Pr(A) \\cdot Pr(B|A) \\quad \\square\\]\n\n\nBeispiel 4.17 (Kalt und Regen) Von McElreath (2020) stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit. Was ist die Wahrscheinlichkeit f√ºr das gemeinsame Auftreten von kalt ‚ùÑ und Regen ‚õàÔ∏è? Die Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von Regen ‚õà, wenn‚Äôs kalt ‚ùÑ ist mal die Wahrscheinlichkeit von K√§lte ‚ùÑ.\nEbenfalls gilt: Die Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von K√§lte ‚ùÑ, wenn‚Äôs regnet ‚õàÔ∏è mal die Wahrscheinlichkeit von Regen ‚õàÔ∏è.\nDas Gesagte als Emoji-Gleichung ist in Gleichung¬†4.1 dargestellt.\n\\[Pr(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è |‚ùÑÔ∏è ) \\cdot P(‚ùÑÔ∏è) =  P(‚ùÑÔ∏è |‚õàÔ∏è ) \\cdot P(‚õàÔ∏è) \\tag{4.1}\\]\nMan kann die ‚ÄúGleichung drehen‚Äù11, s. Gleichung¬†4.2.\n\\[Pr(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è \\text{ und } ‚ùÑÔ∏è) \\tag{4.2}\\] \\(\\square\\)\n\n\nBeispiel 4.18 (Bertie Botts Bohnen jeder Geschmacksrichtung) ¬†\n\nSei blo√ü vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gew√∂hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.‚Äú\n\n‚Äî Ron Weasley zu Harry Potter12\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=2\\) furchtbar scheu√üliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erkl√§rt, \\(k=2\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt hei√üt es tapfer sein. Ziehen und runter damit!\nWie gro√ü ist die Wahrscheinlichkeit, genau eine scheu√üliche Bohne zu erwischen?\nEs gibt 2 Pfade f√ºr 1 Treffer bei 2 Wiederholungen (Z√ºge aus dem Beutel), s. Abbildung¬†4.8: Man kann im ersten Zug eine scheu√üliche Bohne erwischen, aber nicht im zweiten Zug. Oder man man im zweiten Zug Pech haben (aber nicht im ersten). Die Summe der Wahrscheinlichkeiten beider Pfade ist die Wahrscheinlichkeit f√ºr genau eine scheu√üliche Bohne, das sind 19%.\n\n\n\n\n\ngraph LR\n    A[Start: 20 Bohnen] --&gt; B1[Bohne 1 gut = 18/20]\n    A --&gt; B2[Bohne 1 schlecht = 2/20]\n    \n    B1 --&gt; C1[Bohne 2 gut = 17/19]\n    B1 --&gt; C2[Bohne 2 schlecht = 2/19]\n    \n    B2 --&gt; C3[Bohne 2 gut = 18/19]\n    B2 --&gt; C4[Bohne 2 schlecht = 1/19]\n    \n    C1 --&gt; D1[Ergebnis: gut, gut]\n    C2 --&gt; D2[Ergebnis: gut, schlecht]\n    C3 --&gt; D3[Ergebnis: schlecht, gut]\n    C4 --&gt; D4[Ergebnis: schlecht, schlecht]\n\n\n\n\n\nAbbildung¬†4.8: Baumdiagramm f√ºr ein ein zweistufiges Zufallsereignis: Bertie Botts Bohnen.\n\n\n\n\n\nCodePfad1 &lt;- 2/20 * 18/19  # scheu√üliche Bohne im 1. Zug\nPfad2 &lt;- 18/20 * 2/19  # scheu√üliche Bohne im 2. Zug\n\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 \nGesamt_Pr\n## [1] 0.19\n\n\nNutzen Sie diese App, um das auszuprobieren. Sie m√ºssen in der App noch die Zahl der Bohnen (\\(n\\)) und die Zahl der scheu√ülichen Bohnen (\\(x\\)) einstellen.\\(\\square\\)\n\n\n4.6.3 Kettenregel\n\nDefinition 4.7 (Kettenregel) Allgemein gesagt, spricht man von der Kettenregel der Wahrscheinlichkeitsrechnung, wenn man die gemeinsame Wahrscheinlichkeit auf die bedingte zur√ºckf√ºhrt, s. Theorem¬†4.11. \\(\\square\\)\n\n\nTheorem 4.11 (Kettenregel) \\[Pr(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B) \\square\\]\nIn Worten: Die Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) ist gleich der Wahrscheinlichkeit von \\(A\\) mal der Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\).\n\n\n√úbungsaufgabe 4.4 (Baumdiagramm sucht Problem) √úberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit dieser Baumdiagramm-App gel√∂st werden kann.\\(\\square\\)\n\n\n√úbungsaufgabe 4.5 (Peer Instruction: Dreifacher M√ºnzwurf) F√ºnf Studierende unterhalten sich, wie man einen dreifachen M√ºnzwurf verstehen kann mit dem Ergebnis von drei Treffern. Welcher Studierende liegt falsch? Gehen Sie von einer faire M√ºnze aus und Unabh√§ngigkeit der W√ºrfe.\n\nWirft man die M√ºnze drei Mal, so gibt es 6 Ergebnisse, die alle gleich wahrscheinlich sind. Aber nur ein Ergebnis ist gesucht, n√§mlich 3 von 3 Treffern. Also ist die Wahrscheinlichkeit 1/6, ca. 17%.\nMan kann einfach einen Computer fragen, z.B. R mit dbinom(x = 3, size = 3, prob = 1/2), da kommt ungef√§hr 12% raus.\nWirft man die M√ºnze drei Mal, so gibt es 8 Ergebnisse, die alle gleich wahrscheinlich sind. Aber nur ein Ergebnis ist gesucht, n√§mlich 3 von 3 Treffern. Also ist die Wahrscheinlichkeit 1/8, ca. 12,5%.\nWer rechnen kann, ist klar im Vorteil \\(\\left( \\frac{1}{2} \\right)^3 = \\left( \\frac{1}{2^3} \\right) = \\left( \\frac{1}{8} \\right)\\)\n\nHolt mich hier raus! \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#totale-wahrscheinlichkeit",
    "href": "0350-wskt2.html#totale-wahrscheinlichkeit",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.7 Totale Wahrscheinlichkeit",
    "text": "4.7 Totale Wahrscheinlichkeit\n\nBeispiel 4.19 (Gesamter Ausschussanteil) Die folgende Aufgabe bezieht sich auf Bourier (2011), S. 56. Drei Maschinen (\\(M_1, M_2, M_3\\)) produzieren einen Artikel. Die Maschinen haben einen Anteil an der Produktion von 60, 10 bzw. 30% und eine Ausschussquote von 5,2 bzw. 4%. Sei \\(M\\) das Ereignis, dass ein Artikel von Maschine \\(M\\) stammt, und \\(S\\) (Schrott) das Ereignis, dass ein Artikel Ausschuss (Schrott) ist. Gesucht ist ist der Ausschussanteil insgesamt (√ºber alle drei Maschinen). Anders gesagt: Wie hoch ist die Wahrscheinlichkeit \\(Pr(S')\\), dass ein zuf√§llig gezogener Artikel Ausschuss ist? Abbildung¬†4.9 zeigt das Baumdiagramm f√ºr die Aufgabe. \\(\\square\\)\n\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[M1]\n  A --&gt;|0.1|C[M2]\n  A --&gt;|0.3|D[M3]\n  B --&gt;|0.05|E[S]\n  B -.-&gt;|0.95|F[Nicht-S]\n  C --&gt;|0.02|G[S]\n  C -.-&gt;|0.98|H[Nicht-S]\n  D --&gt;|0.04|I[S]\n  D -.-&gt;|0.96|J[Nicht-S]\n\n\n\n\nAbbildung¬†4.9: Totale Wahrscheinlichkeit\n\n\n\n\nDie Anteile an der Produktion und vom Ausschluss sind in Abbildung¬†4.10 verdeutlicht.\n\nCodesource(\"R-code/plot_maschine_schrott.R\")\nplot_maschine_schrott\n\n\n\n\n\n\nAbbildung¬†4.10: Anteile von Produktion und Ausschuss\n\n\n\n\nDazu addieren wir die Wahrscheinlichkeiten der relevanten √Ñste. Jeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse \\(M_i\\) und \\(S\\) dar.\n\nCodeW_Ast1 &lt;- 0.6 * 0.05  # Wahrscheinlichkeit f√ºr Ast 1\nW_Ast2 &lt;- 0.1 * 0.02  # ... Ast 2\nW_Ast3 &lt;- 0.3 * 0.04  # ... Ast 3\nW_total &lt;- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n\n\nDie totale Wahrscheinlichkeit (f√ºr Ausschuss) betr√§gt in diesem Beispiel also \\(Pr(B') = 0.044 = 4.4\\%\\).13\n\nDefinition 4.8 (Totale Wahrscheinlichkeit) Bilden die Ereignisse \\(M_1, M_2, ..., M_n\\) ein vollst√§ndiges Ereignissystem und ist \\(S\\) ein beliebiges Ereignis dann gilt Theorem¬†4.12. \\(\\square\\)\n\n\nTheorem 4.12 (Totale Wahrscheinlichkeit) \\[Pr(S') = \\sum_{i=1}^n Pr(M_i) \\cdot Pr(S|M_i).\\square\\]\n\nIn Worten: Die totale Wahrscheinlichkeit ist die Summe der gewichteten Teil-Wahrscheinlichkeiten.\n\nIn Abbildung¬†4.9 (Beispiel¬†4.19) gilt \\(Pr(S') = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot  0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square\\)\n\n\n√úbungsaufgabe 4.6 (Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2) Es ist die gleich Aufgabe wie Beispiel¬†4.18, aber jetzt lautet die Frage: Wie gro√ü ist die Wahrscheinlichkeit, mindestens eine scheu√üliche Bohne bei 3 Z√ºgen zu erwischen?14 \\(\\square\\)\n\n\n4.7.1 Baumsammlung\nBaumdiagramme sind ein hilfreiches Werkzeug f√ºr wiederholte Zufallsexperimente. Daher ist hier eine ‚ÄúBaumsammlung‚Äù15 zusammengestellt.\n\nSie werfen 1 M√ºnze, Abbildung¬†3.2.\nSie werfen 2 M√ºnzen, Abbildung¬†4.5.\nSie werfen 3 M√ºnzen, Abbildung¬†4.6.\nSie werfen 4 M√ºnzen, Abbildung¬†3.20.\nSie werfen 9 M√ºnzen, ü§Ø Abbildung¬†6.7.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#vertiefung",
    "href": "0350-wskt2.html#vertiefung",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.8 Vertiefung",
    "text": "4.8 Vertiefung\nBei Henze (2019) findet sich eine anspruchsvollere Einf√ºhrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes der Kapitel 2 und 3 von Henze (2019).\nMit dieser App, die ein zweistufiges Baumdiagramm zeigt, k√∂nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\nDiese App l√§sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\nMittag & Sch√ºller (2020) stellen in Kap. 11 die Grundlagen der Wahrscheinlichkeitstheorie vor. √Ñhnliche Darstellungen finden sich in einer gro√üen Zahl an Lehrb√ºchern.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#aufgaben",
    "href": "0350-wskt2.html#aufgaben",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.9 Aufgaben",
    "text": "4.9 Aufgaben\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. Sie k√∂nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\n4.9.1 Paper-Pencil-Aufgaben\n\nAdditionssatz1\nNerd-gelockert\nUrne1\nUrne2\nk-coins-k-hits\nsicherheit\nsicherheit2\nKlausuren-bestehen\nGem-Wskt1\nGem-Wskt2\nGem-Wskt3\nGem-Wskt4\nwuerfel05\nwuerfel06\nBed-Wskt1\nBed-Wskt2\nBed-Wskt3\nvoll-normal\ncorona-blutgruppe\ntotale-Wskt1\nwskt-quiz14\nwskt-quiz09\nprob-vereinigung\nbestehen_ohne_lernen\n\n4.9.2 Aufgaben, f√ºr die man einen Computer braucht\n\nmtcars-abhaengig\nmtcars-abhaengig-var2\nmtcars-abhaengig_var3a\nwskt-df-r",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#section",
    "href": "0350-wskt2.html#section",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "\n4.10 ‚Äî",
    "text": "4.10 ‚Äî\n\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende Statistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√úbungen: Beschreibende Statistik ‚Äì Wahrscheinlichkeitsrechnung ‚Äì Schlie√üende Statistik (7. Auflage). Springer Gabler.\n\n\nHenze, N. (2019). Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der Ma√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0350-wskt2.html#footnotes",
    "href": "0350-wskt2.html#footnotes",
    "title": "\n4¬† Rechnen mit Wahrscheinlichkeiten\n",
    "section": "",
    "text": "Die Wahrscheinlichkeit, keine 6 zu w√ºrfeln, liegt bei \\(2/3\\).‚Ü©Ô∏é\nvermutlich gibt es noch mehr Annahmen, die wir uns explizit machen sollten.‚Ü©Ô∏é\ngenauer besehen sieht sie eher aus wie eine Gr√ºtze oder ein Brei‚Ü©Ô∏é\nSie schmeckt scheu√ülich.‚Ü©Ô∏é\n\\(Pr(L).85; Pr(\\neg L) = .15; Pr(B) =.81; Pr(\\neg B) = .19\\)‚Ü©Ô∏é\nExakte Gleichheit ist in dieser Welt empirisch schwer zu finden. Daher kann man vereinbaren, dass Unabh√§ngigkeit erf√ºllt ist, wenn die Gleichheit ‚Äúeinigerma√üen‚Äù oder ‚Äúziemlich‚Äù gilt, die Gleichheit gewisserma√üen ‚Äúpraktisch bedeutsam‚Äù ist.‚Ü©Ô∏é\nVgl. Theorem¬†4.9‚Ü©Ô∏é\nWer Daten dazu hat oder eine Theorie, der melde sich bitte bei mir.‚Ü©Ô∏é\nhier mit den zwei Auspr√§gungen DEU und USA‚Ü©Ô∏é\n Daten von Our World in Data, https://ourworldindata.org/covid-deaths.‚Ü©Ô∏é\nDer Multiplikationssatz ist symmetrisch‚Ü©Ô∏é\nQuelle: https://harrypotter.fandom.com/de/wiki/Bertie_Botts_Bohnen_jeder_Geschmacksrichtung‚Ü©Ô∏é\nEinfacher als das Rechnen mit Wahrscheinlichkeiten ist es in solchen F√§llen, wenn man anstelle von Wahrscheinlichkeiten absolute H√§ufigkeiten zum Rechnen verwendet.‚Ü©Ô∏é\nDie Wahrscheinlichkeit keine scheu√üliche Bohne zu ziehen ist \\(17/20 \\cdot 16/19 \\cdot 15/18) \\approx 0.6\\). Daher ist die gesuchte Wahrscheinlichkeit (mindestens eine scheu√üliche Bohne) das Komplement davon: \\(0.4\\).‚Ü©Ô∏é\nWald?‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Rechnen mit Wahrscheinlichkeiten</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html",
    "href": "0400-Verteilungen.html",
    "title": "\n5¬† Verteilungen\n",
    "section": "",
    "text": "5.1 Lernsteuerung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#lernsteuerung",
    "href": "0400-Verteilungen.html#lernsteuerung",
    "title": "\n5¬† Verteilungen\n",
    "section": "",
    "text": "5.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n5.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nden Begriff der Zufallsvariablen erl√§utern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erl√§utern\nden Begriff einer Gleichverteilung erl√§utern\nden Begriff einer Binomialverteilung erl√§utern\nBen Begriff einer halben Normalverteilung erl√§utern\nden Begriff einer Exponentialverteilung erl√§utern\nzentrale Konzepte in R umsetzen\n\n5.1.3 Begleitliteratur\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2011), Kap. 6.1 und 6.3 sowie 7.1 und und 7.2.\n\n5.1.4 Vorbereitung im Eigenstudium\nDieses Kapitel setzt einige Grundbegriffe voraus, wie im Buch Statistik1 vorgestellt, insbesondere im Kapitel ‚ÄúRahmen‚Äù. Ben√∂tigt wird auch der Begriff der Normalverteilung sowie der Begriff der Quantile.\nLesen Sie selbst√§ndig, zus√§tzlich zum Stoff dieses Kapitels, noch in Bourier (2011) folgende Abschnitte:\n\n\n\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung)\nKap. 7.2.3 (Normalverteilung)\n\nL√∂sen Sie auch die √úbungsaufgaben dazu.\nWeitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, Bourier (2022).\n\n5.1.5 Pr√ºfungsrelevanter Stoff\nBeachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff pr√ºfungsrelevant ist.\n\n5.1.6 Ben√∂tigte R-Pakete\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)  # f√ºr Plots\n\n\n\n5.1.7 Zentrale Begriffe\n\n5.1.7.1 Eigenschaften von Zufallsvariablen\n\nZufallsvariable (random variable)\nDiskret vs.¬†stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n5.1.7.2 Verteilungen\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n5.1.8 Begleitvideos\n\n√úberblick zu Verteilungen\nGleichverteilung\nBinomialverteilung",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#wichtige-verteilungen",
    "href": "0400-Verteilungen.html#wichtige-verteilungen",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.2 Wichtige Verteilungen",
    "text": "5.2 Wichtige Verteilungen\nIm Folgenden sind einige wichtige Verteilungen aufgef√ºhrt, die in diesem Skript (und in der Statistik und Wahrscheinlichkeitstheorie) eine zentrale Rolle spielen.\nüì∫ Einstieg in Verteilungen",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#gleichverteilung",
    "href": "0400-Verteilungen.html#gleichverteilung",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.3 Gleichverteilung",
    "text": "5.3 Gleichverteilung\n\n5.3.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jede Auspr√§gung der zugeh√∂rigen Zufallsvariablen gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine bestimmte Auspr√§gung einer Zufallsvariablen f√ºr plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. Abbildung¬†5.1 zeigt ein Beispiel f√ºr eine (stetige) Gleichverteilung.\n\n\n\n\n\n\n\n\n\n(a) Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2\n\n\n\n\n\n\n\n\n\n(b) Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3\n\n\n\n\n\n\nAbbildung¬†5.1: Stetige Gleichverteilung; man beachte jeweils die Y-Achse\n\n\nAbbildung¬†5.1, (a): Bei \\(X=0\\) hat eine Einheit von \\(X\\) (z.B. von -1 bis 0) die Wahrscheinlichkeitsmasse von 50%, da der Bereich \\([-1, 0]\\) die H√§lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte identisch. Abbildung¬†5.1, (b): Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von ca. 33%, da der Bereich \\([0, 1]\\) ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte identisch Definierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#sec-bin-distrib",
    "href": "0400-Verteilungen.html#sec-bin-distrib",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.4 Binomialverteilung",
    "text": "5.4 Binomialverteilung\n\n5.4.1 Grundlagen\n\nDefinition 5.1 (Binomialverteilung) Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines \\(n\\)-fach wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei1 Ergebnissen bzw. Elementarereignissen also. Dabei interessiert uns nur die Anzahl der \\(k\\) Treffer, aber nicht die Reihenfolge. Bei jeder Wiederholung liegt die Wahrscheinlichkeit eines Treffers bei \\(p\\). bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die M√ºnze ver√§ndert sich nicht durch die W√ºrfe (Ziehen mit Zur√ºcklegen, ZmZ). Au√üerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc., sog. ‚Äúiid‚Äù: independent and identically distributed.] \\(\\square\\)\n\n\\[\\overbrace{X}^{\\text{Unsere Zufallsvariable}} \\underbrace{\\sim}_{\\text{ist verteilt nach der}} \\underbrace{\\overbrace{\\text{Bin}(n, p)}^{\\text{Binomialverteilung}}}_{\\text{mit den Parametern n, p}} \\tag{5.1}\\]\n\nF√ºr eine binomialverteilte Zufallsvariable \\(X\\) schreibt man kurz wie in Theorem¬†5.1 gezeigt.\n\nTheorem 5.1 (Notation f√ºr eine binomialverteilte Zufallsvariable) \\[X \\sim \\text{Bin}(n, k) \\quad \\square\\]\n\n\nBeispiel 5.1 Anwendungsbeispiele: Wie viele defekte Teile sind in einer Stichprobe von produzierten Schrauben zu erwarten? Wie wahrscheinlich ist es, dass das neue Blutdruck-Medikament einer bestimmten Anzahl von Menschen hilft? Wie viele Personen stimmen in einer Umfrage der Frage ‚ÄúIch halte die √∂ffentlich-rechtlichen Sender f√ºr wichtig.‚Äù zu? Was ist die Wahrscheinlichkeit, 6 mal hintereinander eine 6 zu w√ºrfeln bei einem fairen W√ºrfel? Eine M√ºnze, die in 7 von 10 W√ºrfen ‚ÄúKopf‚Äù zeigt ‚Äì sollte sie als ‚Äúunfair‚Äù eingesch√§tzt werden? \\(\\square\\)\n\nStellen wir uns eine Kistchen2 mit sehr vielen3 Losen vor, darunter 2/5 Treffer (Gewinn) und 3/5 Nieten, s. Abb. Abbildung¬†5.2. Der Versuch l√§uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zur√ºck und ziehen erneut. Da sehr viele Lose im K√§stchen liegen, ist es praktisch egal, ob wir das Los wieder zur√ºcklegen. Die Wahrscheinlichkeit f√ºr einen Treffer √§ndert sich (so gut wie) nicht. Jetzt ziehen wir z.B. drei Lose. Wie gro√ü ist die Wahrscheinlichkeit, davon 2 Treffer zu erzielen (egal in welcher Reihenfolge)?\n\n\n\n\n\n\n\nAbbildung¬†5.2: Ein Losk√§stchen mit 2/5 Treffer und 3/5 Nieten\n\n\n\n\nPraktischerweise ist die Binomialverteilung in R eingebaut,\nhier ist Pseudocode f√ºr Ihre Anwendung, s. Listing¬†5.1.\n\n\n\nListing¬†5.1: R-Pseudocode f√ºr die Binomialverteilung\n\nCodedbinom(x = &lt;Anzahl der Treffer&gt;, \n       size = &lt;Anzahl der W√ºrfe&gt;, \n       prob = &lt;Wahrscheinlichkeit eines Treffers&gt;)\n\n\n\n\n\n\n5.4.2 M√∂glichkeiten z√§hlen\n\nBeispiel 5.2 (Drei Lose gekauft, davon zwei Treffer?) Wie gro√ü ist die Wahrscheinlichkeit \\(p\\) bei \\(n=3\\) Z√ºgen \\(k=2\\) Treffer zu erzielen (und \\(n-k=1\\) Niete)? (Nennen wir dieses gesuchte Ereignis der K√ºrze halber \\(A^{\\prime}\\)). Die Trefferwahrscheinlichkeit ist (bei jedem Zug) \\(p=2/5\\) und die Nietenwahrscheinlichkeit \\(1-p=3/5 \\quad \\square\\), s. Abbildung¬†5.3. Abbildung¬†4.6 zeigt den entsprechenden Baum; Tabelle¬†5.1 zeigt die Ergebnisse dieses Zufallsexperiments.\n\n\n\n\n\n\n\n\nAbbildung¬†5.3: Wie viele M√∂glichkeiten gibt es, 3 Lose zu sortieren, von denen 2 Treffer sind und 1 Niete?\n\n\n\n\n\n\nTabelle¬†5.1: Alle acht Ergebnisse des Zufallsexperiment (bin√§r, 3-fach wiederholt) mit ihren Wahrscheinlichkeiten im √úberblick\n\n\n\n\n\n\n\n\nPfad (Ereignis)\nAnzahl Treffer\nWahrscheinlichkeit\n\n\n\nTTT\n3\n\\(p^3 = \\left(\\tfrac{2}{5}\\right)^3 = \\tfrac{8}{125} \\approx 0.064\\)\n\n\nTTN\n2\n\\(p^2 q = \\tfrac{4}{25}\\cdot\\tfrac{3}{5} = \\tfrac{12}{125} \\approx 0.096\\)\n\n\nTNT\n2\n\\(p^2 q = \\tfrac{12}{125} \\approx 0.096\\)\n\n\nNTT\n2\n\\(p^2 q = \\tfrac{12}{125} \\approx 0.096\\)\n\n\nTNN\n1\n\\(p q^2 = \\tfrac{2}{5}\\cdot\\tfrac{9}{25} = \\tfrac{18}{125} \\approx 0.144\\)\n\n\nNTN\n1\n\\(p q^2 = \\tfrac{18}{125} \\approx 0.144\\)\n\n\nNNT\n1\n\\(p q^2 = \\tfrac{18}{125} \\approx 0.144\\)\n\n\nNNN\n0\n\\(q^3 = \\left(\\tfrac{3}{5}\\right)^3 = \\tfrac{27}{125} \\approx 0.216\\)\n\n\n\n\n\n\nMit Blick auf Beispiel¬†5.2: Wir k√∂nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz, Theorem¬†4.9), vgl. Abbildung¬†4.6. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit (Additionssatz, Theorem¬†4.1). Diagramme zeichnen ist einfach, dauert aber.\nBeachtet man die verschiedenen Reihenfolgen nicht, so z√§hlt man 3 g√ºnstige Pfade (T: Treffer; N: Niete), s. Abbildung¬†4.6:\n\nTTN\nTNT\nNTT.\n\nWir haben also die M√∂glichkeiten (2 Treffer und 1 Niete zu erhalten)\n\n\nohne Beachtung der Reihenfolge und\n\nohne Zur√ºcklegen (der M√∂glichkeiten)\n\ngez√§hlt.\nSchneller geht es, wenn man rechnet. Wir k√∂nnten auch R auffordern, die Anzahl der g√ºnstigen Pfade zu berechnen, s. Theorem¬†5.3 mit choose(3,2), was die Antwort 3 liefert.\n\n5.4.3 Anzahl Pfade mal Pfad-Wahrscheinlichkeit\nIn diesem Fall ist die Wahrscheinlichkeit eines (g√ºnstigen) Pfades, \\(A\\):\n\\(Pr(A) = Pr(T)^2 \\cdot Pr(N)^1 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right)^1 \\approx 0.096\\).\n\nCodep_a = (2/5)^2 * (3/5)^1\np_a\n## [1] 0.096\n\n\nDamit ist die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 3 Z√ºgen) gleich der Anzahl der g√ºnstigen \\(k\\) Pfade (3) mal der Wahrscheinlichkeit eines Pfades (0.1):\n\\(Pr(A^{\\prime}) = k \\cdot Pr(A) = 3 \\cdot 0.096 = 0.29\\).\n\nCodep_a_strich = 3 * p_a\np_a_strich\n## [1] 0.29\n\n\nDie Wahrscheinlichkeit, bei 3 Z√ºgen 2 Treffer zu erzielen, betr√§gt also ca. 29%.\nDabei steht \\(k\\) f√ºr die Anzahl der g√ºnstigen Pfade und \\(Pr(A)\\) f√ºr die Wahrscheinlichkeit eines g√ºnstigen Pfades (d.h. 2 Treffer und 1 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\n\n5.4.4 Formel der Binomialverteilung\nTheorem¬†5.2 zeigt die mathematische Definition der Binomialverteilung. Dabei liegt immer ein Zufallsversuch mit \\(n\\) Durchg√§ngen und \\(k\\) Treffern zugrunde. Jeder Durchgang hat die Trefferwahrscheinlichkeit \\(p\\) und jeder Durchgang ist unabh√§ngig von allen anderen.\n\nTheorem 5.2 (Binomialverteilung) \\[Pr(X=k|p,n) = \\frac{n}{k!(n-k)!}p^k(1-p)^{n-k}\\quad \\square\\]\n\nTheorem¬†5.2 kann wie folgt auf Deutsch √ºbersetzen:\n\nDie Wahrscheinlichkeit f√ºr das Ereignis \\(X\\) gegeben \\(p\\) und \\(n\\) berechnet als Produkt von zwei Termen. Der erste Term ist der Quotient von der Fakult√§t von n im Z√§hler und im Nenner das Produkt von erstens der Fakult√§t von k mit zweitens der Fakult√§t von (n-k). Der zweite Term ist das Produkt von p hoch k mal der komplement√§ren Wahrscheinlichkeit von p hoch (n-k).\n\nOder noch k√ºrzer:\n\nDie Wahrscheinlichkeit f√ºr das Ereignis ‚ÄúX‚Äù gegeben p und k berechnet als Produkt von zwei Termen. Erstens der Anzahl der g√ºnstigen Pfade, k und zweitens der Wahrscheinlichkeit f√ºr einen g√ºnstigen Pfad, P(A).\n\nDie Anzahl der (g√ºnstigen) Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt, s. Theorem¬†5.3.4\n\nDefinition 5.2 (Binomialkoeffizient) Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von \\(n\\) verschiedenen Objekten \\(k\\) Objekte ziehen kann (ohne Zur√ºcklegen und ohne Beachtung der Reihenfolge). \\(\\square\\)\n\n\nTheorem 5.3 (Binomialkoeffizient) \\[\\tbinom{n}{k}= \\frac{n!}{k!(n-k)!} \\quad \\square\\]\nLies: ‚ÄúW√§hle aus \\(n\\) m√∂glichen Ereignissen (Pfade im Baum) \\(k\\) g√ºnstige Ereignisse (g√ºnstige Pfade) oder k√ºrzer‚Äùk aus n‚Äù.\n\nUm den Binomialkoeffizient zu berechnen, muss man die Fakult√§t berechnen. Die Fakult√§t ist eine Rechenvorschrift f√ºr nat√ºrliche Zahlen. Man schreibt sie mit einem Ausrufezeichen hinter der Zahl, also zum Beispiel \\(3!\\). Dabei multipliziert man alle nat√ºrlichen Zahlen von der gegebenen Zahl bis hinunter zur 1.\n\nBeispiel 5.3 ¬†\n\n\\(3! = 3 \\cdot 2 \\cdot 1\\)\n\\(4! = 4 \\cdot 3 \\cdot 2 \\cdot 1\\)\n\n\\(0! = 1\\) (per Definition) \\(\\square\\)\n\n\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange √úbersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und f√ºr uns ausrechnen.\n\nBeispiel 5.4 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie gro√ü ist die Wahrscheinlichkeit, durch blo√ües M√ºnze werfen genau 15 Fragen richtig zu raten?5\n\nCode# Wskt f√ºr genau 15 Treffer bei 20 Versuchen mit einer fairen M√ºnze:\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.015\n\n\nDie Wahrscheinlichkeit liegt bei ca 1%.\nUm h√∂chstens 15 Treffer zu erzielen, m√ºssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern aufsummieren.\nPraktischerweise gibt es einen R-Befehl, der das Aufsummieren f√ºr uns √ºbernimmt: pbinom.\n\nCodepbinom(q = 15, size = 20, prob = .5)\n## [1] 0.99\n\n\nDie Wahrscheinlichkeit h√∂chstens 15 Treffer (d.h. 0, 1, 2, ‚Ä¶ 15 Treffer) zu erzielen, liegt f√ºr prob = .5 laut Binomialverteilung mit pbinom bei gut 99%.\n\n\nBeispiel 5.5 (3 M√ºnzw√ºrfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 M√ºnzw√ºrfen (genau) 3 Treffer (Kopf) zu erzielen, s. Abbildung¬†5.4, links?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\nCodedbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.12\n\n\nDie L√∂sung lautet also \\(p=1/8 = .125.\\qquad \\square\\)\nMan kann sich auch vor Augen f√ºhren, dass es genau 1 g√ºnstigen Pfad gibt, n√§mlich TTT. Nach dem Multiplikationssatz gilt also: \\(Pr(X=3) = 1 \\cdot \\left( \\frac{1}{2} \\right)^3 = \\frac{1}{8} = .125\\).\n\nCodeloesung &lt;- (1/2)^3\nloesung\n## [1] 0.125\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) n=3, p=1/2\n\n\n\n\n\n\n\n\n\n(b) n=9, p=.7\n\n\n\n\n\n\nAbbildung¬†5.4: Verschiedene Binomialverteilungen\n\n\n\n√úbungsaufgabe 5.1 Ô∏è Was f√§llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Ver√§ndert sich die Wahrscheinlichkeit linear?\n\n\n√úbungsaufgabe 5.2 Was ist die Wahrscheinlichkeit f√ºr 0, 1, 2, ‚Ä¶, 9 Treffern bei 9 W√ºrfen, wenn die Trefferwahrscheinlichkeit 70% betr√§gt? Abbildung¬†5.4, rechts, zeigt die Antwort.\n\n\n5.4.5 Rechnen mit der Binomialverteilung\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen: z.B. dbinom(x = 2, size = 3, prob = 2/5). Das ist komfortabler als selber rechnen. Mit diesem Befehl rechnet R aus, wie hoch die Wahrscheinlichkeit ist, bei size = 3 ‚ÄúM√ºnzw√ºrfen‚Äù, x = 2 Treffer zu erzielen, wobei die Trefferwahrscheinlichkeit jeweils prob = 2/5 betr√§gt.\n\nBeispiel 5.6 (Lotto) Wie viele Zahlenkombinationen gibt es im Lotto f√ºr 6 Richtige? Der Binomialkoeffizient verr√§t es uns: \\(\\tbinom{49}{6}= 13\\,983\\,816\\square\\) Ander gesagt: Der Binomialkoeffizient sagt uns, wie viele M√∂glichkeiten es gibt, aus z.B. 46 B√§llen 6 zu ziehen (ohne Beachtung der Reihenfolge und ohne Zur√ºcklegen). \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeispiel 5.7 Wie viele M√∂glichkeiten gibt es, 2 Treffer bei 4 Z√ºgen zu erzielen?\nDas sind folgende Ergebnisse: 1. TTNN, 2. TNTN, 3. TNNT, 4. NTTN, 5. NTNT, 6. NNTT.\n\\(\\tbinom{4}{2} = \\frac{4!}{2! \\cdot (4-2)!} \\overset{\\text{k√ºrzen}}= \\frac{2\\cdot 3}{1}=6\\)\nEs sind also 6 M√∂glichkeiten.\n\nIn R kann man sich die Fakult√§t mit dem Befehl factorial ausrechnen lassen. Der R-Befehl choose berechnet den Binomialkoeffizienten.6\n\nCodeanzahl_pfade_2_aus_4 &lt;- \n  factorial(4) / (factorial(2) * factorial(4-2))\nanzahl_pfade_2_aus_4\n## [1] 6\n\nchoose(4, 2)\n## [1] 6\n\n\n\\(\\square\\)\n\nBeispiel 5.8 Hier sind die 10 Kombinationen, um aus 5 Losen genau 2 Treffer und 3 Nieten zu ziehen:\nTTNNN, TNTNN, TNNTN, TNNNT, NTTNN, NTNTN, NTNNT, NNTTN, NNTNT, NNNTT\n\nCodechoose(5, 2)\n## [1] 10\n\nanzahl_pfade_2_aus_5 &lt;- \n  factorial(5) / (factorial(2) * factorial(5-2))\nanzahl_pfade_2_aus_5\n## [1] 10\n\n\n\\(\\square\\)\n\n\nBeispiel 5.9 (Bef√∂rderung) Aus einem Team mit 25 Personen sollen 11 Personen bef√∂rdert werden. Wie viele m√∂gliche Kombinationen (von bef√∂rderten Personen) k√∂nnen gebildet werden?\n\\(\\tbinom{25}{11} = \\frac{25!}{11!\\cdot(25-11)!} = 4\\,457\\,400\\)\n\nCodechoose(n = 25, k = 11)\n## [1] 4457400\n\n\nEs gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht ber√ºcksichtigt.\\(\\square\\)\n\n\n5.4.6 Pumpstation-Beispiel zur Binomialverteilung\nIn einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% f√§llt ein Motor aus und ist f√ºr den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie gro√ü ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb f√§llt?\n\\(Pr(X=k)\\) (oder kurz: \\(Pr(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an f√ºr das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(Pr(X=5)\\) ausrechnen.\n\nCodedbinom(x = 5, size = 7, prob = .95)\n## [1] 0.041\n\n\nEs gilt also \\(Pr(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist demnach relativ gering ‚Äì wobei ‚Äúgering‚Äù subjektiv ist, die Betreiberfirma findet diese Wahrscheinlichkeit, dass 2 Pumpen ausfallen, wohl viel zu hoch. Die Wahrscheinlichkeit, dass \\(k=0 \\ldots 7\\) Motoren laufen, ist in Abbildung¬†5.5 dargestellt.\ndbinom() steht f√ºr die Wahrscheinlichkeitsdichte (im diskreten Fall, wie hier, Wahrscheinlichkeitsfunktion genannt) und binom f√ºr die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die Stichprobengr√∂√üe an (hier 7 Motoren).\nDamit gilt:\n\\(Pr(X\\ge 5) = Pr(X=5) + Pr(X=6) + Pr(X=7)\\)\nBerechnen wir zun√§chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen mit Hilfe der Binomialverteilung.\n\nCodep_5 &lt;- dbinom(x = 5, size = 7, prob = .95)\np_6 &lt;- dbinom(x = 6, size = 7, prob = .95)\np_7 &lt;- dbinom(x = 7, size = 7, prob = .95)\n\np_5\n## [1] 0.041\np_6\n## [1] 0.26\np_7\n## [1] 0.7\n\n\nDas sind 0.04, 0.26, 0.7. Die gesuchte Wahrscheinlichkeit, p_mind_5, ist die Summe der drei Einzelwahrscheinlichkeiten.\n\nCodep_mind_5 &lt;- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 1\n\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betr√§gt also 1.\nDas komplement√§re Ereignis zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also h√∂chstens 4 und es daher zu einem Ausfall kommt. Es gilt also \\(Pr(\\bar{X}) = 1- Pr(X)\\).\n\nCodep_weniger_als_4 &lt;- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.0038\n\n\nDas sind also 0 also0.38 % Wahrscheinlichkeit, dass die Pumpstation ausf√§llt.\n\n\n\n\n\n\n\nAbbildung¬†5.5: Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen\n\n\n\n\nAlternativ kann man mit der Verteilungsfunktion pbinom() rechnen, die \\(Pr(X \\le 4)\\) berechnet.\nIn R kann man die Funktion pbinom() nutzen (p f√ºr (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen.\n\nCodepbinom(q = 4, size = 7, prob = .95)\n## [1] 0.0038\n\n\nq = 4 steht f√ºr \\(X \\le 4\\), also f√ºr h√∂chstens 4 Treffer (arbeitende Motoren); size = 7 meint die Stichprobengr√∂√üe, hier 7 Motoren; prob gibt die Trefferwahrscheinlichkeit an. \\(\\square\\)\n\n√úbungsaufgabe 5.3 (Peer-Instruction: Qualit√§tskontrolle in einer Fabrik) Eine Fabrik produziert USB-Sticks. Die Wahrscheinlichkeit, dass ein USB-Stick defekt ist, betr√§gt 2%. Aus der laufenden Produktion werden regelm√§√üig 10 USB-Sticks zuf√§llig ausgew√§hlt und getestet. Sei \\(X\\) die Anzahl defekter USB-Sticks in dieser Stichprobe.\nWelche Aussage ist richtig bzw. passt am besten?\n\nMit 98% sind alle 10 USB-Sticks in Ordnung.\nMit 82% sind alle 10 USB-Sticks in Ordnung.\nMit 2% sind alle 10 USB-Sticks defekt.\nEs ist unm√∂glich, dass alle 10 USB-Sticks defekt sind.\nEs ist unm√∂glihc, dass alle 10 USB-Sticks in Ordnung sind. \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#die-halbe-normalverteilung",
    "href": "0400-Verteilungen.html#die-halbe-normalverteilung",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.5 Die halbe Normalverteilung",
    "text": "5.5 Die halbe Normalverteilung\nGrundlagen √ºber die Normalverteilung k√∂nnen in Sauer (2025) nachgelesen werden.\nEin Spezialfall der Normalverteilung ist die halbe (oder halbseitige) Normalverteilung, s. Abbildung¬†5.6.\n\nCodedf &lt;- data.frame(x = seq(-4, 4, length.out = 500))\ndf$y &lt;- dnorm(df$x)\n\n# Separate shading regions\ndf_left  &lt;- subset(df, x &lt;= 0) \ndf_right &lt;- subset(df, x &gt;= 0)\n\nggplot(df, aes(x, y)) +\n  geom_area(data = df_left, aes(x, y), fill = \"grey90\") +\n  geom_area(data = df_right, aes(x, y), fill = \"grey80\") +\n  #geom_line(size = 1) +\n  theme_minimal() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.text.y  = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line.y  = element_blank()\n  ) +\n  scale_x_continuous(limits = c(0, 4))\n\n\n\n\n\n\nAbbildung¬†5.6: Die halbe Normalverteilung\n\n\n\n\n\nDefinition 5.3 (Halbe Normalverteilung) Wenn man die (negativen) Vorzeichen bei den Werten der Normalverteilung ignoriert, erh√§lt man die halbe Normalverteilung. Man ‚Äúspiegelt‚Äù die negative Seite auf die positive. \\(\\square\\)\n\nMan kann sie verwenden, wenn man von normalverteilten Werten ausgeht, die gr√∂√üer als Null sein m√ºssen. Sie hat zwei Parameter, Mittelwert und SD, analog zur Normalverteilung.\n\nBeispiel 5.10 (Halbe Normalverteilungen) ¬†\n\nDie Entfernung Ihres Dart-Pfeiles zur Mitte der Zielscheibe\nDie Entfernung des vom Baum gefallenen Apfels zum Stamm\nDie Abweichung des Gewichts eines Produktionsgegenstands (z.B. einer Schraube) vom Soll-Gewicht\nDie Reaktionszeiten einer Versuchsperson in einer Reaktionszeitaufgabe \\(\\square\\)",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#die-exponentialverteilung",
    "href": "0400-Verteilungen.html#die-exponentialverteilung",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.6 Die Exponentialverteilung",
    "text": "5.6 Die Exponentialverteilung\n\n5.6.1 Die Apfel-f√§llt-nicht-weit-vom-Stamm-Verteilung\n\n\n\nAnstelle der halben Normalverteilung man auch die Exponentialverteilung verwenden. Die beiden Verteilungen haben einen √§hnlichen Verlauf, nur dass bei Exponentialverteilung Extremwerte wahrscheinlicher sind. Das kann vorteilhaft sein, wenn man ein Ph√§nomen darstellen will, dessen Skalierung man nicht genau kennt. Die Normalverteilung setzt dem Streuung der Werte deutlich engere Grenzen als die Exponentialverteilung. Abbildung¬†5.7 stellt die beiden Verteilungen nebeneinander.\n\n\n\n\n\n\n\nAbbildung¬†5.7: Exponentialverteilung (blau, Rate = 1) vs.¬†halbe Normalverteilung (sd = 1)\n\n\n\n\nF√ºr eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung. Sie hat einige n√ºtzliche Eigenschaften:\n\nEine Exponentialverteilung ist nur f√ºr positive Werte, \\(x&gt;0\\), definiert.\nSteigt X um eine Einheit, so √§ndert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (‚Äúlambda‚Äù).\n\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (‚ÄúGestrecktheit‚Äù) der Verteilung an.\nJe gr√∂√üer die Rate \\(\\lambda\\), desto schneller der ‚ÄúVerfall‚Äù der Kurve und desto kleiner die Streuung und der Mittelwert der Verteilung (und umgekehrt: Je gr√∂√üer \\(1/\\lambda\\), desto gr√∂√üer die Streuung und der Mittelwert der Verteilung.)\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren Pl√§nen passt.\n\n5.6.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zur√ºckzuf√ºhren, s. Abbildung¬†5.8.\n\n\n\n\nlambda = 2\nlambda = 1\nlambda = 1/2\nlambda = 1/4\nlambda = 1/8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†5.8\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEine ‚Äúgut passende‚Äù oder gar die ‚Äúrichtige‚Äù Verteilung zu finden, ist nicht immer einfach, wenn nicht unm√∂glich. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu w√§hlen, die einen breiteren Raum an m√∂glichen Werten zul√§sst. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie etwa mehrere Kilometer K√∂rpergr√∂√üe, besser verbieten.\n\n\nMan kann sich den Median und andere Quantile der Exponentialverteilung mit qexp ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, f√ºr den man das Quantil haben m√∂chte, z.B. p = .5 f√ºr den Mediaan (mit pexp() kann man sich analog die die Verteilungsfunktion ausgeben lassen.) Mit rate wird \\(\\lambda\\) (lambda) bezeichnet.7\nDieser Aufruf zum Beispiel, qexp(p = .5, rate = 1/8), gibt uns das 50%-Quantil einer Exponentialverteilung mit Rate (\\(\\lambda\\)) 1/8 zur√ºck, ca. 5.5: Mit einer Wahrscheinlichkeit von 50% wird ein Wert von 5.5 nicht √ºberschritten bei dieser Verteilung.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich auch ausgeben.\n\nCodeqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2 29.5\n\n\nTabelle ?tbl-exp zeigt die Mediane einiger Exponentialverteilungen, d.h. Exponentialverteilungen mit verschiedenen Werten f√ºr \\(\\lambda\\).\n\nDie Median-Werte von Exponentialverteilungen mit verschiedenen Werten f√ºr \\(\\lambda\\).\n\nŒª\nMedian\n\n\n\n100\n0.01\n\n\n50\n0.01\n\n\n8\n0.09\n\n\n4\n0.17\n\n\n2\n0.35\n\n\n1\n0.69\n\n\n1/2\n1.39\n\n\n1/4\n2.77\n\n\n1/8\n5.55\n\n\n1/50\n34.66\n\n\n1/100\n69.31",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#vertiefung",
    "href": "0400-Verteilungen.html#vertiefung",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.7 Vertiefung",
    "text": "5.7 Vertiefung\nBourier (2011), Kap. 6.2 und 7.1 erl√§utert einige (grundlegende) theoretische Hintergr√ºnde zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar f√ºr den Stoff dieses Kapitels ist dabei die Binomialverteilung.\nMittag & Sch√ºller (2020) stellen in Kap. 12 und 13 Zufallsvariablen vor; zum Teil geht die Darstellung dort √ºber die Lernziele bzw. Inhalte dieses Kurses hinaus.",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#aufgaben",
    "href": "0400-Verteilungen.html#aufgaben",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\nZus√§tzlich zu den Aufgaben in der genannten Literatur sind folgende Aufgaben zu empfehlen.\n\n5.8.1 Paper-Pencil-Aufgaben\n\nalphafehler-inflation3\nalphafehler-inflation4\niq1a\niq2a\niq3a\nsimu-uniform\nsimu-unif2\nsimu-unif3\nQuiz zum Thema Verteilungen\nBsp-Binomial\ndistros\nbfi10\nwskt-quiz10\nSchiefe1\nexp-tab\nexp1\nsmall-wide-normal\nlikelihood-nv\nschmalstepost\n\n5.8.2 Aufgaben, f√ºr die man einen Computer braucht\n\nalphafehler-inflation2\nQuiz (Aufgabensammlung) zu Verteilungen\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\niq01\niq02\niq03\niq04\niq05\niq06\niq07\n\niq08  \n\nBus1",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#section",
    "href": "0400-Verteilungen.html#section",
    "title": "\n5¬† Verteilungen\n",
    "section": "\n5.9 ‚Äî",
    "text": "5.9 ‚Äî\n\n\n\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende Statistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen (7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√úbungen: Beschreibende Statistik ‚Äì Wahrscheinlichkeitsrechnung ‚Äì Schlie√üende Statistik (7. Auflage). Springer Gabler.\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nSauer, S. (2025). Statistik1. Independently published via Amazon. https://www.amazon.de/Statistik1-Einf%C3%BChrung-Statistik-Schwerpunkt-Prognose-Modellierung/dp/B0F673WGG5",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#footnotes",
    "href": "0400-Verteilungen.html#footnotes",
    "title": "\n5¬† Verteilungen\n",
    "section": "",
    "text": "von lat. bis ‚Äúzweimal‚Äù‚Ü©Ô∏é\nIn den Lehrb√ºchern h√§ufig als Urne bezeichnet, was den b√∂sen Spott von ‚ÄúFriedhofstatistik‚Äù nach sich zog.‚Ü©Ô∏é\npraktisch unendlich vielen‚Ü©Ô∏é\nwobei gelten muss \\(n \\ge k\\)‚Ü©Ô∏é\nHey, endlich mal was f√ºr echte Leben!‚Ü©Ô∏é\nBei Taschenrechnern ist diese Funktion oft als ‚ÄúnCr‚Äù zu finden.‚Ü©Ô∏é\nEs gibt auch [Online-Apps, die diese Werte ausgeben](https://homepage.divms.uiowa.edu/~mbognar/applets/exp-like.html.‚Ü©Ô∏é",
    "crumbs": [
      "Grundlagen",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html",
    "href": "0500-Globusversuch.html",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "",
    "text": "6.1 Lernsteuerung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#lernsteuerung",
    "href": "0500-Globusversuch.html#lernsteuerung",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "",
    "text": "6.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n6.1.2 √úberblick\nIn diesem Kapitel √ºbersetzen wir eine Problemstellung (Forschungsfrage) in ein (mathematisches) Modell, das uns dann mit Hilfe der Bayes-Formel Antworten auf die Problemstellung gibt.\n\n6.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nUnterschiede zwischen Modellen und der Realit√§t erl√§utern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (f√ºr binomial verteilte Zufallsvariablen)\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\ndas Bayes-Modell anhand bekannter Formeln herleiten\nPost-Wahrscheinlichkeiten anhand der Bayesbox berechnen\n\n6.1.4 Begleitliteratur\nDer Stoff dieses Kapitels deckt einen Teil aus McElreath (2020), Kap. 2, ab. McElreath (2020) stellt das Globusmodell mit mehr Erl√§uterung und etwas mehr theoretischem Hintergrund vor, als es in diesem Kapitel der Fall ist.\n\n6.1.5 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. ‚ÄúDaten Einlesen‚Äù\n\n6.1.6 Begleitvideos\n\nüì∫ Globusversuch\n\n\n6.1.7 Ben√∂tigte R-Pakete\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)  # komfortable Visualisierung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#von-welten-und-golems",
    "href": "0500-Globusversuch.html#von-welten-und-golems",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.2 Von Welten und Golems",
    "text": "6.2 Von Welten und Golems\n\n6.2.1 Kleine Welt, gro√üe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein gl√ºcklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb Abbildung¬†6.1.\n\n\n\n\n\nAbbildung¬†6.1: Behaims Globus: Kein Amerika\n\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der gro√üen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel f√ºr, sagen wir, die Komplexit√§t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Gl√ºck geh√∂rt halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die gro√üe Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der gro√üen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schl√ºssen und vermeintlicher Gewissheit.\n\nüèã Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht! \\(\\square\\)\n\n\n6.2.2 Der Golem von Prag\n\n\n\n\n\nAbbildung¬†6.2: Der Golem von Prag\n\n\nBildquelle: Mikol√°≈° Ale≈°, Wikimedia, Gemeinfrei\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle w√∂rtlich ausf√ºhrt, s. Abbildung¬†6.2. Die Geschichte besagt, dass ein Rabbi mit Zauberkr√§ften den Golem aus Lehm erschuf, um die j√ºdische Bev√∂lkerung der Stadt zu sch√§tzen. Bei kluger F√ºhrung kann ein Golem N√ºtzliches vollbringen. Bei un√ºberlegter Verwendung wird er jedoch gro√üen Schaden anrichten.\n\n6.2.3 Wissenschaftliche Modelle sind wie Golems\n\n\n‚ÄúYeah, ich bin ein Golem!‚Äù - Bildquelle: Klara Schaumann\n\n\n\nGolem\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch ‚ÄúWahrheit‚Äù\nM√§chtig\ndumm\nF√ºhrt Befehle w√∂rtlich aus\nMissbrauch leicht m√∂glich\nM√§rchen\n\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal m√§chtig\nsimpler als die Realit√§t\nF√ºhrt Befehle w√∂rtlich aus\nMissbrauch leicht m√∂glich\nNicht einmal falsch\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildung¬†2.7 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen (Tabelle¬†6.1), wie z.B. Behaims Globus, mit der Gro√üen Welt, die Kolumbus und wir befahren.\n\n\nTabelle¬†6.1: Kleine Welt vs.¬†gro√üe Welt\n\n\n\n\n\n\n\nKleine Welt\nGro√üe Welt\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangsl√§ufig) die Wirklichkeit\nentspricht nicht (zwangsl√§ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n6.2.4 Die Bayes-Formel und Lernen\nüèã Bayes-Inferenz √§hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess √§hnelt!\\(\\square\\)\n\nBeispiel 6.1 (Ein Regressionsmodell ist aus der kleinen Welt) Ein wissenschaftliches Modell, etwa auf Basis eines Regressionsmodell ist Teil der kleinen Welt. Man muss sich bei der Interpretation eines Regressionsmodell vor Augen halten: ‚ÄúDie Ergebnisse des Modell sind nur richtig unter der Annahme, dass sich der Zusammenhang X und Y durch eine Gerade beschreiben lasssen und unter der Annahme, dass meine Daten in Ordnung sind.‚Äù \\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "6.3 Ein erster Versuch: Wir werfen den Globus\n\n6.3.1 Welcher Anteil der Erdoberfl√§che ist mit Wasser bedeckt?\n\nBeispiel 6.2 (Wasseranteil auf der Erdoberfl√§che) Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (Abbildung¬†6.3)? Um m√∂glichst wenig schreiben zu m√ºssen, schreiben wir f√ºr ‚Äúangenommener Wasseranteil auf der Erdoberfl√§che‚Äù kurz \\(p\\) oder \\(\\pi\\) (p wie proportion, Anteil). \\(\\square\\)\n\n\n\n\n\n\nAbbildung¬†6.3: Die Erde. Sch√∂n! Und mit viel Wasser, ca. 70% der Erdoberfl√§che sind mit Wasser bedeckt. Quelle, Lizenz: CC 4.0 BY-NC\n\n\nAnalog k√∂nnen wir uns vorstellen, 11 Wissenschaftler haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus ‚Ä¶ die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.2\nSo sah mein3 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nAlso \\(W=6\\) (Wasser, d.h. ‚ÄúTreffer‚Äù) und \\(L=3\\) (Land) (\\(n=9\\) Versuche).\n\n√úbungsaufgabe 6.1 (Spin the Globe) üèãÔ∏èÔ∏è Besorgen Sie sich einen Globus (zur Not eine M√ºnze) und stellen Sie den Versuch nach!\\(\\square\\)\n\n\n6.3.2 Bayes-Updates\nDer Bayes-Golem denkt eigentlich ganz vern√ºnftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugeh√∂rige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung (s. Definition¬†6.1). In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als n√§chstes beschaut sich der Golem die Daten und √ºberlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 50% betr√§gt. Die zugeh√∂rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die4 Likelihood5, s. Definition¬†6.2. Als letztes bildet sich der Golem eine abschlie√üende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung, s. Definition¬†6.3. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder ‚Äúgeupdatet‚Äù, s. Abbildung¬†6.4.\n\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]--&gt;B[Likelihood]--&gt;C[Post-Vert.]--&gt;A\n\n\n\n\nAbbildung¬†6.4: Updating mit Bayes\n\n\n\n\n\nDefinition 6.1 (Priori-Verteilung) F√ºr jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilit√§t der Hypothese angibt: Priori-Verteilung (synonym: Apriori-Verteilung).\\(\\square\\)\n\n\nDefinition 6.2 (Likelihood) F√ºr jede Hypothese (d.h. jeden Parameterwert \\(\\pi\\)) m√∂chten wir wissen, wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Kurz: Wir suchen die Likelihood. Anders gesagt: Die Likelihood sagt uns, wie gut die Daten zu einer bestimmten Hypothese passen.\\(\\square\\)\n\n\nDefinition 6.3 (Posteriori-Verteilung) Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung6 bekommen.\\(\\square\\)\n\n\n√úbungsaufgabe 6.2 (Wie gut passen die Daten zur Hypothese, dass die Erde komplett trocken ist?) Wir haben in unseren Versuch \\(W=6\\) und \\(L=3\\) erzielt. Diese Daten passen √ºberhaupt nicht zur Hypothese, dass die Erdoberfl√§che komplett trocken ist. Die Likelihood, \\(L\\) f√ºr \\(\\pi=0\\) ist also Null. Analog ist die Likelihood f√ºr \\(\\pi=1\\) auch Null.\\(\\square\\)\n\n\n6.3.3 Was ist die Wahrscheinlichkeit von 6 mal Wasser bei 9 W√ºrfen?\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer (bei 9 W√ºrfen) zu erhalten, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 90%) annimmt? Diese Wahrscheinlichkeit nennt man die Likelihood, \\(L\\).\n\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabh√§ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich √§ndert 7. Der Wasseranteil der Erde bleibt w√§hrend des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit f√ºr Wasser \\(\\pi\\) betr√§gt, so bezeichnen: \\(Pr(W|\\pi, n)\\). Diese Wahrscheinlichkeit kann man im Fall des Globusversuchs mit der Binomialverteilung berechnen.\nM√∂chte man die Wahrscheinlichkeit ansprechen f√ºr das Ereignis ‚Äú6 mal Wasser und 3 mal Land, wenn wir von einem Wasseranteil von 70% ausgehen‚Äù, so w√ºrden wir kurz schreiben: \\(Pr(W=6 | \\pi=.7, n=9)\\).\nZur Erinnerung: Die Binomialverteilung zeigt die Verteilung der Wahrscheinlichkeit der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten M√ºnzwurf (und allen vergleichbaren Zufallsexperimenten): ‚ÄúM√ºnzwurfverteilung‚Äù, s. Kap. Kapitel 5.4.\n\n6.3.4 Likelihood berechnen\nWas ist der Anteil der g√ºltigen Pfade in einem Baumdiagramm (d.h. die Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(n=W+L=3\\) W√ºrfen zu bekommen, wenn wir von \\(\\pi=1/2\\) ausgehen? 8, s. Listing¬†6.1, Abbildung¬†6.5 und Gleichung¬†6.1.\n\n\n\nListing¬†6.1: Binomialverteilung mit R f√ºr x=2, n=3, p=1/2\n\nCodeloesung &lt;- dbinom(x = 2, size = 3, prob = 1/2)\nloesung\n## [1] 0.38\n\n\n\n\n\nOder von Hand gerechnet:\n\\[\\begin{aligned}\nPr(W=2 | \\pi=1/2, n=3) &=\\\\\n\\tbinom{3}{2} \\cdot (1/2)^2 \\cdot (1/2)^1 &=\\\\\n\\frac{3!}{2!1!} \\cdot (1/2)^3 &= \\\\\n3 \\cdot 1/8 = 3/8 &= 0.375\n\\end{aligned} \\tag{6.1}\\]\nWenn man sich den entsprechenden Baum anschaut (s. Abbildung¬†6.5): Von den 8 Endkonten bzw. Pfaden sind 3 g√ºnstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 W√ºrfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-&gt; B[B - 0]\n  A -. 1/2 .-&gt; C[C - 1]\n  B -. 1/2 .-&gt; D[D - 0]\n  B -. 1/2 .-&gt; E[E - 1]\n  C -. 1/2 .-&gt; F[F - 0]\n  C -. 1/2 .-&gt; G[G - 1]\n  D -. 1/2 .-&gt; H[H - 0]\n  D -. 1/2 .-&gt; J[I - 1]\n  E -. 1/2 .-&gt; K[K - 0]\n  E -. 1/2 .-&gt; L[L - 1]\n  F -. 1/2 .-&gt; M[M - 0]\n  F -. 1/2 .-&gt; N[N - 1]\n  G -. 1/2 .-&gt; O[O - 0]\n  G -. 1/2 .-&gt; P[P - 1]\n\n\n\n\nAbbildung¬†6.5: Wir werfen den Globus (oder eine M√ºnze) 3 Mal. Die Knoten sind der √úbersicht halber mit fortlaufenden Buchstaben (von A bis P) bezeichnet. Das Ergebnis ‚ÄòWasser‚Äô ist 1 und das Ergebnis ‚ÄòLand‚Äô mit 0 abgek√ºrzt dargestellt.\n\n\n\n\nAbb. Abbildung¬†6.5 stellt einen einfachen Baum f√ºr 3 Globusw√ºrfe mit je zwei m√∂glichen Ereignissen (W vs.¬†L) dar. In der ersten (obersten) Zeile (Knoten A; ‚ÄúStart‚Äù) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) m√∂gliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nF√ºr mehr W√ºrfe w√ºrde das Diagramm irgendwann un√ºbersichtlich werden.\nAbbildung¬†6.6 zeigt die Binomialverteilung \\(X \\sim Bin(n=9, \\pi = 1/2)\\): Die jeweilige Wahrscheinlichkeit f√ºr \\(k=0,1,\\ldots, 9\\) Treffer bei \\(n=9\\) Versuchen mit Trefferwahrscheinlichkeit \\(\\pi=1/2\\).\n\n\n\n\n\n\n\nAbbildung¬†6.6: Ein Beispiel f√ºr eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\n\n\n\nAbb Abbildung¬†6.7 ist ein vergeblicher Versuch, so einen gro√üen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum Verst√§ndnis, kommen aber bei gr√∂√üeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\n\n\n\nAbbildung¬†6.7: Wir werfen den Globus (oder eine M√ºnze) 9 Mal, es resultieren 512 Endknoten. Nicht gerade √ºbersichtlich.\n\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 6.3 (Globus mit 6 Treffern bei 9 W√ºrfen, p=1/2) Was ist der Anteil der g√ºltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) W√ºrfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\nCodedbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.16\n\n\nOder, synonym, wenn man einen Taschenrechner (oder R als Taschenrechner) benutzt:\n\nCodechoose(9, 6) * (1/2)^6 * (1/2)^3\n## [1] 0.16\n\n\n\\(\\square\\)\n\n\nBeispiel 6.4 (Globus mit 9 Treffern bei 9 W√ºrfen, p=1/2) Was ist die Wahrscheinlichkeit, gegeben \\(W=9\\) bei \\(n=9\\) und \\(\\pi=1/2\\)?\n\nCodedbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.002\n\n\nDas ist 1 g√ºnstiger Pfad von 512 Pfaden, also \\(Pr(W=9|\\pi=1/2, n=9)=1/512\\).\n\n\nBeispiel 6.5 (Globus mit 6 Treffern bei 9 W√ºrfen, p=70%) Was ist die Wahrscheinlichkeit f√ºr \\(W=6\\), gegeben \\(n=9\\) und \\(p=.7\\)?\n\nCodedbinom(x = 6, size = 9, prob = .7)\n## [1] 0.27\n\n\nMit Taschenrechner gerechnet:\n\nCodeanz_pfade &lt;- choose(9,6) \nwskt_pro_pfad &lt;- (.7)^6 * (.3)^3\ngesamt_wkst &lt;- anz_pfade * wskt_pro_pfad\ngesamt_wkst\n## [1] 0.27\n\n\n(Fast) von Hand gerechnet, mit R als Taschenrechner:\n\nCodefactorial(9)/(factorial(6)*factorial(3)) * (.7)^6 * (.3)^3\n## [1] 0.27\n\n\nAls Formel, s. Gleichung¬†6.2:\n\\[\\begin{aligned}\nPr(W=6 | \\pi=.7, n=9) &=\\\\\n\\tbinom{9}{6} \\cdot (.7)^6 \\cdot (.3)^3 &=\\\\\n\\frac{9!}{6!3!} \\cdot (.7)^6 \\cdot (.3)^3 &=\\\\\n84 \\cdot  .003 = .27.\n\\end{aligned} \\tag{6.2}\\]\n\\(\\square\\)\n\nZur Erinnerung: Die Funktion dbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zur√ºck, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\nEs gibt Taschenrechner(-Apps), die die Binomialverteilung oder den Binomialkoeffizienten berechnen k√∂nnen.9\n\n√úbungsaufgabe 6.3 (Peer Instruction: Welche Anzahl von Wasser ist am plausibelsten?) Wir f√ºhren wieder den Globusversuch durch (\\(\\pi=.7\\)), mit 9 W√ºrfen. Welches Ergebnis ist am plausibelsten?\n\n0 Wasser\n1 Wasser\n3 Wasser\n6 Wasser\n9 Wasser \\(\\square\\)\n\n\n\n\n6.3.5 Unser Modell ist geboren\nEin Modell (in der Bayes-Statistik) besteht aus mind. drei Komponenten:\n\nDie Likelihood (die Wahrscheinlichkeit der Daten unter Annahme der Hypothese), s. Gleichung¬†6.3\n\nDie Priori-Verteilung(en) (die Wahrscheinlichkeit der Hypothese vor den Daten), a. Gleichung¬†6.4\n\nDie Posteriori-Verteilung (die Wahrscheinlichkeit der Hypothese nach den Daten), s. Abbildung¬†6.11\n\n\n6.3.6 Likelihood\nIm Globusversuch verwenden wir die Binomialverteilung zur Berechnung der Likelihood, s. Gleichung¬†6.3.\n\\[W \\sim \\text{Bin}(n,\\pi) \\tag{6.3}\\]\nLies: ‚ÄúW ist binomial verteilt mit den Parametern \\(n\\) und \\(\\pi\\)‚Äù. \\(n\\) gibt die Anzahl der Globusw√ºrfe an: \\(n=W+L\\).\nMit einem konkretes Beispiel: \\(W \\sim \\text{Bin}(9, 0.7)\\) bedeutet, dass wir von 9 W√ºrfen ausgehen und eine Wahrscheinlichkeit f√ºr Wasser von 70% annehmen.\nDie Verwendung der Binomialvertielung ist an einige Annahmen gekn√ºpft:\n\nDie Z√ºge sind unabh√§ngig voneinander (Die W√ºrfe des Globusballs beeinflussen sich einander nicht).\nDer Parameterwert \\(\\pi\\) bleibt konstant (Der Wasseranteil der Erde √§ndert sich nicht w√§hrend des Versuchs).\n\n\n√úbungsaufgabe 6.4 üèã Welche Annahmen w√ºrden Sie √§ndern? Welche k√∂nnte man wegnehmen? Welche hinzuf√ºgen? Was w√§ren die Konsequenzen?\\(\\square\\)\n\n\n6.3.7 Priori-Verteilung\nUnser Vorab- bzw. Apriori-Wissen zu \\(p\\) sei, dass uns alle Werte gleich (‚Äúuniform‚Äù) plausibel erscheinen, s. Gleichung¬†6.4.\n\\[\\pi \\sim \\text{Unif}(0,1). \\tag{6.4}\\]\nLies: ‚Äú\\(\\pi\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1‚Äù.\nMan k√∂nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (apriori) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich, s. Abbildung¬†6.8.\n\n\n\n\n\n\n\nAbbildung¬†6.8: Gleichverteilung mit Parametern min=0 und max=1\n\n\n\n\n\n6.3.8 Posteriori-Verteilung\ndie Posteriori-Verteilung quantifiziert unser Wissen nach Kenntnis der Daten, aufbauend auf unserem Vorwissen (Priori-Wissen). Die Posteriori-Verteilung ist das Ergebnis des Bayes-Updates.\nDie Wahrscheinlichkeit bestimmter Hypothesen nennt man Posteriori-Wahrscheinlichkeit und bezeichnet sie kurz mit \\(Pr(H|D)\\). Lies: ‚ÄúDie Wahrscheinlichkeit der Hypothese H gegeben der Daten D‚Äù. Dabei nimmt man stillschweigend an, dass die Daten anhand eines gewissen Modells generiert wurden.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-theorem",
    "href": "0500-Globusversuch.html#bayes-theorem",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.4 Bayes‚Äô Theorem",
    "text": "6.4 Bayes‚Äô Theorem\n\n6.4.1 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes h√§ufig, wenn man Daten \\(D\\) gesammelt hat, und wissen m√∂chte, wie wahrscheinlich eine Hypothese \\(H\\) ist, im Lichte dieser gesammelten Daten, s. Theorem¬†6.1. Anders gesagt: Die Likelihood ist relativ einfach zu bestimmen, \\(Pr(D|H)\\), aber nicht so interessant. Die Posteriori-Wahrscheinlichkeit, \\(Pr(H|D)\\), ist schwerer zu bestimmen, aber interessanter. Man k√∂nnte also sinnbildlich sagen, das Bayes-Theorem ist eine ‚ÄúMaschine‚Äù, die die Priori-Wahrscheinlichkeit zusammen mit der Likelihood zur Posteriori-Wahrscheinlichkeit ‚Äúumbaut‚Äù.\n\n\nTheorem 6.1 (Bayes‚Äô Theorem) \\[Pr(H|D) = \\frac{ Pr(H) \\cdot Pr(D|H) }{Pr(D)}\\quad \\square\\]\n\nBayes‚Äô Theorem (Theorem¬†6.1) fragt nach \\(Pr(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (Theorem¬†6.1):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der Plausibilit√§t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgr√ºnden dividiert man noch die totale Wahrscheinlichkeit der Daten √ºber alle Hypothesen.\n\nF√ºr unser Globusbeispiel:\n\nWie wahrscheinlich ist denn jetzt ein bestimmter Wasseranteil auf der Erde, \\(\\pi\\), (gegeben den Daten, \\(W=6\\) und \\(L=3\\))? Also, wie wahrscheinlich ist z.B. ein Wasseranteil von 70% oder von 50%?\n\n\n6.4.2 Bayes als bedingte Wahrscheinlichkeit\nBayes‚Äô Theorem wird h√§ufig verwendet, um die Wahrscheinlichkeit einer Hypothese, gegeben einer bestimmten Datenlage, zu berechnen, also \\(Pr(H|D)\\). Also zeigt Bayes‚Äô Theorem nichts anderes als eine normale bedingte Wahrscheinlichkeit.\n\\(Pr(H| D)\\) kann man umformen (vgl. Theorem¬†4.3 und Definition¬†4.6), dann erh√§lt man Bayes‚Äô Theorem, s. Theorem¬†6.8.\n\nTheorem 6.2 (Bayes‚Äô Theorem 2) \\[\\begin{aligned}\nPr(H|D) &=\\frac{\\overbrace{ Pr(H\\cap D)}^\\text{umformen}}{Pr(D)} \\\\  &= \\frac{\\overbrace{Pr(H)}^\\text{Apriori-Wahrscheinlichkeit} \\cdot \\overbrace{Pr(D|H)}^\\text{Likelihood}}{\\underbrace{Pr(D)}_\\text{Evidenz}}\n\\end{aligned}\\quad \\square\\]\n\n\n6.4.3 Die Evidenz zur Standardisierung\nDie Aufgabe der Evidenz ist nur daf√ºr zu sorgen, dass der Wert von \\(Pr(H|D)\\) insgesamt nur Werte zwischen 0 und 1 annehmen kann, also eine brave, normale Wahrscheinlichkeit ist. W√ºrde man in Theorem¬†6.8 nicht durch die Evidenz teilen, so w√§re die Posteriori-Wahrscheinlichkeit nicht normiert, d.h. sie k√∂nnte Werte &gt;1 annehmen.\n\nDefinition 6.4 (Evidenz) \\(Pr(D)\\) nennt man die Evidenz. Die Evidenz berechnet sich als Summe der Likelihoods f√ºr alle Parameterwerte \\(H_i\\), d.h. als die totale Wahrscheinlichkeit von \\(D\\), s. Theorem¬†6.3, vgl. auch Definition¬†4.8. \\(\\square\\)\n\n\nTheorem 6.3 (Evidenz) \\[\\begin{aligned}\nPr(D) = \\sum_{i=1}^n Pr(D|H_i) \\cdot Pr(H_i)\n\\end{aligned}\\quad \\square\\]\n\nDie verschiedenen Parameterwerte kann man auch als die verschiedenen Hypothesen \\(H_i\\) auffassen. Falls es nur zwei Hypothesen bzw. Parameterwerte gibt, vereinfacht sich Theorem¬†6.3 zu Theorem¬†6.4.\n\nTheorem 6.4 (Evidenz 2) \\[\\begin{aligned}\nPr(D) = Pr(D|H_1) \\cdot Pr(H_1) + Pr(D|H_2) \\cdot Pr(H_2)\n\\end{aligned}\\quad \\square\\]\n\n\nBeispiel 6.6 In Beispiel¬†6.8 betrug der Wert der Evidenz \\(0.03 + 0.002 + 0.012 = 0.044\\), also ca. 4%. \\(\\square\\)\n\n\n\n\n\n\n6.4.4 Bayes‚Äô Theorem als Formel\n\n\nSchauen wir uns die Bestandteile von Bayes‚Äô Theorem (Theorem¬†6.8) noch etwas n√§her an:\n\n(standardisierte) Posteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nApriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayes‚Äô Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) f√ºttert. Bayes‚Äô Theorem wird verwendet, um die \\(Pr_{Post}\\) zu quantifizieren. Die \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n6.4.5 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Posteriori-Wahrscheinlichkeit \\(Pr_{\\text{unPost}}\\) ist einfach das Produkt von Likelihood und Priori, s. Theorem¬†6.5.\n\nTheorem 6.5 (Unstandardisierte Posteriori-Wahrscheinlichkeit) \\[Pr_{\\text{unPost}} = L \\times \\text{Priori}\\quad \\square\\]\n\nAbb. Abbildung¬†6.9 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\n\n\n\nAbbildung¬†6.9: Prior mal Likelihood = Post\n\n\nStandardisiert man die unstandardisierte Post-Verteilung, so erh√§lt man die standardisierte Post-Verteilung. Das Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung Theorem¬†6.6.\n\nTheorem 6.6 (Standardisierte Posteriori-Verteilung) \\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\quad \\square\\]\n\n\n6.4.6 Wissen updaten: Wir f√ºttern Daten in das Modell\nGolems k√∂nnen lernen?! Abbildung¬†6.10 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. W√ºrfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich f√ºr den Golem (das Modell). Je nach Ergebnis des Wurfes ver√§ndert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung ver√§ndert sich in Abh√§ngigkeit von den Daten.\n\n\n\n\n\nAbbildung¬†6.10: Unser Golem lernt\n\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell n√ºtzlich ist (pr√§zise Vorhersagen liefert), steht auf einem anderen Blatt.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-berechnen-mit-mit-der-bayesbox",
    "href": "0500-Globusversuch.html#bayes-berechnen-mit-mit-der-bayesbox",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.5 Bayes berechnen mit mit der Bayesbox",
    "text": "6.5 Bayes berechnen mit mit der Bayesbox\nWir erstellen uns eine kleine Tabelle, die man ‚ÄúBayesbox‚Äù nennen k√∂nnte.10 Dazu gehen wir so vor:\n\n6.5.1 Die Idee der Bayesbox\n\nTeile den Wertebereich des Parameters in ein ‚ÄúGitter‚Äù auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\).\nW√§hle den Priori-Wert des Parameters f√ºr jeden Parameterwert, z.B. 1/11 bei einer Gleichverteilung von 0 bis 1.\nBerechne den Likelihood f√ºr jeden Parameterwert.\nBerechne den unstandardisierten Posteriori-Wert f√ºr jeden Parameterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nF√ºr jeden Parameterwert berechnen wir eine (Post-)Wahrscheinlichkeit.11 H√§ufig entspricht eine Hypothese einem Parameterwert, etwa wenn man sagt: ‚ÄúIch glaube, die M√ºnze ist fair‚Äù, was auf einen Parameterwert von 50% herausl√§uft. Dazu geben wir an, f√ºr wie wahrscheinlich wie apriori12 ‚Äì also bevor wir irgendwelche Daten erheben ‚Äì jeden einzelnen Parameterwert halten. Wir machen es uns hier einfach und halten jeden Parameterwert f√ºr gleich wahrscheinlich. Tats√§chlich ist der konkrete Wert hier egal, entscheidend ist das Verh√§ltnis der Apriori-Werte zueinander: Geben wir einigen Parameterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere f√ºr (apriori) doppelt so plausibel wie Letztere. Der Likelihood wird in diesem Beispiel mit der Binomialverteilung berechnet (da wir ein bin√§res Ereignis, \\(W\\) oder \\(L\\), haben). Der Likelihood gibt an, wie wahrscheinlich ein Parameterwert ist gegeben einem bestimmten apriori gew√§hlten Parameterwert. Die ‚ÄúEnd-Wahrscheinlichkeit‚Äù, die unstandardisierte Post-Wahrscheinlichkeit, die ‚Äúhinten rauskommt‚Äù ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet13. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen m√∂chten, teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die Anspr√ºche an eine Wahrscheinlichkeitsverteilung erf√ºllt (vgl. Kapitel 3.3.3).\n\n6.5.2 Bayesbox in R berechnen\nLegen wir uns ein Gitter mit Parameterwerten (\\(\\pi\\)) an, um deren Posteriori-Wahrscheinlichkeit zu berechnen. Konkret gesprochen: Wir listen jeden f√ºr uns interessanten Wasseranteil (\\(\\pi\\)) auf, also \\(\\pi=0, 0.1, 0.2, ..., 1\\). Diese Parameterwerte sind die Hypothesen, die wir testen wollen, s. Listing¬†6.2.\n\n\n\nListing¬†6.2: Parameterwerte (Gitter) f√ºr Wasseranteile: 0, 0.1, 0.2, ‚Ä¶, 1\n\nCodewasseranteile &lt;- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte\nwasseranteile\n##  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 W√ºrfen) gegeben jeweils eines Wasseranteils.\n\nCodeLikelihood &lt;- dbinom(6, size = 9, prob = wasseranteile)\nLikelihood\n##  [1] 0.0e+00 6.1e-05 2.8e-03 2.1e-02 7.4e-02 1.6e-01 2.5e-01 2.7e-01 1.8e-01\n## [10] 4.5e-02 0.0e+00\n\n\nSchlie√ülich packen wir das alles in eine Tabelle, die ‚ÄúBayesbox‚Äù, s. Tabelle¬†6.2 und Listing¬†6.3.\n\n\n\nListing¬†6.3: Wir basteln uns eine Bayesbox\n\nCoded &lt;-\n  tibble(\n    # definiere die Hypothesen (die Parameterwerte, p): \n    p = wasseranteile,\n    # Lege den Priori-Wert fest:\n    Priori  = 1/11) |&gt; \n    mutate(\n      # berechne Likelihood f√ºr jeden Wasseranteil (Parameterwert):\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\n\n\n\n\nDie Bayesbox (Tabelle¬†6.2) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\nTabelle¬†6.2: Die Bayesbox f√ºr den Globusversuch, k=6 Treffer, n=9 Versuche, Apriori-Wahrscheinlichkeit Pr(H)=9%, und Wasseranteile p von 0 bis 1\n\n\n\n\nid\np\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n1\n0.0\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n2\n0.1\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n3\n0.2\n0.091\n0.003\n0.000\n0.091\n0.003\n\n\n4\n0.3\n0.091\n0.021\n0.002\n0.091\n0.021\n\n\n5\n0.4\n0.091\n0.074\n0.007\n0.091\n0.074\n\n\n6\n0.5\n0.091\n0.164\n0.015\n0.091\n0.164\n\n\n7\n0.6\n0.091\n0.251\n0.023\n0.091\n0.251\n\n\n8\n0.7\n0.091\n0.267\n0.024\n0.091\n0.267\n\n\n9\n0.8\n0.091\n0.176\n0.016\n0.091\n0.176\n\n\n10\n0.9\n0.091\n0.045\n0.004\n0.091\n0.045\n\n\n11\n1.0\n0.091\n0.000\n0.000\n0.091\n0.000\n\n\n\n\n\n\n\n\nF√ºr jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood, s. Gleichung¬†6.5.\n\\[\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood} = Pr(H) \\cdot Pr(H|D) \\tag{6.5}\\]\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Bayesbox (also f√ºr jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten, s. Theorem¬†6.7.\n\nTheorem 6.7 (Posteriori-Verteilung 2) \\[\\text{Post} = \\frac{\\text{Post}_{\\text{unstand}}}{\\text{Evidenz}} = \\frac{Pr(H) \\cdot Pr(H|D)}{Pr(D)}\\quad \\square\\]\n\nDabei haben wir die Priori-Wahrscheinlichkeit f√ºr alle Parameterwerte als gleich angenommen, da wir keinerlei Vorwissen hatten, \\(Pr(H_i) = 1/11\\). Die Evidenz berechnet sich als Summe der unstandardisierten Post-Wahrscheinlichkeiten, \\(Pr(D) = 0.09\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWenn der Priori-Wert f√ºr jeden Parameterwert gleich ist, dann ist der Likelihood gleich der unstandardisierten Post-Wahrscheinlichkeit.\\(\\square\\)\n\n\n\nBeispiel 6.7 (Post-Wahrscheinlichkeit im Globusversuch f√ºr p=.7) In Beispiel¬†6.5 haben wir die Wahrscheinlichkeit f√ºr 6 Treffer bei 9 W√ºrfen gegeben einer Trefferwahrscheinlichkeit von \\(\\pi = .7\\) berechnet. Damit haben wir die Likelihood \\(L = Pr(D|H) =.25\\) berechnet.\nAuf dieser Basis k√∂nnen wir die Posteriori-Wahrscheinlichkeit \\(Pr_{Post}\\) berechnen, zun√§chst die unstandardisierte. Dazu haben wir die Priori-Wahrscheinlichkeit mit der Likelihood multipliziert, s. Gleichung¬†6.6:\n\\[\\text{Post}_{\\text{unstand}} = Pr(H) \\cdot Pr(D|H) = 0.09 \\cdot 0.25 = 0.025 \\tag{6.6}\\]\nJetzt standardisieren wir die unstandardisierte Post-Wahrscheinlichkeit, indem wir durch die Evidenz dividieren, s. Gleichung¬†6.7.\n\\[\\text{Post} = \\frac{\\text{Post}_{\\text{unstand}}}{\\text{Evidenz}} = \\frac{0.025}{0.1} =0.25 \\tag{6.7}\\]\nGleichung¬†6.8 fasst die Schritte der Berechnung zusammen.\n\\[\\begin{aligned}\nPr(H_{\\pi=0.7}|D) =\n\\frac{Pr(D|H) \\cdot Pr(H)}{Pr(D)} &= \\\\\n\\frac{\\text{Likelihood}  \\cdot \\text{Priori}}{\\text{Evidenz}} &= \\\\\n\\frac{0.25 \\cdot 0.1}{0.1} &= 0.25\n\\end{aligned} \\tag{6.8}\\] \\(\\square\\)\nFazit: Nach dem Versuch, d.h. nachdem wir die Daten in Betracht gezogen haben, hat sich unsere Meinung √ºber den Wasseranteil geupdatet von 0.1 auf 0.25.\\(\\square\\)\n\n\n√úbungsaufgabe 6.5 üèãÔ∏è Was wohl mit Post passiert, wenn wir Priori √§ndern?\\(\\square\\)\n\nAbbildung¬†6.11 zeigt eine Visualisierung der Post-Verteilung mit Hilfe der Funktion ggline(x, y) aus dem Paket ggpubr. Wie man sieht, ist die Post-Wahrscheinlichkeit am h√∂chsten bei \\(\\pi=0.7\\). Wobei der Bereich von 0.6 bis 0.8 auch recht wahrscheinlich ist.\n\n\n\n\n\n\n\nAbbildung¬†6.11: Die Post-Verteilung visualisiert. Die Post-Wahrscheinlichkeit ist am h√∂chsten bei p=0.7\n\n\n\n\n\n6.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: ‚ÄúPost-Verteilung‚Äù, oder ‚ÄúPost‚Äù), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten, jetzt, nachdem wir die Daten des Versuchs kennen. Die Post-Wahrscheinlichkeit updatet unser Apriori-Wissen mit dem Wissen, das wir durch die Daten erhalten haben.\nAbbildung¬†6.12 zeigt die Post-Wahrscheinlichkeit f√ºr 5, 10 und 20 Parameterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben. Man sieht: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\nAbbildung¬†6.12: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen Umst√§nden gilt:\n\nMehr Gitterwerte gl√§tten die Ann√§herung.\nJe gr√∂√üer die Stichprobe (\\(N\\)), desto zuverl√§ssiger wird unsere Berechnung. \\(\\square\\)\n\n\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer Tr√§ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung k√∂nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des n√§chsten Kapitels. \\(\\square\\)\n\n\n√úbungsaufgabe 6.6 (Peer Instruction: Schl√ºsse ziehen mit dem Bayes-Modell) Auf einer Party: Unterhalten sich f√ºnf Studis √ºber das Bayesmodell. Einer hat Unrecht, die anderen Recht.\n\nWenn eine Hypothese \\(A\\) apriori doppelt so wahrscheinlich ist wie die anderen und die Likelihoods f√ºr alle Hypothesen gleich ist, dann ist \\(A\\) aposteriori auch doppelt so wahrscheinlich wie die anderen Hypothesen.\nSind alle Hypothesen apriori gleich wahrscheinlich, dann hat die Hypothese mit dem h√∂chsten Likelihood aposteriori auch die h√∂chste Wahrscheinlichkeit.\nHat eine Hypothese apriori die Wahrscheinlichkeit Null, so hat sie automatisch aposteriori auch die Wahrscheinlichkeit Null, unabh√§ngig von ihrer Likelihood.\nDie unstandardisierte Posteriori-Wahrscheinlichkeit ist gleich der standardisierten mal einen Faktor \\(k\\).\nHat eine Hypothese die h√∂chste Likelihood, so hat sie automatisch auch die h√∂chste Wahrscheinlichkeit aposteriori. \\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#abschluss",
    "href": "0500-Globusversuch.html#abschluss",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.6 Abschluss",
    "text": "6.6 Abschluss\n\n6.6.1 Zusammenfassung\nüì∫ √úbung zum Globusversuch\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der gro√üen Welt n√ºtzlich ist, steht auf einem anderen Blatt.\n\n\n√úbungsaufgabe 6.7 üèãÔ∏è Wenn Sie auf einen Prozentwert f√ºr \\(W\\) tippen m√ºssten, welchen w√ºrden Sie nehmen, laut dem Modell (und gegeben der Daten)? \\(\\square\\)\n\n\n6.6.2 Der Globusversuch als Modell f√ºr zweiwertige Zufallsversuche\nDer Globusversuch ist kein prototypisches Beispiel f√ºr Statistik in der Praxis, zumindest nicht auf dem ersten Blick. Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist. Bei n√§herer Betrachtung ist der Globusversuch prototypisch f√ºr ganz viele Fragestellungen:\n\nVon einem neuen Produkt von von \\(n\\) Exemplaren \\(k\\) verkauft. Auf welchen Wert \\(p\\) kann die Akzeptanzrate dieses Produkts gesch√§tzt werden?\nEin Chat-Bot hat von \\(n\\) Fragen \\(k\\) richtig beantwortet. Wie hoch kann die Verst√§ndnisrate \\(p\\) dieses Programms gesch√§tzt werden?\nEine neue Krebstherapie hat von \\(n\\) ‚Äúaustherapierten‚Äù Patientis \\(k\\) geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie gesch√§tzt werden?\n\nKurz: Der Globusversuch ist ein Muster f√ºr zweiwertige Zufallsversuche. Und solche sind h√§ufig im Leben, im Business und in der Wissenschaft.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#vertiefung",
    "href": "0500-Globusversuch.html#vertiefung",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\n6.7.1 Bayes-Video von 3b1b\nDas ‚ÄúBayes-Paradox-Video‚Äù von 3b1b pr√§sentiert eine gut verst√§ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber √§hnlichen Darstellung wie in diesem Kapitel.\n\n6.7.2 Bayes als Baum\nBayes‚Äô Theorem kann man sich als als Baumdiagramm vor Augen f√ºhren, Abbildung¬†6.13.\nGesucht sei \\(Pr(M_1|A)\\), also: die Wahrscheinlichkeit, dass das Teil von Maschine 1 produziert wurde, gegeben, dass es Ausschuss ist. Gegeben sind die Wahrscheinlichkeiten, dass Machine \\(i\\) das Teil produziert hat, \\(Pr(M_i)\\). Au√üerdem sind die Wahrscheinlichkeiten, dass das Teil Ausschuss ist, \\(Pr(A|M_i)\\), bekannt.\nDas Diagramm l√∂st die Aufgabe f√ºr uns; es zeigt damit die Anwendung von Bayes‚Äô Theorem auf.\nUm \\(Pr(M_1|A)\\) zu erhalten, setzt man die Wahrscheinlichkeit des g√ºnstigen Asts ins Verh√§ltnis zur Wahrscheinlichkeit aller relevanten √Ñste, \\(Pr(A)\\).\n\nBeispiel 6.8 (Maschine produziert Ausschuss) Die drei Maschinen \\(M_1, M_2, M_3\\) produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. Abbildung¬†6.13.\nAufgabe: Wie gro√ü ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde? Berechnen Sie diese Wahrscheinlichkeit.\\(\\square\\)\n\nDer g√ºnstige (gesuchte) Ast, \\(Pr(M1 \\cap A)\\), ist hier fett gedruckt, s. Abbildung¬†6.13. In Abbildung¬†6.13 zeigen die runden K√§stchen am Ende der Pfade die Wahrscheinlichkeiten des jeweiligen Pfades an.\n\n\n\n\n\nflowchart LR\n  A[Start] ==&gt;|0.60|B[M1]\n  A ---&gt;|0.10|C[M2]\n  A ---&gt;|0.30|D[M3]\n  B ==&gt;|0.05|E[A]\n  B --&gt;|0.95|F[Nicht-A]\n  C ---&gt;|0.02|G[A]\n  C ---&gt;|0.98|H[Nicht-A]\n  D ---&gt;|0.04|I[A]\n  D ---&gt;|0.96|J[Nicht-A]\n  E --- K((0.030))\n  F --- L((0.570))\n  G --- M((0.002))\n  H --- N((0.098))\n  I --- O((0.012))\n  J --- P((0.288))\n\n\n\n\nAbbildung¬†6.13: G√ºnstige Pfade\n\n\n\n\n\\[Pr(M1|A) = \\frac{Pr(M1 \\cap A)}{Pr(A)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(Pr(M1|A)\\) betr√§gt also ca. 68%.\nZur Erinnerung: \\(Pr(A)\\) ist die totale Wahrscheinlichkeit (dass ein produziertes Teil Ausschuss ist).\n\n6.7.3 Weitere Herleitung der Bayes-Formel\nMan kann sich Bayes‚Äô Theorem auch wie folgt herleiten:\n\\(Pr(D\\cap H) = Pr(D \\cap H) = Pr(D) \\cdot Pr(H|D) = Pr(H) \\cdot Pr(D|H)\\)\nDann l√∂sen wir nach P\\((H|D)\\) auf, s. Theorem¬†6.8.\n\nTheorem 6.8 (Bayes‚Äô Theorem 3) \\[Pr(H|D) = \\frac{\\overbrace{Pr(H)}^\\text{Apriori-Wahrscheinlichkeit} \\cdot \\overbrace{Pr(D|H)}^\\text{Likelihood}}{\\underbrace{Pr(D)}_\\text{Evidenz}}\\quad \\square\\]\n\n\n6.7.4 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayes‚Äô Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel w√§re: ‚ÄúWas ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?‚Äù.\nDas sieht dann so aus wie in Theorem¬†6.9 gezeigt.\n\nTheorem 6.9 (Bayes‚Äô Theorem f√ºr zusammengesetzte Hypothesen) \\[\n\\begin{aligned}\nPr(R \\cap B |K) &= \\frac{ Pr(R \\cap B) \\cdot Pr(K|R \\cap B) }{Pr(D)} \\\\\n&= \\frac{ Pr(R ) \\cdot Pr(B) \\cdot Pr(K|R \\cap B) }{Pr(D)}\n\\end{aligned}\n\\quad \\square\\]\n\nHier haben wir \\(Pr(R \\cap B)\\) aufgel√∂st in \\(Pr(R) \\cdot Pr(B)\\), das ist nur zul√§ssig, wenn \\(R\\) und \\(B\\) unabh√§ngig sind.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#aufgaben",
    "href": "0500-Globusversuch.html#aufgaben",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\n\n\n\n\n\n\nTipp\n\n\n\nEinige der folgenden Aufgaben sind in englischer Sprache. Wenn Ihnen eine andere Sprache (z.B. Deutsch) lieber ist, nutzen Sie einfach die √úbersetzungsfunktion Ihres Browsers. Das sind meist nur zwei Klicks. \\(\\square\\)\n\n\n\n6.8.1 Papier-und-Bleistift-Aufgaben\n\nVerteilungen-Quiz-01\nglobus1\nglobus2\nglobus3\nglobus-bin\nglobus-bin2\nKrebs1\nkekse01\nkekse03\nbayes2\nBayes-Theorem1\nbayes-ziel1\ntotale-wskt1\nwskt-quiz13\nwskt-quiz12\nwskt-quiz15\n\n6.8.2 Aufgaben, f√ºr die man einen Computer braucht\n\n\nRethink2m1\nRethink2m2\n\nRethink2m3    \n\nkekse02\neuro-bayes\nbath42\nKaefer2\nrethink3m1\nLose-Nieten-Binomial-Grid",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#section",
    "href": "0500-Globusversuch.html#section",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "\n6.9 ‚Äî",
    "text": "6.9 ‚Äî\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#footnotes",
    "href": "0500-Globusversuch.html#footnotes",
    "title": "\n6¬† Bayes-Versuch\n",
    "section": "",
    "text": "wenn auch nicht als Erster‚Ü©Ô∏é\nWarum gerade 9 Mal? Tja, dann hat das Handy geklingelt‚Ä¶ Auch in wissenschaftlichen Versuchen ist (leider?) nicht immer alles genau geregelt.‚Ü©Ô∏é\nIhr Ergebnis kann anders aussehen, schlie√ülich ist es ja Zufall.‚Ü©Ô∏é\noder den?‚Ü©Ô∏é\nzu Deutsch etwa: ‚ÄúMutma√ülichkeit‚Äù‚Ü©Ô∏é\n Anstatt von Priori liest man auch Prior; anstatt Posteriori auch Posterior‚Ü©Ô∏é\nDie sog. ‚Äúiid-Annahme‚Äù, independently and identically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen. Jeder Wurf ist unabh√§ngig von allen anderen: Das Ergebnis eines Wurfes hat keinen (stochastischen) Einfluss auf ein Ergebnis anderer W√ºrfe. Die Wahrscheinlichkeitsverteilung ist bei jedem Wurf identisch.‚Ü©Ô∏é\nAllgemeiner spricht man auch von 2 Treffern bei 3 W√ºrfen (d.h. 1 ‚ÄúNicht-Treffer‚Äù, den wir als ‚ÄúNiete‚Äù bezeichnen). Treffer werden oft mit 1 und Nieten mit 0 bezeichnet‚Ü©Ô∏é\nhttps://www.geogebra.org/scientific?lang=de‚Ü©Ô∏é\nAuch Gitter-Methode oder Grid-Methode genannt.‚Ü©Ô∏é\nEin Parameterwert ist eine m√∂gliche Auspr√§gung des Parameters.‚Ü©Ô∏é\nsynonym: priori‚Ü©Ô∏é\nsynonym: Die Likelihoodwerte werden mit den Apriori-Werten gewichtet.‚Ü©Ô∏é",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Bayes-Versuch</span>"
    ]
  },
  {
    "objectID": "0600-Post.html",
    "href": "0600-Post.html",
    "title": "7¬† Die Post befragen",
    "section": "",
    "text": "7.1 Lernsteuerung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "7¬† Die Post befragen",
    "section": "",
    "text": "7.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n7.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n7.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 3.1 und 3.2.\n\n\n7.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúDaten umformen‚Äù\nStatistik1, Kap. ‚ÄúDaten zusammenfassen‚Äù\nStatistik1, Kap, 6.4 ‚ÄúQuantile\n\n\n\n7.1.5 Ben√∂tigte R-Pakete\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # optional\n\n\n\n\n7.1.6 Begleitvideos\n\nPlaylist QM2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#zur-erinnerung-bayesbox-in-r-berechnen",
    "href": "0600-Post.html#zur-erinnerung-bayesbox-in-r-berechnen",
    "title": "7¬† Die Post befragen",
    "section": "7.2 Zur Erinnerung: Bayesbox in R berechnen",
    "text": "7.2 Zur Erinnerung: Bayesbox in R berechnen\nBerechnen wir mit der Bayesbox (‚ÄúGittermethode‚Äù) die Postverteilung f√ºr den Globusversuch. Die Bayesbox ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele n√ºtzliche Informationen. Sie ist das zentrale Ergebnis einer Bayes-Analyse.\nBetrachten wir wieder das Globusmodell mit folgendem Ergebnis: \\(W=6\\) Wasser, \\(N=9\\) W√ºrfen, bei Apriori-Indifferenz gegen√ºber den Parameterwerten. Und sagen wir \\(k=11\\) Gitterwerten1, also mit 10 Wasseranteilswerten zwischen 0 und 1.\n\n√úbungsaufgabe 7.1 (Welcher Paramterwert hat die h√∂chste Posteriori-Wahrscheinlichkeit?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\nAufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die h√∂chste Wahrscheinlichkeit (d.h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. Listing¬†7.1. \\(\\square\\)\n\n\n\n\n\n\n\n\nListing¬†7.1: Bayesbox mit 6 Wasser bei 9 Versuchen\n\n\n\nCode\nn_success &lt;- 6          \nn_trials  &lt;- 9\n1p_grid &lt;- seq(from = 0, to = 1, by = .1)\n2L &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\n\n3bayesbox_6w_9v &lt;-\n  tibble(p_grid = p_grid,prior  = 1) %&gt;% \n  mutate(likelihood = L) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n\n\n\n1\n\nSequenz von 0 bis 1 mit Schritten der Gr√∂√üe 0.1.\n\n2\n\nLikelihood mit 6 Treffern bei 9 W√ºrfen und das Ganze jeweils f√ºr alle 11 Parameterwerte\n\n3\n\nDann packen wir alles in eine Tabelle.\n\n\n\n\n\n\nAbb. Abbildung¬†6.11 zeigt die resultierende Bayesbox; vor allem ist die Post-Verteilung wichtig.\n\n\nCode\nlibrary(ggpubr)\nggline(bayesbox_6w_9v , x = \"p_grid\", y = \"post\") \n\n\n\n\n\n\n\n\n\n\n\n\nVoil√†, die Post-Verteilung als Tabelle, auch ‚ÄúBayesbox‚Äù (oder Bayes-Gitter) genannt: s. Tabelle¬†7.1.\n\n\n\n\nTabelle¬†7.1: Postverteilung mit der Gittermethode berechnet\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.02\n0.02\n0.02\n\n\n0.4\n1\n0.07\n0.07\n0.07\n\n\n0.5\n1\n0.16\n0.16\n0.16\n\n\n0.6\n1\n0.25\n0.25\n0.25\n\n\n0.7\n1\n0.27\n0.27\n0.27\n\n\n0.8\n1\n0.18\n0.18\n0.18\n\n\n0.9\n1\n0.04\n0.04\n0.04\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.1 Bayesbox automatisiert\n√úbrigens kann man die Berechnung der Bayesbox auch automatisieren, s. Tabelle¬†7.2 und Listing¬†7.2, z.B. so:2\nEntweder so:\n\n\nCode\nsource(\"https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R\") \nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\nMit source importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code f√ºr die Funktion bayesbox.\nOder Sie starten das R-Paket, wo die Funktion wohnt:\n\n\n\n\nListing¬†7.2: Funktion bayesbox, auch im Paket prada erh√§ltlich\n\n\n\nCode\n1library(prada)\nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\n\n\n\n\n1\n\nDas Paket prada steht nicht im Standard-R-App-Store (‚ÄúCRAN‚Äù), sondern auf Github. Sie k√∂nnnen es so installieren: devtools::install_github(\"sebastiansauer/prada\").\n\n\n\n\n\n\nTabelle¬†7.2: Eine Bayesbox ‚Äòautomatisiert‚Äô erstellt, mit Hilfe der Funktion bayesbox\n\n\n\n\n  \n\n\n\n\n\n\nViele n√ºtzliche Fragen (und Antworten) leiten sich ab aus Abb. Abbildung¬†6.11.\n\nBeispiel 7.1 (Beispiele f√ºr Fragen an die Post-Verteilung) ¬†\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die h√∂chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell √ºber die Parameterwerte?\n\netc. \\(\\square\\)\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n7.2.2 Bayesbox geht nicht f√ºr komplexe Modelle\nBisher, f√ºr einfache Fragestellungen, hat unsere Bayesbox gut funktioniert. Allerdings: Funktioniert sie auch bei komplexeren Modellen? Schlie√ülich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 Pr√§diktor, dann haben wir folgende drei Gr√∂√üen3 zu sch√§tzen: \\(\\beta_0, \\beta_1, \\sigma\\). H√∂rt sich gar nicht so viel an. Aber Moment, wir m√ºssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach m√ºssen wir alle Auspr√§gungen (‚ÄúGitterwerte‚Äù) der Variablen multiplizieren, um die Wahrscheinlichkeiten aller Kombinationen zu bestimmen. Puh, das wird eine gro√üe Zahl. Wenn wir f√ºr die drei Gr√∂√üen jeweils 10 Auspr√§gungen annehmen, was wenig ist, k√§men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 Auspr√§gungen und 3 Parametern w√§ren es schon \\(100^3=10^6\\) Kombinationen. Das w√§re doch eine recht lange Tabelle.4 Bei einer multiplen Regression mit sagen wir 10 Parametern mit jeweils 100 Auspr√§gungen rechnet das arme R bis zum j√ºngsten Tag: \\(10^{100}\\).\n\nü§ñ Bitte tue mir das nicht an!\n\n\nüë®‚Äçüè´ Schon gut, das k√∂nnen wir R nicht zumuten. Wir brauchen eine andere L√∂sung!",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "7¬† Die Post befragen",
    "section": "7.3 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "7.3 Mit Stichproben die Post-Verteilung zusammenfassen\n\n7.3.1 Wir arbeiten jetzt mit H√§ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle k√∂nnen nicht mehr ‚Äúeinfach mal eben‚Äù ausgerechnet werden; die Mathematik wird zu rechenintensiv. Gl√ºcklicherwei√üe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht. Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit H√§ufigkeiten. Praktischerweise werden wir in K√ºrze einen R-Golem kennenlernen, der das f√ºr uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zur√ºck. Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung mit H√§ufigkeiten (d.h. in Stichprobenform) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen f√ºr Bayes auf Stichproben eingestellt.\n\n\nDie Bayesbox-Methode5 ist bei gr√∂√üeren Datens√§tzen (oder gr√∂√üeren Modellen) zu unpraktisch. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein.6\n\n\n7.3.2 H√§ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (‚ÄúR-Golems‚Äù) liefern uns die Post-Verteilung in Stichprobenform zur√ºck. Bevor wir uns aber mit diesen R-Werkzeugen besch√§ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform. Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle bayesbox_6w_9v), s. Listing¬†7.3.\n\n\n\nListing¬†7.3: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\n\n\n\nsamples_6w_9v &lt;-\n  bayesbox_6w_9v %&gt;%  # nimm die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit Zur√ºcklegen\n  select(p_grid)\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle bayesbox_6w_9v zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit Zur√ºcklegen h√§lt die Wahrscheinlichkeiten w√§hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird. Wir begn√ºgen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht. Das Ergebnis, Tabelle samples_6w_9v, die aus Stichproben aus der Post-Verteilung besteht, ist (in Ausz√ºgen) in Tabelle¬†7.3 dargestellt.\nWenn Sie jetzt denken: ‚ÄúWarum machen wir das jetzt? Brauchen wir doch gar nicht!‚Äù - Dann haben Sie Recht. K√ºnftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\n\n\nTabelle¬†7.3 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.\n\n\n\n\nTabelle¬†7.3: Stichproben-Post-Verteilung\n\n\n\n\n\n\n\n\n\np_grid\n\n\n\n\n0.500\n\n\n0.900\n\n\n0.700\n\n\n0.600\n\n\n0.900\n\n\n\n\n\n\n\n\n\n\n\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.5 0.9 0.7 0.6 0.9 0.3 0.7 0.6 0.8 0.4 0.7 0.3 0.9 0.7 0.6 0.6 0.4 0.6\n##  [19] 0.5 0.5 0.5 0.6 0.8 0.7 0.5 0.7 0.7 0.4 0.8 0.6 0.6 0.7 0.9 0.6 0.9 0.4\n##  [37] 0.8 0.9 0.8 0.6 0.6 0.6 0.5 0.7 0.5 0.8 0.7 0.7 0.6 0.8 0.3 0.5 0.8 0.5\n##  [55] 0.7 0.6 0.5 0.8 0.7 0.7 0.7 0.7 0.6 0.7 0.5 0.7 0.6 0.6 0.7 0.8 0.7 0.6\n##  [73] 0.8 0.5 0.8 0.7 0.7 0.7 0.6 0.8 0.7 0.7 0.9 0.4 0.5 0.6 0.6 0.5 0.8 0.8\n##  [91] 0.7 0.7 0.6 0.9 0.9 0.5 0.5 0.8 0.7 0.8\n\n\n\nSo sieht unsere ‚ÄúStichproben-Bayesbox‚Äù als Balkendiagramm aus, s. Abbildung¬†7.1.\n\nSyntaxOutput\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  count(p_grid) |&gt; \n  ggbarplot(x = \"p_grid\", y = \"n\") \n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†7.1: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n\n\nAus Abbildung¬†7.1 k√∂nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% f√ºr am wahrscheinlichsten h√§lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlie√üen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie Abbildung¬†7.1 mit Abbildung¬†6.12: beide sind sehr √§hnlich! Das Stichprobenziehen (Abbildung¬†7.1) n√§hert sich recht gut an die exakte Berechnung an (Abbildung¬†6.12).\nEs ist hilfreich, sich die Stichproben-Posterior-Verteilung einmal anzuschauen, um ein Gef√ºhl daf√ºr zu bekommen, wie die Post-Verteilung aussieht.\n Download samples_6w_9v.xlsx \n\n\n7.3.3 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die Aufl√∂sung auf \\(k=100\\) Gitterwerte (Auspr√§gungen) nach oben.\n\n\nCode\n1k &lt;- 100\n2n_success &lt;- 6\n3n_trials  &lt;- 9\n\nbayesbox_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n4                      length.out = k),\n5         prior  = 1) %&gt;%\n6  mutate(likelihood = dbinom(n_success,\n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n7  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n1\n\n\\(k=100\\) Gitterwerte\n\n2\n\n6 Treffer (Wasser)\n\n3\n\n9 Versuche\n\n4\n\nBayesbox anlegen mit 100 Zeilen, d.h. 100 Parameterwerten\n\n5\n\nApriori indifferent: Alle Hypothesen haben die gleiche Apriori-Plausibilit√§t\n\n6\n\nDie Likelihood ist binomialverteilt.\n\n7\n\nPost-Verteilung berechnen wie gewohnt.\n\n\n\n\nbayesbox_k100 ist eine Bayesbox mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\n\nCode\nsamples_k100 &lt;-\n  bayesbox_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zur√ºcklegen\n\n\nAbbildung¬†7.2 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen F√§llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der ‚Äútypische‚Äù Wert des Modells zu sein. Au√üerdem erkennt man, dass das Modell durchaus einige Streuung in der Sch√§tzung des Wasseranteils bereith√§lt. Das Modell ist sich nicht sehr sicher, k√∂nnte man sagen.\n\n\n\n\n\n\n\n\nAbbildung¬†7.2: Post-Verteilung mit 100 Gitterwerten, exakt vs.¬†auf Basis von Stichproben\n\n\n\n\n\nDie Stichprobendaten n√§hern sich der ‚Äúechten‚Äù Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt ‚Äúglattere‚Äù R√§nder. Die Stichproben-Post-Verteilung ist sehr √§hnlich zur echten, exakten Post-Verteilung. Das Stichproben-Verfahren zur Berechnung der Post-Verteilung funktioniert also! Das ist gut, denn wir werden in Zukunft nur noch mit dem Stichproben-Verfahren (zur Erstellung der Post-Verteilung) arbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte gl√§tten die Verteilung.\n\n\nJetzt die Post-Verteilung noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. Abbildung¬†7.3.\n\n\n\n\n\n\n\n\nAbbildung¬†7.3: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): sch√∂n ‚Äòglatt‚Äô. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "7¬† Die Post befragen",
    "section": "7.4 Die Post-Verteilung befragen",
    "text": "7.4 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\nüì∫ Die Post-Verteilung auslesen\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir k√∂nnen viele n√ºtzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abbildung¬†7.4 schematisch illustriert.\n\n\n\n\n\n\nAbbildung¬†7.4: Fragen nach p vs.¬†Fragen nach q\n\n\n\nIm linken Teildiagramm von Abbildung¬†7.4 fragen wir: ‚ÄúWie wahrscheinlich ist ein Wasseranteil von h√∂chstens 80%?‚Äù. Im rechten Teildiagramm fragen wir: ‚ÄúWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht √ºberschritten?‚Äù.\n\n7.4.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie gro√ü ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt? Um diese Frage zu beantworten, z√§hlen wir einfach, wie viele Stichproben die Bedingung erf√ºllen, und summieren die Wahrscheinlichkeiten dieser Stichproben. Wir z√§hlen (count) also die Stichproben, die sich f√ºr einen Wasseranteil (p_grid) von weniger als 50% aussprechen.\n\n\nCode\nsamples_6w_9v %&gt;%\n  count(p_grid &lt; .5) \n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, k√∂nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) f√ºr einen Wasseranteil kleiner als 50%.\n\n√úbungsaufgabe 7.2 (Was macht die Funktion count?) Zur Erinnerung: Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem Pr√ºfkriterium, Wasseranteil h√∂chstens 50%. Dann z√§hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zur√ºck. \\(\\square\\)\n\n\n\nWir z√§hlen, wie oft der Wasseranteil weniger als 50% betr√§gt.\n\n\nCode\nsamples_6w_9v %&gt;%\n  count(p_grid &lt; .5) \n\n\n\n  \n\n\n\n\nNat√ºrlich gibt es verschiedene Wege, die gleiche Frage zu beantworten.\n\n\nCode\nbayesbox_6w_9v %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n\n  \n\n\n\n\n\n\nBeispiel 7.2 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\nWir z√§hlen die Stichproben, die diesen Kriterien entsprechen.\n\n\nCode\nsamples_6w_9v %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n\n  \n\n\n\n\nü§ñ Ich w√ºrde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.\n\n\nüë®‚Äçüè´ Das wollte ich auch gerade sagen‚Ä¶\n\n\n\nCode\nsamples_6w_9v %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n\n  \n\n\n\nAnteile von count() k√∂nnte man, wenn man m√∂chte, auch filter() verwenden.\n\n\nCode\nsamples_6w_9v %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n\n  \n\n\n\nFertig üòÑ \\(\\square\\)\n\n\nBeispiel 7.3 (Wasseranteil zwischen 90& und 100%?) Noch ein Beispiel f√ºr eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nSyntaxOutput\n\n\n\n\nCode\nsamples_6w_9v %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betr√§gt. \\(\\square\\)\n\n\n√úbungsaufgabe 7.3 (Wasseranteil h√∂chstens 50%?) ¬†\n\nüë©‚Äçüî¨ Mit welcher Wahrscheinlichkeit ist der Planet h√∂chstens zur H√§lfte mit Wasser bedeckt?\n\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v %&gt;% count(p_grid &lt;= .5)\n\n\n\n  \n\n\n\n\n\n\n\nWir k√∂nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem ‚ÄúGipfel‚Äù des Berges, s. Abbildung¬†7.3.\nF√ºr unsere Stichproben-Postverteilung, samples_6w_9v, s. Abbildung¬†7.1, l√§sst sich der Modus so berechnen:\n\n\nCode\nmap_estimate(samples_6w_9v$p_grid)  \n\n\n\n  \n\n\n\nDabei steht map f√ºr Maximum Aposteriori, also das Maximum der Post-Verteilung.\n\n√úbungsaufgabe 7.4 Bei der Gelegenheit k√∂nnten wir folgende, √§hnliche Fragen stellen:\n\nWas ist der mittlere Sch√§tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane Sch√§tzwert (Median)?\n\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n\n  \n\n\n\n\n\n\n\n\n\n7.4.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSch√§tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervalle7.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht √ºberschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit.) Wir m√∂chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist. Diese Frage k√∂nnen wir mit dem Befehl quantile beantworten.\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n\n  \n\n\n\nLaut unserem Modell k√∂nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu f√ºhren, s. Abbildung¬†7.3.\n\n\n\n\n\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enth√§lt, laut dem Modell?\nDaf√ºr ‚Äúschneiden‚Äù wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n\n  \n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n√úbungsaufgabe 7.5 (Welcher Parameterwert ist der wahrscheinlich gr√∂√üte?) √úbersetzen wir ‚Äúwahrscheinlich‚Äù gr√∂√üte in ‚Äúmit einer Wahrscheinlichkeit von 99% gibt es keinen gr√∂√üeren‚Äù.\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  summarise(quant99 = quantile(p_grid, p = .99))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der h√∂chste zu erwartende Wasseranteil 0.9.\n\n\n\n\n\n√úbungsaufgabe 7.6 (Welcher Parameterwert ist der wahrscheinlich kleinste?) √úbersetzen wir ‚Äúwahrscheinlich‚Äù kleinste in ‚Äúmit einer Wahrscheinlichkeit von 99% gibt es keinen kleineren‚Äù.\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .01))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 ‚Äì immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\n√úbungsaufgabe 7.7 (Welcher Parameterwert ist der ‚Äúvermutlich‚Äù kleinste?) In der ‚Äúwirklichen‚Äù Welt sind Aussagen nicht immer pr√§zise. Sagen wir, die Chefin der Weltraumbeh√∂rde hat in einem Presse-Statement von der ‚Äúvermutlichen Untergrenze‚Äù hinsichtlich des Wasseranteils gesprochen.\n√úbersetzen wir ‚Äúvermutlich‚Äù kleinste in ‚Äúmit einer Wahrscheinlichkeit von 90% gibt es keinen kleineren‚Äù.\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nsamples_6w_9v |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .1))\n\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 ‚Äì immer auf Basis unserer beobachteten Daten und der Vorannahmen.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#visualisierung-der-verteilungen",
    "href": "0600-Post.html#visualisierung-der-verteilungen",
    "title": "7¬† Die Post befragen",
    "section": "7.5 Visualisierung der Verteilungen",
    "text": "7.5 Visualisierung der Verteilungen\n\n7.5.1 Perzentilintervalle\n\nDefinition 7.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die ‚Äúabzuschneidende‚Äù Wahrscheinlichkeitsmasse h√§lftig auf die beiden R√§nder aufteilen, nennen wir Perzentilintervalle (PI) oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. Abbildung¬†7.5, rechtes Teildiagramm.8 \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\n\n\n(b) Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\nAbbildung¬†7.5: Perzintilintervalle\n\n\n\nDas 10%, 20%, ‚Ä¶ 100%-Quantil9 (auf Basis von samples_k100) sind in Abbildung¬†7.6 illustriert.\n\n\n\n\n\n\nAbbildung¬†7.6: Quantile in 10%-Schritenn durch die Verteilung von samples_k100\n\n\n\n\n\n7.5.2 Schiefe Posteriori-Verteilungen sind m√∂glich\nNoch einmal zum Globusversuch: Gehen wir von 3 W√ºrfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlie√üen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 W√ºrfe), s. Listing¬†7.4 mit dem Objekt d_33.\n\n\n\n\nListing¬†7.4: Schiefe Post-Verteilung in einer Bayesbox\n\n\n\nCode\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e6, \n                 weight_by = post_33, \n                 replace = T)\n\n\n\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\n\n\n\n\n0.99\n1\n0.97\n0.97\n\n\n0.63\n1\n0.25\n0.25\n\n\n1.00\n1\n1.00\n1.00\n\n\n0.94\n1\n0.83\n0.83\n\n\n0.27\n1\n0.02\n0.02\n\n\n0.73\n1\n0.39\n0.39\n\n\n\n\n\n\n\nMit dieser ‚Äúschiefen‚Äù Post-Verteilung k√∂nnen wir gut die Auswirkungen auf das Perzentil- und das H√∂chste-Dichte-Intervall anschauen.\nHier z.B. ein 50%-Perzentilintervall, s. Abb. Abbildung¬†7.7, a).\n\n\n\n\n\n\n\n\n\n\n\n(a) Perentilintervall (PI)\n\n\n\n\n\n\n\n\n\n\n\n(b) H√∂chste-Dichte-Intervall (HDI)\n\n\n\n\n\n\n\nAbbildung¬†7.7: Schiefe Intervalle: Das PI enth√§lt den wahrscheinlichsten Parameterwert nicht, das HDI schon.\n\n\n\nEin Perzentilintervall kann, wenn es dumm l√§uft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zur√ºckweisen. Das ist nicht so toll.\nEin Highest-Density-Intervall (HDI10) ist schm√§ler als der Perzintilintervall und enth√§lt immer den wahrscheinlichsten Parameterwert.\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. mit dem Befehl eti ausgeben lassen.\n\n\nCode\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)  # Paket `easystats`\n\n\n\n\n\n\n  \n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n7.5.3 Intervalle h√∂chster Dichte\n\nDefinition 7.2 (Intervalle h√∂chster Dichte (Highest Density Intervals)) Intervalle h√∂chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schm√§lste Intervall, das den gesuchten Parameter enth√§lt (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht, s. Abbildung¬†7.7. Bei einem HDI sind die abgeschnitten R√§nder nicht mehr gleich gro√ü, im Sinne von enthalten nicht (zwangsl√§ufig) die gleiche Wahrscheinlichkeitsmasse. Beim PI ist die Wahrscheinlichkeitsmasse in diesen R√§ndern hingegen gleich gro√ü.\nJe symmetrischer die Verteilung, desto n√§her liegen die Punktsch√§tzer aneinander (und umgekehrt), s. Abb. Abbildung¬†7.8.\n\n\n\n\n\n\n\n\nAbbildung¬†7.8: Visualisierung der Punktsch√§tzer bei einer schiefen Post-Verteilung\n\n\n\n\n\nMit dem Befehl hdi kann man sich die Grenzwerte eines HDI, z.B. eines 50%-HDI, ausgeben lassen, s. Tabelle¬†7.4.\n\n\nCode\nsamples_6w_9v %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\n\nTabelle¬†7.4: 50%-HDI f√ºr unser Globusmodell (samples_6w_9v)\n\n\n\n\n  \n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfl√§che) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI).",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "7¬† Die Post befragen",
    "section": "7.6 Fazit",
    "text": "7.6 Fazit\n\n7.6.1 Intervalle h√∂chster Dichte vs.¬†Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle √§hnlich oder identisch\nPerzentilintervalle sind verbreiteter\nIntervalle h√∂chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle h√∂chster Dichte sind die schmalsten Intervalle f√ºr eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n7.6.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datensatz samples_6w_9v, s. Listing¬†7.3. Sagen wir, wir haben 6 Treffer bei 9 W√ºrfen erzielt.\nLageparameter: Welchen mittleren Wasseranteil kann man erwarten?\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n\n  \n\n\n\nStreuungsparameter: Wie unsicher sind wir in der Sch√§tzung des Wasseranteils?\n\n\nCode\nsamples_6w_9v %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler\n\n\n\n  \n\n\n\nAnstelle der Streuungsparameter ist es aber √ºblicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel f√ºr einen Parameter, einer unbekannten Gr√∂√ües eines Modells.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "7¬† Die Post befragen",
    "section": "7.7 Aufgaben",
    "text": "7.7 Aufgaben\n\n7.7.1 Papier-und-Bleistift-Aufgaben\n\n\nkekse03\nbfi10\nKaefer2\nmtcars-post2a\nrethink3e1-7-paper\nmtcars-post3a\nmtcars-post3a\nmtcars-post_paper\nfattails1\nfattails2\neti-hdi\n\n\n\n7.7.2 Aufgaben, bei denen man einen Computer ben√∂tigt\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nReThink3e1-7\nWeinhaendler\nRethink3m1\nRethink3m2\ngroesse2\ngroesse1\nAnteil-Apple\nKung-height\nzwielichter-dozent-bayes",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "7¬† Die Post befragen",
    "section": "7.8 -",
    "text": "7.8 -\n\n\n\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#footnotes",
    "href": "0600-Post.html#footnotes",
    "title": "7¬† Die Post befragen",
    "section": "",
    "text": "Die Anzahl der Gitterwerte ist nicht Teil des Modells, streng genommen; die Anzahl der Gitterwerte entscheiden nur √ºber die Genauigkeit der Post-Verteilung.‚Ü©Ô∏é\nAlternativ kann man auf die Funktion √ºber das R-Paket {prada} zugreifen.‚Ü©Ô∏é\nModellparameter genannt‚Ü©Ô∏é\nVorsicht beim Ausdrucken.‚Ü©Ô∏é\nauch Grid-Methode genannt‚Ü©Ô∏é\nEine gute Einf√ºhrung in die Hintergr√ºnde findet sich bei McElreath (2020).‚Ü©Ô∏é\nTats√§chlich gibt es eine Vielzahl an Begriffen, die in der Literatur nicht immer konsistent verwendet werden, etwa Kompatibilit√§tsintervall, Ungewissheitsintervall, Passungsbereich.‚Ü©Ô∏é\nHier auf Basis der Post-Verteilung samples_6w_9v.‚Ü©Ô∏é\nd.h. die Dezile‚Ü©Ô∏é\nAuch als Highest Hensity Posterior Interval (HDPI) bezeichnet.‚Ü©Ô∏é",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html",
    "href": "0800-gauss.html",
    "title": "8¬† Gauss-Modelle",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "8¬† Gauss-Modelle",
    "section": "",
    "text": "8.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nein Gau√ümodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n8.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.1 bis 4.3.\n\n\n8.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúModellg√ºte‚Äù\nStatistik1, Kap. ‚ÄúPunktmodelle 2‚Äù\nStatistik1, Abschnitt ‚ÄúNormalverteilung‚Äù\n\n\n\n8.1.5 Ben√∂tigte R-Pakete\nF√ºr rstanarm wird ggf. weitere Software ben√∂tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, m√ºssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio m√ºssen Sie die (ben√∂tigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Modelle berechnen\nlibrary(easystats)  # Statistik-Komfort\nlibrary(DataExplorer)  # Daten verbildlichen\nlibrary(ggpubr)  # Daten verbildlichen\nlibrary(hexbin)  # stat_bin_hex ggplot2\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nAb diesem Kapitel ben√∂tigen Sie das R-Paket rstanarm. \\(\\square\\)\n\n\n\n\n8.1.6 Ben√∂tigte Daten\nWir ben√∂tigen den Datensatz !Kung. Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\n\n\nCode\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nkung &lt;- read.csv(Kung_path) \n\nhead(kung)\n\n\n\n  \n\n\n\nDatenquelle\n Download \n\n\n8.1.7 Einstieg\n\nBeispiel 8.1 (Was war noch mal eine Normalverteilung?) In diesem Kapitel ben√∂tigen Sie ein gutes Verst√§ndnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! \\(\\square\\)\n\n\nBeispiel 8.2 (Was war noch mal eine Posteriori-Verteilung?) In diesem Kapitel befragen wir die Post-Verteilung f√ºr ein normalverteilte Zufallsvariable, n√§mlich die K√∂rpergr√∂√üe der !Kung San. Was war noch mal eine Post-Verteilung und wozu ist sie gut? \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-gro√ü-sind-die-kung-san",
    "href": "0800-gauss.html#wie-gro√ü-sind-die-kung-san",
    "title": "8¬† Gauss-Modelle",
    "section": "8.2 Wie gro√ü sind die !Kung San?",
    "text": "8.2 Wie gro√ü sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. ?fig-kungs.\n\nThe «ÉKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names «ÉKung («ÉXun) and Ju are variant words for ‚Äòpeople‚Äô, preferred by different «ÉKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of «ÉKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\nWir interessieren uns f√ºr die Gr√∂√üe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als kung_erwachsen.\n\n\nCode\nkung_erwachsen &lt;- kung %&gt;% \n  filter(age &gt;= 18)\n\nnrow(kung_erwachsen)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tats√§chlich recht easy, s. Tabelle¬†8.1.\n\n\nCode\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelle¬†8.1: Statistiken der metrischen Variablen im Kung-Datensatz\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\n‚àí0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\n‚àí0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\n‚àí0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\n‚àí2.00\n352.00\n0\n\n\n\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus {DataExplorer}), s. Abbildung¬†8.1.\n\n\nCode\nplot_density(kung_erwachsen)\n\n\n\n\n\n\n\n\nAbbildung¬†8.1: Verteilungen der Variablen im Kung-Datensatz. Gr√∂√üe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n\n\n\n8.2.2 Wir gehen apriori von normalverteilter Gr√∂√üe Der !Kung aus\nForschungsfrage: Wie gro√ü sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also f√ºr den Mittelwert der K√∂rpergr√∂√üe (erwachsene Person1), \\(\\mu\\).\n\n\n\nMensch, Wikimedia Commons2\n\n\nWir sind uns √ºber diesen Mittelwert in der Population nicht sicher3, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178 cm und Streuung von 20 cm, s. Gleichung¬†8.1.\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{8.1}\\]\nGleichung¬†8.1 definiert ein Modell: Unsere Vorstellung der mittleren (‚Äútypischen‚Äù) K√∂rpergr√∂√üe der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.4 In einer echten Untersuchung sollte man einen inhaltlichen Grund f√ºr einen Priori-Wert haben. Oder man w√§hlt ‚Äúschwach informative‚Äù Prioris, wie das {rstanarm} tut: Damit l√§sst man kaum Vorab-Information in das Modell einflie√üen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern bei der K√∂rpergr√∂√üe).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der K√∂rpergr√∂√üen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. Dar√ºber hinaus ist eine Normalverteilung nicht unplausibel.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "8¬† Gauss-Modelle",
    "section": "8.3 Unser Gauss-Modell der !Kung",
    "text": "8.3 Unser Gauss-Modell der !Kung\nüì∫ Teil 1\n\n8.3.1 Modelldefinition\nWir nehmen an, dass die mittleren Gr√∂√üen, \\(\\mu\\), und die tats√§chlichen Gr√∂√üen, \\(h_i\\), normalverteilt sind und \\(\\sigma\\) exponentialverteilt ist (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior f√ºr den Parameter \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior f√ºr den Parameter \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn Abbildung¬†8.2 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\n\n\n\n\n\n\n(a) Priori der mittleren K√∂rpergr√∂√üe\n\n\n\n\n\n\n\n\n\n\n\n(b) Priori der Sch√§tzungenauigkeit\n\n\n\n\n\n\nAbbildung¬†8.2: Prioris unseres (ersten) Kung-Modells (m_kung)\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDieses Modell hat zwei Parameter, \\(\\mu\\) und \\(\\sigma\\). \\(\\square\\)\n\n\n\n\n8.3.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie K√∂rpergr√∂√üen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})   \\qquad{\\text{Likelihood}}\\]\n\n\n8.3.3 Prioris der Parameter\nDer Mittelwert der K√∂rpergr√∂√üe sei normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)} \\qquad{\\text{Prior}}\\]\nDie Streuung \\(\\sigma\\) der Gr√∂√üen sei exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)} \\qquad{\\text{Prior}}\\]\n\n\n8.3.4 m_kung: fertig!\nJetzt haben wir unser Modell (m_kung) definiert!\nWeil es so sch√∂n ist, schreiben/zeichnen wir es hier noch einmal auf, Gleichung¬†8.2, Abbildung¬†8.3.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) & \\text{Likelihood}  \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) & \\text{Prior} \\\\\n\\sigma &\\sim \\mathcal{E}(1/8) & \\text{Prior}\n\\end{aligned}\n\\tag{8.2}\\]\n\n\n\n\n\n\nAbbildung¬†8.3: Modellschema f√ºr das Modell m_kung\n\n\n\nZur Berechnung von m_kung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich kr√§ftig der Bursche, der soll die Arbeit f√ºr uns tun. Der Golem h√∂rt auf den Namen rstanarm5.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#zuf√§llige-motivationsabschnitt",
    "href": "0800-gauss.html#zuf√§llige-motivationsabschnitt",
    "title": "8¬† Gauss-Modelle",
    "section": "8.4 Zuf√§llige Motivationsabschnitt",
    "text": "8.4 Zuf√§llige Motivationsabschnitt\n\n\n\nGut gemacht!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-gr√∂√üen-modells-m_kung",
    "href": "0800-gauss.html#posteriori-verteilung-des-gr√∂√üen-modells-m_kung",
    "title": "8¬† Gauss-Modelle",
    "section": "8.5 Posteriori-Verteilung des Gr√∂√üen-Modells, m_kung",
    "text": "8.5 Posteriori-Verteilung des Gr√∂√üen-Modells, m_kung\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m_kung6.\n\n\nCode\n1m_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)\n2m41_post &lt;- as_tibble(m_kung)\n3names(m41_post) &lt;- c(\"mu\", \"sigma\")\n\n\n\n1\n\nBayes-Regressionsmodell berechnen\n\n2\n\nModellergebnis in Tabelle umwandeln\n\n3\n\nSch√∂nere Namen f√ºr die Spalten geben\n\n\n\n\nDas Argument refresh = 0 ist nur eine Nebensache, aber es ist praktisch, da es verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdr√ºcke. stan_glm7 ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein ‚Äúrichtiges‚Äù Regressionsmodell. Man k√∂nnte sagen, wir haben eine AV (K√∂rpergr√∂√üe), aber keine UV (keine Pr√§diktoren). Gl√ºcklicherweise k√∂nnen wir auch solche ‚Äúarmen‚Äù Regressionsmodelle formulieren: av ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen m√∂chte, aber keine Pr√§diktoren hat (das soll die 1 symbolisieren). F√ºr das Modell m_kung haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung (defaults) der Prioris von rstanarm zur√ºck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade w√§re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die gemeinsame Posteriori-Verteilung von m_kung, s. Abbildung¬†8.4\n\nFliesendiagrammStreudiagrammHistogramm\n\n\nGemeinsame Post-Verteilung von Mittelwert und Streuung\n\n\nCode\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\n\n\n\nAbbildung¬†8.4: Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m_kung_neue_prioris\n\n\n\n\n\nDa das Modell zwei Parameter hat, k√∂nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen k√∂nnen die Parameter korreliert sein.\nAbbildung¬†8.4 erlaubt uns, f√ºr jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\n\n\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m_kung_neue_prioris, s. Abbildung¬†8.5.\n\n\n\n\n\n\n\n\nAbbildung¬†8.5: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\n\n\n\nUnd hier kommt die Post-Verteilung nur des Mittelwerts.\nNat√ºrlich k√∂nnen wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. Abbildung¬†8.6.\n\n\n\n\n\n\n\n\nAbbildung¬†8.6: Die Post-Verteilung von mu in m_kung_neue_prioris; ein Balkendiagramm bietet sich an.\n\n\n\n\n\n\n\n\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung f√ºr \\(\\mu\\) und eine f√ºr \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, f√ºr die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte f√ºr \\(\\mu\\) und \\(\\sigma\\) klein: Die gro√üe Stichprobe hat die Priori-Werte √ºberstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so k√∂nnen wir interessante Fragen stellen.\n\n\n8.5.1 Hallo, Posteriori-Verteilung\n‚Ä¶ wir h√§tten da mal ein paar Fragen an Sie. üïµ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person gr√∂√üer als 1,55m?\nWelche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?\nWas ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der ‚ÄúBest Guess‚Äù?\n\nAntworten folgen etwas weiter unten.\nAbschlie√üend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), Abbildung¬†8.7.\n\n\n\n\n\n\n\n\nAbbildung¬†8.7: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen f√ºr mu und f√ºr sigma\n\n\n\n\n\n\n\n8.5.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() k√∂nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - √§hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zur√ºck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so: stan_glm(AV ~ UV, data = meine_daten).\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum Gr√∂√üenmittelwert (von Stan √ºbernommen)\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der Gr√∂√üen (von Stan √ºbernommen)\n\n\n8.5.3 Ausgabe von stan_glm()\nWir k√∂nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir k√∂nnen es aber auch komfortabler haben ‚Ä¶ Mit dem Befehl parameters kann man sich die gesch√§tzten Parameterwerte einfach ausgeben lassen (s. Abbildung¬†8.4).\n\n\nCode\nm_kung &lt;- stan_glm(height ~ 1, data = kung_erwachsen, refresh = 0)  # aus Paket rstanarm\n\nparameters(m_kung)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem sch√§tzt den Gr√∂√üenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.76 bis 155.41 sch√§tzt. Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu sp√§ter mehr.\n\n\n\n\n\n\nHinweis\n\n\n\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren ü§ì Wer N√§heres wissen will, findet hier einen Anfang. Au√üerdem sei an McElreath (2020) und Gelman et al. (2021) verwiesen. \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "8¬† Gauss-Modelle",
    "section": "8.6 Wie tickt stan_glm()?",
    "text": "8.6 Wie tickt stan_glm()?\n\n\n Quelle\n\nHier ein paar Kerninfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan f√ºr uns bereit.\nstan_glm() ist f√ºr die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) sch√§tzen, so hat man man ‚Ä¶ eine Regression ohne Pr√§diktor.\nEine Regression ohne Pr√§diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also f√ºr die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\n\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n8.6.1 Sch√§tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die Gr√∂√üen, f√ºr die wir eine Priori-Verteilung annehmen. Au√üerdem w√§hlen wir einen einen Likelihood-Funktion, so dass wir die Likelihood berechnen k√∂nnen. Auf dieser Basis sch√§tzen wir dann die Post-Verteilung. Ich sage sch√§tzen, um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren Sch√§tzungen) einfach mit parameters(modellname) auslesen.\n\n\n8.6.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, k√∂nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_kung:\n\n\nCode\npost_kung &lt;- as_tibble(m_kung)\nhead(post_kung)\n\n\n\n  \n\n\n\nIn einer Regression ohne Pr√§diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss √ºber unsere Sch√§tzwerte zu \\(\\mu\\) (der K√∂rpergr√∂√üe).\n\n√úbungsaufgabe 8.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\n\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist pr√§gnanter\n\npost_kung %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlie√üen, dass die Kung im Schnitt gr√∂√üer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. \\(\\square\\)\n\n\n\n\n\n√úbungsaufgabe 8.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nnames(post_kung) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist pr√§gnanter\n\npost_kung %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nOh, diese Hypothese k√∂nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlie√üen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschlie√üen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\n\n\nBeispiel 8.3 (Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell m_kung?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n  \n\n\n\n\n\n\n\n\n√úbungsaufgabe 8.3 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\npost_kung %&gt;% \n  eti()\n\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\n\n\n\n√úbungsaufgabe 8.4 (Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\n\n\nCode\nm_kung %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.76, 155.41)\n100%\n1.000\n2655\nNormal (154.60 +- 19.36)\n\n\n\n\n\nSeeing is believing, s. Abbildung¬†8.8.\n\n\nCode\nm_kung %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nAbbildung¬†8.8: Parameter von m_kung, nur einer: der Intercept\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren K√∂rpergr√∂√üe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\n\n\n\n√úbungsaufgabe 8.5 (Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der ‚ÄúBest Guess‚Äù?) ¬†\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\nparameters(m_kung) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n\n\n\nüèãÔ∏è √Ñhnliche Fragen bleiben als √úbung f√ºr die Lesis. ü§ì\n\n\n8.6.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt f√ºr uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m_kung)\n## Priors for model 'm_kung' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden daf√ºr die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage f√ºr die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht ‚Äúpures Bayes‚Äù, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte w√§ren auch denkbar.\n\n\n\n\n\n\nStandardwerte von stan_glm\n\n\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (f√ºr \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals ‚ÄúStreuung‚Äù, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen. \\(\\square\\)\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu w√§hlen, dass man nicht √ºbergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlie√üen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflie√üen zu lassen und eigene Entscheidungen zu begr√ºnden. H√§ufig sind mehrere Entscheidungen m√∂glich. M√∂chte man lieber vorsichtig sein, weil man wenig √ºber den Gegenstand wei√ü, dann k√∂nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die ‚Äúschwachinformativ‚Äù ist, also nur wenig Priori-Information in das Modell einflie√üen l√§sst.\n\n\n\n\n8.6.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund f√ºr Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu z√§hlen hat. Au√üerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister pr√ºfen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier Durchf√ºhrungen (auch ‚ÄúKetten‚Äù engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist ‚Äúdumm gelaufen‚Äù. An dieser Stelle schauen wir uns die Ketten nicht n√§her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. M√∂chte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit, s. m_kung_1kette.\n\n\nCode\nm_kung_1kette &lt;- stan_glm(height ~ 1, \n                 data = kung_erwachsen, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m_kung_1kette)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m_kung_neue_prioris-unsere-priori-werte",
    "title": "8¬† Gauss-Modelle",
    "section": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte",
    "text": "8.7 Modell m_kung_neue_prioris: unsere Priori-Werte\nüì∫ Teil 2\nIm Modell m_kung haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflie√üen, in unserem zweiten Kung-Modell, m_kung_neue_prioris.\n\n8.7.1 m_kung_neue_prioris\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.8 Dieses Mal geben wir die Priori-Werte explizit an, Tabelle¬†8.2.\n\n\nCode\nm_kung_neue_prioris &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = kung_erwachsen)\nparameters(m_kung_neue_prioris)\n\n\n\n\n\n\nTabelle¬†8.2: Parameter von m_kung_neue_prioris mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482\nNormal (178 +- 20)\n\n\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in Tabelle¬†8.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige F√§higkeit im Studium. ü§ì\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m_kung und m_kung_neue_prioris! Was f√§llt Ihnen auf? Nichts? Gut! Tats√§chlich liefern beide Modelle sehr √§hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigerma√üen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gew√§hlt waren.\n\n\n\n\n8.7.2 Posteriori-Verteilung und Parameter plotten\nLeider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zur√ºck.\n\nüë®‚Äçüè´ B√∂ser Golem!\n\n\nü§ñ Beim n√§chsten Mal strenge ich mich mehr an!\n\nDaher m√ºssen wir die Ausgabe des Stan-Golemns erst in eine sch√∂ne Tabelle umwandeln:\n\n\nCode\nm_kung_neue_prioris_tibble &lt;-\n  as_tibble(m_kung_neue_prioris)\n\nhead(m_kung_neue_prioris_tibble)\n\n\n\n  \n\n\n\nAu√üerdem ist der Name der ersten Spalte eigentlich unzul√§ssig, da Spaltennamen in R nicht mit Sonderzeichen anfangen d√ºrfen (sondern mit Buchstaben). Daher m√ºssen wir den Namen mit ‚ÄúSamthandschuhen‚Äù anpacken. Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln m√ºssen, s. die folgende Syntax.\n\nMit {ggpubr}Mit {ggplot}\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  gghistogram(x = \"`(Intercept)`\")  # Aus dem Paket \"ggpubr\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nm_kung_neue_prioris_tibble |&gt; \n  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nAls Ausblick: Ein Vergleich mehrerer Priori-Werte w√§re auch n√ºtzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gew√§hlten Priori-Werte zu √ºberzeugen.\n\n\n8.7.3 Welche K√∂rpergr√∂√üen erwartet unser Modell\nBisher haben wir untersucht, wie die Verteilung der mittleren K√∂rpergr√∂√üen, \\(\\mu\\), laut unserem Modell aussehen k√∂nnte; wir haben uns also mit der Post-Verteilung von \\(\\mu\\) besch√§ftigt. Wir k√∂nnten aber auch an der Frage der Verteilung der tats√§chlichen K√∂rpergr√∂√üen, \\(h_i\\), laut Modell, interessiert sein: Wie gro√ü sind sie denn, die !Kung, laut unserem Modell?\nWie wir wissen, liefert unser Stan-Golem eine Stichproben-Postverteilung. Wenn wir das Ergebnisobjekt unserer Analyse, m_kung in eine Tabelle (Tibble) umwandeln und (die ersten paar Zeilen) betrachen, sehen wir diese Stichproben:\n\n\nCode\nm_kung |&gt; as_tibble() |&gt; head()\n\n\n\n  \n\n\n\nLaut unserem Modell sind die K√∂rpergr√∂√üen, \\(h_i\\), normalverteilt mit \\(\\mu\\) und \\(\\sigma\\). \\(\\mu\\) wird von Stan, der in Begriffen der Regressionsanalyse denkt, schn√∂de als (Intercept) bezeichnet. Wir k√∂nnten jetzt also f√ºr jede Zeile eine Normalverteilung berechnen. Und daraus zuf√§llig eine Zahl ziehen. Damit h√§tten wir dann unsere Verteilung von K√∂rpergr√∂√üen laut Modell. Diese Verteilung nennt man auch Posterior-Pr√§diktiv-Verteilung. Pr√§diktiv daher, weil sie die Werte der K√∂rpergr√∂√üen ‚Äúvorhersagt‚Äù.\nWir k√∂nnen uns diese Verteilung auch komfortabel von R ausgeben lassen, s. Abbildung¬†8.9.\n\nCode\npp_check(m_kung)\npp_check(m_kung, \"stat\")\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Die dunkle, dicke Dichtekurve zeigt die tats√§chliche Verteilung der K√∂rpergr√∂√üen im Datensatz. Die hellen, leichten Dichtekurven zeigen die Verteilungen laut der Post-Verteilung unseres Modells.\n\n\n\n\n\n\n\n\n\n\n\n(b) Der wahre Wert einer Test-Statistik (T), hier der Mittelwert der K√∂rpergr√∂√üen, wird mit der Verteilung der K√∂rpergr√∂√üen in Bezug gesetzt.\n\n\n\n\n\n\n\nAbbildung¬†8.9: Die Posterior-Pr√§diktiv-Verteilung: Die Verteilung der tats√§chlichen K√∂rpergr√∂√üen auf Basis der Post-Verteilung. Unser Modell stellt die tats√§chliche Verteilung ganz gut nach.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "8¬† Gauss-Modelle",
    "section": "8.8 Fazit",
    "text": "8.8 Fazit\n\n\n8.8.1 Zusammenfassung\nWir haben die Posteriori-Verteilung f√ºr ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Pr√§diktoren, betrachtet. Die Zielvariable, K√∂rpergr√∂√üe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. F√ºr \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung f√ºr \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n8.8.2 Botschaft von einem Statistiker\n\n\n\nüß° Bleiben Sie dran!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "href": "0800-gauss.html#vertiefung-wahl-der-priori-werte",
    "title": "8¬† Gauss-Modelle",
    "section": "8.9 Vertiefung: Wahl der Priori-Werte",
    "text": "8.9 Vertiefung: Wahl der Priori-Werte\nüèéÔ∏è Dieser Abschnitt ist eine VERTIEFUNG und nicht pr√ºfungsrelevant. üèé\n\n8.9.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\n\nüí≠ Was denkt der Golem (m_kung) apriori von der Gr√∂√üe der !Kung?\nü¶æ Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voil√†:\n\n\nCode\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MW¬±3SD\",\n       x = \"Gr√∂√üe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\n\n\n\n\nQuellcode\n\n\n8.9.2 Priori-Werte pr√ºfen mit der Priori-Pr√§diktiv-Verteilung\n\nDie Priori-Pr√§diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo k√∂nnen wir pr√ºfen, ob die Priori-Werte vern√ºnftig sind.\n\nDie Priori-Pr√§diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Gr√∂√üenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\n\nCode\nanteil_gro√üer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_gro√üer_kung\n\n\n\n  \n\n\n\nü§î Sehr gro√üe Buschleute? 17 Prozent sind gr√∂√üer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsl√§ufig ein schlechter Prior sein.\n\n\n8.9.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n\n\n\n\n8.9.4 Extrem vage Priori-Verteilung f√ºr die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\n\n\n\n\nDie Streuung der Gr√∂√üen ist weit:\n\n\nCode\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nü§î Das Modell geht apriori von ein paar Prozent Menschen mit negativer Gr√∂√üe aus. Ein Haufen Riesen üëπ werden auch erwartet.\nü§Ø Vage (flache, informationslose, ‚Äúneutrale‚Äù, ‚Äúobjektive‚Äù) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "8¬† Gauss-Modelle",
    "section": "8.10 Aufgaben",
    "text": "8.10 Aufgaben\n\n8.10.1 Papier-und-Bleistift-Aufgaben\n\n\nexp-tab\nexp-tab2\nnorms-sd\nsmall-wide-normal\nexp1\ndistros\nmtcars-post_paper\ngroesse03\npupil-size2\ngroesse04\nReThink4e2\nPriorwahl1\n\n\n\n8.10.2 Aufgaben, f√ºr die man einen Computer ben√∂tigt\n\nstan_glm01\nReThink4e1\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "8¬† Gauss-Modelle",
    "section": "8.11 ‚Äî",
    "text": "8.11 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#footnotes",
    "href": "0800-gauss.html#footnotes",
    "title": "8¬† Gauss-Modelle",
    "section": "",
    "text": "Der Einfachheit halber gehen wir davon aus, dass M√§nner und Frauen im Schnitt gleich gro√ü sind.‚Ü©Ô∏é\nBildquelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, 3.0‚Ü©Ô∏é\nDarum machen wir hier ja die ganz Show!‚Ü©Ô∏é\nDer Autor des zugrundeliegenden Lehrbuchs, Richard McElreath, gibt 178cm als seine K√∂rpergr√∂√üe an.‚Ü©Ô∏é\nHey, ich habe ihn diesen Namen nicht gegeben.‚Ü©Ô∏é\nm wie Modell und 4, weil das Modell in Kapitel 4 von McElreath (2020) in √§hnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.‚Ü©Ô∏é\naus dem R-Paket rstanam, das zuvor installiert und gestartet sein muss, bevor Sie den Befehl nutzen k√∂nnen‚Ü©Ô∏é\nHey Stan, los, an die Arbeit!‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html",
    "href": "0900-lineare-modelle.html",
    "title": "9¬† Einfache lineare Modelle",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "9¬† Einfache lineare Modelle",
    "section": "",
    "text": "9.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Post-Verteilung f√ºr einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder Streuungsma√üe und auch Sch√§tzintervalle - aus der Post-Verteilung herauslesen\nk√ºnftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4.\n\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\n\n\n\n9.1.5 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine √úbersicht aller Funktionen des Pakets.1\n\n\n9.1.6 Ben√∂tigte Daten\nIn diesem Kapitel ben√∂tigen wir den Datensatz zu den !Kung-Leuten, Howell1a, McElreath (2020). Sie k√∂nnen ihn hier herunterladen.\n Download \n\n\nCode\n1Kung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\n2kung &lt;- read.csv(Kung_path)\n\n3kung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\n\n\n1\n\nPfad zum Datensatz; Sie m√ºssen online sein, um die Daten herunterzuladen.\n\n2\n\nDaten einlesen\n\n3\n\nAuf Erwachsene Personen begrenzen (d.h. Alter &gt; 18)\n\n\n\n\n\n\n9.1.7 Einstieg\n\nBeispiel 9.1 (Grundkonzepte der linearen Regression) Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! \\(\\square\\)\n\n\nBeispiel 9.2 (Was ist eine Post-Verteilung und wozu ist sie gut?) Erkl√§ren Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. \\(\\square\\)\n\n\n\n9.1.8 √úberblick\nDieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die K√∂rpergr√∂√üe auf das Gewicht zur√ºckgef√ºhrt wird; also ein sehr eing√§ngiges Modell.\nNeu ist dabei lediglich, dass die Parameter des Modells - \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) - jetzt √ºber eine Post-Verteilung verf√ºgen. Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik. Die ‚Äúnormale‚Äù Regression hat uns nur einzelne Werte f√ºr die Modellparameter geliefert (‚ÄúPunktsch√§tzer‚Äù). Mit Bayes haben wir eine ganz Verteilung pro Parameter.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\nDie (einfache) Regression pr√ºft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenh√§ngen. Je mehr sie zusammenh√§ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). H√§ngen \\(X\\) und \\(Y\\) zusammen, hei√üt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).2\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X, UV) und Gr√∂√üe (Y, AV), Abbildung¬†9.1.\n\nCode\nkung_erwachsen %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\nCode\nggscatter(kung_erwachsen,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\") \n\n\n\n\n\n\nMit ggplot2Mit ggpubr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.1: Der Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y)\n\n\n\n\n\n9.2.2 Statistiken zum !Kung-Datensatz\nDie Daten k√∂nnen Sie hier herunterladen.\nTabelle¬†9.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path &lt;- \"data/Howell1a.csv\"  \nkung &lt;- read_csv(Kung_path)  \n\nkung_erwachsen &lt;- kung %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(kung_erwachsen)\n\n\n\n\n\n\nTabelle¬†9.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus Tabelle¬†9.1 abzulesen ist, betr√§gt das mittlere K√∂rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n\n9.2.3 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n9.2.3.1 Gibt es fehlende Werte?\nNein, s. Abb. Abbildung¬†9.2.\n\n\nCode\nkung_erwachsen %&gt;% plot_missing()\n\n\n\n\n\n\n\n\nAbbildung¬†9.2: Fehlende Werte - fehlen.\n\n\n\n\n\n\n\n9.2.3.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. Abbildung¬†9.3.\n\n\nCode\nkung_erwachsen %&gt;% plot_histogram()\n\n\n\n\n\n\n\n\nAbbildung¬†9.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. Abbildung¬†9.4.\n\n\nCode\nkung_erwachsen %&gt;% plot_bar()\n\n\n\n\n\n\n\n\nAbbildung¬†9.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n\n9.2.3.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in Abbildung¬†9.5 dargestellt.\n\n\nCode\nkung_erwachsen %&gt;% plot_correlation()\n\n\n\n\n\n\n\n\nAbbildung¬†9.5: Korrelationsmatrix\n\n\n\n\n\n\n√úbungsaufgabe 9.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(kung_erwachsen). \\(\\square\\)\n\n\n\n\n9.2.4 Pr√§diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor ‚Äúzentrieren‚Äù, engl. to center). Wenn man den Pr√§diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\beta_0\\), einfacher zu verstehen. In einem Modell mit zentriertem Pr√§diktor (weight) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. W√ºrde man weight nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman et al. (2021), Kap. 10.4, 12.2.\nMan zentriert eine Variable \\(X\\), indem man von \\(x_i\\) den Mittelwert \\(\\bar{x}\\) abzieht: \\(x_i - \\bar{x}\\).\n\n\nCode\nkung_zentriert &lt;-\n  kung_erwachsen %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\nMit Hilfe von center() aus {easystats} kann man sich das Zentrieren auch erleichtern.\n\n\nCode\nkung_zentriert &lt;- \n  kung_erwachsen %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\n‚àí9\n\n\n137\n32\n65\n0\n‚àí13\n\n\n\n\n\n\n\nWie man sieht, wird die Verteilung von weight durch die Zentrierung ‚Äúzur Seite geschoben‚Äù: Der Mittelwert von weight_c (das zentrierte Gewicht) liegt jetzt bei 0, s. Abbildung¬†9.6.\n\n\n\n\n\n\n\n\nAbbildung¬†9.6: Das Zentrieren √§ndert die Verteilungsform nicht, sondern ‚Äúschiebt‚Äù die Verteilung nur zur Seite\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass kung_zentriert die Tabelle mit zentriertem Pr√§diktor ist, nicht kung_erwachsen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-pr√§diktor",
    "href": "0900-lineare-modelle.html#modell-m_kung_gewicht_c-zentrierter-pr√§diktor",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.3 Modell m_kung_gewicht_c: zentrierter Pr√§diktor",
    "text": "9.3 Modell m_kung_gewicht_c: zentrierter Pr√§diktor\nüì∫ Pr√§diktoren zentrieren\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was w√§re wohl die K√∂rpergr√∂√üe? Hm, Philosophie steht heute nicht auf der Tagesordnung. Da w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m_kung_gewicht_c\nF√ºr jede Auspr√§gung des Pr√§diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung f√ºr die abh√§ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte f√ºr die Steigung \\(\\beta_1\\) und den Achsenabschnitt \\(\\beta_0\\) der Regressionsgeraden. Au√üerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Gr√∂√üe (height) angibt; dieser Wert wird als exponentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\). Theorem¬†9.1 stellt die Modelldefinition dar. ?fig-kruschke_regr_one_predctor zeigt, wie die drei Parameter zusammen die Likelihood definieren.\n\n\nTheorem 9.1 (Modelldefinition m_kung_gewicht_c) \\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}{\\beta_0} & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}{\\beta_1}  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\quad \\square\\]\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnitt (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ü§∑\n\n\n\n\n9.3.2 Likelihood, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m_kung_gewicht_c ist √§hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines ‚ÄúIndex-i‚Äù am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\n‚ÄúDie Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))‚Äù.\n\n\n\n9.3.3 Regressionsformel, m_kung_gewicht_c\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\beta_0 + \\beta_1\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\beta_0\\) und \\(\\beta_1\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der Pr√§diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\n‚ÄúDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\beta_0\\) und \\(\\beta_1\\) mal \\(\\text{weight}_i\\)‚Äù.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta_1\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\beta_0\\) gibt an, wie gro√ü \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n9.3.4 Priori-Werte des Modells m_kung_gewicht_c\n\\[\\begin{align*}\n\\color{blue}\\beta_1 & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta_1  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen. \\(\\beta_0\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine ‚ÄúRegression ohne Pr√§diktoren‚Äù berechnet haben. \\(\\sigma\\) ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel. Da height nicht zentriert ist, der Mittelwert von \\(\\beta_0\\) bei 178 und nicht 0. \\(\\beta_1\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist. Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.\n\n\n9.3.5 Prioris plus Daten gleich Post\n![Parameter ]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.4 Die Post-Verteilung befragen",
    "text": "9.4 Die Post-Verteilung befragen\nüì∫ Post-Verteilung auslesen 1\nüì∫ Post-Verteilung auslesen 2\n\n9.4.1 m_kung_starkes_beta1\nSagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. Gleichung¬†9.1. Dabei haben wir folgende Prioris gew√§hlt:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{9.1}\\]\nWir nennen das Modell m_kung_starkes_beta13, s. Listing¬†9.1.\n\n\n\nListing¬†9.1: Modelldefinition von m_kung_starkes_beta1 in R\n\n\n\n\nCode\nm_kung_starkes_beta1 &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # beta 0\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = kung_zentriert)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die Nachpr√ºfbarkeit der Ergebnisse (‚ÄúReproduzierbarkeit‚Äù) sichergestellt4. Welche Wert f√ºr seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung sch√§tzen.\n\n\n\n\n9.4.2 Mittelwerte von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. Tabelle¬†9.2.\n\n\n\nTabelle¬†9.2: Parameter von m_kung_starkes_beta1\n\n\n\nCode\nparameters(m_kung_starkes_beta1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 9.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also gr√∂√üer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) √Ñhnliches wie der p-Wert in der Frequentistischen Statistik (Makowski et al., 2019).\n\nAm besten das Diagramm dazu anschauen, s Abbildung¬†9.7.\n\n\nCode\nplot(p_direction(m_kung_starkes_beta1))\n\n\n\n\n\n\n\n\nAbbildung¬†9.7: Diagramm zur Probability of Direction, Modell m_kung_starkes_beta1\n\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) gr√∂√üer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter besch√§ftigen in diesem Kurs.\n\n\n9.4.3 Visualisieren der ‚Äúmittleren‚Äù Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). √úberzeugen wir uns mit einem Blick in die Post-Verteilung von m_kung_starkes_beta1:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n\n  \n\n\n\nWir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die ‚Äúmittlere‚Äù Regressionsgerade zu betrachten, s. Abbildung¬†9.8.\n\nCode\nkung_zentriert %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") |&gt; plot()  # aus {easystats}\n\n\n\n\n\nMit ggplotMit easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. Abbildung¬†9.8 (a). Mit ‚Äúexpectation‚Äù sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\n\n\n\n\n\n\n(a) Erwartete Werte des Modell m_kung_starkes_beta1, sprich, die Regressionsgerade\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.8\n\n\n\n\n\n9.4.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).5 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.\n\n9.4.4.1 Lagema√üe zu den Parametern\n\nWas ist die mittlere Gr√∂√üe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? (\\(\\beta_1\\))\nWas ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert f√ºr z.B: \\(\\beta_1\\)?\n\nEine n√ºtzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. Tabelle¬†9.2.\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m_kung_starkes_beta1, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm_kung_starkes_beta1_post &lt;- \n  m_kung_starkes_beta1 %&gt;% \n  as_tibble()\n\nm_kung_starkes_beta1_post %&gt;% \n  head()\n\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m_kung_starkes_beta1_post. Jetzt haben wir wieder eine sch√∂ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen k√∂nnen. Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. Abbildung¬†9.9.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung¬†9.9: Die Postverteilung f√ºr den Parameter Gewicht (zentriert); die plausiblen Werte liegen zwischen 0.8 und 1.0 cm pro Kilogramm Gewicht\n\n\n\n\n\nAbbildung¬†9.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. Abbildung¬†9.10.\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nAbbildung¬†9.10: Die Post-Verteilung f√ºr den Parameter sigma, m_kung_starkes_beta1; die plausiblen Werte liegen zwischen 4.7 cm und 5.5 cm.\n\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. Abbildung¬†9.11.\n\n\nCode\nm_kung_starkes_beta1_hdi &lt;- hdi(m_kung_starkes_beta1_post)  # analog mit eti(m_kung_starkes_beta1)\n\nplot(m_kung_starkes_beta1_hdi)\n\n\n\n\n\n\n\n\nAbbildung¬†9.11: Die Parameter Gewicht (zentriert) und sigma des Modells m_kung_starkes_beta1\n\n\n\n\n\nErg√§nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt. Den Parameter der Vorhersage-Genauigkeit, \\(\\sigma\\) bekommt man mit get_sigma:\n\n\nCode\nget_sigma(m_kung_starkes_beta1)\n## [1] 5.1\n## attr(,\"class\")\n## [1] \"insight_aux\" \"numeric\"\n\n\n\n\n\n9.4.5 Streuungsma√üe zu den Parametern\n\nWie unsicher sind wir uns in den Sch√§tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.\n\n\n\n\n9.4.6 Ungewissheit von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung visualisiert\nAbbildung¬†9.12 stellt die Ungewissheit der Post-Verteilung dar, in dem einige Stichproben aus der Post-Verteilung visualisiert werden.\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\nCode\nkung_zentriert %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m_kung_starkes_beta1_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\n1010010001000000\n\n\nDie ersten 10 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 100 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 10000006 ‚Ä¶ okay, lassen wir es gut sein7.\n\n\n\n\n\nAbbildung¬†9.12\n\n\n\nEinfacher ist die Visualisierung mit estimate_expectation, s. Abbildung¬†9.13.\n\n\nCode\nestimate_expectation(m_kung_starkes_beta1, by = \"weight_c\") %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildung¬†9.13: Sch√§tzbereich f√ºr die bedingten mittleren K√∂rpergr√∂√üe, also die Regressionsgerade mit Unsicherheitsintervall\n\n\n\n\n\n\n\n9.4.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe8.\n\n\n\nWelche mittlere Gr√∂√üe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht √ºberschritten?\nWelche mittlere Gr√∂√üe mit Wahrscheinlichkeit von 95% nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?\n\nQuantile:\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n  \n\n\n\n50%-PI:\n\n\nCode\nm_kung_starkes_beta1 %&gt;% \n  eti(ci = .5)\n\n\n\n  \n\n\n\n\n\n9.4.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?\n\n\nCode\nm_kung_starkes_beta1_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.29.\n\n\n9.4.9 Typischer Bayes-Nutzer in Aktion\n\n\n\n\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.5 Post-Verteilung bedingt auf einen Pr√§diktorwert",
    "text": "9.5 Post-Verteilung bedingt auf einen Pr√§diktorwert\n\n9.5.1 Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m_kung_post, s. Abbildung¬†9.14.\n\n\n\n\n\n\n\n\nAbbildung¬†9.14: F√ºr jeden beliebigen Pr√§diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgew√§hlten Gewichtswerten. Es ist jeweils die Wahrscheinlichkeitsverteilung f√ºr den vorhergesagten Y-Wert dargestellt (hier sind die Verteilungen zu gro√ü dargestellt zur besseren Sichtbarkeit). B: F√ºr jeden beliebigen Gewichtswert (Y) bekommt man eine (auf den jeweiligen X-Wert bedingten) Post-Verteilung.\n\n\n\n\n\n\n\n9.5.2 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?\nEtwas formaler ausgedr√ºckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 &lt;-\n  m_kung_gewicht_c_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. Abbildung¬†9.15.\n\n\nCode\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.15: Post-Verteilung der Gr√∂√üe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\n\nAnalog k√∂nnen wir fragen, wie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.\n50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. Tabelle¬†9.3.\n\n\nCode\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\nTabelle¬†9.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren Gr√∂√üe bei einem Gewicht von 50kg ist weiter ‚Äúrechts‚Äù (Richtung h√∂here Gr√∂√üe) zentriert, s. Abbildung¬†9.16.\n\n\nCode\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†9.16: Post-Verteilung der mittleren Gr√∂√üe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n\n9.5.3 Lagema√üe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der K√∂rpergr√∂√üe.\nWas ist das 90% PI f√ºr \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %&gt;% \n  eti(ci = .9)\n\n\n\n  \n\n\n\nDie mittlere Gr√∂√üe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#fazit",
    "href": "0900-lineare-modelle.html#fazit",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.6 Fazit",
    "text": "9.6 Fazit\n\n9.6.1 Ausstieg\n\nBeispiel 9.3 (Fassen Sie das Wesentliche zusammen!) Schreiben Sie 5-10 S√§tze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! \\(\\square\\)\n\n\n\n9.6.2 Vertiefung\nMcElreath (2020) bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. Kurz (2021) greift die R-Inhalte von McElreath (2020) auf und setzt sie mit Tidyverse-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen m√∂chte. Gelman et al. (2021) bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einer frequentistischen als auch aus einer Bayes-Perspektive.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.7 Aufgaben",
    "text": "9.7 Aufgaben\n\n9.7.1 Papier-und-Bleistift-Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nmtcars-post2a\nBed-Post-Wskt1\nmtcars-post3a \nregression1a\nregression1b\nRegression2\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\nLikelihood2\ninterpret-koeff\nbed-post-wskt1\n\n\n\n9.7.2 Computer-Aufgaben\n\nPost-befragen1\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-4",
    "href": "0900-lineare-modelle.html#section-4",
    "title": "9¬† Einfache lineare Modelle",
    "section": "9.8 ‚Äî",
    "text": "9.8 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKurz, S. (2021). Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#footnotes",
    "href": "0900-lineare-modelle.html#footnotes",
    "title": "9¬† Einfache lineare Modelle",
    "section": "",
    "text": "Da es viele Funktionen sind, bietet es sich an mit Strg-F auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.‚Ü©Ô∏é\n Datenquelle, McElreath (2020).‚Ü©Ô∏é\nWer ist hier f√ºr die Namensgebung zust√§ndig? Besoffen oder was?‚Ü©Ô∏é\noder zumindest besser sichergestellt‚Ü©Ô∏é\nIn manchen Lehrb√ºchern wird \\(\\beta_0\\) auch als \\(\\alpha\\) bezeichnet.‚Ü©Ô∏é\n1e6‚Ü©Ô∏é\nIm Standard beschert uns stan_glm() 4000 Stichproben.‚Ü©Ô∏é\n\\(\\mu\\)‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html",
    "href": "1050-Schaetzen-Testen.html",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "10.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen‚Ä¶\n\nden Unterschied zwischen dem Sch√§tzen von Modellparametern und dem Testen von Hypothesen erl√§utern\nVor- und Nachteile des Sch√§tzens und Testens diskutieren\nDas ROPE-Konzept erl√§utern und anwenden\nDie G√ºte von Regressionsmodellen einsch√§tzen und berechnen\n\n10.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an Kruschke (2018).\n\n10.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 2‚Äù\n\n10.1.5 R-Pakete\nIn diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n10.1.6 Ben√∂tigte Daten: Pinguine\nWir ben√∂tigen in diesem Kapitel den Datensatz zu Pinguinen: penguins.\nSie k√∂nnen den Datensatz penguins entweder via dem Pfad importieren.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \nOder via dem zugeh√∂rigen R-Paket.\n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\nBeide M√∂glichkeit sind okay.\n\n10.1.7 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\n‚ÄúLernen f√ºr die Klausur bringt etwas!‚Äù\n‚ÄúWie viel bringt Lernen f√ºr die Klausur?‚Äù\n\n\nBeispiel 10.1 Diskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sch√§tzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#sch√§tzen-oder-testen",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.2 Sch√§tzen oder Testen?",
    "text": "10.2 Sch√§tzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen testen: ‚ÄúDie Daten widerlegen die Hypothese (nicht)‚Äù\n\nParameter sch√§tzen: ‚ÄúDer Effekt von X auf Y liegt zwischen A und B‚Äù.\n\n\n10.2.1 Hypothesen testen\nHypothesen testende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 10.2 (‚ÄúLernen erh√∂ht den Pr√ºfungserfolg‚Äù) Die Hypothese Lernen erh√∂ht den Pr√ºfungserfolg kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. \\(\\square\\)\n\nDas Testen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\nüü• Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.\nüü¢ Die Daten unterst√ºtzen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.\n‚ùì Die Datenlage ist unklar; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen pr√ºfen ist bin√§r in dem Sinne, dass sie zu ‚ÄúSchwarz-Wei√ü-Ergebnissen‚Äù f√ºhren (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine g√§ngige Variante des Hypothesen testen1 ist das Testen der Hypothese ‚Äúkein Effekt‚Äù (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n10.2.2 Beispiele f√ºr Nullhypothesen\n\n‚ÄúLernen bringt nichts‚Äù\n‚ÄúFrauen und M√§nner parken gleich schnell ein‚Äù\n‚ÄúEs gibt keinen Zusammenhang von Babies und St√∂rchen‚Äù\n‚ÄúFr√ºher war es auch nicht besser (sondern gleich gut)‚Äù\n‚ÄúBei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern‚Äù (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterst√ºtzen kann, da es die Komplexit√§t reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht best√§tigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann, hat gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt (Popper, 2013). Schlagend ist das Beispiel zur Hypothese ‚ÄúAlle Schw√§ne sind wei√ü‚Äù. Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. Schlie√ülich ist es m√∂glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben. 2 Umgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverl√§ssiger, repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als auch widerlegt werden k√∂nnen (Kruschke, 2018; Morey & Rouder, 2011). \\(\\square\\)\n\n\n\n10.2.3 Parameter sch√§tzen\nBeim Parameter sch√§tzen untersucht man, wie gro√ü ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein ‚Äúja/nein‚Äù, was beim Hypothesen testen der Fall ist.\nBeim Parameter sch√§tzen gibt es zwei Varianten:\n\n‚ö´Ô∏è Punktsch√§tzung: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein ‚ÄúBest Guess‚Äù\nüìè Bereichssch√§tzung: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Sch√§tzen von Parameterns auch wie einen Hypothesentest verstehen: Ist ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 10.3 Wie gro√ü ist der Sch√§tzbereich f√ºr den Effekt des Parameter ‚ÄúGeschlecht‚Äù auf das Gewicht von Pinguinen? Anders gefragt: Um welchen Wert sind m√§nnliche Tiere im Schnitt schwerer als weibliche Tiere?\n\nCodedata(penguins, package = \"palmerpenguins\")\npenguins_nona &lt;-\n  penguins |&gt; drop_na(sex, body_mass_g)  # keine fehlenden Werte\n\nm_penguins_sex &lt;- \n  stan_glm(body_mass_g ~ sex, data = penguins_nona)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3862.94\n(3757.82, 3969.47)\n100%\n1.000\n4246\nNormal (4207.06 +- 2013.04)\n\n\nsexmale\n682.94\n(528.12, 833.63)\n100%\n1.000\n4468\nNormal (0.00 +- 4020.19)\n\n\n\n\n\nGrob gesagt sind m√§nnliche Tiere ca. 500 g bis 800 g schwerer als weibliche Tiere im Schnitt, laut unserem Modell. \\(\\square\\)\n\n\nBeispiel 10.4 (Parametersch√§tzen als Nullhypothesentest) ¬†\n\nForschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nTheorem¬†10.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\nTheorem 10.1 (Nullhypothesentest) \\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0\\quad \\square\\]\n\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nCodem1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\n\nDann z√§hlen wir einfach den Anteil der Stichproben in der Post-Verteilung f√ºr die UV sexmale, die einen Wert gr√∂√üer Null aufweisen:\n\nCodem1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr sexmale, dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht (das weibliche Tiere schwerer w√§ren). Damit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der Parametersch√§tzung ist die Nuanciertheit des Ergebnisses, die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.3 ROPE: Bereich von ‚Äúpraktisch Null‚Äù",
    "text": "10.3 ROPE: Bereich von ‚Äúpraktisch Null‚Äù\nüì∫ Teil 2\nNullhypothesen sind fast immer falsch, s. Abbildung¬†10.1.\n\n\n\n\n\n\n\nAbbildung¬†10.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman et al., 2021)\n\n\n10.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest m√∂glich ist.3\nEin anderer Grund ist vermutlich, ‚Ä¶ wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke, 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n10.3.2 ‚ÄúPraktisch‚Äù kein Unterschied: Das Rope-Konzept\nüì∫ ROPE-Video\n\nBeispiel 10.5 (Beispiele f√ºr ROPE) Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens \\(d=100\\)‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als ‚Äúpraktisch gleich‚Äù, ‚Äúpraktisch kein Unterschied‚Äù bzw. vernachl√§ssigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g ‚Äúvernachl√§ssigbar wenig‚Äù ist.\nEine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umsatzunterschied von 100k Euro ‚Äúpraktisch irrelevant‚Äù sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese (bzw. ‚ÄúPraktisch-Null-Hypothese‚Äù): \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt pr√ºfen wir, ob ein ‚ÄúGro√üteil‚Äù der Posteriori-Stichproben im Rope liegt. Unter ‚ÄúGro√üteil‚Äù wird h√§ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGro√üteil liegt innerhalb von Rope \\(\\rightarrow\\) Annahme der Nullhypothese ‚Äúpraktisch kein Effekt‚Äù, \\(H_0\\)\n\nGro√üteil liegt au√üerhalb von Rope \\(\\rightarrow\\) Ablehnung der Nullhypothese ‚Äúpraktisch kein Effekt‚Äù, \\(H_0\\)\n\nAnsonsten \\(\\rightarrow\\) keine Entscheidung\n\nMit ‚ÄúGro√üteil‚Äù meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n10.3.3 Vernachl√§ssigbarer Regressionseffekt\nKruschke (2018) schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als ‚Äúpraktisch Null‚Äù zu bezeichnen:\nWenn eine Ver√§nderung √ºber ‚Äúpraktisch den ganzen Wertebereich‚Äù von \\(x\\) nur einen vernachl√§ssigbaren Effekt auf \\(y\\) hat. Ein vernachl√§ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der ‚Äúpraktisch ganze Wertebereich‚Äù von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Ver√§nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) f√ºr z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±5% der SD der AV. \\(\\square\\)\n\n\n\n10.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildung¬†10.2: Die Entscheidungsregeln zum ROPE illustiert (Kruschke, 2018).\n\n\n\n\nAbbildung¬†10.2 illustriert die Entscheidungsregel zum ROPE f√ºr mehrere Situationen (Kruschke, 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.\n\n10.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (m_penguins_species).\n\nCodem_penguins_species &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\n\nDen Rope berechnet man mit rope(model).\n\nCoderope(m_penguins_species)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir k√∂nnen daher f√ºr diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.\nAber: Gentoo liegt zu 0% im Rope. F√ºr Gentoo k√∂nnen wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®\n\n10.3.6 Visualisierung unserer Rope-Werte, m_penguins_species\nEin Gro√üteil der Posteriori-Masse von m_penguins_species liegt nicht innerhalb des Rope. Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. Abbildung¬†10.3.\n\nCoderope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m_penguins_species) %&gt;% plot()\n\n\n\n\n\n\nAbbildung¬†10.3: Rope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die ‚ÄúBerge‚Äù der Posteriori-Verteilung f√ºr Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir k√∂nnen das Nullhypothese f√ºr Chinstrap nicht verwerfen, aber auch nicht best√§tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom ‚Äúblauen Fluss‚Äù des Rope: Gentoo liegt au√üerhalb des Rope. Es gibt einen ‚Äúsubstanziellen‚Äù Unterschied, gr√∂√üer als das ROPE. Wir verwerfen die ‚ÄúPraktisch-Null-Hypothese‚Äù in diesem Fall.\n\n10.3.7 Finetuning des Rope\nWir k√∂nnen festlegen, was wir unter ‚Äúpraktischer √Ñquivalenz‚Äù verstehen, also die Grenzen des Ropes ver√§ndern. Sagen wir, 100 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. Abbildung¬†10.4.\n\nCoderope(m_penguins_species, range = c(-100, 100))\nplot(rope(m_penguins_species, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†10.4: ROPE mit selber eingestellter Grenze von ¬±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:\n\nCoderope(m_penguins_species, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht f√ºr ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n10.3.8 Beantwortung der Forschungsfrage\nF√ºr die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. F√ºr Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellg√ºte",
    "href": "1050-Schaetzen-Testen.html#modellg√ºte",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.4 Modellg√ºte",
    "text": "10.4 Modellg√ºte\n\n10.4.1 Wozu Modellg√ºte?\nHat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, m√∂chte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. Diese Kennwerte zielen z.B. darauf ab, wie pr√§zise die Aussagen des Modells sind. Je pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich. Bei einer Parametersch√§tzung erh√§lt man auch Informationen zur Pr√§zision der Sch√§tzung: Ist der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa). Allerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n10.4.2 Modellg√ºte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt. - H√∂here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erkl√§rt. \\(R^2\\) wird normalerweise auf Basis eines Punktsch√§tzers definiert. Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor. Daher ist es w√ºnschenswert, diese Information in \\(R^2\\) einflie√üen zu lassen: Bayes-R-Quadrat.\nM√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R^22\\) ausgeben lassen, s. Abbildung¬†10.5.\n\nCodem_penguins_species_r2 &lt;-\n  m_penguins_species %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m_penguins_species_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung¬†10.5: Die Verteilung von R-Quadrat im Modell m_penguins_species\n\n\n\n\n\\(R^2\\) und \\(\\sigma\\) sind negativ assoziert: In einem Datensatz mit mit hohem \\(R^2\\) ist \\(\\sigma\\) gering und umgekehrt. Beide Koeffizienten berechen sich auf Basis der Vorhersagefehler.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.5 Fazit",
    "text": "10.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. M√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "\n10.6 Aufgaben",
    "text": "10.6 Aufgaben\n\n10.6.1 Papier-und-Bleistift-Aufgaben\n\nrope-luecke\npenguins-rope\nWskt-Schluckspecht2\npenguins-stan-01a\nrope-regr\nrope1\nrope2a\nrope3a\npenguins-stan-04a\nstan_glm01a\npenguins-regr02a\npenguins-stan-02a\npenguins-stan-05a\n\n10.6.2 Computer-Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope2\nrope3\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter Values in Bayesian Estimation. Advances in Methods and Practices in Psychological Science, 1(2), 270‚Äì280. https://doi.org/10.1177/2515245918771304\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes Factor Approaches for Testing Interval Null Hypotheses. Psychological Methods, 16(4), 406‚Äì419. https://doi.org/10.1037/a0024377\n\n\nPopper, K. (2013). Logik Der Forschung (H. Keuth, Hrsg.). Akademie Verlag. https://doi.org/10.1524/9783050063782",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#footnotes",
    "href": "1050-Schaetzen-Testen.html#footnotes",
    "title": "\n10¬† Sch√§tzen vs.¬†Testen\n",
    "section": "",
    "text": "vor allem in der Frequentistischen Statistik‚Ü©Ô∏é\nTats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan‚Ü©Ô∏é\nMittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.‚Ü©Ô∏é\n89 ist die n√§chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. Damit ist 95 hier eine ‚Äúmagic number‚Äù, ein Defacto-Standard ohne hinreichende Begr√ºndung. Um darauf hinzuweisen, benutzen einige Forschis mit √§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Sch√§tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html",
    "href": "1000-metrische-AV.html",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "",
    "text": "11.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen‚Ä¶\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme √ºbersetzen\ntypische Forschungsfragen auswerten\n\n11.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman et al. (2021), Kap. 7 und 10.\n\n11.1.4 Vorbereitung im Eigenstudium\nFrischen Sie Ihr Wissen in den Grundlagen der einfachen und multiplen Regression (inkl. Interaktionseffekte) auf. Dazu sind z.B. folgende Literaturstellen geeignet.\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\nStatistik1, Kap. ‚ÄúGeradenmodelle 2‚Äù\n\n11.1.5 R-Pakete\nIn diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.\n\nCodelibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n11.1.6 Ben√∂tigte Daten\nWir ben√∂tigen in diesem Kapitel folgende Datens√§tze: kidiq, penguins.\n\n11.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\nCodedata(\"kidiq\", package = \"rstanarm\")\n\n\nAlternativ k√∂nnen Sie die Daten hier herunterladen.\n Download \n\n11.1.6.2 penguins\n\nSie k√∂nnen den Datensatz penguins entweder via dem Pfad importieren oder via dem zugeh√∂rigen R-Paket. Beide M√∂glichkeit sind okay.\n\nCodepenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n\n Download \n\nCodedata(\"penguins\", package = \"palmerpenguins\")\n\n\n\n11.1.7 Einstieg\n\nBeispiel 11.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, m√ºssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 11.2 (Was war noch einmal die Interaktion?) Erk√§ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n11.1.8 √úberblick\nWenn Sie die Skalenniveaus wissen, k√∂nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und √§hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, ‚Ä¶) lernen m√ºssen. Au√üerdem ist die Regressionsanalyse (f√ºr viele Situationen) die beste Heransgehensweise, da sie viele M√∂glichkeiten f√ºr Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels g√§ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. Nat√ºrlich w√ºrzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-K√ºche. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "href": "1000-metrische-AV.html#taxonomie-von-forschungsfragen",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.2 Taxonomie von Forschungsfragen",
    "text": "11.2 Taxonomie von Forschungsfragen\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus. Im Folgenden sind f√ºr die UV(s) nominale sowie metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind ebenfalls erlaubt.\nWir untersuchen in diesem Kapitel h√§ufig verwendete Arten von Forschungsfragen mittels Regressionsanalysen. F√ºr jede Variante ist zumeist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abh√§ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabh√§ngige Variable (querschnittlich)\n\nb: bin√§re Variable\n\nx: metrische unabh√§ngige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-b",
    "href": "1000-metrische-AV.html#y-b",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.3 y ~ b\n",
    "text": "11.3 y ~ b\n\n\n11.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im √∂ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufw√§ndigen Studie die Intelligenz vieler Kinder gemessen. Zus√§tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, ‚ÄúRisikofaktoren‚Äù f√ºr geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nIst der mittlere IQ-Wert (kid_score) von Kindern, deren jeweilige Mutter √ºber einen Schlusabschluss (mom_hs, \\(x=1\\)) verf√ºgt h√∂her, als bei Kinderen, deren jeweilige Mutter nicht √ºber einen Schulabschluss verf√ºgt (\\(x=0\\))? (ceteris paribus)4.\n\nDie Modellformel zur Forschungsfrage lautet: y ~  b bzw. kid_iq ~ mom_hs.\nFormaler ausgedr√ºckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (Theorem¬†11.1).\n\nTheorem 11.1 (Hypothese f√ºr ungleiche Mittelwerte) \\[H_A: \\mu_{x=0|M} \\ne \\mu_{x=1|M}\\quad \\square\\]\n\nIn Worten: ‚ÄúDer mittlere IQ-Wert f√ºr Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen ist h√∂her als in der Gruppe von Kindern, deren M√ºtter √ºber keinen Schulabschluss verf√ºgen‚Äù. Zu beachten ist, dass sich eine Population immer auf Parameterwerte bezieht, also auf die Population, nicht auf die Statistiken der Stichprobe.\nDie zugeh√∂rige Nullhypothese lautet:\n\\[H_0: \\mu_{x=1|M} = \\mu_{x=0|M}\\quad \\square\\]\n\n11.3.2 Modell\nDie Regressionsformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in Abbildung¬†11.1 dargestellt. Y hat, laut unserem Modell, zwei Ursachen:\n\nmom_hs (b)\nu, das steht f√ºr ‚Äúunbekannt‚Äù5\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.1: DAG f√ºr kid_iq ~ mom_hs\n\n\n\n\n\nCodedata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nDer Einfachheit halber √ºbernehmen wir die Prioriwerte von Stan, s. Listing¬†11.1.\n\n\n\nListing¬†11.1: Standard-Prioriwerte f√ºr m10.1, von Stan vergeben\n\nCodeprior_summary(m10.1)\n## Priors for model 'm10.1' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 87, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 87, scale = 51)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = 0, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 0, scale = 124)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.049)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\n\n\nDie komplette Modellspezifikation ist in Gleichung¬†11.1 aufgef√ºhrt.\n\\[\\begin{align*}\n\\text{kid score}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) && \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\cdot \\text{mom hs}_i && \\text{Lineares Modell} \\\\\n\\beta_0 &\\sim \\operatorname{Normal}(87, 51) && \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim \\operatorname{Normal}(0, 124) && \\text{Prior Regressionsgewicht} \\\\\n\\sigma &\\sim \\operatorname{Exp}(0.049) && \\text{Prior Vorhersageg√ºte}\n\\end{align*} \\tag{11.1}\\]\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. Tabelle¬†11.1.\n\n\n\nTabelle¬†11.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt, da meistens nicht von hohem Interesse)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\n\n11.3.3 Interpretation der Koeffizienten\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren M√ºtter √ºber keinen Schulabschluss (mom_hs = 0) verf√ºgen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit M√ºtter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit M√ºtter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die Sch√§tzung (Vorhersage) ist bzw. wie stark Pr√§diktor (UV) und Kriterium (AV) zusammenh√§ngen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tats√§chlichen IQ-Wert des Kindes (\\(y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n11.3.4 y ~ g als Mittelwertsdifferenz\nEin lineares Modell der Art y ~ g kann man als Berechnung des Unterschieds im Mittelwert von y zwischen beiden Gruppen (g0 vs.¬†g1) verstehen.\n\nüë®‚Äçüè´ Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll hei√üen kid_score_avg. An die Arbeit!\n\n\nü§ñ Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nCodekidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von M√ºttern mit Abschluss.\n\n\n\nIn Abbildung¬†11.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt, auf Basis des Datensatzes kidiq.\n\nCodeestimate_relation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nAbbildung¬†11.2: Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen, haben im Mittel einen h√∂heren Intelligenztestwert, laut dem vorliegenden Modell. Die Regressionsgerade ist als durchgezogene Linie dargestellt. Die Mittelwerte pro Gruppe als Punkte und als gestrichelte, horizontale Linie.\n\n\n\n\n\n11.3.5 Rope\nPr√ºfen wir mit rope(m10.1), ob der Effekt der UV (Unterschied zwischen den Gruppen) ‚Äúpraktisch Null‚Äù ist; dazu nutzen wir das ROPE-Verfahren.\n\nCoderope(m10.1)\n\n\n\n\n\n\n\n\n\n\nDas Ergebnis zeigt uns, dass es 0% √úberlappung vom Rope und dem 95%-HDI (der Posterior-Verteilung) gibt.\nFazit: Wir verwerfen die Praktisch-Null-Hypothese. Adios! Abbildung¬†11.3 visualisiert die Erstreckung der Posteriori-Verteilung (und des 95%-HDI) sowie des Rope.\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.1) %&gt;% plot()\n\n\n\n\n\n\nAbbildung¬†11.3: Rope und HDI √ºberlappen nicht. Wir verwerfen die Praktisch-Null-Hypothese.\n\n\n\n11.3.6 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation ‚Äì Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das pr√ºft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nAlternativ zum t-Test kann man ‚Äì unabh√§ngig, ob man Frequentistisch oder Bayesianisch unterwegs ist ‚Äì mit einer Regression vom Typ y ~ b das in etwa gleiche Ergebnis erreichen.7\n\n11.3.7 Antwort auf die Forschungsfrage\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nCodem10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # sch√∂nere Namen\n\n\n\n\nHier sind die ersten paar Zeilen, s. Tabelle¬†11.2.\n\n\n\nTabelle¬†11.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n76.1\n12.8\n19.7\n\n\n72.9\n17.5\n20.5\n\n\n79.0\n11.7\n20.5\n\n\n75.7\n13.7\n20.6\n\n\n77.0\n12.6\n20.0\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir zur √úbung ein 95%-PI von Hand; komfortabler geht es mit eti(m10.1), s. Tabelle¬†11.1.\n\nCodepi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlie√üend die Posteriori-Verteilung, s. Abbildung¬†11.4.\n\nCodeplot(eti(m10.1))\n\n\n\n\n\n\nAbbildung¬†11.4: Das 95% ETI zum (statistischen) Effekt des m√ºtterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem ‚ÄúEffekt‚Äù zu sprechen, l√§sst in den meisten K√∂pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang. F√ºr eine Kausalaussage braucht man ein Argument, etwa einen Verweis auf bestehende Studien oder eine Theorie.\n\n\n\n\n\n\n\n\n\n\n11.3.8 Vertiefung: Toleranzbereich\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\nBerechnet man ein Regressionsmodell mit stan_glm (ü§ñüòÅ), dann zieht man dabei Zufallszahlen üé≤. Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zuf√§llig. Das erkl√§rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen k√∂nnen.\nUm zu pr√ºfen, ob Ihre Ergebnisse ‚Äú√§hnlich genug‚Äù oder ‚Äúinnerhalb eines Toleranzbereichs‚Äù sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nGr√∂√üe des Toleranzbereichs\n\n\n\nDie Gr√∂√üe des relativen Toleranzbereichs ist in is_in_toleranzce() auf 5% festgelegt. Das hei√üt, ein Unterschied von 5% zwischen einem Referenzwert (dem ‚Äúwahren‚Äù Wert) und Ihrem Wert ist okay, also im Toleranzbereich. Au√üerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der gr√∂√üere der beiden Werte gilt. \\(\\square\\)\n\n\nWenn Sie diese Funktion nutzen wollen, m√ºssen Sie zun√§chst das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN) und dann wie gewohnt starten.\n\nCodelibrary(remotes)  # dieses Paket k√∂nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\nlibrary(prada)\n\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der ‚Äúrichtige‚Äù oder ‚Äúwahre‚Äù Wert (oder schlicht der Wert einer Musterl√∂sung) f√ºr \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nCodeis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. ‚úÖ",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b",
    "href": "1000-metrische-AV.html#y-x-b",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.4 y ~ x + b\n",
    "text": "11.4 y ~ x + b\n\n\n11.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b bzw. kid_score ~ mom_iq + mom_hs.\nDie Hypothesen lauten:\n\nDer Schulabschluss der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momhs} &gt; 0\\).\nDer IQ der Mutter hat einen positiven Effekt auf den IQ des Kindes: \\(\\beta_{momiq} &gt; 0\\).\n\nDer Kausalgraph8 zur Modellformel sieht aus in Abbildung¬†11.5 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) Einfl√ºsse, b und u, wobei u f√ºr ‚Äúunbekannt‚Äù steht, also f√ºr alle sonstigen Einfl√ºsse.9\n\n\n\n\n\n\n\nAbbildung¬†11.5: DAG f√ºr y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle Tabelle¬†11.3 dargestellt.\n\nCodedata(\"kidiq\")  # Paket rstanarm, alternativ √ºber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\nTabelle¬†11.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n11.4.2 1 metrischer Pr√§diktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. Tabelle¬†11.4.\n\nCodem10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\n\nTabelle¬†11.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. Abbildung¬†11.6.\n\nCodekidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildung¬†11.6: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. Abbildung¬†11.7.\n\nCodeplot(estimate_relation(m10.2))\n\n\n\n\n\n\nAbbildung¬†11.7: Die gesch√§tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder f√ºr verschiedene IQ-Werte der M√ºtter. Vergleicht man Teilpopulationen von M√ºttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n11.4.3 Beide Pr√§diktoren, m10.3\n\nBerechnen wir als n√§chstes ein Modell mit beiden Pr√§diktoren: kid_score ~ mom_hs + mom_iq, s. Tabelle¬†11.5.\n\nCodem10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\nTabelle¬†11.5: Parameter des Modells m10.3 (ohne sigma; ETI-Intervalle)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktsch√§tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\nCodecoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##       25.74        0.57        6.04\n\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nM√∂chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\nCodecoef(m10.3)[3]\n## mom_hs \n##      6\n\n\nAber nat√ºrlich ist es m√∂glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. Abbildung¬†11.8.\n\nCodekidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\npred &lt;- estimate_relation(m10.3a)\nplot(pred)\n\n\n\n\n\n\nAbbildung¬†11.8: Der Effekt von sowohl m√ºtterlicher Intelligenz als auch m√ºtterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann sch√§tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum m√ºtterlichen Schulabschluss: Vergleicht man Kinder von M√ºttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur m√ºtterlichen IQ: Vergleicht man Kinder von M√ºttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n11.4.4 Antwort auf die Forschungsfrage\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 1.6 bis 10.1 IQ-Punkten, laut unserem Modell. Der Effekt des m√ºtterlichen IQs wird auf 0.5 bis 0.7 gesch√§tzt (95%-ETI). Da f√ºr beide UV die Null nicht im Intervall plausibler Werte liegt, kann ein Null-Effekt (die exakte Nullhypothese) abgelehnt werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b-xb",
    "href": "1000-metrische-AV.html#y-x-b-xb",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.5 y ~ x + b + x:b\n",
    "text": "11.5 y ~ x + b + x:b\n\n\n11.5.1 Forschungsfrage und Modelldefinition\n\nGibt es einen Interaktionseffekt zwischen m√ºtterlichem Schulabschluss und m√ºtterlichem IQ (auf den IQ-Wert des Kindes)?\n\nAu√üerdem ist man vermutlich auch an den Effekten der beiden UV auf die AV interessiert; diese Fragen haben wir im letzten Abschnitt untersucht (und greifen sie daher nicht noch mal ausf√ºhrlich auf).\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b. Der Einfachheit halber √ºbernehmen wir wieder die Prioris wie vom R-Paket rstanarm bereitgestellt.\nDer DAG zur Modellformel sieht aus in Abbildung¬†11.9 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†11.9: DAG f√ºr y ~ x + b + x:b\n\n\n\n\n\n11.5.2 Interaktion zur Modellformel hinzuf√ºgen\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. Listing¬†11.2, Abbildung¬†11.10 und Tabelle¬†11.6.\n\n\n\nListing¬†11.2: Die Modelldefition von m10.4 mit stanglm\n\nCodem10.4 &lt;- \n  stan_glm(kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\nIn der Regressionsformel sieht man, dass ein zus√§tzlicher Parametern, eben der Interaktionseffekt, in das Modell aufgenommen wurde.\n\n\n\nTabelle¬†11.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.68\n(-37.44, 15.92)\n77.12%\n1.000\n1338\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.000\n1340\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n50.36\n(21.58, 80.70)\n99.98%\n1.001\n1311\nNormal (0.00 +- 124.21)\n\n\nmom_iq:mom_hs\n-0.47\n(-0.79, -0.17)\n99.88%\n1.001\n1293\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_relation(m10.4) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung¬†11.10.\n\n\n\n\n\n\n\nAbbildung¬†11.10: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt f√ºr diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n11.5.3 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Sch√§tzwerte f√ºr Kinder mit M√ºtter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit M√ºttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten f√ºr mom_iq zwischen M√ºtter mit bzw. ohne Schulabschluss.\nF√ºr beide Gruppen, mom_hs=0 und mom_hs=1 gilt folgende Regressionsformel, s. Gleichung¬†11.2.\n\\[\\text{kid score} = \\beta_0 + \\beta_1 \\cdot \\text{mom hs} + \\beta_2 \\cdot \\text{mom iq} + \\beta_3 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.2}\\]\n\\(\\beta_3\\) gibt die St√§rke des Interaktionseffekts an.\nAuf Errisch schreibt mit Gleichung¬†11.2 so (s. Listing¬†11.2):\nkid_score ~ mom_iq + mom_hs + mom_hs:mom_iq.\nDer Doppelpunkt zwischen mom_hs und mom_iq steht f√ºr den Interaktionseffekt der beiden Variablen.\nTr√§gt man die Werte der Koeffizienten (\\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\)) ein, so erh√§lt man Gleichung¬†11.3.\n\\[\\text{kid score} = -10.7 + 50.4 \\cdot \\text{mom hs} + 1  \\cdot \\text{mom iq} + -0.5 \\cdot \\text{mom hs} \\cdot \\text{mom iq} \\tag{11.3}\\]\nTeilen wir die Regressionsformel einmal auf die beiden Gruppen (mom_hs=0 bzw. mom_hs=1) auf:\nmom_hs=0:\nkid_score = -10.7 + 50.4*0 + 1*mom_iq  - -0.5*0*mom_iq\n          = -10 + 1.1*mom_iq\nmom_hs=1:\nkid_score = -10.7 + 50.4*mom_hs + 1*mom_iq  - -0.5*mom_hs*mom_iq\n          = -10 + 1.1*mom_iq\nNach der Interpretation von 20 unzentrierten Koeffizienten ‚Ä¶\n\n\n\nvia GIPHY\n\nWir m√ºssen dringend die unzentrierten Pr√§diktoren loswerden ‚Ä¶\n\n11.5.4 Antwort auf die Forschungsfrage\nWie in Tabelle¬†11.6 ersichtlich, kann f√ºr alle drei Effekte (m√ºtterliche IQ, m√ºtterlicher Schulabschluss und Interaktion von m√ºtterlichem IQ mit m√ºtterlichem Schulabschluss) ein Nulleffekt ausgeschlossen werden. Ob die Effekte st√§rker als ‚Äúpraktisch Null‚Äù sind, kann mittels des ROPE-Verfahren untersucht werden.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "href": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.6 y ~ x_c + b + x_c:b\n",
    "text": "11.6 y ~ x_c + b + x_c:b\n\n\n11.6.1 Zentrieren von Pr√§diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq; die zentrierte Variable kennzeichnen wir durch den Suffix _c, also mom_iq_c.\nMan k√∂nnte auch mom_hs zentrieren, aber f√ºr eine einfache Interpretation ist es meist n√ºtzlich, nur metrische Pr√§diktoren zu zentrieren.\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\n\ncoef(m10.5)  # nur die Punktsch√§tzer f√ºr die Koeffizienten ausgeben\n\n\nTabelle¬†11.7 zeigt die Punktsch√§tzer der Koeffizienten von m10.5.\n\n\n\nTabelle¬†11.7: Punktsch√§tzer von m10.5 (zentrierte UV)\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.34\n\n\nmom_hs\n2.86\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n\n\n\n11.6.2 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den gesch√§tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten f√ºr mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nMit estimate_relation(m10.5) |&gt; plot() kann man sich das Modell visualisieren, s. Abbildung¬†11.11.\n\n\n\n\n\n\n\nAbbildung¬†11.11: m10.5: Mit zentrierten Pr√§diktoren gibt der Achsenabschnitt den Y-Wert f√ºr eine Beobachtung mit mittleren X-Wert an; daher ist der Achsenabschnitt besser zu interpretieren als ohne Zentrierung.\n\n\n\n\n\n11.6.3 Zentrieren √§ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5: Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\n\nCodenew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren √§ndert auch nicht die zentrierten Regressionskoeffizienten, da die Streuungen dieser Variable nicht ver√§ndert wurden.\n\n11.6.4 Perzentilintervalle aus der Posterori-Verteilung\nTabelle¬†11.8 zeigt die Punktsch√§tzer der Parameter f√ºr m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie daf√ºr parameters(m10.5), s. Tabelle¬†11.8.\n\n\n\nTabelle¬†11.8: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(81.17, 89.61)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.80, 7.62)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. Tabelle¬†11.9.\n\nCodeparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelle¬†11.9: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.34\n(80.96, 89.39)\n100%\n1.003\n2348\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.86\n(-1.64, 7.75)\n87.98%\n1.002\n2470\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.004\n1833\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.17)\n99.83%\n1.003\n1874\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n11.6.5 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei M√ºttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]); die Befundlage ist unklar. Hingegen fand sich ein Effekt der m√ºtterlichen Intelligenz; pro Punkt Unterschied in m√ºtterlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte beim Kind (95%PI). Au√üerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei M√ºtter mit Schulabschluss war der Regressionskoeffizient zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell hat mittels Abbildung¬†11.12 mutig Kausalaussagen postuliert. Das ist zwar sch√∂n, bedarf aber einer Begr√ºndung mit R√ºckgriff auf die Literatur (was hier nicht getan wurde).",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#sec-yg",
    "href": "1000-metrische-AV.html#sec-yg",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.7 y ~ g\n",
    "text": "11.7 y ~ g\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n11.7.1 Forschungsfrage\nNach Ihrem Studium wurden Sie reich als Unternehmensberaterin; Ihre Kompetenz als Wirtschaftspsychologi war hei√ü begehrt. Von Statistik wollte niemand etwas wissen‚Ä¶ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt f√ºhrte Sie in die Antarktis‚Ä¶ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um Gr√∂√üenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren K√∂rpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in Abbildung¬†11.12 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†11.12: DAG f√ºr y ~ g\n\n\n\n\n\n11.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere K√∂rpergewichte in Abh√§ngigkeit von der Pinguinart?\n\nAlternativ k√∂nnen wir die Hypothese pr√ºfen, ob die Mittelwerte ‚Äúpraktisch‚Äù gleich sind, also sich ‚Äúkaum‚Äù unterscheiden. Der Grenzwert f√ºr ‚Äúpraktisch gleich‚Äù bzw. ‚Äúkaum unterschiedlich‚Äù ist subjektiv. Dazu in Kapitel 10.3 mehr.\n\n11.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, Tabelle¬†11.10.\n\nCodepenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\nTabelle¬†11.10: Die Verteilung des K√∂rpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas f√§llt Ihnen auf?\n\n11.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. Abbildung¬†11.13?\n\n\n\n\n\n\n\nAbbildung¬†11.13: Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.7.5 Gewicht pro Spezies, m10.6\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und Tabelle¬†11.11.\nDie Modellformel f√ºr m10.6 lautet also body_mass_g ~ species.\n\nCodeoptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\n\nTabelle¬†11.11: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3700.62\n(3627.04, 3773.47)\n100%\n0.999\n4057\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.49\n(-104.84, 168.88)\n68.53%\n1.000\n4282\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.43\n(1263.00, 1492.13)\n100%\n1.000\n4454\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n11.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, Auspr√§gungen; hier: Spezies), aber es werden in Tabelle¬†11.11 nur zwei Stufen angezeigt (also eine weniger) zus√§tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedr√ºckt (Intercept). Die Koeffizienten f√ºr species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in Abbildung¬†11.14 verdeutlicht.\n\nCodeplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†11.14: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\n\n11.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich h√∂her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich √§hnlich.\nWie in Abbildung¬†11.14 ersichtlich, √ºberlappt sich der Sch√§tzbereich f√ºr den Parameter von Gentoo nicht mit der Null; hingegen √ºberlappt sich der Sch√§tzbereich des Parameters f√ºr Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise h√§tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis pr√ºfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.\n\n11.7.8 Priori-Werte √§ndern\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. F√ºr Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nf√ºr Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich mit prior_summary(modell) ausgeben lassen.\n\nCodeprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Prioris anpassen wollen. So k√∂nnte man z.B. auf Basis von Fachwissen √ºber das Gewicht von Pinguinen postulieren, dass Adelie-Pinguine im Mittel 3000 g wiegen. Und dass die anderen zwei Pinguin-Arten im Mittel sich nicht unterscheiden vom Mittelwert der Adelie-Pinguine.\n\nCodem10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3704               24             1358\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nCodem10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(3000, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##             3700               29             1375\n\n\nDen Parameter f√ºr die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen.\n\nCodesigma(m10.6b)\n## [1] 463\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die Gr√∂√üe der Konfidenzintervalle.\n√úbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren.12\n\n11.7.9 Vertiefung: Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\nCodepenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern.\n\nCodelevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nCodelibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verf√ºgbar sein muss.\nJetzt haben wir die Referenzkategorie ge√§ndert:\n\nCodelevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell, s. Tabelle¬†11.12.\n\nCodem10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nTabelle¬†11.12: m10.6a mit ge√§nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 4988.13, 5155.48]\n\n\nspeciesAdelie\n[-1486.15, -1260.32]\n\n\nspeciesChinstrap\n[-1474.66, -1198.00]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1-x2",
    "href": "1000-metrische-AV.html#y-x1-x2",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.8 y ~ x1 + x2\n",
    "text": "11.8 y ~ x1 + x2\n\nHier untersuchen wir Forschungsfragen mit zwei metrischen UV (und einer metrischen AV).\n\n11.8.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabh√§ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa ‚ÄúIQ der Mutter ist die Ursache zum IQ des Kindes‚Äù) wird impliziert.\nEs geht in dieser Forschungsfrage rein darum, Zusammenh√§nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. F√ºr solche Fragen ist ein Kausalmodell n√∂tig: Fachlich fundierte Annahmen √ºber Kausalzusammenh√§nge zwischen UV und AV.\n\n11.8.2 Was hei√üt, X h√§ngt mit Y zusammen?\n\nDer Begriff ‚ÄúZusammenhang‚Äù ist nicht exakt.\nH√§ufig wird er (f√ºr metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie gro√ü der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem ‚ÄúEffekt von X auf Y‚Äù √ºbersetzt. Vorsicht: ‚ÄúEffekt‚Äù klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begr√ºndung f√ºr einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der St√§rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugeh√∂rigen Regression im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten, bevor man ein (Regressions-)Modell aufstellt, s. Tabelle¬†11.13.\n\nCodekidiq %&gt;% \n  correlation()\n\n\n\n\n\nTabelle¬†11.13: Korrelation der Variablen im Datensatz kidiq (inkl. frequentistischer Statistiken wie t- und p-Werten, die wir hier ignorieren)\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.166\n\n\nkid_score\nmom_iq_c\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_hs\nmom_iq_c\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\nmom_iq\nmom_iq_c\n1.00\n(1.00, 1.00)\n1.39e+09\n&lt; .001***\n\n\nmom_age\nmom_iq_c\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\n\n\nTabelle¬†11.14 zeigt die Korrelationsmatrix als Korrelationsmatrix.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\n\nTabelle¬†11.14: Die Korrelationen zwischen den Variablen der Tabelle kidiq. Die Sterne geben einen Bereich des p-Werts an (wir ignorieren die Sterne hier).\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_iq_c\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.45***\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.28***\n0.21***\n0.28***\n\n\n\nmom_iq\n1.00***\n0.09\n\n\n\n\nmom_age\n0.09\n\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nN√ºtzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, Abbildung¬†11.15.\n\nCodekidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung¬†11.15: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n11.8.3 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro Pr√§diktor, also eine f√ºr mom_iq und eine f√ºr mom_age.\n\nCodem10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nTabelle¬†11.15 zeigt die Ergebnisse f√ºr mom_iq.\n\n\n\nTabelle¬†11.15: Parameter f√ºr m10.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.79\n(14.59, 37.16)\n100%\n1.000\n4452\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.72)\n100%\n1.000\n4436\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nTabelle¬†11.16 zeigt die Ergebnisse f√ºr mom_age.\n\n\n\nTabelle¬†11.16: Parameter f√ºr m10.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n71.39\n(54.39, 87.44)\n100%\n0.999\n3923\nNormal (86.80 +- 51.03)\n\n\nmom_age\n0.68\n(-0.02, 1.41)\n96.92%\n0.999\n3917\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n11.8.4 Visualisierung der univariaten Regressionen\nIn Abbildung¬†11.16 ist die univariate Regression mit jeweils einem der beiden Pr√§diktoren dargestellt.\nm10.7: Die Steigung betr√§gt 0.6. m10.8: Die Steigung betr√§gt 0.7.\n\n\n\n\n\n\n\nAbbildung¬†11.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n11.8.5 Multiples Modell (beide Pr√§diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein Pr√§diktor im Modell aufgenommen ist, s Tabelle¬†11.17.\n\nCodem10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\nparameters(m10.9)\n\n\n\n\n\nTabelle¬†11.17: Parameter f√ºr m10.9\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n17.61\n(-0.06, 35.67)\n97.42%\n1.000\n6102\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.60\n(0.48, 0.72)\n100%\n1.000\n5162\nNormal (0.00 +- 3.40)\n\n\nmom_age\n0.39\n(-0.23, 1.02)\n88.22%\n1.000\n4952\nNormal (0.00 +- 18.89)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich (potenziell) zu den von den jeweiligen univariaten Regressionen.\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils ‚Äúbereinigt‚Äù vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht. Das bedeutet anschaulich, man betrachtet den den Zusammenhang einee UV mit der AV, wobei man gleichzeitig den anderen Pr√§diktor konstant h√§lt.\nIn Abbildung¬†11.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildung¬†11.17: 3D-Visualisierung von m10.9 (zwei Pr√§diktoren)\n\n\n\nAbbildung¬†11.18 zeigt eine Visualisierung von m10.9, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildung¬†11.18: Modell m10.9; die Farbverl√§ufe zeigen der Wert der abh√§ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farb√§nderung) die Ver√§nderung f√ºr die AV (kid_score). Auf der Achse f√ºr mom_age sieht man, dass sich die AV kaum √§ndert, wenn sich mom_age √§ndert.\n\n11.8.6 Visualisierung in 10 Dimensionen\nAbbildung¬†11.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildung¬†11.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schw√§chen, eine gro√üe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y-x1_z-x2_z",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.9 y ~ x1_z + x2_z\n",
    "text": "11.9 y ~ x1_z + x2_z\n\nIn diesem Abschnitt untersuchen wir ein Modell mit zwei z-standardisierten, metrischen Pr√§diktoren (und einer metrischen, nicht-standardisierten AV).\n\n11.9.1 Relevanz der Pr√§diktoren\nWoher wei√ü man, welche UV am st√§rksten mit der AV zusammenh√§ngt? Man k√∂nnte auch sagen: Welcher Pr√§diktor (welche UV) am ‚Äúwichtigsten‚Äù ist oder den ‚Äúst√§rksten Einfluss‚Äù auf die AV aus√ºbt? Bei solchen kausal konnotierten Ausdr√ºcken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann f√ºr sich nur Muster in den Daten, also Zusammenh√§nge bzw. Unterschiede, entdecken, s. Abbildung¬†11.20. M√∂chte man die Relevanz von Pr√§diktoren vergleichen, so ist ein Kausalmodell empfehlenswert.\n\n\n\n\n\nAbbildung¬†11.20: Made at imgflip.com\n\n\nWelcher Pr√§diktor ist nun ‚Äúwichtiger‚Äù oder ‚Äúst√§rker‚Äù in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)? Die Antwort h√§ngt auch von der Streuung bzw. Skalierung der Variablen ab. mom_iq hat den gr√∂√üeren Koeffizienten und viel Streuung; mom_age hat weniger Streuung.\nUm die Relevanz der Pr√§diktoren vergleichen zu k√∂nnen, m√ºsste man vielleicht die Ver√§nderung von kid_score betrachten, wenn man von kleinsten zum gr√∂√üten Pr√§diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die Ver√§nderung in der AV zu betrachten, wenn man den Pr√§diktor von ‚Äúunterdurchschnittlich‚Äù auf ‚Äú√ºberdurchschnittlich‚Äù √§ndert. Das kann man mit z-Standardisierung erreichen, s. ?sec-standardnormalverteilung.\n\n\n\n\nCodekidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;%  # z-Transformation\n  select(mom_iq, mom_iq_z) \n\nkidiq2 %&gt;% \n  head()\n\n\n  \n\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit der Effekte von UV, die (zuvor) verschiedene Mittelwerte und Streuungen hatten13. Die Standardisierung ist √§hnlich zur Vergabe von Prozentr√§ngen: ‚ÄúDieser Messwert geh√∂rt zu den Top-3-Prozent‚Äù. Diese Aussage ist bedeutsam f√ºr Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen f√ºr verschiedene Verteilungen m√∂glich.\n\n11.9.2 Statistiken zu den z-transformierten Variablen\nTabelle¬†11.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Auspr√§gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener Pr√§diktoren sind einfacher in ihrer Gr√∂√üe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und √§hnlich gro√üe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (‚ÄúSkalierung‚Äù) mit standardize (aus easystats) durchf√ºhren, s. Tabelle¬†11.18.\n\nCodekidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\n\nTabelle¬†11.18: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nmom_iq_c\npred_m10.9\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_c_z\npred_m10.9_z\n\n\n\n65\n1\n121.12\n27\n21.12\n101.14\n-1.07\n0.52\n1.41\n1.56\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n-10.64\n81.22\n0.55\n0.52\n-0.71\n0.82\n-0.71\n-0.60\n\n\n85\n1\n115.44\n27\n15.44\n97.72\n-0.09\n0.52\n1.03\n1.56\n1.03\n1.19\n\n\n83\n1\n99.45\n25\n-0.55\n87.30\n-0.19\n0.52\n-0.04\n0.82\n-0.04\n0.06\n\n\n115\n1\n92.75\n27\n-7.25\n84.04\n1.38\n0.52\n-0.48\n1.56\n-0.48\n-0.30\n\n\n98\n0\n107.90\n18\n7.90\n89.67\n0.55\n-1.91\n0.53\n-1.77\n0.53\n0.32\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt daf√ºr, dass die urspr√ºnglichen Variablen beim z-Standardisieren nicht √ºberschrieben werden, sondern angeh√§ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nCodekidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. Tabelle¬†11.19. Dazu verwendet man den Befehl scale().\n\nCodekidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\n\nTabelle¬†11.19: Z-Standardisierung ohne Extrapaket‚Äù\n\n\n\n  \n\n\n\n\n\n\n\n11.9.3 Modell\nBerechnen wir das Modell m10.10: y ~ x1_z + x2_z.\n\nCodem10.10 &lt;- stan_glm(kid_score ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\nparameters(m10.10)\n\n\n\n\n\nTabelle¬†11.20: Parameter von m10.12\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n86.77\n(85.05, 88.48)\n100%\n1.000\n4917\nNormal (86.80 +- 51.03)\n\n\nmom_iq_z\n9.04\n(7.34, 10.83)\n100%\n1.000\n4719\nNormal (0.00 +- 51.03)\n\n\nmom_age_z\n1.04\n(-0.73, 2.78)\n88.02%\n0.999\n4786\nNormal (0.00 +- 51.03)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "href": "1000-metrische-AV.html#y_z-x1_z-x2_z",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.10 y_z ~ x1_z + x2_z\n",
    "text": "11.10 y_z ~ x1_z + x2_z\n\nIn diese Abschnitt berechnen wir ein Modell (Modell m10.12), in dem sowohl die Pr√§diktoren z-transformiert sind (standardisiert) als auch die AV. Das z-Standardisieren der AV, kid_score ist zwar nicht n√∂tig, um den Effekt der Pr√§diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage dar√ºber, um wie viele SD-Einheiten sich die AV ver√§ndert, wenn sich ein Pr√§diktor um eine SD-Einheit ver√§ndert. Das kann auch eine interessante(re) Aussage sein.\n\n11.10.1 Modell y_z ~ x1_z + x2_z\n\nBerechnen wir das Modell m10.12: y_z ~ x1_z + x2_z.\n\nCodem10.12 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z   mom_age_z \n##    -0.00014     0.44384     0.05072\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient f√ºr mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) √§ndert, wenn sich mom_iq um eine SD-Einheit √§ndert.\nDer Koeffizient f√ºr mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) √§ndert, wenn sich mom_age um eine SD-Einheit √§ndert.\n\nJetzt sind die Pr√§diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar. Man sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n11.10.2 95%-PI\nMit parameters k√∂nnen wir uns ein PI f√ºr m10.12 ausgeben lassen, s. Abbildung¬†11.21; im Standard wird ein 95%-ETI berichtet14.\n\nCodeparameters(m10.12) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-1.38e-04\n(-0.08, 0.08)\n50.20%\n1.000\n5259\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n4713\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.85%\n0.999\n4990\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nCodeplot(eti(m10.12)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung¬†11.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI f√ºr m10.12\n\n\n\n\n\n11.10.3 Modellg√ºte\n\nCoder2(m10.12)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.144, 0.271])\n\n\nIst dieser Wert von \\(R2\\) ‚Äúgut‚Äù? Diese Frage ist √§hnlich zur Frage ‚ÄúIst das viel Geld?‚Äù; man kann die Frage nur im Kontext beantworten.\nEine einfache L√∂sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erkl√§rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zuf√§llig hohen Werten der Modellg√ºte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine ‚Äúobjektive‚Äù Antwort auf die Frage ‚Äúwie viel ist viel?‚Äù haben wollen, ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage ‚ÄúWieviel ist viel?‚Äù gegeben hat (Cohen, 1992):\n\nCodeinterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n11.10.4 Priori-Verteilung f√ºr m10.12 und Modelldefinition\nDie Prioris f√ºr m10.12 kann man sich mit prior_summary(m10.12) ausgeben lassen. Danke, Stan!\n\nCodeprior_summary(m10.12)  # aus rstanarm\n## Priors for model 'm10.12' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\n\nü§ñ Nix zu danken!\n\nWie gesagt, Stan nimmt daf√ºr einfach die empirischen Mittelwerte und Streuungen her.15\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. Gleichung¬†11.4.\n\\[\n\\begin{aligned}\n\\text{kidscore}^z_i  &\\sim \\mathcal{N}(\\mu_i,\\sigma)\\\\\n\\mu_i &= \\beta_0 + \\beta_1\\text{momiq}_i^z + \\beta_2\\text{momage}_i^z \\\\\n\\beta_0 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{11.4}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.12. Dadurch, dass nicht nur UV, sondern auch AV z-standardisiert (d.h. zentriert und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuf√ºhren.\n\nBeispiel 11.3 (Anzahl der Modellparameter) Wie viele Modellparameter hat m10.12?16\n\n\n11.10.5 Antwort auf die Forschungsfrage\n\nDas Modell spricht sich klar f√ºr einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Pro Einheit Standardabweichung in der UV (Intelligenz der Mutter) √§ndert sich die AV um ca. 0.44 Standardabweichungseinheiten. Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erk√§rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al., 2020) zur√ºck (s. Anhang f√ºr Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem ‚Äústatistischen Effekt‚Äù gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenh√§nge, und nicht um kausale Zusammenh√§nge, handelt. Kausale Zusammenh√§nge d√ºrfen wir nur verk√ºnden, wenn wir sie a) explizit untersuchen und b) sich in der Literatur Belege daf√ºr finden oder c) wir ein Experiment fachgerecht durchgef√ºhrt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.11 Vertiefung",
    "text": "11.11 Vertiefung\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\n\n11.11.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch, s. Theorem¬†11.2.\n\nTheorem 11.2 (Regression als Korrelation) \\[b = r \\frac{sd_x}{sd_y}\\quad \\square\\]\n\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die Punktsch√§tzer f√ºr die Regressionskoeffizienten, s. m10.12.\n\nCodem10.12 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.12)\n## (Intercept)    mom_iq_z \n##    -0.00033     0.44993\n\n\nVergleichen Sie diese Werte mit der Korrelation, s. Tabelle¬†11.21.17\n\nCodekidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelle¬†11.21: Correlation Matrix (pearson-method)\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n11.11.2 Pr√ºfen der Linearit√§tsannahme\nZentrale Annahme eines linearen Modells: Die AV ist eine lineare Funktion der einzelnen Pr√§diktoren, $y= _0 + _1x_1 + _2 x_2 + $, vgl. Theorem¬†2.1.\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression h√§ufig normalverteilte Residuen an18, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu sch√§tzen (Gelman et al., 2021).\nIst die Linearit√§tsannahme erf√ºllt, so sollte der Residualplot nur zuf√§llige Streuung um \\(y=0\\) herum zeigen, s. Abbildung¬†11.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tats√§chlichem Wert: \\(e_i = y_i - \\hat{y}_i\\)\n\nCodekidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.12_pred = predict(m10.12),  # vorhergesagten Werte\n         m10.12_resid = resid(m10.12))  # Residuen\n\n\n\nCodekidiq %&gt;% \n  ggplot(aes(x = m10.12_pred, y = m10.12_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildung¬†11.22: Die Verteilung der Fehler scheint keinem starken Trend (in Abh√§ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine gr√∂√üeren Auff√§lligkeiten.\n\n11.11.3 Modellpr√ºfung mit der PPV\n\nCodepp_check(m10.12)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht h√§ufig.\n\n11.11.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildung¬†11.23: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildung¬†11.23 zeigt in der oberen Reihe die Regression eines Pr√§diktors auf den anderen Pr√§diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das hei√üt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenh√§ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das hei√üt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenh√§ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n11.11.5 Bayesianisch gleich Frequentistisch?\n√úbrigens liefern stan_glm() und lm oft √§hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nCodestan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.911      -0.019      -2.285\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##      36.908      -0.019      -2.265\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch √§hnlich sein k√∂nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.12 Fazit",
    "text": "11.12 Fazit\n\n11.12.1 Austieg: Bayes in f√ºnf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\nüì∫ Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\nüì∫ Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n11.12.2 Ausblick: Bin√§re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\nCodedata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m14: am ~ mpg_z:\n\nCodem14 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m14)\n## (Intercept)       mpg_z \n##         0.4         0.3\n\n\nAb mpg_z = 0.4, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nCodemtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m14)[1],\n              slope = coef(m14)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nCodeneg_am &lt;- predict(m14, newdata = tibble(mpg_z = -1.3))\n\n\nF√ºr kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte f√ºr am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. M√ºssen wir mal bei Gelegenheit besser machen.\n\n11.12.3 Genug f√ºr heute\nWir waren flei√üig ‚Ä¶\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.\n\n\nGenug f√ºr heute. üëç\n\n11.12.4 Weiterf√ºhrende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman et al. (2021), Kap. 10, insbesondere 10.3.\nGelman et al. (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit f√ºhrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig √ºberschaubarem mathematischen Aufwand.\nF√ºr das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.13 Aufgaben",
    "text": "11.13 Aufgaben\n\n11.13.1 Papier-und-Bleistift-Aufgaben\n\nanz-params\nfofrage-regrformel2\nmodelldef-regrformel\nfinde-prior/\nNullhyp-Beispiel\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nzwert-berechnen\nstan_glm_parameterzahl\nkausale-verben\n\n11.13.2 Aufgaben, f√ºr die man einen Computer ben√∂tigt\n\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope4\n\n11.13.3 Vertiefung\n\nAnova-skalenniveau\nttest-skalenniveau\nstan_glm_prioriwerte",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "\n11.14 ‚Äî",
    "text": "11.14 ‚Äî\n\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155‚Äì159.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). Rstanarm: Bayesian Applied Regression Modeling via Stan. https://mc-stan.org/rstanarm\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#footnotes",
    "href": "1000-metrische-AV.html#footnotes",
    "title": "\n11¬† Fallbeispiele\n",
    "section": "",
    "text": "Hier ist eine kurze Erkl√§rung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablen‚Ü©Ô∏é\nHier finden Sie eine kurze Erkl√§rung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktion‚Ü©Ô∏é\nauch DAG genannt, s. ?sec-kausal‚Ü©Ô∏é\nH√§ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - ‚Äúgr√∂√üer als/kleiner als‚Äù - zu formulieren, anstelle der ‚Äúempirisch √§rmeren‚Äù einfachen, ungerichteten Ungleichheit‚Ü©Ô∏é\nunknown, sozusagen der unbekannte Gott, also f√ºr alle sonstigen Einfl√ºsse; man kann das ‚Äúu‚Äù ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgef√ºhrt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es g√§be keine anderen Einfl√ºsse als mom_hs auf die IQ des Kindes.‚Ü©Ô∏é\nGenauer gesagt wird gepr√ºft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.‚Ü©Ô∏é\nGenauer gesagt, erlaubt der t-Test in der Form des Welche-Tests auch Abweichungen von der Varianzhomogenit√§t der gestesten Gruppen. Die Regression geht hingegen von Varianzhomogenit√§t (Homoskedastizit√§t) aus. Allerdings ist diese Annahme nicht von besonderer Bedeutung, wenn es um die Regressionskoeffizienten geht.‚Ü©Ô∏é\nDAG, s. ?sec-kausal‚Ü©Ô∏é\nDabei nehmen wir an, dass x und u nicht voneinander abh√§ngen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.‚Ü©Ô∏é\nVgl. Abschnitt ‚ÄúUV zentrieren‚Äù im Kursbuch Statistik1.‚Ü©Ô∏é\nauch ETI (Equal Tails Interval) genannt‚Ü©Ô∏é\ns. Details hier.‚Ü©Ô∏é\nam n√ºtzlichsten ist diese Standardisierung bei normal verteilten Variablen.‚Ü©Ô∏é\nZumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen k√∂nnen sich √§ndern. Am besten in der Dokumentation nachlesen: ?parameters.‚Ü©Ô∏é\nNicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Sch√§tzer der echten Parameter sein m√ºssten, wenn die Stichprobe, die wir ihm angeschleppt h√§tten, tats√§chlich gut ist‚Ä¶‚Ü©Ô∏é\n4: \\(\\beta_0, \\beta_1, \\beta_2, \\sigma\\)‚Ü©Ô∏é\nIgnorieren Sie die Zeile mit dem Befehl display(). Dieser Befehl dient nur dazu, die Ausgabe zu versch√∂nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.‚Ü©Ô∏é\nwas auf normal verteilte AV hinauslaufen kann aber nicht muss‚Ü©Ô∏é",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html",
    "href": "1200-abschluss.html",
    "title": "12¬† Abschluss",
    "section": "",
    "text": "12.1 Lernsteuerung",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "12¬† Abschluss",
    "section": "",
    "text": "12.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerl√§utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische ‚ÄúLieblingsfehler‚Äù benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik √ºbersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n12.1.2 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\nCodelibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n\n12.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#probeklausur",
    "href": "1200-abschluss.html#probeklausur",
    "title": "12¬† Abschluss",
    "section": "\n12.2 Probeklausur",
    "text": "12.2 Probeklausur\n\n12.2.1 2024\n(Diese Liste ist im Aufbau. Bitte konsultieren Sie f√ºr weitere Aufgaben selbst√§ndig alle relevanten Aufgaben, die in den Kapiteln vorgestellt wurden.)\n\nttest-als-regr\nAdditionssatz1\n\nNerd-gelockert q\nUrne1\ncorona-blutgruppe\nvoll-normal\nalphafehler-inflation3\nverteilungen-quiz-05\nverteilungen-quiz-03\nverteilungen-quiz-04\nKekse03\nglobus-bin2\nglobus2\niq01a\ngem-wskt4\nRethink2m3\nmtcars-post2a\ngroesse03\nbath42\nklausur-raten\nbed-post-wskt1\nmtcars-post3a\nexp-tab\nnorms-sd\nmtcars-post_paper\nbfi10\nrope-luecke\nwskt-schluckspecht2a\npenguins-stan-06\n\n12.2.2 2023\nDieser Tag auf dem Datenwerk stellt Fragen einer Probepr√ºfung (Version 2023) zusammen.\n\n12.2.3 2022\nDieser Tag auf dem Datenwerk stellt Fragen einer Probepr√ºfung (Version 2022) zusammen.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "12¬† Abschluss",
    "section": "\n12.3 Lieblinglingsfehler",
    "text": "12.3 Lieblinglingsfehler\nLieblingsfehler im √úberblick ü§∑:\n\nQuantile und Verteilungsfunktion verwechseln\nPr√§diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n12.3.1 Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑\nüèé üèé Vertiefung: Dieser Abschnitt ist nicht pr√ºfungsrelevant. üèéÔ∏è üèé\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nCodem1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle¬†12.1.\n\nCodepost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle¬†12.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. H√§ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und Punktsch√§tzer auszulesen.\nDie Posterior-Pr√§diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n12.3.2 Quantile und Verteilungsfuntion verwechseln ü§∑\n\n12.3.2.1 Quantil f√ºr \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung¬†12.1.\n\n\n\n\n\n\n\nAbbildung¬†12.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betr√§gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist gr√∂√üer oder gleich dem \\(p\\)-Quantil.\n\n12.3.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung¬†12.2.\n\n\n\n\n\n\n\nAbbildung¬†12.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betr√§gt hier 50%, dass \\(x\\) nicht gr√∂√üer ist als 0.\n\n12.3.3 Interaktion falsch interpretieren ü§∑\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber k√ºrzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nCodem2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten, s. Tabelle¬†12.2.\n\nCodeparameters(m2)\n\n\n\n\n\nTabelle¬†12.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.68\n(18.99, 30.27)\n100%\n1.000\n2120.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.75%\n1.000\n2200.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.80\n(4.96, 22.96)\n99.78%\n1.000\n1573.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.19, -0.03)\n99.52%\n1.000\n1837.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle¬†12.2 zeigt die Visualisierung der Parameter von m2.\n\nCodeplot(parameters(m2))\n\n\n\n\n\n\nAbbildung¬†12.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch üòà Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11.\nRichtig üëº Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11 ‚Äì wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Pr√§diktoren w√§ren hier eine sinnvolle L√∂sung.\nGelman et al. (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "12¬† Abschluss",
    "section": "\n12.4 Kochrezepte üç≤",
    "text": "12.4 Kochrezepte üç≤\n\n12.4.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen √ºber ein Ph√§nomen, \\(y\\), Kausalfrage finden 2. Literatur w√§lzen, um m√∂gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese pr√§zisieren 4. Modell pr√§zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell pr√ºfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n12.4.2 Parameter sch√§tzen vs.¬†Hypothesen pr√ºfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter sch√§tzen. Beispiel Hypothesenpr√ºfung: ‚ÄúFrauen parken im Durchschnitt schneller ein als M√§nner‚Äù. Beispiel Parametersch√§tzung: ‚ÄúWie gro√ü ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und M√§nnern?‚Äù\nJe ausgereifter ein Forschungsfeld, desto k√ºhnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die n√§chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die n√§chste Sonnenfinsternis wird in den n√§chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen f√ºr den Klausurerfolg. K√ºhne Hypothesen sind w√ºnschenswert ü¶π\n\n12.4.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist h√∂her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist gr√∂√üer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "12¬† Abschluss",
    "section": "\n12.5 Kerngedanken Bayes",
    "text": "12.5 Kerngedanken Bayes\nüì∫ Bayes in f√ºnf Minuten\nüì∫ Bayes in zehn Minuten\n\n12.5.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nCodem3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung¬†12.4.\n\n\n\n\n\n\n\nAbbildung¬†12.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist m√∂glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind m√∂glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings √ºbermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n12.5.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "title": "12¬† Abschluss",
    "section": "\n12.6 Beispiele f√ºr Pr√ºfungsaufgaben",
    "text": "12.6 Beispiele f√ºr Pr√ºfungsaufgaben\n\n12.6.1 Geben Sie den korrekten Begriff an!\nüå¨üöôüôãÔ∏èüë®‚¨ÖÔ∏èHans üëß‚¨ÖÔ∏èAnna üë©‚¨ÖÔ∏èLise\nPuh, wie erstelle ich f√ºr alle Studis ein anderes R√§tsel2?\n\n\n\n\n\n12.6.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung¬†12.5.\n\n\n\n\n\n\n\nAbbildung¬†12.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 12.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge f√ºr x und y gibt eine kleinstm√∂gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu ‚Äúidentifizieren‚Äù). \\(\\square\\)\n\n‚ùìGeben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n‚ùó Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n12.6.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung¬†12.6.\n\n\n\n\n\n\n\nAbbildung¬†12.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n12.6.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung¬†12.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung¬†12.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set f√ºr den totalen Kausaleffekt: {AIS, ALN}\n\n12.6.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPr√ºfungsfragen zu Modellen k√∂nnten z.B. sein:\n\nGeben Sie den Punktsch√§tzer (Median) f√ºr den Pr√§diktor X im Modell Y an!\nGeben Sie ein 89%-HDI f√ºr den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris ‚Ä¶\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI f√ºr den Pr√§diktor X im Modell Y?\nWas ver√§ndert sich an den Parametern, wenn Sie die Pr√§diktoren zentrieren/z-standardisieren?\n‚Ä¶",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "12¬† Abschluss",
    "section": "\n12.7 Aufgabensammlungen",
    "text": "12.7 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere ‚ÄúPr√ºfungsn√§he‚Äù k√∂nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "title": "12¬† Abschluss",
    "section": "\n12.8 Viel Erfolg bei der Pr√ºfung!",
    "text": "12.8 Viel Erfolg bei der Pr√ºfung!\nü•≥üèÜüçÄüçÄüçÄ",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section-3",
    "href": "1200-abschluss.html#section-3",
    "title": "12¬† Abschluss",
    "section": "\n12.9 ‚Äî",
    "text": "12.9 ‚Äî\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2. Aufl.). Taylor and Francis, CRC Press.\n\n\nvan Kampen, D. (2014). The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs. European Psychiatry, 29(7), 437‚Äì448. https://doi.org/10.1016/j.eurpsy.2013.11.001",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#footnotes",
    "href": "1200-abschluss.html#footnotes",
    "title": "12¬† Abschluss",
    "section": "",
    "text": "langweiliges‚Ü©Ô∏é\nFahr-Hier-Hans-Anna-Lise: Varianzanalyse‚Ü©Ô∏é\ndas ist keine vollst√§ndige Liste, sondern eine Anregung. Andere Tags k√∂nnten auch relevant sein‚Ü©Ô∏é",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "definitions.html",
    "href": "definitions.html",
    "title": "13¬† Definitionen",
    "section": "",
    "text": "Kausale Abh√§ngigkeit: ?def-abh\nAdditionssatz f√ºr disjunkte Ereignisse: Definition¬†4.1\nAllgemeiner Additionssatz: Definition¬†4.2\nAlternativhypothese (Effekthypothese): Definition¬†2.10\n#Binomialkoeffizient: Definition¬†5.2\nBinomialverteilung: Definition¬†5.1\nBlockieren: ?def-blocking\nKollision: ?def-collision\nKonfundierungsvariable: ?def-confound\nDAG: ?def-dag\nElementarereignis: Definition¬†3.5\nDeskriptivstatistik: Definition¬†2.1\nDirekter Effekt: ?def-dir-eff\nEffekt: ?def-effekt\nEreignis: Definition¬†3.3\nErgebnisraum: Definition¬†3.2\nPerzentilintervall (PI): Definition¬†7.1\nEvidenz: Definition¬†6.4\nFunktion: Definition¬†2.4\nGemeinsame Wahrscheinlichkeit: Definition¬†4.6\nHalbe Normalverteilung: Definition¬†5.3\nIntervalle h√∂chster Dichte (Highest Density Intervals): Definition¬†7.2\nHintert√ºr: ?def-hintertuer\nIndirekter Effekt: ?def-ind-eff\nStochastische Unabh√§ngigkeit: Definition¬†4.4\nIndifferenzprinzip: Definition¬†3.10\n(Populations-)Inferenzstatistik: Definition¬†2.2\nKettenregel: Definition¬†4.7\nKonfidenzintervall: Definition¬†2.7\nLikelihood: Definition¬†6.2\nLaplace-Experimt: Definition¬†3.11\nM√§chtigkeit: Definition¬†3.7\nMediator: ?def-mediator\nKomplement√§rereignis: Definition¬†3.15\nLogische Differenz: Definition¬†3.16\nSchnittmenge von Ereignissen: Definition¬†3.14\nVereinigung von Ereignissen: Definition¬†3.13\nMinimale Adjustierungsmenge : Definition¬†12.1\nModell: Definition¬†2.3\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse: Definition¬†4.5\nNachfahre: ?def-Nachfahre\nExakte Nullhypothese: Definition¬†2.9\nEffektwahrscheinlichkeit: Definition¬†9.1\nPfad: ?def-pfad\nPosteriori-Verteilung: Definition¬†6.3\nBedingte Wahrscheinlichkeit: Definition¬†4.3\nPriori-Verteilung: Definition¬†6.1\nRelation: Definition¬†3.12\nSigma als mittleren Vorhersagefehler: Definition¬†2.6\nStatistische Signifikanz: Definition¬†2.8\nStratifizieren: ?def-stratifizieren\nTotaler Effekt: ?def-tce\nTotale Wahrscheinlichkeit: Definition¬†4.8\nUnm√∂gliches und sicheres Ereignis: Definition¬†3.4\nVerteilungsfunktion: Definition¬†3.19\nVerteilungsfunktion: Definition¬†3.22\nVollst√§ndiges Ereignissystem: Definition¬†3.6\nWahrscheinlichkeitsdichte: Definition¬†3.21\nEinfache Definition von Wahrscheinlichkeit: Definition¬†3.9\nWahrscheinlichkeit unter formallogischer Sichtweise: Definition¬†3.9\nDiskrete Wahrscheinlichkeitsverteilung: Definition¬†3.18\nZuf√§lliges Ereignis: Definition¬†3.1\nZufallsvorgang: Definition¬†3.1\nZufallsvariable: Definition¬†3.17\nStetige Zufallsvariable: Definition¬†3.20",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "theorems.html",
    "href": "theorems.html",
    "title": "14¬† Theoreme",
    "section": "",
    "text": "Stochastische Abh√§ngigkeit: Theorem¬†4.6\nStochastische Abh√§ngigkeit 2: Theorem¬†4.7\nAllgemeiner Additionssatz: Theorem¬†4.2\nAdditionssatz f√ºr disjunkte Ereignisse: Theorem¬†4.1\nBayes‚Äô Theorem: Theorem¬†6.1\nBayes‚Äô Theorem 2: Theorem¬†6.8\nBayes‚Äô Theorem 3: Theorem¬†6.8\nBayes‚Äô Theorem f√ºr zusammengesetzte Hypothesen: Theorem¬†6.9\n#Binomialkoeffizient: Theorem¬†5.3\n#Binomialverteilung: Theorem¬†5.2\nNotation f√ºr eine binomialverteilte Zufallsvariable: Theorem¬†5.1\nRegression als Korrelation: Theorem¬†11.2\nIndifferenzprinzip: Theorem¬†3.1\nEvidenz: Theorem¬†6.3\nEvidenz 2: Theorem¬†6.4\nHypothese f√ºr ungleiche Mittelwerte: Theorem¬†11.1\nGemeinsame Wahrscheinlichkeit: Theorem¬†4.10\nStochastische Unabh√§ngigkeit: Theorem¬†4.4\nSymmetrie der Unabh√§ngigkeit: Theorem¬†4.8\nStochastische Unabh√§ngigkeit 2: Theorem¬†4.5\nKettenregel: Theorem¬†4.11\nLaplace-Experiment: Theorem¬†3.2\nLineares Modell (Regressionsgleichung): Theorem¬†2.1\nModelldefinition m_kung_gewicht_c: Theorem¬†9.1\nNullhypothesentest: Theorem¬†10.1\nMultiplikationssatz f√ºr unabh√§ngige Ereignisse: Theorem¬†4.9\nStandardisierte Posteriori-Verteilung: Theorem¬†6.6\nPosteriori-Verteilung 2: Theorem¬†6.7\nBedingte Wahrscheinlichkeit: Theorem¬†4.3\nTotale Wahrscheinlichkeit: Theorem¬†4.12\nUnstandardisierte Posteriori-Wahrscheinlichkeit : Theorem¬†6.5",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Theoreme</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Badenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A.,\n& Longobardi, C. (2016). Misconceptions of the p-value among\nChilean and Italian Academic Psychologists.\nFrontiers in Psychology, 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247\n\n\nBourier, G. (2011). Wahrscheinlichkeitsrechnung und schlie√üende\nStatistik: praxisorientierte Einf√ºhrung mit Aufgaben und L√∂sungen\n(7., aktualisierte Aufl). Gabler.\n\n\nBourier, G. (2022). Statistik-√ºbungen: Beschreibende\nstatistik ‚Äì wahrscheinlichkeitsrechnung ‚Äì schlie√üende statistik (7.\nAuflage). Springer Gabler.\n\n\nBriggs, W. M. (2016). Uncertainty: The Soul of\nModeling, Probability &\nStatistics. Springer.\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155‚Äì159.\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020).\nRstanarm: Bayesian applied regression modeling via\nStan. https://mc-stan.org/rstanarm\n\n\nHenze, N. (2019). Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der\nMa√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Springer Berlin\nHeidelberg. https://doi.org/10.1007/978-3-662-59563-3\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157‚Äì1164.\nhttp://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf\n\n\nJaynes, E. T., & Bretthorst, G. L. (2003). Probability theory:\nThe logic of science. Cambridge University Press.\n\n\nKabadayi, F. (2024). Smartphone addiction, depression, distress,\neustress, loneliness, and sleep deprivation in adolescents: A latent\nprofile and network analysis approach. BMC Psychology,\n12(1), 608. https://doi.org/10.1186/s40359-024-02117-6\n\n\nKruschke, J. K. (2018). Rejecting or Accepting Parameter\nValues in Bayesian Estimation. Advances in\nMethods and Practices in Psychological Science, 1(2),\n270‚Äì280. https://doi.org/10.1177/2515245918771304\n\n\nKurz, S. (2021). Statistical Rethinking with\nBrms, Ggplot2, and the Tidyverse:\nSecond Edition. https://bookdown.org/content/4857/\n\n\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & L√ºdecke, D.\n(2019). Indices of Effect Existence and\nSignificance in the Bayesian Framework.\nFrontiers in Psychology, 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd ed.). Taylor and Francis, CRC\nPress.\n\n\nMittag, H.-J., & Sch√ºller, K. (2020). Statistik: Eine Einf√ºhrung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMorey, R. D., & Rouder, J. N. (2011). Bayes factor approaches for\ntesting interval null hypotheses. Psychological Methods,\n16(4), 406‚Äì419. https://doi.org/10.1037/a0024377\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference\nin statistics: A primer. Wiley.\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPopper, K. (2013). Logik der Forschung (H. Keuth,\nEd.). Akademie Verlag. https://doi.org/10.1524/9783050063782\n\n\nSauer, S. (2025). Statistik1. Independently published via\nAmazon. https://www.amazon.de/Statistik1-Einf%C3%BChrung-Statistik-Schwerpunkt-Prognose-Modellierung/dp/B0F673WGG5\n\n\nShmueli, G. (2010). To Explain or to Predict?\nStatistical Science, 25(3), 289‚Äì310. https://doi.org/10.1214/10-STS330\n\n\nvan Kampen, D. (2014). The SSQ model of schizophrenic\nprodromal unfolding revised: An analysis of its causal\nchains based on the language of directed graphs. European\nPsychiatry, 29(7), 437‚Äì448. https://doi.org/10.1016/j.eurpsy.2013.11.001\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs\nStatement on p-Values: Context,\nProcess, and Purpose. The American\nStatistician, 70(2), 129‚Äì133. https://doi.org/10.1080/00031305.2016.1154108",
    "crumbs": [
      "Anhang",
      "Literaturverzeichnis"
    ]
  },
  {
    "objectID": "imprint.html",
    "href": "imprint.html",
    "title": "15¬† Impressum",
    "section": "",
    "text": "15.1 Vertreten durch:\nAngaben gem√§√ü ¬ß 5 DDG\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach\nSebastian Sauer",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#kontakt",
    "href": "imprint.html#kontakt",
    "title": "15¬† Impressum",
    "section": "15.2 Kontakt:",
    "text": "15.2 Kontakt:\nTelefon: 0981 4877 0, E-Mail: sebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#aufsichtsbeh√∂rde",
    "href": "imprint.html#aufsichtsbeh√∂rde",
    "title": "15¬† Impressum",
    "section": "15.3 Aufsichtsbeh√∂rde:",
    "text": "15.3 Aufsichtsbeh√∂rde:\nN√ºrnberg",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "href": "imprint.html#verantwortlich-f√ºr-den-inhalt-nach-55-abs.-2-rstv",
    "title": "15¬† Impressum",
    "section": "15.4 Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:",
    "text": "15.4 Verantwortlich f√ºr den Inhalt nach ¬ß 55 Abs. 2 RStV:\nSebastian Sauer, Residenzstr. 10, 90522 Ansbach",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "imprint.html#haftungsausschluss",
    "href": "imprint.html#haftungsausschluss",
    "title": "15¬† Impressum",
    "section": "15.5 Haftungsausschluss:",
    "text": "15.5 Haftungsausschluss:\n\n15.5.1 Haftung f√ºr Inhalte\nDie Inhalte unserer Seiten wurden mit gr√∂√üter Sorgfalt erstellt. F√ºr die Richtigkeit, Vollst√§ndigkeit und Aktualit√§t der Inhalte k√∂nnen wir jedoch keine Gew√§hr √ºbernehmen. Als Diensteanbieter sind wir gem√§√ü ¬ß 7 Abs.1 DDG f√ºr eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach ¬ß¬ß 8 bis 10 DDG sind wir als Diensteanbieter jedoch nicht verpflichtet, √ºbermittelte oder gespeicherte fremde Informationen zu √ºberwachen oder nach Umst√§nden zu forschen, die auf eine rechtswidrige T√§tigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unber√ºhrt. Eine diesbez√ºgliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung m√∂glich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\n\n\n15.5.2 Haftung f√ºr Links\nUnser Angebot enth√§lt Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb k√∂nnen wir f√ºr diese fremden Inhalte auch keine Gew√§hr √ºbernehmen. F√ºr die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf m√∂gliche Rechtsverst√∂√üe √ºberpr√ºft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\n\n\n15.5.3 Urheberrecht\nDie durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielf√§ltigung, Bearbeitung, Verbreitung und jede Art der Verwertung au√üerhalb der Grenzen des Urheberrechtes bed√ºrfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur f√ºr den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n\n\n15.5.4 Datenschutz\nDie Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten m√∂glich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit m√∂glich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdr√ºckliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Daten√ºbertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitsl√ºcken aufweisen kann. Ein l√ºckenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht m√∂glich. Der Nutzung von im Rahmen der Impressumspflicht ver√∂ffentlichten Kontaktdaten durch Dritte zur √úbersendung von nicht ausdr√ºcklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdr√ºcklich widersprochen. Die Betreiber der Seiten behalten sich ausdr√ºcklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, Fachanw√§lte f√ºr Familienrecht",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "data-privacy.html",
    "href": "data-privacy.html",
    "title": "16¬† Datenschutzhinweise",
    "section": "",
    "text": "16.1 Einleitung\nDiese Datenschutzhinweise informieren Sie √ºber die Art, den Umfang und den Zweck der Verarbeitung von personenbezogenen Daten (nachfolgend ‚ÄúDaten‚Äù) im Rahmen der Nutzung dieser Webseite (nachfolgend ‚ÄúWebseite‚Äù), die auf GitHub gehostet wird.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#einleitung",
    "href": "data-privacy.html#einleitung",
    "title": "16¬† Datenschutzhinweise",
    "section": "",
    "text": "16.1.1 Verantwortliche Person\nProf.¬†Dr.¬†habil. Sebastian Sauer, Residenzstr. 10, 90522 Ansbach, sebastian.sauer@hs-ansbach.de\n\n\n16.1.2 Hosting durch GitHub\nUnsere Webseite wird von GitHub Inc., 88 Colin P. Kelly Jr.¬†St, San Francisco, CA 94107, USA (‚ÄúGitHub‚Äù) gehostet. GitHub verarbeitet in unserem Auftrag Daten von Webseitenbesuchern (z.B. IP-Adressen). Dies ist f√ºr den Betrieb der Webseite und die Bereitstellung von Inhalten erforderlich. GitHub ist unter dem Privacy-Shield-Abkommen zertifiziert und bietet hierdurch eine Garantie, das europ√§ische Datenschutzrecht einzuhalten (https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC&status=Active).\nWeitere Informationen zum Datenschutz bei GitHub finden Sie in der Datenschutzerkl√§rung von GitHub: https://docs.github.com/de/site-policy/privacy-policies/github-general-privacy-statement",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#datenerhebung-und--verarbeitung",
    "href": "data-privacy.html#datenerhebung-und--verarbeitung",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.2 Datenerhebung und -verarbeitung",
    "text": "16.2 Datenerhebung und -verarbeitung\n\n16.2.1 Server-Log-Dateien\nBei jedem Zugriff auf unsere Webseite erfasst GitHub automatisiert Daten und speichert diese in Server-Log-Dateien. Zu diesen Daten geh√∂ren: IP-Adresse des zugreifenden Ger√§ts Datum und Uhrzeit des Zugriffs Name und URL der abgerufenen Datei Webseite, von der aus der Zugriff erfolgt (Referrer-URL) Verwendeter Browser und ggf. das Betriebssystem des zugreifenden Ger√§ts Name des Access-Providers\nDie Verarbeitung dieser Daten erfolgt, um die Funktionsf√§higkeit der Webseite sicherzustellen, die Nutzung der Webseite zu analysieren und unser Angebot zu verbessern. Rechtsgrundlage f√ºr die Datenverarbeitung ist Art. 6 Abs. 1 lit. f DSGVO (berechtigtes Interesse). Unser berechtigtes Interesse liegt in den oben genannten Zwecken.\n\n\n16.2.2 Cookies\nUnsere Webseite verwendet keine Cookies.\n\n\n16.2.3 Einbindung von Drittinhalten\nEs k√∂nnen Inhalte von Drittanbietern wie Videos, Schriftarten oder Karten eingebunden sein. Beim Abruf dieser Inhalte wird Ihre IP-Adresse m√∂glicherweise an den Drittanbieter √ºbertragen. F√ºr weitere Informationen konsultiere bitte die Datenschutzrichtlinien der jeweiligen Anbieter.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#ihre-rechte",
    "href": "data-privacy.html#ihre-rechte",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.3 Ihre Rechte",
    "text": "16.3 Ihre Rechte\nSie habengegen√ºber uns folgende Rechte hinsichtlich der dich betreffenden personenbezogenen Daten: Recht auf Auskunft (Art. 15 DSGVO) Recht auf Berichtigung (Art. 16 DSGVO) Recht auf L√∂schung (Art. 17 DSGVO) Recht auf Einschr√§nkung der Verarbeitung (Art. 18 DSGVO) Recht auf Daten√ºbertragbarkeit (Art. 20 DSGVO) Recht auf Widerspruch gegen die Verarbeitung (Art. 21 DSGVO)\nSie haben zudem das Recht, sich bei einer Datenschutz-Aufsichtsbeh√∂rde √ºber die Verarbeitung deiner personenbezogenen Daten durch uns zu beschweren.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "href": "data-privacy.html#anwendbare-rechtsgrundlagen",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.4 Anwendbare Rechtsgrundlagen",
    "text": "16.4 Anwendbare Rechtsgrundlagen\nNachstehend geben wir Ihnen eine √úbersicht der rechtlichen Grundlagen der DSGVO, auf deren Basis personenbezogene Daten auf dieser Webseite verarbeitet werden. Bitte beachten Sie, dass neben den Regelungen der DSGVO auch nationale Datenschutzvorgaben in Ihrem oder unserem Land relevant sein k√∂nnen. Sofern in Einzelf√§llen spezifische Rechtsgrundlagen gelten, werden diese in der Datenschutzerkl√§rung gesondert erw√§hnt.\n\n16.4.1 Vertragserf√ºllung und vorvertragliche Ma√ünahmen (Art. 6 Abs. 1 S. 1 lit. b) DSGVO)\nDie Verarbeitung personenbezogener Daten ist erforderlich zur Erf√ºllung eines Vertrags, bei dem die betroffene Person Vertragspartei ist, oder zur Durchf√ºhrung vorvertraglicher Ma√ünahmen, die auf Anfrage der betroffenen Person erfolgen.\n\n\n16.4.2 Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO)\nDie Datenverarbeitung erfolgt zur Wahrung berechtigter Interessen des Verantwortlichen oder eines Dritten, sofern keine entgegenstehenden Interessen, Grundrechte oder Grundfreiheiten der betroffenen Person, die den Schutz ihrer personenbezogenen Daten erfordern, √ºberwiegen.\n\n\n16.4.3 Nationale Datenschutzbestimmungen in Deutschland\nNeben der DSGVO gelten in Deutschland nationale Datenschutzvorgaben, insbesondere das Bundesdatenschutzgesetz (BDSG). Das BDSG beinhaltet spezielle Regelungen zum Recht auf Auskunft, L√∂schung, Widerspruch, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung f√ºr andere Zwecke sowie zur Daten√ºbermittlung und zu automatisierten Einzelentscheidungen einschlie√ülich Profiling. In bestimmten F√§llen k√∂nnen auch Datenschutzgesetze der Bundesl√§nder Anwendung finden.\n\n\n16.4.4 Hinweis auf die Geltung von DSGVO und Schweizer DSG\nDiese Datenschutzhinweise ber√ºcksichtigen die Vorgaben sowohl der DSGVO als auch des Schweizer Datenschutzgesetzes (DSG). Zur besseren Verst√§ndlichkeit und zur Vermeidung wiederholter Begriffsdefinitionen werden die Begriffe der DSGVO verwendet. Begriffe wie ‚ÄûVerarbeitung‚Äú, ‚Äûpersonenbezogene Daten‚Äú, ‚Äûberechtigtes Interesse‚Äú und ‚Äûbesondere Kategorien von Daten‚Äú entsprechen inhaltlich den Begriffen ‚ÄûBearbeitung‚Äú, ‚ÄûPersonendaten‚Äú, ‚Äû√ºberwiegendes Interesse‚Äú und ‚Äûbesonders sch√ºtzenswerte Personendaten‚Äú des Schweizer DSG. Die genaue Auslegung und Anwendung erfolgt jedoch gem√§√ü den Vorgaben des Schweizer DSG.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#sicherheitsma√ünahmen",
    "href": "data-privacy.html#sicherheitsma√ünahmen",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.5 Sicherheitsma√ünahmen",
    "text": "16.5 Sicherheitsma√ünahmen\nWir setzen angemessene technische und organisatorische Ma√ünahmen zum Schutz Ihrer Daten entsprechend den gesetzlichen Anforderungen um. Dabei ber√ºcksichtigen wir den aktuellen Stand der Technik, die Implementierungskosten, Art, Umfang, Umst√§nde und Zweck der Verarbeitung sowie die Wahrscheinlichkeit und Schwere m√∂glicher Risiken f√ºr die Rechte und Freiheiten betroffener Personen.\nZu den Schutzma√ünahmen geh√∂ren insbesondere: Sicherstellung der Vertraulichkeit, Integrit√§t und Verf√ºgbarkeit von Daten durch Kontrolle des Zugriffs auf die Daten und die Infrastruktur, der Eingaben, Weitergaben und Trennungen von Daten. Zudem haben wir Verfahren eingerichtet, um die Rechte betroffener Personen zu gew√§hrleisten, Daten zu l√∂schen und angemessen auf Bedrohungen zu reagieren. Bereits in der Entwicklung und Auswahl von Hard- und Software sowie Verfahren ber√ºcksichtigen wir Datenschutzprinzipien wie Datenschutz durch Technikgestaltung und datenschutzfreundliche Voreinstellungen.\nSicherung von Online-Verbindungen mit TLS-/SSL-Verschl√ºsselung (HTTPS) Um die Daten√ºbertragung √ºber unsere Online-Dienste vor unbefugtem Zugriff zu sch√ºtzen, nutzen wir die TLS-/SSL-Verschl√ºsselungstechnologie. Dies gew√§hrleistet eine sichere Daten√ºbertragung zwischen unserem Server und Ihrem Browser, erkennbar an der HTTPS-Kennung in der URL-Leiste.\n\n16.5.1 Internationale Daten√ºbertragungen\nFalls Datenverarbeitungen in Drittl√§ndern (au√üerhalb der EU und des EWR) stattfinden oder personenbezogene Daten an Dritte im Ausland √ºbermittelt werden, erfolgt dies ausschlie√ülich unter Einhaltung gesetzlicher Anforderungen. Sofern ein Angemessenheitsbeschluss der EU-Kommission f√ºr das betreffende Drittland vorliegt (Art. 45 DSGVO), gilt dieser als Grundlage der √úbertragung. Falls kein Angemessenheitsbeschluss vorliegt, sichern Standardvertragsklauseln (Art. 46 Abs. 2 lit. c) DSGVO), eine ausdr√ºckliche Einwilligung oder gesetzliche Erfordernisse die √úbertragung ab (Art. 49 Abs. 1 DSGVO).\nWeitere Informationen zu den Angemessenheitsbeschl√ºssen der EU-Kommission finden Sie auf dieser Seite. Die USA bieten mit dem sogenannten ‚ÄûData Privacy Framework‚Äú (DPF) eine Regelung zur Sicherstellung eines angemessenen Datenschutzniveaus, das durch die EU-Kommission am 10.07.2023 anerkannt wurde. Die Liste der zertifizierten Unternehmen und weitere Informationen finden Sie auf der Webseite des US-Handelsministeriums unter Data Privacy Framework.\nWir informieren Sie in unseren Datenschutzhinweisen, welche Drittanbieter unter diesem Rahmen zertifiziert sind.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#kontakt",
    "href": "data-privacy.html#kontakt",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.6 Kontakt",
    "text": "16.6 Kontakt\nF√ºr Anfragen zum Datenschutz k√∂nnen Sie sich an uns wenden:\nProf.¬†Dr.¬†habil. Sebastian Sauer\nResidenzstr. 10, 90522 Ansbach\nsebastian.sauer@hs-ansbach.de",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  },
  {
    "objectID": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "href": "data-privacy.html#√§nderung-der-datenschutzhinweise",
    "title": "16¬† Datenschutzhinweise",
    "section": "16.7 √Ñnderung der Datenschutzhinweise",
    "text": "16.7 √Ñnderung der Datenschutzhinweise\nWir behalten uns vor, diese Datenschutzhinweise jederzeit anzupassen, um sie an ge√§nderte Rechtslagen oder bei √Ñnderungen des Dienstes sowie der Datenverarbeitung anzupassen.\nStand: 15. November 2024",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Datenschutzhinweise</span>"
    ]
  }
]