# Globusversuch

![Bayes:Start!](img/Golem_hex.png){width=5%}


```{r}
#| include: false
library(tidyverse)
library(patchwork)
```


## Von Welten und Golems

### Kleine Welt, groÃŸe Welt

Bekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb @fig-behaim.

![Behaims Globus: Kein Amerika](img/Behaim.jpg){@fig-behaim}



Die *kleine Welt des Modells* entsprach hier nicht *der groÃŸen Welt, der echten Erdkugel*.

Das ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.

| Kleine Welt                                                | GroÃŸe Welt                                 |
|-----------------------------------------|-------------------------------|
| Die Welt, wie sie der Golem sieht                          | Die Welt, wie sie in Wirklichkeit ist      |
| ist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit | entspricht nicht (zwangslÃ¤ufig) dem Modell |
| Verwenden wir beim Modellieren                             | Ist das, was wir modellieren               |

: Kleine Welt vs. groÃŸe Welt

::: callout-note
Behaims Globus ist nicht gleich der Erde. Die kleine Welt ist nicht die groÃŸe Welt.
:::

Was in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.

ğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!






### Der Golem von Prag

![Der Golem von Prag](img/170px-Golem_and_Loew.jpg)

[Quelle](https://de.wikipedia.org/wiki/Golem)

Der Golem von Prag, eine vom Menschen geschaffene Kreatur gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt.

Bei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen.

Bei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.

### Wissenschaftliche Modelle sind wie Golems

**Golem**

![](img/Golem_hex.png){width=25%}

-   Besteht aus Lehm
-   Belebt durch "Wahrheit"
-   MÃ¤chtig
-   dumm
-   FÃ¼hrt Befehle wÃ¶rtlich aus
-   Missbrauch leicht mÃ¶glich
-   MÃ¤rchen

**Modell**

```{mermaid}
flowchart LR
X --> Y
```

-   Besteht aus ~~Lehm~~Silikon
-   Belebt durch Wahrheit (?)
-   Manchmal mÃ¤chtig
-   simpler als die RealitÃ¤t
-   FÃ¼hrt Befehle wÃ¶rtlich aus
-   Missbrauch leicht mÃ¶glich
-   Nicht einmal falsch

::: callout-important
Wir bauen Golems.
:::

### So denkt unser Bayes-Golem

![So denkt unser Bayes-Golem](img/bayesupdate2.png)

ğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!

## Ein erster Versuch: Wir werfen den Globus





### Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?

Unsere Hypothese bzw. unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist?

![Der Erdball](img/earth.png){width="50%"}

[Quelle](https://pngimg.com/image/25340) CC 4.0 BY-NC

Sie werden einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie 9 Mal.

So sah mein Ergebnis aus:

$$W \quad L \quad W \quad W \quad W \quad L \quad W \quad L \quad W$$

ğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!

### Wie entstanden die Daten?

Der physikalische Prozess, der zur Entstehung der Daten fÃ¼hrt, nennt man den *den datengenierende Prozess*.

In diesem Fall kann man ihn so beschreiben:

1.  Der wahre Anteil von Wasser, $W$, der ErdoberflÃ¤che ist $p$ (und $1-p$ ist der Anteil Land, $L$).
2.  Ein Wurf des Globusballes hat die Wahrscheinlichkeit $p$, eine $W$-Beobachtung zu erzeugen.
3.  Die WÃ¼rfe des Globusballes sind unabhÃ¤ngig voneinander.
4.  Wir haben kein Vorwissen Ã¼ber $p$; jeder Wert ist uns gleich wahrscheinlich.

ğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?





### Wissen updaten: Wir fÃ¼ttern Daten in das Modell

```{r QM2-Thema2-kleineModelle-19}
#| echo: false
#| out.width="100%"
#source("R-Code/img221.R")
```


![Unser Golem lernt](img/img221.png)


Unser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt.




### Ein paar Fachbegriffe

-   FÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: *Priori-Verteilung*.

-   FÃ¼r jede Hypothese (d.h. jeden *Parameterwert* $p$) mÃ¶chten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den *Likelihood*.

-   Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die *Posteriori-Verteilung*[^globusversuch-1] bekommen.

[^globusversuch-1]: Anstatt von *Priori* liest man auch *Prior*; anstatt *Posteriori* auch *Posterior*

![Updating mit Bayes](img/bayesupdate.png)

### WDie Binomialverteilung

Wir nehmen an, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert[^globusversuch-2].

[^globusversuch-2]: Die sog. "iid-Annahme", wie *i*ndependently and *i*dentically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen

Dann kann man die Wahrscheinlichkeit ($Pr$), $W$ mal Wasser und $L$ mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser $p$ betrÃ¤gt, mit der *Binomialverteilung* berechnen.

Die Binomialverteilung zeigt die Verteilung der HÃ¤ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten)[^globusversuch-3].

[^globusversuch-3]: "MÃ¼nzwurfverteilung"

$$Pr(W,L|p) = \frac{(W+L)!}{W!L!}p^W(1-p)^L$$

### Binomialverteilung mit R

Was ist der Anteil der gÃ¼ltigen Pfade (Wahrscheinlichkeit), um 6 mal $W$ bei $N=W+L=9$ WÃ¼rfen zu bekommen, wenn wir von $p=1/2$ ausgehen?

```{r QM2-Thema2-kleineModelle-21, echo = TRUE}
dbinom(x = 6, size = 9, prob = 1/2)
```

Was ist die Wahrscheinlichkeit fÃ¼r $W=9$ bei $N=9$ und $p=1/2$?

```{r QM2-Thema2-kleineModelle-22, echo = TRUE}
dbinom(x = 9, size = 9, prob = 1/2)
```

### Beispiele zur Berechnung einer binomial verteilten Wahrscheinlichkeit

Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?[^globusversuch-4]

[^globusversuch-4]: Hey, endlich mal was fÃ¼r echte Leben!

```{r QM2-Thema2-kleineModelle-23, echo = TRUE}
dbinom(x = 15, size = 20, prob = .5)
```

Was ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen?

```{r QM2-Thema2-kleineModelle-24, echo = TRUE}
dbinom(3, 3, 1/2)
```

### Unser Modell ist geboren

Wir fassen das Globusmodell so zusammen:

$$W \sim \text{Bin}(N,p),$$

Lies: "W ist *bin*omial verteilt mit den Parametern $N$ und $p$". $N$ gibt die Anzahl der GlobuswÃ¼rfe an: $N=W+L$.

Unser Vorab-Wissen zu $p$ sei, dass uns alle Werte gleich plausibel erscheinen ("uniform"):

$$p \sim \text{Unif}(0,1).$$

Lies: "$p$ ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1".

### So sehen die Verteilungen aus

Abb. @fig-bin zeigt die Binomialverteilung.

```{r QM2-Thema2-kleineModelle-25}
#| echo: false
#| label: fig-bin
#| fig-cap: Ein Beispiel fÃ¼r eine Binomialverteilung
dbinom(0:9, 9, 1/2) %>% 
  tibble(Wahrscheinlichkeit = .,
         Treffer = seq(0,9)) %>% 
  ggplot(aes(x = Treffer, y = Wahrscheinlichkeit)) +
  geom_segment(aes(xend = Treffer, yend = 0)) + 
  geom_point(color = "red", size = 5, alpha = .5) +
  scale_x_continuous(breaks = 0:9)

```

$N=9, p = 1/2$

Abb. @fig-unif zeigt ein Beispiel fÃ¼r eine Gleichverteilung (uniform distribution).

```{r QM2-Thema2-kleineModelle-26}
#| echo: false
#| fig-cap: Gleichverteilung
#| label: fig-unif



uniform_Plot <- function(a, b){
  xvals <- data.frame(x = c(a, b)) #Range for x-values
  
  ggplot(data.frame(x = xvals), 
         aes(x = x)) + xlim(c(a, b)) + ylim(0, 1/(b - a)) +
    stat_function(fun = dunif, args = list(min = a, max = b), 
                  geom = "area", 
                  fill = "green", alpha = 0.35) + 
    stat_function(fun = dunif, args = list(min = a, max = b)) +
    labs(x = "X", y = "Dichte")  +
    geom_vline(xintercept = a, linetype = "dashed", colour = "red") +
    geom_vline(xintercept = b, linetype = "dashed", colour = "red") 
  
}
uniform_Plot(0, 1)
```

$Min = 0, Max = 1$

ğŸ‹ï¸ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear? Was fÃ¤llt Ihnen bei der Gleichverteilung auf?

## Zur Erinnerung: Bayes Theorem

### Herleitung Bayes' Theorem 1/2: Gemeinsame Wahrscheinlichkeit

Die Wahrscheinlichkeit fÃ¼r *Regen* und *kalt* ist gleich der Wahrscheinlihckeit von *Regen*, *gegeben kalt* mal der Wahrscheinlicht von *kalt*. Entsprechend gilt: Die Wahrscheinlichkeit von $W$, $L$ und $p$ ist das Produkt von $Pr(W,L|p)$ und der Prior-Wahrscheinlichkeit $Pr(p)$:

$$Pr(W,L,p) = Pr(W,L|p) \cdot Pr(p)$$

Genauso gilt: Die Wahrscheinlichkeit von *Regen* und *kalt* ist gleich der Wahrscheinlichkeit *kalt, wenn's regnet* mal der Wahrscheinlichkeit von *Regen*:

$$Pr(W,L,p) = Pr(p|W,L) \cdot Pr(W, L)$$

### Herleitung Bayes' Theorem 2/2: Posteriori-Wahrscheinlichkeit

Wir setzen die letzten beiden Gleichungen gleich:

$$Pr(W,L|p) \cdot Pr(p) = Pr(p|W,L) \cdot (W,L)$$

Und lÃ¶sen auf nach der Posteriori-Wahrscheinlichkeit, $Pr(p|W,L)$:

$$Pr(p|W,L) = \frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}$$

$Pr(W,L)$ nennt man die *mittlere Wahrscheinlichkeit der Daten* oder *Evidenz*. Die Evidenz berechnet sich als Mittelwert der Likelihoods Ã¼ber alle Werte von $p$. Die Aufgabe dieser GrÃ¶ÃŸe ist nur dafÃ¼r zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.

### Bayes' Theorem als Formel

$$Pr(H|D) = \frac{Pr(D|H) Pr(H)}{Pr(D)}$$

-   Bestandteile:

    -   Posteriori-Wahrscheinlichkeit: $Pr_{Post} := Pr(H|D)$

    -   Likelihood: $L := Pr(D|H)$

    -   Priori-Wahrscheinlichkeit: $Pr_{Priori} := Pr(H)$

    -   Evidenz: $E := Pr(D)$

-   Bayes' Theorem gibt die $Pr_{Post}$ an, wenn man die Gleichung mit der $Pr_{Priori}$ und dem $L$ fÃ¼ttert.

-   Bayes' Theorem wird hÃ¤ufig verwendet, um die $Pr_{Post}$ zu quantifizieren.

-   Die $Pr_{Post}$ ist proportional zu $L \times Pr_{Priori}$.

### Posteriori als Produkt von Priori und Likelihood

$$\text{Posteriori} = \frac{\text{Likelihood} \times \text{Priori}}{\text{Evidenz}}$$

```{r QM2-Thema2-kleineModelle-27}
#source("R-Code/img241.R")
```

![Prior mal Likelihood = Post](img/img241.png)



## Bayes berechnen mit mit der Gitter-Methode

Die Methode *Gitter-AnnÃ¤herung* nennt man auch Grid Approximation\*.

### Idee

1.  Teile den Wertebereich des Parameter in ein "Gitter" auf, z.B. $0.1, 0.2, ..., 0.9, 1$ ("Gitterwerte").
2.  Bestimme den Priori-Wert des Parameters fÃ¼r jeden Gitterwert.
3.  Berechne den Likelihood fÃ¼r Gitterwert.
4.  Berechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Gitterwert (Produkt von Priori und Likelihood).
5.  Standardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.

### Gitterwerte in R berechnen

```{r QM2-Thema2-kleineModelle-28, echo = TRUE}
d <-
  tibble(
    # definiere das Gitter: 
    p_Gitter = seq(from = 0, to = 1, length.out = 10),
    # bestimme den Priori-Wert:       
    Priori  = 1) %>%  
    mutate(
      # berechne Likelihood fÃ¼r jeden Gitterwert:
      Likelihood = dbinom(6, size = 9, prob = p_Gitter),
      # berechen unstand. Posteriori-Werte:
      unstd_Post = Likelihood * Priori,
      # berechne stand. Posteriori-Werte (summiert zu 1):
      Post = unstd_Post / sum(unstd_Post))  
```

So sehen unsere "Gitterdaten" aus:

```{r QM2-Thema2-kleineModelle-29}
d %>% 
  knitr::kable(digits = 2)
```

ğŸ‹ï¸ Was wohl mit *Post* passiert, wenn wir *Priori* Ã¤ndern?

### Was sagt die Post?

Die Posteriori-Verteilung (Kurz: "Post-Verteilung"), $Pr_{Post}$, zeigt, wie plausibel wir jeden Wert von $p$ halten.

```{r QM2-Thema2-kleineModelle-30}
#source("R-Code/img242.R")
```

![Je mehr Gittewerte, desto genauer wird die Verteilung wiedergegeben.](img/img242.png)

Mehr Gitterwerte glÃ¤tten die AnnÃ¤herung.

Je grÃ¶ÃŸer die Stichprobe ($N$), desto zuverlÃ¤ssiger wird unsere Berechnung.

```{r QM2-Thema2-kleineModelle-32, out.width="100%"}
#source("R-Code/img243.R")
```




### Zusammenfassung

-   In unserem Modell haben wir Annahmen zu $Pr_{Priori}$ und $L$ getroffen.

-   Auf dieser Basis hat der Golem sein Wissen geupdated zu $Pr_{Post}$.

-   Mit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die $Pr_{Post}$ berechnet.

-   Unser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.

ğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r $W$ tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)?



