
# Kausalinferenz

## Lernsteuerung


### R-Pakete


Für dieses Kapitel benötigen Sie folgende R-Pakete:

```{r libs}
#| warning: false
library(dagitty)
library(tidyverse)
library(rstanarm)
library(easystats)
```



```{r libs-hidden}
#| echo: false
library(gt)
#library(DT)
library(ggdag)

theme_set(theme_modern())
```


### Lernziele


Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie können ... 

- erklären, wann eine Kausalaussage gegeben eines DAGs berechtigt ist
- die “Atome” der Kausalität eines DAGs benennen
- “kausale Hintertüren” schließen




## Statistik, was soll ich tun?


### Studie A: Östrogen

#### Medikament einnehmen?

Mit Blick auf @tbl-studie-a: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?

</br>

```{r tbl-studie-a}
#| echo: false
#| label: tbl-studie-a
#| tbl-cap: "Daten zur Studie A"

studie_a <-
  tibble::tribble(
     ~ Gruppe,      ~`Mit Medikament`,         ~`Ohne Medikament`,
"Männer",    "81/87 überlebt (93%)", "234/270 überlebt (87%)",
"Frauen",  "192/263 überlebt (73%)",   "55/80 überlebt (69%)",
"Gesamt",  "273/350 überlebt (78%)", "289/350 überlebt (83%)"
  ) 

studie_a %>% 
  gt()
```

</br>


Die Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualität (Beobachtungsstudie).
Bei Männern scheint das Medikament zu helfen; bei Frauen auch.
Aber *insgesamt* (Summe von Frauen und Männern) *nicht*?!
Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? 
Vielleicht nur dann, wenn er das Geschlecht kennt [@pearl_causal_2016]?





#### Kausalmodell zur Studie A



In Wahrheit sehe die kausale Struktur so aus:
Das Geschlecht (Östrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-).
Das Medikament hat einen Einfluss (+) auf Heilung.
Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Östrogen) und Medikament *vermengt* (konfundiert, confounded).
Die kausale Struktur, also welche Variable beeinflusst bzw. nicht,
ist in @fig-dag-studie-a dargestellt.



```{r dag-studie-a}
#| echo: false
#| label: fig-dag-studie-a
#| fig-cap: "Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender über drug) auf recovery"
#| out-width: "50%"
dag_studie_a <-
  dagitty("dag{
          gender -> drug
          drug -> recovery
          gender -> recovery
          }
      ")

coordinates(dag_studie_a) <-
  list(x = c(gender = 0, drug = 0, recovery  = 1),
       y = c(gender = 0, drug = 1, recovery = 0.5))


plot(dag_studie_a)
```


Betrachtung der Gesamtdaten zeigt in diesem Fall einen *konfundierten* Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.


:::callout-important
Betrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. 
Stratifizieren ist also in diesem Fall der korrekte, richtige Weg.
Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige Lösung.
Stratifizieren bedeutet,
den Gesamtdatensatz in Gruppen oder "Schichten" ("Strata")
:::




### Studie B: Blutdruck


#### Medikament einnehmen?

Mit Blick auf @tbl-studie-b: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?


```{r dag-studie-b-table}
#| echo: false
#| message: false
#| label: tbl-studie-b
#| tbl-cap: "Daten zur Wirksamkeit eines Medikaments (Studie B)"
studie_b <- 
  tibble::tribble(
~ Gruppe,          ~`Ohne Medikament`,          ~`Mit Medikament`,
"geringer Blutdruck",    "81/87 überlebt (93%)", "234/270 überlebt (87%)",
"hoher Blutdruck",  "192/263 überlebt (73%)",   "55/80 überlebt (69%)",
"Gesamt",  "273/350 überlebt (78%)", "289/350 überlebt (83%)"
  )

studie_b %>% 
  gt()
```






Die Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualität (Beobachtungsstudie).
Bei geringem Blutdruck scheint das Medikament zu schaden.
Bei hohem Blutdrck scheint das Medikamenet auch zu schaden.
Aber *insgesamt* (Summe über beide Gruppe) *nicht*, da scheint es zu nutzen?!
Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? @pearl_causal_2016


#### Kausalmodell zur Studie B





Das Medikament hat einen (absenkenden) Einfluss auf den Blutdruck.
Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung.
Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung.
Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schädlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.

Das Kausalmodell ist in @fig-dag-studie-b dargestellt.



```{r dag-studie-b}
#| echo: false
#| label: fig-dag-studie-b
#| fig-cap: "Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schädlich"
#| out-width: "50%"
dag_studie_b <-
  dagitty("dag{
          drug -> pressure
          drug -> toxic
          pressure -> recovery
          toxic -> recovery
          }
      ")

plot(dag_studie_b)
```

Betrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nützlichen (Reduktion des Blutdrucks).




:::callout-important
Betrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. 
Stratifizieren wäre falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wäre.
:::






### Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell


Vergleichen Sie die DAGs @fig-dag-studie-a und @fig-dag-studie-b,
die die *Kausalmodelle* der Studien A und B darstellen:
Sie sind *unterschiedlich*.
Aber: Die *Daten* sind *identisch*.



Kausale Interpretation - und damit Entscheidungen für Handlungen - war nur möglich, da das Kausalmodell bekannt ist. 
Die Daten alleine reichen nicht.
Gut merken.





### Sorry, Statistik: Du allein schaffst es nicht




Statistik alleine reicht nicht für Kausalschlüsse. 🧟
Statistik plus Theorie erlaubt Kausalschlüsse. 📚➕📊  🟰  🤩



:::callout-important
Für Entscheidungen ("Was soll ich tun?") braucht man kausales Wissen.
Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.
:::


### Vertiefung^[Dieser Abschnitt ist prüfungsrelevant, birgt aber nichts Neues.]




#### Studie C: Nierensteine



Nehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ärzte tendieren zu Behandlung A bei großen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ärzte zu Behandlung B. 


Sollte ein Patient, der nicht weiß, ob sein Nierenstein groß oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach Steingröße) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wählt?










Die Größe der Nierensteine hat einen Einfluss auf die Behandlungsmethode.
Die Behandlung hat einen Einfluss auf die Heilung.
Damit gibt es eine Mediation ("Kette") von Größe $\rightarrow$ Behandlung $\rightarrow$ Heilung.
Darüber hinaus gibt es noch einen Einfluss von Größe der Nierensteine auf die Heilung.

Das Kausalmodell ist in @fig-dag-studie-c dargestellt; @fig-dag-studie-c2 visualisiert alternativ.

Sollte man hier `size` kontrollieren,
wenn man den Kausaleffekt von `treatment` schätzen möchte? 
Oder lieber nicht kontrollieren?




```{r dag-studie-c}
#| echo: false
#| fig-cap: "DAG zur Nierenstein-Studie"
#| out-width: "50%"
#| label: fig-dag-studie-c
dag_studie_c <-
  dagitty("dag{
         size -> recovery
         size -> treatment
         treatment -> recovery
          }
      ")

coordinates(dag_studie_c) <-
  list(x = c(size = 0, treatment = 0, recovery  = 1),
       y = c(size = 0, treatment = 1, recovery = 0.5))
plot(dag_studie_c)


```


```{r dag-c2}
#| echo: false
#| fig-cap: "DAG zur Nierenstein-Studie in zweiter Darstellungsform"
#| out-width: "50%"
#| label: fig-dag-studie-c2
coordinates(dag_studie_c) <-
  list(x = c(size = 0.5, treatment = 0, recovery  = 1),
       y = c(size = 0, treatment = 1, recovery = 1))
plot(dag_studie_c)
```

Ja: In diesem Fall sollte man `size` kontrollieren,
denn man ist am Effekt des `treatments` interessiert.
Würde man nicht `size` kontrollieren,
bekäme man den "vermengten" Effekt von `size ` und `treatment`,
also keine (belastbare) Aussage über den Effekt der Behandlung.




#### Mehr Beispiele

Nehmen Sie Bezug zu folgenden Aussagen:


>   Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhöhen, wenn du heiratest.





>   Studien zeigen, dass Leute, die sich beeilen, zu spät zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spät zu deiner Besprechung.







### Zwischenfazit

Bei *Beobachtungsstudien* ist aus den Daten alleine nicht herauszulesen,
ob eine Intervention wirksam ist,
ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt.
Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist.
Nur Kenntnis des Kausalmodells zusätzlich zu den Daten erlaubt,
eine Entscheidung sinnvoll zu treffen.

Bei *experimentellen Daten* ist die Kenntnis des Kausalmodells nicht nötig (wenn das Experiment handwerklich gut gestaltet ist):
Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafür,
dass es keine Konfundierung gibt.





## Konfundierung

\newcommand{\indep}{\perp \!\!\! \perp}




### Datensatz 'Hauspreise im Saratoga County'


Wir nutzen den Datensatz [Saratoga County](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv); s. @tbl-saratoga.
Hier gibt es eine 
[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SaratogaHouses.html).


```{r data-saratoga, echo = TRUE}
d_path <- "https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv"
```



```{r read-data, echo = FALSE}
#| message: false
d <- data_read(d_path)  # aus easystats
```

```{r}
#| echo: false
#| label: tbl-saratoga
#| tbl-cap: "Saratoga-County-Datensatz"
d %>% 
  select(price, livingArea, bedrooms,waterfront) %>% 
  slice_head(n = 5)
```




### Immobilienpreise in einer schicken Wohngegend vorhersagen



>   "Finden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!"

🧑 Das ist Don, Immobilienmogul, Auftraggeber.



>   Das finde ich heraus. Ich mach das wissenschaftlich.

👩 🔬 Das ist Angie, Data Scientistin.



### Modell 1: Preis als Funktion der Anzahl der Zimmer



>   "Hey Don! Mehr Zimmer, mehr Kohle!"
👩 🔬


Modell 1 (`m1`) modelliert den Hauspreis als Funktion der Zimmerzahl, s. @fig-m1.



```{r d-plot-don1}
#| echo: false
#| message: false
#| label: fig-m1
#| fig-cap: "Modell m1"
d %>% 
  ggplot() +
  aes(x = bedrooms, y = price) +
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm")
```






>   "Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don."

👩

>   Zu wenig! 🤬

🧑


Berechnen wir das Modell `m1`; der Punktschätzer des Parameters `bedroom` steht in @tbl-m1-hdi.


```{r m1, echo = TRUE}
#| results: hide
m1 <- stan_glm(price ~ bedrooms,
               refresh = 0,
               seed = 42,
               data = d)

point_estimate(m1)
```



```{r}
#| label: tbl-m1-hdi
#| tbl-cap: "Parameter für m1"
#| echo: false
point_estimate(m1)
```


`point_estimates(modell)` gibt die Punktschätzer der Parameter eines Modells zurück,
aber nicht die Schätzbereiche. Möchten Sie beides, können Sie die Funktion `parameters(modell)` nutzen.^[In aller Regel macht es mehr Sinn, die Schätzbereiche der Punktschätzer auch zu betrachten. Nur die Punktschätzer zu betrachten vernachlässigt wesentliche Information.]

Mit `estimate_predictions` können wir Vorhersagen berechnen (bzw. schätzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist "schätzen" vielleicht das treffendere Wort).
@tbl-m1-pred zeigt den laut `m1` vorhergesagten Hauspreis für ein Haus mit 2 Zimmern.


```{r echo = TRUE}
#| results: hide
dons_house <- tibble(bedrooms = 2)
estimate_prediction(m1, data = dons_house)
```


```{r}
#| tbl-cap: "Vorhersage des Hauspreises für ein Haus mit 2 Zimmern"
#| label: tbl-m1-pred
#| echo: false
estimate_prediction(m1, data = dons_house) |> display() 
```



### Don hat eine Idee 



>   "Ich bau eine Mauer! Genial! An die Arbeit, Angie!" 
🧑

Don hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?

>   "Das ist keine gute Idee, Don."

👩

Berechnen wir die Vorhersagen für Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. @tbl-m1-pred2a.^[Anstelle  von `estimate_relation()` kann man auch (einfacher vielleicht) `predict()` verwenden: `predict(m1, newdata = dons_new_house)`. Allerdings gibt `predict()` nur den vorhergesagten Wert aus. `estimate_prediction()` gibt noch zusätzlich das *Vorhersageintervall* aus, berücksichtigt also die (doppelte) Ungewissheit der Vorhersage. Mit anderen Worten: `estimate_prediction` gibt die PPV aus.]


```{r}
#| results: hide
dons_new_house <- tibble(bedrooms = 4)
estimate_prediction(m1, dons_new_house)
predict(m1, newdata = dons_new_house)
```


```{r}
#| tbl-cap: "Vorhergesagter Hauspreis laut m1 für ein Haus mit 4 Zimmern"
#| label: tbl-m1-pred2a
#| echo: false
estimate_prediction(m1, dons_new_house) |> display()
```



Mit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut `m1`, @fig-m1.


>   "Volltreffer! Jetzt verdien ich 100 Tausend mehr! 🤑 Ich bin der Größte!"
🧑




:::callout-note
Zur Erinnerung: "4e+05" ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: $4 \cdot 100000 = 4\cdot10^5 = 400000$
:::


### R-Funktionen, um Beobachtungen vorhersagen 



`estimate_prediction(m1, dons_new_house)` erstellt *Vorhersageintervalle*, berücksichtigt also *zwei Quellen* von Ungewissheit:

- Ungewissheiten in den Parametern (Modellkoeffizienten, $\beta_0, \beta_1, ...$)
- Ungewissheit im "Strukturmodell": Wenn also z.B. in unserem Modell ein wichtiger Prädiktor fehlt, so kann die Vorhersagen nicht präzise sein. Fehler im Strukturmodell schlagen sich in breiten Schätzintervallen (bedingt durch ein großes $\sigma$) nieder.



`estimate_expectation(m1, dons_new_house)` erstellt *Konfidenzintervalle*.  berücksichtigt also nur *eine Quelle* von Ungewissheit:

- Ungewissheiten in den Parametern (Modellkoeffizienten, $\beta_0, \beta_1, ...$)


Die Schätzbereiche sind in dem Fall deutlich kleiner, s. @tbl-m1-dons-new.


```{r plot-m1-dons-new-house}
#| eval: false
estimate_expectation(m1, dons_new_house)
```


```{r plot-m1-dons-new-house-show}
#| echo: false
#| label: tbl-m1-dons-new
#| fig-cap: "Ungewissheit für die Parameter, also die Regressionsgerade, nicht die Beobachtungen"
estimate_expectation(m1, dons_new_house) |> display()
```



### Modell 2


Berechnen wir das Modell  `m2: price ~ bedrooms + livingArea`.
@tbl-m2 gibt den Punktschätzer für die Koeffizienten wider.

```{r, echo = TRUE}
#| results: hide
m2 <- stan_glm(price ~ bedrooms + livingArea, 
               data = d, 
               seed = 42,
               refresh = 0)

point_estimate(m2, centrality = "median")
```

```{r}
#| tbl-cap: "Parameter (Punktschätzer, keine Schätzung der Ungewissheit) von m2"
#| label: tbl-m2
#| echo: false
point_estimate(m2, centrality = "median") |> display()
```



Was sind die Vorhersagen des Modell? 
@tbl-m2-pred gibt Aufschluss für den laut `m2` vorhersagten Kaufpreis eines Hauses
mit 4 Zimmern und 1200 Quadratfuß Wohnfläche; @tbl-m2-pred2 gibt die Schätzung (laut `m2`) für den Preis eines Hauses mit 2 Zimmern (und der gleichen Wohnfläche).
Die Vorhersage erhält man mit dem Befehl `predict()`:

```{r}
predict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))
```



```{r m2-pred, echo = TRUE}
#| echo: false
#| tbl-cap: "Vorhersage von m2 für ein Haus mit *4* Zimmern und 1200 Einheiten Wohnfläche"
#| label: tbl-m2-pred
estimate_prediction(m2, data = tibble(bedrooms = 4, livingArea = 1200))
```


```{r m2-pred2, echo = FALSE}
#| tbl-cap: "Vorhersage von m2 für ein Haus mit *2* Zimmern und 1200 Einheiten Wohnfläche"
#| label: tbl-m2-pred2
#| echo: false
estimate_prediction(m2, data = tibble(bedrooms = 2, livingArea = 1200))
```




Andere, aber ähnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer *gemittelt* über die verschiedenen Größen von `livingArea`? Stellen Sie sich alle Häuser mit 4 Zimmern vor (also mit verschiedenen Wohnflächen). Wir möchten nur wissen, was so ein Haus "im Mittel" kostet.
Wir möchten also die Mittelwerte pro `bedroom` schätzen, gemittelt für jeden Wert von `bedroom` über `livingArea`.
Die Ergebnisse stehen in @tbl-m2-estimate-pred2 und sind in @fig-m2-preds visualisiert.

```{r m2-pred-means}
#| label: tbl-m2-estimate-pred2
#| tbl-cap: "Vorhersagen des Preises von Häusern mit verschiedener Zimmerzahl gemittelt über die verschiedenen Werte der Wohnfläche; basierend auf m2."
estimate_means(m2, at = "bedrooms", length = 7)
```


```{r}
#| echo: false
#| label: fig-m2-preds
#| fig-asp: 0.3
#| fig-cap: "Hauspreis als Funktion der Zimmerzahl, laut m2"
estimate_means(m2, at = "bedrooms", length = 7) %>% 
  ggplot() +
  aes(x = bedrooms, y = Mean) +
  geom_line() +
  geom_point(alpha = .7) 
```




>   "Die Zimmer zu halbieren,
hat den Wert des Hauses *verringert*,
Don!"

👩


>   "Verringert!? Weniger Geld?! Oh nein!"

🧑





### Die Zimmerzahl ist negativ mit dem Preis korreliert 

... wenn man die Wohnfläche (Quadratmeter) kontrolliert, s. @fig-m2-negativ.



>   **"Ne-Ga-Tiv!"**

👩


![Hauspreis stratifizieren](img/hauspreis1.png){#fig-m2-negativ fig-asp=.5}

[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Hauspreis-stratifizieren.Rmd)


## Kontrollieren von Variablen


💡 Durch das Aufnehmen von Prädiktoren in die multiple Regression werden die Prädiktoren *kontrolliert* (adjustiert, konditioniert):

Die Koeffizienten einer multiplen Regression zeigen den Zusammenhang $\beta$ des einen Prädiktors mit $y$, wenn man den (oder die) anderen Prädiktoren statistisch *konstant hält*. 

Man nennt die Koeffizienten einer multiplen Regression daher auch *parzielle Regressionskoeffizienten*. Manchmal spricht man, eher umgangssprachlich, auch vom "Netto-Effekt" eines Prädiktors, oder davon, dass ein Prädiktor "bereinigt" wurde vom (linearen) Einfluss der anderen Prädiktoren auf $y$.

Damit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Prädiktors $x_1$ auf $y$ anzeigen *unabhängig* vom Effekt der anderen Prädiktoren, $x_2,x_3,...$ auf $y$.

Man kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Prädiktors $x_1$ wird für jede Ausprägung (Gruppe) des Prädiktors $x_2$ berechnet.




### Das Hinzufügen von Prädiktoren kann die Gewichte der übrigen Prädiktoren ändern






>   Aber welche und wie viele Prädiktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!

🧑

>   Leider kann die Statistik keine Antwort darauf geben.

👩


>   Wozu ist sie dann gut?!

🧑


:::callout-important
In Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erklärung der Ursachen heranzuziehen:
Die Regressionskoeffizienten können sich wild ändern, wenn man Prädiktoren hinzufügt oder weglässt. 
Es können sich sogar die Vorzeichen der Regressionsgewichte ändern;
in dem Fall spricht man von einem Simpson-Paradox.
:::




## Welches Modell richtig ist, kann die Statistik nicht sagen

>   Often people want statistical modeling to do things that statical modeling cannot do.
For example, we'd like to know wheter an effect is "real" or rather spurios.
Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem.
Usually answers to lage world questions about truth and causation depend upon information not included in the model.
For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model.
But if we cannot think of the right variable,
we might never notice.
Therefore all statical models are vulnerable to and demand critique,
regardless of the precision of their estimates
and apparaent accuracy of their predictions.
Rounds of model criticism and revision embody the real tests of scientific hypotheses.
A true hypothesis will pass and fail many statistical "tests" on its way to acceptance.


@mcelreath_statistical_2020, S. 139



### Kausalmodell für Konfundierung, `km1`

Das Kausalmodell `km1` ist in @fig-km1 dargestellt; vgl.  @fig-m2-negativ.


```{r km1, fig.asp = .33, fig.width=9}
#| echo: false
#| warning: false
#| label: fig-km1
#| fig-cap: "Kausalmodell km1 - Eine Erklärung (von mehreren) für m1 bzw. die Daten, die m1 zugrunde liegen"
km1 <- confounder_triangle(x = "bedrooms",
                          y = "price",
                          z = "living area") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()

print(km1)
```

Wenn dieses Kausalmodell stimmt, findet man eine *Scheinkorrelation* zwischen `price` und `bedrooms`.

Eine Scheinkorrelation ist ein Zusammenhang, der *nicht* auf eine kausalen Einfluss beruht.

`d_connected` heißt, dass die betreffenden Variablen "verbunden" sind durch einen gerichteten (`d` wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss fließt 🌊. `d_separated` heißt, dass sie nicht `d_connected` sind.


### `m2` kontrolliert die Konfundierungsvariable `livingArea`

Wenn das Kausalmodell stimmt, dann zeigt `m2` den kausalen Effekt von `livingArea`.

>   Was tun wir jetzt bloß?! Oh jeh!

🧑


>   Wir müssen die Konfundierungsvariable kontrollieren.

👩


@fig-km1-controlled zeigt, dass `bedrooms` und `price` *unkorreliert* werden (`d_separated`), wenn man `living area` kontrolliert.

```{r confounder-triangle, fig.asp = 0.45, fig.width=9, dpi=300}
#| echo: false
#| warning: false
#| label: fig-km1-controlled
#| fig-cap: "Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben."
confounder_triangle(x = "bedrooms",
                          y = "price",
                          z = "living area") %>% 
 ggdag_dconnected(text = FALSE, use_labels = "label", 
                  controlling_for = "z") +
  theme_dag()
```

Durch das Kontrollieren ("adjustieren"), sind `bedrooms` und `price` nicht mehr korreliert, nicht mehr `d_connected`, sondern jetzt `d_separeted`.


### Konfundierer kontrollieren

Gehen wir in diesem Abschnitt davon aus, dass `km1` richtig ist.


```{r}
#| echo: false
source("https://raw.githubusercontent.com/sebastiansauer/QM2-Folien/41bc43754169f64abd6ad98f8d52b5c0e23eda80/R-Code/controlling-confounder.R")
```



*Ohne* Kontrollieren der Konfundierungsvariablen: Regressionsmodell `y ~ x`, @fig-p-konf1, links:
Es wird (fälschlich) eine Korrelation zwischen `x` und `y`  angezeigt: Scheinkorrelation.
*Mit* Kontrollieren der Konfundierungsvariablen: Regressionsmodell `y ~ x + group`, @fig-p-konf1, rechts.

```{r}
#| echo: false
#| fig-cap: "Konfundierung von y und x!"
#| layout-ncol: 2
#| fig-subcap: 
#|   - "Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf."
#|   - "Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf."
#| label: fig-p-konf1
p_konf1
p_konf2
```





@fig-p-konf1, rechts, zeigt korrekt, dass es keine Korrelation zwischen `x` und `y` gibt, wenn `group` kontrolliert wird.
Außerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable `group` durch Aufnahme als Prädiktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).






[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Konfundierer-kontrollieren.Rmd)






### `m1` und `m2` passen nicht zu den Daten, wenn `km1` stimmt






Laut `km1` dürfte es keine Assoziation (Korrelation) zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert, wie in @fig-km1 dargestellt.
Es gibt aber noch eine Assoziation zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert.
 Daher sind sowohl `m1` und `m2` nicht mit dem Kausalmodell `km1` vereinbar.





### Kausalmodell 2, `km2` 

Unser Modell `m2` sagt uns, 
dass beide Prädiktoren jeweils einen eigenen Beitrag zur Erklärung der AV haben.



Daher könnte das folgende Kausalmodell, `km2` besser passen.

In diesem Modell gibt es eine *Wirkkette*: $a \rightarrow b \rightarrow p$.

Insgesamt gibt es zwei Kausaleinflüsse von `a` auf `p`:
    - $a \rightarrow p$
    - $a \rightarrow b \rightarrow p$

Man nennt die mittlere Variable einer Wirkkette auch einen *Mediator* und den Pfad von der UV (`a`) über den Mediator (`b`) zur AV (`p`) auch *Mediation*, s. @fig-m1-mediation.



```{r km2}
#| echo: false
#| fig-cap: "Der Effekt von livingArea wird über den Mediator bedrooms auf price vermittelt."
#| label: fig-m1-mediation
km2 <- 
  dagify(
  b ~ a,
  p ~ a,
  p ~ b,
  labels = c(b = "bedrooms",
             p = "price",
             a = "livingArea")) %>% 
    ggdag(use_labels = "label") +
  theme_dag()

print(km2)
```






### Dons Kausalmodell, `km3`

So sieht Dons Kausalmodell aus, s. @fig-km3.


```{r km3, fig.width=9}
#| echo: false
#| out-width: "50%"
#| label: fig-km3
#| fig-cap: "Dons Kausalmodell"
km3 <- collider_triangle(x = "bedrooms",
                          y = "livingArea",
                          m = "price") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()

print(km3)
```



>   "Ich glaube aber an mein Kausalmodell. Mein Kausalmodell ist das größte! Alle anderen Kausalmodelle sind ein Disaster!"

🧑

</br>

>   "Don, nach deinem Kausalmodell müssten `bedrooms` und `livingArea` unkorreliert sein. Sind sie aber nicht."

🧑


Rechne doch selber die Korrelation aus, Don:


>   "Äh, wie ging das nochmal?"

🧑


So könntest du das rechnen, Don: `correlation(d, select = c("bedrooms", "livingArea"))`. 
Oder z.B. so:

```{r}
dons_r <- d %>% 
  summarise(cor(bedrooms, livingArea))
```

Die Korrelation liegt also bei `r  round(cor(d$bedrooms, d$livingArea), 2)`


>   "Bitte, gerne hab ich dir geholfen, Don."

👩






### Unabhängigkeiten laut der Kausalmodelle


`km1`: `b`: bedrooms, `p`: price, `a` area (living area), s. @fig-km1.



Das Kausalmodell `km1` behauptet: $b \indep p \, |\, a$: `bedrooms` sind unabhängig von `price`, wenn man `livingArea` kontrolliert.

*Kontrollieren* einer Variable $Z$ erreicht man auf einfache Art,
indem man sie in zusätzlich zur vermuteten Ursache $X$ in die Regressionsgleichung mit aufnimmt, also `y ~ x + z`. 


Aber diese behauptete Unabhängigkeit findet sich *nicht* in den Daten wieder, s. @tbl-m2. Also: ⛈️ Passt nicht zu den Daten!






`km2` `b`: bedrooms, `p`: price, `a` area (living area), s. @fig-m1-mediation.



Das Kausalmodell `km2` postuliert *keine* Unabhängigkeiten:
Laut `km2`sind alle Variablen des Modells miteinander assoziiert (korreliert).

:::callout-note
Ein Modell, in dem alle Variablen miteinander korreliert sind,
nennt man auch *satuiert* oder saturiertes Modell.
So ein Modell ist empirisch *schwach*.
Denn: Behauptet ein Modell, 
dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 beträgt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). 
So ein Modell ist wissenschaftlich wenig wert. 
Das ist so ähnlich wie ein Modell, das voraussagt,
dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein,
so werden wir nicht gerade beeindruckt sein. 🥱
:::

Fazit: `km2` passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.






`km3`: `b`: bedrooms, `p`: price, `a` area (living area), s. @fig-km3.





$b \indep a$: `bedrooms` sind unabhängig von `livingArea` (`a`)


⛈️ `km3` passt nicht zu den Daten/zum Modell!





## DAGs: Directed Acyclic Graphs


Was sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B.  @fig-km3.

- DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.

- Ein *Graph* besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.

- DAGs sind *gerichtet*; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).

- DAGs sind *azyklisch*; die Wirkung eines Knoten darf nicht wieder auf ihn zurückführen. 

- Ein *Pfad* ist ein Weg durch den DAG, von Knoten zu Knoten über die Kanten, unabhängig von der Pfeilrichtung.



Der DAG von `km1` ist in @fig-km1 zu sehen.


### Leider passen potenziell viele DAGs zu einer Datenlage

`b`: bedrooms, `p`: price, `a` area (living area)


Ja, der Job der Wissenschaft ist kein Zuckerschlecken.
Aber wenn es einfach wäre, die Kausalstruktur der Phänomene zu entdecken,
wären sie längst erkannt, und alle Probleme der Menschheit gelöst.

In @fig-kms sind mögliche Kausalmodelle für Dons Studie dargestellt.


```{r dag-km1, fig.width=9}
#| echo: false
#| label: fig-kms
#| fig-cap: "Kausalmodelle, die potenziell geeignet sind für Dons Fragestellung"
dag_km1 <-
  dagitty("dag{
         a -> b
         a -> p
         }
         ")


coordinates(dag_km1) <- list(
  x = list(a = 0, b = 1, p = 1),
  y = list(a = 0.5, b= 1, p = 0 )
)

ggdag_equivalent_dags(dag_km1) +
  theme_dag()
```


Alle diese DAgs in @fig-km1 haben die *gleichen* Implikationen hinsichtlich der (Un-)Abhängigkeiten zwischen der Variablen.
Wir können also leider empirisch nicht bestimmen,
welcher der DAGs der richtige ist.
Um den richtigen DAG zu identifizieren, bräuchten wir z.B. einen reichhaltigeren DAG,
also mit mehr Variablen.




### Was ist eigentlich eine Ursache?

Etwas verursachen kann man auch (hochtrabend) als "Kausation" bezeichnen.

:::callout-note
Weiß man, was die Wirkung $W$ einer Handlung $H$ (Intervention) ist,  so hat man $H$ als Ursache von $W$ erkannt.
:::
  
@mcelreath_statistical_2020


Viele Menschen denken - fälschlich - dass Korrelation Kausation bedeuten muss, s. @fig-xkcd-causation.


```{r}
#| echo: false
#| fig-align: "center"
#| out-width: "50%"
#| label: fig-xkcd-causation
#| fig-cap: "xkcd zum Thema Kausation"
knitr::include_graphics("img/correlation.png")
```


[Quelle](https://xkcd.com/552/) und [Erklärung](https://www.explainxkcd.com/wiki/index.php/552:_Correlation)





### Zwischenfazit

Sind zwei Variablen korreliert (abhängig, assoziiert), so kann es dafür zwei Gründe geben:

- Kausaler Zusammenhang
- Nichtkausaler Zusammenhang ("Scheinkorrelation")
    
Eine mögliche Ursache einer Scheinkorrelation ist Konfundierung.

Konfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Prädiktor in eine Regression aufnimmt.

Ist die Annahme einer Konfundierung korrekt, so löst sich der Scheinzusammenhang nach dem Adjustieren auf.

Löst sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenhänge nach Adjustieren um, so spricht man einem *Simpson-Paradox*.

Die Daten alleine können nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nötig, um DAGs auszuschließen.






### Schoki macht Nobelpreis! (?)

🏎️ Vertiefung 🏎️



Eine Studie fand eine starke Korrelation, $r=0.79$ zwischen (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes [@messerli_chocolate_2012], s. @fig-schoki.


```{r schoki-plot, out.width="50%"}
#| echo: false
#| warning: false
#| fig-align: "center"
#| label: fig-schoki
#| fig-cap: "Je mehr Schoki, desto mehr Nobelpreise"
knitr::include_graphics("img/correlation_550.png")
```



:::callout-important
Korrelation ungleich Kausation! Korrelation *kann* bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt.
Liegt Korrelation ohne Kausation vor, so spricht man von einer *Scheinkorrelation*.
Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen,
muss man die Kausalmodelle überprüfen,
so wie wir das hier tun.
:::











Der "Schoki-DAG" in @fig-schoki-dag zeigt den DAG für das Schokoloaden-Nobelpreis-Modell.

```{r schok-dag, fig.width=7}
#| echo: false
#| label: fig-schoki-dag
#| fig-cap: "Macht Schokolade Nobelpreise?"
confounder_triangle(x = "Schoki",
                          y = "Nobelpreise",
                          z = "Entwicklungsstand") %>% 
  ggdag_dconnected(text = FALSE, use_labels = "label") +
  theme_dag()
```













## Kollision









### Kein Zusammenhang von Intelligenz und Schönheit (?)

Gott ist gerecht (?)

Zumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (`talent`) und Schönheit (`looks`),
wie @fig-iq-schoen illustriert.
Für geringe Intelligenzwerte gibt es eine breites Spektrum von Schönheitswerten
und für hohe Intelligenzwerte sieht es genauso aus.

```{r p-coll1}
#| echo: false
#| out-width: "50%"
#| label: fig-iq-schoen
#| fig-cap: "Kein Zusammenhang von Intelligenz und Schönheit in den Daten"

myf <- function(x) -x+0.75

myf2 <- function(x) -x + 1.25

n <- 1e3

d2 <- tibble(
  x = runif(n),
  y = runif(n),
  status = case_when(
    y > myf(x) & y < myf2(x) ~ TRUE,
    TRUE ~ FALSE
  )
)


p_coll1 <-
  d2 %>% 
  ggplot() +
  aes(x  = x,
      y = y) +
  geom_point() +
 # scale_color_manual(values = c("grey80", "black")) +
  theme_bw() +
  labs(x = "Looks",
       y = "Talent") +
    theme(legend.position = "bottom",
          axis.text = element_blank())

p_coll1
```

[Gott ist gerecht (?)](https://twitter.com/TheTweetOfGod/status/1462594155176026123)




### Aber Ihre Dates sind entweder schlau oder schön

Seltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates),
entweder schön sind oder schlau - aber seltens beides gleichzeitig (schade),
s. @fig-dates-beauty.


```{r p-coll2}
#| echo: false
#| label: fig-dates-beauty
#| fig-cap: Ihre Datingpartner sind komischerweise entweder schlau oder schön (aber nicht beides), zumindest in der Tendenz.
#| out-width: "50%"
p_coll2 <- 
  d2 %>% 
  ggplot() +
  aes(x  = x,
      y = y,
      color = status) +
  geom_point() +
  scale_color_manual(values = c("grey80", "black")) +
  theme_bw() +
  labs(x = "Looks",
       y = "Talent") +
    theme(legend.position = "bottom",
          axis.text = element_blank())

p_coll2
```

Wie kann das sein?




## DAG zur Rettung 

🦹 🦸

Der DAG in @fig-coll1-dag bietet eine rettende Erklärung.




```{r plot-coll-dag1}
#| echo: false
#| fig-cap: "Date als gemeinsame Wirkung von Schönheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Schönheit und Intelligenz."
#| out-width: "50%"
#| label: fig-coll1-dag

coll1_dag <-
  dagify(date ~ Looks + Talent)

p_coll_dag1 <- 
coll1_dag %>% 
  ggdag() +
  theme_dag()

p_coll_dag1
```


Eine ähnliche Visualisierung des gleichen Sachverhalts zeigt @fig-coll2-dag.

```{r p-coll-dag22, fig.width=9}
#| echo: false
#| label: fig-coll2-dag
#| fig-cap: "Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen"
p_coll_dag2 <-
  collider_triangle(x = "Looks",
                  y = "Talent",
                  m = "date") %>% 
  ggdag_dseparated(controlling_for = "m",
                   text = TRUE,
                   use_labels = "label") +
  theme_dag()

p_coll_dag2
```




```{r eval = FALSE}
#| echo: false
#| eval: false
ggdag_adjust(coll1_dag, var = "date") +
  theme_dag()
```



### Was ist eine Kollision?



Als *Kollision* (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen).
Kontrolliert man  die *Wirkung* `m`, so entsteht eine Scheinkorrelation zwischen den Ursachen `x` und `y`.
Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. @fig-coll1-dag, vgl. @rohrer_thinking_2018.


::: callout-important
Man kann also zu viele oder falsche Prädiktoren einer Regression hinzufügen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.
:::


### Einfaches Beispiel zur Kollision



In der Zeitung *Glitzer* werden nur folgende Menschen gezeigt:

- Schöne Menschen
- Reiche Menschen
    
Sehen wir davon aus, dass Schönheit und Reichtum unabhängig voneinander sind.

Wenn ich Ihnen sage, dass Don nicht schön ist, aber in der Glitzer häufig auftaucht, was lernen wir dann über seine finanzielle Situation?^[Don muss reich sein.]




>   "Ich bin schön, unglaublich schön, und groß, großartig, tolle Gene!!!" 🧑





### Noch ein einfaches Beispiel zur Kollision

>   "So langsam check ich's!" 🧑



Sei Z = X + Y, wobei X und Y unabhängig sind.

Wenn ich Ihnen sage, X = 3, lernen Sie nichts über Y, da die beiden Variablen unabhängig sind
 Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).

Also: X und Y sind abhängig, gegeben Z: $X \not\indep Y \,|\, Z$.^[Der horizontale Balken "|" bedeutet "gegeben, dass". Ein Beispiel lautet $Pr(A|B)$: "Die Wahrscheinlichkeit von A, gegeben dass B der Fall ist.]


### Durch Kontrollieren entsteht eine Verzerrung bei der Kollision


@fig-coll1-dag zeigt: Durch Kontrollieren entsteht eine Kollision,
eine Scheinkorrelation zwischen den Ursachen.

*Kontrollieren* kann z.B. bedeuten:

- *Stratifizieren*: Aufteilen von `date` in zwei Gruppen und dann Analyse des Zusammenhangs von `talent` und `looks` in jeder Teilgruppe von `date`
- *Kontrollieren mit Regression*: Durch Aufnahme von `date` als Prädiktor in eine Regression zusätzlich zu `looks` mit `talent` als Prädikotr


*Ohne* Kontrolle von `date` entsteht *keine* Scheinkorrelation zwischen `Looks` und `Talent`. Der Pfad ("Fluss") von `Looks` über `date` nach `Talent` ist blockiert.

Kontrolliert man `date`, so *öffnet* sich der Pfad `Looks -> date -> talent` und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr "blockiert", die
Korrelation kann "fließen" - was sie hier nicht soll,
denn es handelt sich um Scheinkorrelation.

Das Kontrollieren von `date` geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.




### IQ, Fleiss und Eignung fürs Studium


Sagen wir, über die *Eignung* für ein Studium würden nur (die individuellen Ausprägungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in @fig-coll3-dag.

```{r coll32-dag}
#| echo: false
#| label: fig-coll3-dag
#| fig-cap: Kollisionsstruktur im Dag zur Studiumseignung
coll2_dag <- ggdag::dagify(s ~ d + iq,
                      outcome = "s",
                      labels = c("s" = "Studium",
                                 "iq" = "Intelligenz",
                                 "d" = "Fleiss"))

p_coll_dag2 <- ggdag(coll2_dag, use_labels = "label")  + theme_dag_blank()
p_coll_dag2

# coll2_dag <-
#   dagify(eignung ~ fleiss + iq)
# 
# p_coll_dag2 <- 
# coll2_dag %>% 
#   ggdag() +
#   theme_dag()
# 
# p_coll_dag2
```

Bei positiver `eignung` wird ein Studium aufgenommen (`studium = 1`) ansonsten nicht (`studium = 0)`. 


[Quelle](https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/)



`eignung` (fürs Studium) sei definiert als die Summe von `iq` und `fleiss`, plus etwas Glück:

```{r d-eignung, echo = TRUE}
set.seed(42)  # Reproduzierbarkeit
N <- 1e03  

d_eignung <-
tibble(
  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1
  fleiss = rnorm(N),
  glueck = rnorm(N, mean = 0, sd = .1),
  eignung = 1/2 * iq + 1/2 * fleiss + glueck,
  # nur wer geeignet ist, studiert (in unserem Modell):
  studium = ifelse(eignung > 0, 1, 0) 
  )
```

Laut unserem Modell setzt sich Eignung zur Hälfte aus Intelligenz und zur Hälfte aus Fleiss zusammen, plus etwas Glück.



### Schlagzeile "Schlauheit macht Studentis faul!"

Eine Studie untersucht den Zusammenhang von Intelligenz (iq) und Fleiß (f) bei Studentis (s).
Ergebnis: Ein *negativer* Zusammenhang!?



Berechnen wir das "Eignungsmodell", aber nur mit Studis (`studium == 1`, also ohne Nicht-Studis), 
s. @tbl-m-eignung.

```{r}
#| results: hide
m_eignung <-
  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)

hdi(m_eignung)
```

```{r}
#| tbl-cap: "Zum Zusammenhang von Fleiss und Talent"
#| label: tbl-m-eignung
#| echo: false
hdi(m_eignung) |> display()
```




@fig-eignung zeigt das Modell und die Daten.

```{r}
#| echo: false
#| label: fig-eignung
#| fig-cap: "Der Zusammenhang von Fleiss und IQ"

d_eignung %>% 
  filter(studium == 1) %>% 
  ggplot(aes(x = fleiss, y = iq)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm") +
  labs(title = "Negativer Zusammenhang von Fleiss und IQ bei Studentis",
       subtitle = "Macht Fleiss blöd?")
```


IQ ist *nicht* unabhängig von Fleiß in unseren Daten, sondern abhängig.

Nichtwissenschaftliche Berichte, etwa in einigen Medien,
greifen gerne Befunde über Zusammenhänge auf und interpretieren die Zusammenhänge
-- oft vorschnell -- als kausal.^[Ehrlicherweise muss man zugeben, dass auch wissenschaftliche Berichte Daten über Zusammenhänge gerne kausal interpretieren, oft vorschnell.]





### Kollisionsverzerrung nur bei Stratifizierung

Nur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. @fig-eignung-strat.


:::callout-note
*Ohne* Stratifizierung tritt *keine* Scheinkorrelation auf.
*Mit* Stratifizierung tritt Scheinkorrelation auf.
:::



```{r}
#| echo: false
#| fig-cap: "Stratifizierung und Scheinkorrelation"
#| label: fig-eignung-strat
p1 <- d_eignung %>% 
 ggplot(aes(x = fleiss, y = iq)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")

p2 <- 
d_eignung %>% 
  mutate(studium = factor(studium)) %>% 
  ggplot(aes(x = fleiss, y = iq, color = studium)) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")


plots(p1, p2,
      title = c("Kein Stratifizierung, keine Scheinkorrelation",
               "Mit Stratifizierung gibt es Scheinkorrelation"))
```




Wildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nützen.

*Nur* Kenntnis des DAGs verrät die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.


:::callout-note
Nimmt man eine Variable als zweiten Prädiktor auf,
so "kontrolliert" man diese Variable. Das Regressiongewicht des ersten Prädiktors wird "bereinigt" um den Einfluss des zweiten Prädiktors; insofern ist der zweite Prädiktor dann "kontrolliert".
:::




### Einfluss von Großeltern und Eltern auf Kinder





Wir wollen hier den (kausalen) Einfluss der Eltern `E` und Großeltern `G` auf den *Bildungserfolg* der Kinder `K` untersuchen.

Wir nehmen folgende Effekte an:

- indirekter Effekt von `G` auf `K`: $G \rightarrow E \rightarrow K$
- direkter Effekt von `E` auf `K`: $E \rightarrow K$
- direkter Effekt von `G` auf `K`: $G \rightarrow K$


Wir sind v.a. interessiert an $G \rightarrow K$, dem *direkten kausalen* Effekt von Großeltern auf ihre Enkel, s. @fig-dag-grannies [@kurz_statistical_2021], $G \rightarrow K$.





```{r}
#| echo: false
#| label: fig-dag-grannies
#| fig-cap: "Der kausale Effekt von Großeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft"
dag_coords <-
  tibble(name = c("G", "E", "K"),
         x    = c(1, 2, 2),
         y    = c(2, 2, 1))

dagify(E ~ G,
       K ~ E + G,
       coords = dag_coords) %>%
  ggdag() +
  theme_dag()
```


Aber was ist, wenn wir vielleicht eine *u*nbekannte Variable übersehen haben? (S. nächster Abschnitt). 👻







### Der Gespenster-DAG

👻

Es gibt "unheilbare" DAGs, nennen wir sie "Gespenster-DAGs",
in denen es nicht möglich ist, einen (unverzerrten) Kausaleffekt zu bestimmen,
s. @fig-dag-ghost.
Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG:
"Deine Theorie ist nicht gut, zurück an den Schreibtisch und denk noch mal gut nach. 
Oder sammele mehr Daten."



```{r}
#| echo: false
#| label: fig-dag-ghost
#| fig-cap: "Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollständig) möglich."
#| out-width: "50%"

# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding
gg_fancy_dag <- function(d, x = 1, y = 1, circle = "U") {
  
  d %>% 
    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(aes(color = name == circle),
                   alpha = 1/2, size = 6.5, show.legend = F) +
    geom_point(x = x, y = y, 
               size = 6.5, shape = 1, stroke = 1, color = "orange") +
    geom_dag_text(color = "black") +
    geom_dag_edges() + 
    scale_color_manual(values = c("steelblue", "orange")) +
    theme_dag()
}

coll4_dag <-
  dagitty("dag
          {
          G -> E
          E -> K
          G -> K
          U -> E
          U -> K
          }
          ")

dag_coords <-
  tibble(name = c("G", "E", "K", "U"),
         x    = c(1, 2, 2, 2.5),
         y    = c(2, 2, 1, 1.5))

dagify(E ~ G + U,
       K ~ E + G + U,
       coords = dag_coords) %>% 
  gg_fancy_dag(x = 2.5, y = 1.5, circle = "U")
```



- `U` könnte ein ungemessener Einfluss sein, der auf `E` und `K` wirkt, etwa *Nachbarschaft*.

- Die Großeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.

- `E` ist sowohl für `G` als auch für `U` eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.

- Wenn wir `E` kontrollieren, wird es den Pfad $G \rightarrow K$ verzerren, auch wenn wir niemals `U` messen.


Die Sache ist in diesem Fall chancenlos. Wir müssen diesen DAG verloren geben, @mcelreath_statistical_2020, S. 180.


















## Die Hintertür schließen



### Zur Erinnerung: Konfundierung





*Forschungsfrage*: Wie groß ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?

`a:` livingArea, `b`: bedrooms, `p`: prize

UV: `b`, AV: `p`


Das Kausalmodell ist in @fig-dag-don1 dargestellt.

```{r}
#| echo: false
#| label: fig-dag-don1
#| fig-cap: "Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfläche beeinflusst"
#| out-width: "50%"


# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding


gg_simple_dag <- function(d) {
  
  d %>% 
    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(color = "steelblue", alpha = 1/2, size = 6.5) +
    geom_dag_text(color = "black") +
    geom_dag_edges() + 
    theme_dag()
}

dag_coords <-
  tibble(name = c("a", "b", "p"),
         x    = c(0, -1, 1),
         y    = c(1, 0, 0))

dagify(p ~ a + b,
       b ~ a,
       coords = dag_coords) %>%
  gg_simple_dag()
```



 Im Regressionsmodell `p ~ b` wird der kausale Effekt verzerrt sein durch die Konfundierung mit `a`.
 Der Grund für die Konfundierung sind die zwei Pfade zwischen `b` und `p`:
 
1. $b \rightarrow p$
2. $b \rightarrow a \rightarrow p$

Beide Pfade erzeugen (statistische) Assoziation zwischen `b` und `p`.
Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal.
Gäbe es nur nur den zweiten Pfad und wir würden `b` ändern, so würde sich `p` nicht ändern.



### Gute Experimente zeigen den echten kausalen Effekt

@fig-dag-tuer-zu zeigt eine erfreuliche Situation:
Die "Hintertür" zu unserer UV (Zimmerzahl) ist geschlossen!

Ist die Hintertür geschlossen - führen also keine Pfeile in unserer UV -
so kann eine Konfundierung ausgeschlossen werden.

```{r}
#| echo: false
#| label: fig-dag-tuer-zu
#| fig-cap: "Unverzerrte Schätzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Prädiktor im Modell enthalten ist. Da die beiden Prädiktoren unkorreliert sind, hat die Aufnahme des einen Prädiktors keinen Einfluss auf das Regressionsgewicht des anderen."
#| out-width: "50%"
dag_coords <-
  tibble(name = c("a", "b", "p"),
         x    = c(0, -1, 1),
         y    = c(1, 0, 0))

dagify(p ~ a + b,
       coords = dag_coords) %>%
  gg_simple_dag()
```

Die "Hintertür" der UV (`b`) ist jetzt zu!
Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen `b` und `p` ist jetzt komplett kausal.


Eine berühmte Lösung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment.
Wenn wir den Häusern zufällig (randomisiert) eine Anzahl von Schlafzimmern (`b`) zuweisen könnten (unabhängig von ihrer Quadratmeterzahl, `a`), würde sich der Graph so ändern.
Das Experiment *entfernt* den Einfluss von `a` auf `b`.
Wenn wir selber die Werte von `b` einstellen im Rahmen des Experiments, so kann `a` keine Wirkung auf `b` haben.
Damit wird der zweite Pfad, $b \rightarrow a \rightarrow p$ geschlossen ("blockiert").




### Hintertür schließen auch ohne Experimente

Konfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch *die Hintertür schließen* (backdoor criterion).

Wir wollen die Hintertüre schließen, da wir sonst nicht den wahren, kausalen Effekt bestimmen können.

Zum Glück gibt es neben Experimenten noch andere Wege, die Hintertür zu schließen, wie die Konfundierungsvariable `a` in eine Regression mit aufzunehmen.

Warum blockt das Kontrollieren von `a`den Pfad $b \leftarrow a \rightarrow p$?
Stellen Sie sich den Pfad als eigenen Modell vor.
Sobald Sie `a` kennen, bringt Ihnen Kenntnis über `b` kein zusätzliches Wissen über `p`.
Wissen Sie hingegen nichts über `a`, lernen Sie bei Kenntnis von `b` auch etwas über `p`.
Konditionieren ist wie "gegeben, dass Sie `a` schon kennen...".

$b \indep p \,|\,a$



### Die vier Atome der Kausalanalyse


@fig-four-atoms stellt die vier "Atome" der Kausalinferenz dar.
Mehr gibt es nicht!
Kennen Sie diese vier Grundbausteine,
so können Sie jedes beliebige Kausalsystem (DAG) entschlüsseln.




```{r}
#| echo: false
p_conf <- confounder_triangle(x = NULL, y = NULL, z = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Konfundierung")
```

```{r}
#| echo: false
p_med <- 
  mediation_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Mediation")
```


```{r}
#| echo: false
p_coll <- collider_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% 
  gg_simple_dag() +
  labs(title = "Die Kollision")
```



```{r}
#| echo: false
dag_desc <- 
  dagitty('
          dag{
          
          m [pos="1.000,0.000"]
          x [exposure,pos="0.000,1.000"]
          y [outcome,pos="2.000,1.000"]
          d [pos="1,1"]

          x -> m
          y -> m
          m -> d
          }')

p_desc <-
  dag_desc %>%
  gg_simple_dag() +
  labs(title ="Der Nachfahre")
```





```{r}
#| echo: false
#| label: fig-four-atoms
#| fig-cap: Die vier Atome der Kausalinferenz
#| fig-width: 9
plots(p_conf, p_med, p_coll, p_desc, n_rows = 2)
```





### Mediation

Die *Mediation* (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: $x \rightarrow m \rightarrow y$. 
Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art $x \rightarrow m \rightarrow y$, s. @fig-med1.
Die Variable in der Mitte $m$ der Kette wird auch *Mediator* genannt,
weil sei die Wirkung von X auf Y "vermittelt" oder überträgt.
Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften,
wie der Psychologie.

```{r}
#| echo: false
#| label: fig-med1
#| fig-cap: Das Kausalmodell der Mediation.
p_med
```




Ohne Kontrollieren ist der Pfad offen: Die Assoziation "fließt" den Pfad entlang (in beide Richtungen).
Kontrollieren blockt (schließt) die Kette (genau wie bei der Gabel).


Es kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. @fig-part-med.
In @fig-part-med gibt es zwei kausale Pfade von X zu Y: $x\rightarrow m \rightarrow y$ und $x \rightarrow y$. 
Die Summe der Effekte beider Pfade nennt man den *totalen (kausalen) Effekt*. 
Den Effekt über den Mediatorpfad nennt man den *indirekten (kausalen) Effekt*
und den Pfad $x\rightarrow y$ nennt man den *direkten (kaudalen) Effekt*.

```{r}
#| label: fig-part-med
#| fig-cap: Partielle Mediation
#| echo: false
dag <- 
  dagitty('
          dag{
          
          m [pos="1.000,0.000"]
          x [pos="0.000,1.000"]
          y [pos="2.000,1.000"]
         

          x -> m
          x -> y
          m -> y
          }')

gg_fancy_dag(dag)
```


## Der Nachfahre



Ein *Nachfahre* (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. @fig-dag-nachfahre.
Kontrolliert man einen Nachfahren `d`, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), `m`.
Der Grund ist, dass `d` Information beinhaltet über `m`.
Hier wird das Kontrollieren von `d` den Pfad von `x` nach `y` teilweise öffnen, da `m` eine Kollisionsvariable ist.



```{r}
#| echo: false
#| label: fig-dag-nachfahre
#| fig-cap: "Ein Nachfahre verhält sich ähnlich wie sein Vorfahre..."
#| out-width: "50%"
p_desc
```



### Kochrezept zur Analyse von DAGs

Wie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.

Hier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:

1. Listen Sie alle Pfade von UV (`X`) zu AV (`Y`) auf.
2. Beurteilen Sie jeden Pfad, ob er gerade geschlossen oder geöffnet ist.
3. Beurteilen Sie für jeden Pfad, ob er ein Hintertürpfad ist (Hintertürpfade haben einen Pfeil, der zur UV führt).
4. Wenn es geöffnete Hinterpfade gibt, prüfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schließen (falls möglich).




## Schließen Sie die Hintertür (wenn möglich)!, `bsp1`

UV: $X$, AV: $Y$, drei Covariaten (A, B, C) und ein ungemessene Variable, U





```{r gg-fancey-dag, out.width="50%"}
#| echo: false
#| label: fig-dag-fancy
#| fig-cap: "Puh, ein schon recht komplizierter DAG"
dag_coords <-
  tibble(name = c("A", "B", "C", "U", "X", "Y"),
         x    = c(2, 2, 3, 1, 1, 3),
         y    = c(4, 2, 3, 3, 1, 1))

dagify(B ~ C + U,
       C ~ A,
       U ~ A,
       X ~ U,
       Y ~ C + X,
       coords = dag_coords) %>%
  gg_fancy_dag(x = 1, y = 3, circle = "U")
```



Es gibt zwei Hintertürpfade in @fig-dag-fancy:

1. $X \leftarrow U \leftarrow A \rightarrow C \rightarrow Y$, offen
2. $X \leftarrow U \rightarrow B \leftarrow C \rightarrow Y$, geschlossen

Kontrollieren von $A$ oder (auch) $C$ schließt die offene Hintertür.



@mcelreath_statistical_2020, @kurz_statistical_2021, s.S. 186.





### Schließen Sie die Hintertür (wenn möglich)!, `bsp2`

S. DAG in @fig-dag-bsp2: UV: $W$, AV: $D$

```{r bsp2}
#| echo: false
#| label: fig-dag-bsp2
#| fig-asp: 0.5
#| fig-cap: "Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?"
dag_coords <-
  tibble(name = c("A", "D", "M", "S", "W"),
         x    = c(1, 3, 2, 1, 3),
         y    = c(1, 1, 2, 3, 3))

dagify(A ~ S,
       D ~ A + M + W,
       M ~ A + S,
       W ~ S,
       coords = dag_coords) %>%
  gg_simple_dag()
```



Kontrollieren Sie diese Variablen, um die offenen Hintertüren zu schließen:

- entweder $A$ und $M$
- oder $S$

[Mehr Infos](https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#backdoor-waffles.)



Details finden sich bei @mcelreath_statistical_2020 oder @kurz_statistical_2021, ‚S. 188.



### Implizierte bedingte Unabhängigkeiten von `bsp2`

Ein Graph ohne `U`s ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme.
Auch wenn die Daten nicht sagen können, welcher DAG der richtige ist, können wir zumindest lernen, welcher DAG falsch ist.
Die vom Modell implizierten bedingten Unabhängigkeiten geben uns Möglichkeiten, zu prüfen, ob wir einen DAG verwerfen (ausschließen) können.
Bedingten Unabhängigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhängig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.

`bsp2` impliziert folgende bedingte Unabhängigkeiten:

```{r bsp2-cond-independence}
#| echo: false
dag_6.2 <- 
  dagitty(
    "dag {
    A -> D
    A -> M -> D
    A <- S -> M
    S -> W -> D
    }"
  )

impliedConditionalIndependencies(dag_6.2)
```



## Fazit

Wie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren können, hängt von der *epistemologischen Zielrichtung* der Forschungsfrage ab:

- Bei *deskriptiven* Forschungsfragen können die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. "Der Unterschied zwischen beiden Gruppen beträgt etwa ...". Allerdings ist eine kausale Interpretation nicht zulässig.
- Bei *prognostischen* Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, $\hat{y}_i$, z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht möglich, aber auch nicht von Interesse.
- Bei *kausalen* Forschungsfragen dürfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.
    
Modellkoeffizienten ändern sich (oft), wenn man Prädiktoren zum Modell hinzufügt oder wegnimmt.
Entgegen der verbreiteten Annahme ist es falsch, möglichst viele Prädiktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist.
Kenntnis der "kausalen Atome" ist Voraussetzung zur Ableitung von Kausalschlüsse in Beobachtungsstudien.



## Aufgaben


- [Sammlung "kausal"](https://datenwerk.netlify.app/#category=causal)









## ---



![](img/outro-11.jpg){width=100%}





