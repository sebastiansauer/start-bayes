{
  "hash": "cf18d4ce18a94c3695157ce81b77fa7e",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Die Atome des Kausalit√§t {#sec-kausal2}\n\n## Lernsteuerung\n\n\n\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\n\n\n\n### Position im Modulverlauf\n\n@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n### R-Pakete\n\n\nF√ºr dieses Kapitel ben√∂tigen Sie folgende R-Pakete:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n### Daten  {#sec-kausal2-daten}\n\n\nWir nutzen den Datensatz [Saratoga County](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv); s. @tbl-saratoga.\nHier gibt es eine \n[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SaratogaHouses.html).\n\n\n{{< downloadthis data/SaratogaHouses.csv dname=\"SaratogaHouses.csv\" >}}\n\n\n\nSie k√∂nnen ihn entweder √ºber die Webseite herunterladen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSaratogaHouses_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd <- read.csv(SaratogaHouses_path)\n```\n:::\n\n\nOder aber √ºber das Paket `mosaic` importieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd <- SaratogaHouses  # k√ºrzerer Name, das ist leichter zu tippen\n```\n:::\n\n\n\n\n### Lernziele\n\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ... \n\n- erkl√§ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\n- erkl√§ren, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\n- die ‚ÄúAtome‚Äù der Kausalit√§t eines DAGs benennen\n- ‚Äúkausale Hintert√ºren‚Äù schlie√üen\n\n### Begleitliteratur\n\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. √Ñhnliche Darstellungen wie in diesem Kapitel findet sich bei @rohrer_thinking_2018.\n\n\n\n\n\n\n\n## Kollision\n\n\n\n\nüì∫ [Kollision](https://www.youtube.com/watch?v=RymOFwVU3PQ)\n\n\n\n\n\n### Kein Zusammenhang von Intelligenz und Sch√∂nheit (?)\n\n[Gott ist gerecht (?)](https://twitter.com/TheTweetOfGod/status/1462594155176026123)\n\n\n\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (`talent`) und Sch√∂nheit (`looks`),\nwie @fig-iq-schoen illustriert.\nF√ºr geringe Intelligenzwerte gibt es eine breites Spektrum von Sch√∂nheitswerten\nund f√ºr hohe Intelligenzwerte sieht es genauso aus.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Kein Zusammenhang von Intelligenz und Sch√∂nheit in den Daten](1180-kausalatome_files/figure-html/fig-iq-schoen-1.png){#fig-iq-schoen width=50%}\n:::\n:::\n\n\n\n\n\n### Aber Ihre Dates sind entweder schlau oder sch√∂n\n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates),\nentweder sch√∂n sind oder schlau - aber seltens beides gleichzeitig (schade),\ns. @fig-dates-beauty.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ihre Datingpartner sind komischerweise entweder schlau oder sch√∂n (aber nicht beides), zumindest in der Tendenz.](1180-kausalatome_files/figure-html/fig-dates-beauty-1.png){#fig-dates-beauty width=50%}\n:::\n:::\n\n\nWie kann das sein?\n\n\n\n\n### DAG zur Rettung \n\nü¶π ü¶∏\n\nDer DAG in @fig-coll1-dag bietet eine rettende Erkl√§rung.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Date als gemeinsame Wirkung von Sch√∂nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Sch√∂nheit und Intelligenz.](1180-kausalatome_files/figure-html/fig-coll1-dag-1.png){#fig-coll1-dag width=50%}\n:::\n:::\n\n\n\nEine √§hnliche Visualisierung des gleichen Sachverhalts zeigt @fig-coll2-dag.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen](1180-kausalatome_files/figure-html/fig-coll2-dag-1.png){#fig-coll2-dag width=864}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n### Was ist eine Kollision?\n\n\n\n:::{#def-collision}\n### Kollision\nAls *Kollision* (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) [@pearl_causal_2016, p. 40]. $\\square$\n:::\n\nKontrolliert man  die *Wirkung* `m`, so entsteht eine *Scheinkorrelation* zwischen den Ursachen `x` und `y`.\nKontrolliert man die Wirkung *nicht*, so entsteht *keine Scheinkorrelation* zwischen den Ursachen, s. @fig-coll1-dag, vgl. @rohrer_thinking_2018.\n\n\n::: callout-important\nMan kann also zu viele oder falsche Pr√§diktoren einer Regression hinzuf√ºgen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n:::\n\n::: callout-tip\nüôÖ‚Äç‚ôÄÔ∏è Kontrollieren Sie keine Kollisionsvariablen. $\\square$\n:::\n\n\n\n\n### Einfaches Beispiel zur Kollision\n\n\n\nIn der Zeitung *Glitzer* werden nur folgende Menschen gezeigt:\n\n- Sch√∂ne Menschen ü™û\n- Reiche Menschen ü§ë \n    \nSehen wir davon aus, dass Sch√∂nheit und Reichtum unabh√§ngig voneinander sind.\n\n\n:::{#exr-coll1}\nWenn ich Ihnen sage, dass Don nicht sch√∂n ist, aber in der Glitzer h√§ufig auftaucht, was lernen wir dann √ºber seine finanzielle Situation?^[Don muss reich sein.] $\\square$\n:::\n\n\n\n\n>   \"Ich bin sch√∂n, unglaublich sch√∂n, und gro√ü, gro√üartig, tolle Gene!!!\" üßë\n\n\n\n\n\n### Noch ein einfaches Beispiel zur Kollision\n\n>   \"So langsam check ich's!\" üßë^[Super, Don!]\n\n\n\nSei Z = X + Y, wobei X und Y unabh√§ngig sind.\n\nWenn ich Ihnen sage, X = 3, lernen Sie nichts √ºber Y, da die beiden Variablen unabh√§ngig sind\n Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\n\nAlso: X und Y sind abh√§ngig, gegeben Z: $X \\not\\indep Y \\,|\\, Z$.^[Der horizontale Balken \"|\" bedeutet \"gegeben, dass\". Ein Beispiel lautet $Pr(A|B)$: \"Die Wahrscheinlichkeit von A, gegeben dass B der Fall ist.]\n\n\n### Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\n\n\n@fig-coll1-dag zeigt: Durch Kontrollieren entsteht eine Kollision,\neine Scheinkorrelation zwischen den Ursachen.\n\n*Kontrollieren* kann z.B. bedeuten:\n\n- *Stratifizieren*: Aufteilen von `date` in zwei Gruppen und dann Analyse des Zusammenhangs von `talent` und `looks` in jeder Teilgruppe von `date`\n- *Kontrollieren mit Regression*: Durch Aufnahme von `date` als Pr√§diktor in eine Regression zus√§tzlich zu `looks` mit `talent` als Pr√§dikotr\n\n\n*Ohne* Kontrolle von `date` entsteht *keine* Scheinkorrelation zwischen `Looks` und `Talent`. Der Pfad (\"Fluss\") von `Looks` √ºber `date` nach `Talent` ist blockiert.\n\nKontrolliert man `date`, so *√∂ffnet* sich der Pfad `Looks -> date -> talent` und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr \"blockiert\", die\nKorrelation kann \"flie√üen\" - was sie hier nicht soll,\ndenn es handelt sich um Scheinkorrelation.\n\nDas Kontrollieren von `date` geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n\n\n\n### IQ, Fleiss und Eignung f√ºrs Studium\n\n\nSagen wir, √ºber die *Eignung* f√ºr ein Studium w√ºrden nur (die individuellen Auspr√§gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in @fig-coll3-dag.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Kollisionsstruktur im Dag zur Studiumseignung](1180-kausalatome_files/figure-html/fig-coll3-dag-1.png){#fig-coll3-dag width=672}\n:::\n:::\n\n\nBei positiver `eignung` wird ein Studium aufgenommen (`studium = 1`) ansonsten nicht (`studium = 0)`. \n\n\n[Quelle](https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/)\n\n\n\n`eignung` (f√ºrs Studium) sei definiert als die Summe von `iq` und `fleiss`, plus etwas Gl√ºck, s. @lst-studium.\n\n\n::: {.cell}\n\n```{#lst-studium .r .cell-code  lst-cap=\"Eignung ist die Summe von Fleiss und Intelligenz, plus ein Quentchen Gl√ºck\"}\nset.seed(42)  # Reproduzierbarkeit\nN <- 1e03  \n\nd_eignung <-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung > 0, 1, 0) \n  )\n```\n:::\n\n\nLaut unserem Modell setzt sich Eignung zur H√§lfte aus Intelligenz und zur H√§lfte aus Fleiss zusammen, plus etwas Gl√ºck.\n\n\n\n### Schlagzeile \"Flei√ü macht bl√∂d!\"\n\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Flei√ü (f) bei Studentis (s).\nErgebnis: Ein *negativer* Zusammenhang!?\n\n\n\nBerechnen wir das \"Eignungsmodell\", aber nur mit Studis (`studium == 1`, also ohne Nicht-Studis), \ns. @tbl-m-eignung.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_eignung <-\n  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n```\n:::\n\n::: {#tbl-m-eignung .cell tbl-cap='Zum Zusammenhang von Fleiss und Talent'}\n::: {.cell-output-display}\n\n\nTable: Highest Density Interval\n\n|Parameter   |       95% HDI |\n|:-----------|:--------------|\n|(Intercept) |[ 0.70,  0.86] |\n|fleiss      |[-0.53, -0.36] |\n\n\n:::\n:::\n\n\n\n\n\n@fig-eignung zeigt das Modell und die Daten.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Der Zusammenhang von Fleiss und IQ](1180-kausalatome_files/figure-html/fig-eignung-1.png){#fig-eignung width=672}\n:::\n:::\n\n\n\nIQ ist *nicht* unabh√§ngig von Flei√ü in unseren Daten, sondern abh√§ngig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien,\ngreifen gerne Befunde √ºber Zusammenh√§nge auf und interpretieren die Zusammenh√§nge\n-- oft vorschnell -- als kausal.^[Ehrlicherweise muss man zugeben, dass auch wissenschaftliche Berichte Daten √ºber Zusammenh√§nge gerne kausal interpretieren, oft vorschnell.]\n\n\n\n\n\n### Kollisionsverzerrung nur bei Stratifizierung\n\n:::{#def-stratifizieren}\n### Stratifizieren\nDurch Stratifizieren wird eine Stichprobe in (homogene) Untergruppen unterteilt (sog. *Strata*). $\\square$\n:::\n\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. @fig-eignung-strat.\n\n\n:::callout-note\n*Ohne* Stratifizierung tritt *keine* Scheinkorrelation auf.\n*Mit* Stratifizierung tritt Scheinkorrelation auf.\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Stratifizierung und Scheinkorrelation. A: Keine Stratifizierung und keine Scheinkorrelation. B: Stratifizierung und Scheinkorrelation](1180-kausalatome_files/figure-html/fig-eignung-strat-1.png){#fig-eignung-strat width=672}\n:::\n:::\n\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie n√ºtzen.\n\n*Nur* Kenntnis des DAGs verr√§t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n:::callout-note\nNimmt man eine Variable als zweiten Pr√§diktor auf,\nso \"kontrolliert\" man diese Variable. Das Regressiongewicht des ersten Pr√§diktors wird \"bereinigt\" um den Einfluss des zweiten Pr√§diktors; insofern ist der zweite Pr√§diktor dann \"kontrolliert\".\n:::\n\n\n\n\n### Einfluss von Gro√üeltern und Eltern auf Kinder\n\n\n\n\n\nWir wollen hier den (kausalen) Einfluss der Eltern `E` und Gro√üeltern `G` auf den *Bildungserfolg* der Kinder `K` untersuchen.\n\nWir nehmen folgende Effekte an:\n\n- indirekter Effekt von `G` auf `K`: $G \\rightarrow E \\rightarrow K$\n- direkter Effekt von `E` auf `K`: $E \\rightarrow K$\n- direkter Effekt von `G` auf `K`: $G \\rightarrow K$\n\n\nWir sind v.a. interessiert an $G \\rightarrow K$, dem *direkten kausalen* Effekt von Gro√üeltern auf ihre Enkel, s. @fig-dag-grannies [@kurz_statistical_2021], $G \\rightarrow K$.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Der kausale Effekt von Gro√üeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft](1180-kausalatome_files/figure-html/fig-dag-grannies-1.png){#fig-dag-grannies width=672}\n:::\n:::\n\n\n\nAber was ist, wenn wir vielleicht eine *u*nbekannte Variable √ºbersehen haben? (S. n√§chster Abschnitt). üëª\n\n\n\n\n\n\n\n### Der Gespenster-DAG\n\nüëª Es gibt \"unheilbare\" DAGs, nennen wir sie \"Gespenster-DAGs\",\nin denen es nicht m√∂glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen,\ns. @fig-dag-ghost.\nLetztlich sagt uns der DAG bzw. unsere Analyse zum DAG:\n\"Deine Theorie ist nicht gut, zur√ºck an den Schreibtisch und denk noch mal gut nach. \nOder sammele mehr Daten.\"\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollst√§ndig) m√∂glich.](1180-kausalatome_files/figure-html/fig-dag-ghost-1.png){#fig-dag-ghost width=50%}\n:::\n:::\n\n\n\n\n`U` k√∂nnte ein ungemessener Einfluss sein, der auf `E` und `K` wirkt, etwa *Nachbarschaft*.\nDie Gro√üeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\n`E` ist sowohl f√ºr `G` als auch f√ºr `U` eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir `E` kontrollieren, wird es den Pfad $G \\rightarrow K$ verzerren, auch wenn wir niemals `U` messen.\n\n\nDie Sache ist in diesem Fall chancenlos. Wir m√ºssen diesen DAG verloren geben, @mcelreath_statistical_2020, S. 180; ein Gespenster-DAG. üëª \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Die Hintert√ºr schlie√üen\n\n\n\n:::{#def-hintertuer}\n### Hintert√ºr\n\nEine \"Hintert√ºr\"  ist ein nicht-kausaler Pfad zwischen einer UV und einer AV. \nEin Hintert√ºrpfad entsteht, wenn es eine alternative Route √ºber eine oder mehrere Variable gibt, die UV mit der AV verbindet. Dieser Pfad verzerrt die Sch√§tzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. $\\square$\n:::\n\n\n\n### Zur Erinnerung: Konfundierung\n\n\n\n\n\n*Forschungsfrage*: Wie gro√ü ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\n\n`a:` livingArea, `b`: bedrooms, `p`: prize\n\nUV: `b`, AV: `p`\n\n\nDas Kausalmodell ist in @fig-dag-don1 dargestellt.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfl√§che beeinflusst](1180-kausalatome_files/figure-html/fig-dag-don1-1.png){#fig-dag-don1 width=50%}\n:::\n:::\n\n\n\n\n Im Regressionsmodell `p ~ b` wird der kausale Effekt verzerrt sein durch die Konfundierung mit `a`.\n Der Grund f√ºr die Konfundierung sind die zwei Pfade zwischen `b` und `p`:\n \n1. $b \\rightarrow p$\n2. $b \\leftarrow a \\rightarrow p$\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen `b` und `p`.\nAber nur der erste Pfad ist kausal; der zweite ist nichtkausal.\nG√§be es nur nur den zweiten Pfad und wir w√ºrden `b` √§ndern, so w√ºrde sich `p` *nicht* √§ndern.\n\n\n\n### Gute Experimente zeigen den echten kausalen Effekt\n\n@fig-dag-tuer-zu zeigt eine erfreuliche Situation:\nDie \"Hintert√ºr\" zu unserer UV (Zimmerzahl) ist geschlossen!\n\nIst die Hintert√ºr geschlossen - f√ºhren also keine Pfeile in unserer UV -\nso kann eine Konfundierung ausgeschlossen werden.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Unverzerrte Sch√§tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Pr√§diktor im Modell enthalten ist. Da die beiden Pr√§diktoren unkorreliert sind, hat die Aufnahme des einen Pr√§diktors keinen Einfluss auf das Regressionsgewicht des anderen.](1180-kausalatome_files/figure-html/fig-dag-tuer-zu-1.png){#fig-dag-tuer-zu width=50%}\n:::\n:::\n\n\nDie \"Hintert√ºr\" der UV (`b`) ist jetzt zu!\nDer einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen `b` und `p` ist jetzt komplett kausal.\n\n\nEine ber√ºhmte L√∂sung, den kausalen Pfad zu isolieren, ist ein (randomisiertes, kontrolliertes^[engl. randomized, controlled trial, RCT]) Experiment.\nWenn wir den H√§usern zuf√§llig (randomisiert) eine Anzahl von Schlafzimmern (`b`) zuweisen k√∂nnten (unabh√§ngig von ihrer Quadratmeterzahl, `a`), w√ºrde sich der Graph so √§ndern.\nDas Experiment *entfernt* den Einfluss von `a` auf `b`.\nWenn wir selber die Werte von `b` einstellen im Rahmen des Experiments, so kann `a` keine Wirkung auf `b` haben.\nDamit wird der zweite Pfad, $b \\leftarrow a \\rightarrow p$ geschlossen (\"blockiert\").\n\n\n::: callout-important\nDie St√§rke von (gut gemachten) Experimente ist, dass sie kausale Hintert√ºren schlie√üen. Damit erlauben sie (korrekte) Kausalaussagen. $\\square$\n:::\n\n\n\n### Hintert√ºr schlie√üen auch ohne Experimente\n\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch *die Hintert√ºr schlie√üen* (backdoor criterion).\nWir wollen die Hintert√ºre schlie√üen, da wir sonst nicht den wahren, kausalen Effekt bestimmen k√∂nnen.\n\nZum Gl√ºck gibt es neben Experimenten noch andere Wege, die Hintert√ºr zu schlie√üen, wie die Konfundierungsvariable `a` in eine Regression mit aufzunehmen.\n\n::: callout-tip\nKontrollieren Sie Konfundierer, um kausale Hintert√ºren zu schlie√üen. $\\square$\n:::\n\n\nWarum blockt das Kontrollieren von `a`den Pfad $b \\leftarrow a \\rightarrow p$?\nStellen Sie sich den Pfad als eigenen Modell vor.\nSobald Sie `a` kennen, bringt Ihnen Kenntnis √ºber `b` kein zus√§tzliches Wissen √ºber `p`.\nWissen Sie hingegen nichts √ºber `a`, lernen Sie bei Kenntnis von `b` auch etwas √ºber `p`.\nKonditionieren ist wie \"gegeben, dass Sie `a` schon kennen...\".\n\n$b \\indep p \\,|\\,a$\n\n\n\n## Die vier Atome der Kausalanalyse\n\n\n@fig-four-atoms stellt die vier \"Atome\" der Kausalinferenz dar.\nMehr gibt es nicht!\nKennen Sie diese vier Grundbausteine,\nso k√∂nnen Sie jedes beliebige Kausalsystem (DAG) entschl√ºsseln.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Die vier Atome der Kausalinferenz](1180-kausalatome_files/figure-html/fig-four-atoms-1.png){#fig-four-atoms width=864}\n:::\n:::\n\n\n\n\n\n\n### Mediation\n\n\n:::{#def-mediator}\n### Mediator\nEinen Pfad mit drei Knoten (Variablen), die √ºber insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man *Mediation*. Der *Mediator* ist die Variable zwischen UV und AV [@pearl_causal_2016; p. 38]. $\\square$\n:::\n\nDie *Mediation* (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: $x \\rightarrow m \\rightarrow y$. \nAnders gesagt: Eine Mediation ist eine Kausalabfolge der Art $x \\rightarrow m \\rightarrow y$, s. @fig-med1.\nDie Variable in der Mitte $m$ der Kette wird auch *Mediator* genannt,\nweil sei die Wirkung von X auf Y \"vermittelt\" oder √ºbertr√§gt.\nDie Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften,\nwie der Psychologie.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Das Kausalmodell der Mediation.](1180-kausalatome_files/figure-html/fig-med1-1.png){#fig-med1 width=672}\n:::\n:::\n\n\n\n:::{#exm-mediator}\n### Mediator kontrollieren?\nSollte man den Mediator `m` in @fig-med1 kontrollieren, wenn man den Kausaleffekt von `x` auf `y` sch√§tzen m√∂chte?^[Nein, durch das Kontrollieren von `m` wird der Kausalpfad von `x` zu `y` geschlossen. Es kann keine kausale Assoziation von `x` auf `y` mehr \"flie√üen\".] $\\square$\n:::\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation \"flie√üt\" den Pfad entlang (in beide Richtungen).\nKontrollieren blockt (schlie√üt) die Kette (genau wie bei der Gabel).\n\n::: callout-tip\nKontrollieren Sie den Mediator *nicht*. Der Pfad √ºber den Mediator ist ein \"echter\" Kausalpfad, keine Scheinkorrelation. $\\square$\n:::\n\n::: callout-important\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. $\\square$\n:::\n\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. @fig-part-med.\nIn @fig-part-med gibt es zwei kausale Pfade von X zu Y: $x\\rightarrow m \\rightarrow y$ und $x \\rightarrow y$. \nDie Summe der Effekte beider Pfade nennt man den *totalen (kausalen) Effekt*. \nDen Effekt √ºber den Mediatorpfad nennt man den *indirekten (kausalen) Effekt*\nund den Pfad $x\\rightarrow y$ nennt man den *direkten (kaudalen) Effekt*.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Partielle Mediation](1180-kausalatome_files/figure-html/fig-part-med-1.png){#fig-part-med width=672}\n:::\n:::\n\n\n\n### Der Nachfahre\n\n\n\n:::{#def-Nachfahre}\n### Nachfahre\nEin *Nachfahre* (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. @fig-dag-nachfahre. $\\square$\n:::\n\nKontrolliert man einen Nachfahren `d`, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), `m`.\nDer Grund ist, dass `d` Information beinhaltet √ºber `m`.\nHier wird das Kontrollieren von `d` den Pfad von `x` nach `y` teilweise √∂ffnen, da `m` eine Kollisionsvariable ist.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein Nachfahre verh√§lt sich √§hnlich wie sein Vorfahre...](1180-kausalatome_files/figure-html/fig-dag-nachfahre-1.png){#fig-dag-nachfahre width=50%}\n:::\n:::\n\n\n\n\n\n\n### Kochrezept zur Analyse von DAGs üë®‚Äçüç≥ \n\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\n\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: üìÑ \n\n1. Listen Sie alle Pfade von UV (`X`) zu AV (`Y`) auf.\n2. Beurteilen Sie jeden Pfad, ob er gerade geschlossen oder ge√∂ffnet ist.\n3. Beurteilen Sie f√ºr jeden Pfad, ob er ein Hintert√ºrpfad ist (Hintert√ºrpfade haben einen Pfeil, der zur UV f√ºhrt).\n4. Wenn es ge√∂ffnete Hinterpfade gibt, pr√ºfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlie√üen (falls m√∂glich).\n\n\n\n\n## Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, `bsp1`\n\n\n### Fall 1: `x->`\n\n$\\boxed{X \\rightarrow}$\n\nAlle Pfade, die von der UV (`X`) *wegf√ºhren*, sind entweder \"gute\" Kausalpfade oder automatisch geblockte Nicht-Kausal-Pfade. In diesem Fall m√ºssen wir nichts tun.^[Denken Sie daran, dass Sie keine Nachkommen der UV kontrollieren d√ºrfen, da das den Kausalpfad von der UV zur AV blockieren k√∂nnte.]\n\n### Fall 2: `->x`\n$\\boxed{X \\leftarrow}$\n\nAlle Pfade, die zur UV *hinf√ºhren*, sind immer Nicht-Kausal-Pfade. Diese Pfade k√∂nnen offen sein, dann m√ºssen wir sie schlie√üen. Sie k√∂nnen auch geschlossen sein, dann m√ºssen wir nichts tun.\n\n\n\n\nüì∫ [Hintert√ºr schlie√üen](https://www.youtube.com/watch?v=Hns1UIYKTds)\n\nUV: $X$, AV: $Y$, drei Kovariaten (A, B, C) und ein ungemessene Variable, U\n\n\n::: callout-tip\nSchlie√üen Sie immer offene Hintert√ºren, um Verzerrungen der Kausaleffekte zu verhinden. $\\square$\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Puh, ein schon recht komplizierter DAG](1180-kausalatome_files/figure-html/fig-dag-fancy-1.png){#fig-dag-fancy width=50%}\n:::\n:::\n\n\n\n\nEs gibt zwei Hintert√ºrpfade in @fig-dag-fancy:\n\n1. $X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y$, offen\n2. $X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y$, geschlossen\n\nKontrollieren von $A$ oder (auch) $C$ schlie√üt die offene Hintert√ºr.\n\n\n\n@mcelreath_statistical_2020, @kurz_statistical_2021, s.S. 186.\n\n\n\n\n\n### Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, `bsp2`\n\nS. DAG in @fig-dag-bsp2: UV: $W$, AV: $D$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?](1180-kausalatome_files/figure-html/fig-dag-bsp2-1.png){#fig-dag-bsp2 width=672}\n:::\n:::\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintert√ºren zu schlie√üen:\n\n- entweder $A$ und $M$\n- oder $S$\n\n[Mehr Infos](https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#backdoor-waffles.)\n\n\n\nDetails finden sich bei @mcelreath_statistical_2020 oder @kurz_statistical_2021, ‚ÄöS. 188.\n\n\n\n### Implizierte bedingte Unabh√§ngigkeiten von `bsp2`\n\nEin Graph ohne `U`s ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme.\nAuch wenn die Daten nicht sagen k√∂nnen, welcher DAG der richtige ist, k√∂nnen wir zumindest lernen, welcher DAG falsch ist.\nDie vom Modell implizierten bedingten Unabh√§ngigkeiten geben uns M√∂glichkeiten, zu pr√ºfen, ob wir einen DAG verwerfen (ausschlie√üen) k√∂nnen.\nBedingten Unabh√§ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabh√§ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\n\n`bsp2` impliziert folgende bedingte Unabh√§ngigkeiten:\n\n\n::: {.cell}\n\n```\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S\n```\n:::\n\n\n\n\n## Fazit\n\n### Ausstieg\n\nüì∫ [Musterl√∂sung f√ºr eine DAG-Pr√ºfungsaufgabe](https://www.youtube.com/watch?v=lHUEURFjW78)\n\nüì∫ [Musterl√∂sung f√ºr schwierige DAG-Pr√ºfungsaufgaben](https://www.youtube.com/watch?v=5HKmOdzuDXw)\n\n:::{#exm-pmi-kausal1}\n### PMI zum heutigen Stoff\nDer Kreativit√§tsforscher Edward de Bono hat verschiedene \"Denkmethoden\" vorgestellt, die helfen sollen, Probleme besser zu l√∂sen.\nEine Methode ist die \"PMI-Methode\". PMI steht f√ºr *Plus*, *Minus*, *Interessant*. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anf√ºhren. Bei *Interessant* verzichtet man aber explizit auf eine Bewertung (im Sinne von \"gut\" oder \"schlecht\") und fokussiert sich auf Interessantes, √úberraschendes, Bemerkenswertes (vgl. @DeBono1974).\n\nF√ºhren Sie die PMI-Methode zum heutigen Stoff durch!\n\n1. Plus: Was fanden Sie am heutigen Stoff gut, sinnvoll, n√ºtzlich?\n2. Minus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, n√ºtzlich?\n3. Interessant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! $\\square$\n:::\n\n\n### Zusammenfassung\n\n\nüì∫ [Kausalmodelle √ºberpr√ºfen](https://www.youtube.com/watch?v=JEHgAJEdIa0)\n\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren k√∂nnen, h√§ngt von der *epistemologischen Zielrichtung* der Forschungsfrage ab:\n\n- Bei *deskriptiven* Forschungsfragen k√∂nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. \"Der Unterschied zwischen beiden Gruppen betr√§gt etwa ...\". Allerdings ist eine kausale Interpretation nicht zul√§ssig.\n- Bei *prognostischen* Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, $\\hat{y}_i$, z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht m√∂glich, aber auch nicht von Interesse.\n- Bei *kausalen* Forschungsfragen d√ºrfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n    \nModellkoeffizienten √§ndern sich (oft), wenn man Pr√§diktoren zum Modell hinzuf√ºgt oder wegnimmt.\nEntgegen der verbreiteten Annahme ist es falsch, m√∂glichst viele Pr√§diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist.\nKenntnis der \"kausalen Atome\" ist Voraussetzung zur Ableitung von Kausalschl√ºsse in Beobachtungsstudien.\n\n\n### Vertiefung\n\nAn weiterf√ºhrender Literatur sei z.B. @cummiskey_causal_2020, @lubke_why_2020,\n@pearl_causal_2016 und @dablander_introduction_2020 empfohlen.\nEin gutes Lehrbuch, das auf Kausalinferenz eingeht, ist @huntington-klein_effect_2022. Praktischerweise ist es [√∂ffentlich lesbar](https://theeffectbook.net/ch-CausalPaths.html).\nDas Web-Buch [Causal Inference for the Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html) sieht auch vielversprechend aus.\nEs gibt viele Literatur zu dem Thema; relevante Suchterme sind z.B. \"DAG\", \"causal\" oder \"causal inference\".\n\n\n## Aufgaben\n\n\n- [Sammlung \"kausal\"](https://datenwerk.netlify.app/#category=causal)\n\n\n\n\n\n\n\n\n## ---\n\n\n\n![](img/outro-14.jpg){width=100%}\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}