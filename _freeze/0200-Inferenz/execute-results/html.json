{
  "hash": "4de67f3c50cc0707bc7932b4beccd95c",
  "result": {
    "engine": "knitr",
    "markdown": "# Inferenz\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n![Bayes:Start!](img/Golem_hex.png){width=10%}\n\n\n\n\n\n\n## Lernsteuerung\n\n### Position im Modulverlauf\n\n@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ...\n\n\n\n- die Definition von Inferenzstatistik sowie Beispiele f√ºr inferenzstatistische Fragestellungen nennen\n- zentrale Begriffe der Inferenzstatistik nennen und in Grundz√ºgen erkl√§ren\n- den Nutzen von Inferenzstatistik nennen\n- erl√§utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\n- anhand von Beispielen erkl√§ren, was ein statistisches Modell ist\n- die Grundkonzepte der Regression angeben\n- Unterschiede zwischen frequentistischer (\"klassischer\") und Bayes-Inferenz benennen\n- Vor- und Nachteile der frequentistischen vs. Bayes-Inferenz diskutieren\n- Die grundlegende Herangehensweise zur Berechnung des p-Werts informell erkl√§ren\n\n\n### Begleitliteratur\n\nBei @gelman_regression_2021, Kap. 1 findet sich eine Darstellung √§hnlich zu der in diesem Kapitel.\n\n\n\n### Vorbereitung im Eigenstudium\n\n- [Statistik 1, Kap. \"Rahmen\"](https://statistik1.netlify.app/010-rahmen)\n- [Statistik 1](https://statistik1.netlify.app/), dort alle Inhalte zum Thema \"Modellieren\" und \"Regression\"\n\n\n\n\n\n### Begleitvideos\n\n- [Video zur Inferenz, Teil 1](https://youtu.be/gcwWwBy0kPI)\n- [Video zur Inferenz, Teil 2](https://https://youtu.be/QNMVi6IqQ90)\n\n\n### Wozu ist Statistik √ºberhaupt da?\n\n\nüì∫ [Ja, wozu ist Statistik eigentlich da?](https://www.youtube.com/watch?v=gcwWwBy0kPI&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=2)\n\nJa, diese Frage haben Sie sich auch schon mal gestellt? \nAbb. @fig-goals gibt einen √úberblick √ºber die Ziele der Statistik.^[Ziele existieren nicht \"in echt\" in der Welt. Wir denken sie uns aus.\nZiele haben also keine ontologische Wirklichkeit,\nsie sind epistemologische Dinge (existieren nur in unserem Kopf).\nDas hei√üt, dass man sich nach Beliebem Ziele ausdenken kann.\nAllerdings hilft es, wenn man andere Menschen vom Nutzen der eigenen Ideen √ºberzeugen kann...]\nNach dieser Einteilung lassen sich drei Arten von Zielen unterscheiden: Beschreiben, Vorhersagen und Erkl√§ren.\n\n\n:::{#exm-ziele-stat}\n### Beispiele f√ºr die Zielarten statistischer Analysen\n- Beschreiben: ‚ÄúWie gro√ü ist der Gender-Paygap in der Branche X im Zeitraum Y?‚Äù\n- Vorhersagen: Wenn eine Person, Mr. X, 100 Stunden auf die Statistikklausur lernen, welche Note kann diese Person dann erwarten?\n- Erkl√§ren: Wie viel bringt (mir) das Lernen auf die Statistikklausur?$\\square$\n:::\n\nF√ºr die Wissenschaft ist *Erkl√§ren* das wichtigste Ziel. \nBei wenig beackerten Wissenschaftsfeldern ist das *Beschreiben* ein sinnvoller erster Schritt,\nder allerdings nicht Stolperfallen ist, wie in @sec-kausal erl√§utert.\n*Vorhersagen* ist mehr f√ºr die Praxis als f√ºr die Wissenschaft relevant.^[Vielleicht hat Ihr Dozent Sie schon mal mit einem Prognosewettbewerb gequ√§lt? Ja? Genau! In einem Prognosewettbewerb ist das Ziel eine - nat√ºrlich m√∂glichst exakte - Vorhersage zu treffen.]\n\n\n\n\n```{mermaid}\n%%| label: fig-goals\n%%| fig-cap: Eine Einteilung der Ziele von statistischen Analysen\nflowchart TD \n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n```\n\n\n\n\n\n\n\n\n\n\n\n## Was ist Inferenz?\n\n\n\n\n\n\n\n\n\n\n<!-- TODO: -->\n<!-- Attentio Grabber zum Einstieg -->\n<!-- An Vorwissen ankn√ºpfen -->\n<!-- -- gilt auch f√ºr √ºbrige Kapitel und √ºbrige B√ºcher -->\n\n\n<!-- ### Inferenz als Generalisieren -->\n\n\nüì∫ [Was ist Inferenz?](https://www.youtube.com/watch?v=QNMVi6IqQ90&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN)\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlie√üen, bzw. vom Konkreten auf das Abstrakte.^[Statistische Inferenz sieht sich drei \"Herausforderungen\" gegen√ºber, laut  @gelman_regression_2021, Kap. 1.1.; Diese betreffen das Schlie√üen (oder Generalisieren) vom Einzelfall auf das Allgemeine: 1. Von der Stichprobe aus die Grundgesamtheit (Population), 2. Von der Experimental- auf die Kontrollgruppe (Kausalinferenz), 3. Von einem Messwert auf das zugrundeliegende Konstrukt. In diesem Kurs besch√§ftigen wir uns mit den ersten beiden Herausforderungen.]\n\n\nTypischerweise untersuchen im Rahmen einer statistischen Analyse eine *Stichprobe*, \nwie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht \"Tolle Studie zu dem Geheimnis des Gl√ºcks!!!\" zu klicken.\nIhr Freundeskreis ist ein *Teil* der Menschen (z.B. aus Deutschland), also eine Stichprobe.\nSchauen wir uns den Unterschied zwischen Stichprobe und Population n√§her an.\n\n## Stichprobe vs. Population\n\n\nNehmen wir an, wir m√∂chten herausfinden, wie gro√ü der Anteil der R-Fans in der Population der Studierenden ist. \nDen Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit `A`^[~~Meistens~~ Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?].\n\nDas *Grundproblem der Inferenzstatistik* ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.\n\nWir m√ºssen also den Anteil der R-Fans *in der Population* auf Basis des Anteils *in der Stichprobe* schlie√üen:\nWir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. @fig-pop und @fig-sample.\n\n\n\n:::: {layout-ncol=\"2\"}\n\n:::{#population}\n![Population](img/pvoll.png){#fig-pop}\n:::\n\n\n:::{#sample}\n![Sample](img/psti.png){#fig-sample}\n:::\n\n\n\nPopulation vs. Sample. Autor: Karsten L√ºbke. OEM\n::::\n\n<!-- Quelle: LAYOUT in PDF: https://github.com/quarto-dev/quarto-cli/discussions/7497 -->\n\n\n<!-- ![Population](img/pvoll.png){#fig-pop width=\"40%\"} -->\n<!-- ![Sample](img/psti.png){#fig-sample width=\"40%\"} -->\n<!-- Ohne Zwischenzeile funktioniert die REferenz nicht, aber es s√§he besesr im PDF-Druck aus. -->\n\n\nH√§ufig ist das praktische Vorgehen recht simpel: \nAh, in unserer Stichprobe sind 42% R-Fans!^[Manch einer h√§tte mit mehr gerechnet; andere mit weniger...]. Man schreibt gerne: $p = 0.42$ (`p` wie `proportion`). Die Stichprobe sei repr√§sentativ f√ºr die Grundgesamtheit aller Studierender. \nMesserscharf schlie√üen wir:\nIn der Grundgesamtheit ist der Anteil der R-Fans auch 42%, $\\pi=0.42$.\n\n\n:::callout-note\nWir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische ($\\pi$) f√ºr Populationen.$\\square$\n:::\n\n\n\n\n### Deskriptiv- vs. Inferenzstatistik\n\nStatistik gibt es in zwei Geschmacksrichtungen, k√∂nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. @fig-inf1.\n\n\n\nVereinfacht gesprochen fasst die Deskriptivstatistik  Daten (einer Stichprobe) zu einer einzelnen Kennzahl zusammen.\n\n::: {#exm-desk}\nIn einem H√∂rsaal sitzen 100 Studis. Alle schreiben Ihre K√∂rpergr√∂√üe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der K√∂rpergr√∂√üe der anwesenden Studentis aus. Voil√†: Deskriptive Statistik!$\\square$\n:::\n\n![Deskriptiv- vs. Inferenzstatistik](img/desk_vs_inf-crop.png){#fig-inf1 width=70% fig-align=\"center\"}\n\n\n:::{#exr-smple-pop}\nüèã Schlie√üen Sie die Augen und zeichnen Sie obiges Diagramm, @fig-inf1!$\\square$\n:::\n\n\n\n:::{#def-desk}\n### Deskriptivstatistik\n*Deskriptivstastistik* fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\n:::\n\n:::{def-inf}\n### Inferenzstatistik\n*Inferenzstatistik* ist ein Verfahren zum Schlie√üen von Statistiken (Kennzahl einer Grundgesamtheit) auf *Parameter* (eine Kennzahl  einer Grundgesamtheit).\n\n\nInferenz bedeutet Schlie√üen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schl√ºsse zu ziehen.\n\n:::\n\n\n\n\n:::{#exr-inf}\nüèãÔ∏èÔ∏è Heute Nacht vor dem Schlafen wiederholen Sie die Definition. √úben Sie jetzt schon mal.$\\square$\n:::\n\n\n### Deskriptiv- und Inferenzstatistik gehen Hand in Hand\n\nF√ºr jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, um den zugeh√∂rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle @tbl-kennwerte. \nDa man die Parameter der Population so gut wie nie sicher kennt (schlie√ülich hat man meist nur Ausz√ºge, Teile der Population, also Stichproben), muss man sich mit *Sch√§tzwerten* begn√ºgen.\nSch√§tzwerte macht man kenntlich mit einem \"Dach-Zeichen\" √ºber dem Parameter, also z.b. $\\hat{\\mu}$, lies: \"m√º-Dach\".\n\n\n\n\n::: {#tbl-kennwerte .cell tbl-cap='Bezeichnungen f√ºr Kennwerte'}\n::: {.cell-output-display}\n\n\nKennwert      Stichprobe   Grundgesamtheit (Aussprache)   Sch√§tzwert     \n------------  -----------  -----------------------------  ---------------\nMittelwert    $\\bar{X}$    $\\mu$ (m√º)                     $\\hat{\\mu}$    \nStreuung      $sd$         $\\sigma$ (sigma)               $\\hat{\\sigma}$ \nAnteil        $p$          $\\pi$ (pi)                     $\\hat{\\pi}$    \nKorrelation   $r$          $\\rho$ (rho)                   $\\hat{\\rho}$   \nRegression    $b$          $\\beta$ (beta)                 $\\hat{\\beta}$  \n\n\n:::\n:::\n\n\n\n\n\n\n\n\nF√ºr Statistiken (Daten einer Stichprobe) verwendet man *lateinische* Buchstaben; \nf√ºr Parameter (Population) verwendet man *griechische* Buchstaben.\n\n\n:::{#exr-greek}\nüèãÔ∏è Geben Sie die griechischen Buchstaben f√ºr typische Statistiken an. Ohne auf die Tabelle zu schauen.üòú$\\square$!\n:::\n\n\n### Sch√§tzen von Parametern einer Grundgesamtheit\n\nMeist begn√ºgt man sich  beim Analysieren von Daten nicht mit Aussagen f√ºr eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\n\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit *Sch√§tzungen* begn√ºgen.\n\nSch√§tzwerte werden mit einem \"Dach\" √ºber dem Kennwert gekennzeichnet, s. letzte Spalte in @tbl-kennwerte.\n\n\nIn der angewandten Forschung interessieren h√§ufig Fragen wie: \"Welche Entscheidung ist (wahrscheinlich) besser?\".\nDa bekanntlich (fast) keine Aussagen sicher sind, spielt *Wahrscheinlichkeit* eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.\n\n:::callout-note\nWahrscheinlichkeit wird oft mit *Pr* oder *p* abgek√ºrzt, f√ºr engl. *probability*.$\\square$\n:::\n\n\n:::{#exm-inf}\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, $\\bar{X}_{V1}$ und $\\bar{X}_{V2}$. \nDie Mittelwerte unterscheiden sich etwas, $\\bar{X}_{V1} > \\bar{X}_{V2}$. \nSind diese Unterschiede \"zuf√§llig\" oder \"substanziell\"? Gilt also $\\mu_{V1} > \\mu_{V2}$ oder gilt $\\mu_{V1} \\le \\mu_{V2}$? \nWie gro√ü ist die Wahrscheinlichkeit$Pr(\\mu_{V1} > \\mu_{V2})$?\n:::\n\n\n:::{#exr-pred-maint}\nüèãÔ∏è VERTIEFUNG  *Predictive Maintenance* ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 [dieses Berichts](https://www.rolandberger.com/publications/publication_pdf/roland_berger_vdma_predictive_maintenance_d_1.pdf)!$\\square$\n:::\n\n\n## Modellieren\n\n### Modellieren als Grundraster des Erkennens\n\nIn der Wissenschaft -- wie auch oft in der Technik, Wirtschaft oder im Alltag -- betrachtet man einen Teil der Welt n√§her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\n\nNun ist die Welt ein weites Feld. \nJedes Detail zu ber√ºcksichtigen ist nicht m√∂glich.\nWir m√ºssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend n√∂tig sind.\nAber gleichzeitig die Strukturelemente der wirklichen Welt, die f√ºr unsere Fragestellung zentral ist, beibehalten.\n\nDieses Tun nennt man *Modellieren*: Man erstellt sich ein Modell.\n\n:::{#def-model}\n### Modell\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.$\\square$\n:::\n\nDer Nutzen eines Modells ist, einen (√ºberm√§√üig) komplexen Sachverhalt zu vereinfachen oder √ºberhaupt erst handhabbar zu machen.\nMan versucht zu vereinfachen, ohne Wesentliches wegzulassen. \nDer Speck muss weg, sozusagen. Das Wesentliche bleibt.\n\nAuf die Statistik bezogen hei√üt das,\ndass man einen Datensatz dabei so zusammenfasst,\ndamit man das Wesentliche erkennt.\nWas ist das \"Wesentliche\"? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. Etwa: \"Wie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?\"^[Das ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.]\nNoch allgemeiner ist man dabei h√§ufig am Zusammenhang von `X ` und `Y` interessiert, s. @fig-xy, die ein Sinnbild von statistischen Modellen widergibt.\n\n\n\n\n\n:::{#fig-xy fig-align=\"center\"}\n\n\n\n\n\n```{mermaid}\nflowchart LR\nX --> Y\n\n\nX1 --> Y2\nX2 --> Y2\n```\n\n\n\n\noben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\n:::\n\n\nMan kann @fig-xy als ein Sinnbild einer (mathematischen) Funktion lesen.\n\n:::{#def-fun}\n### Funktion\nEine Funktion $f$ setzt zwei Gr√∂√üen in Beziehung. $\\square$\n:::\n\nIn Mathe-Sprech:\n\n$f: X \\rightarrow Y$\n\noder:\n\n$y = f(x)$, lies: \"Y ist eine Funktion von X\".\n\n\n\n\n\n\nEs h√∂rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren:\nWenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet,\nmacht man sich ein Modell:\nman vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl,\ndie das forschungsleitende Interesse zusammenfasst.\n\n### Vertiefung\n\nLesen Sie die Einf√ºhrung zum Thema Modellieren bei @poldrack_statistical_2022 (Kap. 5.1).\n\n\n:::callout-note\nNutzen Sie die √úbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.\n:::\n\n\n## Regression\n\nEinflussreiche Leute schw√∂ren auf die Regressionsanalyse (@fig-gandalf).\n\n![One regression](img/einring.jpg){width=\"50%\" #fig-gandalf fig-align=\"center\"}\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n@fig-linfun zeigt ein interaktives Beispiel einer linearen Funktion. \nSie k√∂nnen Punkte per Klick/Touch hinzuf√ºgen.\n\n\n:::{#fig-linfun}\n\n::: {.figure-content}\n\n<!-- ```{=html} -->\n<!-- <iframe width=\"500\" height=\"400\" src=\"https://www.geogebra.org/m/vfjW1dZt\" title=\"Visualisierung eines Geradenmodells\"></iframe> -->\n<!-- ``` -->\n\n\n\n\n\n\n\n\n\n```{ojs}\n//| echo: false\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () => {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n```\n\n```{ojs}\n//| echo: false\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () => {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n```\n\n```{ojs}\n//| echo: false\nrSquaredPlot = RSquaredPlot({ width: width })\n```\n\n```{ojs}\n//| echo: false\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) => x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) => y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n```\n\n```{ojs}\n//| echo: false\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) => {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n```\n\n```{ojs}\n//| echo: false\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) => {\n    setTimeout(() => {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n```\n\n```{ojs}\n//| echo: false\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R¬≤\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =>\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =>\n        update.call((update) => {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) => xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =>\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =>\n        update.call((update) => {\n          // Check if bar is too short\n          const check = (d) => d < 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) => xScale(d))\n            .text((d) => labelFormat(d))\n            .attr(\"fill\", (d) => (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) => (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) => (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n```\n\n```{ojs}\n//| echo: false\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) => x, // accessor function for x-coordinate\n    y = ([, y]) => y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) => ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) => ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) => d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) => d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) => d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) => d.xCoord)\n    .y((d) => d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) => g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) => {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) => g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) => {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () => {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () => {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) => d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) => {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) => xScale(d[0][0]))\n          .attr(\"x2\", (d) => xScale(d[1][0]))\n          .attr(\"y1\", (d) => yScale(d[0][1]))\n          .attr(\"y2\", (d) => yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) => xScale(d.xCoord))\n            .attr(\"cy\", (d) => yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =>\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =>\n          update\n            .transition()\n            .attr(\"cx\", (d) => xScale(d.xCoord))\n            .attr(\"cy\", (d) => yScale(d.yCoord)),\n        (exit) =>\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) => xScale(d.xCoord))\n            .attr(\"y1\", (d) => yScale(d.yCoord))\n            .attr(\"x2\", (d) => xScale(d.xCoord))\n            .attr(\"y2\", (d) => yScale(d.yCoord))\n            // Add transition\n            .call((enter) =>\n              enter\n                .transition()\n                .attr(\"y2\", (d) => yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =>\n          update.call((update) => {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) => xScale(d.xCoord))\n              .attr(\"y1\", (d) => yScale(d.yCoord))\n              .attr(\"x2\", (d) => xScale(d.xCoord))\n              .attr(\"y2\", (d) => yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =>\n          exit\n            .transition()\n            .attr(\"y2\", (d) => yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) => {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) => {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) < 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) => xScale(d.xCoord))\n            .attr(\"y\", (d) => yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) => {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =>\n          update.call((update) => {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) => xScale(d.xCoord))\n              .attr(\"y\", (d) => yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) => exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) => ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n```\n\n```{ojs}\n//| echo: false\nd3 = require(\"d3-regression\", \"d3\")\n```\n\n\n\n[Quelle](https://observablehq.com/@yizhe-ang/interactive-visualization-of-linear-regression)\n\n\n\n\n\n:::\n\nInteraktives Beispiel f√ºr eines lineares Modell. F√ºgen Sie Punkte per Klick/Touch hinzu.\n\n:::\n\n\n\nAlternativ k√∂nnen Sie [diese App](https://gallery.shinyapps.io/simple_regression/) njutzen, Regressionskoeffizienten, Steigung (slope) und Achsenabschnitt (Intercept), zu optimieren.\nDabei meint \"optimieren\", die Abweichungen (Residuen, Residualfehler; die roten Balken in der App) zu minimieren.^[<https://gallery.shinyapps.io/simple_regression/>]\n\n\n\n:::\n\n\n[Hier](https://shinyapps.org/showapp.php?app=https://shiny.psy.lmu.de/felix/lmfit&by=Felix%20Sch%C3%B6nbrodt&title=Find-a-fit!&shorttitle=Find-a-fit!) finden Sie eine App, die Ihnen gestattet, selber Hand an eine Regressionsgerade zu legen.\n\n\n:::{#exr-setosa-vis}\n### VERTIEFUNG Regression mit Animationen erkl√§rt\nLesen Sie [diesen Post](https://setosa.io/ev/ordinary-least-squares-regression/), der Ihnen mit Hilfe von Bildern und Animationen (okay, und etwas) Text die Grundlagen der Regressionsanalyse erkl√§rt.$\\square$\n:::\n\n\n\n### Regression zum Modellieren\n\nDie Regression ist eine Art Schweizer Taschenmesser der Statistik: F√ºr vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden.\nDas ist nicht nur einfacher, sondern auch sch√∂ner. \nWir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n:::callout-note\nRegression + Inferenz = üíñ\n:::\n\n\n\nAlternativ zur Regression k√∂nnte man sich in den Wald der statistischen Verfahren begeben, [wie hier von der Uni M√ºnster als Ausschnitt (!) aufgef√ºhrt](https://web.archive.org/web/20091029162244/http://www.wiwi.uni-muenster.de/ioeb/en/organisation/pfaff/stat_overview_table.html).\nAuf dieser Basis kann man meditieren,\nwelches statistischen Verfahren man f√ºr eine bestimmte Fragestellung verwenden sollte, s. Abb.  @fig-choose-test.\nMuss man aber nicht -- man kann stattdessen die Regression benutzen.\n\n![W√§hle deine Statistik mit Bedacht. Oder w√§hle die Regressionsanalyse.](img/choose-test.png){#fig-choose-test}\n\n:::callout-note\nEs ist meist einfacher und n√ºtzlicher, die Regression zu verwenden, anstelle der Vielzahl von anderen Verfahren (die zumeist Spezialf√§lle der Regression sind). In diesem Kurs werden wir f√ºr alle Fragestellungen die Regression verwenden.^[Wie Jonas [Kristoffer Lindel√∏v](https://lindeloev.github.io/tests-as-linear/) uns erkl√§rt, sind viele statistische Verfahren, wie der sog. t-Test Spezialf√§lle der Regression.]$\\square$\n:::\n\n\n\n\n\n\n<!-- ![Common statistical tests as linear models](img/linear_tests_cheat_sheet.png){#fig-lindeloev} -->\n\n\n\n### In voller Pracht\n\n\nHier ist die Regressionsgleichung in voller Pracht; s. @fig-regr-rules.\nLinks sieht man eine einfache Regression mit `hp` als Pr√§diktor (`X`, unabh√§ngige Variable) und `mpg` als abh√§ngige Variable (`Y`).\nDas rechte Teildiagramm zeigt eine multiple Regression mit den Pr√§diktoren `hp` und `am`.^[Der Datensatz `mtcars` wird gerne als Studienobjekt verwendet, da er einfach ist und f√ºr viele Beispiele geeignet. Wenn Sie sich einen Sachverhalt an einem einfachen Datensatz vergegenw√§rtigen wollen, bietet sich auch der Datensatz `mtcars` an. Zudem ist er \"fest in R eingebaut\"; mit `data(mtcars)` k√∂nnen Sie ihn verf√ºgbar machen.]\n\nIm einfachsten Fall sind die vom Modell vorhergesagten (gesch√§tzten) Werte, $\\hat{y}$, durch eine einfache Gerade beschrieben, s. @fig-regr-rules, links.\nEine Gerade l√§sst sich durch folgende Formel beschreiben: $\\hat{y} = \\beta_0 + \\beta_1$. \nDabei ist $\\beta_0$ der *Achsenabschnitt* (eng. intercept) und $\\beta_1$ die *Steigung* der Regressiongeraden.\n\n\n:::{def-lm}\nIn allgemeiner Form schreibt man die Regressionsgleichung so, s. @eq-lm\n\n\n$$y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon$${#eq-lm}\n\nMan nennt alle $\\beta_0, \\beta_1, \\beta_2, ...$ die *Koeffizienten*, *Regressionsgewichte* oder *Parameter* des Modells [@gelman_regression_2021].\n:::\n\nAnhand von @eq-lm erkennt man auch, warum man von einem *linearen Modell* spricht: \nY wird als gewichteter Mittelwert mehrerer Summanden ($X_1, X_2, ...$) berechnet.\n\n\n\n\n\n\n::: {#fig-regr-rules .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Einfache Regression (ein Pr√§diktor: hp)](0200-Inferenz_files/figure-html/fig-regr-rules-1.png){#fig-regr-rules-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Multiple Regression (zwei Pr√§diktoren: hp und am)](0200-Inferenz_files/figure-html/fig-regr-rules-2.png){#fig-regr-rules-2 width=672}\n:::\n\nDie Regressionsgerade in voller Pracht\n:::\n\n\n\n\n\n\n## Unsicherheit\n\n### Inferenz beinhaltet Ungewissheit\n\nInferenzstatistische Schl√ºsse sind mit Unsicherheit (Ungewissheit) behaftet: Schlie√ülich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), m√∂chte aber vom Teil auf das Ganze schlie√üen.\n\n\n\n:::callout-important\nNichts Genaues wei√ü man nicht: Schlie√üt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von *Ungewissheit*, da man die Unsicherheit das Wissen √ºber die Genauigkeit des Schlie√üens betrifft.\n:::\n\n\nSchlie√üt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit; es ist ungewiss.\nMan ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger.\nSchlie√ülich hat man *nicht* die ganze Population gesehen bzw. vermessen. \n*Sicher* ist man sich hingegen f√ºr die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer m√∂glich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird daher auch als die Mathematik des Zufalls bezeichnet.\n\n::: {#def-zufall}\n\n## Zuf√§lliges Ereignis\nUnter einem zuf√§lligen (engl. random) Ereignis verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres n√§chsten W√ºrfelwurfs. Zuf√§llig bedeutet nicht (zwangsl√§ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines W√ºrfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n:::\n\n:::{#exr-muenz}\nüèã Welche physikalischen Randbedingungen wirken wohl auf einen M√ºnzwurf ein?$\\square$\n:::\n\n\n:::{#exm-muenz}\n### Beispiele zur Quantifizierung von Ungewissheit\n\nAussagen mit Unsicherheit k√∂nnen unterschiedlich pr√§zise formuliert sein.\n\n-   Morgen regnet's $\\Leftrightarrow$ Morgen wird es hier mehr als 0 mm Niederschlag geben ($p=97\\%$).\n\n-   Methode $A$ ist besser als Methode $B$ $\\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert von $Y$ f√ºr Methode $A$ h√∂her als f√ºr Methode $B$.\n\n-   Die Maschine f√§llt demn√§chst aus $\\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den n√§chsten 1-3 Tagen ausfallen, laut unserem Modell.\n\n-   Die Investition lohnt sich $\\Leftrightarrow$ Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n:::\n\n\n:::{#exr-ungewiss}\nüèã Geben Sie weitere Beispiele an!\n:::\n\n\n### Wahrscheinlichkeit\n\nDie Wahrscheinlichkeitsrechnung ist die typische Methode, um Ungewissheit zu pr√§zisieren, d.h. zu quantifizieren.\n\n:::{#def-wskt}\n### Wahrscheinlichkeit\nDie Wahrscheinlichkeit ist ein Ma√ü daf√ºr, f√ºr wie sicher jemand es h√§lt, dass ein Ereignis eintritt. Die Wahrscheinlichkeit eines Ereignisses wird als Zahl zwischen 0 und 1 angegeben, wobei 0 bedeutet, dass das Ereignis als unm√∂glich angesehen wird, und 1 bedeutet, dass das Ereignis als sicher betrachtet wird. $\\square$\n:::\n\n\n\n### Zwei Arten von Ungewissheit\n\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. @fig-zwei-arten.\n\n\n1. Wie (un)gewiss ist man sich √ºber die Regressionsgewichte?\n\n2. Wie (un)gewiss ist man sich √ºber die Genauigkeit der Vorhersage (des Modells)?\n\n\n\n\n\n```{mermaid}\n%%| label: fig-zwei-arten\n%%| fig-cap: Zwei Arten der Ungewissheit beim Modellieren\nflowchart LR\nX1 -->|Werte von Steigung und Achsenabschnitt?|B\nX2 -. Genauigkeit des Modells .-> B\n\n```\n\n\n\n\n\n#### Ungewissheit der Modellkoeffizienten\n\nWie man in @fig-regr-div sieht, k√∂nnen sich die Koeffizienten (Achsenabschnitt und Steigung) unterscheiden.\nWoran liegt das?\n\n:::{#exm-flights}\n### Stichproben der New Yorker Fl√ºge\nNehmen wir an, wir ziehen ein paar Zufallstichproben aus der Menge (Population) aller Fl√ºge, die in New York im Jahre 2013 gestartet sind.\nIn jeder Stichprobe berechnen wir eine Regression zwischen Flugzeit und Versp√§tung des Flugs am Ankunftsort.\nSicherlich werden sich die Stichproben in ihren Kennwerten, z.B. in den Koeffizienten der genannten Regression, unterscheiden.$\\square$\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nycflights13)\ndata(flights)\n\nstipro1 <- sample_n(flights, size = 100)\nstipro2 <- sample_n(flights, size = 100)\nstipro3 <- sample_n(flights, size = 100)\n```\n:::\n\n::: {#fig-regr-div .cell layout-ncol=\"3\"}\n::: {.cell-output-display}\n![Stichprobe 1](0200-Inferenz_files/figure-html/fig-regr-div-1.png){#fig-regr-div-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Stichprobe 2](0200-Inferenz_files/figure-html/fig-regr-div-2.png){#fig-regr-div-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Stichprobe 3](0200-Inferenz_files/figure-html/fig-regr-div-3.png){#fig-regr-div-3 width=672}\n:::\n\nRegressionsanalysen mit verschiedenen Koeffizienten aufgrund der Zuf√§lligkeit  des Stichprobenziehens\n:::\n\n\n\n\n\nDer Grund f√ºr die Schwankungen der Modellparameter zwischen den Stichproben ist die Zuf√§lligkeit des Stichprobenziehens. \nJe nachdem, wie es der Zufall (oder sonst wer) will, landen bestimmte F√§lle (Fl√ºge in unserem Beispiel) in unserer Stichprobe.\nZumeist unterscheiden sich die Stichproben; theoretisch k√∂nnten sie aber auch rein zuf√§llig gleich sein.\n\n:::callout-important\nStichproben-Kennwerte schwanken um den tats√§chlichen Wert in der Population herum.$\\square$\n:::\n\nUm diese Ungewissheit, die sich in den Schwankungen der Stichproben-Regressionskoeffizienten ausdr√ºckt, anzuzeigen, ist ein \"grauer Schleier\" um die Regressionsgeraden in @fig-regr-div gekennzeichnet.\nDieser grauer Schleier gibt also eine Spannbreite anderer, plausibler Ergebnisse an, die sich in einer anderen Stichprobe auch manifestieren k√∂nnten.\n\n\n\n#### Ungewissheit der Modellg√ºte\n\nAngenommen, wir sind uns *sicher* √ºber die Werte der Modellparameter,\nalso √ºber die Lage der Regressionsgeraden, anschaulich gesprochen.\nDann bliebe immer noch Ungewissheit zur Modellg√ºte.\nEin bestimmtes Modell kann genau oder ungenaue Vorhersagen abgeben;\ndas ist die zweite Art der Ungewissheit.\n\nDiese Art der Ungewissheit ist nicht von Interesse, wenn man nur an Modellkoeffizienten interessiert ist.\nSie ist dann interessant, wenn man f√ºr einzelne F√§lle eine Vorherage macht und sich fragt, wie zuverl√§ssig diese Vorhersage ist.\n\n\n\n\n\n::: {#fig-resid-var .cell layout-ncol=\"3\"}\n::: {.cell-output-display}\n![geringer Vorhersagefehler (hohe Vorhersageg√ºte)](0200-Inferenz_files/figure-html/fig-resid-var-1.png){#fig-resid-var-1 width=672}\n:::\n\n::: {.cell-output-display}\n![hoher Vorhersagefehler](0200-Inferenz_files/figure-html/fig-resid-var-2.png){#fig-resid-var-2 width=672}\n:::\n\n::: {.cell-output-display}\n![auch hoher Vorhsagefehler](0200-Inferenz_files/figure-html/fig-resid-var-3.png){#fig-resid-var-3 width=672}\n:::\n\nRegressionsanalyse mit gleicher Regressionsgerade, aber unterschiedlicher Vorhersageg√ºte\n:::\n\n\n\n\n\n\n\n### Ich wei√ü, was ich nicht wei√ü: Ungewissheit angeben\n\n\nStreng genommen ist eine Inferenz ohne Angabe der Ungewissheit (Genauigkeit der Sch√§tzung) wertlos.\nAngenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% sch√§tzt, l√§sst aber offen wie *sicher* (pr√§zise) die Sch√§tzung (der Modellparameter) ist.\nWir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Sch√§tzung schlie√üt sogar 41% oder 43% aus.\n\n:::callout-important\nSchlie√üt man auf eine Population, sch√§tzt also die Modellparameter, so sollte stets die (Un-)Genauigkeit der Sch√§tzung, also die Ungewissheit des Modells, angegeben sein.$\\square$\n:::\n\n\n\nIm Rahmen der Regressionsanalyse schl√§gt sich die Ungewissheit an zwei Stellen nieder:\n\n1.  zur Lage der Regressionsgeraden, $\\beta_0$, $\\beta_1$\n2.  zur Modellg√ºte bzw. zum Vorhersagefehler, $\\sigma$ ^[$\\sigma$, das griechische *s* f√ºr Streuung (um die Regressionsgerade herum), manchmal wird auch e wie *error* verwendet]\n\n\n\n### Visualisierung von Ungewissheit\n\n\n::: {#def-punktschaetzer}\n\n### Punktsch√§tzer\n\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem *Punktsch√§tzer*.\n\n\nPunktsch√§tzer beinhalten *keine Angabe* der Sch√§tz(un)genauigkeit, s. Abb. @fig-ungewiss2, links. Rot markiert: Die Punktsch√§tzung von `mpg` f√ºr `hp=200`.\n\n:::\n\n\n<!-- ![Eine Punktsch√§tzung der Regressionsgeraden und die zugeh√∂rige Ungewissheit Ungewissheit](img/fig-punktschaetzer.png){#fig-punktschaetzer2} -->\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n\n\nIn Abb. @fig-ungewiss2, links, ist die Ungewissheit in den *Regressionskoeffizienten* visualisiert: Wie sicher sind wir uns bzgl. der Lage der Regressionskoeffizienten? Vgl. @def-punktschaetzer.\n\n\n\nAuch wenn wir uns *sicher* w√§ren im Hinblick auf die Regressionsgewichte in Abb. @fig-ungewiss2, links, bliebe Ungewissheit bei der Vorhersage des Bereichs plausibler Werte f√ºr individuelle Vorhersagen, s. @fig-ungewiss2, rechts.\nUnsere Sch√§tzungen w√§ren auch dann nicht sicher, nicht fehlerfrei, wenn wir den genauen Verlauf der Regressiongerade sicher w√ºssten.\nDas liegt daran, da das Modell nicht alle Einfl√ºsse auf Y ber√ºcksichtigt, sondern nur einen einzigen, hier als X bezeichnet. \nDas Modell hat also keine perfekte Information, es ist ungewiss √ºber alle m√∂glichen Einflussfaktoren auf Y.\nW√ºsste unser Modell alle Einflussfaktoren genau, so w√§re unser Vorhersageintervall sehr schmal (bzw. h√§tte null Breite). \n\nIn Abb. @fig-ungewiss2, rechts, ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die Ungewissheit zur Vorhersage der Y-Werte individueller Beobachtungen dargestellt. In diesem Fall spricht man von einem \"Vorhersageintervall\", da man nicht nur von \"typischen F√§llen\" auf der Regressiongeraden spricht, sondern f√ºr echte F√§lle Vorhersagen (Sch√§tzungen) t√§tigt, wo auch die Ungewissheit der Modellg√ºte relevant ist.\n\n\n<!-- ![Das Vorhersageintevall zeigt eine Punktsch√§tzung und ihre Ungewissheit](img/fig-predintervall.png){fig-ungewiss2 width=\"50%\"} -->\n\n\n\n\n\n::: {#fig-ungewiss2 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Eine Punktsch√§tzung der Regressionsgeraden und die zugeh√∂rige Ungewissheit der Koeffizienten](0200-Inferenz_files/figure-html/fig-ungewiss2-1.png){#fig-ungewiss2-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Das Vorhersageintevall zur Regressionsgeraden zeigt die Ungewissheit f√ºr die jeweiligen Beobachtungen](0200-Inferenz_files/figure-html/fig-ungewiss2-2.png){#fig-ungewiss2-2 width=672}\n:::\n\nDie zwei Arten der Ungewissheit visualisiert\n:::\n\n\n\n\n@fig-ungewiss2 zeigt auch, dass f√ºr eine Beobachtung mit `hp=200` der *Punktsch√§tzer* der gesch√§tzte Wert von `mpg` bei ca `16.5` liegt.\nDas ist sozusagen unser *Best Guess*.\nWeiterhin ist (in gr√ºn) das *Vorhersageintervall* f√ºr `hp=200` angezeigt.\nF√ºr Beobachtungen mit `hp=200` liegt der Bereich plausibler `mpg`-Werte in dem (gr√ºn) markierten Bereich (ca. 8 bis 25).\n\n:::{#def-vorhersageintervall}\n### Vorhersageintervall\nEin Vorhersageintervall zeigt den Bereich plausibler Werte (laut unserer Analyse) f√ºr eine Beobachtung mit bestimmten Pr√§diktor-Werten.$\\square$\n:::\n\n\n\nWie man sieht, wird die Ungewissheit *gr√∂√üer*, wenn man beide Arten der Ungewissheit ber√ºcksichtigt. Das Vorhersage-Intervall ber√ºcksichtigt Ungewissheit in $\\beta_0, \\beta_1, \\epsilon$ bei der Vorhersage von $\\hat{y_i}$.\n\n\n:::{#exr-zweifache-ungewissheit}\nüèã Geben Sie ein vergleichbares Beispiel an!\n:::\n\n\n\n### Konfidenzintervall\n\n\nWir sehen in @fig-ungewiss2, dass ein \"Ungewissheitskorridor\" angegeben wird f√ºr die Lage der Regressionsgerade (linkes Teildiagramm) bzw. f√ºr den Bereich plausibler Vorhersagen im konkreten Fall einer Beobachtung mit bestimmten X-Wert.\nEntsprechend wird nicht ein *Punktsch√§tzer*, sondern ein *Sch√§tzbereich* angegeben.\nMan spricht auch von einem *Konfidenzintervall* oder *Unsicherheitsbereich*.^[Tats√§chlich gibt es mehrere Synonyme oder √§hnliche Begriffe f√ºr Konfidenzintervall. Wir kommen sp√§ter darauf detaillierter zu sprechen.]\n\n::: {#def-konfintervall}\n\n### Konfidenzintervall\n\nEin Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff f√ºr Sch√§tzbereiche. Die Grenzen eines Konfindenzintervall markieren einen Bereich plausibler Werte f√ºr einen Parameter. \n\n:::\n\n\nEs gibt verschiedene Arten, Konfidenzintervalle zu berechnen; wir sprechen in sp√§teren Kapiteln dazu ausf√ºhrlicher. Ein Konfidenzintervall wird h√§ufig mit 90% oder 95% Genauigkeit angegeben.  Im Kontext der Bayes-Analyse - auf der dieser Kurs aufbaut - ist ein Konfidenzintervall einfach zu interpretieren. \nSagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall f√ºr den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.\nDieser Befund l√§sst sich so interpretieren: ‚ÄúLaut Modell liegt der gesuchte Anteil der R-Fans mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.‚Äù Diese (einfache) Interpretation ist im Frequentismus *nicht* m√∂glich.\n\n\n\n\n:::{#exm-ungewisskorr}\nGeben Sie Beispiele f√ºr Konfidenzintervalle an.\n:::\n\n##  Frequentismus vs. Bayes-Inferenz\n\n\n::::{.columns}\n:::{.column}\n###  Frequentismus: Klassische Inferenz\n\n-   Die Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zur√ºckgewiesen.\n-   Nur die Daten selber fliesen in die Ergebnisse ein, keine Vorannahmen.\n-   Wahrscheinlichkeit wird √ºber relative H√§ufigkeiten definiert.\n-   Es ist *nicht* m√∂glich, die Wahrscheinlichkeit einer Hypothese bzw. eines Werts in der Population (eines Parameters) anzugeben.\n-   Stattdessen wird angegeben, wie h√§ufig eine vergleichbare Datenlage zu erwarten ist, wenn der Versuch sehr h√§ufig wiederholt ist.\n-   Ein Gro√üteil der Forschung (in den Sozialwissenschaften) verwendet (aktuell) diesen Ansatz.\n:::\n\n\n:::{.column}\n### Bayesianische Inferenz\n\n-   Vorwissen (Priori-Wissen) flie√üt explizit in die Analyse ein (zusammen mit den Daten).\n-   *Wenn* das Vorwissen gut ist, wird die Vorhersage durch das Vorwissen genauer, ansonsten ungenauer.\n-   Die Wahl des Vorwissens muss explizit (kritisierbar) sein.\n-   In der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen f√ºr Hypothesen m√∂glich.\n-   Die Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (f√ºr g√§ngige Computer) komfortabel geworden.\n:::\n::::\n\n\n\n\n### Frequentismus\n\n#### Der p-Wert\n\nDie zentrale Statistik des Frequentismus hei√üt der *p-Wert*\n\nDer p-Wert ist so definiert, vgl. @wasserstein_asa_2016: \n\n>   Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zuf√§llig verschieden und auf Basis unseres Modells)?\n\nFindet man $p<.05$ (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von \"(statistischer) Signifikanz\" und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\nFaktisch entscheidet man sich, die Forschungshypothese weiterhin als \"vorl√§ufig g√ºltig\" oder zumindest als \"nicht widerlegt\" zu betrachten.\n\n\n:::{#exr-p}\nüèã Recherchieren Sie eine Definition des p-Werts und lesen Sie sie einem Freund. Beobachten sie die Reaktionen auf ihre Erkl√§rung.$\\square$\n:::\n\nDer p-Wert wird oft falsch verstanden [@badenes-ribera_misconceptions_2016-1].\nAber er ist auch nicht leicht zu verstehen, meint Meister Yoda, s. @fig-yoda.\nHier sind einige *FALSCHE* Interpretationen zum p-Wert laut der Autoren:\n\n- üôÖ‚Äç‚ôÄ Der p-Wert w√ºrde die Wahrscheinlichkeit der Nullhypothese oder der Forschungshypothese angeben. üôä \n- üôÖ‚Äç‚ôÄ Der p-Wert w√ºrde ein inhaltlich bedeutsames, praktisch signifikantes Ergebnis anzeigen. üôä \n\n\n![Der p-Wert ist wenig intuitiv, meint Meister Yoda](img/pvalue-yoda.jpg){#fig-yoda width=50%}\n\n\n#### Konfidenzintervalle\n\nDie korrekte Definition der Konfidenzintervalls in *frequentistischer* Lesart lautet:\n\n\n\n>   Der Konfidenzbereich, z.B. von 95%, repr√§sentiert den Anteil der Konfidenzintervalle bei sehr vielen (oder undentlich vielen) Wiederholungen des Experiments, die den echten Parameterwert enthalten [@hoekstra_robust_2014-2].\n\n\n::::: {.content-visible when-format=\"html\"}\n\nDie folgende Visualisierung (@fig-sim-ci) zeigt das Prinzip frequentistischer Konfidenzintervalle: *Auf Dauer* enthalten 95% der Stichproben den wahren Wert (in der Population).\n\n\n::::{#fig-sim-ci}\n\n::: {.figure-content}\n\n<br><br><br> <!-- Insert vertical space here -->\n\n\n\n\n\n<!-- Source: https://observablehq.com/@mattiasvillani/confidence-interval-for-a-mean -->\n\n\n\n```{ojs}\n//| echo: false\nviewof settings = Inputs.form([\n  Inputs.range([-5, 5], {value: 1, label: tex`\\text{MW, }\\mu`, step: 0.01}),\n  Inputs.range([0.01, 5], {value: 1, label: tex`\\text{SD, }\\sigma`, step: 0.01}),\n  Inputs.range([0, 99], {value: 90, label: \"Konfidenzlevel\", step: 1}),\n  Inputs.range([0, 200], {value: 50, label: \"n\", step: 1})\n  ])\n```\n\n```{ojs}\n//| echo: false\nviewof nrep = Scrubber(d3.ticks(1, 1000, 1000), {\n  autoplay: false,\n  loop: false,\n  initial: 1,\n  delay: 500,\n  format: x => `Anzahl von Stichproben = ${x.toFixed(0)}`\n})\n```\n\n```{ojs}\n//| echo: false\ntextinfo = md`\nVon insgesamt ${nrep} Stichproben, ${d3.sum(data.map(d => d.rep <= nrep && (mu >= d.lower && mu <= d.upper)))} (**<span style=\"color:red\">${(d3.sum(data.map(d => d.rep <= nrep && (mu >= d.lower && mu <= d.upper)))*100/nrep).toFixed(3)}%</span>**) von den ${confidence}% Konfindenzintervallen enthielten den wahren (tats√§chlichen) Populationswert ${tex`\\mu= `} ${mu}.\n`\n```\n\n```{ojs}\n//| echo: false\nlockvertical = Inputs.toggle({label: \"Achse einrasten\", value: false})\n```\n\n```{ojs}\n//| echo: false\nplt = Plot.plot({\n  style: {fontSize: \"12px\"},\n  width: 960,\n  y: {\n    label: \"mean\",\n    domain: lockvertical ? [mu- 3, mu + 3] : [mu - 5*sigma/Math.sqrt(nobs),mu + 5*sigma/Math.sqrt(nobs)]\n  },\n  x: {\n    label: \"Stichprobennummer\",\n    domain:  [0, nrep]\n  },\n  marks: [\n    Plot.ruleX([0]),    \n    Plot.ruleX(data, {\n      filter: d => (d.rep <= nrep && mu >= d.lower && mu <= d.upper),\n      x: \"rep\",\n      y1: \"lower\",\n      y2: \"upper\",  \n      stroke: \"steelblue\",\n      strokeWidth: 1.5\n    }),\n    Plot.dot(data, {filter: d => (d.rep <= nrep && mu >= d.lower && mu <= d.upper), x: \"rep\", y: \"xbar\", fill: \"steelblue\", r: 3}),\n\n    Plot.ruleX(data, {\n      filter: d => d.rep <= nrep && (mu < d.lower || mu > d.upper),\n      x: \"rep\",\n      y1: \"lower\",\n      y2: \"upper\",  \n      stroke: \"orange\",\n      strokeWidth: 1.5\n    }),\n    Plot.dot(data, {filter: d => d.rep <= nrep && (mu < d.lower || mu > d.upper), x: \"rep\", y: \"xbar\", fill: \"orange\", r: 3}),\n    Plot.ruleY([mu], {stroke: \"#D22B2B\", strokeWidth: 1.5})\n\n  ]\n})\n```\n\n```{ojs}\n//| echo: false\njstat = require('jstat')\nimport {Scrubber} from \"@mbostock/scrubber\"\n\nfunction simulate_means(mu, sigma, nobs, nrep){\n  \n  const tvalue = jstat.studentt.inv(1-(1-(confidence/100))/2, nobs-1);\n  var data = [];\n  for (let j = 1; j <= nrep; j++){\n        let sample = d3.range(nobs).map(d => d3.randomNormal(mu,sigma)())\n        let xbar = d3.mean(sample)\n        let s = jstat.stdev(sample, true) \n        let lower = xbar - tvalue*s/Math.sqrt(nobs)\n        let upper = xbar + tvalue*s/Math.sqrt(nobs)\n        data.push({rep: j, xbar: xbar, lower: lower, upper: upper})\n  }\n  return data\n}\n```\n\n```{ojs}\n//| echo: false\nmu = 1\nsigma = 1\nconfidence = 90\nnobs = 50\n```\n\n```{ojs}\n//| echo: false\ndata = {\n  nobs;\n  mu;\n  sigma;\n  const d = new Date();\n  let time = d.getTime();\n  const data = simulate_means(mu, sigma, nobs, 1000)\n  return data\n}\n```\n\n\n\n\nQuelle: <https://observablehq.com/@mattiasvillani/confidence-interval-for-a-mean>\n\n\n\n:::\n\nEin frequentistisches 95%-Konfidenzintervall: Auf Dauer enthalten 95% der Konfidenzintervalle den wahren Wert in der Population.\n\n::::\n:::::\n\n:::{.callout-important}\nEin frequentistisches Konfidenzintervall macht keine Aussage zur Wahrscheinlichkeit eines Werts in der Population (eines Parameters). Stattdessen wird eine Aussage √ºber das Ergebnis einer sehr h√§ufig wiederholten Stichprobenziehung berichtet. Ob ein bestimmtes (unseres, Ihres) den wahren Wert enth√§lt, bzw. mit welcher Wahrscheinlichkeit es den wahren Wert enth√§lt, dar√ºber macht das frequentistische Konfidenzintervball keine Aussagen. $\\square$\n:::\n\n#### Aus der Forschung\n\n\nFrequentistische Konfidenzintervalle werden oft falsch verstanden, wie die folgende Studie zeigt. Das liegt aber nicht daran, dass die Menschen zu dumm sind, sondern dass frequentistische Konfidenzintervalle f√ºr viele Menschen kontraintuitiv sind.\n\n@hoekstra_robust_2014-2 berichten von einer Studie, in der $n=442$ Bachelor-Studentis, $n=34$ Master-Studentis und $n=120$ Forschende befragt wurden.\n\nDen Versuchpersonen wurde folgender Fragebogen vorgelegt, s. @fig-bumbledorf.\n\n![Frageobgen zu Konfidenzintervallen](img/bumbledorf.png){#fig-bumbledorf}\n\nKurz gesagt war die Frage, die die Befragten beantworten sollten:\n\n>    In einem Experiment wird ein 95%-Konfidenzintervall mit dem Bereich von 0.1 bis 0.4 beichtet. Welcher der folgenden sechs Aussagen sind richtig bzw. falsch?\n\nMit \"Konfidenzintervall\" meinen die Forschenden ein *frequentistisches* Konfidenzintervall.\n\nAlle diese sechs Aussagen sind *FALSCH*. Die Aussagen lauten:\n\n\n\n1. Die Wahrscheinlichkeit, dass der wahre Mittelwert gr√∂√üer als 0 ist, betr√§gt mindestens 95 %.\n\n2. Die Wahrscheinlichkeit, dass der wahre Mittelwert gleich 0 ist, ist kleiner als 5 %.\n\n3. Die ‚ÄûNullhypothese‚Äú, dass der wahre Mittelwert gleich 0 ist, ist wahrscheinlich falsch.\n\n4. Es gibt eine 95%ige Wahrscheinlichkeit, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\n\n5. Wir k√∂nnen mit 95%iger Sicherheit sagen, dass der wahre Mittelwert zwischen 0,1 und 0,4 liegt.\n\n6. Wenn wir das Experiment immer wieder wiederholen w√ºrden, dann liegt der wahre Mittelwert in 95 % der F√§lle zwischen 0,1 und 0,4.\n\n\nAussagen 1-4 weisen den Hypothesen bzw. den Parametern eine Wahrscheinlichkeit zu, was im Frequentismus nicht erlaubt ist. Aussagen 5-6 spezifizieren die Grenzen des Sch√§tzintervalls, allerdings kann das Konfidenzintervall nur Aussagen zu den zugrundeliegenden Stichproben, nicht zum Sch√§tzintervall, machen.\n\n\nDie Ergebnisse zeigen, dass die Aussagen mehrheitlich *falsch* verstanden wurden, also mit \"stimmt\" angekreuzt wurden, s. @fig-ci-wrong.\n\n![Eine hohe Zustimmung zu den sechs falschen Aussagen](img/ci-wrong.png){#fig-ci-wrong width=75%}\n\n\n#### Bayes-Statistik\n\nDie zentrale Statistik der Bayes-Statistik ist die *Posteriori-Verteilung*.\n\nDie Posteriori-Verteilung beantwortet uns die Frage: \"Wie wahrscheinlich ist die Forschungshypothese (oder Varianten von ihr), jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?\"\n\n\nIn der Bayes-Statistik sind Aussagen folgender Art erlaubt:\n\n>    Mit einer Wahrscheinlichkeit von 95% ist der neue Webshop besser als der alte.\n>    Mit einer Wahrscheinlichkeit von 89% liegt die Wirksamkeit des neuen Medikaments zwischen 0.1 und 0.4.\n\n\n\n[In diesem Post](https://data-se.netlify.app/2022/01/27/warum-bayes/) wird f√ºr Bayes geworben und (einseitig) Stellung pro Bayes bezogen.\n\n\n\n### Frequentist und Bayesianer\n\n\nIm Cartoon 1132 [von xkcd](https://xkcd.com/) wird sich √ºber das Nicht-Ber√ºcksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. @fig-xkcd-bayes.\n\n![Frequentist wettet mit Bayesianer](img/frequentists_vs_bayesians_2x.png){#fig-xkcd-bayes width=50%}\n\n[Quelle](https://xkcd.com/1132/)\n\n\n\n\n\n\n<div>\n\n<a href=\"https://imgflip.com/memegenerator\">from Imgflip Meme Generator</a>\n\n</div>\n\n### Beispiel zum Nutzen von Apriori-Wissen 1\n\nEin Betrunkener behauptet, er k√∂nne hellsehen.\nEr wirft eine M√ºnze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering ($2^{-10}$) unter der Hypothese, dass die M√ºnze fair ist, dass Ergebnis also \"zuf√§llig\" ist, also $p < .05$ und damit ist das Ergebnis \"statistisch signifikant\".\n\nUnser Vorwissen l√§sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zuf√§lligkeit des Ergebnisses wohl nicht verwerfen.\n\n### Beispiel zum Nutzen von Apriori-Wissen 2\n\nEine Studie [@gelman_regression_2021] fand einen \"gro√üen Effekt\" auf das Einkommen von Babies, die eine Stunde pro Woche w√§hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), $n=127$.\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% h√∂her (als in der Kontrollgruppe) mit einem Konfidenzintervall von \\[+2%,+98%\\].\n\nAllerdings l√§sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln l√§sst. Wir w√ºrden den Effekt lieber in einem konservativeren Intervall sch√§tzen (enger um Null).\n\n\n\n\n\n\n\n\n## Fazit\n\n\n\n:::callout-important\n[Kontinuierliches Lernen](https://imgflip.com/i/77wn7m) ist der Schl√ºssel zum Erfolg.\n:::\n\n\n\n\n## Aufgaben\n\n\n1. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz/)\n2. [korr-als-regr](https://datenwerk.netlify.app/posts/korr-als-regr/korr-als-regr/)\n3. [ttest-als-regr](https://datenwerk.netlify.app/posts/ttest-als-regr/ttest-als-regr/)\n4. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau/)\n5. [adjustieren2a](https://datenwerk.netlify.app/posts/adjustieren2a/adjustieren2a/)\n6. [inferenz-fuer-alle](https://datenwerk.netlify.app/posts/inferenz-fuer-alle/inferenz-fuer-alle)\n7. [adjustieren1a](https://datenwerk.netlify.app/posts/adjustieren1a/adjustieren1a.html)\n8. [ungewiss-arten-regr](https://datenwerk.netlify.app/posts/ungewiss-arten-regr/ungewiss-arten-regr.html)\n9. [vorhersageintervall1](https://datenwerk.netlify.app/posts/vorhersageintervall1/vorhersageintervall1.html)\n10. [lm-standardfehler](https://datenwerk.netlify.app/posts/lm-standardfehler/lm-standardfehler)\n11. [punktschaetzer-reicht-nicht](https://datenwerk.netlify.app/posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html)\n12. [Warum-Bayes](https://datenwerk.netlify.app/posts/warum-bayes/warum-bayes)\n\n\n\n\n\n## ---\n\n\n\n![](img/outro-02.jpg){width=100%}\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}