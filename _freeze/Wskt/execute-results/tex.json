{
  "hash": "7ca87f7bc7bf4ef98f70588b9be11eb8",
  "result": {
    "markdown": "\n# Wahrscheinlichkeit\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Lernsteuerung\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.\n\nSie können ...\n\n\n- die Grundbegriffe der Wahrscheinlichkeitsrechnung erläuternd definieren\n- die drei Arten der direkten Ermittlung von Wahrscheinlichkeit erläutern\n- typische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\n- mit Wahrscheinlichkeiten rechnen\n\n\n\n### Prüfungsrelevanter Stoff\n\nLesen Sie dazu @bourier_2018, Kap. 2-4. Weitere Übungsaufgaben finden Sie im dazugehörigen Übungsbuch, @bourier_statistik-ubungen_2022.\n\n\n\n\n\n### Zentrale Begriffe\n\n\n#### Grundbegriffe\n\n- Zufallsvorgang (Zufallsexperiment)\n- Elementarereignis\n- Ereignisraum\n- Zufallsereignis (zufälliges Ereignis)\n- Sicheres Ereignis\n- Unmögliches Ereignis\n\n\n#### Wahrscheinlichkeitsbegriffe\n\n- Klassische Wahrscheinlichkeit (LaPlace'sche Wahrscheinlichkeit)\n- Statistische (empirische) Wahrscheinlichkeitsermittlung\n- Subjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n\n#### Wahrscheinlichkeitsrelationen\n\n- Vereinigung von Ereignissen\n- Schnitt(menge) von Ereignissen\n- Komplementärereignis\n- Vollständiges Ereignissystem\n- Kolmogorovs Definition von Wahrscheinlichkeit\n\n\n#### Wahrscheinlichkeitsrechnung\n\n- Allgemeiner Additionsssatz\n- Disjunkte Ereignisse\n- Additionssatz für disjunkte Ereignisse\n- Bedingte Wahrscheinlichkeit\n- (Stochastische) Unabhängigkeit\n- Baumdiagramm für gemeinsame Wahrscheinlichkeit\n- Allgemeiner Multiplikationssatz\n- Multiplikationssatz für unabhängige Ereignisse\n- Totale Wahrscheinlichkeit\n- Satz von Bayes\n\n\n### Begleitvideos\n\n\n- [Video zum Thema Wahrscheinlichkeit](https://youtu.be/rR6NspapEyo)\n\n\n\n\n## Unterstützung: Wahrscheinlichkeit in Bildern\n\nWahrscheinlichkeit in Bildern: zur einfachen Erschließung des Materials,\nein Unterstützungsangebot.\n\n\nIm Folgenden sind einige Schlüsselbegriffe und -regeln in (ver-)einfach(t)er Form schematisch bzw. visuell dargestellt mit dem Ziel, den Stoff einfacher zu erschließen.\n\n\n### Zufall\n\nWerfen Sie eine Münze!\n\nDiese hier zum Beispiel:\n\n![](img/1024px-Coin-155597.svg.png){width=10% fig-align=\"center\"}\n\n[Quelle: By OpenClipartVectors, CC0]( https://pixabay.com/pt/moeda-euro-europa-fran%C3%A7a-dinheiro-155597)\n\nWiederholen Sie den Versuch 10, nein, 100, nein 1000, nein: $10^6$ Mal.\n\nNotieren Sie das Ergebnis!\n\nOder probieren Sie die [App der Brown University](https://seeing-theory.brown.edu/basic-probability/index.html#section1).\n\n\n\n### Relationen von Mengen\n\nVenn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren.\n\n\n\n#### Überblick\n\nDie folgenden Diagramme stammen von [Wikipedia (En)](https://en.wikipedia.org/wiki/Venn_diagram).\n\nWir gehen von Ereignisraum $\\Omega$ aus, mit dem Ereignis $A$ als Teilmenge: $A \\subset B$.\n\n\n::: {#fig-sets layout-ncol=2}\n\n\n\n\n![$A \\cap B$](img/Venn0001.svg.png)\n\n\n\n\n![$A \\cup B$](img/Venn0111.svg.png)\n\n\n\n\n![$\\bar{A}$](img/2560px-Venn1010.svg.png)\n\n\n\n\n\n\n![$A \\setminus B$](img/Venn0100.svg.png){width=25%}\n\nTypische Mengenoperationen\n:::\n\n\n\n#### Disjunkte Ereignisse\n\n\n(Engl. disjoint events)\n\n$A= \\{1,2,3\\}; B= \\{4,5,6\\}$\n\n$A$ und $B$ sind disjunkt: ihre Schnittmenge ist leer: $A \\cap B = \\emptyset$,\ns. @fig-disjunkt.\n\n\n\n\n\n![](img/2880px-Disjunkte_Mengen.svg.png){#fig-disjunkt width=\"25%\" fig-align=\"center\"}\n\n\n\n\n\n#### Eselsbrücke zur Vereinigungs- und Schnittmenge\n\nDas Zeichen für eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen für einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine Eselbrücke gelesen, s. @fig-esel.\n\n![Eselsbrücke für Vereinigungs- und Schnittmenge](img/ven_cup_cap.jpeg){#fig-esel width=55%}\n\n[Quelle: rither.de](http://www.rither.de/a/mathematik/stochastik/mengentheorie-und-venn-diagramme/)\n\n\n#### Animationen\n\n\n[Animation zu Mengenoperationen](https://seeing-theory.brown.edu/compound-probability/index.html)\n\n\n\n[Animation zur Vereinigung von Mengen](https://www.geogebra.org/m/GEZV4xXc#material/cmXR8fHN)\n\n[Quelle](Geogebra, J. Merschhemke)\n\n\n### Additionssatz \n\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass *mindestens eines der Ereignisse* eintritt.\n\n#### Diskunkte Ereignisse\n\n$\\Omega = {1,2,3,4,5,6}$\n\n\n\n$\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}$\n\nGesucht sei die Wahrscheinlichkeit des Ereignis $A=\\{1,2\\}$.\n\n\n$\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}$\n\n$P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}$\n\n\n#### Allgemein (disjunkt oder nicht disjunkt)\n\n\nBei der Addition der Wahrscheinlichkeiten für $A$ und $B$ wird der Schnitt $A\\cap B$ doppelt erfasst. Er muss daher noch abgezogen werden (vgl. @fig-sets2):\n\n\n\n$$P(A \\cup B) = P(A) + P(B) - P(A\\cap B)$$\n\n\n\n::: {#fig-sets2 layout-ncol=2}\n\n![$A \\cup B$](img/Venn0111.svg.png){width=25%}\n\n\n\n\n![$A \\cap B$](img/Venn0001.svg.png){width=25%}\n\n\n\nDie Schnittmenge muss beim Vereinigen abgezogen werden,\ndamit sie nicht doppelt gezählt wird.\n\n\n:::\n\n\n\n### Bedingte Wahrscheinlichkeit\n\n\n#### Animation\n\n\nSchauen Sie sich mal diese [Wahnsinnsanimation von Victor Powell an](https://setosa.io/conditional/). Hammer!\n\n\n#### Schema\n\n\nAbb. @fig-schema-p illustriert gemeinsame Wahrscheinlichkeit, $P(A \\cap B) und bedingte Wahrscheinlichkeit, $P(A|B)$.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Illustration von gemeinsamer und bedingter Wahrscheinlichkeit](Wskt_files/figure-pdf/fig-schema-p-1.pdf){#fig-schema-p}\n:::\n:::\n\n\n\n\n\nBedingte Wahrscheinlichkeit ist vergleichbar zu Filtern einer Tabelle:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- \n  tibble::tribble(\n      ~id, ~A, ~B,\n      \"1\", 0L, 0L,\n      \"2\", 0L, 1L,\n      \"3\", 1L, 0L,\n      \"4\", 1L, 1L,\n  \"SUMME\", 2L, 2L\n  )\n```\n:::\n\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\n$P(A) = 2/4$\n\n$P(B) = 2/4$\n\n$P(A \\cap B) = 1/4$\n\n$P(A|B) = 1/2$\n\n\n\n\n\n\n### (Un-)Abhängigkeit\n\nStochastische Unabhängigkeit ist ein Spezialfall von Abhängigkeit: Es gibt sehr viele Ausprägungen für Abhängigkeit, aber nur eine für Unabhängigkeit.\nKönnen wir Unabhängigkeit nachweisen, haben wir also eine starke Aussage getätigt.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n*Abhängig*, s. @fig-abh, links: Überleben auf der Titanic ist offenbar *abhängig* von der Passagierklasse.\nAuf der anderen Seite: Das Ereignis *Überleben* auf der Titanic ist *un*abhängig vom Ereignis *Alter ist eine Primzahl*, s. @fig-abh, rechts.\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Abhängigkeit und Unabhängigkeit zweier Ereignisse](Wskt_files/figure-pdf/QM2-Thema1-WasistInferenz-31-1.pdf){width=100%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nZur Ab- bzw. Un-Abhängigkeit zweier Variablen, an Beispielen illustriert.\n\n\n\n\n:::{#exm-covid}\n\n## Zusammenhang von Covidsterblichkeit und Impfquote\n\n\nSind die Ereignisse *Tod durch Covid*  bzw. *Impfquote* ($A$) und *Land*^[hier mit den zwei Ausprägungen *DEU* und *USA*] ($B$) voneinander abhängig (Abb. @fig-covid1)?\n\n\n\n::: {.cell hash='Wskt_cache/pdf/fig-covid1_b6f9431db1713026c3ccd9591861af2a'}\n::: {.cell-output-display}\n![Impfquote und Sterblichkeit sind voneinander abhängig (bezogen auf Covid, auf Basis vorliegender Daten)](Wskt_files/figure-pdf/fig-covid1-1.pdf){#fig-covid1}\n:::\n:::\n\n\n\nJa, da in beiden Diagrammen gilt: $P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)$.\n\n\nDaten von [Our World in Data](https://ourworldindata.org/covid-deaths).\n\n\n:::\n\n\n\n\n\n\n\n\n### Multiplikationssatz\n\nDer Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass *alle Ereignisse* eintreten.\n\n\n#### Unabhängige Ereignisse\n\n\nWir werfen eine faire Münze *zwei* Mal (Abb. @fig-2muenzen).\n\n\n![Wir werfen 2 faire Münzen](img/muenz1.png){#fig-2muenzen}\n\nAbb. @fig-2muenzen zeigt ein *Baumdiagramm*. Jeder *Kasten* (Knoten) zeigt ein *Ergebnis.* \nDie Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom \"Start\" (schwarzer Kreis) \nführen zwei mögliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2.\nDie untersten Knoten nennt man auch *Blätter* (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen Münzwurfs.\nDer Weg vom Start zu einem bestimmten Blatt nennt man *Pfad*. \nDie Anzahl der Pfade entspricht der Anzahl der Blätter.\nIn diesen Diagramm gibt es vier Pfade (und Blätter).\n\n\n\n\n\n\n\n::: {.cell}\n\n```\n## # A tibble: 3 x 2\n##   Ereignis Pr             \n##   <chr>    <chr>          \n## 1 0K       1/2 * 1/2 = 1/4\n## 2 1K       1/4 + 1/4 = 1/2\n## 3 2K       1/2 * 1/2 = 1/4\n```\n:::\n\n\n\nWir werfen eine faire Münze *drei* Mal (Abb. @fig-3muenzen)\n\n![Wir werfen drei faire Münzen](img/muenz2.png){#fig-3muenzen}\n\n\n\n\n\n::: {.cell}\n\n```\n## # A tibble: 4 x 2\n##   Ereignis Pr                   \n##   <chr>    <chr>                \n## 1 0K       1/2 * 1/2 * 1/2 = 1/8\n## 2 1K       1/8 + 1/8 + 1/8 = 3/8\n## 3 2K       3 * 1/8 = 3/8        \n## 4 3K       1/2 * 1/2 * 1/2 = 1/8\n```\n:::\n\n\n\n\n\n\n$Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Unabhängige Ereignisse visualisiert](Wskt_files/figure-pdf/fig-unabh-e-1.pdf){#fig-unabh-e}\n:::\n:::\n\n\n\n\nAbb. @fig-unabh-e zeigt, dass gilt: $P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)$.\n\n\n#### Kalt und Regen\n\nVon @mcelreath_statistical_2020 stammt diese Verdeutlichung der gmeinsamen Wahrscheinlichkeit:\n\nWas ist die Wahrscheinlichkeit für *kalt ❄ und Regen ⛈️*?\n\nDie Wahrscheinlichkeit für kalt und Regen ist die Wahrscheinlichkeit von *Regen* ⛈, wenn's *kalt* ❄ ist mal die Wahrscheinlichkeit von *Kälte* ❄.\n\nEbenfalls gilt:\n\nDie Wahrscheinlichkeit für kalt und Regen ist die Wahrscheinlichkeit von *Kälte* ❄, wenn's *regnet* ⛈️ mal die Wahrscheinlichkeit von *Regen* ⛈️.\n\nDas Gesagte als Emoji-Gleichung:\n\n$P(❄️ und ⛈️) = P(⛈️ |❄️ ) \\cdot P(❄️) =  P(❄️ |⛈️ ) \\cdot P(⛈️) = P(⛈️ und  ❄️)$\n\n\n\nAllgemein:\n\n$P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)$\n\n\nMan kann also die \"Gleichung drehen\".\n\n#### Abhängige Ereignisse\n\n\n\nEin Baumdiagramm bietet sich zur Visualisierung abhängiger Ereignisse an, s. Abb. @fig-baum-abh. Für unabhängige Ereignisse übrigens auch.\n\n\nIn einer Urne befinden sich fünf Kugeln, von denen vier rot sind und eine blau ist.\n\nwie groß ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zurücklegen (*ZOZ*) *zwei rote Kugeln* gezogen werden [@bourier_2018], S. 47.\n\n\nHier ist unsere Urne:\n\n$$\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}$$\n\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. Abb. @fig-baum-abh.\n\n\n\n\n```{mermaid}\n%%| fig-cap: \"Baumdiagramm für ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abhängig ist vom 1. Zug.\"\n%%| label: fig-baum-abh\nflowchart LR\n  A[Start] -->|4/5|B[1. Zug: R]\n  A -->|1/5|C[1. Zug: B]\n  B -->|3/4|D[2. Zug: R]\n  B -->|1/4|E[2. Zug: B]\n  D --- H[Fazit: RR:  12/20]\n  E --- I[Fazit: RB: 4/20]\n  C -->|4/4|F[2. Zug: R]\n  C -->|0/4|G[2. Zug: B]\n  F --- J[Fazit: BR: 4/20]\n  G --- K[Fazit: BB: 0/20]\n```\n\n\n\n\n\nEs gilt also: $P(A\\cap B) = P(A) \\cdot P(B|A)$.\n\n\n\n### Totale Wahrscheinlichkeit\n\n\n\n\n@fig-tot-wskt zeigt das Baumdiagramm für die Aufgabe @bourier_2018, S. 56.\n\n\n\n```{mermaid}\n%%| fig-cap: Totale Wahrscheinlichkeit\n%%| label: fig-tot-wskt\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -->|0.1|C[A2]\n  A -->|0.3|D[A3]\n  B -->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n```\n\n\n\n\n\nGesucht ist die Wahrscheinlichkeit $P(B)$.\n\nDazu addieren wir die Warhscheinlichkeiten der relevanten Äste.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nW_total <- 0.6 * 0.05 + 0.1 * 0.02 + 0.3 * 0.04\nW_total\n## [1] 0.044\n```\n:::\n\n\n\nDie totale Wahrscheinlichkeit beträgt also $P(B) = 4.4\\%$.\n\nEinfacher noch ist es, wenn man anstelle von Wahrscheinlichkeiten absolute Häufigkeiten verwendet.\n\n\n### Bayes\n\n#### Bayes als Baum\n\nGesucht sei $P(A_1|B)$.\n\nFür Bayes' Formel setzt man die Wahrscheinlichkeit des  *günstigen* Ast zur Wahrscheinlichkeit aller relevanten Äste, $P(B)$.\n\nDer günstige Ast ist hier schwarz gedruckt, die übrigen Äste gestrichelt, s. @fig-tot-wskt2.\n\n\n\n```{mermaid}\n%%| fig-cap: Günstige Pfade\n%%| label: fig-tot-wskt2\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -.->|0.1|C[A2]\n  A -.->|0.3|D[A3]\n  B --->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -.->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -.->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n```\n\n\n\n\n\n$$P(A|B) = \\frac{P(A1 \\cap B)}{P(B)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68$$\n\n$P(A|B)$ beträgt also ca. 68%.\n\nZur Erinnerung: $P(B)$ ist die totale Wahrscheinlichkeit.\n\n\n## Bayes' Theorem\n\n### Bayes als bedingte Wahrscheinlichkeit\n\n\nBayes' Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:\n\n\n$P(A|B) = \\frac{\\overbrace{ P(A\\cap B)}^\\text{umformen}}{P(B)}$\n\n$P(A\\cap B)$ kann man  umformen, s. @eq-bayes1:\n\n$$P(A|B) =\\frac{P(A\\cap B)}{P(B)} = \\frac{P(B|A) \\cdot P(A)}{P(B)}$${#eq-bayes1}\n\nMan kann sich Bayes' Theorem  auch wie folgt herleiten:\n\n\n\n$P(A\\cap B) = P(B \\cap A) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)$\n\nDann lösen wir nach P$(A|B)$ auf:\n\n\n$P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(B)}$\n\n\n### Wozu wird Bayes in der Praxis genutzt?\n\n\nIn der Praxis nutzt man Bayes häufig, wenn man Daten zu einer Wirkung $W$ hat,\nund auf die Ursache $U$ zurückschließen möchte, sinngemäß:\n\n$W \\quad \\underrightarrow{Bayes} \\quad U$.\n\nDann kann man @eq-bayes1 so schreiben, s. @eq-bayes2:\n\n$$P(U|W) = \\frac{ P(U) \\cdot P(W|U) }{P(W)}$${#eq-bayes2}\n\nEine ähnliche Situation, die in der Praxis häufig ist,\ndass man Daten $D$ hat und auf die Wahrscheinlichkeit einer Hypothese $H$ schließen möchte, s. @eq-bayes3.\n\n$D \\quad \\underrightarrow{Bayes} \\quad H$.\n\n\n$$P(H|D) = \\frac{ P(H) \\cdot P(D|H) }{P(D)}$${#eq-bayes3}\n\n@eq-bayes3 fragt nach $P(H|D)$:\n\n>    Was ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (@eq-bayes3):\n\n>    Diese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der Plausibilität (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgründen dividiert man noch die totale Wahrscheinlichkeit der Daten über alle Hypothesen.\n\n\n### Zusammengesetzte Hypothesen\n\nDas ist vielleicht ein bisschen fancy,\naber man kann Bayes' Theorem auch nutzen, um die Wahrscheinlichkeit einer *zusammengesetzten Hypothese* zu berechnen: $H = H_1 \\cap H_2$. \nEin Beispiel wäre: \"Was ist die Wahrscheinlichkeit, dass es Regen ($R$) *und* Blitzeis ($B$) gibt, wenn es kalt ($K$) ist?\".\n\nDas sieht dann so aus, @eq-bayes4:\n\n$$\n\\begin{aligned}\nP(R \\cap B |K) &= \\frac{ P(R \\cap B) \\cdot P(K|R \\cap B) }{P(D)} \\\\\n&= \\frac{ P(R ) \\cdot P(B) \\cdot P(K|R \\cap B) }{P(D)}\n\\end{aligned}\n$${#eq-bayes4}\n\n\nHier haben wir $P(R \\cap B)$  aufgelöst in $P(R) \\cdot P(B)$,\ndas ist nur zulässig, wenn $R$ und $B$ unabhängig sind.\n\n#### Bayes-Video von 3b1b\n\nDas [Video zu Bayes von 3b1b](https://youtu.be/HZGCoVF3YvM) verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\n\n\n\n\n\n\n## Aufgaben\n\n\nZusätzlich zu den Aufgaben im Buch:\n\n- [mtcars-abhaengig](https://datenwerk.netlify.app/posts/mtcars-abhaengig/mtcars-abhaengig.html)\n- [voll-normal](https://datenwerk.netlify.app/posts/voll-normal/voll-normal.html)\n- [corona-blutgruppe](https://datenwerk.netlify.app/posts/corona-blutgruppe/corona-blutgruppe.html)\n- [Bed-Wskt2](https://datenwerk.netlify.app/posts/bed-wskt2/bed-wskt2)\n- [Gem-Wskt1](https://datenwerk.netlify.app/posts/gem-wskt1/gem-wskt1)\n- [wuerfel01](https://datenwerk.netlify.app/posts/wuerfel01/wuerfel01.html)\n- [wuerfel02](https://datenwerk.netlify.app/posts/wuerfel02/wuerfel02.html)\n- [wuerfel03](https://datenwerk.netlify.app/posts/wuerfel03/wuerfel03.html)\n- [wuerfel04](https://datenwerk.netlify.app/posts/wuerfel04/wuerfel04.html)\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}