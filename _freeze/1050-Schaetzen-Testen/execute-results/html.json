{
  "hash": "96cf9ee0c22ccb8af30da6bb16d06412",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n# Sch√§tzen vs. Testen\n\n\n\n## Lernsteuerung\n\n\n### Position im Modulverlauf\n\n@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen... \n\n- den Unterschied zwischen dem *Sch√§tzen* von Modellparametern und dem *Testen* von Hypothesen erl√§utern\n- Vor- und Nachteile des Sch√§tzens und Testens diskutieren\n- Das ROPE-Konzept erl√§utern und anwenden\n- Die G√ºte von Regressionsmodellen einsch√§tzen und berechnen\n\n\n### Begleitliteratur\n\nDer Stoff dieses Kapitels orientiert sich an [@kruschke_rejecting_2018].\n\n\n\n\n\n\n### R-Pakete\n\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n\n\n### Ben√∂tigte Daten\n\n\nWir ben√∂tigen in diesem Kapitel folgenden Datensatz:  `penguins`.\n\n\n\nSie k√∂nnen den Datensatz `penguins` entweder via dem Pfad importieren:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_url <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins <- read.csv(penguins_url)\n```\n:::\n\n{{< downloadthis data/penguins.csv dname=\"penguins.csv\" >}}\n\n\n\n\n\n\n\nOder via dem zugeh√∂rigen R-Paket:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"penguins\", package = \"palmerpenguins\")\n```\n:::\n\n\n\n\nBeide M√∂glichkeit sind okay.\n\n\n### Einstieg\n\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\n\n1. \"Lernen f√ºr die Klausur bringt etwas!\"\n2. \"Wie viel bringt Lernen f√ºr die Klausur?\"\n\n\n:::{#exm-schaetzen-testen}\nDiskutieren Sie die epistemologische Ausrichtung sowie m√∂gliches F√ºr und Wider der beiden Ausrichtungen! $\\square$\n:::\n\n\n\n## Sch√§tzen oder Testen?\n\n\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n1. *Hypothesen pr√ºfend*: \"Die Daten widerlegen die Hypothese (nicht)\"\n2. *Parameter sch√§tzend*: \"Der Effekt von X auf Y liegt zwischen A und B\".\n\n### Hypothesen pr√ºfen\n\nHypothesen pr√ºfende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann nat√ºrlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\n:::{#exm-lernen-hyp}\n### \"Lernen erh√∂ht den Pr√ºfungserfolg\"\nDie Hypothese *Lernen erh√∂ht den Pr√ºfungserfolg* kann durch eine Studie und eine entsprechende Analyse grunds√§tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts f√ºr den Klausurerfolg. 2) Die Daten unterst√ºtzen die Hypothese: Lernen erh√∂ht den Pr√ºfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Pr√ºfungserfolg m√∂glich. $\\square$\n:::\n\nDas Pr√ºfen einer Hypothese kann zu drei Arten von Ergebnissen f√ºhren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\n1. üü• Die Daten *widersprechen* der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubw√ºrdigkeit der Hypothese gelitten.\n\n2. üü¢ Die Daten *unterst√ºtzen* die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubw√ºrdigkeit gewonnen.\n\n3. ‚ùì Die Datenlage ist *unklar*; zum Teil unterst√ºtzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schl√ºsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\n\nHypothesen pr√ºfen ist *bin√§r* in dem Sinne, dass sie zu \"Schwarz-Wei√ü-Ergebnissen\" f√ºhren (sofern die Datenlage stark genug ist).\n\n:::{.callout-important}\nEine g√§ngige Variante des Hypothesen testen^[vor allem in der Frequentistischen Statistik]  ist das Testen der Hypothese \"kein Effekt\" (Null Effekt), man spricht vom *Nullhypothesen testen*. $\\square$\n:::\n\n:::{.exm-null}\n### Beispiele f√ºr Nullhypothesen\n\n- \"Lernen bringt nichts\"\n- \"Frauen und M√§nner parken gleich schnell ein\"\n- \"Es gibt keinen Zusammenhang von Babies und St√∂rchen\"\n- \"Fr√ºher war es auch nicht besser (sondern gleich gut)\"\n- \"Bei Frauen ist der Anteil, derer, die Statistik m√∂gen gleich hoch wie bei M√§nnern\" (Null Unterschied zwischen den Geschlechtern) $\\square$\n:::\n\n\n*Vorteil* des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterst√ºtzen kann, da es die Komplexit√§t reduziert.\n\n\n:::callout-note\n### Man kann Hypothesen nicht best√§tigen\nKarl Poppers These, dass man Hypothesen nicht best√§tigen (verifizieren) kann, hat gro√üen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausge√ºbt [@popper_logik_2013].\nSchlagend ist das Beispiel zur Hypothese \"Alle Schw√§ne sind wei√ü\". Auch eine gro√üe Stichprobe an wei√üen Schw√§nen kann die Wahrheit der Hypothese nicht beweisen. Schlie√ülich ist es m√∂glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben.^[Tats√§chlich gibt es schwarze Schw√§ne, aber nicht in Europa: https://en.wikipedia.org/wiki/Black_swan]\nUmgekehrt reicht die (zuverl√§ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). $\\square$\n:::\n\n\n:::{.callout-note}\n### Wirklich nicht?\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. \nKomplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht.\nDas bedeutet, dass Evidenz im best√§tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist.\nAuf dieser Basis und der Basis zuverl√§ssiger, repr√§sentativer Daten erscheint plausibel, dass Hypothesen sowohl best√§tigt als auch widerlegt werden k√∂nnen [@kruschke_rejecting_2018; @morey_bayes_2011]. $\\square$\n:::\n\n### Parameter sch√§tzen\n\nBeim Parameter sch√§tzen untersucht man, *wie gro√ü* ein Effekt ist, etwa der Zusammenhang zwischen X und Y.\nEs geht also um eine Skalierung, um ein *wieviel* und nicht um ein \"ja/nein\", was beim Hypothesen testen der Fall ist.\n\nBeim Parameter sch√§tzen gibt es zwei Varianten:\n\na) ‚ö´Ô∏è Punktsch√§tzung: Das Sch√§tzen eines einzelnen Parameterwerts, sozusagen ein \"Best Guess\"\n\nb) üìè Bereichssch√§tzung: Das Sch√§tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Parameter sch√§tzen auch wie einen Hypothesentest nutzen:\nIst ein bestimmter Wert, etwa die Null, nicht im Sch√§tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\n\n:::{#exm-param-hyptest}\n### Parametersch√§tzen als Nullhypothesentest\n\n>   Forschungsfrage: Sind m√§nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\n@eq-muf-mum formalisiert diese Forschungsfrage als statistische Hypothese $H$.\n\n$$H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0$${#eq-muf-mum}\n\nDer Unterschied zwischen den Mittelwerten, $d$, ist genau dann Null, wenn $\\beta_1$ in unserem Regressionsmodell `m1` gleich Null ist.\nEntsprechend gilt $d \\ge 0$ wenn $\\beta_1 \\ge 0$.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n```\n:::\n\n\n\n\nDann z√§hlen wir einfach den Anteil der Stichproben in der Post-Verteilung f√ºr die UV `sexmale`, die einen Wert gr√∂√üer Null aufweisen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_post <-\n  m1 |> \n  as_tibble()\n\nm1_post |> \n  count(sexmale < 0)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"sexmale < 0\"],\"name\":[1],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"FALSE\",\"2\":\"4000\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert gr√∂√üer Null f√ºr `sexmale`, dass also weibliche Tiere leichter bzw. m√§nnliche Tiere schwerer sind.\nEntsprechend finden 0% der Stichproben einen Wert, der f√ºr das Gegenteil spricht (das weibliche Tiere schwerer w√§ren).\nDamit res√ºmieren wir, dass unser Modell 100% Wahrscheinlichkeit f√ºr die Hypothese einr√§umt: $p_H = 1$. $\\square$\n:::\n\n\n\n*Vorteil* der Parametersch√§tzung ist die Nuanciertheit des Ergebnisses, die der Komplexit√§t echter Systeme besser Rechnung tr√§gt.\n\n\n\n\n\n## ROPE: Bereich von \"praktisch Null\"  {#sec-rope}\n\n\nüì∫ [Teil 2](https://youtu.be/k-CB0VGRENY)\n\n\n\n\nNullhypothesen sind fast immer falsch, s. @fig-nullmeme.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Du testest Nullhypothesen?](img/5v5531.jpg){#fig-nullmeme width=250}\n:::\n:::\n\n\n\n\n[Quelle: Imgflip Meme Generator](https://imgflip.com/i/5v5531)\n\n\n\n\n\n\n\n>   We do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have *some* effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. [@gelman_regression_2021]\n\n\n\n\n\n\n### Alternativen zu Nullhypothesen\n\n\nNullhypothesen, $H_0$, sind z.B.: $\\rho=0$, $\\rho_1 = \\rho_2$, $\\mu_1 = \\mu_2$, $\\mu=0$, $\\beta_1=0$.\nNullhypothesen zu testen, ist sehr verbreitet.\nEin Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest m√∂glich ist.^[Mittlerweile gibt es neue Frequentistische Ans√§tze f√ºr ein Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.]\n\nEin anderer Grund ist vermutlich, ... wir haben es schon immer so gemacht. ü§∑‚Äç‚ôÄÔ∏è\n\nAlternativen zum Testen von Nullhypothesen sind: \n  \n- Posteriori-Intervalle (PI oder HDI) berichten\n- *Rope*-Konzept [@kruschke_rejecting_2018]\n- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\n- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n\n\n\n\n\n### \"Praktisch\" kein Unterschied: Das Rope-Konzept\n\n\nüì∫ [ROPE-Video](https://www.youtube.com/watch?v=VweMjEBeQFg)\n\n\n:::{#exm-rope}\n### Beispiele f√ºr ROPE\nSagen wir, wenn sich zwei Preismittelwerte um h√∂chstens $d=100$‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als \"praktisch gleich\", \"praktisch kein Unterschied\" bzw. vernachl√§ssigbar.\n\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g \"vernachl√§ssigbar wenig\" ist.\n\nEine findige Gesch√§ftsfrau entscheidet f√ºr ihre Firma, dass ein Umssatzunterschied von 100k Euro \"praktisch irrelevant\" sei. $\\square$\n:::\n\n\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer *Nullhypothese*: $H_0$.\nDie Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte.\nDiesen Bereich bezeichnen wir den *Indifferenzbereich* (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder *Region of practical equivalence*, Rope). \nJetzt pr√ºfen wir, ob ein \"Gro√üteil\" der Posteriori-Stichproben im Rope liegt.\nUnter \"Gro√üteil\" wird h√§ufig das *95%-HDI* verstanden (das ist auch der Standard der R-Funktion `rope()`, die wir hier nutzen).\n\n\n\n\n\n\n\n*Entscheidungsregel* nach @kruschke_rejecting_2018:\n  \n- Gro√üteil liegt *innerhalb* von Rope  ‚û°Ô∏è *Annahme* der Nullhypothese \"praktisch kein Effekt\", $H_0$\n- Gro√üteil liegt *au√üerhalb* von Rope  ‚û°Ô∏è *Ablehnung* der Nullhypothese \"praktisch kein Effekt\", $H_0$\n- Ansonsten  ‚û°Ô∏è  keine Entscheidung \n\n\nMit \"Gro√üteil\" meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n### Vernachl√§ssigbarer Regressionseffekt\n\n@kruschke_rejecting_2018 schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als \"praktisch Null\" zu bezeichnen:\n\n\n\nWenn eine Ver√§nderung √ºber \"praktisch den ganzen Wertebereich\" von $x$ nur einen vernachl√§ssigbaren Effekt auf $y$ hat.\nEin vernachl√§ssigbarer Effekt ist dabei $\\hat{y}= \\pm 0.1 sd_y$.\nDer \"praktisch ganze Wertebereich\" von $x$ sei $\\bar{x} \\pm 2 sd_x$.\nResultiert der Vergleich von $\\bar{x} -2 sd$ mit $\\bar{x}+2sd$ nur eine Ver√§nderung in $\\hat{y}$ von $\\bar{y} - 0.1sd_y$ auf $\\bar{y} + 0.1 sd_y$, so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar.\nDas impliziert Rope-Grenzen von $\\beta_x = \\pm 0.05$ f√ºr z-standardisierte Variablen.\n\n:::{.callout-note}\n### ROPE-Defaults\nIm der Voreinstellung umfasst die Gr√∂√üe des ROPE ¬±5% der SD der AV. $\\square$\n:::\n\n\n\n### HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Die Entscheidungsregeln zum ROPE illustiert.](img/Kruschke-2018-Fig1.png){#fig-kruschke-rope fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n@fig-kruschke-rope illustriert die Entscheidungsregel zum ROPE \nf√ºr mehrere Situatioenen [@kruschke_rejecting_2018, Abbildung 1, S. 272]:\n  \n- Liegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.\n- Liegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\n- Ansonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.\n\n\n\n### Rope berechnen\n\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erkl√§rt (`m10.6`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6 <- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n```\n:::\n\n\n\n\nDen Rope berechnet man mit `rope(model)`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Parameter\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"CI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_low\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_high\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_Percentage\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Effects\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Component\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.95\",\"3\":\"-80.19545\",\"4\":\"80.19545\",\"5\":\"0.0000000\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"1\"},{\"1\":\"speciesChinstrap\",\"2\":\"0.95\",\"3\":\"-80.19545\",\"4\":\"80.19545\",\"5\":\"0.7584211\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"2\"},{\"1\":\"speciesGentoo\",\"2\":\"0.95\",\"3\":\"-80.19545\",\"4\":\"80.19545\",\"5\":\"0.0000000\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nDie Faktorstufe `Chinstrap` von `species` hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. \nWir k√∂nnen daher f√ºr diese Gruppe  das ROPE *nicht* verwerfen. \nDie Datenlage ist *unklar*. \nEs ist keine abschlie√üende Entscheidung √ºber die Hypothese m√∂glich.\n\nAber: `Gentoo` liegt zu 0% im Rope. F√ºr Gentoo k√∂nnen wir das Rope *verwerfen*.\n\n\n\n:::callout-note\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. `help(rope)`.\n:::\n  \n\nDas h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. üé®\n\n\n### Visualisierung unserer Rope-Werte, m10.6\n  \nEin Gro√üteil der Posteriori-Masse von `m10.6` liegt  *nicht* innerhalb des Rope. \nAber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut, s. @fig-rope-penguins.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6) %>% plot()\n```\n:::\n\n::: {#fig-rope-penguins .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Diagramm mit `rope(m10.6) %>% plot()`](1050-Schaetzen-Testen_files/figure-html/fig-rope-penguins-1.png){#fig-rope-penguins-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Diagramm mit `parameters(m10.6) %>% plot()`](1050-Schaetzen-Testen_files/figure-html/fig-rope-penguins-2.png){#fig-rope-penguins-2 width=672}\n:::\n\nRope und HDI √ºberlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n:::\n\n\n\n\n\nDas ROPE druchkreuzt die \"Berge\" der Posteriori-Verteilung f√ºr Chinstrap deutlich.\nAber: Das 95%-HDI liegt nicht komplett innerhalb des Rope.\nWir k√∂nnen das Nullhypothese f√ºr Chinstrap *nicht verwerfen*, aber auch *nicht best√§tigen*.\n\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, \nes ist weit entfernt vom \"blauen Fluss\" des Rope: Gentoo liegt au√üerhalb des Rope. \nEs gibt einen \"substanziellen\" Unterschied, gr√∂√üer als das ROPE. \nWir verwerfen die \"Praktisch-Null-Hypothese\" in diesem Fall.\n\n\n\n\n\n\n\n\n### Finetuning des Rope\n\nWir k√∂nnen festlegen, was wir unter \"praktischer √Ñquivalenz\" verstehen,\nalso die Grenzen des Ropes ver√§ndern.\nSagen wir, 100 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. @fig-rope-range.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n```\n\n::: {.cell-output-display}\n![ROPE mit selber eingestellter Grenze von ¬±100 (Gramm)](1050-Schaetzen-Testen_files/figure-html/fig-rope-range-1.png){#fig-rope-range width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:\n  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n```\n:::\n\n\n\n\n`ETI` (equal tails interval) steht f√ºr ein PI.\nJetzt wird berichtet, welcher Teil eines 89%-CI^[89 ist die n√§chst kleinste Primzahl unter 95; und 95 wird gemeinhin als Grenzwert f√ºr Sch√§tzbereiche verwendet. Damit ist 95 hier eine \"magic number\", ein Defacto-Standard ohne hinreichende Begr√ºndung. Um darauf hinzuweisen, benutzen einige Forschis mit √§hem subtilen Humor lieber die 89 als die 95. ü§∑‚Äç‚ôÇÔ∏è ] sich im Rope befindet.\n\n\n\n\n\n\n### Beantwortung der Forschungsfrage\n\n\nF√ºr die Spezeis *Gentoo* wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, *Adelie*, vom Modell entdeckt. F√ºr *Chinstrap* hingegen  ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.\n\n\n\n\n\n\n\n\n\n\n\n\n## Modellg√ºte \n\n\n\n\n<!-- ### Was ist ein kleiner, was ein gro√üer Effekt? -->\n\n<!-- @cohen_statistical_1988 definiert Effektst√§rken in Bezug auf Mittelwertsvergleiche anhand von $d=(\\mu_1 - \\mu_o) / \\sigma$. -->\n<!-- F√ºr kleine, mittlere und gro√üe Werte gab er folgende Richtwerte: -->\n\n<!-- - klein: $d \\approx 0.2$ -->\n<!-- - mittel: $d \\approx 0.5$ -->\n<!-- - gro√ü: $d \\approx 0.8$ -->\n\n<!-- Auf dieser Basis schl√§gt @kruschke_rejecting_2018 einen Rope von $\\pm0.1$ vor. -->\n<!-- F√§llt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als \"praktisch null\". -->\n<!-- Richtlinien f√ºr Effektst√§rken sind nur Notl√∂sungen, die durch  Sachverstand ersetzt werden sollen, wo immer m√∂glich. -->\n<!-- Man kann Effektst√§rken ineinander √ºberf√ºhren, s. [hier](https://www.escal.site/), z.B. von Korrelation (*r*) zu Cohens *d* oder $R^2$. -->\n\n\n\n\n\n\n\n\n\n\n\n\n### Wozu Modellg√ºte?\n\nHat man ein Modell aufgestellt und gepr√ºft und Ergebnisse erhalten, m√∂chte man wissen, wie belastbar diese Ergebnisse sind.\nEin Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellg√ºte. \nDiese Kennwerte zielen z.B. darauf ab, wie *pr√§zise* die Aussagen des Modells sind. \nJe pr√§ziser die Aussagen eines Modells, desto n√ºtzlicher ist es nat√ºrlich.\nBei einer Parametersch√§tzung erh√§lt man  auch Informationen zur Pr√§zision der Sch√§tzung:\nIst der Sch√§tzbereich schmal, so ist die Sch√§tzung pr√§zise (und vice versa).\nAllerdings k√∂nnte ein Modell aus mehreren Parametersch√§tzungen bestehen, die unterschiedlich pr√§zise sind. \nDa kann es helfen, eine zusammenfassen Beurteilung zur Pr√§zision, oder allgemeiner zur G√ºte des Modells, zu erhalten.\n\nIm Folgenden ist eine Kennzahl von mehreren gebr√§uchlichen und sinnvollen vorgestellt, $R^2$.\n\n\n### Modellg√ºte mit $R^2$ bestimmen\n\n\n\n$R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt.\n- H√∂here Wert von $R^2$ bedeuten, dass das Modell die Daten besser erkl√§rt.\n$R^2$ wird normalerweise auf Basis eines Punktsch√§tzers definiert.\nSolch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor.\nDaher ist es w√ºnschenswert, diese Information in $R^2$ einflie√üen zu lassen: *Bayes-R-Quadrat*.\n\n\n\n\n\n<!-- R^2_{Bayes} = \\frac{\\text{erkl√§rte Varianz}}{\\text{erk√§rte Varianz + Residualvarianz}} = \\frac{var_{fit}}{var_{fit}+var_{res}} -->\n  \n  <!-- - $var_{fit}$ ist die Varianz der vorhergesagten Sch√§tzwerte $\\hat{y}_i$. -->\n  \n\n\n<!-- ```{r echo = TRUE} -->\n<!-- r2(m10.6) -->\n<!-- ``` -->\n\n\nM√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen,\nso kann man sich die Posteriori-Verteilung von $R2$ ausgeben lassen, s. @fig-m106-r2.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6_r2 <-\n  m10.6 %>% \n  r2_posterior() %>% \n  as_tibble()\n\nhdi(m10.6_r2) %>% \n  plot()\n```\n\n::: {.cell-output-display}\n![Die Verteilung von R-Quadrat im Modell m10.6](1050-Schaetzen-Testen_files/figure-html/fig-m106-r2-1.png){#fig-m106-r2 width=672}\n:::\n:::\n\n\n\n\n\n\n\n### Definition vom \"klassischen\" $R^2$\n\n\n\n\nWie genau sind die Vorhersagen des Modells? $\\sigma$ (Vorhersagefehler) quantifiziert die Streuung der Residuen $r_i = y_i - X_i\\hat{\\beta}$, mit $\\hat{y}_i = X_i\\hat{\\beta}$. \nAnders gesagt: $\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}$.\nAnders gesagt gibt $\\sigma$ die \"typische\" Abweichung einer Beobachtung vom vorhergesagten Wert an.\nEs ist n√ºtzlich, $\\sigma$ in Bezug zu setzen zur Streuung der AV, $sd_y=s_y$:\n  $R^2 = 1- (\\hat{\\sigma}^2/s^2_y)$.\n$R2$ gibt damit den Anteil der vom Modell erkl√§rten Varianz, $V$, an.\nBerechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck √§quivalent zu:\n  $R^2=V_{i=1}^n \\hat{y}_i/s_y^2$\n  Die beiden obigen Ausdr√ºcke nehmen $\\hat{y}_i$ als fix (sicher) an und vernachl√§ssigen Ungewissheit; sie sind √ºbergewiss aus Bayes-Sicht.\n\n\n\n\n### Bayes' $R^2$\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellg√ºte miteinzubeziehen:\n  $\\text{Bayes }R^2 = \\frac{\\text{erk√§rte Varianz}}{\\text{Erkl√§rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}$.\n\n$V_{mod}$ ist die Varianz in der PPV mit $s = 1, \\ldots, S$ simulierten Stichproben, $V(\\hat{y}_i)$ und $V_{res}$ ist die Residualvarianz im Modell.\nF√ºr jede Stichprobe $s$ berechnet man die vorhergesagten Werte, $\\hat{y}_i^s$, die Residualvarianz $\\sigma^2_s$ und den Anteil der erkl√§rten Varianz:\n  $\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}$, vgl. \n@gelman_r-squared_2019, @gelman_regression_2021, Kap. 11.7.\n\n\n\n\n\n\n## Fazit\n\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorz√ºge der Parametersch√§tzung. \nM√∂chte man aber, um sich bestimmter bestehender Forschung anzun√§hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.\n\n\n## Aufgaben\n\n\n1. [Wskt-Schluckspecht](https://datenwerk.netlify.app/posts/wskt-schluckspecht/wskt-schluckspecht)\n2. [wskt-mtcars-1l](https://datenwerk.netlify.app/posts/wskt-mtcars-1l/wskt-mtcars-1l.html)\n2. [rope-regr](https://datenwerk.netlify.app/posts/rope-regr/rope-regr.html)\n3. [rope1](https://datenwerk.netlify.app/posts/rope1/rope1.html)\n3. [rope2](https://datenwerk.netlify.app/posts/rope2/rope2.html)\n3. [rope3](https://datenwerk.netlify.app/posts/rope3/rope3.html)\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}