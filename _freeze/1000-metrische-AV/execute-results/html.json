{
  "hash": "dc560feb54b37eb41212952d78bb64e4",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Fallbeispiele\n\n\n\n## Lernsteuerung\n\n\n### Position im Modulverlauf\n\n@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen... \n\n- typische, deskriptive Forschungsfragen spezifizieren als Regression\n- Forschungsfragen in Regressionsterme √ºbersetzen\n- typische Forschungsfragen auswerten\n\n\n### Begleitliteratur\n\nDer Stoff dieses Kapitels orientiert sich an @mcelreath_statistical_2020, Kap. 4.4 sowie @gelman_regression_2021, Kap. 7 und 10.\n\n\n\n### Vorbereitung im Eigenstudium\n\n- [Statistik1, Kap. \"Geradenmodelle 2\"](https://statistik1.netlify.app/090-regression2)\n\n\n\n\n### R-Pakete\n\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/unnamed-chunk-1_28d813fe2fe8e4391b90fb58f59e28eb'}\n\n```{.r .cell-code}\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n### Ben√∂tigte Daten\n\n\nWir ben√∂tigen in diesem Kapitel folgende Datens√§tze: `kidiq`, `penguins`.\n\n#### `kidiq`\n\nDen Datensatz `kidiq` importieren Sie am einfachsten aus dem R-Paket `rstanarm`, das Sie schon installiert haben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"kidiq\", package = \"rstanarm\")\n```\n:::\n\n\nAlternativ k√∂nnen Sie die Daten [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/kidiq.csv) herunterladen.\n\n\n{{< downloadthis data/kidiq.csv dname=\"kidiq.csv\" >}}\n\n\n\n\n#### `penguins`\n\nSie k√∂nnen den Datensatz `penguins` entweder via dem Pfad importieren:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_url <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins <- read.csv(penguins_url)\n```\n:::\n\n{{< downloadthis data/penguins.csv dname=\"penguins.csv\" >}}\n\n\n\n\nOder via dem zugeh√∂rigen R-Paket:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"penguins\", package = \"palmerpenguins\")\n```\n:::\n\n\nBeide M√∂glichkeit sind okay.\n\n\n### Einstieg\n\n\n:::{#exm-skalenniveaus}\n### Was waren noch mal die Skalenniveaus?\nUm Forschungsfragen zu klassifizieren, m√ºssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.^[Hier ist eine kurze Erkl√§rung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablen]\n$\\square$\n:::\n\n:::{#exm-interaktion}\n### Was war noch einmal die Interaktion?\nErk√§ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!^[Hier finden Sie eine kurze Erkl√§rung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktion] $\\square$\n:::\n\n\n### √úberblick\n\nWenn Sie die Skalenniveaus wissen, k√∂nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren.\nWir werden hier viele der typischen Forschungsfragen (aus psychologischen und √§hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil,\ndass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, ...) lernen m√ºssen.\nAu√üerdem ist die Regressionsanalyse (f√ºr viele Situationen) die beste Heransgehensweise, da sie viele M√∂glichkeiten f√ºr Erweiterungen bietet.\nEntsperchend ist das Thema dieses Kapitels g√§ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen.\nWenn Sie die Grundkonzepte der Regression schon kennen,\nwird Ihnen vieles sehr bekannt vorkommen.\nNat√ºrlich w√ºrzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-K√ºche.\nAllerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.\n\n\n\n\n## Arten von Forschungsfragen\n\n\n### Nach dem Erkenntnisziel\n\nüìÑ  *Deskriptiv* (beschreibend)\n\n- Wie stark ist der (lineare) Zusammenhang $r$ von Gr√∂√üe und Gewicht?\n- Wie stark ist der (lineare) Zusammenhang $b$ von Lernzeit und Note?\n- Bevorzugen unsere Kunden Webshop A oder B?\n\n\n\nüîÆ *Pr√§diktiv* (prognostisch, vorhersagend)\n\n- Wie schwer ist ein deutscher Mann der Gr√∂√üe 1,80m im Schnitt?\n- Welche Note kann man erwarten, wenn man nichts f√ºr die Klausur lernt?\n- Wie viel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufh√§lt?\n\n\n\nüîó *Pr√§skriptiv* (erkl√§rend, kausal)\n\n- Ist Gr√∂√üe eine Ursache von Gewicht (bei deutschen M√§nnern)?\n- Wenn ich 100 Stunden lerne, welche Note schreibe ich dann?\n- Hat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n:::callout-note\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erkl√§rend.\nAnhand der verwendeten statistischen Methode (z.B. Regressionsanalyse)\nkann man *nicht* feststellen, zu welchem Erkenntnisziel die Studie geh√∂rt.\n:::\n\n\n### Nach dem Skalenniveau\n\n\n\n\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit *metrischer* AV. Andere Skalenniveaus bei der AV klammern wir aus.\n\nF√ºr die UV(s) sind nominale und metrische Skalenniveaus erlaubt. \nModelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.\n\n\n### Varianten von Forschungsfragen\n\nIm Folgenden sind beispielhafte, h√§ufig verwendete Arten von Forschungsfragen aufgef√ºhrt.\nF√ºr jede Variante ist ein Beispiel, die Modellformel, der Kausalgraph^[auch DAG genannt, s. @sec-kausal], die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\n\n\nDabei wird folgende Nomenklatur verwendet, um die Skalenmniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\n- `y`: metrische abh√§ngige Variable\n- `g`: Gruppierungsvariable; nominal skalierter unabh√§ngige Variable (querschnittlich)\n- `b`: bin√§re Variable\n- `x`: metrische unabh√§ngige Variable\n- `u`: ungemessene Variable\n\n\n\n## `y ~ b`\n\n\n\n\n\n### Forschungsfrage\n\n*Hintergrund:*\n\nEine Psychologin, die im √∂ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufw√§ndigen Studie die Intelligenz vieler Kinder gemessen. Zus√§tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, \"Risikofaktoren\" f√ºr geringere Intelligenz zu entdecken.\n\n\n\n\n*Forschungsfrage:* \n\n\n>    Unterscheidet sich der mittlere IQ-Wert (`kid_score`) von Kindern in Abh√§ngigkeit davon, ob ihre jeweilige Mutter √ºber einen Schlusabschluss (`mom_hs`, $x=1$) verf√ºgt (bzw. nicht, $x=0$)? (ceteris paribus)^[H√§ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - \"gr√∂√üer als/kleiner als\" - zu formulieren, anstelle der hier verwendeteten \"empirisch √§rmeren\" einfachen, ungerichteten Ungleichheit. Sch√∂ner w√§re nat√ºrlich noch pr√§ziser als \"Ich erwarte einen gr√∂√üeren Wert\", also z.B. \"Ich erwarte einen Wert von 42!\"].\n\n\nDie Modellformel zur Forschungsfrage lautet: `y ~  b` bzw. `kid_iq ~ mom_hs`.\n\nFormaler ausgedr√ºckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (@eq-fofra1):\n\n\n$$\\mu_{x=1|\\alpha, \\beta, \\sigma} \\ne \\mu_{x=0|\\alpha, \\beta, \\sigma}$${#eq-fofra1}\n\n\nDie Modellformel zur Forschungsfrage lautet: `y ~ b` bzw. `kid_iq ~ mom_hs`.\n\n\nDer Kausalgraph zur Modellformel sieht aus in @fig-binuv dargestellt.\nY hat, laut unserem Modell, drei Ursachen:\n\n- b\n- x\n- u, das steht f√ºr \"unbekannt\"^[unknown, sozusagen der unbekannte Gott, also f√ºr alle sonstigen Einfl√ºsse; man kann das \"u\" ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgef√ºhrt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es g√§be keine anderen Einfl√ºsse als `mom_hs` auf die IQ des Kindes.]\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![DAG f√ºr `kid_iq ~ mom_hs`](1000-metrische-AV_files/figure-html/fig-binuv-1.png){#fig-binuv width=100%}\n:::\n:::\n\n\n\n\n\n### IQ von Kindern, bin√§rer Pr√§diktor\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-1_e70d3b630b58ea4245a1f0bfe48fa779'}\n\n```{.r .cell-code}\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 <- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n```\n:::\n\n\n\n\nMit `parameters(m10.1)` bekommt man die Parameter des Modells, s. @tbl-m101.\n\n\n\n::: {#tbl-m101 .cell tbl-cap='Parameter des Modells m10.1 (sigma ist nicht dargestellt)' hash='1000-metrische-AV_cache/html/tbl-m101_9cc079c3da0ec8262c54969d2a23047a'}\n::: {.cell-output-display}\n\n\n|Parameter   | Median |         95% CI |   pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:----:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  77.56 | (73.28, 81.64) | 100% | 1.001 | 3917.00 | Normal (86.80 +- 51.03) |\n|mom_hs      |  11.80 |  (7.18, 16.48) | 100% | 1.001 | 3789.00 | Normal (0.00 +- 124.21) |\n\n\n:::\n:::\n\n\nIn @fig-momkid ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_expectation(m10.1) %>% plot()\n```\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-momkid_cf140d79a9dbef910b8dce4b2a12c998'}\n::: {.cell-output-display}\n![Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen, haben im Mittel einen h√∂heren Intelligenztestwert, laut dem vorliegenden Modell](1000-metrische-AV_files/figure-html/fig-momkid-1.png){#fig-momkid width=672}\n:::\n:::\n\n\n\n### Interpretation von `m10.1`\n\n`m10.1: kid_score = 78 + 12*mom_hs + error`\n\nDer *Achsensabschnitt* (intercept, $\\beta_0$ oder auch mit $\\alpha$ bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren M√ºtter √ºber keinen Schulabschluss (`mom_hs = 0`) verf√ºgen:\n\n`kid_score = 78 + 0*12 + error`\n\nDas *Regressionsgewicht* (slope, $\\beta_1$, $\\beta$) ist der Unterschied im IQ-Wert von Kindern mit M√ºtter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit M√ºtter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\n`kid_score = 78 + 1*12 + error = 90 + error`\n\nDer Wert von `error` zeigt, wie genau die Sch√§tzung (Vorhersage) ist bzw. wie stark Pr√§diktor (UV) und Kriterium (AV) zusammenh√§ngen.\n\n\n`error` entspricht dem Vorhersagefehler, also dem Unterschied vom tats√§chlichen IQ-Wert des Kindes ($y$) zum vom Modell vorhergesagten Wert ($\\hat{y}$).\n\n\n### `m10.1` als Mittelwertsdifferenz \n\n\n- UV: bin√§r (zweistufig nominal/kategorial)\n- AV: metrisch (quantitativ)\n\n\n>    üë®‚Äçüè´ Hey R-Golem! Nimm den Datensatz `kidiq`, gruppiere nach `mom_hs` und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll hei√üen `kid_score_avg`.  An die Arbeit!\n\n>    ü§ñ Loving it!\n\n\n:::{.panel-tabset}\n\n### R-Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  group_by(mom_hs) %>% \n  summarise(kid_score_avg = \n              mean(kid_score))\n```\n:::\n\n\n### Ausgabe\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|mom_hs | kid_score_avg|\n|:------|-------------:|\n|0      |         77.55|\n|1      |         89.32|\n\n\n:::\n:::\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von M√ºttern mit Abschluss. \n:::\n\n\n\n\n### t-Test\n\nIn der *frequentistischen* Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation - Mittelwertsdifferenz zwischen zwei Gruppen - mit einem *t-Test*.\n\nDer t-Test ist ein inferenzstatistisches Verfahren, das pr√ºft, ob die Mittelwertsdifferenz (in der Population) $\\mu_d$ Null ist: $\\mu_d = 0$.^[Genauer gesagt wird gepr√ºft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.]\nIn der Bayes-Statistik betrachtet man dazu stattdessen z.B. die Posteriori-Verteilung (z.B. mit 95%PI).\n\n\n\n\n\n\n\n### Antwort auf die Forschungsfrage, `m10.1`\n\nBetrachten wir die Ergebnisse von `m10.1`.\n\n:::{.panel-tabset}\n\n### R-Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.1_post <-\n  m10.1 %>% \n  as_tibble() \n\nnames(m10.1_post) <- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # sch√∂nere Namen\n```\n:::\n\n\n### Ausgabe\n\nHier sind die ersten paar Zeilen, s. @tbl-m101post.\n\n\n\n::: {#tbl-m101post .cell tbl-cap='m10.1, Postverteilung, ersten paar Zeilen'}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"przcqcjssw\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#przcqcjssw table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#przcqcjssw thead, #przcqcjssw tbody, #przcqcjssw tfoot, #przcqcjssw tr, #przcqcjssw td, #przcqcjssw th {\n  border-style: none;\n}\n\n#przcqcjssw p {\n  margin: 0;\n  padding: 0;\n}\n\n#przcqcjssw .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#przcqcjssw .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#przcqcjssw .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#przcqcjssw .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#przcqcjssw .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#przcqcjssw .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#przcqcjssw .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#przcqcjssw .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#przcqcjssw .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#przcqcjssw .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#przcqcjssw .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#przcqcjssw .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#przcqcjssw .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#przcqcjssw .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#przcqcjssw .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#przcqcjssw .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#przcqcjssw .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#przcqcjssw .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#przcqcjssw .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#przcqcjssw .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#przcqcjssw .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#przcqcjssw .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#przcqcjssw .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#przcqcjssw .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#przcqcjssw .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#przcqcjssw .gt_left {\n  text-align: left;\n}\n\n#przcqcjssw .gt_center {\n  text-align: center;\n}\n\n#przcqcjssw .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#przcqcjssw .gt_font_normal {\n  font-weight: normal;\n}\n\n#przcqcjssw .gt_font_bold {\n  font-weight: bold;\n}\n\n#przcqcjssw .gt_font_italic {\n  font-style: italic;\n}\n\n#przcqcjssw .gt_super {\n  font-size: 65%;\n}\n\n#przcqcjssw .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#przcqcjssw .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#przcqcjssw .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#przcqcjssw .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#przcqcjssw .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#przcqcjssw .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#przcqcjssw .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"3\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Stichprobe aus der Post-Verteilung</td>\n    </tr>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Achsenabschnitt\">Achsenabschnitt</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"momhs\">momhs</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"sigma\">sigma</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Achsenabschnitt\" class=\"gt_row gt_right\">75.9</td>\n<td headers=\"momhs\" class=\"gt_row gt_right\">11.5</td>\n<td headers=\"sigma\" class=\"gt_row gt_right\">19.3</td></tr>\n    <tr><td headers=\"Achsenabschnitt\" class=\"gt_row gt_right\">78.6</td>\n<td headers=\"momhs\" class=\"gt_row gt_right\">10.8</td>\n<td headers=\"sigma\" class=\"gt_row gt_right\">21.2</td></tr>\n    <tr><td headers=\"Achsenabschnitt\" class=\"gt_row gt_right\">79.0</td>\n<td headers=\"momhs\" class=\"gt_row gt_right\">10.2</td>\n<td headers=\"sigma\" class=\"gt_row gt_right\">18.7</td></tr>\n    <tr><td headers=\"Achsenabschnitt\" class=\"gt_row gt_right\">79.1</td>\n<td headers=\"momhs\" class=\"gt_row gt_right\">9.5</td>\n<td headers=\"sigma\" class=\"gt_row gt_right\">19.8</td></tr>\n    <tr><td headers=\"Achsenabschnitt\" class=\"gt_row gt_right\">80.3</td>\n<td headers=\"momhs\" class=\"gt_row gt_right\">8.5</td>\n<td headers=\"sigma\" class=\"gt_row gt_right\">19.8</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n:::\n\n\n\n\nBerechnen wir ein 95%-PI von Hand:^[komfortabler geht es mit `eti(m10.1)`.]\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/unnamed-chunk-7_134571c0cc8b9045ca8e95a4d72c1918'}\n\n```{.r .cell-code}\npi_mom_hs <-\n  m10.1_post %>% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"pi_95\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"7.177759\"},{\"1\":\"16.482883\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen \nKindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, \nlaut unserem Modell: $95\\%PI: [7,16]$.\nDie Hypothese, dass es keinen  Unterschied oder einen Unterschied in die andere Richtung geben sollte, \nist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\n\nVisualisieren wir abschlie√üend die Posteriori-Verteilung, s. @fig-m101hdi.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m101hdi_ba53fa02d2d751b09fd1c85a76c142c6'}\n\n```{.r .cell-code}\nplot(eti(m10.1))\n```\n\n::: {.cell-output-display}\n![Das 95% ETI zum (statistischen) Effekt des m√ºtterlichen Schulabschlusses](1000-metrische-AV_files/figure-html/fig-m101hdi-1.png){#fig-m101hdi width=672}\n:::\n:::\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation.\nVon einem \"Effekt\" zu sprechen,\nl√§sst in den meisten K√∂pfen wohl die Assoziation zu einem *kausalen* Effekt\nentstehen. \nEin Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung,\ndie mehr Fundierung bedarf als eine einfache Korrelation bzw. ein\n einfacher Zusammenhang.\n \n\n\n<!-- ### Variante zur Forschungsfrage -->\n\n\n<!-- Unsere Psychologin k√∂nnte auch folgende Hypothese formulieren: -->\n\n<!-- >    Die Wahrscheinlichkeit f√ºr ein Kind mit IQ-Testwerten (y) von √ºber 100 Punkten ist h√∂her, wenn die Mutter √ºber einen Schulabschluss verf√ºgt. -->\n\n\n<!-- Pr√§ziser formuliert: -->\n\n\n<!-- $$Pr(y > 100|x=1, \\alpha, \\beta, \\sigma) > Pr(y > 100|x=0, \\alpha, \\beta, \\sigma)$$ -->\n\n<!-- Der vertikale Balken \"|\" liest sich als \"gegeben, dass\".  -->\n<!-- Hier wird auf die Wahrscheinlichkeit f√ºr ein Testergebnis $y>100$, -->\n<!-- *gegeben, dass* die Mutter √ºber einen Schulabschluss verf√ºgt ($x=1$)  -->\n<!-- und gegeben der Modellparameter $\\alpha, \\beta, \\sigma$. -->\n\n\n\n### Toleranzbereich\n\nBerechnet man ein Regressionsmodell mit `stan_glm` (ü§ñüòÅ), dann zieht man dabei Zufallszahlen üé≤.\nDer Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zuf√§llig.\nDas erkl√§rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels `stan_glm` von denen in diesem Buch abweichen k√∂nnen.\n\nUm zu pr√ºfen, ob Ihre Ergebnisse \"√§hnlich genug\" oder \"innerhalb eines Toleranzbereichs\" sind, kann man die Funktion `is_in_tolerance()` aus dem R-Paket `prada` nutzen.\n\n:::{.callout-note}\nGr√∂√üe des Toleranzbereichs\nDie Gr√∂√üe des *relativen Toleranzbereichs* ist auf 5% festgelegt.\nDas hei√üt, ein Unterschied von 5% zwischen einem Referenzwert (dem \"wahren\" Wert) und Ihrem Wert ist *okay*, also im Toleranzbereich.\nAu√üerdem gibt es noch einen *absoluten Toleranzbereich*, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen).\nDer *gr√∂√üere* der beiden Werte gilt. $\\square$\n:::\n\nZuerst m√ºssen Sie das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN), das geht z.B. so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(remotes)  # dieses Paket k√∂nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\n```\n:::\n\n\nDann starten Sie es wie gewohnt:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(prada)\n```\n:::\n\n\n\nDann testen Sie, ob Ihr Modellparameter, z.B. $\\beta_1$ innerhalb eines Toleranzbereichs liegt.\n\nSagen wir der \"richtige\" oder \"wahre\" Wert (oder schlicht der Wert einer Musterl√∂sung) f√ºr $\\beta_0$ ist `77`. Unser Wert sei `77.56`.\nLiegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n```\n:::\n\n\nJa, unser Wert ist *innerhalb* des Toleranzbereichs. ‚úÖ \n\n## `y ~ x + b`\n\n\n\n\n### Forschungsfrage\n\n\n>    Wie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (`mom_hs`) und  IQ der Mutter (`mom_iq`)  auf den IQ des Kindes (`kid_score`) ?\n\n\n\nDie Modellformel zur Forschungsfrage lautet: `y ~ x + b` bzw. `kid_score ~ mom_iq + mom_hs`.\n\n\nDer Kausalgraph^[DAG, s. @sec-kausal] zur Modellformel sieht aus in @fig-yxb dargestellt.\nLaut unserem Modell ist `y` also eine Funktion zweier (kausaler) Einfl√ºsse, `b` und `u`, wobei `u` f√ºr \"unbekannt\" steht, also f√ºr alle sonstigen Einfl√ºsse.^[Dabei nehmen wir an, dass `x` und `u` nicht voneinander abh√§ngen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.]\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![DAG f√ºr `y ~ b`](1000-metrische-AV_files/figure-html/fig-yxb-1.png){#fig-yxb width=100%}\n:::\n:::\n\n\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle @tbl-kidiq1 dargestellt.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/Thema6-Teil2-1_12a203b98bd4b849ee54088f8cc303b8'}\n\n```{.r .cell-code}\ndata(\"kidiq\")  # Paket rstanarm, alternativ √ºber CSV einlesen\ndescribe_distribution(kidiq)\n```\n:::\n\n::: {#tbl-kidiq1 .cell tbl-cap='Variablen und ihre Verteilung im Datenatz kidiq' hash='1000-metrische-AV_cache/html/tbl-kidiq1_fd95c0eff343a31e3fa3daa10a416d4c'}\n::: {.cell-output-display}\n\n\n|Variable  |   Mean |    SD |   IQR |           Range | Skewness | Kurtosis |   n | n_Missing |\n|:---------|:------:|:-----:|:-----:|:---------------:|:--------:|:--------:|:---:|:---------:|\n|kid_score |  86.80 | 20.41 | 28.00 | (20.00, 144.00) |    -0.46 |    -0.16 | 434 |         0 |\n|mom_hs    |   0.79 |  0.41 |  0.00 |    (0.00, 1.00) |    -1.40 |    -0.05 | 434 |         0 |\n|mom_iq    | 100.00 | 15.00 | 21.67 | (71.04, 138.89) |     0.47 |    -0.57 | 434 |         0 |\n|mom_age   |  22.79 |  2.70 |  4.00 |  (17.00, 29.00) |     0.18 |    -0.63 | 434 |         0 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n### 1 metrischer Pr√§diktor\n\n\nBerechnen wir folgendes Modell: `kid_score ~ mom_iq` (`m10.2`), s. Tab. @tbl-m102.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/Thema6-Teil2-3_46d6428161b521028ba5cdb513620ffb'}\n\n```{.r .cell-code}\nm10.2 <-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %>% \n  parameters()\n```\n:::\n\n::: {#tbl-m102 .cell tbl-cap='Parameter des Modells m10.2' hash='1000-metrische-AV_cache/html/tbl-m102_8068aa0c73c8a6595cb8ab80acd1fc31'}\n::: {.cell-output-display}\n\n\n|Parameter   | Median |         95% CI |   pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:----:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  25.78 | (14.04, 36.99) | 100% | 1.000 | 3518.00 | Normal (86.80 +- 51.03) |\n|mom_iq      |   0.61 |   (0.50, 0.73) | 100% | 1.000 | 3486.00 |   Normal (0.00 +- 3.40) |\n\n\n:::\n:::\n\n\n\n`kid_score = 26 + 0.6 * mom_iq + error`\n\n\n\n\n:::{.panel-tabset}\n\n\n### mit `ggplot2`\n\nVisualisieren wir uns noch das Modell m10.2, s. @fig-kidiqmomiq.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-kidiqmomiq_4bd92b89263560f2eaa8aa2c276cff29'}\n\n```{.r .cell-code}\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n```\n\n::: {.cell-output-display}\n![Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)](1000-metrische-AV_files/figure-html/fig-kidiqmomiq-1.png){#fig-kidiqmomiq width=672}\n:::\n:::\n\n\n### Mit `easystats`\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets `easystats`, s. @fig-m102-a.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m102-a_84dc34d6977ccc7ee78a5d25a17d4125'}\n\n```{.r .cell-code}\nplot(estimate_expectation(m10.2))\n```\n\n::: {.cell-output-display}\n![Die gesch√§tzten Erwartungswerte von m10.2 visualisiert](1000-metrische-AV_files/figure-html/fig-m102-a-1.png){#fig-m102-a width=672}\n:::\n:::\n\n\n:::\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder f√ºr verschiedene IQ-Werte der M√ºtter.\nVergleicht man Teilpopulationen von M√ºttern mit mittleren Unterschied von einem IQ-Punkt, \nso findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern *im Durchschnitt*, laut dem Modell m10.2.\nDer Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n\n\n\n\n\n### Beide Pr√§diktoren, `m10.3`\n\n\nBerechnen wir als n√§chstes ein Modell mit beiden Pr√§diktoren: `kid_score ~ mom_hs + mom_iq`, s. @tbl-m103.\n\n    \n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-3_d671b1d2c7190ab9ad98f3986a0e68a5'}\n\n```{.r .cell-code}\nm10.3 <- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n```\n:::\n\n::: {#tbl-m103 .cell tbl-cap='Parameter des Modells m10.3 (ohne sigma)' hash='1000-metrische-AV_cache/html/tbl-m103_74f957776a830b7afb5fdfe8dc47ad92'}\n::: {.cell-output-display}\n\n\n|Parameter   | Median |         95% CI |     pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:------:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  25.74 | (13.87, 36.76) |   100% | 1.001 | 3961.00 | Normal (86.80 +- 51.03) |\n|mom_iq      |   0.57 |   (0.45, 0.69) |   100% | 1.001 | 3456.00 |   Normal (0.00 +- 3.40) |\n|mom_hs      |   6.04 |  (1.62, 10.15) | 99.60% | 0.999 | 3616.00 | Normal (0.00 +- 124.21) |\n\n\n:::\n:::\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktsch√§tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von `parameters(mein_modell)` auch `coef(mein_modell)` schreiben:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n```\n:::\n\n\n\n`m10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error`\n\nM√∂chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n```\n:::\n\n\n\nAber nat√ºrlich ist es m√∂glich (und einfacher) anstelle von `coef` den Befehl `parameters` zu verwenden.\n\nUnd die Visualisierung des Modells `m10.3`, s. @fig-m103.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m103_2536e73300d6844f969e028d12635236'}\n\n```{.r .cell-code}\nkidiq2 <-\n  kidiq %>% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a <- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\nplot(estimate_expectation(m10.3a))\n```\n\n::: {.cell-output-display}\n![Der Effekt von sowohl m√ºtterlicher Intelligenz als auch m√ºtterlichem Schulabschluss.](1000-metrische-AV_files/figure-html/fig-m103-1.png){#fig-m103 width=672}\n:::\n:::\n\n\n\n\n\n- *Achsenabschnitt*: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann sch√§tzt das Modell den IQ-Wert des Kindes auf 26.\n- *Koeffizient zum m√ºtterlichen Schulabschluss*: Vergleicht man Kinder von M√ºttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n- *Koeffizient zur m√ºtterlichen IQ*: Vergleicht man Kinder von M√ºttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n\n\n\n\n## `y ~ x + b + x:b`\n\n\n### Interaktion zur Modellformel hinzuf√ºgen\n\nIn `m10.3` hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. \nBetrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen.\nSind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n:::callout-important\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.\nLiegt keine Interaktion vor, so sind die Geraden parallel.$\\square$\n:::\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: `kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq`, s. @fig-m104 und @tbl-m104.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.4 <- \n  stan_glm(kid_score ~  mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n```\n:::\n\n::: {#tbl-m104 .cell tbl-cap='Parameter von m10.4' hash='1000-metrische-AV_cache/html/tbl-m104_a438023b2d29d6800b44cd5cdba10c5e'}\n::: {.cell-output-display}\n\n\n|Parameter     | Median |          95% CI |     pd |  Rhat |     ESS |                   Prior |\n|:-------------|:------:|:---------------:|:------:|:-----:|:-------:|:-----------------------:|\n|(Intercept)   | -10.10 | (-37.00, 17.79) | 77.10% | 1.000 | 1416.00 | Normal (86.80 +- 51.03) |\n|mom_hs        |  49.01 |  (20.09, 79.88) | 99.85% | 1.000 | 1438.00 | Normal (0.00 +- 124.21) |\n|mom_iq        |   0.95 |    (0.65, 1.24) |   100% | 1.000 | 1362.00 |   Normal (0.00 +- 3.40) |\n|mom_hs:mom_iq |  -0.46 |  (-0.78, -0.15) | 99.75% | 1.000 | 1388.00 |   Normal (0.00 +- 1.16) |\n\n\n:::\n:::\n\n\nMit `estimate_expectation(m10.4) |> plot()` kann man es sich visualisieren, s. @fig-m104.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m104_8a9c929dae2252c788f31fa59cbc39b0'}\n::: {.cell-output-display}\n![Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt f√ºr diese Daten kaum zu interpretieren ist.](1000-metrische-AV_files/figure-html/fig-m104-1.png){#fig-m104 width=768}\n:::\n:::\n\n\n\n\n\nDie Modellformel zur Forschungsfrage lautet: `y ~ x + b + x:b`.\n\n\nDer DAG zur Modellformel sieht aus in @fig-yxbi dargestellt.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![DAG f√ºr `y ~ x + b + x:b`](1000-metrische-AV_files/figure-html/fig-yxbi-1.png){#fig-yxbi width=100%}\n:::\n:::\n\n\n\n\n\n### Interpretation von `m10.4`\n\n*Achsenabschnitt:* IQ-Sch√§tzwerte f√ºr Kinder mit M√ºtter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\n- `mom_hs`: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\n`mom_iq`: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit M√ºttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\n*Interaktion*: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten f√ºr `mom_iq` zwischen M√ºtter mit bzw. ohne Schulabschluss.\n\n```\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\n```\n\n\n\n\n\n\n\n### Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n<iframe src=\"https://giphy.com/embed/Zaej3GIZTzCI8\" width=\"480\" height=\"306\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/muppets-rachel-maddow-kermit-Zaej3GIZTzCI8\">via GIPHY</a></p>\n\n\n\n\n\n\n## `y ~ x_c + b + x_c:b`\n\n### Zentrieren von Pr√§diktoren\n\nUnter *Zentrieren* (to *c*enter) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.^[Vgl. [Abschnitt \"UV zentrieren\"](https://statistik1.netlify.app/090-regression2.html#uv-zentrieren) im Kursbuch [Statistik1](https://statistik1.netlify.app/).]\nZentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist.\nMit zentrierten Werten ist eine Regression einfacher zu interpretieren.\nHier zentrieren wir (nur) `mom_iq`; \ndie zentrierte Variable kennzeichnen wir durch den Suffix `_c`, also `mom_iq_c`.\n\n\nMan k√∂nnte auch `mom_hs` zentrieren,\naber f√ºr eine einfache Interpretation ist es meist n√ºtzlich,\nnur metrische Pr√§diktoren zu zentrieren.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/Thema6-Teil2-7_1d960a94e0b9508e3242d22b9ea919ee'}\n\n```{.r .cell-code}\nkidiq <-\n  kidiq %>% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Fixed Effects\n\n|Parameter       | Median |\n|:---------------|:------:|\n|(Intercept)     |  85.31 |\n|mom_hs          |   2.91 |\n|mom_iq_c        |   0.97 |\n|mom_hs:mom_iq_c |  -0.48 |\n\n\n:::\n:::\n\n\n\n\n\n\n### Interpretation von `m10.5`\n\n- Der *Achsenabschnitt* (`Intercept`) gibt den gesch√§tzten IQ des Kindes an, wenn man eine Mutter *mittlerer* Intelligenz und *ohne* Schulabschluss betrachtet.\n- `mom_hs` gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n- `mom_iq_c` gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n- `mom_hs:mom_iq_c` gibt den Unterschied in den Koeffizienten f√ºr `mom_iq_c` an zwischen den beiden Grupen von `mom_hs`.\n\n\n`m10.5` ist in @fig-m105 dargestellt.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![m10.5: Interaktionsmodell mit zentriertem Pr√§diktor f√ºr m√ºtterlicher Intelligenz. Wie man sieht, ist der Achsenabschnitt deutlich besser zu interpretieren als in m10.4, s. @fig-m104.](1000-metrische-AV_files/figure-html/fig-m105-1.png){#fig-m105 width=768}\n:::\n:::\n\n\n\n\n\n### Zentrieren √§ndert nichts an den Vorhersagen\n\nBetrachten wir die Vorhersagen von `m10.4`: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new <- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.34184\n```\n:::\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von `m10.5`: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new <- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.3592\n```\n:::\n\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): $\\sigma_{m10.4}= 18$; $\\sigma_{m10.5}= 18$.\n\n\nDas Zentrieren √§ndert auch *nicht* die Regressionskoeffizienten, da die Streuungen der Pr√§diktoren nicht ver√§ndert wurden.\n\n\n\n\n\n### Perzentilintervalle aus der Posterori-Verteilung\n\n@tbl-m105 zeigt die Punktsch√§tzer der Parameter f√ºr m10.5 sowie ihre Perzentilintervalle^[auch ETI (Equal Tails Interval) genannt].\nNutzen Sie daf√ºr `parameters(m10.5)`, s. @tbl-m105.\n\n\n::: {#tbl-m105 .cell tbl-cap='Parameter von m10.5 und ETIs' hash='1000-metrische-AV_cache/html/tbl-m105_404439ad1f87223ce0017b936993d0ba'}\n::: {.cell-output-display}\n\n\n|Parameter       | Median |         95% CI |     pd |  Rhat |     ESS |                   Prior |\n|:---------------|:------:|:--------------:|:------:|:-----:|:-------:|:-----------------------:|\n|(Intercept)     |  85.31 | (80.99, 89.72) |   100% | 1.001 | 2610.00 | Normal (86.80 +- 51.03) |\n|mom_hs          |   2.91 |  (-1.89, 7.69) | 88.00% | 1.001 | 2832.00 | Normal (0.00 +- 124.21) |\n|mom_iq_c        |   0.97 |   (0.67, 1.24) |   100% | 1.002 | 1982.00 |   Normal (0.00 +- 3.40) |\n|mom_hs:mom_iq_c |  -0.48 | (-0.78, -0.16) | 99.78% | 1.002 | 1992.00 |   Normal (0.00 +- 3.87) |\n\n\n:::\n:::\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich  komfortabel ausgeben lassen mit `hdi(m10.5)` oder mit `parameters(m10.5, ci_method = \"hdi\")`,\ns. @tbl-m105-hdi.\n\n\n::: {#tbl-m105-hdi .cell tbl-cap='Parameter von m10.5 und HDIs' hash='1000-metrische-AV_cache/html/tbl-m105-hdi_6f55fe49013192d5a8a34a2ed816a691'}\n\n```{.r .cell-code}\nparameters(m10.5, ci_method = \"hdi\") %>% \n  display()\n```\n\n::: {.cell-output-display}\n\n\n|Parameter       | Median |         95% CI |     pd |  Rhat |     ESS |                   Prior |\n|:---------------|:------:|:--------------:|:------:|:-----:|:-------:|:-----------------------:|\n|(Intercept)     |  85.31 | (81.26, 89.88) |   100% | 1.001 | 2610.00 | Normal (86.80 +- 51.03) |\n|mom_hs          |   2.91 |  (-1.89, 7.70) | 88.00% | 1.001 | 2832.00 | Normal (0.00 +- 124.21) |\n|mom_iq_c        |   0.97 |   (0.68, 1.24) |   100% | 1.002 | 1982.00 |   Normal (0.00 +- 3.40) |\n|mom_hs:mom_iq_c |  -0.48 | (-0.79, -0.17) | 99.78% | 1.002 | 1992.00 |   Normal (0.00 +- 3.87) |\n\n\n:::\n:::\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n\n\n### Beantworten der Forschungsfrage\n\n>   Das Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei M√ºttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der m√ºtterlichen Intelligenz; pro Punkt Unterschied in m√ºttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). Au√üerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei M√ºtter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n</br>\n</br>\n\n\n\n:::callout-important\nDas Modell macht *keine* kausalen Aussagen. Es werden lediglich Unterschiede bzw. Zusammenh√§nge beschrieben.\nF√ºr kausale Aussagen ist mehr n√∂tig, als einen statistischen Zusammenhang festzustellen.\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## `y ~ g`\n\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n\n\n\n### Forschungsfrage\n\n\n\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in;\nIhre Kompetenz als Wirtschaftspsychologi war hei√ü begehrt.\nVon Statistik wollte niemand etwas wissen...\nDoch nach einiger Zeit kamen Sie in eine Sinnkrise.\nSie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen.\nKurz entschlossen bewarben Sie sich auf das erste Stellenangebot\nals Nachwuchswissenschaftler:in.\n\nIhr Forschungsprojekt f√ºhrte Sie in die Antarktis...\nNun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\n\n\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen.\nGenauer gesagt ging es um Gr√∂√üenunterschiede zwischen drei Pinguinarten.\nJa, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\n\n\n</br>\n\n\n> Unterscheiden sich die mittleren K√∂rpergewichte der drei Pinguinarten?\n\n\n\n\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: `y ~ g`. \n\n\nDer DAG zur Modellformel sieht aus in @fig-yg dargestellt.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-yg_f1f0499b1171ddd4bb5eec01ac846918'}\n::: {.cell-output-display}\n![DAG f√ºr `y ~ g`](1000-metrische-AV_files/figure-html/fig-yg-1.png){#fig-yg width=100%}\n:::\n:::\n\n\n\n### Alle Mittelwerte sind gleich, exakt gleich (?)\n\n- Formal: $\\mu_1 = \\mu_2 = \\ldots = \\mu_k$ mit $k$ verschiedenen Gruppen von Pinguinarten.\n\n- Hypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als *Nullhypothesen* bezeichnen.\n\n- Moment. Dass sich *alle* Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:\n\n> *Wie sehr* unterscheiden sich mittlere K√∂rpergewichte in Abh√§ngigkeit von der Pinguinart?\n\nAlternativ k√∂nnen wir  die Hypothese pr√ºfen, ob die Mittelwerte \"praktisch\" gleich sind, also sich \"kaum\" unterscheiden. Der Grenzwert f√ºr \"praktisch gleich\" bzw. \"kaum unterschiedlich\" ist subjektiv. Dazu in @sec-rope mehr.\n\n\n\n### Erster Blick in den Datensatz `penguins`\n\n![Palmer Penguins](img/penguins-logo.png){width=\"25%\"}\n\n[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv), [Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/palmerpenguins/penguins.html)\n\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, @tbl-penguins.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins %>% \n  select(body_mass_g, species) %>% \n  group_by(species) %>% \n  describe_distribution(range = FALSE, iqr = FALSE)\n```\n:::\n\n::: {#tbl-penguins .cell tbl-cap='Die Verteilung des K√∂rpergewichts pro Spezies der Pinguine' hash='1000-metrische-AV_cache/html/tbl-penguins_008923d60a89599cc14a4abb4dd2fe0f'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Variable\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Mean\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SD\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Skewness\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Kurtosis\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n_Missing\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".group\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"body_mass_g\",\"2\":\"3700.662\",\"3\":\"458.5661\",\"4\":\"0.28533613\",\"5\":\"-0.5737376\",\"6\":\"151\",\"7\":\"1\",\"8\":\"species=Adelie\"},{\"1\":\"body_mass_g\",\"2\":\"3733.088\",\"3\":\"384.3351\",\"4\":\"0.24743313\",\"5\":\"0.5933789\",\"6\":\"68\",\"7\":\"0\",\"8\":\"species=Chinstrap\"},{\"1\":\"body_mass_g\",\"2\":\"5076.016\",\"3\":\"504.1162\",\"4\":\"0.06963485\",\"5\":\"-0.7227912\",\"6\":\"123\",\"7\":\"1\",\"8\":\"species=Gentoo\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\nWas f√§llt Ihnen auf?\n\n\n\n### Visualisierung (EDA)\n\n\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, \ns. @fig-penguines1? \n\n\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-penguines1_fb9c572c2f9f4d29107a11f541978918'}\n::: {.cell-output-display}\n![Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violine](1000-metrische-AV_files/figure-html/fig-penguines1-1.png){#fig-penguines1 width=672}\n:::\n:::\n\n\n<!-- @fig-penguines2 zeigt die Gewichtsverteilung pro Spezies als \"Bergr√ºcken\" (`geom_ridges`). -->\n\n<!-- ```{r fig.asp = .3, fig.width=7} -->\n<!-- #| echo: false -->\n<!-- #| label: fig-penguines2 -->\n<!-- #| fig-cap: \"Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Ridges\" -->\n<!-- ggplot(penguins) + -->\n<!--   aes(x = body_mass_g, y = species) + -->\n<!--   geom_density_ridges() -->\n<!-- ``` -->\n\n<!-- @fig-penguines3 zeigt die Gewichtsverteilung pro Spezies als \"halbe Violinen\" (`geom_ridges`),  -->\n<!-- sozusagen Dichtediagramme um 90 Grad gedreht. -->\n\n<!-- ```{r} -->\n<!-- #| label: fig-penguines3 -->\n<!-- #| fig-cap: \"Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violindot\" -->\n<!-- penguins %>%  -->\n<!--   ggplot(aes(x = species, y = body_mass_g, fill = species)) + -->\n<!--   geom_violindot(fill_dots = \"black\") -->\n<!-- ``` -->\n\n\n\n\n\n\n### Gewicht pro Spezies, `m10.6`\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. `m10.6` und @tbl-m106-params.\n\nDie Modellformel  f√ºr `m10.6` lautet also `body_mass_g ~ species`.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m106_52ce4808eb029eba6005f1271f83ef04'}\n\n```{.r .cell-code}\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 <- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %>% parameters()\n```\n:::\n\n::: {#tbl-m106-params .cell tbl-cap='Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen' hash='1000-metrische-AV_cache/html/tbl-m106-params_80dfcc0e89f3efd226c54447b3bdab79'}\n::: {.cell-output-display}\n\n\n|Parameter        |  Median |             95% CI |     pd |  Rhat |     ESS |                       Prior |\n|:----------------|:-------:|:------------------:|:------:|:-----:|:-------:|:---------------------------:|\n|(Intercept)      | 3699.92 | (3624.56, 3776.46) |   100% | 1.001 | 4194.00 | Normal (4201.75 +- 2004.89) |\n|speciesChinstrap |   32.24 |  (-100.80, 159.99) | 69.92% | 1.000 | 4266.00 |    Normal (0.00 +- 5015.92) |\n|speciesGentoo    | 1374.94 | (1265.80, 1486.83) |   100% | 1.001 | 4187.00 |    Normal (0.00 +- 4171.63) |\n\n\n:::\n:::\n\n\n\n\n\n### Interpretation von `m10.6`\n\nDie UV hat drei verschiedene Stufen (Werte, Auspr√§gungen; hier: Spezies), aber es werden in @tbl-m106-params nur zwei Stufen angezeigt (also eine weniger) zus√§tzlich zum Achsenabsdhnitt.\nDie fehlende Stufe (`Adelie`, nicht ausgegeben) ist die *Vergleichs- oder Referenzkategorie* (baseline) und ist im Achsenabschnitt ausgedr√ºckt (Intercept).\nDie Koeffizienten f√ºr `species` geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder.\nPinguine der Spezies `Adelie` haben laut Modell ein mittleres Gewicht von ca. 3700g.\nPinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies `Adelie`, etc.\n\n\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in @fig-m106-params verdeutlicht.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m106-params_b39b9991198a86650cb4b629c02b3456'}\n\n```{.r .cell-code}\nplot(hdi(m10.6)) + scale_fill_okabeito()\n```\n\n::: {.cell-output-display}\n![Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)](1000-metrische-AV_files/figure-html/fig-m106-params-1.png){#fig-m106-params width=672}\n:::\n:::\n\n\n\nDas [Farbschema nach Okabe und Ito](https://jfly.uni-koeln.de/color/) ist gut geeignet, um nominal skalierte Farben zu kodieren (d. [Details hier](https://data-se.netlify.app/2023/06/30/farbpaletten/)).\n\n\n### Glauben wir jetzt an Gruppeneffekte?\n\nGlauben wir jetzt, auf Basis der Modellparameter,\nan Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\n\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. \nSo ist der Mittelwert der Gruppe `Gentoo` deutlich h√∂her als der der beiden anderen Gruppen. \nUmgekehrt sind sich die Pinguinarten `Adelie` und `Chinstrap` in ihren Mittelwerten ziemlich √§hnlich.\n\nWie in @fig-m106-params ersichtlich,\n√ºberlappt sich der Sch√§tzbereich f√ºr den Parameter von Gentoo *nicht* mit der Null;\nhingegen √ºberlappt sich der Sch√§tzbereich des Parameters f√ºr Chinstrap deutlich mit der Nullinie.\n\n\n\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass *alle* Mittelwerte   *exakt* identisch sind.\n\nEhrlicherweise h√§tte sowieso (fast) niemand geglaubt, dass die *exakte Nullhypothese* $\\mu_1 = \\mu_2 = \\ldots = \\mu_k$ bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.\nAber: Viele Forschis pr√ºfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese.\nDas Verfahren der Frequentistischen Statistik, um die Nullhypothese $\\mu_1 = \\mu_2 = \\ldots = \\mu_k$ zu testen, nennt man *Varianzanalyse* (analysis of variance, kurz *ANOVA*).\nIn der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art)  inferenzstatistisch zu beurteilen.\n\n\n\n\n\n\n\n\n### Priori-Werte √§ndern\n\nUnser Modell `m10.6` hat schwach informierte (weakly informative) Priors.\nF√ºr Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\n- Achsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\n- mit Mittelwert entsprechend den Stichprobendaten \n- und einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\n- f√ºr Sigma wird eine Exponentialverteilung mit Rate $\\lambda=1$ angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: `prior_summary(modell)`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n```\n:::\n\n\n\n\n\nWo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Prioris anpassen wollen, z.B.:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6b <- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3703.90575         26.67909       1360.23645\n```\n:::\n\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher.\nDazu gibt man bei dem oder den entsprechenden Parametern den Zusatz `autoscale = TRUE` an.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6c <- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.98554         30.95782       1375.37494\n```\n:::\n\n\n\n\n\n\nDen Parameter f√ºr die Streuung des Modells, $\\sigma$, kann man sich mit `sigma(modell)` ausgeben lassen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma(m10.6b)\n## [1] 462.6415\n```\n:::\n\n\n\n\nImplizit bekommt man die Informationen zu $\\sigma$ mitgeteilt durch die Gr√∂√üe der Konfidenzintervalle.\n\n√úbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren^[s. Details [hier](https://mc-stan.org/rstanarm/articles/priors.html#how-to-specify-flat-priors-and-why-you-typically-shouldnt).].\n\n\n\n### Wechsel der Referenzkategorie\n\n`species` ist eine nominale Variable, da passt in R der Typ `factor` (Faktor) am besten. Aktuell ist der Typ noch `character` (Text):\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins <- penguins %>% \n  mutate(species = factor(species))\n```\n:::\n\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n```\n:::\n\n\nSetzen wir `Gentoo` als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forcats)\npenguins <- penguins %>% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n```\n:::\n\n\nBeachten Sie, dass dazu das Paket `forcats` verf√ºgbar sein muss.\n\nJetzt haben wir die Referenzkategorie ge√§ndert:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n```\n:::\n\n\n\n\n\n\n\n\n\n\nDer Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell, s. @tbl-m106a.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n```\n:::\n\n::: {#tbl-m106a .cell tbl-cap='m10.6a mit ge√§nderter Referenzkategorie; die Effekte der UVs bleiben gleich.' hash='1000-metrische-AV_cache/html/tbl-m106a_b6f02c01a050280800814c851cbecf2d'}\n::: {.cell-output-display}\n\n\nTable: Highest Density Interval\n\n|Parameter        |             95% HDI |\n|:----------------|:--------------------|\n|(Intercept)      |[ 5001.08,  5160.63] |\n|speciesAdelie    |[-1477.80, -1264.23] |\n|speciesChinstrap |[-1475.95, -1204.52] |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## `y ~ x1 + x2`\n\n\n\n\n### Forschungsfrage\n\n>   Stehen sowohl der IQ der Mutter als auch, unabh√§ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\n- Das ist wieder eine *deskriptive* Forschungsfrage. *Keine* Kausalwirkung (etwa \"IQ der Mutter ist die Ursache zum IQ des Kindes\") wird impliziert. \n- Es geht rein darum, Zusammenh√§nge in den Daten - bzw. in der Population - aufzuzeigen.\n- Viele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. F√ºr solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist n√∂tig.\n\n\n\n\n### Was hei√üt, X h√§ngt mit Y zusammen?\n\n\n- Der Begriff \"Zusammenhang\" ist nicht exakt.\n- H√§ufig wird er (f√ºr metrische Variablen) verstanden als\n    - lineare Korrelation $\\rho$ bzw. $r$ \n    - lineare Regression $\\beta$, bzw. $b$ \n\n\n- Der Regressionskoeffizient \n    - misst die *Steigung* der Regressionsgerade\n    - zeigt, wie gro√ü der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\n    - wird manchmal mit dem \"Effekt von X auf Y\" √ºbersetzt. Vorsicht: \"Effekt\" klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begr√ºndung f√ºr einen Kausalzusammenhang. \n    \n- Der Korrelationskoeffizient\n    - misst eine Art der St√§rke des linearen Zusammenhangs\n    - zeigt, wie klein die Vorhersagefehler der zugeh√∂rigen Regrssion im Schnitt sind.\n    - [Korrelation ist nicht (automatisch) Kausation.](https://xkcd.com/552/)\n    \n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten,\nbevor man ein (Regressions-)Modell aufstellt.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  correlation()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Correlation Matrix (pearson-method)\n\n|Parameter1 | Parameter2 |    r |            95% CI |   t(432) |         p |\n|:----------|:----------:|:----:|:-----------------:|:--------:|:---------:|\n|kid_score  |     mom_hs | 0.24 |      (0.15, 0.32) |     5.07 | < .001*** |\n|kid_score  |     mom_iq | 0.45 |      (0.37, 0.52) |    10.42 | < .001*** |\n|kid_score  |    mom_age | 0.09 | (-2.15e-03, 0.18) |     1.92 | 0.166     |\n|kid_score  |   mom_iq_c | 0.45 |      (0.37, 0.52) |    10.42 | < .001*** |\n|mom_hs     |     mom_iq | 0.28 |      (0.19, 0.37) |     6.13 | < .001*** |\n|mom_hs     |    mom_age | 0.21 |      (0.12, 0.30) |     4.57 | < .001*** |\n|mom_hs     |   mom_iq_c | 0.28 |      (0.19, 0.37) |     6.13 | < .001*** |\n|mom_iq     |    mom_age | 0.09 | (-2.54e-03, 0.18) |     1.91 | 0.166     |\n|mom_iq     |   mom_iq_c | 1.00 |      (1.00, 1.00) | 1.39e+09 | < .001*** |\n|mom_age    |   mom_iq_c | 0.09 | (-2.54e-03, 0.18) |     1.91 | 0.166     |\np-value adjustment method: Holm (1979)\nObservations: 434\n\n\n:::\n:::\n\n\n\n@tbl-kidiq-corr zeigt die Korrelationsmatrix als Korrelationsmatrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  correlation() %>% \n  summary()\n```\n:::\n\n::: {#tbl-kidiq-corr .cell tbl-cap='Die Korrelationen zwischen den Variablen der Tabelle kidiq' hash='1000-metrische-AV_cache/html/tbl-kidiq-corr_3f8ad8b840402a6ac69fe78e133af923'}\n::: {.cell-output-display}\n\n\nTable: Correlation Matrix (pearson-method)\n\n|Parameter | mom_age |  mom_iq |  mom_hs |\n|:---------|:-------:|:-------:|:-------:|\n|kid_score |    0.09 | 0.45*** | 0.24*** |\n|mom_hs    | 0.21*** | 0.28*** |         |\n|mom_iq    |    0.09 |         |         |\np-value adjustment method: Holm (1979)\n\n\n:::\n:::\n\n\n\nN√ºtzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, @fig-kidiq-heatmap.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-kidiq-heatmap_a1e3a80faf6243258328ce22a7b47442'}\n\n```{.r .cell-code}\nkidiq %>% \n  correlation() %>% \n  summary() %>% \n  plot()\n```\n\n::: {.cell-output-display}\n![Visualisierung der Korrelationsmatrix als Heatmap](1000-metrische-AV_files/figure-html/fig-kidiq-heatmap-1.png){#fig-kidiq-heatmap width=672}\n:::\n:::\n\n\n\n\n\n### Univariate Regressionen\n\nWir berechnen jeweils eine univariate Regression, pro Pr√§diktor,\nalso eine f√ºr `mom_iq` und eine f√ºr `mom_age`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n```\n:::\n\n\nHier die Ergebnisse f√ºr `mom_iq`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.8084927   0.6101706\n```\n:::\n\n\nHier die Ergebnisse f√ºr `mom_age`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.1650562   0.6875296\n```\n:::\n\n\n\n\n\n### Visualisierung der univariaten Regressionen\n\nIn @fig-regr-one-pred ist die univariate Regression mit jeweils einem der beiden Pr√§diktoren dargestellt.\n\n\n`m10.7`: Die Steigung betr√§gt 0.6.\n`m10.8`: Die Steigung betr√§gt 0.7.\n\n\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-regr-one-pred_c7d0408a274c9d42522e4282478ade3d'}\n::: {.cell-output-display}\n![Zwei univariate Regressionen](1000-metrische-AV_files/figure-html/fig-regr-one-pred-1.png){#fig-regr-one-pred width=672}\n:::\n:::\n\n\n\nUnivariate Regressionen\n\n\n\n\n### Multiples Modell (beide Pr√§diktoren), m10.9\n\n\n`m10.9` stellt das multiple Regressionsmodell dar;\n*multipel* bedeutet in diesem Fall, dass mehr als ein Pr√§diktor im Modell aufgenommen ist.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m109_4f26ebfdb81a99eb8bc3f75056342895'}\n\n```{.r .cell-code}\nm10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n```\n:::\n\n\n\n:::callout-important\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n:::\n\n\n- Bei einer multiplen Regression ist ein Regressionsgewicht jeweils \"bereinigt\" vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\n- Das bedeutet, man betrachtet den den Zusammenhang eines Pr√§diktors mit der AV, wobei man gleichzeitig den anderen Pr√§diktor konstant h√§lt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n```\n:::\n\n\n\n\n\n### 3D-Visualisierung eines Modells mit zwei Pr√§diktoren 1\n\nIn @fig-m109-plotly ist das Modell `m10.9` in 3D dargestellt via [Plotly](https://plotly.com/r/).\n\n\n::: {.cell layout-align=\"center\" hash='1000-metrische-AV_cache/html/fig-m109-plotly_94ed5e8e37b77775b4a36f40acc29e16'}\n::: {#fig-m109-plotly .cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-f6b41cd6595dd8e57218\" style=\"width:100%;height:406px;\" class=\"plotly html-widget \"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f6b41cd6595dd8e57218\">{\"x\":{\"visdat\":{\"f9a770f0807\":[\"function () \",\"plotlyVisDat\"],\"f9a7bd840a1\":[\"function () \",\"data\"]},\"cur_data\":\"f9a7bd840a1\",\"attrs\":{\"f9a770f0807\":{\"x\":{},\"y\":{},\"z\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"surface\"},\"f9a7bd840a1\":{\"x\":{},\"y\":{},\"z\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\",\"mode\":\"markers\",\"marker\":{\"color\":\"#00998a\",\"opacity\":0.69999999999999996,\"size\":1,\"symbol\":105},\"inherit\":true}},\"layout\":{\"width\":800,\"height\":500,\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"aspectmode\":\"manual\",\"aspectratio\":{\"x\":1,\"y\":1,\"z\":1},\"xaxis\":{\"title\":\"mom_iq\"},\"yaxis\":{\"title\":\"mom_age\"},\"zaxis\":{\"title\":\"kid_score\"}},\"hovermode\":\"closest\",\"showlegend\":false,\"legend\":{\"yanchor\":\"top\",\"y\":0.5}},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"colorbar\":{\"title\":\"z<br />kid_score\",\"ticklen\":2,\"len\":0.5,\"lenmode\":\"fraction\",\"y\":1,\"yanchor\":\"top\"},\"colorscale\":[[\"0\",\"rgba(68,1,84,1)\"],[\"0.0416666666666666\",\"rgba(70,19,97,1)\"],[\"0.0833333333333332\",\"rgba(72,32,111,1)\"],[\"0.125\",\"rgba(71,45,122,1)\"],[\"0.166666666666667\",\"rgba(68,58,128,1)\"],[\"0.208333333333333\",\"rgba(64,70,135,1)\"],[\"0.25\",\"rgba(60,82,138,1)\"],[\"0.291666666666667\",\"rgba(56,93,140,1)\"],[\"0.333333333333333\",\"rgba(49,104,142,1)\"],[\"0.375\",\"rgba(46,114,142,1)\"],[\"0.416666666666667\",\"rgba(42,123,142,1)\"],[\"0.458333333333333\",\"rgba(38,133,141,1)\"],[\"0.5\",\"rgba(37,144,140,1)\"],[\"0.541666666666667\",\"rgba(33,154,138,1)\"],[\"0.583333333333333\",\"rgba(39,164,133,1)\"],[\"0.625\",\"rgba(47,174,127,1)\"],[\"0.666666666666667\",\"rgba(53,183,121,1)\"],[\"0.708333333333333\",\"rgba(79,191,110,1)\"],[\"0.75\",\"rgba(98,199,98,1)\"],[\"0.791666666666667\",\"rgba(119,207,85,1)\"],[\"0.833333333333333\",\"rgba(147,214,70,1)\"],[\"0.875\",\"rgba(172,220,52,1)\"],[\"0.916666666666667\",\"rgba(199,225,42,1)\"],[\"0.958333333333333\",\"rgba(226,228,40,1)\"],[\"1\",\"rgba(253,231,37,1)\"]],\"showscale\":true,\"x\":[71.037405135662993,73.864726007975449,76.692046880287904,79.519367752600374,82.346688624912829,85.174009497225285,88.001330369537754,90.82865124185021,93.655972114162665,96.483292986475121,99.310613858787576,102.13793473110005,104.9652556034125,107.79257647572496,110.61989734803743,113.44721822034988,116.27453909266234,119.10185996497479,121.92918083728725,124.75650170959972,127.58382258191217,130.41114345422463,133.2384643265371,136.06578519884954,138.89310607116201],\"y\":[17,17.5,18,18.5,19,19.5,20,20.5,21,21.5,22,22.5,23,23.5,24,24.5,25,25.5,26,26.5,27,27.5,28,28.5,29],\"z\":[[67.137312591068977,68.842478682869924,70.547644774670871,72.252810866471805,73.957976958272752,75.6631430500737,77.368309141874647,79.073475233675595,80.778641325476542,82.48380741727749,84.188973509078423,85.894139600879384,87.599305692680318,89.304471784481265,91.009637876282213,92.71480396808316,94.419970059884093,96.125136151685041,97.830302243485988,99.535468335286936,101.24063442708788,102.94580051888882,104.65096661068978,106.35613270249071,108.06129879429166],[67.33225385269381,69.037419944494758,70.742586036295705,72.447752128096639,74.152918219897586,75.858084311698533,77.563250403499481,79.268416495300428,80.973582587101376,82.678748678902323,84.383914770703257,86.089080862504218,87.794246954305152,89.499413046106099,91.204579137907047,92.909745229707994,94.614911321508927,96.320077413309875,98.025243505110822,99.73040959691177,101.43557568871272,103.14074178051365,104.84590787231461,106.55107396411555,108.25624005591649],[67.527195114318658,69.232361206119606,70.937527297920539,72.642693389721487,74.347859481522434,76.053025573323382,77.758191665124329,79.463357756925276,81.168523848726224,82.873689940527171,84.578856032328105,86.284022124129066,87.98918821593,89.694354307730947,91.399520399531895,93.104686491332842,94.809852583133775,96.515018674934723,98.22018476673567,99.925350858536618,101.63051695033757,103.3356830421385,105.04084913393946,106.74601522574039,108.45118131754134],[67.722136375943492,69.42730246774444,71.132468559545387,72.83763465134632,74.542800743147268,76.247966834948215,77.953132926749163,79.65829901855011,81.363465110351058,83.068631202152005,84.773797293952939,86.4789633857539,88.184129477554833,89.889295569355781,91.594461661156728,93.299627752957676,95.004793844758609,96.709959936559557,98.415126028360504,100.12029212016145,101.8254582119624,103.53062430376333,105.23579039556429,106.94095648736523,108.64612257916617],[67.917077637568326,69.622243729369274,71.327409821170221,73.032575912971168,74.737742004772116,76.442908096573063,78.148074188374011,79.853240280174958,81.558406371975906,83.263572463776853,84.968738555577772,86.673904647378748,88.379070739179667,90.084236830980615,91.789402922781562,93.49456901458251,95.199735106383457,96.904901198184405,98.610067289985352,100.3152333817863,102.02039947358725,103.72556556538817,105.43073165718914,107.13589774899006,108.84106384079101],[68.112018899193174,69.817184990994122,71.522351082795055,73.227517174596002,74.93268326639695,76.637849358197897,78.343015449998845,80.048181541799792,81.75334763360074,83.458513725401687,85.16367981720262,86.868845909003582,88.574012000804515,90.279178092605463,91.98434418440641,93.689510276207358,95.394676368008291,97.099842459809238,98.805008551610186,100.51017464341113,102.21534073521208,103.92050682701301,105.62567291881398,107.33083901061491,109.03600510241586],[68.306960160818008,70.012126252618955,71.717292344419903,73.422458436220836,75.127624528021784,76.832790619822731,78.537956711623679,80.243122803424626,81.948288895225573,83.653454987026521,85.358621078827454,87.063787170628416,88.768953262429349,90.474119354230297,92.179285446031244,93.884451537832192,95.589617629633125,97.294783721434072,98.99994981323502,100.70511590503597,102.41028199683691,104.11544808863785,105.82061418043881,107.52578027223974,109.23094636404069],[68.501901422442856,70.207067514243803,71.912233606044737,73.617399697845684,75.322565789646632,77.027731881447579,78.732897973248527,80.438064065049474,82.143230156850422,83.848396248651369,85.553562340452302,87.258728432253264,88.963894524054197,90.669060615855145,92.374226707656092,94.07939279945704,95.784558891257973,97.48972498305892,99.194891074859868,100.90005716666082,102.60522325846176,104.3103893502627,106.01555544206366,107.72072153386459,109.42588762566554],[68.69684268406769,70.402008775868637,72.107174867669571,73.812340959470518,75.517507051271465,77.222673143072413,78.92783923487336,80.633005326674308,82.338171418475255,84.043337510276203,85.748503602077136,87.453669693878098,89.158835785679031,90.864001877479978,92.569167969280926,94.274334061081873,95.979500152882807,97.684666244683754,99.389832336484702,101.09499842828565,102.8001645200866,104.50533061188753,106.21049670368849,107.91566279548942,109.62082888729037],[68.891783945692524,70.596950037493471,72.302116129294419,74.007282221095352,75.712448312896299,77.417614404697247,79.122780496498194,80.827946588299142,82.533112680100089,84.238278771901037,85.94344486370197,87.648610955502932,89.353777047303865,91.058943139104812,92.76410923090576,94.469275322706707,96.174441414507641,97.879607506308588,99.584773598109535,101.28993968991048,102.99510578171143,104.70027187351236,106.40543796531333,108.11060405711426,109.81577014891521],[69.086725207317372,70.791891299118319,72.497057390919252,74.2022234827202,75.907389574521147,77.612555666322095,79.317721758123042,81.02288784992399,82.728053941724937,84.433220033525885,86.138386125326818,87.84355221712778,89.548718308928713,91.25388440072966,92.959050492530608,94.664216584331555,96.369382676132489,98.074548767933436,99.779714859734383,101.48488095153533,103.19004704333628,104.89521313513721,106.60037922693817,108.30554531873911,110.01071141054005],[69.281666468942205,70.986832560743153,72.6919986525441,74.397164744345034,76.102330836145981,77.807496927946929,79.512663019747876,81.217829111548824,82.922995203349771,84.628161295150719,86.333327386951652,88.038493478752613,89.743659570553547,91.448825662354494,93.153991754155442,94.859157845956389,96.564323937757322,98.26949002955827,99.974656121359217,101.67982221316016,103.38498830496111,105.09015439676205,106.79532048856301,108.50048658036394,110.20565267216489],[69.476607730567039,71.181773822367987,72.886939914168934,74.592106005969868,76.297272097770815,78.002438189571762,79.70760428137271,81.412770373173657,83.117936464974605,84.823102556775552,86.528268648576486,88.233434740377447,89.938600832178381,91.643766923979328,93.348933015780275,95.054099107581223,96.759265199382156,98.464431291183104,100.16959738298405,101.874763474785,103.57992956658595,105.28509565838688,106.99026175018784,108.69542784198877,110.40059393378972],[69.671548992191887,71.376715083992835,73.081881175793768,74.787047267594716,76.492213359395663,78.19737945119661,79.902545542997558,81.607711634798505,83.312877726599453,85.0180438184004,86.723209910201334,88.428376002002295,90.133542093803229,91.838708185604176,93.543874277405124,95.249040369206071,96.954206461007004,98.659372552807952,100.3645386446089,102.06970473640985,103.77487082821079,105.48003692001173,107.18520301181269,108.89036910361362,110.59553519541457],[69.866490253816721,71.571656345617669,73.276822437418616,74.981988529219549,76.687154621020497,78.392320712821444,80.097486804622392,81.802652896423339,83.507818988224287,85.212985080025234,86.918151171826167,88.623317263627129,90.328483355428062,92.03364944722901,93.738815539029957,95.443981630830905,97.149147722631838,98.854313814432786,100.55947990623373,102.26464599803468,103.96981208983563,105.67497818163656,107.38014427343752,109.08531036523846,110.7904764570394],[70.061431515441555,71.766597607242502,73.47176369904345,75.176929790844383,76.882095882645331,78.587261974446278,80.292428066247226,81.997594158048173,83.702760249849121,85.407926341650068,87.113092433451001,88.818258525251963,90.523424617052896,92.228590708853844,93.933756800654791,95.638922892455739,97.344088984256672,99.049255076057619,100.75442116785857,102.45958725965951,104.16475335146046,105.8699194432614,107.57508553506236,109.28025162686329,110.98541771866424],[70.256372777066403,71.961538868867351,73.666704960668284,75.371871052469231,77.077037144270179,78.782203236071126,80.487369327872074,82.192535419673021,83.897701511473969,85.602867603274916,87.308033695075849,89.013199786876811,90.718365878677744,92.423531970478692,94.128698062279639,95.833864154080587,97.53903024588152,99.244196337682467,100.94936242948341,102.65452852128436,104.35969461308531,106.06486070488624,107.7700267966872,109.47519288848814,111.18035898028909],[70.451314038691237,72.156480130492184,73.861646222293132,75.566812314094065,77.271978405895013,78.97714449769596,80.682310589496907,82.387476681297855,84.092642773098802,85.79780886489975,87.502974956700683,89.208141048501645,90.913307140302578,92.618473232103526,94.323639323904473,96.028805415705421,97.733971507506354,99.439137599307301,101.14430369110825,102.8494697829092,104.55463587471014,106.25980196651108,107.96496805831204,109.67013415011297,111.37530024191392],[70.646255300316085,72.351421392117032,74.056587483917966,75.761753575718899,77.466919667519846,79.172085759320794,80.877251851121741,82.582417942922689,84.287584034723636,85.992750126524584,87.697916218325531,89.403082310126479,91.108248401927426,92.813414493728374,94.518580585529321,96.223746677330269,97.928912769131188,99.634078860932135,101.33924495273308,103.04441104453403,104.74957713633498,106.45474322813592,108.15990931993687,109.86507541173782,111.57024150353877],[70.841196561940919,72.546362653741866,74.251528745542799,75.956694837343747,77.661860929144694,79.367027020945642,81.072193112746589,82.777359204547537,84.482525296348484,86.187691388149432,87.892857479950365,89.598023571751327,91.30318966355226,93.008355755353207,94.713521847154155,96.418687938955102,98.123854030756036,99.829020122556983,101.53418621435793,103.23935230615888,104.94451839795983,106.64968448976076,108.35485058156172,110.06001667336265,111.7651827651636],[71.036137823565753,72.7413039153667,74.446470007167648,76.151636098968581,77.856802190769528,79.561968282570476,81.267134374371423,82.972300466172371,84.677466557973318,86.382632649774266,88.087798741575199,89.792964833376161,91.498130925177094,93.203297016978041,94.908463108778989,96.613629200579936,98.318795292380869,100.02396138418182,101.72912747598276,103.43429356778371,105.13945965958466,106.84462575138559,108.54979184318655,110.25495793498749,111.96012402678844],[71.231079085190601,72.936245176991548,74.641411268792481,76.346577360593415,78.051743452394362,79.75690954419531,81.462075635996257,83.167241727797204,84.872407819598152,86.577573911399099,88.282740003200047,89.987906095000994,91.693072186801942,93.398238278602889,95.103404370403837,96.808570462204784,98.513736554005703,100.21890264580665,101.9240687376076,103.62923482940855,105.33440092120949,107.03956701301044,108.74473310481139,110.44989919661234,112.15506528841328],[71.426020346815434,73.131186438616382,74.836352530417315,76.541518622218263,78.24668471401921,79.951850805820158,81.657016897621105,83.362182989422053,85.067349081223,86.772515173023947,88.477681264824881,90.182847356625842,91.888013448426776,93.593179540227723,95.298345632028671,97.003511723829618,98.708677815630551,100.4138439074315,102.11900999923245,103.82417609103339,105.52934218283434,107.23450827463527,108.93967436643624,110.64484045823717,112.35000655003812],[71.620961608440268,73.326127700241216,75.031293792042163,76.736459883843096,78.441625975644044,80.146792067444991,81.851958159245939,83.557124251046886,85.262290342847834,86.967456434648781,88.672622526449715,90.377788618250676,92.082954710051609,93.788120801852557,95.493286893653504,97.198452985454452,98.903619077255385,100.60878516905633,102.31395126085728,104.01911735265823,105.72428344445918,107.42944953626011,109.13461562806107,110.839781719862,112.54494781166295],[71.815902870065116,73.521068961866064,75.226235053666997,76.931401145467945,78.636567237268892,80.341733329069839,82.046899420870787,83.752065512671734,85.457231604472682,87.162397696273629,88.867563788074563,90.572729879875524,92.277895971676458,93.983062063477405,95.688228155278352,97.3933942470793,99.098560338880233,100.80372643068118,102.50889252248213,104.21405861428308,105.91922470608402,107.62439079788496,109.32955688968592,111.03472298148685,112.7398890732878]],\"type\":\"surface\",\"frame\":null},{\"x\":[121.117528602603,89.361881710066299,115.443164881725,99.449639436072303,92.745709998211794,107.901837758501,138.89310607116201,125.145119475328,81.619526178984302,95.073068620649593,88.576997718556697,94.859708194367101,88.962800850959596,114.114297012333,100.53407191524499,120.41914559108599,114.42687689144699,111.59235758083101,133.84922720815899,97.264801063467303,110.09680614075,126.72399416984,97.911590309262806,99.925725160313306,97.595008052151101,121.748013460479,98.748078698993396,97.915254329167098,80.358556463233597,114.30786063392701,109.13831630297101,101.817179733939,117.965104313227,108.63349691304801,96.528619145464006,92.871375466164196,95.898134287588604,107.015457730577,87.197011745285806,89.361881710066299,102.53098784624601,130.16686023538799,83.414102598033594,125.75346623026,85.8103765615827,126.520072628695,79.203048104857004,113.16590717569601,110.33138786508,99.4092237400546,102.42552648887199,124.900437749856,94.859708194367101,92.368564550167406,101.817179733939,79.833532962732306,96.226139267492002,82.3554723942338,76.575647315981399,110.013482886319,111.59235758083101,113.657407368227,101.16455677312101,101.341094009698,101.698163476419,98.819154578196901,93.498196304135206,87.293889899862606,87.316028002805993,86.209457420689503,89.837967434307402,121.870014908527,127.544378629405,109.99134478337599,90.446314189239502,88.894902697317704,113.046890918176,78.013154268309705,95.389650877761298,83.616442109984604,86.246280610394393,95.389650877761298,111.252314499127,127.01443594601101,89.951950871923998,99.273102199494701,81.165578557686501,110.52128746677,136.49384691708499,123.862011656634,134.602392343459,91.098937150058205,103.26937177302899,126.287072933559,127.544378629405,92.473890303425506,84.794088571304499,100.53407191524499,108.003012055173,78.8071449713118,121.117528602603,103.056011346747,100.437193760669,88.554859615613395,85.3055571716597,119.44861765150701,90.551775546613598,96.334038336400297,127.644920803886,119.85655888685299,112.018920897562,92.514305999443195,96.023799755541006,91.416842128819198,103.07814944969,100.243630139074,89.8158293313641,115.057361749322,96.650620593512002,105.577950778248,97.721690707572904,131.835771186485,101.817179733939,93.498196304135206,104.02653928632699,103.708634307566,107.368863177393,92.551129189148099,94.442583762774206,93.144790857318597,83.414102598033594,71.037405135662993,127.66705890682999,115.687846607198,90.976256872633698,132.86533690346701,72.502296392558094,100.71060915182299,132.688799666889,98.5457391870425,115.665708504254,117.062799760565,136.49384691708499,106.548478717828,134.12630661921801,104.657024144202,99.378563556868798,100.437193760669,89.525387555193106,120.92294779354,113.143769072753,126.414746875437,122.73716348144301,115.37526672808301,91.6067417305091,88.660320972987506,107.17896357570299,104.96960402331599,103.8630334412,110.09680614075,88.454317441132204,117.032139577379,125.656588075683,122.60104194088299,121.04963044896201,93.144790857318597,99.378563556868798,123.89280744393599,113.043226898272,115.771169861628,114.938345491802,93.620876581559699,121.748013460479,90.349436034662702,83.410438578129302,99.486462625777193,113.910375471188,97.595008052151101,89.8158293313641,119.584739192066,97.381647625868595,84.877411825735294,102.328648334295,99.273102199494701,99.075049748245505,96.927700004570795,108.313250636032,100.53407191524499,99.486462625777193,113.987614356911,92.770201169491799,88.029836115112204,106.111557481547,103.232548583324,99.295240302438003,106.742042339422,99.172560025013496,102.447664591815,92.867711446259804,116.826136045524,85.424573429179802,115.56516632977301,113.174564860055,106.861058596942,95.830236133946798,77.109254019279902,89.290805830862894,112.412742040396,110.643967744195,109.53739716207799,107.901837758501,104.96960402331599,107.68276577815701,109.466321282875,133.53264495104699,128.80901236506,101.270018130495,87.316028002805993,118.09076978117901,120.255639745959,90.345772014758296,79.904608841935797,136.57717017151501,102.42552648887199,132.688799666889,96.297215146695393,118.20978603869899,118.09076978117901,101.504599854825,94.334684693865896,84.671408293880006,86.7688663993614,129.24593360134099,127.78104234444601,106.861058596942,105.75448801482599,117.032139577379,119.35173949692999,102.76556957057601,108.205351567124,126.414746875437,101.90050298836999,99.156255637093395,91.812745262364402,84.141465610485795,84.354826036768301,79.119724850426095,91.416842128819198,90.446314189239502,79.000708592906093,109.263981770924,76.752184552558901,97.595008052151101,128.80901236506,113.657407368227,114.206686337254,112.513284214877,75.336815703173897,81.522648024407502,102.638886915154,101.186694876064,112.222842438706,123.408064035336,86.566526887410504,100.11694748365299,102.328648334295,87.946512860681295,80.258014288752406,80.258014288752406,91.076799047114903,85.578972562814101,113.16590717569601,112.05933659358,101.270018130495,81.832886605266793,81.094502678483096,81.329084402813294,120.60904519277599,102.447664591815,90.976256872633698,103.708634307566,102.328648334295,121.870014908527,88.660320972987506,90.029189757646606,83.533118855553695,91.920644331272797,87.1933477253815,80.464017820607694,84.318002847063397,77.739738877155304,82.272149139803005,77.382669410434303,89.715287156882994,79.904608841935797,82.153132882282904,80.261678308656798,77.382669410434303,82.783617740158306,89.207482576432099,89.088466318911998,88.9872920222396,118.92359415100501,83.851023834314802,84.044587455908996,105.052927277747,107.99934803526899,97.381647625868595,103.791957561996,97.595008052151101,88.660320972987506,107.246861729345,89.837967434307402,108.906912304203,100.63953327262,118.840270896574,95.512331155185805,84.771950468361197,100.747432341528,87.003448123691598,77.858755134675405,85.301893151755394,92.770201169491799,74.860729978932795,115.248584072661,107.372527197298,102.202982866342,97.911590309262806,96.856624125367304,111.465674925409,109.466321282875,82.250011036859703,92.770201169491799,115.568830349677,84.044587455908996,116.199315207553,99.295240302438003,87.1933477253815,76.711768856541298,80.698599544937906,82.463371463142195,85.179891703707398,93.073714978115106,88.576997718556697,103.056011346747,86.876765468269795,97.915254329167098,120.92294779354,91.729422007933493,87.507250326145197,90.446314189239502,84.163603713429097,96.654284613416394,95.703553478524995,88.768220041895901,92.139716311616397,108.003012055173,80.389352250535396,99.803044882888898,90.029189757646606,93.938781560320706,103.708634307566,77.109254019279902,117.55716307788001,79.833532962732306,83.616442109984604,88.731396852190997,82.783617740158306,86.876765468269795,88.731396852190997,92.240890608288794,90.551775546613598,84.141465610485795,93.073714978115106,85.834867732862705,98.855977767901805,95.512331155185805,101.06767861854399,85.932378009630796,82.783617740158306,98.664755444562601,82.149468862378498,85.615795752519105,79.437629829187202,75.336815703173897,80.8921631665322,115.771169861628,97.159104003339394,80.8921631665322,79.505527982828994,98.012132483743898,108.866496608185,80.698599544937906,100.747432341528,91.098937150058205,82.985957252109202,89.715287156882994,131.01070551954601,124.514634617453,91.610405750413406,92.990391723684297,91.883821141567793,88.690981156173294,126.09350931196499,84.985310894643703,82.985957252109202,101.795041630996,100.243630139074,110.013482886319,88.576997718556697,106.742042339422,95.292140600993207,108.313250636032,110.33138786508,116.829800065428,86.685543144930605,96.856624125367304,90.248261737990305,89.290805830862894,74.230245121057493,91.883821141567793,96.4607209918222,97.403785728811897,131.53329130851199,78.244558267078304,127.67571659118801,124.514634617453,80.464017820607694,74.860729978932795,84.877411825735294,92.990391723684297,94.859708194367101,96.856624125367304,91.253336283692406],\"y\":[27,25,27,25,27,18,20,23,24,19,23,24,27,26,24,26,23,26,20,17,21,26,20,23,19,27,21,22,24,22,27,23,27,22,27,22,27,25,22,25,21,24,22,24,27,28,21,23,26,28,24,27,24,29,23,21,21,21,24,23,26,17,24,25,22,25,20,24,23,25,23,20,20,24,24,26,22,25,20,21,19,20,24,24,28,24,25,20,23,24,23,23,19,22,20,28,23,24,22,26,27,24,22,24,22,24,21,19,24,27,28,25,22,26,23,26,24,23,20,24,26,27,23,20,26,23,20,19,19,25,22,28,23,23,20,25,26,25,24,22,24,28,23,26,25,26,21,22,26,19,24,29,28,26,20,21,26,23,25,21,20,21,22,24,26,25,21,29,20,21,22,23,27,22,20,19,28,19,24,28,24,21,22,24,18,25,19,24,19,19,18,21,22,25,23,22,20,23,20,20,23,20,29,23,26,22,21,20,23,25,18,23,19,21,19,22,21,23,22,25,20,25,21,24,24,25,23,22,26,21,20,21,26,28,23,25,21,22,26,21,29,21,17,21,24,19,23,26,24,22,22,25,19,22,17,18,24,23,22,19,23,26,25,22,19,22,23,20,20,24,25,23,25,21,19,21,26,20,23,20,23,22,20,21,19,23,19,20,21,25,22,23,25,20,25,22,22,25,22,23,22,18,21,26,22,21,20,24,21,19,21,27,23,25,21,23,23,24,19,26,23,20,18,25,19,22,27,20,21,19,21,24,18,22,22,22,23,20,28,26,19,27,21,23,24,19,22,19,23,19,24,23,22,19,19,18,22,29,20,19,26,23,22,24,21,21,25,22,19,25,22,21,24,21,18,19,23,22,20,22,23,20,19,26,23,22,21,27,22,27,24,28,26,19,23,21,20,19,23,22,23,25,28,26,19,21,24,26,23,23,22,18,19,26,22,23,21,18,21,25,25,26,23,21,27,29,23,21,25,21,23,24,21,25],\"z\":[65,98,85,83,115,98,69,106,102,95,91,58,84,78,102,110,102,99,105,101,102,115,100,87,99,96,72,78,77,98,69,130,109,106,92,100,107,86,90,110,107,113,65,102,103,111,42,100,67,92,100,110,56,107,97,56,95,78,76,86,79,81,79,79,56,52,63,80,87,88,92,100,94,117,102,107,99,73,56,78,94,110,109,86,92,91,123,102,105,114,96,66,104,108,84,83,83,92,109,95,93,114,106,87,65,95,61,73,112,113,49,105,122,96,97,94,117,136,85,116,106,99,94,89,119,112,104,92,86,69,45,57,94,104,89,144,52,102,106,98,97,94,111,100,105,90,98,121,106,121,102,64,99,81,69,84,104,104,107,88,67,103,94,109,94,98,102,104,114,87,102,77,109,94,93,86,97,97,88,103,87,87,90,65,111,109,87,58,87,113,64,78,97,95,75,91,99,108,95,100,85,97,108,90,100,82,94,95,119,98,100,112,136,122,126,116,98,94,93,90,70,110,104,83,99,81,104,109,113,95,74,81,89,93,102,95,85,97,92,78,104,120,83,105,68,104,80,120,94,81,101,61,68,110,89,98,113,50,57,86,83,106,106,104,78,99,91,40,42,69,84,58,42,72,80,58,52,101,63,73,68,60,69,73,75,20,56,49,71,46,54,54,44,74,58,46,76,43,60,58,89,43,94,88,79,87,46,95,92,42,62,52,101,97,85,98,94,90,72,92,75,83,64,101,82,77,101,50,90,103,96,50,47,73,62,77,64,52,61,86,41,83,64,83,116,100,42,74,76,92,98,96,67,84,111,41,68,107,82,89,83,73,74,94,58,76,61,38,100,84,99,86,94,90,50,112,58,87,76,68,110,88,87,54,49,56,79,82,80,60,102,87,42,119,84,86,113,72,104,94,78,80,67,104,96,65,64,95,56,75,91,106,76,90,108,86,85,104,87,41,106,76,100,89,42,102,104,59,93,94,76,50,88,70],\"type\":\"scatter3d\",\"mode\":\"markers\",\"marker\":{\"color\":\"#00998a\",\"opacity\":0.69999999999999996,\"size\":1,\"symbol\":105,\"line\":{\"color\":\"rgba(255,127,14,1)\"}},\"error_y\":{\"color\":\"rgba(255,127,14,1)\"},\"error_x\":{\"color\":\"rgba(255,127,14,1)\"},\"line\":{\"color\":\"rgba(255,127,14,1)\"},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n\n3D-Visualisierung von m10.9 (zwei Pr√§diktoren)\n:::\n:::\n\n\n\n\n\n\n### Visualisierung mit Farbe statt 3. Dimension\n\n3D-Visualisierungen haben Vorteile, aber auch Nachteile;\n@fig-m109-color zeigt eine alternative Visualisierung,\nin der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m109-color_739b2b97a7824f274bf9e28256da4c5c'}\n::: {.cell-output-display}\n![Modell m10.9; die Farbverl√§ufe zeigen der Wert der abh√§ngigen Variablen](1000-metrische-AV_files/figure-html/fig-m109-color-1.png){#fig-m109-color width=672}\n:::\n:::\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farb√§nderung) die Ver√§nderung f√ºr die AV (kid_score). Auf der Achse f√ºr `mom_age` sieht man, dass sich die AV kaum √§ndert, wenn sich `mom_age` √§ndert.\n\n\n\n\n### Visualisierung in 10 Dimensionen\n\n@fig-ten-dims visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n::: {.cell layout-align=\"center\" hash='1000-metrische-AV_cache/html/fig-ten-dims_a4415ec8275299dfc973a03a02d26321'}\n::: {.cell-output-display}\n![So sieht der Zusammenhang im 10-dimensionalen Raum aus](1000-metrische-AV_files/figure-html/fig-ten-dims-1.png){#fig-ten-dims fig-align='center' width=50%}\n:::\n:::\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schw√§chen, eine gro√üe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\n\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n\n\n\n\n\n\n### Relevanz der Pr√§diktoren\n\n\nWoher wei√ü man,\nwelcher Pr√§diktor am st√§rksten mit der AV zusammenh√§ngt?\nMan k√∂nnte auch sagen: Welcher Pr√§diktor (welche UV) am \"wichtigsten\" ist\noder den \"st√§rksten Einfluss\" auf die AV aus√ºbt?\nBei solchen kausal konnotierten Ausdr√ºcken muss man vorsichtig sein:\nDie Regressionsanalyse als solche ist keine Kausalanalyse.\nDie Regressionsanalyse - wie jede statistische Methoden - kann\nf√ºr sich *nur Muster in den Daten*, also Zusammenh√§nge bzw. Unterschiede,\nentdecken, s. @fig-how-would-i-know.\n\n\n![Made at imgflip.com](img/5sps62.jpg){#fig-how-would-i-know width=50%}\n\n\n\n\n\n\n\n\nWelcher Pr√§diktor ist nun \"wichtiger\" oder \"st√§rker\" in Bezug auf den Zusammenhang mit der AV, `mom_iq` oder `mom_age` (Modell `m10.9`)?\n\n- `mom_iq` hat den gr√∂√üeren Koeffizienten.\n- `mom_age` hat weniger Streuung.\n\n\nUm die Relevanz der Pr√§diktoren vergleichen zu k√∂nnen, m√ºsste man vielleicht die Ver√§nderung von `kid_score` betrachten, wenn man von kleinsten zum gr√∂√üten Pr√§diktorwert geht.\nAllerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden).\nSinnvoller ist es daher, die Ver√§nderung in der AV zu betrachten, wenn man den Pr√§diktor von \"unterdurchschnittlich\" auf \"√ºberdurchschnittlich\" √§ndert.\nDas kann man mit *z-Standardisierung* erreichen.\n\n\n\n\n\n\n\n### z-Standardisierung\n\n\n\n\n*z-Standardisierung* bedeutet, eine Variable so zu transformieren, dass sie √ºber einen Mittelwert von 0 und eine SD von 1 verf√ºgt:\n\n$$z = \\frac{x - \\bar{x}}{sd(x)}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq2 <- \n  kidiq %>% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% \n  select(mom_iq, mom_iq_z) %>% \n  head()\n```\n:::\n\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten^[am n√ºtzlichsten ist diese Standardisierung bei normal verteilten Variablen.].\nDie Standardisierung ist √§hnlich zur Vergabe von Prozentr√§ngen: \"Dieser Messwert geh√∂rt zu den Top-3-Prozent\".\nDiese Aussage ist bedeutsam f√ºr Variablen mit verschiedenem Mittelwert und Streuung.\nSo werden vergleichende Aussagen f√ºr verschiedene Verteilungen m√∂glich.\n\n\n\n\n\n\n### Statistiken zu den z-transformierten Variablen\n\n@tbl-kidiq1 zeigt die Verteilung der (metrischen) Variablen im Datensatz `kidiq`.\n\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\n- der Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Auspr√§gung bezieht)\n- Interaktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\n- Prioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\n- die Effekte verschiedener Pr√§diktoren sind einfacher in ihrer Gr√∂√üe zu vergleichen, da dann mit gleicher Skalierung/Streuung\n- kleine und √§hnlich gro√üe Wertebereich erleichtern dem Golem die Rechenarbeit\n\n\nMan kann die z-Transformation (\"Skalierung\") mit `standardize` (aus `easystats`) durchf√ºhren, s. @tbl-kidiq-z.\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/kidiq-stand_7869da1eeb7ee4ef488e42de4908c759'}\n\n```{.r .cell-code}\nkidiq_z <- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n```\n:::\n\n::: {#tbl-kidiq-z .cell tbl-cap='z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)' hash='1000-metrische-AV_cache/html/tbl-kidiq-z_8d050c7a799d4a1fcb8b1bcc5e232fa5'}\n::: {.cell-output-display}\n\n\n| kid_score| mom_hs|mom_iq | mom_age| kid_score_z| mom_hs_z| mom_iq_z| mom_age_z|\n|---------:|------:|:------|-------:|-----------:|--------:|--------:|---------:|\n|        65|      1|121.12 |      27|       -1.07|     0.52|     1.41|      1.56|\n|        98|      1| 89.36 |      25|        0.55|     0.52|    -0.71|      0.82|\n|        85|      1|115.44 |      27|       -0.09|     0.52|     1.03|      1.56|\n|        83|      1| 99.45 |      25|       -0.19|     0.52|    -0.04|      0.82|\n|       115|      1| 92.75 |      27|        1.38|     0.52|    -0.48|      1.56|\n|        98|      0|107.90 |      18|        0.55|    -1.91|     0.53|     -1.77|\n\n\n:::\n:::\n\n\n\nDer Schalter `append = TRUE` sorgt daf√ºr, dass die urspr√ºnglichen Variablen beim z-Standardisieren nicht √ºberschrieben werden, sondern angeh√§ngt werden (mit einem Suffix `_z`).\n\n\nMan kann auch nur einzelne Variablen mit `standardize` standardisieren, indem man das Argument `select` nutzt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n```\n:::\n\n\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. @tbl-scale-manual.\nDazu verwendet man den Befehl `scale()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n```\n:::\n\n::: {#tbl-scale-manual .cell tbl-cap='Z-Standardisierung ohne Extrapaket\"'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"kid_score\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"mom_hs\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"mom_iq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mom_age\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"pred_m10.9\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mom_iq_z2\"],\"name\":[6],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]},{\"label\":[\"mom_age_z2\"],\"name\":[7],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]},{\"label\":[\"kid_score_z2\"],\"name\":[8],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"65\",\"2\":\"1\",\"3\":\"121.11753\",\"4\":\"27\",\"5\":\"101.23962\",\"6\":\"1.4078352\",\"7\":\"1.5602285\",\"8\":\"-1.06793237\",\"_rn_\":\"1\"},{\"1\":\"98\",\"2\":\"1\",\"3\":\"89.36188\",\"4\":\"25\",\"5\":\"81.30792\",\"6\":\"-0.7092079\",\"7\":\"0.8197811\",\"8\":\"0.54886757\",\"_rn_\":\"2\"},{\"1\":\"85\",\"2\":\"1\",\"3\":\"115.44316\",\"4\":\"27\",\"5\":\"97.81739\",\"6\":\"1.0295443\",\"7\":\"1.5602285\",\"8\":\"-0.08805362\",\"_rn_\":\"3\"},{\"1\":\"83\",\"2\":\"1\",\"3\":\"99.44964\",\"4\":\"25\",\"5\":\"87.39188\",\"6\":\"-0.0366907\",\"7\":\"0.8197811\",\"8\":\"-0.18604150\",\"_rn_\":\"4\"},{\"1\":\"115\",\"2\":\"1\",\"3\":\"92.74571\",\"4\":\"27\",\"5\":\"84.12848\",\"6\":\"-0.4836193\",\"7\":\"1.5602285\",\"8\":\"1.38176451\",\"_rn_\":\"5\"},{\"1\":\"98\",\"2\":\"0\",\"3\":\"107.90184\",\"4\":\"18\",\"5\":\"89.76025\",\"6\":\"0.5267892\",\"7\":\"-1.7717849\",\"8\":\"0.54886757\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n\n\n\n## `y_c ~ x1_c + x2_c`\n\n\n### AV z-transformieren\n\nIn diese Abschnitt berechnen wir ein Modell (Modell `m10.10`), in dem die Pr√§diktoren z-transformiert sind (standardisiert) *und* die *AV* ebenfalls.\nDas Standardisieren der AV, `kid_score` ist zwar *nicht* n√∂tig, um den Effekt der Pr√§diktoren (UV) auf die AV zu untersuchen.\nStandardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage dar√ºber,\num wie viele *SD-*Einheiten sich die AV ver√§ndert, wenn sich ein Pr√§diktor um eine *SD-*Einheit ver√§ndert.\nDas kann auch eine interessante(re) Aussage sein.\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-10_7de908bf8e907b0f5bdd3fed1bd86877'}\n\n```{.r .cell-code}\nm10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.10)\n## (Intercept)    mom_iq_z   mom_age_z \n## 0.001554359 0.443843346 0.050380199\n```\n:::\n\n\n\n- Der *Achsenabschnitt* gibt den Mittelwert der AV (`kid_score`) an, da `kid_score_z = 0` identisch ist zum Mittelwert von  `kid_score`.\n- Der Koeffizient f√ºr `mom_iq_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) √§ndert, wenn sich `mom_iq` um eine SD-Einheit √§ndert. \n- Der Koeffizient f√ºr `mom_age_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) √§ndert, wenn sich `mom_age` um eine SD-Einheit √§ndert.\n\n\n\nJetzt sind die Pr√§diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar: \n\n- Man sieht, dass die Intelligenz der Mutter *deutlich wichtiger* ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n\n\n### 95%-PI\n\n\nMit `parameters` k√∂nnen wir uns ein PI f√ºr `m10.10` ausgeben lassen, s. @fig-m1010hdi;\n im Standard wird ein 95%-ETI berichtet^[Zumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen k√∂nnen sich √§ndern. Am besten in der Dokumentation nachlesen: `?parameters`.].\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-10-params-noeval_2f388bf194bbb3c402153ffaa61be670'}\n\n```{.r .cell-code}\nparameters(m10.10) \n```\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/m1010-params_3118d891a51924e65fad01648be897cb'}\n::: {.cell-output-display}\n\n\n|Parameter   |   Median |        95% CI |     pd |  Rhat |     ESS |                      Prior |\n|:-----------|:--------:|:-------------:|:------:|:-----:|:-------:|:--------------------------:|\n|(Intercept) | 1.55e-03 | (-0.08, 0.08) | 51.12% | 0.999 | 4683.00 | Normal (-2.81e-16 +- 2.50) |\n|mom_iq_z    |     0.44 |  (0.36, 0.53) |   100% | 1.000 | 5372.00 |      Normal (0.00 +- 2.50) |\n|mom_age_z   |     0.05 | (-0.03, 0.14) | 88.33% | 0.999 | 4779.00 |      Normal (0.00 +- 2.50) |\n\n\n:::\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-m1010hdi_bb5070de99c2e787f065118924c76938'}\n\n```{.r .cell-code}\nplot(eti(m10.10)) + scale_fill_okabeito()\n```\n\n::: {.cell-output-display}\n![Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI f√ºr m10.10](1000-metrische-AV_files/figure-html/fig-m1010hdi-1.png){#fig-m1010hdi width=672}\n:::\n:::\n\n\n\n\n### Modellg√ºte\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-10-r2_d02a04b95c7741c1cc7e52b275df84c3'}\n\n```{.r .cell-code}\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.204 (95% CI [0.142, 0.268])\n```\n:::\n\n\n\nIst dieser Wert von $R2$ \"gut\"?\nDiese Frage ist √§hnlich zur Frage \"Ist das viel Geld?\"; \nman kann die Frage nur im Kontext beantworten.\n\nEine einfache L√∂sung ist immer, Modelle zu vergleichen.\nDann kann man angeben, welches Modell die Daten am besten erkl√§rt,\nz.B. auf Basis von $R^2$.\n\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte.\nVergleicht man viele Modelle aufs Geratewohl, so muss man von zuf√§llig hohen Werten der Modellg√ºte im Einzelfall ausgehen.\n\n\nWenn Sie aber unbedingt eine \"objektive\" Antwort auf die Frage \"wie viel ist viel?\" haben wollen,\nziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage \"Wieviel ist viel?\" gegeben hat [@cohen_power_1992]:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n```\n:::\n\n\nDanke, Herr Cohen!\n\n\n### Priori-Verteilung f√ºr `m10.10` und Modelldefinition\n\nStan hat f√ºr uns folgende Prioris ausgesucht:\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-10-prior_3eaf80d295277c49ccd9063439f7211e'}\n\n```{.r .cell-code}\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n```\n:::\n\n\n\n>   ü§ñ  Nix zu danken!\n\nWie gesagt, Stan nimmt daf√ºr einfach die empirischen Mittelwerte und Streuungen her^[Nicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Sch√§tzer der echten Parameter sein m√ºssten, wenn die Stichprobe, die wir ihm angeschleppt h√§tten, tats√§chlich gut ist...].\n\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. @eq-m1010.\n\n\n$$\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n$${#eq-m1010}\n\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird:\nBei *mittlerer* Intelligenz und *mittlerem* Alter der Mutter wird *mittlere* Intelligenz des Kindes erwartet in `m10.10`. \nDadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\n\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition *zumindest* im Anhang aufzuf√ºhren.\n\n\n:::{#exm-anz-mod-m1010}\n### Anzahl der Modellparameter\nWie viele Modellparameter hat `m10.10`?^[4: $\\alpha, \\beta_1, \\beta_2, \\sigma$]\n\n### Beantwortung der Forschungsfrage\n\n\n\n>   Das Modell spricht sich klar f√ºr einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erk√§rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm [@goodrich_rstanarm_2020] zur√ºck (s. Anhang f√ºr Details).\n\n\n\n:::callout-important\nHier wird von einem \"statistischen Effekt\" gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenh√§nge, und nicht um kausale Zusammenh√§nge, handelt.\nKausale Zusammenh√§nge d√ºrfen wir nur verk√ºnden, \nwenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege daf√ºr finden oder c) wir ein  Experiment fachgerecht durchgef√ºhrt haben.\n:::\n\n\n\n\n\n\n## Vertiefung\n\n\nüèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è\n\n\n\n\n\n\n\n\n### Verwandtheit von Korrelation und Regression\n\n\n Sind X und Y *z-standardisiert*, so sind Korrelation und Regression identisch, s. @eq-br.\n\n\n$$b = r \\frac{sd_x}{sd_y}$${#eq-br}\n\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen \nund betrachten die Punktsch√§tzer f√ºr die Regressionskoeffizienten:\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-11_4c1453eb5982bf7aea1c0d6f6f9bdc6d'}\n\n```{.r .cell-code}\nm10.11 <- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.11)\n##  (Intercept)     mom_iq_z \n## 0.0002786206 0.4483327620\n```\n:::\n\n\nVergleichen Sie diese Werte mit der Korrelation, s. @tbl-m10.11-corr.^[Ignorieren Sie die Zeile mit dem Befehl `display()`. Dieser Befehl dient nur dazu, die Ausgabe zu versch√∂nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.]\n\n\n::: {#tbl-m10.11-corr .cell hash='1000-metrische-AV_cache/html/tbl-m10.11-corr_facd239cbcfe68b04710490911904ab0'}\n\n```{.r .cell-code}\nkidiq_z %>% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% \n  correlation() |> \n  display()\n```\n\n::: {.cell-output-display}\n\n\nTable: Correlation Matrix (pearson-method)\n\n|Parameter1  |  Parameter2 |    r |       95% CI | t(432) |         p |\n|:-----------|:-----------:|:----:|:------------:|:------:|:---------:|\n|kid_score   |      mom_iq | 0.45 | (0.37, 0.52) |  10.42 | < .001*** |\n|kid_score   | kid_score_z | 1.00 | (1.00, 1.00) |    Inf | < .001*** |\n|kid_score   |    mom_iq_z | 0.45 | (0.37, 0.52) |  10.42 | < .001*** |\n|mom_iq      | kid_score_z | 0.45 | (0.37, 0.52) |  10.42 | < .001*** |\n|mom_iq      |    mom_iq_z | 1.00 | (1.00, 1.00) |    Inf | < .001*** |\n|kid_score_z |    mom_iq_z | 0.45 | (0.37, 0.52) |  10.42 | < .001*** |\np-value adjustment method: Holm (1979)\nObservations: 434\n\n\n\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n:::\n:::\n\n\n\n\n\n\n\n### Pr√ºfen der Linearit√§tsannahme\n\n\nZentrale Annahme eines linearen Modells: Die AV ist eine *lineare* Funktion der einzelnen Pr√§diktoren, s. @eq-lm1.\n\n$$y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots $${#eq-lm1} \n\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist.\nZwar nimmt die Regression h√§ufig normalverteilte Residuen an^[was auf normal verteilte AV hinauslaufen kann aber nicht muss], aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu sch√§tzen [@gelman_regression_2021].\n\n\n\n\n\nIst die Linearit√§tsannahme erf√ºllt, so sollte der Residualplot nur *zuf√§llige* Streuung um $y=0$ herum zeigen, s. @fig-kidiqresiduum.\n\n\nEin Residuum $e$ ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tats√§chlichem Wert:\n\n\n$e_i = y_i - \\hat{y}_i$\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/kidiq-def_2facc87728b04cddbcb60ea294c8fcb6'}\n\n```{.r .cell-code}\nkidiq <-\n  kidiq %>% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n```\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-kidiqresiduum_63d3dddb90e94c2600106b8c79dc684f'}\n\n```{.r .cell-code}\nkidiq %>% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n```\n\n::: {.cell-output-display}\n![Die Verteilung der Fehler scheint keinem starken Trend (in Abh√§ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.](1000-metrische-AV_files/figure-html/fig-kidiqresiduum-1.png){#fig-kidiqresiduum width=672}\n:::\n:::\n\n\nHier erkennt man keine gr√∂√üeren Auff√§lligkeiten.\n\n\n\n\n\n\n\n### Modellpr√ºfung mit der PPV\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m10-10-pp-check_1862acffd7bfa75debc4db63079f028c'}\n\n```{.r .cell-code}\npp_check(m10.10)\n```\n\n::: {.cell-output-display}\n![](1000-metrische-AV_files/figure-html/m10-10-pp-check-1.png){width=672}\n:::\n:::\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, $y_{rep}$ verfehlt den Mittelwert von $y$ leider recht h√§ufig.\n\n\n\n\n\n### Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/comp-resid-lm-plot-kidiq3_62b0a702e9d1095e92aaa35a913d6e9b'}\n\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-bereinigt_02cd5173dd97743e5bb0ea67804f284a'}\n::: {.cell-output-display}\n![Bereinigte Regressionskoeffizienten](1000-metrische-AV_files/figure-html/fig-bereinigt-1.png){#fig-bereinigt width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n@fig-bereinigt zeigt in der oberen Reihe die Regression eines Pr√§diktors auf den anderen Pr√§diktor.\nUntere Reihe: Regression der Residuen der oberen Reihe auf die AV, `kid-score_z`. \nUnten links (C): Die Residuen von `mom_iq_c` sind kaum mit der AV assoziiert. Das hei√üt, nutzt man den Teil von `mom_age_z`, der nicht mit `mom_iq_z` zusammenh√§ngt, um `kid_score` vorher zusagen, findet man keinen (*kaum*) Zusammenhang.\nUnten rechts (D): Die Residuen von `mom_age_c` sind *stark* mit der AV assoziiert. Das hei√üt, nutzt man den Teil von `mom_iq_z`, der nicht mit `mom_age_z` zusammenh√§ngt, um `kid_score` vorher zusagen, findet man einen starken Zusammenhang.\n\n\n\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n\n\n\n\n\n### Bayesianisch gleich Frequentistisch?\n\n\n\n\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/mtcars2_6484845bfc8be0eaab98df2f4c257b65'}\n\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/comp-resid-lm-plot_50dd551cdeab9724bf343da2fa1f6fb6'}\n\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/fig-resid-lm-plot_ea31c1ffc01a54604782052bb6435415'}\n\n:::\n\n\n\n√úbrigens liefern `stan_glm()` und `lm` oft √§hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/stan-vs-lm_cd0abfc3fa316ece56231ccfbef74235'}\n\n```{.r .cell-code}\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %>% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n```\n:::\n\n\n\n:::callout-important\nWenn auch die  Ergebnisse eines Frequentistischen und Bayes-Modell numerisch √§hnlich sein k√∂nnen, so ist doch die Interpretation grundverschieden. \nBayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.\n:::\n\n\n\n\n\n\n\n## Fazit\n\n\n### Austieg: Bayes in f√ºnf Minuten\n\n\nEine Kurzdarstellung des Bayes-Inferenz findet sich [in diesem Post](https://data-se.netlify.app/2022/01/27/bayes-in-f%C3%BCnf-minuten/) und in [diesem](https://data-se.netlify.app/2022/01/28/bayes-in-f%C3%BCnf-minuten-f%C3%BCr-fortgeschrittene/).\n\n\nüì∫ [Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars](https://www.youtube.com/watch?v=Yoo8IcmwRWg)\n\nüì∫ [Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress](https://www.youtube.com/watch?v=5A5bDNeB6sA)\n\n\n\n### Ausblick: Bin√§re AV\n\n\n>    *Forschungsfrage:* Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart? (Datensatz `mtcars`)\n\n\nDazu nutzen wir den Datensatz `mtcars`, wobei wir die Variablen z-standardisieren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mtcars)\nmtcars2 <-\n  mtcars %>% \n  standardize(append = TRUE)\n```\n:::\n\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: `m13: am ~ mpg_z`:\n\n\n::: {.cell hash='1000-metrische-AV_cache/html/m13_ed82c7632a10bcb91f0b76fe569892b0'}\n\n```{.r .cell-code}\nm13 <-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n```\n:::\n\n\nAb  `mpg_z = 0.41, 0.3` sagt das Modell `am=1` (manuell) vorher. Ganz ok.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars2 %>% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n```\n\n::: {.cell-output-display}\n![](1000-metrische-AV_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='1000-metrische-AV_cache/html/neg-am-predict_c0eb9b15e0245520af6d2648ec95ee08'}\n\n```{.r .cell-code}\nneg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))\n```\n:::\n\n\n\nF√ºr kleine Werte von `mpg_z` (<1.3) sagt unser Modell *negative* Werte f√ºr `am` voraus. Das macht keinen Sinn: Es gibt keine negative Werte von `am`, nur 0 und 1.\nM√ºssen wir mal bei Gelegenheit besser machen.\n\n\n\n\n\n\n\n\n### Genug f√ºr heute\n\n\n\nWir waren flei√üig ... \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://media.giphy.com/media/XIqCQx02E1U9W/giphy.gif)\n:::\n:::\n\n\n[Quelle](https://giphy.com/gifs/XIqCQx02E1U9W)\n\n\n\n\n\n\n\n:::callout-important\nKontinuierliches Lernen ist der Schl√ºssel zum Erfolg.\n:::\n\n\nGenug f√ºr heute. üëç \n\n\n### Weiterf√ºhrende Literatur\n\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei @gelman_regression_2021, Kap. 10, insbesondere 10.3.\n\n@gelman_regression_2021 bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit f√ºhrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig √ºberschaubarem mathematischen Aufwand. \n\nF√ºr das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.\n\n\n\n## Aufgaben\n\n\n1. [Anova-skalenniveau](https://datenwerk.netlify.app/posts/anova-skalenniveau/anova-skalenniveau.html)\n2. [Nullhyp-Beispiel](https://datenwerk.netlify.app/posts/nullhyp-beispiel/nullhyp-beispiel)\n1. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau.html)\n2. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz)\n3. [Interaktionseffekt1](https://datenwerk.netlify.app/posts/interaktionseffekt1/interaktionseffekt1)\n1. [Regression2](https://datenwerk.netlify.app/posts/regression2/regression2)\n2. [Regression3](https://datenwerk.netlify.app/posts/regression3/regression3)\n<!-- 3. [Regression6](https://datenwerk.netlify.app/posts/regression6/regression6) -->\n<!-- 1. [posterior_interval](https://datenwerk.netlify.app/posts/posterior_interval/posterior_interval.html) -->\n2. [diamonds-nullhyp-mws](https://datenwerk.netlify.app/posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html)\n3. [stan_glm_parameterzahl](https://datenwerk.netlify.app/posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html)\n1. [stan_glm_prioriwerte](https://datenwerk.netlify.app/posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html)\n2. [zwert-berechnen](https://datenwerk.netlify.app/posts/zwert-berechnen/zwert-berechnen.html)\n3. [Regr-Bayes-interpret](https://datenwerk.netlify.app/posts/regr-bayes-interpret/regr-bayes-interpret)\n3. [Regr-Bayes-interpret03](https://datenwerk.netlify.app/posts/regr-bayes-interpret03/regr-bayes-interpret03)\n3. [Regr-Bayes-interpret02](https://datenwerk.netlify.app/posts/regr-bayes-interpret03/regr-bayes-interpret02)\n3. [rope4](https://datenwerk.netlify.app/posts/rope4/rope4.html)\n\n\n\n\n\n## ---\n\n\n\n![](img/outro-10.jpg){width=100%}\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/htmlwidgets-1.6.2/htmlwidgets.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.3/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}