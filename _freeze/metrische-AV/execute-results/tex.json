{
  "hash": "576959ca412d0362393419914af2734d",
  "result": {
    "markdown": "\n# Forschungsfragen mit metrischer AV\n\n\n\n## Lernsteuerung\n\n\n### R-Pakete\n\nBenötigte R-Pakete für dieses Thema:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages(\"rstanarm\")\n## [1] \"rstanarm\"\n#| message: false\n#| results: \"hide\"\n#| warnings: false\nlibrary(rstanarm)\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.\n\nSie können... \n\n- typische, deskriptive Forschungsfragen spezifizieren als Regression\n- Forschungsfragen in Regressionsterme übersetzen\n- typische Forschungsfragen auswerten\n\n\n\n## Wissenschaft als Gerechtigkeitsprojekt\n\n### Meinungen als Grundlage der Konfliktlösung ?\n\n\nContra:\n\n- \"Ich find Masken doof!\"\n- \"Impfen ist schädlich!\"\n- \"Corona gibt's gar nicht!\"\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nPro:\n\n- \"Ich find Masken gut!\"\n- \"Impfen ist nützlich!\"\n- \"Corona ist gefährlich!\"\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\nMeinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte können auf Basis von Meinungen nur schwer gelöst werden.\n\n\n\n\n\n### Fakten als Grundlage der Konfliktlösung\n\nWissenschaft produziert Fakten.\nDa Fakten universell sind (sein können), ist Wissenschaft potenziell ein Weg zur Konfliktlösung.\nWarum helfen Fakten bei Konflikten?\n\n\nFakten sind neutral gegenüber Personen.\nFakten bieten daher eine Chance zur fairen Einigung.\n\n\nWann ist ein Fakt ein Fakt?\n\n\n Fakten müssen vor allem nachprüfbar sein (Daten, Analyse und Bericht müssen offen zugänglich sein).\n\n\n\n### Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung\n\n\n\n\n>    The effectiveness of full messenger RNA (mRNA) vaccination (≥14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.\n\n@thompson_effectiveness_2021; vgl. auch @nasreen_effectiveness_2021; @pormohammad_efficacy_2021\n\n\n\nDrei Anforderungen an die Qualität von Studien:\n\n1. *handwerklich gut*:  z.B. vergleichbare Gruppen, genaue Messinstrumente\n2. *bescheiden*: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche Qualität der Studie zulässt. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage berücksichtigt. \n3. *transparent*: Das Vorgehen, die Hintergründe und Ziele werden offengelegt. Das betrifft auch möglich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen\n\n\n\n### Psychologische Intervention zur Erhöhung der Impfquote\n\n@dai_behavioural_2021 zeigen den Effekt einer psychologischen Intervention zur Erhöhung der Impfquote, s. @fig-dai.\n\n\n>   Here we present two sequential randomized controlled trials to test the effect of behavioural interventions on the uptake of COVID-19 vaccines. ... We designed text-based reminders that make vaccination salient and easy, and delivered them to participants drawn from a healthcare system one day (first randomized controlled trial) (n = 93,354 participants; clinicaltrials number NCT04800965) and eight days (second randomized controlled trial) (n = 67,092 individuals; clinicaltrials number NCT04801524) after they received a notification of vaccine eligibility. The first reminder boosted appointment and vaccination rates within the healthcare system by 6.07 (84%) and 3.57 (26%) percentage points, respectively; the second reminder increased those outcomes by 1.65 and 1.06 percentage points, respectively. The first reminder had a greater effect when it was designed to make participants feel ownership of the vaccine dose.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![a, b, Proportion of participants in each condition who scheduled an appointment for the first dose of the COVID-19 vaccine at UCLA Health between 15:00 h on the first reminder date and 23:59 h on the fifth day following the first reminder date (a) and the proportion of participants in each condition who obtained the first dose of the COVID-19 vaccine at UCLA Health within four weeks of the first reminder date (b). Error bars represent ± 1 s.e.m. The number of participants in each condition (from left to right in each panel) is 18,629, 18,592, 18,757, 18,627 and 18,749.](img/41586_2021_3843_Fig2_HTML.png){#fig-dai width=100%}\n:::\n:::\n\n\n\n[Quelle/Volltext](https://www.nature.com/articles/s41586-021-03843-2)\n\n\n\n\n\n\n### Was heißt \"ist effektiv\"?\n\n@nasreen_effectiveness_2021  definieren *effectivity*, $e$, so:\n\n\n\n$$e = 1 - C; C= \\frac{n_{vacc|pos}}{n_{vacc|neg}}$$\n\n\n- $C$ nennt man das *Chancenverhältnis* (*odds ratio*), es beschreibt einen Bruchterm: $\\frac{x}{y}$.\n- $n_{vacc|pos}$: Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose\n- $n_{vacc|neg}$: Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose\n\n\n*Beispiel*: Von den 100 Personen mit *positiver* Corona-Diagnose sind 10 geimpft, $n_{vacc|pos}=10$. Von den 100 Personen mit *negativer* Corona-Diagnose sind 90 geimpft, $n_{vacc|neg}=90$\n\n$$C= \\frac{10}{90} = \\frac{1}{9}; e = 1 - \\frac{1}{9} = \\frac{8}{9} \\approx 0.88$$\n\n\nIn diesem Beispiel liegt die Effektvitität $e$ bei knapp 90%.\n\n\n## Arten von Forschungsfragen\n\n\n### Nach dem Erkenntnisziel\n\n*Deskriptiv* (beschreibend)\n\n- Wie stark ist der (lineare) Zusammenhang $r$ von Größe und Gewicht?\n- Wie stark ist der (lineare) Zusammenhang $b$ von Lernzeit und Note?\n- Bevorzugen unsere Kunden Webshop A oder B?\n\n\n\n*Prädiktiv* (prognostisch, vorhersagend)\n\n- Wie schwer ist ein deutscher Mann der Größe 1,80m im Schnitt?\n- Welche Note kann man erwarten, wenn man nichts für die Klausur lernt?\n- Wieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhält?\n\n\n\n*Präskriptiv* (erklärend, kausal)\n\n- Ist Größe eine Ursache von Gewicht (bei deutschen Männern)?\n- Wenn ich 100 Stunden lerne, welche Note schreibe ich dann?\n- Hat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n### Nach dem Skalenniveau\n\n\n\n\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit *metrischer* AV. Andere Skalenniveaus bei der AV klammern wir aus.\n\nFür die UV(s) sind nominale und metrische Skalenniveaus erlaubt. \nModelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.\n\n\n\n\n## Eine binäre UV\n\n\n\n### Forschungsfrage\n\n*Hintergrund:*\n\nEine Psychologin, die im öffentlichen Dienst arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwändigen Studie die Intelligenz vieler Kinder gemessen. Zusätzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, \"Risikofaktoren\" für geringere Intelligenz zu entdecken.\n\n\n\n\n*Forschungsfrage:* \n\n\n>    Unterscheidet sich der mittlere IQ-Wert (`kid_score`) von Kindern in Abhängigkeit davon, ob ihre jeweilige Mutter über einen Schlusabschluss (`mom_hs`) verfügt? (ceteris paribus)\n\n\n\n\n### IQ von Kindern, binärer Prädiktor\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 <- stan_glm(\n  kid_score ~ mom_hs, \n  data = kidiq)\n```\n:::\n\n\n\nAlternativ können Sie die Daten [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/kidiq.csv) herunterladen.\n\nMit `parameters(m10.1)` bekommt man die Parameter des Modells:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Fixed effects\n\n|Parameter   | Median |         95% CI |   pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:----:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  77.58 | (73.47, 81.56) | 100% | 1.001 | 3750.00 | Normal (86.80 +- 51.03) |\n|mom_hs      |  11.78 |  (7.35, 16.30) | 100% | 1.001 | 3822.00 | Normal (0.00 +- 124.21) |\n:::\n:::\n\n\n\nIn @fig-momkid ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(kidiq) +\n  aes(x = mom_hs, y = kid_score) +\n  geom_jitter(width = 0.1, alpha = .5) +\n  geom_abline(slope = coef(m10.1)[2],\n              intercept = coef(m10.1)[1])  +\n  scale_x_continuous(breaks = c(0, 1))\n```\n\n::: {.cell-output-display}\n![Kinder, deren Mütter über einen Schulabschluss verfügen, haben im Mittel einen höheren Intelligenztestwert, laut dem vorliegenden Modell](metrische-AV_files/figure-pdf/fig-momkid-1.pdf){#fig-momkid fig-pos='H'}\n:::\n:::\n\n\n\n\n### Interpretation von `m10.1`\n\n`m10.1: kid_score = 78 + 12*mom_hs + error`\n\n- Der *Achsensabschnitt* (intercept, $\\beta_0$ oder auch mit $\\alpha$ bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren Mütter über keinen Schulabschluss (`mom_hs = 0`) verfügen:\n\n`kid_score = 78 + 0*12 + error`\n\n- Das *Regressionsgewicht* (slope, $\\beta$) ist der Unterschied im IQ-Wert von Kindern mit Mütter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit Mütter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\n`kid_score = 78 + 1*12 + error = 90 + error`\n\n- Die Größer der Konfidenzintervalle zeigt, wie genau die Schätzung (Vorhersage) ist bzw. wie stark Prädiktor (UV) und Kriterium (AV) zusammenhängen.\n\n\n\n### `m10.1` als Mittelwertsdifferenz \n\n\n- UV: binär (zweistufig nominal/kategorial)\n- AV: metrisch (quantitativ)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  group_by(mom_hs) %>% \n  summarise(kid_score_avg = \n              mean(kid_score))\n## # A tibble: 2 x 2\n##   mom_hs kid_score_avg\n##    <int>         <dbl>\n## 1      0          77.5\n## 2      1          89.3\n```\n:::\n\n\n\n\n- In der klassischen Statistik untersucht man diese Datensituation mit einem *t-Test*.\n- Der t-Test ist ein inferenzstatistisches Verfahren, dass prüft, ob die Mittelwertsdifferenz (in der Population) $\\mu_d$ Null ist: $\\mu_d = 0$.\n- In der Bayes-Statistik betrachtet man dazu die Posteriori-Verteilung (z.B. mit 95%PI).\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von Müttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.\n\n\n### Antwort auf die Forschungsfrage, `m10.1`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.1_post <-\n#| eval: false\n  m10.1 %>% \n  as_tibble() \n\nnames(m10.1_post) <- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schönere Namen\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{longtable}{rrr}\n\\caption*{\n{\\large Stichprobe aus der Post-Verteilung}\n} \\\\ \n\\toprule\nAchsenabschnitt & momhs & sigma \\\\ \n\\midrule\n$79.4$ & $9.0$ & $21.4$ \\\\ \n$81.6$ & $9.4$ & $20.2$ \\\\ \n$80.9$ & $7.3$ & $20.7$ \\\\ \n$74.3$ & $16.7$ & $19.5$ \\\\ \n$79.1$ & $9.0$ & $20.7$ \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npi_mom_hs <-\n  m10.1_post %>% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n## # A tibble: 2 x 1\n##   pi_95\n##   <dbl>\n## 1  7.35\n## 2 16.3\n```\n:::\n\n\n\n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen \nKindern von Müttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, \nlaut unserem Modell: $95\\%PI: [7,16]$.\n\nDie Hypothese, dass es keinen  Unterschied oder einen Unterschied in die andere Richtung geben sollte, \nist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\n\nVisualisieren wir abschließend die Posteriori-Verteilung, s. @fig-m101hdi.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hdi(m10.1))\n```\n\n::: {.cell-output-display}\n![Das 95% HDI zum Effekt des mütterlichen Schulabschlusses](metrische-AV_files/figure-pdf/fig-m101hdi-1.pdf){#fig-m101hdi fig-pos='H'}\n:::\n:::\n\n\n\n\n\n## Nullhypothesen sind praktisch immer falsch\n\n\n\nNullhypothesen sind fast immer falsch, s. @fig-nullmeme.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Du testest Nullhypothesen?](img/5v5531.jpg){#fig-nullmeme width=1.67in}\n:::\n:::\n\n\n\n[Quelle: Imgflip Meme Generator](https://imgflip.com/i/5v5531)\n\n\n\n\n\n\n\n>   We do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have *some* effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\n\n@gelman_regression_2021\n\n\n\n\n\n\n### Alternativen zu Nullhypothesen\n\n\n- Nullhypothesen, $H_0$, sind z.B.: $\\rho=0$, $\\rho_1 = rho_2$, $\\mu_1 = \\mu_2$, $\\mu=0$, $\\beta_1=0$.\n\n- Nullhypothesen zu testen, ist sehr verbreitet.\n\n- Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest möglich ist^[Mittlerweile gibt es Ansätze für einem Verfahren ähnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.]\n\n- Ein anderer Grund ist vermutlich, ... wir haben es schon immer so gemacht.\n\n- Alternativen zum Testen von Nullhypothesen:\n    - Posteriori-Intervalle (PI oder HDI)  berichten\n    - Rope-Konzept, @kruschke_rejecting_2018\n    - Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\n    - Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n\n\n\n\n\n## Eine metrische plus eine nominale UV \n\n\n\n\n### Forschungsfrage\n\n\n>    Wie stark ist der Zusammenhang von jeweils Schulabschluss der Mutter (`mom_hs`) und  IQ der Mutter (`mom_iq`)  auf den IQ des Kindes (`kid_score`) ?\n\n\nDeskriptive Statistiken zum Datensatz:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"kidiq\")  # Paket rstanarm, alternativ über CSV einlesen\ndescribe_distribution(kidiq)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n|Variable  |   Mean |    SD |   IQR |           Range | Skewness | Kurtosis |   n | n_Missing |\n|:---------|:------:|:-----:|:-----:|:---------------:|:--------:|:--------:|:---:|:---------:|\n|kid_score |  86.80 | 20.41 | 28.00 | (20.00, 144.00) |    -0.46 |    -0.16 | 434 |         0 |\n|mom_hs    |   0.79 |  0.41 |  0.00 |    (0.00, 1.00) |    -1.40 |    -0.05 | 434 |         0 |\n|mom_iq    | 100.00 | 15.00 | 21.67 | (71.04, 138.89) |     0.47 |    -0.57 | 434 |         0 |\n|mom_age   |  22.79 |  2.70 |  4.00 |  (17.00, 29.00) |     0.18 |    -0.63 | 434 |         0 |\n:::\n:::\n\n\n\n\n\n[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/2021-wise/main/Data/kidiq.csv)\n\n\n\n\n### 1 metrischer Prädiktor\n\n\nBerechnen wir folgendens Modell: `kid_score ~ mom_iq`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.2 <-\n  stan_glm(kid_score ~ mom_iq, data = kidiq)\n\nm10.2 %>% \n  parameters()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Fixed effects\n\n|Parameter   | Median |         95% CI |   pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:----:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  26.05 | (14.29, 37.39) | 100% | 1.001 | 3446.00 | Normal (86.80 +- 51.03) |\n|mom_iq      |   0.61 |   (0.50, 0.72) | 100% | 1.001 | 3543.00 |   Normal (0.00 +- 3.40) |\n:::\n:::\n\n\n\n\n`kid_score = 26 + 0.6 * mom_iq + error`\n\n\nVisualisieren wir uns noch das Modell, s. @fig-kidiqmomiq.\n\n\n\n\n::: {.cell fig.asp='1' fig.cao='Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter'}\n\n```{.r .cell-code}\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/fig-kidiqmomiq-1.pdf){#fig-kidiqmomiq fig-pos='H'}\n:::\n:::\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder für verschiedene IQ-Werte der Mütter.\nVergleicht man Teilpopulationen von Müttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern *im Durchschnitt*.\nDer Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n\n\n\n### Beide Prädiktoren, `m10.3`\n\n\nBerechnen wir als nächstes ein Modell mit beiden Prädiktoren: `kid_score ~ mom_hs + mom_iq`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.3 <- \n  stan_glm(\n    kid_score ~ mom_hs + mom_iq, \n    refresh = 0,\n    data = kidiq)\n```\n:::\n\n\n\n\n\n\n\nWill man nur schnell die Punktschätzer (Median) zu den Modellparametern (auch als Koeffizienten bezeichnet), so kann man anstelle von `parameters()` auch schreiben:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.3)\n## (Intercept)      mom_hs      mom_iq \n##  25.6325781   5.9343462   0.5651093\n```\n:::\n\n\n\n\n`m10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error`\n\nMöchte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.3)[3]\n##    mom_iq \n## 0.5651093\n```\n:::\n\n\n\n\nUnd die Visualisierung des Modells `m10.3`, s. @fig-m103.\n\n\n\n::: {.cell fig.asp='0.62'}\n\n```{.r .cell-code}\nkidiq %>% \n  mutate(mom_hs = factor(mom_hs)) %>%  \n  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.3)[3],  # den 3. Wert aus dem Vector, den `coef()` zurückgibt\n              intercept = 26,\n              linewidth = 1,\n              color = \"blue\") +\n  geom_abline(slope = coef(m10.3)[3],\n              intercept = 32,\n              color = \"red\",\n              linewidth = 2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![Der Effekt von sowohl mütterlicher Intelligenz als auch mütterlichem Schulabschluss](metrische-AV_files/figure-pdf/fig-m103-1.pdf){#fig-m103 fig-pos='H'}\n:::\n:::\n\n\n\n\n- *Achsenabschnitt*: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schätzt das Modell den IQ-Wert des Kindes auf 26.\n- *Koeffizient zum mütterlichen Schulabschluss*: Vergleicht man Kinder von Müttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n- *Koeffizient zur mütterlichen IQ*: Vergleicht man Kinder von Müttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.\n\n\n\n\n\n## Interaktion\n\nIn `m10.3` hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. \nBetrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen.\nSind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n:::callout-important\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.\n:::\n\nWir berechnen mit m10.4 folgendes Modell: `kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq`, s. @fig-m104.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.4 <- \n  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, \n                  data = kidiq, refresh = 0)\n\ncoef(m10.4)\n##   (Intercept)        mom_hs        mom_iq mom_hs:mom_iq \n##   -10.7693485    50.3180149     0.9609959    -0.4738657\n```\n:::\n\n::: {.cell fig.asp='0.3'}\n::: {.cell-output-display}\n![Wie m10.3, aber mit Interaktionseffekt](metrische-AV_files/figure-pdf/fig-m104-1.pdf){#fig-m104}\n:::\n:::\n\n\n\n\n\n\n### Interpretation von `m10.4`\n\n- *Achsenabschnitt:* IQ-Schätzwerte für Kinder mit Mütter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\n- `mom_hs`: Unterschied der IQ-Schätzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\n- `mom_iq`: Unterschied der IQ-Schätzwerte zwischen Kindern mit Müttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\n- *Interaktion*: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten für `mom_iq` zwischen Mütter mit bzw. ohne Schulabschluss.\n\n```\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\n```\n\n@gelman_regression_2021, Kap. 10.3\n\n\n\n\n\n### Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n<iframe src=\"https://giphy.com/embed/Zaej3GIZTzCI8\" width=\"480\" height=\"306\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/muppets-rachel-maddow-kermit-Zaej3GIZTzCI8\">via GIPHY</a></p>\n\n\n\n\n\n\n## Zentrieren von Prädiktoren\n\n- Unter *Zentrieren* (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.\n- Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist.\n- Mit zentrierten Werten ist eine Regression einfacher zu interpretieren.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq <-\n  kidiq %>% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq),\n         mom_hs_c = mom_hs - mean(mom_hs))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.5)\n##     (Intercept)          mom_hs        mom_iq_c mom_hs:mom_iq_c \n##      85.3934940       2.8208618       0.9685442      -0.4806509\n```\n:::\n\n\n\n\n\n\n### Interpretation von `m10.5`\n\n- Der *Achsenabschnitt* (`Intercept`) gibt den geschätzten IQ des Kindes an, wenn man eine Mutter *mittlerer* Intelligenz und *ohne* Schulabschluss betrachtet.\n- `mom_hs` gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n- `mom_iq_c` gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n- `mom_hs:mom_iq_c` gibt den Unterschied in den Koeffizienten für `mom_iq_c` an zwischen den beiden Grupen von `mom_hs`.\n\n\n`m10.5` ist in @fig-m105 dargestellt.\n\n\n\n\n::: {.cell fig.asp='0.4'}\n::: {.cell-output-display}\n![m10.5: Interaktionsmodell mit zentriertem Prädiktor für mütterlicher Intelligenz](metrische-AV_files/figure-pdf/fig-m105-1.pdf){#fig-m105}\n:::\n:::\n\n\n\n\n\n\n### Zentrieren ändert nichts an den Vorhersagen\n\n`m10.4`: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new <- posterior_predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.67553\n```\n:::\n\n\n\n`m10.5`: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new <- posterior_predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.4309\n```\n:::\n\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): $\\sigma_{m10.4}= 18$; $\\sigma_{m10.5}= 18$.\n\n\nDas Zentrieren ändert auch nicht die Regressionskoeffizienten, da die Streuungen der Prädiktoren nicht verändert wurden.\n\n\n\n\n\n### Perzentilintervalle aus der Posterori-Verteilung\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neti(m10.5)\n## Equal-Tailed Interval\n## \n## Parameter       |        95% ETI | Effects |   Component\n## --------------------------------------------------------\n## (Intercept)     | [81.13, 89.55] |   fixed | conditional\n## mom_hs          | [-1.65,  7.54] |   fixed | conditional\n## mom_iq_c        | [ 0.68,  1.26] |   fixed | conditional\n## mom_hs:mom_iq_c | [-0.80, -0.16] |   fixed | conditional\n```\n:::\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich  komfortabel ausgeben lassen mit `hdi(m10.5)`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhdi(m10.5)\n## Highest Density Interval\n## \n## Parameter       |        95% HDI\n## --------------------------------\n## (Intercept)     | [80.93, 89.34]\n## mom_hs          | [-1.65,  7.54]\n## mom_iq_c        | [ 0.67,  1.25]\n## mom_hs:mom_iq_c | [-0.81, -0.17]\n```\n:::\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n\n\n### Beantworten der Forschungsfrage\n\n>   Das Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei Müttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mütterlichen Intelligenz; pro Punkt Unterschied in müttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). Außerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei Mütter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n</br>\n</br>\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\nDas Modell macht *keine* kausalen Aussagen. Es werden lediglich Unterschiede bzw. Zusammenhänge beschrieben.\n\n\n\n\n### Relevanz von Prädiktoren\n\n\n\n\n\n![Made at imgflip.com](img/5sps62.jpg){width=50%}\n\n\nBetrachten wir `m10.3` noch einmal.\n\nWelcher Prädiktor, `mom_hs` oder `mom_hs` ist wichtiger, im Sinne von stärker mit AV `kid_score` verbunden?\n\n\n\n\n::: {.cell}\n\n```\n## Highest Density Interval\n## \n## Parameter   |        95% HDI\n## ----------------------------\n## (Intercept) | [14.34, 37.23]\n## mom_hs      | [ 1.70, 10.31]\n## mom_iq      | [ 0.45,  0.68]\n```\n:::\n\n\n\n\n\n\n\nDas Problem ist, dass die Prädiktoren auf verschiedenen Skalen gemessen wurden, so dass sie nicht direkt vergleichbar sind.\nMan könnte \n\n- die Skalierungen der Prädiktoren angleichen\n- Vorhersagegüte verschiedener Modelle vergleichen (Modell mit einem vs. Modell mit beiden Prädiktoren)\n- ...\n- Dazu später mehr 🤓\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Eine nominale UV mit mehreren Stufen\n\n\n\n\n### Forschungsfrage\n\n*Hintergrund*:\n\n\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in;\nIhre Kompetenz als Wirtschaftspsychologi war heiß begehrt.\nVon Statistik wollte niemand etwas wissen...\nDoch nach einiger Zeit kamen Sie in eine Sinnkrise.\nSie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen.\nKurz entschlossen bewarben Sie sich auf das erste Stellenangebot\nals Nachwuchswissenschaftler:in.\n\nIhr Forschungsprojekt führte Sie in die Antarktis...\nNun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\n\n\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen.\nGenauer gesagt ging es um Größenunterschiede zwischen drei Pinguinarten.\nJa, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\n<!-- Nach Ihrem Studium haben Sie bei einem aufstrebenden Online-Händler angeheuert -->\n<!-- Sie sind für alles zuständig,  -->\n<!-- was nach Wissenschaft oder Analyse aussieht oder sonst den Anschein erweckt, -->\n<!-- kompliziert zu sein.  -->\n<!-- Aus irgendwelchen Gründen liebt Ihre Chefin Diamanten, -->\n<!-- so dass Ihre erste Aufgabe darin besteht, Diamantenpreise zu analysieren.  -->\n<!-- Das Ziel Ihrer Chefin liegt darin,  -->\n<!-- zu erkennen, was ein Preis ist,  -->\n<!-- für den ein Diamant gut verkauft werden kann. Kennt man diesen Preis,  -->\n<!-- kann man sich auf die Suche machen,  -->\n<!-- ob man den Diamant irgendwo günstiger findet.  -->\n<!-- Wenn ja, macht man Gewinn.  -->\n<!-- Gutes Geschäftsmodell, meint Ihre Chefin. -->\n\n</br>\n\n\n> Unterscheiden sich die mittleren Körpergewichte der drei Pinguinarten?\n\n\n\n\n\n\n### Alle Mittelwerte sind gleich (?)\n\n- Formal: $\\mu_1 = \\mu_2 = \\ldots = \\mu_k$ mit $k$ verschiedenen Gruppen von Schliffart.\n\n- Hypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als *Nullhypothesen* bezeichnen.\n\n- Moment. Dass sich *alle* Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? 🤔 Daher ist die bessere Forschungsfrage:\n\n> *Wie sehr* unterscheiden sich mittlere Körpergewichte in Abhängigkeit von der Pinguinart?\n\nOder wir prüfen die Hypothese, ob die Mittelwerte \"praktisch\" gleich sind, also sich \"kaum\" unterscheiden. Der Grenzwert für \"praktisch gleich\" bzw. \"kaum unterschiedlich\" ist subjektiv.\n\n\n\n### Erster Blick in den Datensatz `penguins`\n\n[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv), [Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/palmerpenguins/penguins.html)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_url <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)  # Zufallszahlen für `sample()` festlegen\npenguins <- \n  read_csv(penguins_url)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins %>% \n  select(body_mass_g, species) %>% \n  group_by(species) %>% \n  describe_distribution(range = FALSE, iqr = FALSE)\n## # species=Adelie\n## \n## Variable    |    Mean |     SD | Skewness | Kurtosis |   n | n_Missing\n## ----------------------------------------------------------------------\n## body_mass_g | 3700.66 | 458.57 |     0.29 |    -0.57 | 151 |         1\n## \n## # species=Chinstrap\n## \n## Variable    |    Mean |     SD | Skewness | Kurtosis |  n | n_Missing\n## ---------------------------------------------------------------------\n## body_mass_g | 3733.09 | 384.34 |     0.25 |     0.59 | 68 |         0\n## \n## # species=Gentoo\n## \n## Variable    |    Mean |     SD | Skewness | Kurtosis |   n | n_Missing\n## ----------------------------------------------------------------------\n## body_mass_g | 5076.02 | 504.12 |     0.07 |    -0.72 | 123 |         1\n```\n:::\n\n\n\n\n\n\n\n\n### Ein Überblick über die metrischen Variablen\n\n\n\n... aufgeteilt in die Stufen von `species`:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: species=Adelie\n\n|Variable    |    Mean |     SD | Skewness | Kurtosis |   n | n_Missing |\n|:-----------|:-------:|:------:|:--------:|:--------:|:---:|:---------:|\n|body_mass_g | 3700.66 | 458.57 |     0.29 |    -0.57 | 151 |         1 |\n\nTable: species=Chinstrap\n\n|Variable    |    Mean |     SD | Skewness | Kurtosis |  n | n_Missing |\n|:-----------|:-------:|:------:|:--------:|:--------:|:--:|:---------:|\n|body_mass_g | 3733.09 | 384.34 |     0.25 |     0.59 | 68 |         0 |\n\nTable: species=Gentoo\n\n|Variable    |    Mean |     SD | Skewness | Kurtosis |   n | n_Missing |\n|:-----------|:-------:|:------:|:--------:|:--------:|:---:|:---------:|\n|body_mass_g | 5076.02 | 504.12 |     0.07 |    -0.72 | 123 |         1 |\n:::\n:::\n\n\n\n\nWas fällt Ihnen auf?\n\n\n\n### Visualisierung (EDA)\n\n\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. @fig-penguines1, @fig-penguines2, @fig-penguines3 ? \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Violine](metrische-AV_files/figure-pdf/fig-penguines1-1.pdf){#fig-penguines1}\n:::\n:::\n\n::: {.cell fig.asp='0.3'}\n::: {.cell-output-display}\n![Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Ridges](metrische-AV_files/figure-pdf/fig-penguines2-1.pdf){#fig-penguines2}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins %>% \n  ggplot(aes(x = species, y = body_mass_g, fill = species)) +\n  geom_violindot(fill_dots = \"black\")\n```\n\n::: {.cell-output-display}\n![Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Violindot](metrische-AV_files/figure-pdf/fig-penguines3-1.pdf){#fig-penguines3 fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n### Mittlere Preisunterschiede in der Population\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\n# refresh=0 unterdrückt Ausgabe der Posteriori-Stichproben\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6 %>% \n  parameters()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Fixed effects\n\n|Parameter        |  Median |             95% CI |     pd |  Rhat |     ESS |                       Prior |\n|:----------------|:-------:|:------------------:|:------:|:-----:|:-------:|:---------------------------:|\n|(Intercept)      | 3702.38 | (3626.92, 3778.38) |   100% | 1.001 | 3362.00 | Normal (4201.75 +- 2004.89) |\n|speciesChinstrap |   32.66 |  (-102.47, 163.66) | 67.92% | 1.001 | 3994.00 |    Normal (0.00 +- 5015.92) |\n|speciesGentoo    | 1373.99 | (1260.23, 1482.76) |   100% | 1.001 | 3757.00 |    Normal (0.00 +- 4171.63) |\n:::\n:::\n\n\n\n\n\n\n### Interpretation von `m10.6`\n\n- Die UV hat drei verschiedene Stufen (Werte, Ausprägungen), aber es werden nur zwei angezeigt (also eine weniger)\n- Die fehlende Stufe (`Adelie`, nicht ausgegeben) ist die *Vergleichs- oder Referenzkategorie* (baseline) und ist im Achsenabschnitt ausgedrückt (Intercept).\n- Die Koeffizienten für `species` geben jeweils den Unterschied zur Vergleichskategorie wieder.\n- Diamanten der Schliffart `Adelie` haben laut Modell ein mittleres Gewicht von ca. 3700$.\n- Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies `Adelie`, etc.\n\n\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in @fig-m106-params verdeutlicht.\n\n\n\n::: {.cell fig.asp='0.33'}\n\n```{.r .cell-code}\nplot(hdi(m10.6))\n```\n\n::: {.cell-output-display}\n![Effekt der UV: Unterschiede zur Referenzgruppe](metrische-AV_files/figure-pdf/fig-m106-params-1.pdf){#fig-m106-params fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n### Schätzbereiche für die Modellparameter\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6 %>% \n  hdi()\n## Highest Density Interval\n## \n## Parameter        |            95% HDI\n## -------------------------------------\n## (Intercept)      | [3630.86, 3781.64]\n## speciesChinstrap | [ -97.65,  168.25]\n## speciesGentoo    | [1261.12, 1483.27]\n```\n:::\n\n\n\n\n\n\n\n### Glauben wir jetzt an Gruppeneffekte?\n\nGlauben wir jetzt, auf Basis der Modellparameter,\nan Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\n\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheidne. So ist der Mittelwert der Gruppe `Gentoo` deutlich höher als der der beiden anderen Gruppen. Umgekehrt sind sich `Adelie` und `Chinstrap` in ihren Mittelwerten ziemlich ähnlich.\n\nWie in @fig-m106-params ersichtlich,\nüberlappt sich der Schätzbereich für den Parameter von Gentoo *nicht* mit der Null;\nhingegen überlappt sich der Schätzbereich des Parameters für Chinstrap deutlich mit der Nullinie.\n\n\n\nAuf Basis unseres Modells schließen wir also (mit hoher Sicherheit) aus, dass *alle* Mittelwerte   *exakt* identisch sind.\n\nEhrlicherweise hätte sowieso niemand geglaubt, dass die *exakte Nullhypothese* $\\mu_1 = \\mu_2 = \\ldots = \\mu_k$ bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.\n\nAber: Viele Forscheris prüfen gerne die Nullhypothese, daher taucht der Begriff hier auf.\n\nDas Verfahren der Frequentistischen Statistik, um die Nullhypothese $\\mu_1 = \\mu_2 = \\ldots = \\mu_k$ zu testen, nennt man *Varianzanalyse* (analysis of variance, kurz *ANOVA*).\n\nIn der Bayes-Statistik nutzt man - wie immer - primär die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) zu inferenzstatistisch zu beurteilen.\n\n\n\n\n\n<!-- ### Modellkoeffizienten von `m10.6` -->\n\n<!-- Die Regressionsoeffizienten pro Stufe der UV entsprechen den Mittelwerten $\\hat{y_i}$ aus der Posteriori-Verteilung. Mit `coef(m10.6)` kann man sie sich bequem ausgeben lassen. -->\n\n<!-- ```{r echo = TRUE} -->\n<!-- coef(m10.6) -->\n<!-- ``` -->\n\n\n<!-- - $\\hat{y}_{Fair} = 3702$ -->\n<!-- - $\\hat{y}_{Good} = 33$ -->\n<!-- - etc. -->\n\n\n\n\n\n\n\n\n\n## Priori-Werte\n\nUnser Modell `m10.6` hat schwach informierte (weakly informative) Priors.\nFür Achsenabschnitt und die Regressionskoeffizienten werden Normalverteilungen angenommen mit Mittelwert entsprechend den Stichprobendaten und Streuung, die der 2.5-fachen der Streuung in der Stichprobe entspricht.\nMehr Infos kann man sich so ausgeben lassen: `prior_summary(m10.6)`.\nWo man man über mehr inhaltliches Wissen verfügt, so wird man die Priors anpassen wollen, z.B.:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6b <- stan_glm(price ~ cut, data = diamonds, refresh = 0,\n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(100, 100, 100, 100)),\n                   prior_intercept = normal(3000, 500))\ncoef(m10.6b)\n## (Intercept)       cut.L       cut.Q       cut.C       cut^4 \n##   4025.6909   -244.7507   -283.1645   -575.5653   -264.8581\n```\n:::\n\n\n\n\nDie Streuung des Modells, $\\sigma$, kann man sich mit `sigma(modell)` ausgeben lassen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma(m10.6b)\n## [1] 3964.851\n```\n:::\n\n\n\n\nImplizit bekommt man diese Informationen mitgeteilt durch die Größe der Konfidenzintervalle.\n\n\n\n### Wechsel der Referenzkategorie\n\n- `species` ist eine nominale Variable, da passt in R der Typ `factor` (Faktor) am besten. Aktuell ist der Typ noch `character` (Text):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins <- penguins %>% \n  mutate(species = factor(species))\n```\n:::\n\n\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge ändern. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n```\n:::\n\n\n\nSetzen wir `Gentoo` als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forcats)\npenguins <- penguins %>% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n```\n:::\n\n\n\nBeachten Sie, dass dazu das Paket `forcats` verfügbar sein muss.\n\nJetzt haben wir die Referenzkategorie geändert:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\nDer Wechsel der Referenzkategorie ändert nichts Wesentliches am Modell:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n## Highest Density Interval\n## \n## Parameter        |              95% HDI\n## ---------------------------------------\n## (Intercept)      | [ 4990.22,  5150.33]\n## speciesAdelie    | [-1486.36, -1269.02]\n## speciesChinstrap | [-1472.29, -1198.04]\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Modellgüte mit R-Quadrat bestimmen\n\n### Modellgüte mit $R^2$ bestimmen\n\n\n\n$R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklärt.\n- Höhere Wert von $R^2$ bedeuten, dass das Modell die Daten besser erklärt.\n$R^2$ wird normalerweise auf Basis eines Punktschätzers definiert.\nSolch eine Definition lässt aber viel Information - über die Ungewissheit der Schätzung - außen vor.\nDaher ist es wünschenswert, diese Information in $R^2$ einfließen zu lassen: *Bayes-R-Quadrat*.\n\n\n\n\n\n<!-- R^2_{Bayes} = \\frac{\\text{erklärte Varianz}}{\\text{erkärte Varianz + Residualvarianz}} = \\frac{var_{fit}}{var_{fit}+var_{res}} -->\n\n<!-- - $var_{fit}$ ist die Varianz der vorhergesagten Schätzwerte $\\hat{y}_i$. -->\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2(m10.6)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.668 (95% CI [0.620, 0.716])\n```\n:::\n\n\n\n\nMöchte man es ausführlicher, und im Komfort einer Bayes-Analyse schwelgen,\nso kann man sich die Posteriori-Verteilung von $R2$ ausgeben lassen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.6_r2 <-\nm10.6 %>% \n  r2_posterior() %>% \n  as_tibble()\n\nhdi(m10.6_r2) %>% \n  plot()\n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/unnamed-chunk-33-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## Definition vom \"klassischen\" $R^2$\n\n\n\n\nWie genau sind die Vorhersagen des Modells? $\\sigma$ (Vorhersagefehler) quantifiziert die Streuung der Residuen $r_i = y_i - X_i\\hat{\\beta}$, mit $\\hat{y}_i = X_i\\hat{\\beta}$. \nAnders gesagt: $\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}$.\nAnders gesagt gibt $\\sigma$ die \"typische\" Abweichung einer Beobachtung vom vorhergesagten Wert an.\nEs ist nützlich, $\\sigma$ in Bezug zu setzen zur Streuung der AV, $sd_y=s_y$:\n$R^2 = 1- (\\hat{\\sigma}^2/s^2_y)$.\n$R2$ gibt damit den Anteil der vom Modell erklärten Varianz, $V$, an.\nBerechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck äquivalent zu:\n$R^2=V_{i=1}^n \\hat{y}_i/s_y^2$\nDie beiden obigen Ausdrücke nehmen $\\hat{y}_i$ als fix (sicher) an und vernachlässigen Ungewissheit; sie sind übergewiss aus Bayes-Sicht.\n\n\n\n\n## Bayes' $R^2$\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellgüte miteinzubeziehen:\n$\\text{Bayes }R^2 = \\frac{\\text{erkärte Varianz}}{\\text{Erklärte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}$\n$V_{mod}$ ist die Varianz in der PPV mit $s = 1, \\ldots, S$ simulierten Stichproben, $V(\\hat{y}_i)$ und $V_{res}$ ist die Residualvarianz im Modell.\nFür jede Stichprobe $s$ berechnet man die vorhergesagten Werte, $\\hat{y}_i^s$, die Residualvarianz $\\sigma^2_s$ und den Anteil der erklärten Varianz:\n$\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}$\n\n\n@gelman_r_squared_2019, @gelman_regression_2021, Kap. 11.7\n\n\n\n\n\n\n\n\n\n## \"Praktisch\" kein Unterschied\n\n\n\nSagen wir, wenn sich zwei Preismittelwerte um höchstens $d=100$€ unterscheiden, gilt dieser Unterschied für uns als \"praktisch gleich\", \"praktisch kein Unterschied\" bzw. vernachlässigbar.\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer *Nullhypothese*: $H_0$.\nDie Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen Überlegungen geleitet sein sollte.\nDiesen Bereich bezeichnen wir den *Indifferenzbereich* (Äquivalenzzone, Bereich eines vernachlässigbaren Unterschieds oder *Region of practical equivalence*, Rope). \nJetzt prüfen wir, ob ein \"Großteil\" der Posteriori-Stichproben im Rope liegt.\nUnter \"Großteil\" wird häufig das *95%-HDI* verstanden.\n\n*Entscheidungsregel*:\n\nGroßteil liegt *innerhalb* von Rope  ➡️ *Annahme* der Nullhypothese \"praktisch kein Effekt\", $H_0$\nGroßteil liegt *außerhalb* von Rope  ➡️ *Ablehnung* der Nullhypothese \"praktisch kein Effekt\", $H_0$\nAnsonsten  ➡️  keine Entscheidung \n\n@kruschke_rejecting_2018\n\n\n\n\n### HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](img/Kruschke-2018-Fig1.png){width=70%}\n:::\n:::\n\n\n\n@kruschke_rejecting_2018, Abbildung 1, S. 272\n\n\n\n### Rope berechnen\n\nDen Rope berechnet man mit `rope(model)`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6)\n## # Proportion of samples inside the ROPE [-80.20, 80.20]:\n## \n## Parameter        | inside ROPE\n## ------------------------------\n## (Intercept)      |      0.00 %\n## speciesChinstrap |     75.08 %\n## speciesGentoo    |      0.00 %\n```\n:::\n\n\n\nDie Faktorstufe `Chinstrap` von `species` hat doch einen beträchtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. \n\nWir können daher für diese Gruppe  das ROPE *nicht* verwerfen.\n\nAber: `Gentoo` liegt zu 0% im Rope. Für Gentoo können wir das Rope verwerfen.\n\nDas hört sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n:::callout-note\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. `help(rope)`.\n:::\n\n\n### Visualisierung unserer Rope-Werte, m10.6\n\n- Ein Großteil der Posteriori-Masse von `m10.6` liegt  *nicht* innerhalb des Rope. \n- Aber können wir umgekehrt sagen, dass ein Großteil außerhalb liegt? Das erkennt man optisch ganz gut.\n\n\n\n::: {.cell fig.asp='0.5'}\n\n```{.r .cell-code}\nrope(m10.6) %>% plot()\n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/unnamed-chunk-36-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nDas ROPE druchkreuzt die \"Berge\" der Posteriori-Verteilung für Chinstrap deutlich.\nWir knönen das Rope für Chinstrap nicht verwerfen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom \"blauen Fluss\" des Rope.\n\n\n\n\n### Finetuning des Rope\n\nWir können festlegen, was wir unter \"praktischer Äquivalenz\" verstehen,\nalso die Grenzen des Ropes verändern.\nSagen wir, 100 Gramm sind unsere Grenze für einen vernachlässigbaren Effekt, s. @fig-rope-range.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100)))\n```\n\n::: {.cell-output-display}\n![ROPE mit selber eingestellter Grenze von ±100 (Gramm)](metrische-AV_files/figure-pdf/fig-rope-range-1.pdf){#fig-rope-range fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so ändern, wenn man möchte:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n```\n:::\n\n\n\n`ETI` (equal tails interval) steht für ein PI.\nJetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.\n\n\n\n\n\n\n### Beantwortung der Forschungsfrage\n\n\nFür die Spezeis *Gentoo* wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. Für *Chinstrap* hingegen  ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs möglich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.\n\n\n\n\n\n\n\n\n\n\n\n\n## Mehrere metrische UV\n\n\n\n\n### Forschungsfrage\n\n>   Stehen sowohl der IQ der Mutter als auch, unabhängig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\n- Das ist wieder eine *deskriptive* Forschungsfrage. *Keine* Kausalwirkung (etwa \"IQ der Mutter ist die Ursache zum IQ des Kindes\") wird impliziert. \n- Es geht rein darum, Zusammenhänge in den Daten - bzw. in der Population - aufzuzeigen.\n- Viele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. Für solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nötig.\n\n\n[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/data/main/Data/kidiq.csv) als CSV-Datei oder alternativ:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstanarm)\ndata(\"kidiq\")\n```\n:::\n\n\n\n\n\n### Was heißt, X hängt mit Y zusammen?\n\n\n- Der Begriff \"Zusammenhang\" ist nicht exakt.\n- Häufig wird er (für metrische Variablen) verstanden als\n    - lineare Korrelation $\\rho$ bzw. $r$ \n    - lineare Regression $\\beta$, bzw. $b$ \n\n\n- Der Regressionskoeffizient \n    - misst die *Steigung* der Regressionsgerade\n    - zeigt, wie groß der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\n    - wird manchmal mit dem \"Effekt von X auf Y\" übersetzt. Vorsicht: \"Effekt\" klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begründung für einen Kausalzusammenhang. \n    \n- Der Korrelationskoeffizient\n    - misst eine Art der Stärke des linearen Zusammenhangs\n    - zeigt, wie klein die Vorhersagefehler der zugehörigen Regrssion im Schnitt sind.\n    - [Korrelation ist nicht (automatisch) Kausation.](https://xkcd.com/552/)\n    \n\n\n\n\n### Korrelationen zur Forschungsfrage\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  correlation()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Correlation Matrix (pearson-method)\n\n|Parameter1 | Parameter2 |    r |            95% CI | t(432) |         p |\n|:----------|:----------:|:----:|:-----------------:|:------:|:---------:|\n|kid_score  |     mom_hs | 0.24 |      (0.15, 0.32) |   5.07 | < .001*** |\n|kid_score  |     mom_iq | 0.45 |      (0.37, 0.52) |  10.42 | < .001*** |\n|kid_score  |    mom_age | 0.09 | (-2.15e-03, 0.18) |   1.92 | 0.111     |\n|mom_hs     |     mom_iq | 0.28 |      (0.19, 0.37) |   6.13 | < .001*** |\n|mom_hs     |    mom_age | 0.21 |      (0.12, 0.30) |   4.57 | < .001*** |\n|mom_iq     |    mom_age | 0.09 | (-2.54e-03, 0.18) |   1.91 | 0.111     |\np-value adjustment method: Holm (1979)\nObservations: 434\n:::\n:::\n\n\n\n\nOder als Korrelationsmatrix:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  correlation() %>% \n  summary()\n## # Correlation Matrix (pearson-method)\n## \n## Parameter | mom_age |  mom_iq |  mom_hs\n## ---------------------------------------\n## kid_score |    0.09 | 0.45*** | 0.24***\n## mom_hs    | 0.21*** | 0.28*** |        \n## mom_iq    |    0.09 |         |        \n## \n## p-value adjustment method: Holm (1979)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  correlation() %>% \n  summary() %>% \n  plot()\n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/unnamed-chunk-43-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n### Univariate Regressionen\n\nWir berechnen jeweils eine univariate Regression, pro Prädiktor,\nalso eine für `mom_iq` und eine für `mom_age`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n```\n:::\n\n\n\nHier die Ergebnisse für `mom_iq`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.8153709   0.6098634\n```\n:::\n\n\n\nHier die Ergebnisse für `mom_age`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.0768929   0.6920222\n```\n:::\n\n\n\n\n\n\n### Visualisierung der univariaten Regressionen\n\nIn @fig-regr-one-pred ist die univariate Regression mit jeweils einem der beiden Prädiktoren dargestellt.\n\n\n`m10.7`: Die Steigung beträgt 0.6.\n`m10.8`: Die Steigung beträgt 0.7.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- \n  kidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.7)[1],\n              slope = coef(m10.7)[2],\n              color = \"blue\") \n\np2 <- \nkidiq %>% \n  ggplot(aes(x = mom_age, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.8)[1],\n              slope = coef(m10.8)[2],\n              color = \"blue\")\n\nplots(p1, p2,\n      title = c(\"m10.7: Die univariate Regression mit dem Alter der Mutter als Prädiktor\",\n        \"m10.8: Die univariate Regression mit dem IQ der Mutter als Prädiktor\"))\n```\n\n::: {.cell-output-display}\n![Zwei univariate Regressionen](metrische-AV_files/figure-pdf/fig-regr-one-pred-1.pdf){#fig-regr-one-pred fig-pos='H'}\n:::\n:::\n\n\n\n\nUnivariate Regressionen\n\n:::\n\n\n### Multiples Modell (beide Prädiktoren), m10.9\n\n\n`m10.9` stellt das multiple Regressionsmodell dar;\n*multipel* bedeutet in diesem Fall, dass mehr als ein Prädiktor im Modell aufgenommen ist.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.5091004   0.6036698   0.3965563\n```\n:::\n\n\n\n\n:::callout-important\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n:::\n\n\n- Bei einer multiplen Regression ist ein Regressionsgewicht jeweils \"bereinigt\" vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\n- Das bedeutet, man betrachtet den den Zusammenhang eines Prädiktors mit der AV, wobei man gleichzeitig den anderen Prädiktor konstant hält.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.5091004   0.6036698   0.3965563\n```\n:::\n\n\n\n\n\n\n### 3D-Visualisierung eines Modells mit zwei Prädiktoren 1\n\nIn @fig-m109-plotly ist das Modell `m10.9` in 3D dargestellt via [Plotly](https://plotly.com/r/).\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![3D-Visualisierung von m10.9 (zwei Prädiktoren)](img/m109-plotly.jpg){#fig-m109-plotly fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\n\n### Visualisierung mit Farbe statt 3. Dimension\n\n3D-Visualisierungen haben Vorteile, aber auch Nachteile;\n@fig-m109-color zeigt eine alternative Visualisierung,\nin der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n::: {.cell fig.asp='0.5'}\n::: {.cell-output-display}\n![Modell m10.9; die Farverläufe zeigen der Wert der abhängigen Variablen](metrische-AV_files/figure-pdf/fig-m109-color-1.pdf){#fig-m109-color}\n:::\n:::\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farbänderung) die Veränderung für die AV (kid_score). Auf der Achse für `mom_age` sieht man, dass sich die AV kaum ändert, wenn sich `mom_age` ändert.\n\n\n\n\n### Visualisierung in 10 Dimensionen\n\n@fig-ten-dims visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![So sieht der Zusammenhang im 10-dimensionalen Raum aus](metrische-AV_files/figure-pdf/fig-ten-dims-1.pdf){#fig-ten-dims fig-align='center' width=50%}\n:::\n:::\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schwächen, eine große Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\n\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n\n\n\n\n\n\n### Relevanz der Prädiktoren\n\nWelcher Prädiktor ist nun \"wichtiger\" oder \"stärker\" in Bezug auf den Zusammenhang mit der AV, `mom_iq` oder `mom_age`?\n\n- `mom_iq` hat den größeren Koeffizienten.\n- `mom_age` hat weniger Streuung.\n\n\nUm die Relevanz der Prädiktoren vergleichen zu können, müsste man vielleicht die Veränderung von `kid_score` betrachten, wenn man von kleinsten zum größten Prädiktorwert geht.\nAllerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden).\nSinnvoller ist es daher, die Veränderung in der AV zu betrachten, wenn man den Prädiktor von \"unterdurchschittlich\" auf \"überdurchschnittlich\" ändert.\nDas kann man mit *z-Standardisierung* erreichen.\n\n\n\n\n\n\n\n### z-Standardisierung\n\n\n\n\n*z-Standardisierung* bedeutet, eine Variable so zu transformieren, dass sie über einen Mittelwert von 0 und eine SD von 1 verfügt:\n\n$$z = \\frac{x - \\bar{x}}{sd(x)}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"kidiq\")\nkidiq2 <- \n  kidiq %>% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% \n  select(mom_iq, mom_iq_z) %>% \n  head()\n```\n:::\n\n\n\n\n\n\n\n### Statistiken zu den z-transformierten Variablen\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{longtable}{lrrrrrrrrr}\n\\toprule\nVariable & Mean & SD & IQR & Min & Max & Skewness & Kurtosis & n & n\\_Missing \\\\ \n\\midrule\nkid\\_score & 86.7972350 & 20.4106885 & 28.00000 & 20.00000 & 144.0000 & -0.4621661 & -0.16043080 & 434 & 0 \\\\ \nmom\\_hs & 0.7857143 & 0.4107994 & 0.00000 & 0.00000 & 1.0000 & -1.3974558 & -0.04735679 & 434 & 0 \\\\ \nmom\\_iq & 100.0000000 & 15.0000000 & 21.67107 & 71.03741 & 138.8931 & 0.4684126 & -0.57070796 & 434 & 0 \\\\ \nmom\\_age & 22.7857143 & 2.7010696 & 4.00000 & 17.00000 & 29.0000 & 0.1770876 & -0.63324884 & 434 & 0 \\\\ \n\\bottomrule\n\\end{longtable}\n:::\n:::\n\n\n\n\nSo kann man auch die z-Transformation (\"Skalierung\") durchführen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq <- \n  standardize(kidiq, append = TRUE)\n\nhead(kidiq)\n##   kid_score mom_hs    mom_iq mom_age kid_score_z  mom_hs_z   mom_iq_z\n## 1        65      1 121.11753      27 -1.06793237  0.521631  1.4078352\n## 2        98      1  89.36188      25  0.54886757  0.521631 -0.7092079\n## 3        85      1 115.44316      27 -0.08805362  0.521631  1.0295443\n## 4        83      1  99.44964      25 -0.18604150  0.521631 -0.0366907\n## 5       115      1  92.74571      27  1.38176451  0.521631 -0.4836193\n## 6        98      0 107.90184      18  0.54886757 -1.912647  0.5267892\n##    mom_age_z\n## 1  1.5602285\n## 2  0.8197811\n## 3  1.5602285\n## 4  0.8197811\n## 5  1.5602285\n## 6 -1.7717849\n```\n:::\n\n\n\n\nDer Schalter `append = TRUE` sorgt dafür, dass die ursprünglichen Variablen beim Z-Standardisieren nicht überschrieben werden, sondern angehängt werden (mit einem Suffix `_z`).\n\n\nMan kann auch nur einzelne Variablen standardisieren\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n```\n:::\n\n\n\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#data(kidiq)\nkidiq %>% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score)) %>% \n  head()\n##   kid_score mom_hs    mom_iq mom_age kid_score_z  mom_hs_z   mom_iq_z\n## 1        65      1 121.11753      27 -1.06793237  0.521631  1.4078352\n## 2        98      1  89.36188      25  0.54886757  0.521631 -0.7092079\n## 3        85      1 115.44316      27 -0.08805362  0.521631  1.0295443\n## 4        83      1  99.44964      25 -0.18604150  0.521631 -0.0366907\n## 5       115      1  92.74571      27  1.38176451  0.521631 -0.4836193\n## 6        98      0 107.90184      18  0.54886757 -1.912647  0.5267892\n##    mom_age_z  mom_iq_z2 mom_age_z2 kid_score_z2\n## 1  1.5602285  1.4078352  1.5602285  -1.06793237\n## 2  0.8197811 -0.7092079  0.8197811   0.54886757\n## 3  1.5602285  1.0295443  1.5602285  -0.08805362\n## 4  0.8197811 -0.0366907  0.8197811  -0.18604150\n## 5  1.5602285 -0.4836193  1.5602285   1.38176451\n## 6 -1.7717849  0.5267892 -1.7717849   0.54886757\n```\n:::\n\n\n\n\n\n### Modell mit standardisierten Prädiktoren, `m10.10`\n\nDas Standardisieren der AV, `kid_score` ist nicht nötig, um den Effekt der Prädiktoren (UV) auf die AV zu untersuchen.\nStandardisiert man die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darüber,\num wie viele *SD-*Einheiten sich die AV verändert, wenn sich ein Prädiktor um eine *SD-*Einheit verändert.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, data = kidiq, refresh = 0)\ncoef(m10.10)\n##   (Intercept)      mom_iq_z     mom_age_z \n## -0.0005729838  0.4441140164  0.0502720014\n```\n:::\n\n\n\n\n- Der *Achsenabschnitt* gibt den Mittelwert der AV (`kid_score`) an, da `kid_score_z = 0` identisch ist zum Mittelwert von  `kid_score`.\n- Der Koeffizient für `mom_iq_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) ändert, wenn sich `mom_iq` um eine SD-Einheit ändert. \n- Der Koeffizient für `mom_age_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) ändert, wenn sich `mom_age` um eine SD-Einheit ändert.\n\n\n\nJetzt sind die Prädiktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar: \n\n- Man sieht, dass die Intelligenz der Mutter *deutlich wichtiger* ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n\n\n### 95%-PI\n\n\nMit `parameters` können wir uns ein PI ausgeben lassen, s. @fig-m1010hdi.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparameters(m10.10) \n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Fixed effects\n\n|Parameter   |    Median |        95% CI |     pd |  Rhat |     ESS |                      Prior |\n|:-----------|:---------:|:-------------:|:------:|:-----:|:-------:|:--------------------------:|\n|(Intercept) | -5.73e-04 | (-0.08, 0.09) | 50.50% | 1.000 | 4134.00 | Normal (-2.81e-16 +- 2.50) |\n|mom_iq_z    |      0.44 |  (0.36, 0.53) |   100% | 1.000 | 4517.00 |      Normal (0.00 +- 2.50) |\n|mom_age_z   |      0.05 | (-0.04, 0.13) | 88.20% | 1.000 | 5066.00 |      Normal (0.00 +- 2.50) |\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hdi(m10.10))\n```\n\n::: {.cell-output-display}\n![Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet](metrische-AV_files/figure-pdf/fig-m1010hdi-1.pdf){#fig-m1010hdi fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n### Was ist ein kleiner, was ein großer Effekt?\n\n@cohen_statistical_1988 definiert Effektstärken in Bezug auf Mittelwertsvergleiche anhand von $d=(\\mu_1 - \\mu_o) / \\sigma$.\nFür kleine, mittlere und große Werte gab er folgende Richtwerte:\n\n- klein: $d \\approx 0.2$\n- mittel: $d \\approx 0.5$\n- groß: $d \\approx 0.8$\n\nAuf dieser Basis schlägt @kruschke_rejecting_2018 einen Rope von $\\pm0.1$ vor.\nFällt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als \"praktisch null\".\nRichtlinien für Effektstärken sind nur Notlösungen, die durch  Sachverstand ersetzt werden sollen, wo immer möglich.\nMan kann Effektstärken ineinander überführen, s. [hier](https://www.escal.site/), z.B. von Korrelation (*r*) zu Cohens *d* oder $R^2$.\n\n\n\n\n### Vernachlässigbarer Regressionseffekt\n\n@kruschke_rejecting_2018 schlägt vor, einen Regressionskoeffizienten unter folgenden Umständen als \"praktisch Null\" zu bezeichnen:\n\n\n\nWenn eine Veränderung über \"praktisch den ganzen Wertebereich\" von $x$ nur einen vernachlässigbaren Effekt auf $y$ hat.\nEin vernachlässigbarer Effekt ist dabei $\\hat{y}= \\pm 0.1 sd_y$.\nDer \"praktisch ganze Wertebereich\" von $x$ sei $\\bar{x} \\pm 2 sd_x$.\nResultiert der Vergleich von $\\bar{x} -2 sd$ mit $\\bar{x}+2sd$ nur eine Veränderung in $\\hat{y}$ von $\\bar{y} - 0.1sd_y$ auf $\\bar{y} + 0.1 sd_y$, so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlässigbar.\nDas impliziert Rope-Grenzen von $\\beta_x = \\pm 0.05$ für z-standardisierte Variablen.\n\n\n\n\n\n\n\n\n\n\n\n### Verwandtheit von Korrelation und Regression\n\n\n Sind X und Y *z-standardisiert*, so sind Korrelation und Regression identisch.\n\n\n$$b = r \\frac{sd_x}{sd_y}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm10.11 <- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq, refresh = 0)\ncoef(m10.11)\n##  (Intercept)     mom_iq_z \n## -0.001144459  0.448499026\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% \n  correlation()\n## # Correlation Matrix (pearson-method)\n## \n## Parameter1  |  Parameter2 |    r |       95% CI | t(432) |         p\n## --------------------------------------------------------------------\n## kid_score   |      mom_iq | 0.45 | [0.37, 0.52] |  10.42 | < .001***\n## kid_score   | kid_score_z | 1.00 | [1.00, 1.00] |    Inf | < .001***\n## kid_score   |    mom_iq_z | 0.45 | [0.37, 0.52] |  10.42 | < .001***\n## mom_iq      | kid_score_z | 0.45 | [0.37, 0.52] |  10.42 | < .001***\n## mom_iq      |    mom_iq_z | 1.00 | [1.00, 1.00] |    Inf | < .001***\n## kid_score_z |    mom_iq_z | 0.45 | [0.37, 0.52] |  10.42 | < .001***\n## \n## p-value adjustment method: Holm (1979)\n## Observations: 434\n```\n:::\n\n\n\n\n\n### Modellgüte\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.141, 0.269])\n```\n:::\n\n\n\n\nIst dieser Wert von $R2$ \"gut\"?\nDiese Frage ist ähnlich zur Frage \"Ist das viel Geld?\"; \nman kann die Frage nur im Kontext beantworten.\n\nEine einfache Lösung ist immer, Modelle zu vergleichen.\nDann kann man angeben, welches Modell die Daten am besten erklärt,\nz.B. auf Basis von $R^2$.\n\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte.\nVergleicht man viele Modelle aufs Geratewohl, so muss man von zufällig hohen Werten der Modellgüte im Einzelfall ausgehen.\n\n\nWenn Sie aber unbedingt eine \"objektive\" Antwort auf die Frage \"wie viel ist viel?\" haben wollen,\nziehen wir Herrn Cohen zu Rate:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n```\n:::\n\n\n\nDanke, Herr Cohen!\n\n\n### Priori-Verteilung für `m10.10` und Modelldefinition\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n```\n:::\n\n\n\n\n\n\n\n$$\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n$$\n\n\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuführen.\n\n\n### Beantwortung der Forschungsfrage\n\n\n\n>   Das Modell spricht sich klar für einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkärt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm [@goodrich_rstanarm_2020] zurück (s. Anhang für Details).\n\n\nHier wird von einem \"statistischen Effekt\" gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenhänge, und nicht um kausale Zusammenhänge, handelt.\nKausale Zusammenhänge dürfen wir nur verkünden, \nwenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafür finden oder c) wir ein  Experiment fachgerecht durchgeführt haben.\n\n\n\n\n\n\n\n## Vertiefung\n\n\n🏎️VERTIEFUNG, nicht prüfungsrelevant🏎️\n\n\n\n### Prüfen der Linearitätsannahme\n\n\nZentrale Annahme: Die AV ist eine *lineare* Funktion der einzelnen Prädiktoren: \n\n$$y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .$$ \n\nHingegen ist es weniger, dass die AV (y) normalverteilt ist.\nZwar nimmt die Regression häufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schätzen [@gelman_regression_2021].\n\n\n\n\n\nIst die Linearitätsannahme erfüllt, so sollte der Residualplot nur *zufällige* Streuung um $y=0$ herum zeigen, s. @fig-kidiqresiduum.\n\n\nEin Residuum $e$ ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsächlichem Wert:\n\n\n$e_i = y_i - \\hat{y}_i$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq <-\n  kidiq %>% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n```\n:::\n\n::: {.cell fig.asp='0.5'}\n\n```{.r .cell-code}\nkidiq %>% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n```\n\n::: {.cell-output-display}\n![Die Verteilung der Fehler scheint keinem starken Trend (in Abhängigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.](metrische-AV_files/figure-pdf/fig-kidiqresiduum-1.pdf){#fig-kidiqresiduum fig-pos='H'}\n:::\n:::\n\n\n\nHier erkennt man keine größeren Auffälligkeiten.\n\n\n\n\n\n\n\n### Modellprüfung mit der PPV\n\n\n\n\n::: {.cell fig.asp='0.5'}\n\n```{.r .cell-code}\npp_check(m10.10)\n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/m10-10-pp-check-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, $y_{rep}$ verfehlt den Mittelwert von $y$ leider recht häufig.\n\n\n\n\n\n### Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\ndata(kidiq)\nkidiq3 <- \n  kidiq %>% \n  standardize(append = TRUE) %>% \n  sample_n(size = 300)\n\n#| results: \"hide\"\nm10.10a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)\nm10.10b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(mom_age_resid = resid(m10.10a)) %>% \n  mutate(mom_iq_resid = resid(m10.10b))\n\n\nm10.10c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)\nm10.10d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)\n\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(m10.10c_resid = resid(m10.10c)) %>% \n  mutate(m10.10d_resid = resid(m10.10d))\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell fig.asp='0.619'}\n\n```{.r .cell-code}\n#(m10.10a_plot + m10.10b_plot) / (m10.10c_plot + m10.10d_plot)\nplots(m10.10a_plot, m10.10b_plot, m10.10c_plot, m10.10d_plot, \n      n_rows = 2, tags = \"A\",\n      guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/resid-lm-plot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\nDie vertikalen Balken zeigen die Residuen.\n\n\n\n\n\n\nObere Reihe: Regression eines Prädiktors auf den anderen Prädiktor.\nUntere Reihe: Regression der Residuen der oberen Reihe auf die AV, `kid-score_z`. \nUnten links (C): Die Residuen von `mom_iq_c` sind kaum mit der AV assoziiert. Das heißt, nutzt man den Teil von `mom_age_z`, der nicht mit `mom_iq_z` zusammenhängt, um `kid_score` vorher zusagen, findet man keinen (*kaum*) Zusammenhang.\nUnten rechts (D): Die Residuen von `mom_age_c` sind *stark* mit der AV assoziiert. Das heißt, nutzt man den Teil von `mom_iq_z`, der nicht mit `mom_age_z` zusammenhängt, um `kid_score` vorher zusagen, findet man einen starken Zusammenhang.\n\n\n\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: Fixed effects\n\n|Parameter   |    Median |        95% CI |     pd |  Rhat |     ESS |                      Prior |\n|:-----------|:---------:|:-------------:|:------:|:-----:|:-------:|:--------------------------:|\n|(Intercept) | -5.73e-04 | (-0.08, 0.09) | 50.50% | 1.000 | 4134.00 | Normal (-2.81e-16 +- 2.50) |\n|mom_iq_z    |      0.44 |  (0.36, 0.53) |   100% | 1.000 | 4517.00 |      Normal (0.00 +- 2.50) |\n|mom_age_z   |      0.05 | (-0.04, 0.13) | 88.20% | 1.000 | 5066.00 |      Normal (0.00 +- 2.50) |\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n### Bereinigte Regressionskoeffizienten für mtcars\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars2 <-\n  mtcars %>% \n  standardize()\n\nm12a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)\nm12b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)\n\nmtcars2 <-\n  mtcars %>% \n  mutate(m12a_resid = resid(m12a)) %>% \n  mutate(m12b_resid = resid(m12b))\n\n\nm12c <- stan_glm(mpg ~ m12a_resid, data = mtcars2, refresh = 0, chains = 1)\nm12d <- stan_glm(mpg ~ m12b_resid, data = mtcars2, refresh = 0, chains = 1)\n\n\nmtcars2 <-\n  mtcars2 %>% \n  mutate(m12c_resid = resid(m12c)) %>% \n  mutate(m12d_resid = resid(m12d))\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell fig.asp='0.619'}\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/resid-lm-plot-mtcars-1.pdf)\n:::\n:::\n\n\n\n\nÜbrigens liefern `stan_glm()` und `lm` oft ähnliche Parameterwerte (bei schwach informativen Prioriwerten):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %>% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n```\n:::\n\n\n\n\n:::callout-important\nWenn auch die  Parameterwerte eines Frequentistischen und Bayes-Modell numerisch ähnlich sein können, so ist doch die Interpretation grundverschieden. \nBayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.\n:::\n\n\n\n\n\n### Post: Bayes in fünf Minuten\n\n\nEine Kurzdarstellung des Bayes-Inferenz findet sich [in diesem Post](https://data-se.netlify.app/2022/01/27/bayes-in-f%C3%BCnf-minuten/) und in [diesem](https://data-se.netlify.app/2022/01/28/bayes-in-f%C3%BCnf-minuten-f%C3%BCr-fortgeschrittene/).\n\n\n\n\n## Ausblick: Binäre AV\n\n\n>    *Forschungsfrage:* Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: Hängen Spritverbrauch und Getriebeart? (Datensatz `mtcars`)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mtcars)\nmtcars2 <-\n  mtcars %>% \n  standardize(append = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm13 <-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n```\n:::\n\n\n\nAb  `mpg_z = 0.41, 0.3` sagt das Modell `am=1` (manuell) vorher. Ganz ok.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars2 %>% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n```\n\n::: {.cell-output-display}\n![](metrische-AV_files/figure-pdf/unnamed-chunk-55-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nneg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))\n```\n:::\n\n\n\n\nFür kleine Werte von `mpg_z` (<1.3) sagt unser Modell *negative* Werte für `am` voraus. Das macht keinen Sinn. Müssen wir mal bei Gelegenheit besser machen.\n\n\n\n\n\n\n\n## Wir waren fleißig\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n[Quelle](https://giphy.com/gifs/XIqCQx02E1U9W)\n\n\nGenug für heute. 👍 \n\n\n\n\n\n\n\n\n",
    "supporting": [
      "metrische-AV_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"m10.1-post\",\"m10.1-post\",\"m10.1-post\",\"m10.1-post\",\"discribe-kidiq\",\"discribe-kidiq\",\"discribe-kidiq\",\"discribe-kidiq\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"amsmath\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"caption\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"amsmath\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"caption\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}