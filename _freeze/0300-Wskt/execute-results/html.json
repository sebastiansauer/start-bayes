{
  "hash": "f84aafa423c9b4343bc3c42f4b53150e",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Wahrscheinlichkeit\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## Lernsteuerung\n\n\n### Position im Modulverlauf\n\n@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n\n\n\n### √úberblick\n\nDieses Kapitel hat die Wahrscheinlichkeitstheorie (synonym: Wahrscheinlichkeitsrechnung) bzw. das Konzept der Wahrscheinlichkeit zum Thema.^[Die Wahrscheinlichkeitstheorie bildet zusammen mit der Statistik das Fachgebiet der Stochastik.]\nEs geht sozusagen um die Mathematik des Zufalls.\n\n\n\n### Wozu brauche ich dieses Kapitel?\n\nIm wirklichen Leben sind Aussagen (Behauptungen) so gut wie nie sicher.\n\n- \"Weil sie so schlau ist, ist sie erfolgreich.\"\n- \"In Elektroautos liegt die Zukunft.\"\n- \"Das klappt sicher, meine Meinung.\"\n- \"Der n√§chste Pr√§sident wird XYZ.\"\n\nAussagen sind nur *mehr oder weniger* (graduell) sicher.\nWir k√∂nnen die Regeln der Wahrscheinlichkeitslogik verwenden, um den Grad der Sicherheit (von ganz unsicher bis ganz sicher) zu pr√§zisieren.\nDaher sagt man auch, Wahrscheinlichkeit sei die Logik der Wissenschaft [@Janes2014].\n\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ...\n\n\n- die Grundbegriffe der Wahrscheinlichkeitsrechnung erl√§uternd definieren\n- die drei Arten der direkten Ermittlung von Wahrscheinlichkeit erl√§utern\n- typische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\n- mit Wahrscheinlichkeiten rechnen\n\n\n\n### Begleitliteratur\n\nLesen Sie zur Begleitung dieses Kapitels @bourier_2018, Kap. 2-4. \n\n\n### Eigenstudium\n\n\n:::{.callout-important}\nDieses Kapitel ist selbst√§ndig im Eigenstudium vorzubereiten vor dem Unterricht.\nLesen Sie dazu die angegebene Literatur.\nIm Unterricht werden Fragen beantwortet und Aufgaben gemeinsam bearbeitet. Der Stoff wird aber nicht vorgestellt, sondern ist im Selbststudium vorab vorzubereiten.$\\square$\n:::\n\n\n### Pr√ºfungsrelevanter Stoff\n\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit @bourier_2018, Kap. 2-4. \nWeitere √úbungsaufgaben finden Sie im dazugeh√∂rigen √úbungsbuch, @bourier_statistik-ubungen_2022.\n\n:::callout-note\nIn Ihrer [Hochschul-Bibliothek kann das Buch als Ebook verf√ºgbar](https://fantp20.bib-bvb.de/TouchPoint/singleHit.do?methodToCall=showHit&curPos=3&identifier=2_SOLR_SERVER_1157422278) sein. Pr√ºfen Sie, ob Ihr Dozent Ihnen weitere Hilfen im [gesch√ºtzten Bereich (Moodle)](https://moodle.hs-ansbach.de/mod/resource/view.php?id=136047) eingestellt hat.$\\square$\n:::\n\n\n\n\n\n### Zentrale Begriffe\n\n\n#### Grundbegriffe\n\n- Zufallsvorgang (Zufallsexperiment)\n- Elementarereignis\n- Ereignisraum\n- Zufallsereignis (zuf√§lliges Ereignis)\n- Sicheres Ereignis\n- Unm√∂gliches Ereignis\n\n\n#### Wahrscheinlichkeitsbegriffe\n\n- Klassische Wahrscheinlichkeit (LaPlace'sche Wahrscheinlichkeit)\n- Statistische (empirische) Wahrscheinlichkeitsermittlung\n- Subjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n\n#### Wahrscheinlichkeitsrelationen\n\n- Vereinigung von Ereignissen\n- Schnitt(menge) von Ereignissen\n- Komplement√§rereignis\n- Vollst√§ndiges Ereignissystem\n- Anforderungen an eine Definition von Wahrscheinlichkeit\n\n\n#### Wahrscheinlichkeitsrechnung\n\n- Allgemeiner Additionsssatz\n- Disjunkte Ereignisse\n- Additionssatz f√ºr disjunkte Ereignisse\n- Bedingte Wahrscheinlichkeit\n- (Stochastische) Unabh√§ngigkeit\n- Baumdiagramm f√ºr gemeinsame Wahrscheinlichkeit\n- Allgemeiner Multiplikationssatz\n- Multiplikationssatz f√ºr unabh√§ngige Ereignisse\n- Totale Wahrscheinlichkeit\n- Satz von Bayes\n\n\n\n#### Kolmogorovs Wahrscheinlichkeitsdefinition {#sec-kolmogorov}\n\nWir richten eine Reihe von Forderungen an eine Definition von bzw. an das Rechnen mit Wahrscheinlichkeiten, die direkt plausibel erscheinen:^[Ein Herr Kolmogorov hat das mal aufgeschrieben.]\n\n1. *Nichtnegativit√§t*: Die Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein.\n2. *Normierung*: Das sichere Ereignis hat die Wahrscheinlichkeit 1 bzw. 100%: $Pr(\\Omega)=1$; das unm√∂gliche Ereignis hat die Wahrscheinlichkeit 0: $Pr(\\emptyset)=0$.\n3. *Additivit√§t*. Sind $A$ und $B$ disjunkt, dann ist die Wahrscheinlichkeit von $A\\cup B$ die Summe der beiden Einzelwahrscheinlichkeiten von $A$ und $B$.\n\n\n### Begleitvideos\n\n\n- [Video zum Thema Wahrscheinlichkeit](https://youtu.be/rR6NspapEyo)\n\n\n\n\n<!-- ## Unterst√ºtzung: Wahrscheinlichkeit in Bildern -->\n\n<!-- Wahrscheinlichkeit in Bildern: zur einfachen Erschlie√üung des Materials, -->\n<!-- ein Unterst√ºtzungsangebot. -->\n\n\n<!-- Im Folgenden sind einige Schl√ºsselbegriffe und -regeln in (ver-)einfach(t)er Form schematisch bzw. visuell dargestellt mit dem Ziel, den Stoff einfacher zu erschlie√üen. -->\n\n\n\n\n\n\n\n## Grundbegriffe\n\n\n\n\n\n:::{#exm-muenz}\nKlassisches Beispiel f√ºr einen Zufallsvorgang ist das (einmalige oder mehrmalige) Werfen einer M√ºnze.$\\square$\n\nWerfen Sie eine M√ºnze!\nDiese hier zum Beispiel:\n\n![](img/1024px-Coin-155597.svg.png){width=10% fig-align=\"center\"}\n\n[Quelle: By OpenClipartVectors, CC0]( https://pixabay.com/pt/moeda-euro-europa-fran%C3%A7a-dinheiro-155597)\n\n\n\nWiederholen Sie den Versuch 10 Mal.\n\nDas reicht Ihnen nicht? Okay, wiederholen Sie den Versuch 100, nein 1000, nein: $10^6$ Mal.\n\nNotieren Sie als Ergebnis, wie oft die Seite mit der Zahl oben liegen kommt (\"Treffer\").$\\square$\n:::\n\n\nOder probieren Sie die [App der Brown University](https://seeing-theory.brown.edu/basic-probability/index.html#section1), wenn Sie keine Sehnenscheidenentz√ºndung bekommen wollen.\n\n\n:::{#def-zufall}\n### Zufallsvorgang\nEin *Zufallsvorgang* oder *Zufallsexperiment* ist eine einigerma√üen klar beschriebene T√§tigkeit, deren Ergebnis nicht bekannt ist. Allerdings ist die Menge m√∂glicher Ergebnisse sicher und die Wahrscheinlichkeit f√ºr die Ergebnisse kann quantifiziert werden.$\\square$\n:::\n\n\n:::{#exr-zufall2}\nNennen Sie Beispiele f√ºr Zufallsvorg√§nge!\\square^[Beispiele f√ºr Zufallsexperimente sind das Werfen einer M√ºnze, das Ziehen einer Karte aus einem Kartenspiel, das Messen eines Umweltph√§nomens wie der Temperatur oder die Anzahl der Kunden, die einen Laden betreten. In jedem dieser F√§lle sind die m√∂glichen Ergebnisse nicht im Voraus bekannt und h√§ngen von nicht komplett bekannten Faktoren ab.]\n:::\n\n\n:::callout-caution\nZufall hei√üt nicht, dass ein Vorgang keine Ursachen h√§tte. So gehorcht der Fall einer M√ºnze komplett den Gesetzen der Gravitation. W√ºrden wir diese Gesetze und die Ausgangsbedingungen (Luftdruck, Fallh√∂he, Oberfl√§chenbeschaffenheit, Gewichtsverteilungen, ...) exakt kennen, k√∂nnten wir theoretisch sehr genaue Vorhersagen machen. Der \"Zufall\" w√ºrde aus dem M√ºnzwurf verschwinden. Man sollte \"Zufall\" also besser verstehen als \"unbekannt\".$\\square$\n::::\n\n\n:::{#exr-w√ºrfel-geo}\n[Mit dieser App](https://www.geogebra.org/m/cbqee8h7) k√∂nnen Sie W√ºrfelw√ºrfe simulieren und die Ausg√§nge dieses Zufallsexperiments beobachten.$\\square$\n:::\n\n\n\n:::{#def-ereignisraum}\n### Ereignisraum\nDie m√∂glichen Ergebnisse eines Zufallvorgangs fasst man als Menge mit dem Namen *Ereignisraum*[leider gibt es eine F√ºlle synonymer Namen: *Ereignisraum*, *Elementarereignisraum*, *Ergebnisraum* oder *Grundraum*] zusammen. Man verwendet den griechischen Buchstaben $\\Omega$ f√ºr diese Menge.\nDie Elemente $\\omega$ (kleines Omega) von $\\Omega$ nennt man *Ergebnisse*.$\\square$\n:::\n\n:::{#exm-grundraum}\nBeobachtet man beim W√ºrfelwurf (s. @fig-wuerfel) die oben liegende Augenzahl, so ist \n\n\n\n$$\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{‚öÄ, ‚öÅ, ‚öÇ, ‚öÉ, ‚öÑ, ‚öÖ\\}$$\n\nein nat√ºrlicher Grundraum [@henze_stochastik_2019].$\\square$\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![Ein (sechsseitiger) W√ºrfel](img/Dice_2005.jpg){width=33%}\n\n[Bildquelle: CC BY-SA 3.0](https://commons.wikimedia.org/w/index.php?curid=474827)\n:::\n\n::: {.column width=\"50%\"}\n![Ein (sechsseitiger) W√ºrfel, Bildquelle: Peter Steinberg, Wikipedia, CC-BY-](img/120px-Hexahedron-slowturn.gif){#fig-wuerfel}\n:::\n\n::::\n\n\n\n\n:::{#def-ereignis}\n### Ereignis\nJede Teilmenge^[$A$ ist eine Teilmenge von $B$, wenn alle Elemente von $A$ auch Teil von $B$ sind.] von $\\Omega$ hei√üt *Ereignis*; $A \\subseteq B$ .$\\square$\n:::\n\n\n\n:::{#exm-ereignis}\nBeim Mensch-√§rger-dich-nicht Spielen habe ich eine 6 geworfen.^[Schon wieder.]\nDas Nennen wir das Ereignis $A$: \"Augenzahl 6 liegt oben\".$\\square$\n\n$A= \\{6\\}$\n:::\n\n\n:::{#exm-muenzwurf}\nSie werfen eine M√ºnze (Sie haben keinen Grund, an ihrer Fairness zu zweifeln). \"Soll ich jetzt lernen f√ºr die Klausur (Kopf) oder lieber zur Party gehen (Zahl)?\"\n\n@fig-baummuenz1 zeigt die m√∂glichen Ausg√§nge (T wie Treffer (Party) und N  (Niete, Lernen)) dieses Zufallexperiments.\n\n\n```{mermaid}\n%%| label: fig-baummuenz1\n%%| fig-cap: Sie werfen eine M√ºnze. Party oder Lernen???\nflowchart LR\n M[Sie werfen die M√ºnze] --> T\n M --> N\n```\n\n\nZahl! Treffer! Gl√ºck gehabt!^[?]$\\square$\n:::\n\n\n\n\n\n\n:::{#def-unm-sich}\n### Unm√∂gliches und sicheres Ereignis\nDie leere Menge $\\varnothing$ hei√üt das *um√∂gliche*, der Grundraum $\\Omega$ hei√üt das *sichere Ereignis*. $\\square$\n:::\n\n:::{#exm-unm}\n### Unm√∂gliches Ereignis\nAlois behauptet, er habe mit seinem W√ºrfel eine 7 geworfen.\nSchorsch erg√§nt, sein W√ºrfel liege auf einer Ecke, so dass keine Augenzahl oben liegt.\nDraco hat seinen W√ºrfel runtergeschluckt.$\\square$\n:::\n\n\n:::{#exm-sicher}\nNach dem der W√ºrfel geworfen wurde, liegt eine Augenzahl zwischen 1 und 6 oben.$\\square$\n:::\n\n\n:::{#def-elementarereignis}\n### Elementarereignis\n\nJede einelementige Teilmenge $\\{\\omega\\}$ von $\\Omega$ hei√üt *Elementarereignis* (h√§ufig mit $A$ bezeichnet).$\\square$\n:::\n\n\n:::{#exm-elementarereignis}\n### Elementarereignis\n\n- Sie spielen Mensch-√§rger-dich-nicht. Und brauchen dringend eine `6`. Sie w√ºrfeln. Das Ereignis $A = \\{1\\}$ tritt ein.^[Na toll.]\n\n- Sie schreiben eine Statistik-Klausur. Irgendwie haben Sie das Gef√ºhl, das Ergebnis ist eine Zufallsexperiment... Jedenfalls k√∂nnen nach Adam Riese zwei Dinge passieren: $\\Omega= \\{\\text{bestehen, nicht bestehen}\\}$.\nDas erste der beiden Elementarereignisse tritt ein. Yeah!\n\n- Sie f√ºhren eine Studie durch zur Wirksamkeit einer Lern-App. Es ist nicht klar, ob die App wirklich was bringt f√ºr den Lernerfolg. Vereinfacht gesprochen ist der Grundraum dieses Experiments: $\\Omega = \\{\\text{schadet, bringt nichts, n√ºtzt}\\}$.\nDie Daten sprechen f√ºr das Ereignis $A = \\{\\text{bringt nichts}\\}$.\n:::\n\n\n\n\n:::{#def-vollereignis}\n### Vollst√§ndiges Ereignissystem\nWird der Grundraum $\\Omega$ vollst√§ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollst√§ndiges Ereignissystem, s. @fig-vollereignis.$\\square$\n:::\n\n\n![Zerlegung des Grundraums in ein vollst√§ndiges Ereignissystem](img/vollereignis.png){#fig-vollereignis width=50%}\n\n\n\n:::{#exm-vollereig1}\nSei $\\Omega$ der typische Ereignisraum des W√ºrfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, $A$ \"gerade Zahlen\", und $B$ \"ungerade Zahlen\". \nDamit haben wir ein vollst√§ndiges Ereignissystem erstellt.\n\n\n\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\}  \\qquad  \\hfill \\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6 } \n\n\\end{align}\n:::\n\n\n:::{#exm-vollereig2}\nSei $\\Omega$ der typische Ereignisraum des W√ºrfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, $A$ \"1,2,3\", und $B$ \"4,5,6\". \nDamit haben wir ein vollst√§ndiges Ereignissystem erstellt.\n\n\\begin{align}\nA = \\{1,2,3\\} \\qquad \\qquad \\hfill  \\boxed{\\boxed{ \\color{black}{1\\; 2\\; 3}}\\; \\color{gray}{4\\; 5\\; 6}} \\\\\nB = \\{4,5, 6\\} \\qquad \\qquad  \\hfill \\boxed{\\color{gray}{1 \\; 2 \\; 3}\\; \\boxed{\\color{black}{4\\; 5 \\; 6}}} \\\\\n\n\\newline\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\} \\qquad \\qquad \\hfill  \\boxed{1\\; 2\\; 3\\; 4\\; 5\\;6}\n\\end{align}\n:::\n\n\n:::{#def-macht}\n### M√§chtigkeit\nDie Anzahl der Elementarereignisse eines Ereignismraums nennt man die M√§chtigkeit (des Ereignisraums).^[Die Menge aller Teilmengen einer Menge $A$ nennt man die *Potenzmenge* $\\mathcal{P}(A)$, vgl. [hier](https://de.wikipedia.org/wiki/Datei:Hasse_diagram_of_powerset_of_3.svg).]$\\square$\n:::\n\n\nDie M√§chtigkeit von $\\Omega$ bezeichnet man mit dem Symbol $|\\Omega|$.\n\n:::{#exm-macht}\nBeim Wurf eines W√ºrfels mit $\\Omega=\\{1,2,3,4,5,6\\}$ gibt es 6 Elementarereignisse. Die M√§chtigkeit ist also 6: $|\\Omega|=6$.$\\square$\n:::\n\n## Direkte Ermittlung von Wahrscheinlichkeiten\n\n### Epistemologische Wahrscheinlichkeit\n\n\nVor uns liegt ein W√ºrfel. Schlicht, ruhig, unbesonders.\nWir haben keinen Grund anzunehmen, dass eine seiner $n=6$ Seiten bevorzugt nach oben zu liegen kommt. \nJedes der sechs Elementarereignisse ist uns gleich plausibel;\nder W√ºrfel erscheint uns fair.\nIn Ermangelung weiteres Wissens zu unserem W√ºrfel gehen wir schlicht davon aus, dass jedes der $n$ Elementarereignis gleich wahrscheinlich ist.\nEs gibt keinerlei Notwendigkeit, den W√ºrfel in die Hand zu nehmen,\num zu einer Wahrscheinlichkeitsaussage auf diesem Weg zu kommen.\nNat√ºrlich *k√∂nnten* wir unsere Auffassung eines fairen W√ºrfels testen,\naber auch ohne das Testen k√∂nnen wir eine stringente Aussage (basierend auf unserer Annahme der Indifferenz der $n$ Elementarereignisse) zur Wahrscheinlichkeit eines bestimmten (Elementar-)Ereignisses $A$ kommen [@briggs_uncertainty:_2016], s. @eq-briggs.\n\n\n$$Pr(A) = 1/n= \\frac{1}{|\\Omega|}$$ {#eq-briggs}\n\n:::{#exm-briggs}\nSei $A$ = \"Der W√ºrfel wird beim n√§chsten Wurf eine 6 zeigen.\"\nDie Wahrscheinlichkeit f√ºr $A$ ist $1/6. \\square$\n:::\n\n\n:::{#def-laplace}\nEin Zufallsexperiment, bei dem alle Elementarereignisse die selbe Wahrscheinlichkeit haben, nennt man man ein *Laplace-Experiment*.$\\square$\n:::\n\nIn Erweiterung von @eq-briggs k√∂nnen wir schreiben:\n\n$$Pr(A)=\\frac{\\text{Anzahl Treffer}}{\\text{Anzahl m√∂glicher Ergebnisse}}$$\n\n### Frequentistische Wahrscheinlichkeit\n\nIn Ermangelung einer Theorie zum Verhalten eines (uns) unbekannten Zufallsvorgangs und unter der Vermutung, dass die Elementarereignisse nicht gleichwahrscheinlich sind, bleibt uns ein einfacher (aber aufw√§ndiger) Ausweg: Ausprobieren.\n\nAngenommen, ein Statistik-Dozent, bekannt f√ºr seine Vorliebe zum Gl√ºcksspiel und scheinbar endlosen Gl√ºcksstr√§hnen, er wirft andauernd eine 6, hat seinen Lieblingsw√ºrfel versehentlich liegen gelassen. Das ist *die* Gelegenheit!\nSie greifen sich den W√ºrfel, und ... Ja, was jetzt?\nNach kurzer √úberlegung kommen Sie zum Entschluss, den W√ºrfel einen \"Praxistest\" zu unterziehen: Sie werfen ihn 1000 Mal (Puh!) und z√§hlen den Anteil der `6`.\nFalls der W√ºrfel fair ist, m√ºsste gelten $Pr(A=6)=1/6\\approx .17$. Schauen wir mal!\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\nUnd hier der Anteil von  `6` im Verlauf unserer W√ºrfe, s. @fig-wuerfel.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Das Gesetz der gro√üen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten W√ºrfelwurf](0300-Wskt_files/figure-html/fig-wuerfel-1.png){#fig-wuerfel width=672}\n:::\n:::\n\n\nHm, leider ist auf den ersten Blick kein Anzeichen f√ºr Schummeln bzw. einen gezinkten W√ºrfel zu finden (zumindest nicht zu Gunsten des Zwielichten Dozenten).\n\n\n\n### Subjektive Wahrscheinlichkeit\n\nUm subjektiv zu einer Wahrscheinlichkeit zu kommen, sagt man einfach seine Meinung.\nDas h√∂rt sich nat√ºrlich total plump an. \nUnd tats√§chlich besteht die Gefahr, dass die so ermittelten Wahrscheinlichkeiten aus der Luft gegriffen, also haltlos, sind.\n\nAllerdings kann diese Art von Wahrscheinlichkeitsermittlung auch sehr wertvoll sein.\nIn komplizierten Situation im echten Leben kommt man oft in die Situation, dass weder die epistemologische noch die frequentistische Variante verwendet werden kann.\nDann muss man auf Sch√§tzungen, Vorwissen, Erfahrung, theoretischen √úberlengungen etc. zur√ºckgreifen.\n\n## Indirekte Ermittlung von Wahrscheinlichkeiten\n\nDie indirekte Ermittlung von Wahrscheinlichkeiten meint das Ableiten von Wahrscheinlichkeitsaussagen, wenn man schon etwas √ºber die Wahrscheinlichkeiten des Grundraums wei√ü. \nDazu greift man auf Rechenregeln der Stochastik zur√ºck.\nDas h√∂rt sich vielleicht wild an, ist aber oft ganz einfach.\n\n:::{#exm-ind}\n### Gezinkter W√ºrfel\nEin gezinkter W√ºrfel hat eine erh√∂hte Wahrscheinlichkeit f√ºr das Ereignis $A=$\"6 liegt oben\", und zwar gelte $Pr(A)=1/3$.\nWas ist die Wahrscheinlichkeit, *keine*  `6` zu w√ºrfeln?$\\square$^[Die Wahrscheinlichkeit, keine `6` zu w√ºrfeln, liegt bei $2/3$.]\n:::\n\nF√ºr das Rechnen mit Wahrscheinlichkeiten ist es hilfreich, ein paar Werkzeuge zu kennen, die wir uns im Folgenden anschauen.\n\n\n## Relationen von Ereignissen\n\n\n### √úberblick\n\n\nWir gehen von Grundraum $\\Omega$ aus, mit dem Ereignis $A$ als Teilmenge: $A \\subset B$.\n\n\nDa wir Ereignisse als Mengen auffassen, verwenden wir im Folgenden die beiden Begriffe synonym.\n\n\nDabei nutzen wir u.a. Venn-Diagramme.\nVenn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren. Die folgenden Venn-Diagramme stammen von [Wikipedia (En)](https://en.wikipedia.org/wiki/Venn_diagram).\n\n:::callout-note\n### Wozu sind die Venn-Diagramme gut? Warum soll ich die lernen?\nVenn-Diagramme zeigen Kreise und ihre √ºberlappenden Teile;\ndaraus lassen sich R√ºckschl√ºsse auf Rechenregeln f√ºr Wahrscheinlichkeiten ableiten.\nViele Menschen tun sich leichter, Rechenregeln visuell aufzufassen als mit Formeln und Zahlen alleine. Aber entscheiden Sie selbst!$\\square$\n:::\n\n[Die folgende App](https://www.geogebra.org/m/QZvCMSDs) versinnbildlicht das Rechnen mit Relationen von Ereignissen anhand von Venn-Diagrammen.\n\n\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.geogebra.org/m/QZvCMSDs\" title=\"Mengenoperationen mit Venn-Diagrammen verbildlicht\"></iframe>\n```\n\n\n\n### Vereinigung von Ereignissen\n\n:::{#def-mengen-verein}\n### Vereinigung von Ereignissen\nVereinigt man zwei Ereignisse $A$ und $B$, dann besteht das neue Ereignis $C$ genau aus den Elementarereignissen der vereinigten Ereignisse.\nMan schreibt $C = A \\cup B$, lies: \"C ist A vereinigt mit B\".$\\square$\n:::\n\n@fig-cup zeigt ein Venn-Diagramm zur Verdeutlichung der Vereinigung von Ereignissen.\n\n![$A \\cup B$](img/Venn0111.svg.png){#fig-cup width=25%}\n\n:::{#exm-mengen-verein}\n\nUm einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem n√§chsten Wurf mindestens eines der beiden Ereignisse $A$ oder $B$ eintreten.\n\n\\begin{aligned}\nA = \\{1,2\\} \\qquad \\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}} \\\\\nB = \\{2,3\\} \\qquad  \\boxed{1\\; \\boxed{2\\; 3}\\; \\color{gray}{ 4\\; 5\\; 6}} \\\\\n\\newline\n\\hline \\\\\nA \\cup B = \\{1,2,3\\} \\qquad \\boxed{\\boxed{1\\; 2\\; 3}\\; \\color{gray}{4\\; 5\\; 6}}\n\\end{aligned}\n:::\n\n\n\nZur besseren Verbildlichung betrachten Sie mal diese\n[Animation zur Vereinigung von Mengen](https://www.geogebra.org/m/GEZV4xXc#material/cmXR8fHN); [Quelle](Geogebra, J. Merschhemke).\n\n\nIn R hei√üt die Vereinigung von Mengen `union()`. Praktisch zum Ausprobieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- c(1, 2)\nB <- c(2, 3)\n\nunion(A, B)\n## [1] 1 2 3\n```\n:::\n\n\n\n\n### (Durch-)Schnitt von Ereignissen\n\n\n:::{#def-mengen-schnitt}\n### Schnittmenge von Ereignissen\nDie Schnittmenge zweier Ereignisse $A$ und $B$ umfasst genau die Elementarereignisse, die Teil beider Ereignisse sind. Man schreibt: $A \\cap B.$^[Synonym und k√ºrzer: $AB$ anstelle von $A \\cap B$.] Lies: \"A geschnitten B\". $\\square$\n:::\n\n@fig-cap zeigt ein Sinnbild zur Schnittmenge zweier Ereignisse.\n\n\n\n![$A \\cap B$](img/Venn0001.svg.png){#fig-cap width=25%}\n\n\n:::{#exm-mengen-schnitt}\n\nUm einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem n√§chsten Wurf sowohl das Ereignis $A$ = \"gerade Augenzahl\" als auch $B$ = \"Augenzahl gr√∂√üer 4\".\n\n\n\\begin{align}\n& A = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n& B = \\{5,6\\} \\qquad \\qquad \\hfill  \\boxed{ \\color{gray}{1\\; 2\\; 3\\; 4\\;} \\boxed{\\color{black}{5\\; 6}}} \\\\\n\\newline\n\\hline \\\\\n& A \\cap B = \\{6\\} \\qquad \\qquad \\hfill  \\boxed{\\color{gray}{1\\; 2\\; 3\\; 4\\; 5\\;} \\color{black}{6}}\n\\end{align}\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- c(2, 4, 6)\nB <- c(5, 6)\nintersect(A, B)\n## [1] 6\n```\n:::\n\n\n\n\n:::callout-note\n#### Eselsbr√ºcke zur Vereinigungs- und Schnittmenge\n\nDas Zeichen f√ºr eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen f√ºr einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine Eselbr√ºcke gelesen, s. @fig-esel.\n\n![Eselsbr√ºcke f√ºr Vereinigungs- und Schnittmenge](img/ven_cup_cap.jpeg){#fig-esel width=55%}\n:::\n\n\n### Komplement√§rereignis\n\n\n:::{#def-menge-komplement}\n### Komplement√§rereignis\nEin Ereignis $A$ ist genau dann ein Komplement√§rereignis zu $B$, wenn es genau die Elementarereignisse von $\\Omega$ umfasst, die nicht Elementarereignis des anderen Ereignisses sind, s. @fig-neg.$\\square$\n:::\n\n\nMan schreibt f√ºr das Komplement√§rereignis von $A$ oft $\\bar{A}$ oder $\\neg A$^[manchmal auch $A^C$; *C* wie *c*omplementary event]; lies \"Nicht-A\" oder \"A-quer\".\n\n\n:::{#exm-mengen-komplement}\n\nBeim normalen W√ºrfelwurf sei $A$ das Ereignis \"gerade Augenzahl\"; \ndas Komplement√§rereignis ist dann $\\neg A$ \"ungerade Augenzahl\".\n\n\n\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n\\hline \\\\\n\\neg A = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\end{align}\n:::\n\n\n![$\\bar{A}$](img/2560px-Venn1010.svg.png){#fig-neg width=25%}\n\n\n### Logische Differenz\n\n:::{#def-mengen-diff}\n### Logische Differenz\nDie logische Differenz der Ereignisse $A$ und $B$ ist das Ereignis, \ndas genau aus den Elementarereignissen besteht von $A$ besteht, die nicht zugleich Elementarereignis von $B$ sind, s. @fig-setminus.$\\square$\n:::\n\nDie logische Differenz von $A$ zu $B$ schreibt man h√§ufig so: $A \\setminus B$; lies \"A minus B\".\n\n\n![$A \\setminus B$](img/Venn0100.svg.png){#fig-setminus width=25%}\n\n:::{#exm-mengen-setminus}\n\nSei $A$ die Menge \"gro√üe Zahlen\" mit $A = \\{4,5,6 \\}$.\nSei $B$ die Menge \"gerade Zahlen\".\nWir suchen die logische Differenz, $A \\setminus B$.\n\n\n\\begin{align}\nA = \\{4,5, 6\\} \\qquad \\hfill \\boxed{4\\; 5\\; 6} \\\\\nB = \\{2,4,6\\} \\qquad  \\hfill \\boxed{2\\; 4\\; 6} \\\\\n\\hline \\\\\nA \\setminus B \\qquad \\hfill \\boxed{5}\n\\end{align}\n:::\n\n\nIn R gibt es die Funktion `setdiff()`, die eine Mengendifferenz ausgibt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- c(4, 5, 6)\nB <- c(2, 4, 6)\n\nsetdiff(A, B)\n## [1] 5\n```\n:::\n\n\nü§Ø Von der Menge $A$ die Menge $B$ abzuziehen, ist etwas anderes, als von $B$ die Menge $A$ abzuziehen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetdiff(B, A)\n## [1] 2\n```\n:::\n\n\n:::callout-caution\n$A \\setminus B \\ne B \\setminus A$.\n:::\n\n\n### Disjunkte Ereignisse\n\n\n\n\nSeien $A= \\{1,2,3\\}; B= \\{4,5,6\\}$.\n\n$A$ und $B$ sind disjunkt^[engl. disjoint]: ihre Schnittmenge ist leer: $A \\cap B = \\emptyset$,\ns. @fig-disjunkt\n\n\n\n\n![Zwei disjunkte Ereignisse, dargestellt noch √ºberlappungsfreie Kreise](img/2880px-Disjunkte_Mengen.svg.png){#fig-disjunkt width=\"25%\" fig-align=\"center\"}\n\n\n\n\n\n[Quelle: rither.de](http://www.rither.de/a/mathematik/stochastik/mengentheorie-und-venn-diagramme/)\n\n\n::: {#exm-disjunkt1}\n- Das Ereignis $A$ \"Gerade Augenzahl beim W√ºrfelwurf\", $A={2,4,6}$ und das Ereignis $B$ \"Ungerade Augenzahl beim W√ºrfelwurf\", $B={1,3,5}$ sind disjunkt.\n\n- Die Ereignisse \"normaler Wochentag\" und \"Wochenende\" sind disjunkt.$\\square$\n:::\n\n### Vertiefung\n\n\n[Animation zu Mengenoperationen](https://seeing-theory.brown.edu/compound-probability/index.html)\n\n\n## Rechnen mit Wahrscheinlichkeiten\n\n### Additionssatz \n\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass *mindestens eines der Ereignisse* eintritt.\n\n#### Disjunkte Ereignisse\n\nGegeben sei $\\Omega = {1,2,3,4,5,6}$. Als Sinnbild: $\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}$.\n\nGesucht sei die Wahrscheinlichkeit des Ereignis $A=\\{1,2\\}$.\n\n\n$\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}$\n\n$P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}$\n\n\n:::{#exm-sonntag}\nWas ist die Wahrscheinlichkeit, an einem Samstag oder Sonntag geboren zu sein?\nUnter der (vereinfachten) Annahme, dass alle Jahre zu gleichen Teilen aus allen Wochentagen bestehen und dass an allen Tagen gleich viele Babies geworden werden^[vermutlich gibt es noch mehr Annahmen, die wir uns explizit machen sollten.], ist die Antwort $Pr(A)=1/7 + 1/7 = 2/7$.$\\square$\n:::\n\n\n\n#### Allgemein (disjunkt oder nicht disjunkt)\n\n\nBei der Addition der Wahrscheinlichkeiten f√ºr $A$ und $B$ wird der Schnitt $A\\cap B$ doppelt erfasst.^[sofern sie nicht disjunkt sind, aber wenn sie diskunkt sind, so ist der Schnitt gleich Null und wir machen auch dann nichts falsch] Er muss daher noch abgezogen werden.\n\n\n:::{#def-additionssatz}\n### Allgemeiner Additionssatz\nDie Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse $A$ und $B$ eintritt, ist gleich der Summe ihrer Wahrscheinlichkeiten minus ihrer gemeinsamen Wahrscheinlichkeit, s. @eq-add.\n\n$$P(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\square$${#eq-add}\n:::\n\n\n<!-- ::: {#fig-sets2 layout-ncol=2} -->\n\n<!-- ![$A \\cup B$](img/Venn0111.svg.png){width=20%}{#fig-sets2-a} -->\n\n\n\n\n<!-- ![$A \\cap B$](img/Venn0001.svg.png){width=20%}{#fig-sets2-b} -->\n\n\n\n<!-- Die Schnittmenge muss beim Vereinigen abgezogen werden, -->\n<!-- damit sie nicht doppelt gez√§hlt wird. -->\n\n\n<!-- ::: -->\n\n\n\n:::{#exm-klausur-bed-wskt}\n### Lernen und Klausur bestehen\n\nIn einem angewandten Psychologie-Studiengang sind die Studis verdonnert, zwei Statistik-Module ($S1, S2$) zu belegen.\nDie meisten bestehen ($B$), einige leider nicht ($N$), s. tbl-klausur2.\n\nEreignis $A$ ist \"Klausur Statistik 1\" mit den Ergebnissen \"bestanden\" und \"nicht bestanden\". \nEreignis $B$ ist analog f√ºr \"Klausur Statistik 2\".\n\nWir suchen die Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen: $Pr(S_1B \\cup S_2B)$.\nNennen wir das Ereignise $A$.\n\n\n\n\n::: {#tbl-klausur2 .cell tbl-cap='Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht'}\n::: {.cell-output-display}\n\n\n|.     | S1_B| S1_NB| Summe|\n|:-----|----:|-----:|-----:|\n|S2_B  |   85|     9|    94|\n|S2_NB |    5|     1|     6|\n|Summe |   90|    10|   100|\n\n\n:::\n:::\n\n\n\n\\begin{aligned}\nPr(A) &= Pr(S_1B \\cup S_2B) \\\\\n&= Pr(S1_B) + Pr(S_2B) - Pr(S_1B \\cap S_2B)  \\\\\n&= (90 + 94 - 85) / 100 = 99 / 100\\\\\n\\end{aligned}\n\nDie Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen liegt bei 99%.\nUmgekehrt liegt die Wahrscheinlichkeit, keine der beiden Klausuren zu bestehen, liegt bei $Pr(\\neg A) = 1- Pr(A) = 0.01 = 1\\%$; ein Sachverhalt, der sich auch mit einem kurzen Blick in die Datentabelle erkennen l√§sst.$\\square$\n:::\n\n\n\n\n\n### Bedingte Wahrscheinlichkeit\n\n:::{#def-pr-cond}\n### Bedingte Wahrscheinlichkeit\nDie Bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit, dass $A$ eintritt, *gegeben dass* $B$ schon eingetreten ist. $\\square$\n:::\n\nMan schreibt: $Pr(A|B).$ Lies: \"A gegeben B\" oder \"A wenn B\".\n\n\n\n\n\n\n\n\n\n:::{#exr-victorpowell}\nSchauen Sie sich mal diese [Wahnsinnsanimation von Victor Powell an](https://setosa.io/conditional/) zu bedingten Wahrscheinlichkeiten. \nHammer!\n:::\n\n\n\n\n@fig-schema-p illustriert *gemeinsame Wahrscheinlichkeit*, $P(A \\cap B)$, und *bedingte Wahrscheinlichkeit*, $P(A|B)$.\n\n\n\n::: {#fig-schema-p .cell layout-ncol=\"3\"}\n::: {.cell-output-display}\n![Wahrscheinlichkeit f√ºr Ereignis B: 50%](0300-Wskt_files/figure-html/fig-schema-p-1.png){#fig-schema-p-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Wahrscheinlichkeit f√ºr Ereignis A: 50%](0300-Wskt_files/figure-html/fig-schema-p-2.png){#fig-schema-p-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Wahrscheinlichkeit f√ºr Ereignis B gegeben A: 50%](0300-Wskt_files/figure-html/fig-schema-p-3.png){#fig-schema-p-3 width=672}\n:::\n\nIllustration von gemeinsamer und bedingter Wahrscheinlichkeit\n:::\n\n\n\n:::{#exm-bed-p}\n### Bedingte Wahrscheinlichkeit\nSei $A$ \"Sch√∂nes Wetter\" und $B$ \"Klausur steht an\".\nDann meint $Pr(A|B)$ die Wahrscheinlichkeit, dass das Wetter sch√∂n ist, wenn gerade eine Klausur ansteht.$square$\n:::\n\n\n:::{#exm-papst}\n### Von P√§psten und M√§nnern\n\nMan(n) beachte, dass die Wahrscheinlichkeit, Papst $P$ zu sein, wenn man Mann $M$ ist *etwas anderes* ist, als die Wahrscheinlichkeit, Mann zu sein, wenn man Papst ist:\n$Pr(P|M) \\ne Pr(M|P)$. Das h√∂rt sich erst verwirrend an, aber wenn man dar√ºber nachdenkt, wird es sehr plausibel.$\\square$\n:::\n\n\n:::{#exm-kalt-regen}\n### Kalt und Regen\nDie Wahrscheinlichkeit, dass es kalt ist, wenn es regnet, ist gleich der Wahrscheinlichkeit, dass es gleichzeitig kalt ist und regnet geteilt durch die Wahrscheinlichkeit, dass es regnet.$\\square$\n:::\n\n\n:::{#exm-hirn-gr√ºtze}\nGustav Gro√ü-G√ºtz verkauft eine Tinktur^[genauer besehen sieht sie eher aus wie eine Gr√ºtze oder ein Brei], die schlau machen soll, \"G√ºtzis Gehirn Gr√ºtze\".^[Sie schmeckt scheu√ülich.]\nGustav trinkt die Gr√ºtze und sagt schlaue Dinge.\nWas schlie√üen wir daraus?\nSei $H$ (wie *H*ypothese) \"G√ºtzis Gr√ºtze macht schlau\"; sei $D$ (wie *D*aten) die Beobachtung, dass Gustav schlaue Dinge gesagt hat.\nOhne exakte Zahlen zu suchen, wie hoch ist wohl $Pr(D|H)$? In Worten: \"Wie wahrscheinlich ist es, schlaue Dinge gesagt zu haben, wenn die Gr√ºtze wirklich schlau macht?\".\nVermutlich ist diese Wahrscheinlichkeit sehr hoch.\nAber wie hoch ist wohl $Pr(H|D)$? In Worten: \"Wie wahrscheinlich ist es, dass die Gr√ºtze wirklich schlau macht, gegeben, dass wir gesehen hat, dass jemand etwas schlaues gesagt hat, nachdem er besagte Gr√ºtze getrunken hat?\"\nSkeptische Geister werden der Meinung sein, $Pr(H|D)$ ist gering.\nDas Beispiel zeigt u.a. $Pr(H|D) \\ne Pr(D|H).\\square$\n:::\n\n\n\n\nDas Berechnen einer bedingten Wahrscheinlichkeit, $Pr(A|B)$, ist vergleichbar zum Filtern einer Tabelle:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|id    |  A|  B|\n|:-----|--:|--:|\n|1     |  0|  0|\n|2     |  0|  1|\n|3     |  1|  0|\n|4     |  1|  1|\n|SUMME |  2|  2|\n\n\n:::\n:::\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\n$Pr(A) = 2/4; Pr(B) = 2/4; Pr(A \\cap B) = 1/4; Pr(A|B) = 1/2$\n\n\n#### Rechenregel\n\nDie Wahrscheinlichkeit f√ºr $A$, wenn $B$ schon eingetreten ist, berechnet sich so, s. @eq-pr-cond.\n\n$$Pr(A|B) = \\frac{Pr(A \\cap B)}{Pr(B)}$${#eq-pr-cond}\n\nAu√üerdem gilt analog\n\n$$Pr(B|A) = \\frac{Pr(B \\cap A)}{Pr(A)}$${#eq-pr-cond2}\n\n\nStochastische Unabh√§ngigkeit ist symmetrisch: Wenn $A$ unabh√§ngig zu $B$ ist auch $B$ unabh√§ngig zu $A$,\n\n$$Pr(A|B) = Pr(A) \\leftrightarrow Pr(B|A) = Pr(A)$${#eq-indep-symm}\n\nMan beachte, dass stochastische Unabh√§ngigkeit und kausale Unabh√§ngigkeit unterschiedliche Dinge sind [@henze_stochastik_2019]: Stochastische Unabh√§ngigkeit impliziert nicht kausale Unahb√§ngigkeit.\n\n:::{#exm-klausur-bed-wskt}\n### Lernen und Klausur bestehen\n\n\nSie bereiten sich gerade auf die Klausur bei Prof. S√º√ü vor.\nDas hei√üt: Sie √ºberlegen, ob Sie sich auf die Klausur vorbereiten sollten.\nVielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr gro√ü?\nAber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen k√∂nnen, s. @tbl-klausur-lernen.\nIn der Tabelle sind die Daten von 100 Studis ausgewiesen.\nEin Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die \"*L*erner.\nEin anderer Teil hat nicht gelernt, $NL$ bzw. $\\neg L$. Ein Teil hat bestanden, $B$, ein Teil nicht $NB$ oder $\\neg B$.\n\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: $Pr(B |\\neg L)$.\n\n\n\n\n::: {#tbl-klausur-lernen .cell tbl-cap='Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht'}\n::: {.cell-output-display}\n\n\n|.     |  L| NL| Summe|\n|:-----|--:|--:|-----:|\n|B     | 80|  1|    81|\n|NB    |  5| 14|    19|\n|Summe | 85| 15|   100|\n\n\n:::\n:::\n\n\n\n\\begin{aligned}\nPr(B |\\neg L) &= \\frac{Pr(B \\cap \\neg L)}{Pr(\\neg L)} \\\\\n&=\\frac{1/100}{15/100} = 1/15 \\\\\n\\end{aligned}\n\nDie Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat, liegt bei 1 von 15,\nalso ca. 7%.^[$Pr(L).85; Pr(\\neg L) = .15; Pr(B) =.81; Pr(\\neg B) = .19$] $\\square$\n:::\n\n\n\n\n### Stochastische (Un-)Abh√§ngigkeit\n\nStochastische Unabh√§ngigkeit ist ein Spezialfall von Abh√§ngigkeit: Es gibt sehr viele Auspr√§gungen f√ºr Abh√§ngigkeit, aber nur eine f√ºr Unabh√§ngigkeit.\nK√∂nnen wir Unabh√§ngigkeit nachweisen, haben wir also eine starke Aussage get√§tigt.\n\n\n:::{#def-indep}\n### Stochastische Unabh√§ngigkeit\nZwei Ereignisse sind (stochastisch) unabh√§ngig voneinander, wenn die Wahrscheinlichkeit von $A$ nicht davon abh√§ngt, ob $B$ der Fall ist, s. @eq-indep.\nDann gilt:^[Exakte Gleichheit ist in dieser Welt empirisch schwer zu finden. Daher kann man vereinbaren, dass Unabh√§ngigkeit erf√ºllt ist, wenn die Gleichheit \"einigerma√üen\" oder \"ziemlich\" gilt, die Gleichheit gewisserma√üen \"praktisch bedeutsam\" ist.]\n\n \\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\n\n\n\n$$Pr(A|B) = Pr(A) = Pr(A|\\neg B). \\square$${#eq-indep}\n\nDie Unabh√§ngigkeit von $A$ und $B$ wird manchmal so in Kurzschreibweise ausgedr√ºckt: $\\indep(A, B) \\square$.\n:::\n\n\nSetzt man @eq-pr-cond2 in @eq-indep (linke Seite) ein, so folgt^[Vgl. @eq-multtheorem]\n\n$$Pr(B \\cap A) = Pr(A) \\cdot Pr(B).$${#eq-indep2}\n\n\n\n\n\n:::{#exm-indep1}\n### Augenfarbe und Statistikliebe\nIch vermute, dass die Ereignisse $A$, \"Augenfarbe ist blau\", und $B$, \"Ich liebe Statistik\", voneinander unabh√§ngig sind.$\\square$^[Wer Daten dazu hat oder eine Theorie, der melde sich bitte bei mir.]\n:::\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n:::{#exm-titanic}\n### √úberleben auf der Titanic\nS. @fig-abh, links: √úberleben (√ú) auf der Titanic ist offenbar *abh√§ngig* von der Passagierklasse ($K_1, K_2, K_3$). \nIn @fig-abh, links gilt also $Pr(√ú|K_1) \\ne Pr(√ú|K_2) \\ne Pr(√ú|K_3) \\ne Pr(√ú)$.\n\nAuf der anderen Seite: Das Ereignis *√úberleben* (√ú) auf der Titanic ist *un*abh√§ngig vom Ereignis *Alter ist eine Primzahl* (P), s. @fig-abh, rechts.\nAlso: $Pr(√ú|P) = Pr(√ú|\\neg P) = Pr(√ú)$, vgl. @tbl-titanic-prime. \n\n\n::: {#tbl-titanic-prime .cell tbl-cap='Kontingenztablle (H√§ufigkeiten) f√ºr \\'√úberleben auf der Titanic\\' und \\'Alter ist Primzahl\\'. Wie man sieht, gibt es keine stochastische Abh√§ngigkeit.'}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"uyrtnbavvn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#uyrtnbavvn table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#uyrtnbavvn thead, #uyrtnbavvn tbody, #uyrtnbavvn tfoot, #uyrtnbavvn tr, #uyrtnbavvn td, #uyrtnbavvn th {\n  border-style: none;\n}\n\n#uyrtnbavvn p {\n  margin: 0;\n  padding: 0;\n}\n\n#uyrtnbavvn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#uyrtnbavvn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#uyrtnbavvn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#uyrtnbavvn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#uyrtnbavvn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#uyrtnbavvn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#uyrtnbavvn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#uyrtnbavvn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#uyrtnbavvn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#uyrtnbavvn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#uyrtnbavvn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#uyrtnbavvn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#uyrtnbavvn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#uyrtnbavvn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#uyrtnbavvn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uyrtnbavvn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#uyrtnbavvn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#uyrtnbavvn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#uyrtnbavvn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uyrtnbavvn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#uyrtnbavvn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uyrtnbavvn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#uyrtnbavvn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uyrtnbavvn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#uyrtnbavvn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#uyrtnbavvn .gt_left {\n  text-align: left;\n}\n\n#uyrtnbavvn .gt_center {\n  text-align: center;\n}\n\n#uyrtnbavvn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#uyrtnbavvn .gt_font_normal {\n  font-weight: normal;\n}\n\n#uyrtnbavvn .gt_font_bold {\n  font-weight: bold;\n}\n\n#uyrtnbavvn .gt_font_italic {\n  font-style: italic;\n}\n\n#uyrtnbavvn .gt_super {\n  font-size: 65%;\n}\n\n#uyrtnbavvn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#uyrtnbavvn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#uyrtnbavvn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#uyrtnbavvn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#uyrtnbavvn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#uyrtnbavvn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#uyrtnbavvn .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Age_prime\">Age_prime</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"n\">n</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"prop\">prop</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"3\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"0\">0</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"0  Age_prime\" class=\"gt_row gt_center\">non-prime</td>\n<td headers=\"0  n\" class=\"gt_row gt_right\">96</td>\n<td headers=\"0  prop\" class=\"gt_row gt_right\">0.17</td></tr>\n    <tr><td headers=\"0  Age_prime\" class=\"gt_row gt_center\">prime</td>\n<td headers=\"0  n\" class=\"gt_row gt_right\">453</td>\n<td headers=\"0  prop\" class=\"gt_row gt_right\">0.83</td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"3\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"1\">1</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"1  Age_prime\" class=\"gt_row gt_center\">non-prime</td>\n<td headers=\"1  n\" class=\"gt_row gt_right\">58</td>\n<td headers=\"1  prop\" class=\"gt_row gt_right\">0.17</td></tr>\n    <tr><td headers=\"1  Age_prime\" class=\"gt_row gt_center\">prime</td>\n<td headers=\"1  n\" class=\"gt_row gt_right\">282</td>\n<td headers=\"1  prop\" class=\"gt_row gt_right\">0.83</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n:::\n\n\n\n\n\n\n::: {#fig-abh .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![√úberleben und Passagierklasse sind abh√§ngig](0300-Wskt_files/figure-html/fig-abh-1.png){#fig-abh-1 width=100%}\n:::\n\n::: {.cell-output-display}\n![√úberleben und 'Geburstag ist eine Primzahl' sind nicht abh√§ngig](0300-Wskt_files/figure-html/fig-abh-2.png){#fig-abh-2 width=100%}\n:::\n\nAbh√§ngigkeit und Unabh√§ngigkeit zweier Ereignisse\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::{#exm-covid}\n\n## Zusammenhang von Covidsterblichkeit und Impfquote\n\n\nSind die Ereignisse *Tod durch Covid*  bzw. *Impfquote* ($A$) und *Land*^[hier mit den zwei Auspr√§gungen *DEU* und *USA*] ($B$) voneinander abh√§ngig (@fig-covid1)?\n\n\n::: {#fig-covid1 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Impfquote und Land sind voneinander abh√§ngig](0300-Wskt_files/figure-html/fig-covid1-1.png){#fig-covid1-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Anteil Corona-Tote und Land sind voneinander abh√§ngig](0300-Wskt_files/figure-html/fig-covid1-2.png){#fig-covid1-2 width=672}\n:::\n\nImpfquote und Sterblichkeit sind voneinander abh√§ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n:::\n\n\nJa, die beiden Ereignisse sind abh√§gig, da in beiden Diagrammen gilt: $P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)$.$\\square$^[\nDaten von [Our World in Data](https://ourworldindata.org/covid-deaths).]\n\n\n:::\n\n\n\n\n\n\n\n\n### Multiplikationssatz\n\nGegeben seien die Ereignisse $A$ und $B$. Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass *beide Ereignisse* $A$ und $B$ eintreten.\n\n\n#### Unabh√§ngige Ereignisse\n\n\n:::{#exm-indep2}\nWir f√ºhren das Zufallsexperiment \"Wurf einer fairen M√ºnze\" zwei Mal aus (@fig-zweimuenzen).\nWie gro√ü ist die Wahrscheinlichkeit, 2 Mal *K*opf zu werfen?\nDabei vereinbaren wir, dass \"Kopf\" als \"Treffer\" z√§hlt (und \"Zahl\" als \"Niete\").$\\square$\n:::\n\n\n![Wir werfen zwei faire M√ºnzen](img/muenz1.png){#fig-zweimuenzen width=\"50%\"}\n\n @fig-zweimuenzen zeigt ein *Baumdiagramm*. \nJeder *Kasten* (Knoten) zeigt ein *Ergebnis.* \nDie Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom \"Start\" (schwarzer Kreis) \nf√ºhren zwei m√∂gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2.\nDie untersten Knoten nennt man auch *Bl√§tter* (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen M√ºnzwurfs.\nDer Weg vom Start zu einem bestimmten Blatt nennt man *Pfad*. \nDie Anzahl der Pfade entspricht der Anzahl der Bl√§tter.\nIn diesen Diagramm gibt es vier Pfade (und Bl√§tter).\n\nDen Wurf der ersten M√ºnze nennen wir in gewohnter Manier $A$; den Wurf der zweiten M√ºnze $B$.\n\n\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in @tbl-muenz2.\n\n\n\n::: {#tbl-muenz2 .cell tbl-cap='Wahrscheinlichkeiten der Ereignisse im zweimaligen M√ºnzwurf'}\n::: {.cell-output-display}\n\n\n|Ereignis |Pr              |\n|:--------|:---------------|\n|0K       |1/2 * 1/2 = 1/4 |\n|1K       |1/4 + 1/4 = 1/2 |\n|2K       |1/2 * 1/2 = 1/4 |\n\n\n:::\n:::\n\n\n\nSei $K_1$ das Ereignis, mit der 1. M√ºnze Kopf zu werfen; sei $K_2$ das Ereignis, mit der 2. M√ºnze Kopf zu werfen-\n\nWir suchen $Pr(K_1 \\cap K_2)$. Aufgrund der stochastischen Unabh√§ngigkeit der beiden Ereignisse gilt: $Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPr_K1K2 <- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n```\n:::\n\n\n\n:::{#def-multsatz}\n### Multiplikationssatz f√ºr unabh√§ngige Ereignisse\nDie Wahrscheinlichkeit, dass zwei unabh√§ngige Ereignisse $A$ und $B$ *gemeinsam* eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. @eq-multtheorem.\n\n$$Pr(A \\cap B) = Pr(AB) = Pr(A) \\cdot Pr(B) = Pr(B\\cap A) = Pr(B) \\cdot Pr(A)\\square$$ {#eq-multtheorem}\n:::\n\n\nMit [dieser App](https://www.geogebra.org/m/gzxz57ak) k√∂nnen Sie das Baumdiagramm f√ºr den zweifachen M√ºnzwurf n√§her erkunden.\n\n\n\n\nWir f√ºhren das Zufallsexperiment \"Wurf einer fairen M√ºnze\" drei Mal aus (@fig-dreimuenzen).\nDabei vereinbaren wir wieder, dass \"Kopf\" (K) als \"Treffer\" gilt und \"Zahl\" (Z) als \"Niete\".\n\n![Wir werfen drei faire M√ºnzen](img/muenz2.png){#fig-dreimuenzen}\n\n\nBeim Wurf von \"fairen\" M√ºnzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere Einsch√§tzung des Ergebnis des 2. Wurfes nicht ver√§ndert etc.\nAnders gesagt: Wir gehen von (stochastischer) Unabh√§ngigkeit aus.\n\n\nF√ºr z.B. das Ereignis $A=\\{ZZZ\\}$ gilt: $Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3$.\nDa jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jeweils gleich.\n\nAllgemeiner gilt: F√ºr ein Zufallsexpriment, das aus $k$ Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit $Pr(X)=p$ ist,\nso ist die Wahrscheinlichkeit f√ºr einen Endkonten $Pr(X^k)=p^k$.\n\n\n\n\n\n\n::: {#tbl-baum3 .cell tbl-cap='Ausgew√§hlte Wahrscheinlichkeiten von Ereignissen im dreifachen M√ºnzwurf'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Ereignis\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Pr\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"0K\",\"2\":\"1/2 * 1/2 * 1/2 = 1/8\"},{\"1\":\"1K\",\"2\":\"1/8 + 1/8 + 1/8 = 3/8\"},{\"1\":\"2K\",\"2\":\"3 * 1/8 = 3/8\"},{\"1\":\"3K\",\"2\":\"1/2 * 1/2 * 1/2 = 1/8\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. @tbl-baum3.\n\n\n@fig-schema-p versinnbildlicht nicht nur die Bedingtheit zweier Ereignisse, sondern auch die (Un-)Abh√§ngigkeit zweier Ereignisse, $A$ und $B$.\nIn diesem Fall ist die Wahrscheinlichkeit von $A$ gleich $B$: $Pr(A)=Pr(B)=.5$.\nMan sieht, dass die Wahrscheinlichkeit von $A$ bzw. von $B$ jeweils die H√§lfte der Fl√§che (der Gesamtfl√§che, d.h von $Pr(\\Omega)=1$) ausmacht. \nDie Schnittmenge der Fl√§che von $A$ und $B$ entspricht einem Viertel der Fl√§che: $Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.$\nIn diesem Fall sind $A$ und $B$ unabh√§ngig.\n\n\n::: {#fig-unabh-e .cell layout-ncol=\"3\"}\n::: {.cell-output-display}\n![$A$](0300-Wskt_files/figure-html/fig-unabh-e-1.png){#fig-unabh-e-1 width=672}\n:::\n\n::: {.cell-output-display}\n![$B$](0300-Wskt_files/figure-html/fig-unabh-e-2.png){#fig-unabh-e-2 width=672}\n:::\n\n::: {.cell-output-display}\n![$A \\cap B$, $B|A$](0300-Wskt_files/figure-html/fig-unabh-e-3.png){#fig-unabh-e-3 width=672}\n:::\n\nUnabh√§ngige Ereignisse visualisiert\n:::\n\n\n\n@fig-unabh-e zeigt weiterhin, dass gilt: $P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)$.\n\n:::{#exm-kaltregen}\n### Kalt und Regen\n\nVon @mcelreath_statistical_2020 stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit:\n\nWas ist die Wahrscheinlichkeit f√ºr *kalt ‚ùÑ und Regen ‚õàÔ∏è*?\n\nDie Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von *Regen* ‚õà, wenn's *kalt* ‚ùÑ ist mal die Wahrscheinlichkeit von *K√§lte* ‚ùÑ.\n\nEbenfalls gilt:\n\nDie Wahrscheinlichkeit f√ºr kalt und Regen ist die Wahrscheinlichkeit von *K√§lte* ‚ùÑ, wenn's *regnet* ‚õàÔ∏è mal die Wahrscheinlichkeit von *Regen* ‚õàÔ∏è.\n\nDas Gesagte als Emoji-Gleichung:\n\n$P(‚ùÑÔ∏è \\text{ und } ‚õàÔ∏è) = P(‚õàÔ∏è |‚ùÑÔ∏è ) \\cdot P(‚ùÑÔ∏è) =  P(‚ùÑÔ∏è |‚õàÔ∏è ) \\cdot P(‚õàÔ∏è) = P(‚õà \\text{ und }   ‚ùÑÔ∏è)$\nMan kann also die \"Gleichung drehen\".^[Da $P(A\\cap B)=Pr(B \\cap A)$]$\\square$\n:::\n\n\n:::{#def-kettenregel}\n### Kettenregel\nAllgemein gesagt, spricht man von der *Kettenregel* der Wahrscheinlichkeitsrechnung, s. @eq-kette.\n\n$$P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\square$${#eq-kette}\n\nIn Worten: Die Wahrscheinlichkeit von $A$ gegeben $B$ ist gleich der Wahrscheinlichkeit von $A$ mal der Wahrscheinlichkeit von $B$ gegeben $A$.\n:::\n\n\n\n\n#### Abh√§ngige Ereignisse\n\n\n\nEin Baumdiagramm bietet sich zur Visualisierung abh√§ngiger Ereignisse an, s.  @fig-baum-abh. F√ºr unabh√§ngige Ereignisse √ºbrigens auch.\n\n\n:::{#exm-urne1}\nIn einer Urne befinden sich f√ºnf Kugeln, von denen vier rot sind und eine blau ist.\n\nwie gro√ü ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zur√ºcklegen (*ZOZ*) *zwei rote Kugeln* gezogen werden [@bourier_2018], S. 47.\n\n\nHier ist unsere Urne:\n\n$$\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}$$\n\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s.  @fig-baum-abh.\n\n\n\n```{mermaid}\n%%| fig-cap: \"Baumdiagramm f√ºr ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abh√§ngig ist vom 1. Zug.\"\n%%| label: fig-baum-abh\nflowchart LR\n  A[Start] -->|4/5|B[1. Zug: R]\n  A -->|1/5|C[1. Zug: B]\n  B -->|3/4|D[2. Zug: R]\n  B -->|1/4|E[2. Zug: B]\n  D --- H[Fazit: RR:  12/20]\n  E --- I[Fazit: RB: 4/20]\n  C -->|4/4|F[2. Zug: R]\n  C -->|0/4|G[2. Zug: B]\n  F --- J[Fazit: BR: 4/20]\n  G --- K[Fazit: BB: 0/20]\n```\n\n\n\n\nEs gilt also: $P(A\\cap B) = P(A) \\cdot P(B|A) \\square$.\n:::\n\n\n\n:::{#exm-bertie-botts}\n### Bertie Botts Bohnen jeder Geschmacksrichtung\n\n>   Sei blo√ü vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gew√∂hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.‚Äú\n\n‚Äî Ron Weasley zu Harry Potter^[Quelle: https://harrypotter.fandom.com/de/wiki/Bertie_Botts_Bohnen_jeder_Geschmacksrichtung]\n\nIn einem Beutel liegen $n=20$ *Bertie Botts Bohnen jeder Geschmacksrichtung*.\nUns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch $x=3$ furchtbar scheu√üliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres).\nSie haben sich nun bereit erkl√§rt, $k=3$ Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort!\nAlso, jetzt hei√üt es tapfer sein. Ziehen und runter damit!\n\nWie gro√ü ist die Wahrscheinlichkeit, *genau eine* scheu√üliche Bohne zu erwischen?\n\nEs gibt drei Pfade f√ºr 1 Treffer bei 3 Wiederholungen: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nPfad1 <- 3/20 * 17/19 * 16/18\nPfad2 <- 17/20 * 3/19 * 16/18\nPfad3 <- 17/20 * 16/19 * 3/18\n\nGesamt_Pr <- Pfad1 + Pfad2 + Pfad3\nGesamt_Pr\n## [1] 0.3578947\n```\n:::\n\n\n\n\nNutzen Sie [diese App](https://www.geogebra.org/m/j545R3Fu), um das auszuprobieren.\nSie m√ºssen in der App noch die Zahl der Bohnen ($n$) und die Zahl der scheu√ülichen Bohnen ($x$) einstellen.$\\square$\n:::\n\n\n:::{exr-baum3}\n### Baumdiagramm sucht Problem\n\n√úberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit [folgender Baumdiagramm-App](\nhttps://www.geogebra.org/m/WVKur4yM) gel√∂st werden kann.$\\square$\n:::\n\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.geogebra.org/m/WVKur4yM\" title=\"Baumdiagramm sucht Problem\"></iframe>\n```\n\n\n\n\n\n\n\n\n\n\n### Totale Wahrscheinlichkeit\n\n\n\n\n@fig-tot-wskt zeigt das Baumdiagramm f√ºr die Aufgabe @bourier_2018, S. 56.\n\n\n```{mermaid}\n%%| fig-cap: Totale Wahrscheinlichkeit\n%%| label: fig-tot-wskt\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -->|0.1|C[A2]\n  A -->|0.3|D[A3]\n  B -->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n```\n\n\n\n\nGesucht ist die Wahrscheinlichkeit $P(B)$; $A$ ist ein vollst√§ndiges Ereignissystem.\n\n\nDazu addieren wir die Wahrscheinlichkeiten der relevanten √Ñste.\nJeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse $A_i$ und $B$ dar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nW_Ast1 <- 0.6 * 0.05  # Wahrscheinlichkeit f√ºr Ast 1\nW_Ast2 <- 0.1 * 0.02  # ... Ast 2\nW_Ast3 <- 0.3 * 0.04  # ... Ast 3\nW_total <- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n```\n:::\n\n\nDie *totale Wahrscheinlichkeit* betr√§gt in diesem Beispiel also $P(B) = 4.4\\%$.^[Einfacher als das Rechnen mit Wahrscheinlichkeiten ist es in solchen F√§llen, wenn man anstelle von Wahrscheinlichkeiten absolute H√§ufigkeiten zum Rechnen verwendet.]\n\n:::{#def-totwskt}\n### Totale Wahrscheinlichkeit\nBilden die Ereignisse $A_1, A_2, ..., A_n$ ein vollst√§ndiges Ereignissystem und ist $B$ ein beliebiges Ereignis dann gilt $Pr(B) = \\sum_{i=1}^n Pr(A_i) \\cdot Pr(B|A_i).\\square$\n:::\n\n::: {exm-totwskt1}\nIn @fig-tot-wskt gilt $Pr(B) = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot  0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square$\n:::\n\n\n\n\n\n:::{#exr-bertie-botts2}\n### Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2\n\n\n::: {.cell}\n\n:::\n\n\n\nEs ist die gleich Aufgabe wie @exm-bertie-botts, aber jetzt lautet die Frage: \nWie gro√ü ist die Wahrscheinlichkeit, *mindestens eine* scheu√üliche Bohne zu erwischen?^[Die Wahrscheinlichkeit *keine* scheu√üliche Bohne zu ziehen ist $1 - (17/20 \\cdot 16/19 \\cdot 15/18) \\approx 0.4$.]\n\n$\\square$\n:::\n\n\n### Baumsammlung\n\nBaumdiagramme sind ein hilfreiches Werkzeug f√ºr wiederholte Zufallsexperimente.\nDaher ist hier eine \"Baumsammlung\"^[Wald?] zusammengestellt, s. fig-baumsammlung.\n\n- Sie werfen 1 M√ºnze, @fig-baummuenz1.\n- Sie werfen 2 M√ºnzen, @fig-zweimuenzen.\n- Sie werfen 3 M√ºnzen, @fig-dreimuenzen.\n- Sie werfen 4 M√ºnzen, @fig-4muenzen.\n- Sie werfen 9 M√ºnzen, ü§Ø @fig-binom2.\n\n\n\n## Bayes' Theorem\n\n### Wozu wird Bayes in der Praxis genutzt?\n\n\n\n\nIn der Praxis nutzt man Bayes h√§ufig, wenn man Daten zu einer Wirkung $W$ hat,\nund auf die Ursache $U$ zur√ºckschlie√üen m√∂chte, sinngem√§√ü:\n\n$$W \\quad \\underrightarrow{Bayes} \\quad U$$\n\nDann kann man @eq-bayes1 so schreiben, s. @eq-bayes2:\n\n$$P(U|W) = \\frac{ P(U) \\cdot P(W|U) }{P(W)}$${#eq-bayes2}\n\nEine √§hnliche Situation, die in der Praxis h√§ufig ist,\ndass man Daten $D$ hat und auf die Wahrscheinlichkeit einer Hypothese $H$ schlie√üen m√∂chte, s. @eq-bayes3.\n\n$$D \\quad \\underrightarrow{Bayes} \\quad H$$\n\n\n$$P(H|D) = \\frac{ P(H) \\cdot P(D|H) }{P(D)}$${#eq-bayes3}\n\n@eq-bayes3 fragt nach $P(H|D)$:\n\n>    Was ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (@eq-bayes3):\n\n>    Diese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der Plausibilit√§t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgr√ºnden dividiert man noch die totale Wahrscheinlichkeit der Daten √ºber alle Hypothesen.\n\n\n\n### Bayes als Baum\n\nGesucht sei $P(A_1|B)$.\n\nF√ºr Bayes' Formel^[synonym: Satz von Bayes] setzt man die Wahrscheinlichkeit des  *g√ºnstigen* Ast zur Wahrscheinlichkeit aller relevanten √Ñste, $P(B)$.\n\n:::{#exm-bayes1}\n### Maschine produziert Ausschuss\n\nDie drei Maschinen $M_1, M_2, M_3$ produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. \nDie jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. @fig-tot-wskt2.\n*Aufgabe*: Wie gro√ü ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde?$\\square$\n:::\n\n\n\nDer g√ºnstige (gesuchte) Ast ist hier schwarz gedruckt, die √ºbrigen √Ñste gestrichelt, s. @fig-tot-wskt2. $A_i$ zeigt das Ereignis, dass der Artikel von Maschine $i$ produziert wurde. $B$ ist das Ereignis \"Artikel ist Ausschuss\".\n\n\n```{mermaid}\n%%| fig-cap: G√ºnstige Pfade\n%%| label: fig-tot-wskt2\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -.->|0.1|C[A2]\n  A -.->|0.3|D[A3]\n  B --->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -.->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -.->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n```\n\n\n\n$$P(A|B) = \\frac{P(A1 \\cap B)}{P(B)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68$$\n\n\n$P(A|B)$ betr√§gt also ca. 68%.\n\nZur Erinnerung: $P(B)$ ist die totale Wahrscheinlichkeit.\n\n\n\n\n### Bayes als bedingte Wahrscheinlichkeit\n\n\nBayes' Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:\n\n\n$P(A|B) = \\frac{\\overbrace{ P(A\\cap B)}^\\text{umformen}}{P(B)}$\n\n$P(A| B)$ kann man  umformen, s. @eq-bayes1:\n\n$$P(A|B) =\\frac{P(A\\cap B)}{P(B)} = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$ {#eq-bayes1}\n\nMan kann sich Bayes' Theorem  auch wie folgt herleiten:\n\n\n\n$P(A\\cap B) = P(B \\cap A) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)$\n\nDann l√∂sen wir nach P$(A|B)$ auf:\n\n\n$P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(B)}$\n\n\n\n### Zusammengesetzte Hypothesen\n\nDas ist vielleicht ein bisschen fancy,\naber man kann Bayes' Theorem auch nutzen, um die Wahrscheinlichkeit einer *zusammengesetzten Hypothese* zu berechnen: $H = H_1 \\cap H_2$. \nEin Beispiel w√§re: \"Was ist die Wahrscheinlichkeit, dass es Regen ($R$) *und* Blitzeis ($B$) gibt, wenn es kalt ($K$) ist?\".\n\nDas sieht dann so aus, @eq-bayes4:\n\n$$\n\\begin{aligned}\nP(R \\cap B |K) &= \\frac{ P(R \\cap B) \\cdot P(K|R \\cap B) }{P(D)} \\\\\n&= \\frac{ P(R ) \\cdot P(B) \\cdot P(K|R \\cap B) }{P(D)}\n\\end{aligned}\n$${#eq-bayes4}\n\n\nHier haben wir $P(R \\cap B)$  aufgel√∂st in $P(R) \\cdot P(B)$,\ndas ist nur zul√§ssig, wenn $R$ und $B$ unabh√§ngig sind.\n\n\n\n## Vertiefung\n\n\n\nBei @henze_stochastik_2019 findet sich eine anspruchsvollere Einf√ºhrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes  der Kapitel 2 und 3 von @henze_stochastik_2019.\n\nMit [dieser App, die ein zweistufiges Baumdiagramm zeigt](https://www.geogebra.org/m/n4xrk4x5), k√∂nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\n\n[Diese App l√§sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.](https://www.geogebra.org/m/tkdfxa8f)\n\nDas [Video zu Bayes von 3b1b](https://youtu.be/HZGCoVF3YvM) verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\n\n@mittag_statistik_2020 stellen in Kap. 11 die Grundlagen der Wahrscheinlichkeitstheorie vor.\n√Ñhnliche Darstellungen finden sich in einer gro√üen Zahl an Lehrb√ºchern.\n\n\n## Aufgaben\n\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\n\n1. [Additionssatz1](https://datenwerk.netlify.app/posts/additionssatz1/additionssatz1)\n2. [Nerd-gelockert](https://datenwerk.netlify.app/posts/nerd-gelockert/nerd-gelockert) \n3. [Urne1](https://datenwerk.netlify.app/posts/urne1/urne1) \n3. [Urne2](https://datenwerk.netlify.app/posts/urne2/urne2)\n3. [k-coins-k-hits](https://datenwerk.netlify.app/posts/k-coins-k-hits/k-coins-k-hits)\n\n5. [sicherheit](https://datenwerk.netlify.app/posts/sicherheit/sicherheit)\n4. [sicherheit2](https://datenwerk.netlify.app/posts/sicherheit2/sicherheit2)\n6. [Klausuren-bestehen](https://datenwerk.netlify.app/posts/klausuren-bestehen/klausuren-bestehen)\n\n3. [Gem-Wskt1](https://datenwerk.netlify.app/posts/gem-wskt1/gem-wskt1)\n3. [Gem-Wskt2](https://datenwerk.netlify.app/posts/gem-wskt2/gem-wskt2)\n3. [Gem-Wskt3](https://datenwerk.netlify.app/posts/gem-wskt3/gem-wskt3)\n3. [wuerfel05](https://datenwerk.netlify.app/posts/wuerfel05/wuerfel05)\n3. [wuerfel06](https://datenwerk.netlify.app/posts/wuerfel06/wuerfel06)\n\n3. [Bed-Wskt1](https://datenwerk.netlify.app/posts/bed-wskt1/bed-wskt1)\n3. [Bed-Wskt2](https://datenwerk.netlify.app/posts/bed-wskt2/bed-wskt2)\n3. [Bed-Wskt3](https://datenwerk.netlify.app/posts/bed-wskt3/bed-wskt3)\n\n3. [mtcars-abhaengig](https://datenwerk.netlify.app/posts/mtcars-abhaengig/mtcars-abhaengig.html)\n3. [mtcars-abhaengig-var2](https://datenwerk.netlify.app/posts/mtcars-abhaengig_var2/mtcars-abhaengig_var2)\n3. [mtcars-abhaengig_var3a](https://datenwerk.netlify.app/posts/mtcars-abhaengig_var3a/mtcars-abhaengig_var3a)\n\n3. [voll-normal](https://datenwerk.netlify.app/posts/voll-normal/voll-normal.html)\n3. [corona-blutgruppe](https://datenwerk.netlify.app/posts/corona-blutgruppe/corona-blutgruppe.html)\n\n\n3. [totale-Wskt1](https://datenwerk.netlify.app/posts/totale-wskt1/totale-wskt1)\n3. [Krebs1](https://datenwerk.netlify.app/posts/krebs1/krebs1)\n3. [Bayes-Theorem1](https://datenwerk.netlify.app/posts/bayes-theorem1/bayes-theorem1) \n \n\n\n\n\n## ---\n\n\n\n![](img/outro-03.jpg){width=100%}\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}