{
  "hash": "c150f5052e6b2ea6951c8983632ff317",
  "result": {
    "engine": "knitr",
    "markdown": "# Abschluss {#sec-abschluss}\n\n\n## Lernsteuerung\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ... \n\n- erl√§utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\n- typische ‚ÄúLieblingsfehler‚Äù benennen und Wege aufzeigen, um die Fehler zu umgehen\n- zwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik √ºbersetzen\n- die Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n\n### Ben√∂tigte R-Pakete\n\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n### Begleitvideos\n\n- [Fragestunde QM2](https://youtu.be/5nKy1hueZlIs)\n- [Playlist QM2](https://www.youtube.com/playlist?list=PLRR4REmBgpIGVptiSN-qDVEJKfFnUqDyL)\n- [Lieblingsfehler](https://youtu.be/imnicKTbStU)\n\n\n## Probeklausur\n\n\n### 2024\n\n(Diese Liste ist im Aufbau. Bitte konsultieren Sie f√ºr weitere Aufgaben selbst√§ndig alle relevanten Aufgaben, die in den Kapiteln vorgestellt wurden.)\n\n1. [ttest-als-regr](https://datenwerk.netlify.app/posts/ttest-als-regr/ttest-als-regr/)\n1. [Additionssatz1](https://datenwerk.netlify.app/posts/additionssatz1/additionssatz1)\n2. [Nerd-gelockert](https://datenwerk.netlify.app/posts/nerd-gelockert/nerd-gelockert) \n3. [Urne1](https://datenwerk.netlify.app/posts/urne1/urne1) \n3. [corona-blutgruppe](https://datenwerk.netlify.app/posts/corona-blutgruppe/corona-blutgruppe.html)\n3. [voll-normal](https://datenwerk.netlify.app/posts/voll-normal/voll-normal.html)\n4. [alphafehler-inflation3](https://datenwerk.netlify.app/posts/alphafehler-inflation3/alphafehler-inflation3.html)\n5. [verteilungen-quiz-05](https://datenwerk.netlify.app/posts/verteilungen-quiz-05/verteilungen-quiz-05)\n5. [verteilungen-quiz-03](https://datenwerk.netlify.app/posts/verteilungen-quiz-05/verteilungen-quiz-03)\n5. [verteilungen-quiz-04](https://datenwerk.netlify.app/posts/verteilungen-quiz-05/verteilungen-quiz-04)\n6. [Kekse03](https://datenwerk.netlify.app/posts/kekse03/index.qmd)\n6. [globus-bin2](https://datenwerk.netlify.app/posts/globus-bin2/)\n7. [globus2](https://datenwerk.netlify.app/posts/globus2/)\n8. [iq01a](https://datenwerk.netlify.app/posts/iq01a/)\n9. [gem-wskt4](https://datenwerk.netlify.app/posts/gem-wskt4/)\n10. [Rethink2m3](https://datenwerk.netlify.app/posts/rethink2m3/rethink2m3)\n3. [mtcars-post2a](https://datenwerk.netlify.app/posts/mtcars-post2a/)\n4. [groesse03](https://datenwerk.netlify.app/posts/groesse03/)\n5. [bath42](https://datenwerk.netlify.app/posts/bath42/bath42.html)\n6. [klausur-raten](https://datenwerk.netlify.app/posts/klausur-raten/klausur-raten)\n\n\n\n\n### 2023\n\n\n[Dieser Tag auf dem Datenwerk](https://datenwerk.netlify.app/#category=qm2-pruefung)  stellt Fragen einer Probepr√ºfung (Version 2023) zusammen.\n\n\n\n### 2022\n\n[Dieser Tag auf dem Datenwerk](https://datenwerk.netlify.app/#category=exam-22)  stellt Fragen einer Probepr√ºfung (Version 2022) zusammen.\n\n\n\n## Lieblinglingsfehler\n\n\n\nLieblingsfehler im √úberblick ü§∑:\n\n\n1. Quantile und Verteilungsfunktion verwechseln\n2. Pr√§diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\n4. Interaktion falsch interpretieren\n5. Regressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n\n\n### Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑\n\nüèé üèé Vertiefung: Dieser Abschnitt ist nicht pr√ºfungsrelevant. üèéÔ∏è üèé\n\nBerechnen wir unser Standard-mtcars-Modell: `mpg ~ hp`. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n```\n:::\n\n\n\n\n\n\nDie *Post-Verteilung* zeigt Stichproben zu den Parameterwerten, s. @tbl-post-m1.\n\n\n\n\n\n::: {#tbl-post-m1 .cell tbl-cap='Postverteilung in Stichprobenform (m1)'}\n\n```{.r .cell-code}\npost_verteilung <- m1 %>% \n  as_tibble()\nhead(post_verteilung)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"(Intercept)\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"hp\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sigma\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"28.88237\",\"2\":\"-0.04933309\",\"3\":\"4.031083\"},{\"1\":\"28.15858\",\"2\":\"-0.05843584\",\"3\":\"5.000400\"},{\"1\":\"32.33903\",\"2\":\"-0.07453341\",\"3\":\"5.048232\"},{\"1\":\"31.64452\",\"2\":\"-0.07162598\",\"3\":\"3.561679\"},{\"1\":\"28.71255\",\"2\":\"-0.05874985\",\"3\":\"4.520694\"},{\"1\":\"29.62507\",\"2\":\"-0.06900292\",\"3\":\"4.271953\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\nDiese Tabelle kann man hernehmen,\num Fragen zu Post-Verteilung zu beantworten.\nH√§ufig ist es aber bequemer, z.B. mit `parameters(m1)` Post-Intervalle und Punktsch√§tzer auszulesen.\n\n\n\nDie *Posterior-Pr√§diktiv-Verteilung (PPV)* zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Mazda RX4\",\"2\":\"22.70425\"},{\"1\":\"Mazda RX4 Wag\",\"2\":\"25.36519\"},{\"1\":\"Datsun 710\",\"2\":\"25.81817\"},{\"1\":\"Hornet 4 Drive\",\"2\":\"21.17388\"},{\"1\":\"Hornet Sportabout\",\"2\":\"20.75181\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n### Quantile und Verteilungsfuntion verwechseln ü§∑\n\n\n\n#### Quantil f√ºr $p$\n\nEin $p$-Quantil teilt eine Verteilung in zwei Teile, \nund zwar so, dass mind. $p$ kleiner oder gleich dem $p$-Quantil sind. s. @fig-quantil.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![50%-Quantil](1200-abschluss_files/figure-html/fig-quantil-1.png){#fig-quantil width=672}\n:::\n:::\n\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betr√§gt $x=0$.\nMind ein Anteil $1-p$ ist gr√∂√üer oder gleich dem $p$-Quantil.\n\n\n\n#### Verteilungsfunktion $F$\n\n$F(x)$ gibt die Wahrscheinlichkeit an der Stelle $x$ an, \ndass $X$ einen Wert kleiner oder gleich $x$ annimmt, s. @fig-F.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilungsfunktion F(x=0)=1/2](1200-abschluss_files/figure-html/fig-F-1.png){#fig-F width=672}\n:::\n:::\n\n\n\n\n\n$F(0)=1/2$, die Wahrscheinlichkeit betr√§gt hier 50%, dass $x$ nicht gr√∂√üer ist als 0.\n\n\n\n### Interaktion falsch interpretieren ü§∑\n\n\nBerechnen wir ein einfaches Interaktionsmodell: `mpg ~ hp*vs`.\n\n:::callout-note\nZur Erinnerung: `mpg ~ hp*vs` ist synonym zu (aber k√ºrzer als) `mpg ~ hp + vs + hp:vs`.\n:::\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n```\n:::\n\n\n\n\n\n\nModellkoeffizienten, s. @tbl-m2-params.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparameters(m2)\n```\n:::\n\n::: {#tbl-m2-params .cell tbl-cap='Parameter von m2'}\n::: {.cell-output-display}\n\n\n|Parameter   | Median |         95% CI |     pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:------:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  24.62 | (18.87, 30.21) |   100% | 1.003 | 2246.00 | Normal (20.09 +- 15.07) |\n|hp          |  -0.04 | (-0.07, -0.01) | 99.75% | 1.003 | 2257.00 |   Normal (0.00 +- 0.22) |\n|vs          |  14.05 |  (4.82, 23.14) | 99.85% | 1.002 | 1792.00 |  Normal (0.00 +- 29.89) |\n|hp:vs       |  -0.11 | (-0.19, -0.03) | 99.30% | 1.001 | 1941.00 |   Normal (0.00 +- 0.31) |\n\n\n:::\n:::\n\n\n\n\n\n@tbl-m2-params zeigt die Visualisierung der Parameter von m2.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(m2))\n```\n\n::: {.cell-output-display}\n![Parameter von m2 visualisiert](1200-abschluss_files/figure-html/fig-m2-params-1.png){#fig-m2-params width=672}\n:::\n:::\n\n\n\n\n\n\n\n**Falsch üòà**\nDer Unterschied im Verbrauch zwischen den beiden Gruppen `vs=0` und `vs=1` betr√§gt ca. -0.11.\n\n\n\n\n**Richtig üëº**\nDer Unterschied im Verbrauch zwischen den beiden Gruppen `vs=0` und `vs=1` betr√§gt ca. -0.11 -- *wenn* `hp=0`.\n\n\n\nDa `hp=0` kein realistischer Wert ist, \nist das Modell schwer zu interpretieren.\nZentrierte Pr√§diktoren w√§ren hier eine sinnvolle L√∂sung.\n\n\n\n@gelman2021,Kap. 10, @mcelreath2020, Kap. 8\n\n\n\n\n\n\n\n\n\n\n\n\n## Kochrezepte üç≤\n\n\n\n\n\n\n\n\n### Kochrezept: Forschungsfrage untersuchen\n\n*Theoretische Phase*\n1. Staunen √ºber ein Ph√§nomen, $y$, Kausalfrage finden\n2. Literatur w√§lzen, um m√∂gliche Ursachen $x$ von $y$ zu lernen\n3. Forschungsfrage, Hypothese pr√§zisieren\n4. Modell pr√§zisieren (DAG(s), Prioris)\n\n*Empirische Phase*\n\n5. Versuch planen\n6. Daten erheben\n\n*Analytische Phase*\n\n7. Daten aufbereiten\n8. Modell berechnen anhand eines oder mehrerer DAGs\n9. Modell pr√ºfen/kritisieren\n10. Forschungsfrage beantworten\n\n\n\nYeah! Fertig.\n\n\n\n### Parameter sch√§tzen vs. Hypothesen pr√ºfen\n\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter sch√§tzen.\nBeispiel Hypothesenpr√ºfung: \"Frauen parken im Durchschnitt schneller ein als M√§nner\".\nBeispiel Parametersch√§tzung: \"Wie gro√ü ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und M√§nnern?\"\n\nJe ausgereifter ein Forschungsfeld, desto *k√ºhnere* Hypothesen lassen sich formulieren:\n    - stark ausgereift: \n      - Die n√§chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, [Quelle](https://www.solar-eclipse.info/de/eclipse/country/DE/)\n    - gering ausgereift: \n      - Die n√§chste Sonnenfinsternis wird in den n√§chsten 100 Jahren stattfinden.\n      - Lernen bringt mehr als Nicht-Lernen f√ºr den Klausurerfolg.\nK√ºhne Hypothesen sind w√ºnschenswert ü¶π \n\n\n\n\n### Formalisierung von Forschungsfragen\n\nDer Mittelwert in Gruppe A ist h√∂her als in Gruppe B (der Unterschied, $d$, im Mittelwert ist gr√∂√üer als Null):\n\n$$\\mu_1 > \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 > 0 \\Leftrightarrow \\mu_d > 0$$\n\n\n\n\n\n\n\n\n## Kerngedanken Bayes\n\n\nüì∫ [Bayes in f√ºnf Minuten](https://www.youtube.com/watch?v=yfOppH_2uSI)\n\nüì∫ [Bayes in zehn Minuten](https://www.youtube.com/watch?v=8a75ZnyycFc)\n\n### Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\n\nBerechnen wir wieder ein einfaches^[langweiliges] Modell: `mpg ~ hp`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- stan_glm(mpg ~ hp, data = mtcars)\n```\n:::\n\n\n\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. @fig-post-m3.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Post-Verteilung (HDI) von m3](1200-abschluss_files/figure-html/fig-post-m3-1.png){#fig-post-m3 width=672}\n:::\n:::\n\n\n\n\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist m√∂glich und oft sinnvoll.\nVerschiedene Arten des Zusammenfassens der Post-Verteilung sind m√∂glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall.\nAllerdings √ºbermittelt nur die gesamte Post-Verteilung alle Informationen.\nDaher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n\n\n\n\n### Posteriori als Produkt von Priori und Likelihood\n\n$$\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Beispiele f√ºr Pr√ºfungsaufgaben\n\n\n\n\n### Geben Sie den korrekten Begriff an!\n\n\n  üå¨üöôüôãÔ∏èüë®‚¨ÖÔ∏èHans üëß‚¨ÖÔ∏èAnna üë©‚¨ÖÔ∏èLise \n  \n  \n  \nPuh, wie erstelle ich f√ºr alle Studis ein anderes R√§tsel^[Fahr-Hier-Hans-Anna-Lise: Varianzanalyse]? \n\n\n<!-- :::callout-note -->\n<!-- In einer Open-Book-Pr√ºfung bekommen alle Studentis eine eigene, jeweils andere Pr√ºfung. -->\n<!-- Teamarbeit bleibt nat√ºrlich trotzdem untersagt. -->\n<!-- ::: -->\n\n\n\n### DAG mit doppelter Konfundierung\n\n\nPuh, jetzt kommt ein wilder DAG, s. @fig-dag-wild.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?](1200-abschluss_files/figure-html/fig-dag-wild-1.png){#fig-dag-wild width=672}\n:::\n:::\n\n\n\n\n\n:::{#def-minadjust}\n### Minimale Adjustierungsmenge \n\ndie Minimale Adjustierungsmenge f√ºr `x` und `y` gibt eine kleinstm√∂gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von `x` auf `y` zu bestimmen (zu \"identifizieren\"). $\\square$\n:::\n\n‚ùìGeben Sie die minimale Adjustierungsmenge (minimal adjustment set) an,\num den totalen (gesamten) Effekt von *E* auf *D* zu bestimmen!\n\n‚ùó Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\n\nJa, dem DAG ist zu helfen.\n\n\n### DAG mit vielen Variablen\n\nJe nach dem wie komplex Ihre Theorie ist, ist\nIhr DAG auch komplex, s. @fig-dag-komplex.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein DAG mit vielen Variablen](1200-abschluss_files/figure-html/fig-dag-komplex-1.png){#fig-dag-komplex width=672}\n:::\n:::\n\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\n\nTrotz der vielen Variablen,\nist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n\n### Ein Kausalmodell der Schizophrenie, van Kampen (2014)\n\n*The SSQ model of schizophrenic prodromal unfolding revised:* \n\n*An analysis of its causal chains based on the language of directed graphs*\n\nD. van Kampen\n\nLesen Sie [hier den Abstract](https://www.cambridge.org/core/journals/european-psychiatry/article/abs/ssq-model-of-schizophrenic-prodromal-unfolding-revised-an-analysis-of-its-causal-chains-based-on-the-language-of-directed-graphs/F2E7BBFC1B392616DB894AFBFABE7818).\n\nFolgende Symptome der Schizophrenie wurden gemessen:\n\nSocial Anxiety (*SAN*), Active Isolation (*AIS*), Affective Flattening (*AFF*), Suspiciousness (*SUS*), Egocentrism (*EGC*), Living in a Fantasy World (*FTW*), Alienation (*ALN*), Apathy (*APA*), Hostility (*HOS*), Cognitive Derailment (*CDR*), Perceptual Aberrations (*PER*), and Delusional Thinking (*DET*)\n\n@vankampen2014\n\nUV: *SUS*, AV: *EGC*\n\n\nBerechnen Sie die minimale Adjustierungsmenge, \num den kausalen Effekt der UV auf die AV zu identifizieren!\n\n\n\n@fig-van-kampen zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein DAG zu den Symptomen der Schizophrenie](1200-abschluss_files/figure-html/fig-van-kampen-1.png){#fig-van-kampen width=672}\n:::\n:::\n\n\n\n\n\n\nMinimales Adjustment-Set f√ºr den totalen Kausaleffekt: {AIS, ALN}\n\n\n\n\n\n\n### Modelle berechnen\n\n\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen.\nOrientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\n\nPr√ºfungsfragen zu Modellen k√∂nnten z.B. sein:\n\n- Geben Sie den Punktsch√§tzer (Median) f√ºr den Pr√§diktor X im Modell Y an!\n- Geben Sie ein 89%-HDI f√ºr den Parameter X im Modell Y an!\n- Geben Sie R-Quadrat an.\n- Formulieren Sie ein Interaktionsmodell!\n- Welches Modell ist korrekt, um den kausalen Effekt zu modellieren?\n- Formulieren Sie ein Modell mit folgenden Prioris ...\n- Liegt der Effekt X noch im ROPE ?\n- Unterscheidet sich die Breite des CI von der Breite des HDI f√ºr den Pr√§diktor X im Modell Y?\n- Was ver√§ndert sich an den Parametern, wenn Sie die Pr√§diktoren zentrieren/z-standardisieren?\n- ...\n\n\n\n\n## Aufgabensammlungen \n\nFolgende Tags auf dem [Datenwerk](https://datenwerk.netlify.app/) beinhalten relevante Aufgaben^[das ist keine vollst√§ndige Liste, sondern eine Anregung. Andere Tags k√∂nnten auch relevant sein]:\n\n\n- [bayes](https://datenwerk.netlify.app/#category=bayes)\n- [bayes-grid](https://datenwerk.netlify.app/#category=bayes-grid)\n- [dag](https://datenwerk.netlify.app/#category=dag)\n- [qm2](https://datenwerk.netlify.app/#category=dag)\n- [probability](https://datenwerk.netlify.app/#category=probability)\n- [post](https://datenwerk.netlify.app/#category=post)\n- [rope](https://datenwerk.netlify.app/#category=rope)\n\n\n\nBesondere \"Pr√ºfungsn√§he\" k√∂nnten diese Sammlungen haben:\n\n- [qm2-pruefung](https://datenwerk.netlify.app/#category=qm2-pruefung)\n- [exam-22](https://datenwerk.netlify.app/#category=exam-22)\n- [quiz1-qm2-ws23](https://datenwerk.netlify.app/#category=quiz1-qm2-ws23)\n- [Verteilungen-Quiz](https://datenwerk.netlify.app/#category=Verteilungen-Quiz)\n\n\n\n\n\n\n\n\n## FAQ \n\n\n\n\n### Probeklausur?\n\nFRAGE: Wo finde ich eine Probeklausur? \n\nANTWORT: [Dieser Tag](https://datenwerk.netlify.app/#category=qm2-pruefung)  stellt Fragen einer Probepr√ºfung zusammen.\n\n\n### Wie bereite ich mich gut auf die Pr√ºfung vor? \nFRAGE: Wie bereite ich mich gut auf die Pr√ºfung vor? \n\nANTWORT:\n[Hier](https://hinweisbuch.netlify.app/hinweise-pruefungsvorbereitung-frame) finden Sie Tipps zur Pr√ºfungsvorbereitung.\n\n\n### Intercept?\n\nFRAGE: Wenn man '(Intercept)' benutzt, welche Anf√ºhrungszeichen sind die richtigen? Bei verschiedenen Anf√ºhrungszeichen, also ' oder \\` oder ¬¥ kommen entweder keine oder sogar verschiedene Ergebnisse raus. \n\nANTWORT: Normalerweise ist innerhalb von R-Befehlen aus dem Tidyverse keine Anf√ºhrungsstriche f√ºr Spaltennamen n√∂tig. Wenn es allerdings ein \"verbotener\" Name ist, muss man aufpassen. `(Intercept)` ist so ein verbotener Variablenname. Warum verboten? Ein \"braver\" Variablenname (in R) muss mit einem Buchstaben beginnen und darf keine Sonderzeichen (`(, {, #,` etc.) enthalten. Hat man aber einen an sich unerlaubten Variablennamen, so kann man den trotzdem verwenden, *wenn* man ihn mit Backticks (\\`) umgibt, also wie in `\\(Intercept)\\`). Doppelte und einfache Anf√ºhrungsstriche sind in R √ºbrigens beide okay, wenn man etwa einen String (Text) auszeichnen will, aber im Rahmen von Tidyverse nicht n√∂tig f√ºr Variablennamen.\n\n\n\n### Pr√§diktoren vorher zentrieren?\n\nFRAGE: Woher wei√ü ich, dass ich die Pr√§diktoren vorher zentrieren muss? Kann man das aus der Aufgabenstellung irgendwie herauslesen? Z.B. wie bei Tutorium Aufgabe 10.1 d). \n\nANTWORT: Es gibt mehrere Gr√ºnde, Variablen zu zentrieren, dazu z√§hlen 1) bessere Interpretation des Intercepts, 2) bessere Interpretation von Interaktionseffekten, 3) Verringerung von Kollinearit√§t. Die Steigung (beta 1) ver√§ndert sich (fast immer) aber nicht durch das Zentrieren, ebenso wie R-Quadrat.\n\n\n### Dichotomisierung\n\nFRAGE: Bei der Bearbeitung der Pr√ºfung heute ist ein Fehler aufgekommen, den ich bis jetzt nicht verstehe. Deshalb war es auch f√ºr mich nicht m√∂glich die Aufgabe zu bearbeiten. Die AV high Aufteilung in die Werte 0 und 1 (0 = AV <= median (AV)) (1 =AV > median(AV) hat geklappt.\nDie UV high Aufteilung in die Werte 0 und 1 (0 = UV <= median (UV)) (1 =UV > median(UV) hat dabei aber nicht geklappt.\nAnstatt die Werte 0 und 1 bei der neuen UV_high Spalte zu bekommen, kommen nur Nas raus. Auch mit dem Befehl drop_na hat es nicht geklappt. Dies habe ich nicht nur mit dem RStudio auf meinem Computer versucht sondern auch √ºber die Cloud √ºber mein IPad. (Bei beiden Ger√§ten kam es zuvor noch nie zu Problemen) Hier mein R-Code:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n#library(easystats)\n#library(rstanarm)\n\ndata(\"msleep\", package = \"ggplot2\")\n\nmsleep1 <-\n  msleep |> \n    mutate(av_high = case_when(awake > median(awake) ~ 1,\n                               awake <= median(awake) ~ 0))\n\nmsleep2 <-\n  msleep1 |> \n    mutate(uv_high = case_when(sleep_rem > median(sleep_rem) ~ 1,\n                               sleep_rem <= median(sleep_rem) ~ 0))\n  \nmsleep2 |> \ncount(uv_high)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"uv_high\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"83\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nANTWORT: Sie haben nicht die fehlenden Werte ausgeschlossen. Wenn Sie die fehlenden Wert ausschlie√üen, dann klappt die Dichotomisierung (die Aufteilung einer metrischen Variablen in eine bin√§re):\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmsleep2 <-\n  msleep1 |> \n  drop_na(sleep_rem) |>  # fehlende Werte aus `sleep_rem` entfernen\n    mutate(uv_high = case_when(sleep_rem > median(sleep_rem) ~ 1,\n                               sleep_rem <= median(sleep_rem) ~ 0))\n  \nmsleep2 |> \ncount(uv_high)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"uv_high\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"31\"},{\"1\":\"1\",\"2\":\"30\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n### Bin ich im Toleranzbereich?\n\nFRAGE: Ich habe meine L√∂sungswege mit Ihren abgeglichen und finde keinen bedeutenden Unterschied. Dennoch erhalte ich andere Ergebnisse, welche nicht im Toleranzbereich liegen. Um das nochmals zu √ºberpr√ºfen, habe ich Ihre L√∂sungswege 1:1 in mein RStudio √ºbertragen, aber auch dann erhalte ich nicht die angegebene L√∂sung. \n\nANTWORT: Es sollte ein Modell berechnet werden mit z-transformierten Variablen. F√ºr die UV war der ROPE anzugeben. Leider haben Sie vergessen, die Daten zu z-transformieren.\n\nHier ist das Modell *ohne* z-Transformation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(dplyr)\n\npenguins <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm1 <- stan_glm(bill_length_mm ~ year, data = penguins, refresh = 0)\n\nrope(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Parameter\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"CI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_low\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_high\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_Percentage\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Effects\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Component\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.95\",\"3\":\"-0.5459584\",\"4\":\"0.5459584\",\"5\":\"0.0005263158\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"1\"},{\"1\":\"year\",\"2\":\"0.95\",\"3\":\"-0.5459584\",\"4\":\"0.5459584\",\"5\":\"0.7123684211\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nHier ist das Modell *mit* z-Transformation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np2 <- \n  penguins |> \n  select(bill_length_mm, year) |> \n  standardise()\n\nm2 <- stan_glm(bill_length_mm ~ year, data = p2, refresh = 0)\n\nrope(m2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Parameter\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"CI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_low\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_high\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_Percentage\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Effects\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Component\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.95\",\"3\":\"-0.1\",\"4\":\"0.1\",\"5\":\"0.9789474\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"1\"},{\"1\":\"year\",\"2\":\"0.95\",\"3\":\"-0.1\",\"4\":\"0.1\",\"5\":\"0.8147368\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\nDer Wert von `m2` findet sich in der Musterl√∂sung. Man beachte, dass sich die Rope-Werte von `m1` und `m2` deutlich unterscheiden.\n\n\n### Andere Ergebnisse trotz gleichen Befehls und `set.seed`?\n\nFRAGE: ich habe bei fast allen Aufgaben, die ich l√∂se, dass Problem, dass mein Ergebnis stark von der L√∂sung abweicht, selbst bei exakt gleichem Code wie in der Musterl√∂sung.\nLeider ist die Abweichung so stark, dass ich nicht mal mehr im Toleranzbereich bin.\nTeilweise kommen extrem andere Ergebnisse raus. Wie ist dieses Problem zu l√∂sen?\nIch bearbeite die Aufgaben in der R Cloud und habe die Pakete tidyverse, easystats und rstanarm geladen.\nZudem habe ich die Pakete geupdated, sodass ich hier nicht weiter wei√ü.\n\nMeine L√∂sung:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins <- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm10.1 <- stan_glm(body_mass_g ~  flipper_length_mm,  # Regressionsgleichung\n               data = penguins, #  Daten\n               seed = 42,  # Repro.\n               refresh = 0)  # nicht so viel Output\n\nparameters(m10.1)\n```\n:::\n\n\n\n\n\n![](img/toleranzbereich.png)\n\n\nANTWORT: Tats√§chlich ist es so, dass es trotz gleichem Wert bei `set.seed()` Abweichungen nicht ausgeschlossen werden k√∂nnen. \nHintergrund ist, dass verschiedene Betriebssysteme oder weitere, im Hintergrund involvierte Software in unterschiedlichen Versionen zu Abweichungen f√ºhren k√∂nnen.\nIn Ihrem Fall ist der Wert aber innerhalb des Toleranzbereichs.\nIm Zweifel werden Sie mit einigem Probieren Ihren Wert nach der Pr√ºfung wiederholen k√∂nnen und so ggf. dem Pr√ºfer nachweisen k√∂nnen, das Ihr Ergebnis statthaft, sogar, wenn es nicht im Toleranzbereich w√§re.\n\nHier ist die von der Studentin angesprochene Musterl√∂sung:\n\n![](img/toleranz2.png)\n\n\nUnd hier ist der Toleranzbereich (vgl. @sec-toleranz) f√ºr den Intercept:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(prada)\nis_in_tolerance(asis = 5774.83,  # Ihr Wert\n                tobe = 5787.34917,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(penguins$body_mass_g))\n## [1] TRUE\n```\n:::\n\n\n\n\nWie man sieht, ist `is_in_tolerance` gleich `TRUE`. \n\nAuch der Punktsch√§tzer f√ºr die UV ist im Toleranzbereich:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_in_tolerance(asis = 49.66,  # Ihr Wert\n                tobe = 49.71739,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(penguins$body_mass_g))\n## [1] TRUE\n```\n:::\n\n\n\n\n\nAlso alles in Ordnung. Sie brauchen sich keine Sorgen zu machen, die Abweichung ist im Toleranzbereich.\n\n\n\n### RStudio Cloud st√ºrzt ab, was tun?\n\nFRAGE: Zudem wollte ich sie gerne noch fragen, wie ich in der Klausur verhindern kann, dass mein R Cloud mir diese Fehlermeldung anzeigt. Diese tritt vermehrt auf, wenn ich einige Minuten nichts in der R Cloud bearbeite. Danach erscheint das Fenster sehr oft nacheinander und es ist teilweise nicht mehr m√∂glich weiterzuarbeiten weil die Meldung immer wieder auftritt.\n\n![](img/rstudio-cloud-crash.png)\n\n\nANTWORT: Probieren Sie folgende Ma√ünahmen:\n\n1. Ist der Speicher in RStudio Cloud aufgebraucht? Das kann zu Abst√ºrzen f√ºhren. L√∂schen Sie Objekte und ent-laden Sie R-Pakete, um Speicher freizugeben.\n\n2. Wenn Sie mehr Speicher ben√∂tigen, k√∂nnten Sie (ggf. nur f√ºr einen Monat) ein kostenpflichtiges Abo abschlie√üen, welches mehr Speicher enth√§lt.\n\n3. Verringern Sie die Zeit, in der Sie RStudio Cloud nicht nutzen (die Idle-Time).\n\n4. Versuchen Sie, weniger speicherintensive Berechnungen durchzuf√ºhren.\n\n5. Weichen Sie auf RStudio Desktop aus.\n\n\n### Welche Themengebiete werden in der Pr√ºfung besonders behandelt?\n\n\nFRAGE: Welche Themengebiete werden in der Pr√ºfung besonders behandelt?\n\n\nANTWORT: In den Pr√ºfungen werden alle Themengebiete abgefragt, die in der Vorlesungbehandelt wurden. Es gibt keine speziellen Schwerpunkte, die besonders behandelt werden. Es ist ratsam, sich auf alle Themengebiete vorzubereiten. Tipp: Schwerpunkte im Unterricht spiegeln sich oft in den Pr√ºfungen wider.\n\n\n### RStudio in der Pr√ºfung?\n\n\nFRAGE: Wird R Studio noch eine Rolle spielen, z. B. indem wir Code oder Pseudocode schreiben m√ºssen, oder liegt der Fokus komplett auf Theorie? \n\nANTWORT: Bei einer \"Papier-und-Kugelschreiber-Klausur\" spielt RStudio keine Rolle. Es wird also kein Code geschrieben. Es wird aber durchaus vorkommen, dass Sie in der Klausur R-Code lesen und interpretieren m√ºssen.\n\n\n\n### Welche Art von Fragen?\n\nFRAGE: Welche Art von Fragen k√∂nnen wir erwarten? (z. B. Multiple Choice, offene Fragen oder mathematische Herleitungen)\n\n\nANTWORT: Die Pr√ºfung wird zu einem gro√üen Teil aus Multiple-Choice-Fragen bestehen. Es wird aber auch offene Fragen geben. Mathematische Herleitungen sind nicht zu erwarten.\nHingegen sind einfache Berechnungen (die mit einem kaufm√§nnischen Taschenrechner durchgef√ºhrt werden k√∂nnen) durchaus m√∂glich.\n\n\n### Vorbereitung?\n\n\nFRAGE: Gibt es bestimmte √úbungsaufgaben oder Materialien, die Sie empfehlen, um sich gezielt auf die Theorie-Klausur vorzubereiten?\n\nATNWORT: [Hier](https://datenwerk.netlify.app/#category=qm2-pruefung) finden Sie eine Sammlung von Fragen, die in einer Probepr√ºfung gestellt wurden. Diese Fragen k√∂nnen Ihnen helfen, sich gezielt auf die Pr√ºfung vorzubereiten.\n\nDar√ºber hinaus sollten Sie die theoretischen Inhalte des Skripts kennen sowie alle Themen, die im Unterricht behandelt wurden.\n\nZwar ist es formal kein Bestandteil der Pr√ºfung, die Begleitliteratur zu lesen, aber es kann hilfreich sein, um den Stoff besser zu verstehen.\n\n\n\n\n\n\n\n## Whiteboard\n\n\n<iframe style=\"border: 1px solid rgba(0, 0, 0, 0.1);\" width=\"800\" height=\"450\" src=\"https://applications.zoom.us/integration/wb/embedwhiteboard/home?docId=gqztui_gQRCZ5ky-UJgP6Q&pageId=211862677487616&embedId=1731053440541\" allowfullscreen></iframe>\n\n\n\n\n\n\n\n\n\n\n## Viel Erfolg bei der Pr√ºfung!\n\n\nü•≥üèÜüçÄüçÄüçÄ \n\n\n\n\n\n\n## ---\n\n\n\n![](img/outro-05.jpg){width=100%}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}