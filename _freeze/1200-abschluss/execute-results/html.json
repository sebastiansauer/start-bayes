{
  "hash": "efc24acbfa99614e61825c3b502283c9",
  "result": {
    "engine": "knitr",
    "markdown": "# Abschluss {#sec-abschluss}\n\n\n## Lernsteuerung\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ... \n\n- erl√§utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\n- typische ‚ÄúLieblingsfehler‚Äù benennen und Wege aufzeigen, um die Fehler zu umgehen\n- zwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik √ºbersetzen\n- die Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n\n### Ben√∂tigte R-Pakete\n\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n### Begleitvideos\n\n- [Fragestunde QM2](https://youtu.be/5nKy1hueZlIs)\n- [Playlist QM2](https://www.youtube.com/playlist?list=PLRR4REmBgpIGVptiSN-qDVEJKfFnUqDyL)\n- [Lieblingsfehler](https://youtu.be/imnicKTbStU)\n\n\n\n## Lieblinglingsfehler\n\n\n\nLieblingsfehler im √úberblick ü§∑:\n\n\n1. Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln\n2. Quantile und Verteilungsfunktion verwechseln\n3. Pr√§diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\n4. Interaktion falsch interpretieren\n5. Regressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n\n\n### Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑\n\nüèé üèé Vertiefung: Dieser Abschnitt ist nicht pr√ºfungsrelevant. üèéÔ∏è üèé\n\nBerechnen wir unser Standard-mtcars-Modell: `mpg ~ hp`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n```\n:::\n\n\n\nDie *Post-Verteilung* zeigt Stichproben zu den Parameterwerten, s. @tbl-post-m1.\n\n\n::: {#tbl-post-m1 .cell tbl-cap='Postverteilung in Stichprobenform (m1)'}\n\n```{.r .cell-code}\npost_verteilung <- m1 %>% \n  as_tibble()\nhead(post_verteilung)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"(Intercept)\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"hp\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sigma\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"31.46664\",\"2\":\"-0.07086419\",\"3\":\"4.488585\"},{\"1\":\"26.85402\",\"2\":\"-0.04849984\",\"3\":\"4.521452\"},{\"1\":\"27.83077\",\"2\":\"-0.05260868\",\"3\":\"3.595727\"},{\"1\":\"30.79478\",\"2\":\"-0.07927706\",\"3\":\"4.532495\"},{\"1\":\"34.38225\",\"2\":\"-0.09940896\",\"3\":\"4.266275\"},{\"1\":\"33.64277\",\"2\":\"-0.09474096\",\"3\":\"3.998164\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nDiese Tabelle kann man hernehmen,\num Fragen zu Post-Verteilung zu beantworten.\nH√§ufig ist es aber bequemer, z.B. mit `parameters(m1)` Post-Intervalle und Punktsch√§tzer auszulesen.\n\n\n\nDie *Posterior-Pr√§diktiv-Verteilung (PPV)* zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Mazda RX4\",\"2\":\"34.23679\"},{\"1\":\"Mazda RX4 Wag\",\"2\":\"24.09391\"},{\"1\":\"Datsun 710\",\"2\":\"19.78253\"},{\"1\":\"Hornet 4 Drive\",\"2\":\"24.45920\"},{\"1\":\"Hornet Sportabout\",\"2\":\"15.02487\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n\n### Quantile und Verteilungsfuntion verwechseln ü§∑\n\n\n\n#### Quantil f√ºr $p$\n\nEin $p$-Quantil teilt eine Verteilung in zwei Teile, \nund zwar so, dass mind. $p$ kleiner oder gleich dem $p$-Quantil sind. s. @fig-quantil.\n\n::: {.cell}\n::: {.cell-output-display}\n![50%-Quantil](1200-abschluss_files/figure-html/fig-quantil-1.png){#fig-quantil width=672}\n:::\n:::\n\n\nDas 50%-Quantil (.5-Quantil) betr√§gt $x=0$.\nMind ein Anteil $1-p$ ist gr√∂√üer oder gleich dem $p$-Quantil.\n\n\n\n#### Verteilungsfunktion $F$\n\n$F(x)$ gibt die Wahrscheinlichkeit an der Stelle $x$ an, \ndass $X$ einen Wert kleiner oder gleich $x$ annimmt, s. @fig-F.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilungsfunktion F(x=0)=1/2](1200-abschluss_files/figure-html/fig-F-1.png){#fig-F width=672}\n:::\n:::\n\n\n$F(0)=1/2$, die Wahrscheinlichkeit betr√§gt hier 50%, dass $x$ nicht gr√∂√üer ist als 0.\n\n\n\n### Interaktion falsch interpretieren ü§∑\n\n\nBerechnen wir ein einfaches Interaktionsmodell: `mpg ~ hp*vs`.\n\n:::callout-note\nZur Erinnerung: `mpg ~ hp*vs` ist synonym zu (aber k√ºrzer als) `mpg ~ hp + vs + hp:vs`.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n```\n:::\n\n\n\nModellkoeffizienten, s. @tbl-m2-params.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparameters(m2)\n```\n:::\n\n::: {#tbl-m2-params .cell tbl-cap='Parameter von m2'}\n::: {.cell-output-display}\n\n\n|Parameter   | Median |         95% CI |     pd |  Rhat |     ESS |                   Prior |\n|:-----------|:------:|:--------------:|:------:|:-----:|:-------:|:-----------------------:|\n|(Intercept) |  24.58 | (19.10, 30.36) |   100% | 1.002 | 1851.00 | Normal (20.09 +- 15.07) |\n|hp          |  -0.04 | (-0.07, -0.01) | 99.67% | 1.001 | 1860.00 |   Normal (0.00 +- 0.22) |\n|vs          |  14.05 |  (4.18, 23.19) | 99.72% | 1.001 | 1517.00 |  Normal (0.00 +- 29.89) |\n|hp:vs       |  -0.11 | (-0.20, -0.02) | 99.28% | 1.000 | 1668.00 |   Normal (0.00 +- 0.31) |\n\n\n:::\n:::\n\n\n@tbl-m2-params zeigt die Visualisierung der Parameter von m2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(m2))\n```\n\n::: {.cell-output-display}\n![Parameter von m2 visualisiert](1200-abschluss_files/figure-html/fig-m2-params-1.png){#fig-m2-params width=672}\n:::\n:::\n\n\n\n\n**Falsch üòà**\nDer Unterschied im Verbrauch zwischen den beiden Gruppen `vs=0` und `vs=1` betr√§gt ca. -0.11.\n\n\n\n\n**Richtig üëº**\nDer Unterschied im Verbrauch zwischen den beiden Gruppen `vs=0` und `vs=1` betr√§gt ca. -0.11 -- *wenn* `hp=0`.\n\n\n\nDa `hp=0` kein realistischer Wert ist, \nist das Modell schwer zu interpretieren.\nZentrierte Pr√§diktoren w√§ren hier eine sinnvolle L√∂sung.\n\n\n\n@gelman_regression_2021,Kap. 10, @mcelreath_statistical_2020, Kap. 8\n\n\n\n\n\n\n\n\n\n\n\n\n## Kochrezepte üç≤\n\n\n\n\n\n\n\n\n### Kochrezept: Forschungsfrage untersuchen\n\n*Theoretische Phase*\n1. Staunen √ºber ein Ph√§nomen, $y$, Kausalfrage finden\n2. Literatur w√§lzen, um m√∂gliche Ursachen $x$ von $y$ zu lernen\n3. Forschungsfrage, Hypothese pr√§zisieren\n4. Modell pr√§zisieren (DAG(s), Prioris)\n\n*Empirische Phase*\n\n5. Versuch planen\n6. Daten erheben\n\n*Analytische Phase*\n\n7. Daten aufbereiten\n8. Modell berechnen anhand eines oder mehrerer DAGs\n9. Modell pr√ºfen/kritisieren\n10. Forschungsfrage beantworten\n\n\n\nYeah! Fertig.\n\n\n\n### Parameter sch√§tzen vs. Hypothesen pr√ºfen\n\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter sch√§tzen.\nBeispiel Hypothesenpr√ºfung: \"Frauen parken im Durchschnitt schneller ein als M√§nner\".\nBeispiel Parametersch√§tzung: \"Wie gro√ü ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und M√§nnern?\"\n\nJe ausgereifter ein Forschungsfeld, desto *k√ºhnere* Hypothesen lassen sich formulieren:\n    - stark ausgereift: \n      - Die n√§chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, [Quelle](https://www.solar-eclipse.info/de/eclipse/country/DE/)\n    - gering ausgereift: \n      - Die n√§chste Sonnenfinsternis wird in den n√§chsten 100 Jahren stattfinden.\n      - Lernen bringt mehr als Nicht-Lernen f√ºr den Klausurerfolg.\nK√ºhne Hypothesen sind w√ºnschenswert ü¶π \n\n\n\n\n### Formalisierung von Forschungsfragen\n\nDer Mittelwert in Gruppe A ist h√∂her als in Gruppe B (der Unterschied, $d$, im Mittelwert ist gr√∂√üer als Null):\n\n$$\\mu_1 > \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 > 0 \\Leftrightarrow \\mu_d > 0$$\n\n\n\n\n\n\n\n\n## Kerngedanken Bayes\n\n\nüì∫ [Bayes in f√ºnf Minuten](https://www.youtube.com/watch?v=yfOppH_2uSI)\n\nüì∫ [Bayes in zehn Minuten](https://www.youtube.com/watch?v=8a75ZnyycFc)\n\n### Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\n\nBerechnen wir wieder ein einfaches^[langweiliges] Modell: `mpg ~ hp`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- stan_glm(mpg ~ hp, data = mtcars)\n```\n:::\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. @fig-post-m3.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Post-Verteilung (HDI) von m3](1200-abschluss_files/figure-html/fig-post-m3-1.png){#fig-post-m3 width=672}\n:::\n:::\n\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist m√∂glich und oft sinnvoll.\nVerschiedene Arten des Zusammenfassens der Post-Verteilung sind m√∂glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall.\nAllerdings √ºbermittelt nur die gesamte Post-Verteilung alle Informationen.\nDaher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n\n\n\n\n### Posteriori als Produkt von Priori und Likelihood\n\n$$\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Beispiele f√ºr Pr√ºfungsaufgaben\n\n\n\n\n### Geben Sie den korrekten Begriff an!\n\n\n  üå¨üöôüôãÔ∏èüë®‚¨ÖÔ∏èHans üëß‚¨ÖÔ∏èAnna üë©‚¨ÖÔ∏èLise \n  \n  \n  \nPuh, wie erstelle ich f√ºr alle Studis ein anderes R√§tsel^[Fahr-Hier-Hans-Anna-Lise: Varianzanalyse]? \n\n\n:::callout-note\nIn einer Open-Book-Pr√ºfung bekommen alle Studentis eine eigene, jeweils andere Pr√ºfung.\nTeamarbeit bleibt nat√ºrlich trotzdem untersagt.\n:::\n\n\n\n### DAG mit doppelter Konfundierung\n\n\nPuh, jetzt kommt ein wilder DAG, s. @fig-dag-wild.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?](1200-abschluss_files/figure-html/fig-dag-wild-1.png){#fig-dag-wild width=672}\n:::\n:::\n\n\n:::{#def-minadjust}\n### Minimale Adjustierungsmenge \n\ndie Minimale Adjustierungsmenge f√ºr `x` und `y` gibt eine kleinstm√∂gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von `x` auf `y` zu bestimmen (zu \"identifizieren\"). $\\square$\n:::\n\n‚ùìGeben Sie die minimale Adjustierungsmenge (minimal adjustment set) an,\num den totalen (gesamten) Effekt von *E* auf *D* zu bestimmen!\n\n‚ùó Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\n\nJa, dem DAG ist zu helfen.\n\n\n### DAG mit vielen Variablen\n\nJe nach dem wie komplex Ihre Theorie ist, ist\nIhr DAG auch komplex, s. @fig-dag-komplex.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein DAG mit vielen Variablen](1200-abschluss_files/figure-html/fig-dag-komplex-1.png){#fig-dag-komplex width=672}\n:::\n:::\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\n\nTrotz der vielen Variablen,\nist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n\n### Ein Kausalmodell der Schizophrenie, van Kampen (2014)\n\n*The SSQ model of schizophrenic prodromal unfolding revised:* \n\n*An analysis of its causal chains based on the language of directed graphs*\n\nD. van Kampen\n\nLesen Sie [hier den Abstract](https://www.cambridge.org/core/journals/european-psychiatry/article/abs/ssq-model-of-schizophrenic-prodromal-unfolding-revised-an-analysis-of-its-causal-chains-based-on-the-language-of-directed-graphs/F2E7BBFC1B392616DB894AFBFABE7818).\n\nFolgende Symptome der Schizophrenie wurden gemessen:\n\nSocial Anxiety (*SAN*), Active Isolation (*AIS*), Affective Flattening (*AFF*), Suspiciousness (*SUS*), Egocentrism (*EGC*), Living in a Fantasy World (*FTW*), Alienation (*ALN*), Apathy (*APA*), Hostility (*HOS*), Cognitive Derailment (*CDR*), Perceptual Aberrations (*PER*), and Delusional Thinking (*DET*)\n\n@van_kampen_ssq_2014\n\nUV: *SUS*, AV: *EGC*\n\n\nBerechnen Sie die minimale Adjustierungsmenge, \num den kausalen Effekt der UV auf die AV zu identifizieren!\n\n\n\n@fig-van-kampen zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Ein DAG zu den Symptomen der Schizophrenie](1200-abschluss_files/figure-html/fig-van-kampen-1.png){#fig-van-kampen width=672}\n:::\n:::\n\n\n\nMinimales Adjustment-Set f√ºr den totalen Kausaleffekt: {AIS, ALN}\n\n\n\n\n\n\n### Modelle berechnen\n\n\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen.\nOrientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\n\nPr√ºfungsfragen zu Modellen k√∂nnten z.B. sein:\n\n- Geben Sie den Punktsch√§tzer (Median) f√ºr den Pr√§diktor X im Modell Y an!\n- Geben Sie ein 89%-HDI f√ºr den Parameter X im Modell Y an!\n- Geben Sie R-Quadrat an.\n- Formulieren Sie ein Interaktionsmodell!\n- Welches Modell ist korrekt, um den kausalen Effekt zu modellieren?\n- Formulieren Sie ein Modell mit folgenden Prioris ...\n- Liegt der Effekt X noch im ROPE ?\n- Unterscheidet sich die Breite des CI von der Breite des HDI f√ºr den Pr√§diktor X im Modell Y?\n- Was ver√§ndert sich an den Parametern, wenn Sie die Pr√§diktoren zentrieren/z-standardisieren?\n- ...\n\n\n\n\n## Aufgabensammlungen \n\nFolgende Tags auf dem [Datenwerk](https://datenwerk.netlify.app/) beinhalten relevante Aufgaben^[das ist keine vollst√§ndige Liste, sondern eine Anregung. Andere Tags k√∂nnten auch relevant sein]:\n\n\n- [bayes](https://datenwerk.netlify.app/#category=bayes)\n- [bayes-grid](https://datenwerk.netlify.app/#category=bayes-grid)\n- [dag](https://datenwerk.netlify.app/#category=dag)\n- [qm2](https://datenwerk.netlify.app/#category=dag)\n- [probability](https://datenwerk.netlify.app/#category=probability)\n- [post](https://datenwerk.netlify.app/#category=post)\n- [rope](https://datenwerk.netlify.app/#category=rope)\n\n\n\nBesondere \"Pr√ºfungsn√§he\" k√∂nnten diese Sammlungen haben:\n\n- [qm2-pruefung](https://datenwerk.netlify.app/#category=qm2-pruefung)\n- [exam-22](https://datenwerk.netlify.app/#category=exam-22)\n- [quiz1-qm2-ws23](https://datenwerk.netlify.app/#category=quiz1-qm2-ws23)\n- [Verteilungen-Quiz](https://datenwerk.netlify.app/#category=Verteilungen-Quiz)\n\n\n\n\n\n\n\n\n## Fragenspeicher \n\n\n\n\n1. FRAGE: Wo finde ich eine Probeklausur? -- ANTWORT: [Dieser Tag](https://datenwerk.netlify.app/#category=qm2-pruefung)  stellt Fragen einer Probepr√ºfung zusammen.\n\n2. FRAGE: Wie bereite ich mich gut auf die Pr√ºfung vor? -- ANTWORT:\n[Hier](https://hinweisbuch.netlify.app/hinweise-pruefungsvorbereitung-frame) finden Sie Tipps zur Pr√ºfungsvorbereitung.\n\n3. FRAGE: Wenn man '(Intercept)' benutzt, welche Anf√ºhrungszeichen sind die richtigen? Bei verschiedenen Anf√ºhrungszeichen, also ' oder \\` oder ¬¥ kommen entweder keine oder sogar verschiedene Ergebnisse raus. -- ANTWORT: Normalerweise ist innerhalb von R-Befehlen aus dem Tidyverse keine Anf√ºhrungsstriche f√ºr Spaltennamen n√∂tig. Wenn es allerdings ein \"verbotener\" Name ist, muss man aufpassen. `(Intercept)` ist so ein verbotener Variablenname. Warum verboten? Ein \"braver\" Variablenname (in R) muss mit einem Buchstaben beginnen und darf keine Sonderzeichen (`(, {, #,` etc.) enthalten. Hat man aber einen an sich unerlaubten Variablennamen, so kann man den trotzdem verwenden, *wenn* man ihn mit Backticks (\\`) umgibt, also wie in `\\(Intercept)\\`). Doppelte und einfache Anf√ºhrungsstriche sind in R √ºbrigens beide okay, wenn man etwa einen String (Text) auszeichnen will, aber im Rahmen von Tidyverse nicht n√∂tig f√ºr Variablennamen.\n\n4. FRAGE: Woher wei√ü ich, dass ich die Pr√§diktoren vorher zentrieren muss? Kann man das aus der Aufgabenstellung irgendwie herauslesen? Z.B. wie bei Tutorium Aufgabe 10.1 d). -- ANTWORT: Es gibt mehrere Gr√ºnde, Variablen zu zentrieren, dazu z√§hlen 1) bessere Interpretation des Intercepts, 2) bessere Interpretation von Interaktionseffekten, 3) Verringerung von Kollinearit√§t. Die Steigung (beta 1) ver√§ndert sich (fast immer) aber nicht durch das Zentrieren, ebenso wie R-Quadrat.\n\n\n5. FRAGE: Bei der Bearbeitung der Pr√ºfung heute ist ein Fehler aufgekommen, den ich bis jetzt nicht verstehe. Deshalb war es auch f√ºr mich nicht m√∂glich die Aufgabe zu bearbeiten. Die AV high Aufteilung in die Werte 0 und 1 (0 = AV <= median (AV)) (1 =AV > median(AV) hat geklappt.\nDie UV high Aufteilung in die Werte 0 und 1 (0 = UV <= median (UV)) (1 =UV > median(UV) hat dabei aber nicht geklappt.\nAnstatt die Werte 0 und 1 bei der neuen UV_high Spalte zu bekommen, kommen nur Nas raus. Auch mit dem Befehl drop_na hat es nicht geklappt. Dies habe ich nicht nur mit dem RStudio auf meinem Computer versucht sondern auch √ºber die Cloud √ºber mein IPad. (Bei beiden Ger√§ten kam es zuvor noch nie zu Problemen) Hier mein R-Code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n#library(easystats)\n#library(rstanarm)\n\ndata(\"msleep\", package = \"ggplot2\")\n\nmsleep1 <-\n  msleep |> \n    mutate(av_high = case_when(awake > median(awake) ~ 1,\n                               awake <= median(awake) ~ 0))\n\nmsleep2 <-\n  msleep1 |> \n    mutate(uv_high = case_when(sleep_rem > median(sleep_rem) ~ 1,\n                               sleep_rem <= median(sleep_rem) ~ 0))\n  \nmsleep2 |> \ncount(uv_high)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"uv_high\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"83\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nANTWORT: Sie haben nicht die fehlenden Werte ausgeschlossen. Wenn Sie die fehlenden Wert ausschlie√üen, dann klappt es:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmsleep2 <-\n  msleep1 |> \n  drop_na(sleep_rem) |>  # fehlende Werte aus `sleep_rem` entfernen\n    mutate(uv_high = case_when(sleep_rem > median(sleep_rem) ~ 1,\n                               sleep_rem <= median(sleep_rem) ~ 0))\n  \nmsleep2 |> \ncount(uv_high)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"uv_high\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"31\"},{\"1\":\"1\",\"2\":\"30\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n6. FRAGE: Ich habe meine L√∂sungswege mit Ihren abgeglichen und finde keinen bedeutenden Unterschied. Dennoch erhalte ich andere Ergebnisse, welche nicht im Toleranzbereich liegen. Um das nochmals zu √ºberpr√ºfen, habe ich Ihre L√∂sungswege 1:1 in mein RStudio √ºbertragen, aber auch dann erhalte ich nicht die angegebene L√∂sung. -- ANTWORT: Es sollte ein Modell berechnet werden mit z-transformierten Variablen. F√ºr die UV war der ROPE anzugeben. Leider haben Sie vergessen, die Daten zu z-transformieren.\n\nHier ist das Modell *ohne* z-Transformation:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(dplyr)\n\npenguins <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm1 <- stan_glm(bill_length_mm ~ year, data = penguins)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 3.6e-05 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.09 seconds (Warm-up)\n## Chain 1:                0.133 seconds (Sampling)\n## Chain 1:                0.223 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 3.9e-05 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.115 seconds (Warm-up)\n## Chain 2:                0.18 seconds (Sampling)\n## Chain 2:                0.295 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 3.3e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.107 seconds (Warm-up)\n## Chain 3:                0.223 seconds (Sampling)\n## Chain 3:                0.33 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 0.000137 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.37 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.176 seconds (Warm-up)\n## Chain 4:                0.158 seconds (Sampling)\n## Chain 4:                0.334 seconds (Total)\n## Chain 4:\n\nrope(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Parameter\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"CI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_low\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_high\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_Percentage\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Effects\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Component\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.95\",\"3\":\"-0.5459584\",\"4\":\"0.5459584\",\"5\":\"0.0005263158\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"1\"},{\"1\":\"year\",\"2\":\"0.95\",\"3\":\"-0.5459584\",\"4\":\"0.5459584\",\"5\":\"0.7089473684\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nHier ist das Modell *mit* z-Transformation:\n\n::: {.cell}\n\n```{.r .cell-code}\np2 <- \n  penguins |> \n  select(bill_length_mm, year) |> \n  standardise()\n\nm2 <- stan_glm(bill_length_mm ~ year, data = p2)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 8e-05 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.092 seconds (Warm-up)\n## Chain 1:                0.15 seconds (Sampling)\n## Chain 1:                0.242 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 0.000111 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.11 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.079 seconds (Warm-up)\n## Chain 2:                0.149 seconds (Sampling)\n## Chain 2:                0.228 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 3.7e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.087 seconds (Warm-up)\n## Chain 3:                0.129 seconds (Sampling)\n## Chain 3:                0.216 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 3.8e-05 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.095 seconds (Warm-up)\n## Chain 4:                0.134 seconds (Sampling)\n## Chain 4:                0.229 seconds (Total)\n## Chain 4:\n\nrope(m2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Parameter\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"CI\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_low\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_high\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ROPE_Percentage\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Effects\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Component\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.95\",\"3\":\"-0.1\",\"4\":\"0.1\",\"5\":\"0.9834211\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"1\"},{\"1\":\"year\",\"2\":\"0.95\",\"3\":\"-0.1\",\"4\":\"0.1\",\"5\":\"0.8086842\",\"6\":\"fixed\",\"7\":\"conditional\",\"_rn_\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[5],\"max\":[5]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nDer Wert von `m2` findet sich in der Musterl√∂sung. Man beachte, dass sich die Rope-Werte von `m1` und `m2` deutlich unterscheiden.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Viel Erfolg bei der Pr√ºfung!\n\n\nü•≥üèÜüçÄüçÄüçÄ \n\n\n\n\n\n\n## ---\n\n\n\n![](img/outro-05.jpg){width=100%}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}