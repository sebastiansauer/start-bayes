# Lineare Modelle



## Ben√∂tigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(easystats)
library(rstanarm)
```


```{r libs-hidden}
#| include: false
library(latex2exp)
library("patchwork")
library("gt")
```



## Post-Verteilung der Regression


### Einfache Regression



- Die (einfache) Regression pr√ºft, inwieweit zwei Variablen, $Y$ und $X$ linear zusammenh√§ngen.
- Je mehr sie zusammenh√§ngen, desto besser kann man $X$ nutzen, um $Y$ vorherzusagen (und umgekehrt).
- H√§ngen $X$ und $Y$ zusammen, hei√üt das nicht (unbedingt), dass es einen *kausalen* Zusammenhang zwische $X$ und $Y$ gibt.
- Linear bedeutet, der Zusammenhang ist additiv und konstant: wenn $X$ um eine Einheit steigt, steigt $Y$ immer um $b$ Einheiten (nicht kausal, sondern deskriptiv gemeint).

[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv), @mcelreath_statistical_2020.



```{r Post-Regression-2}
#| fig-asp: 0.5
Kung_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv"

d <- read_csv(Kung_path)  

d2 <- 
  d %>% 
  filter(age > 18) 

d2 %>% 
  #select(weight, height) %>% 
  #drop_na() %>% 
  ggplot(
       aes(x = weight, y = height)) +
  geom_point(alpha = .7) +
  geom_smooth(method = "lm")
```





### Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr $\mu$


Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von $mu$) zu berechnen.

Hier am Beispiel von `m42`: 

```{r m42-read-from-disk, echo = FALSE}
#| echo: false
#| output: "hide"
m42 <- read_rds(paste0(here::here(),"/objects/m42.rds"))

m42_post <- as_tibble(m42)
names(m42_post) <- c("mu", "sigma")
```




```{r Post-Regression-10}
#| echo: false
plot_post_42 <- 
  m42_post %>% 
  ggplot() +
  aes(x = mu) +
  geom_density(fill = "grey60") +
  labs(x = expression(mu),
       title = TeX("Posteriori-Verteilung f√ºr $\\mu$, m42")) +
  scale_y_continuous(breaks = NULL)
```


```{r Post-Regression-11}
#| echo: false
lm1 <- lm(height ~ weight, data = d2)

d_pred <-
  tibble(weight = c(40, 45, 50, 55),
         height = predict(lm1, newdata = data.frame(weight)))

plot_condition <- 
  d2 %>% 
  #select(weight, height) %>% 
  #drop_na() %>% 
  ggplot(
       aes(x = weight, y = height)) +
  geom_point(alpha = .7) +
  geom_smooth(method = "lm") +
  geom_point(data = d_pred, color = "red", size = 5, alpha = .5) 
  scale_x_continuous(limits = c(0, 70))
```

```{r m3}
#| echo: false
#| results: "hide"

d2 <-
  d2 %>% 
  mutate(weight_c = weight - mean(weight))

m43 <- 
  stan_glm(height ~ weight_c, 
           prior = normal(0, 10),
           prior_intercept = normal(178, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = d2)

m43_prior_pred <-
    stan_glm(height ~ weight_c, 
           prior_intercept = normal(178, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE, 
           prior_PD = TRUE,
           data = d2)

stan_glm(height ~ weight_c, 
           prior = normal(0, 10),
           prior_intercept = normal(0, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = d2)

m43a_prior_pred <-
    stan_glm(height ~ weight_c, 
           prior_intercept = normal(0, 20),  # mu
           prior_aux = exponential(0.1),  # sigma
           refresh = FALSE, 
           prior_PD = TRUE,
           data = d2)
```






```{r eval = FALSE}
#| eval: false
#| echo: false
print(m43)
summary(m43_prior_pred)
write_rds(m43, "objects/m43.rds")
write_rds(m43a, "objects/m43a.rds")
```




```{r m43-plot}
#| echo: false
nd <- tibble(
  weight_c = c(-5, 0, +5, 10)
)

ppv_m43 <- 
  posterior_predict(m43, , newdata = nd) %>% 
  as_tibble() %>% 
  pivot_longer(everything(), 
               names_to = "weight_condition",
               values_to = "h")



ppv_m43_summary <-
  ppv_m43 %>% 
  group_by(weight_condition) %>% 
  summarise(m = mean(h),
            s = sd(h))


post_at_plot <-
  ppv_m43 %>% 
  ggplot() +
  aes(x = h) +
  geom_density(fill = "grey60") +
  facet_wrap(~ weight_condition, nrow = 1, scales = "free") +
  scale_y_continuous(breaks = NULL) +
  labs(title = "Post-Verteilungen an verschiedenen Werten von X",
       caption = "MW¬±2sd",
       x = "Gr√∂√üe",
       y = "Post-Wskt") +
  geom_point(data = ppv_m43_summary,
             aes(x = m,
                 y = 0),
             size = 2, color = "blue", alpha = .5) +
  geom_segment(data = ppv_m43_summary,
               aes(x = m-2*s,
                   xend = m+2*s),
               y = 0,
               yend = 0,
               color = "blue",
               alpha = .5,
               size = 2) 
```



```{r Post-Regression-12, out.width="100%", fig.width=7}
#| echo: false
p1 <- (plot_condition) / post_at_plot
p1
```





### Statistiken zum !Kung-Datensatz

[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv)




```{r Post-Regression-3}
#| echo: true
#| eval: false
Kung_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv"  
d <- read_csv(Kung_path)  

d2 <- d %>% filter(age > 18)

describe_distribution(d2)
```



```{r Post-Regression-4, echo = FALSE, eval = TRUE}
#| echo: false
library(rstatix)

get_summary_stats(d2) %>% 
  gt() %>% 
  fmt_number(columns = 2:13, decimals = 1)
```


Das mittlere K√∂rpergewicht (`weight`) liegt bei ca. 45kg (sd 7 kg).


### Etwas mehr EDA


Das Paket `DataExplorer` hat ein paar nette Hilfen zur explorativen Datenanylse.

Wir brauchen das hier nicht wirklich, aber es ist praktisch:


```{r}
#| message: false
library(DataExplorer)
```

#### Gibt es fehlende Werte?

```{r}
d2 %>% plot_missing()
```

#### Verteilung der numerischen Variablen

```{r}
d2 %>% plot_histogram()
```



#### Verteilung der kategorialen Variablen


```{r}
d2 %>% plot_bar()
```



#### Korrelationen


```{r}
d2 %>% plot_correlation()
```


#### Bonus

Probieren Sie mal diese Funktion aus:

```{r}
#| eval: false
create_report(d2)
```




<!-- ### Selbsgetrickte Visualisierung von `weight` und `height` -->


<!-- ```{r Post-Regression-6} -->
<!-- d2 %>%  -->
<!--   select(weight, height) %>%  -->
<!--   pivot_longer(everything()) %>%  -->
<!--   ggplot(aes(x = value)) + -->
<!--   geom_histogram() + -->
<!--   facet_wrap(~ name, scales = "free") + -->
<!--   geom_vline(data = d2_summary, -->
<!--              aes(xintercept = avg)) + -->
<!--   geom_segment(data = d2_summary, -->
<!--               aes(x = avg-stdev, -->
<!--                   xend = avg+stdev), -->
<!--               y = 0, -->
<!--               yend = 0, -->
<!--               alpha = .7, -->
<!--               color = "blue", -->
<!--               size = 2) + -->
<!--   labs(caption = "Vertikale Linie: Mittelwert\nhorizontale Linie: Standardabweichung") -->
<!-- ``` -->





### Pr√§diktor zentrieren 




- Zieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor "zentrieren").
- Wenn man den Pr√§diktor (`weight`) zentriert hat, ist der Achsenabschnitt, $\alpha$, einfacher zu verstehen.
- In einem Modell mit zentriertem Pr√§diktor (`weight`) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. 
- W√ºrde man `weight` nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit `weight=0` an, was nicht wirklich sinnvoll zu interpretieren ist.



Vgl. @gelman_regression_2021, Kap. 10.4,  12.2.




So kann man das Zentrieren bewerkstelligen:


```{r}
d3 <- 
  d2 %>% 
  center(weight)
```

Oder so, von Hand:

```{r Post-Regression-7, echo = TRUE}
d3 <-
  d2 %>% 
  mutate(weight_c = weight - mean(weight))
```


```{r Post-Regression-8}
#| echo: false
d3 %>% 
  slice_head(n=3) %>% 
  gt() %>% 
  fmt_number(columns = everything(), decimals = 0)
```


Wie man sieht, bleibt die Form der Verteilung gleich, aber sie ist "zur Seite geschoben": Der Mittelwert liegt jetzt eben bei 0.



```{r Post-Regression-9, fig.asp=0.4}
d3 %>% 
  select(weight, weight_c) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~ name, scales = "free")
```



Das schwierigste ist dabei, nicht zu vergessen, dass `d3` die Tabelle mit zentriertem Pr√§diktor ist, nicht `d2`.


## Modell m43: zentrierter Pr√§diktor


Einige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren:
Bei einem (erwachsenen) Menschen mit *Gewicht 0*, was w√§re wohl die K√∂rpergr√∂√üe?
Hm, Philosophie steht heute nicht auf der Tagesordnung.

Da w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht.
Zum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!


:::callout-important
Durch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.
:::





### Modelldefinition von `m43`

- F√ºr jede Auspr√§gung des Pr√§diktors (`weight`), $h_i$, wird eine Post-Verteilung f√ºr die abh√§ngige Variable (`height`) berechnet.
- Der Mittelwert $\mu$ f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel).
- Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel).
- Wir brauchen Priori-Werte f√ºr die Steigung $\beta$ und den Achsenabschnitt $\alpha$ der Regressionsgeraden.
- Au√üerdem brauchen wir einen Priori-Wert, der die Streuung $\sigma$ der Gr√∂√üe (`height`) angibt; dieser Wert wird als exonentialverteilt angenommen.
- Der Likelihood gibt an, wie wahrscheinlich ein Wert `height` ist, gegeben $\mu$ und $\sigma$.


$$
\begin{align*}
\color{red}{\text{height}_i} & \color{red}\sim \color{red}{\operatorname{Normal}(\mu_i, \sigma)} && \color{red}{\text{Likelihood}} \\
\color{green}{\mu_i} & \color{green}= \color{green}{\alpha + \beta\cdot \text{weight}_i}  && \color{green}{\text{Lineares Modell} } \\
\color{blue}\alpha & \color{blue}\sim \color{blue}{\operatorname{Normal}(178, 20)} && \color{blue}{\text{Priori}} \\
\color{blue}\beta  & \color{blue}\sim \color{blue}{\operatorname{Normal}(0, 10)}  && \color{blue}{\text{Priori}}\\
\color{blue}\sigma & \color{blue}\sim \color{blue}{\operatorname{Exp}(0.1)}  && \color{blue}{\text{Priori}}
\end{align*}
$$




### Likelihood, `m43`



$$
\begin{aligned}
\color{red}{\text{height}_i} & \color{red}\sim \color{red}{\operatorname{Normal}(\mu_i, \sigma)} && \color{red}{\text{Likelihood}}
\end{aligned}
$$




- Der Likelihood von `m43` ist √§hnlich zu den vorherigen Modellen (`m41, m42`).
- Nur gibt es jetzt ein kleines "Index-i" am $\mu$ und am $h$ (h wie `heights`).
- Es gibt jetzt nicht mehr nur einen Mittelwert $\mu$, sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert $\mu_i$.
- Lies  etwa so:

>    "Die Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person $i$ zu beobachten, gegeben $\mu$ und $\sigma$ ist normalverteilt (mit Mittelwert $\mu$ und Streuung $\sigma$)".





### Regressionsformel, `m43`


$$
\begin{aligned}
\color{green}{\mu_i} & \color{green}= \color{green}{\alpha + \beta\cdot \text{weight}_i}  && \color{green}{\text{Lineares Modell} } \\
\end{aligned}
$$


- $\mu$ ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. $\mu$ wird jetzt (deterministisch) *berechnet*. Gegeben $\alpha$ und $\beta$ ist $\mu$ ohne Ungewissheit bekannt.
- $\text{weight}_i$ ist der Pr√§diktorwert (`weight`) der $i$ten Beobachtung, also einer !Kung-Person (Zeile $i$ im Datensatz).
- Lies  etwa so:

>    "Der Mittelwert $\mu_i$ der $i$ten Person berechnet sich als Summe von $\alpha$ und $\beta$ mal  $\text{weight}_i$".


- $\mu_i$ ist eine lineare Funktion von `weight`.
- $\beta$ gibt den Unterschied in `height` zweier Beobachtung an, die sich um eine Einheit in `weight` unterscheiden (Steigung der Regressionsgeraden).
- $\alpha$ gibt an, wie gro√ü $\mu$ ist, wenn `weight` Null ist (Achsenabschnitt, engl. intercept).



### Priori-Werte des Modells `m43`



$$
\begin{align*}
\color{blue}\alpha & \color{blue}\sim \color{blue}{\operatorname{Normal}(178, 20)} && \color{blue}{\text{Priori Achsenabschnitt}} \\
\color{blue}\beta  & \color{blue}\sim \color{blue}{\operatorname{Normal}(0, 10)}  && \color{blue}{\text{Priori Regressionsgewicht}}\\
\color{blue}\sigma & \color{blue}\sim \color{blue}{\operatorname{Exp}(0.1)}  && \color{blue}{\text{Priori Sigma}}
\end{align*}
$$

- Parameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.
- $\alpha$ wurde in `m41` als $\mu$ bezeichnet, da wir dort eine "Regression ohne Pr√§diktoren" berechnet haben.
- $\sigma$ ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel.
- Da `height` nicht zentriert ist, der Mittelwert von $\alpha$ bei 178 und nicht 0.
- $\beta$ fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist.


## Vertiefung: Prior-Pr√§diktiv-Verteilung

üèéÔ∏è VERTIEFUNG üèéÔ∏è

### Moment

   - ü§î Moment. Dieser Prior, $\beta$ in `m43` erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!
   - Sind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Gr√∂√üe positiv oder negativ ist? [Nein, sind wir nicht.](https://media.giphy.com/media/daPCSjwus6UR2JxRX1/giphy.gif) 
    


### Priori-Pr√§diktiv-Verteilung f√ºr `m43`



- Was denkt [wir](https://media.giphy.com/media/Aausss8uUBIe3bZ3d2/giphy.gif) bzw. unser Golem *apriori* √ºber den Zusammenhang von Gr√∂√üe und Gewicht?
- Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also f√ºr $\alpha$, $\beta$ und $\sigma$.

.pull-left[

```{r m43-prior-pred}
m43_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),
             prior_intercept = normal(178, 20),  # mu
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # Schalter f√ºr Prior-Pred-Verteilung
             data = d2)


m43_prior_pred_draws <- 
  m43_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```



```{r}
m43_prior_pred_draws %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```



Jede Zeile definiert eine Regressionsgerade.



### Prior-Pr√§diktiv-Simulation f√ºr `m43` mit `stan_glm()` 




```{r echo = TRUE, eval = FALSE}
m43_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),  # beta
             prior_intercept = normal(178, 20),  # alpha
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # DIESER Schalter macht's
             data = d2)

m43_prior_pred_draws <- 
  m43_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```



```{r echo = FALSE, eval = FALSE}
m43a_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),  # beta
             prior_intercept = normal(0, 20),  # alpha
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # DIESER Schalter machts
             data = d2)

m43a_prior_pred_draws <- 
  m43a_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```









### Visualisieren der Prior-Pr√§diktiv-Verteilung



```{r prior-pv1, echo = TRUE, eval = FALSE, fig.asp = .5}
d2 %>% ggplot() +
  geom_point(aes(x = weight_c, y = height)) + 
  geom_abline(data = m43_prior_pred_draws,
aes(intercept = a, slope = b), color = "skyblue", size = 0.2) +
  scale_y_continuous(limits = c(0, 500)) +
  geom_hline(yintercept = 272, size = .5) +
  geom_hline(yintercept = 0, linetype = "dashed")
```



ü§Ø Einige dieser Regressionsgeraden sind unsinnig!


```{r ref.label = "prior-pv1", eval = TRUE, fig.asp = .3}

```


Die durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.





### Ein positiver Wert f√ºr $\beta$ ist plausibler


#### Oh no

Eine Normalverteilung mit viel Streuung:

```{r Post-Regression-16, fig.asp = .5}
#| echo: false
d <-
  tibble(
    x = seq(-30,30,.1),
    y = dnorm(x, mean = 0, sd = 10)
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  scale_y_continuous(breaks = NULL) +
  labs(title = "mu=0, s=10")
```

üëé $\beta=-20$ w√§re mit diesem Prior gut m√∂glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.




#### Oh yes

Wir br√§uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):

```{r Post-Regression-17, fig.asp=.5}
#| echo: false
d <-
  tibble(
    x = seq(-30,30,.1),
    y = dnorm(x, mean = 3, sd = 2)
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  scale_y_continuous(breaks = NULL) +
  labs(title = "mu=5, sd = 3")
```

üëç Vermutlich besser: Ein Gro√üteil der Wahrscheinlichkeitsmasse ist $X>0$. Allerdings gibt's keine Gew√§hr, dass unser Prior "richtig" ist.




### Priori-Pr√§diktiv-Simulation, 2. Versuch





```{r echo = TRUE}
m43a_prior_pred <-
    stan_glm(
      height ~ weight_c, 
      prior = normal(2, 2),  # Regressionsgewicht
      prior_intercept = normal(178, 20),  # mu
      prior_aux = exponential(0.1),  # sigma
      refresh = FALSE, 
      # Schalter f√ºr Prior-Pred-Verteilung:
      prior_PD = TRUE, 
      data = d2)


m43a_prior_pred_draws <- 
  m43a_prior_pred %>% 
  as_tibble() %>% 
  # Spaltennamen k√ºrzen: 
  rename(a = `(Intercept)`) %>%  
  rename(b = weight_c,
         s = sigma)
```





```{r}
#| echo: false
m43a_prior_pred_draws %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```



Das Argument `prior_PD = TRUE` sorgt daf√ºr, dass keine Posteriori-Verteilung, sondern eine Prior-Pr√§diktiv-Verteilung berechnet wird.




### Visualisieren der Prior-Pr√§diktiv-Verteilung, `m43a`


Unsere Priori-Werte scheinen einigerma√üen vern√ºnftige Vorhersagen zu t√§tigen. Allerdings erwartet unser Golem einige Riesen.


```{r, eval = TRUE, fig.asp=.5}
d2 %>% 
  ggplot(aes(x = weight_c, y = height)) +
  geom_point() +
  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},
              aes(slope = b,
                  intercept = a),
              color = "skyblue",
              size = .2,
              alpha = .7) +
  geom_hline(yintercept = 272, size = .5) +
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_y_continuous(limits = c(0, 500)) 
```


Die durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.








### Moment, kann hier jeder machen, was er will?



Es doch den einen, richtigen, objektiven Priori-Wert geben?!

Kann denn jeder hier machen, was er will?! Wo kommen wir da hin?!


>    This is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.  

@mcelreath_statistical_2020, p. 96.





### Hier ist unser Modell, `m43a`




$$
\begin{align}
\text{height}_i &\sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot  \text{weight}_i\\
\alpha &\sim \operatorname{Normal}(178, 20)\\
\beta &\sim \operatorname{Normal}(5,3)\\
\sigma &\sim \operatorname{Exp}(0.1)
\end{align}
$$



```{r Post-Regression-25, echo = TRUE}
# Zufallszahlen festlegen:
set.seed(42)  
# Posteriori-Vert. berechnen:
m43a <-
  stan_glm(
    height ~ weight_c,  # Regressionsformel
    prior = normal(5, 3),  # Regressionsgewicht (beta 1)
    prior_intercept = normal(178, 20),  # mu
    prior_aux = exponential(0.1),  # sigma
    refresh = 0,  # zeig mir keine Details
    data = d2)
```





### Eine Zusammenfassung der Posteriori-Verteilung f√ºr `m43a`


```{r}
m43a %>% 
  parameters()
```


Unser Modell `m43a` sch√§tzt die typische K√∂rpergr√∂√üe einer !Kung-Person *mittleren Gewichts* (`weight_c = 0`) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher.
Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise;
auch hier ist sich das Modell ziemlich sicher, da dass zugeh√∂rige 95%-CI keine 20 Zentimenter umfasst.













## Die Post-Verteilung befragen


### m43a


Sagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt:



```{r m43a, echo = TRUE}
# Zufallszahlen festlegen:
set.seed(42)  
# Posteriori-Vert. berechnen:
m43a <-
  stan_glm(
    height ~ weight_c,  # Regressionsformel
    prior = normal(5, 3),  # Regressionsgewicht (beta 1)
    prior_intercept = normal(178, 20),  # mu
    prior_aux = exponential(0.1),  # sigma
    refresh = 0,  # zeig mir keine Details
    data = d2)
```


Wir nennen es `m43a`^[Wer ist hier f√ºr die Namensgebung zust√§ndig?].


### Mittelwerte von $\alpha$ und $\beta$ aus der Post-Verteilung



Die ersten paar Zeilen:

```{r Post-Regression-befragen-3}
#| echo: false
m43a %>%  
  as_tibble() %>% 
  mutate(id = 1:nrow(.), .before = 1) %>% 
  head(n=3) %>% 
  gt() %>% 
  fmt_number(columns = 2:4, decimals = 1)
```



```{r Post-Regression-befragen-4, echo = TRUE}
#| echo: true
#| results: hide
#| message: false
parameters(m43a)
```


```{r Post-Regression-befragen-5}
#| echo: false
parameters(m43a) %>% 
  display()
```





### Visualisieren der "mittleren" Regressiongeraden



Zur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern,
hier $\beta_0$, $\beta_1$ und $\sigma$:



```{r}
m43a %>% 
  as_tibble() %>% 
  head()
```

Wir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die "mittlere" Regressionsgerade zu betrachten:


```{r Post-Regression-befragen-6, echo = TRUE, eval = FALSE}
#| echo: true
#| eval: true
d2 %>% 
  ggplot() +
  aes(x = weight_c, y = height) +
  geom_point() +
  geom_abline(
    slope = 0.9,  # Median beta 1
    intercept = 154,  # Median beta 0
    color = "blue")
```






### Zentrale Statistiken zu den Parametern

In diesem Modell gibt es drei Parameter: $\mu, \beta, \sigma$.

Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.


#### Lagema√üe zu den Parametern

- Was ist die mittlere Gr√∂√üe einer !Kung-Person? ($\beta_0$)
- Was ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? ($\beta_1$)
- Was ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? ($\sigma$)
- Was ist der wahrscheinlichste Wert f√ºr z.B: $\beta_1$?

```{r Post-Regression-befragen-7, echo = TRUE}
m43a %>% 
  parameters()
```


Wandelt man das Ausgabe-Objekt der Bayes-Regression mit `as_tibble()` in eine Tabelle um,
so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:


```{r}
m43a_post <- 
  m43a %>% 
  as_tibble()

m43a_post %>% 
  head()
```


Wie wir gesehen haben, nutzen wir diese Tabeller der Post-Verteilung immer wieder.
Speichern wir uns sie also als ein Objekt ab, `m43_post`.



![Typischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR](https://easystats.github.io/bayestestR/reference/figures/bayesianMaster.jpg)

[Quelle](https://easystats.github.io/bayestestR/articles/bayestestR.html)


Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob:



```{r}
m43a_post %>% 
  ggplot(aes(x = weight_c)) +
  geom_density(fill = "orange")
```


Das Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen.
Zur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an.

Der Modus wird hier auch *Maximum a Posteriori* (MAP) genannt, daher:


```{r map-estimate-m43a}
#| eval: false
m43a_post %>% 
  summarise(map_b1 = map_estimate(weight_c))
```





Hier ist die Verteilung von $\sigma$ visualisiert:


```{r}
m43a_post %>% 
  ggplot(aes(x = sigma)) +
  geom_density(fill = "orange")
```


Alternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen,
gleich mit Intervallgrenzen, z.B. 95%.

```{r}
m43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)

plot(m43a_hdi)
```

Erg√§nzt man bei `plot()` noch `show_intercept = TRUE` wird auch der Achsenabschnitt angezeigt.




### Streuungsma√üe zu den Parametern


- Wie unsicher sind wir uns in den Sch√§tzungen der Parameter?



Diese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.


:::callout-note
An einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls 
auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.
:::


### Ungewissheit von $\alpha$ und $\beta$ aus der Post-Verteilung visualisiert



Die ersten 10 Stichproben
```{r Post-Regression-befragen-10, echo = TRUE}
d2 %>% 
  ggplot(aes(x = weight_c, 
             y = height)) +
  geom_point() +
  geom_abline(
    data = m43a_post %>% 
      slice_head(n = 10),
    aes(slope = weight_c,
        intercept = `(Intercept)`),
    alpha = .3)
```


Die ersten 100 Stichproben
```{r Post-Regression-befragen-11-ersten-1000, echo = TRUE}
d2 %>% 
  ggplot(aes(x = weight_c, 
             y = height)) +
  geom_point() +
  geom_abline(
    data = m43a_post %>% 
      slice_head(n = 100),
     aes(slope = weight_c,
        intercept = `(Intercept)`),
    alpha = .1)
```


Die ersten `1e3` Stichproben
```{r Post-Regression-befragen-11-die-ersten-1000, echo = TRUE}
d2 %>% 
  ggplot(aes(x = weight_c, 
             y = height)) +
  geom_point() +
  geom_abline(
    data = m43a_post %>% 
      slice_head(n = 1e3),
     aes(slope = weight_c,
        intercept = `(Intercept)`),
    alpha = .01)
```


Die ersten 1000000 ... okay, lassen wir es gut sein^[Im Standard beschert uns `stan_glm()` 4000 Stichproben.].


### Fragen zu Quantilen des Achsenabschnitts 

:::callout-note
Zur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe.
:::

- Welche mittlere Gr√∂√üe mit zu 50%, 90% Wskt. nicht √ºberschritten?
- Welche mittlere Gr√∂√üe mit zu 95% Wskt. nicht unterschritten?
- Von wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?



Quantile:

```{r quantile-post}
m43a_post %>% 
  summarise(
    q_50 = quantile(`(Intercept)`, prob = .5),
    q_90 = quantile(`(Intercept)`, prob = .9),
    q_05 = quantile(`(Intercept)`, prob = .05))
```

50%-PI:

```{r}
m43a_post %>% 
  summarise(pi_50 = quantile(`(Intercept)`, prob = c(.25, .75)))
```



### Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts 



Wie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?


```{r echo = TRUE}
m43a_post %>% 
  count(gross = `(Intercept)` >= 155) %>% 
  mutate(prop = n / sum(n))
```

```{r}
#| echo: false
wskt_gross <- 
  m43a_post %>% 
  count(gross = `(Intercept)` >= 155) %>% 
  mutate(prop = n / sum(n)) %>% 
  pull(prop) %>% 
  `[`(2) %>% 
  round(2)
```

Die Wahrscheinlichkeit betr√§gt `r wskt_gross`.


- Wie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?


```{r echo = TRUE}
m43a_post %>% 
  count(klein = (`(Intercept)` <= 154.5)) %>% 
  mutate(prop = n / sum(n))
```

```{r}
#| echo: false
wskt_klein <- 
  m43a_post %>% 
  count(klein = `(Intercept)` <= 154.5) %>% 
  mutate(prop = n / sum(n)) %>% 
  pull(prop) %>% 
  `[`(2) %>% 
  round(2)
```


Die Wahrscheinlichkeit betr√§gt `r wskt_klein`.






<!-- ### Ungewissheit von Achsenabschnitt und Steigung  -->

<!-- ... als Histogramme visualisiert -->

<!-- .pull-left[ -->

<!-- ### Achsenabschnitt -->

<!-- ```{r Post-Regression-befragen-13, echo = TRUE, eval = TRUE} -->
<!-- post_m43a %>%  -->
<!--   ggplot(aes(x = a)) + -->
<!--   geom_density() -->
<!-- ``` -->

<!-- ] -->

<!-- .pull-right[ -->

<!-- ### Regressionsgewicht (Steigung) -->

<!-- ```{r Post-Regression-befragen-14, echo = TRUE} -->
<!-- post_m43a %>%  -->
<!--   ggplot(aes(x = b)) + -->
<!--   geom_density() -->
<!-- ``` -->

<!-- ] -->


## Post-Verteilung bedingt auf einen Pr√§diktorwert


### Visualisierung


Was ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?

Angenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt.
Welche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?

Etwas formaler ausgedr√ºckt:

$\mu|\text{weight}=45$


45 kg entspricht genau dem Mittelwert von `weight`. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall `weight_c = 0`.


```{r mu-at-45, echo = TRUE}
mu_at_45 <-
  m43a_post %>% 
  mutate(mu_at_45 = `(Intercept)`)
```


```{r Post-Regression-befragen-15, echo = TRUE, eval = FALSE}
#| eval: false
mu_at_45 %>% 
  ggplot(aes(x = mu_at_45)) +
  geom_density()
```



```{r Post-Regression-befragen-17}
# | echo: false
mu_at_45 %>% 
  ggplot(aes(x = mu_at_45)) +
  geom_density() +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(mu["height | weight = 45"])) +
  scale_x_continuous(limits = c(150, 160))
```


Analog k√∂nnen wir fragen,
wie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.


50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also `weight_c = 5`.



```{r mu-at-50, echo = TRUE}
mu_at_50 <-
  m43a_post %>% 
  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)
```



```{r Post-Regression-befragen-16, echo = TRUE, eval = FALSE}
#| eval: false
mu_at_50 %>% 
  ggplot(aes(x = mu_at_50)) +
  geom_density()
```





```{r Post-Regression-befragen-18}
#| echo: false
mu_at_50 %>% 
  ggplot(aes(x = mu_at_50)) +
  geom_density() +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(mu["height | weight = 50"])) +
  scale_x_continuous(limits = c(150, 160))
```




### Lagema√üe und Streuungen




Was ist das 90% PI f√ºr $\mu|w=50$ ?

```{r Post-Regression-befragen-19, echo = TRUE}
mu_at_50 %>% 
  summarise(pi = quantile(mu_at_50, prob = c(0.05, .95)))
```

Die mittlere Gr√∂√üe - gegeben $w=50$ - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten.



Welche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?

```{r Post-Regression-befragen-20, echo = TRUE}
mu_at_45 %>% 
  summarise(q_95 = quantile(mu_at_45, prob = .95))
```




## Die PPV befragen


üèéÔ∏è VERTIEFUNG üèéÔ∏è








Die Posterior-Pr√§diktiv-Verteilung (PPV) gibt uns die M√∂glichkeit,
nach der Wahrscheinlichkeit *tats√§chlicher* K√∂rpergr√∂√üen zu fragen - 
und nicht nur nach *mittleren* K√∂rpergr√∂√üen anhand der Post-Verteilung.


:::callout-important
Die Post-Verteilung macht nur Aussagen zur mittleren K√∂rpergr√∂√üe,
denn das ist was wir modellieren wollten.
M√∂chten wir Aussagen zur Wahrscheinlichkeit tats√§chlicher Gr√∂√üen treffen,
brauchen wir die PPV.
:::


### Perzentil-Intervalle f√ºr verschiedenen Pr√§diktor-Werte


Wir erstellen uns eine Sequenz an Pr√§diktorwerten, die uns interessieren:

```{r echo = TRUE}
weight_df <- tibble(weight_c = seq(-20,20, by = 5))
```


F√ºr diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:

```{r Post-Regression-befragen-21, echo = TRUE}
mus <- 
  predictive_interval(
    m43a, 
    newdata = weight_df) %>% 
  as_tibble() %>% 
  bind_cols(weight_df)
```

Um die Perzentilintervalle zu erstellen, wird von `predictive_interval()` f√ºr jeden Pr√§diktorwert eine Posteriori-Verteilung erstellt und das 5%- sowie 95%-Quantil berechnet. 

Wir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine K√∂rpergr√∂0e von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI).
Hoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben.
Ja, denn die Post-Verteilung hat die Ungewissheit zum *Mittelwert* ausgedr√ºckt;
die PPV gibt die Ungewissheit *tats√§chlicher* beobachtbarer K√∂rpergr√∂√üen aus,
nicht nur die Ungewissheit zum Mittelwert.



Hier ist ein Auszug aus der PPV-Tabelle:




```{r Post-Regression-befragen-23}
#| echo: false
mus %>% 
  head() %>% 
  relocate(weight_c, .before = 1) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```






### Perzentilintervalle f√ºr verschiedenen Pr√§diktorwerte visualisiert



```{r}
mus <- 
  mus %>% 
  mutate(height = 154.6 + 0.9*weight_c)

d2 %>% 
  ggplot(aes(x = weight_c, y = height)) +
  geom_point() +
  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = "blue") +
  geom_errorbar(data = mus,
                aes(ymin = `5%`,
                    ymax = `95%`),
                size = .5,
                width = .5,
                color = "firebrick")
```


Die vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.

Noch eine andere Visualisierung; je dicker die Katzenaugen, desto mehr Samples liegen vor an der Stelle,
und umso genauer ist die Sch√§tzung.


```{r}
#| echo: false
ppv_m43_weight_df <-
  posterior_predict(m43a,
                    newdata = weight_df) %>% 
  as_tibble() %>% 
  pivot_longer(everything(),
               names_to = "weight_condition",
               values_to = "height")

weight_df <-
  weight_df %>% 
  mutate(weight_condition = as.character(c(1:9)))

ppv_m43_weight_df <- 
  ppv_m43_weight_df %>% 
  full_join(weight_df, by = "weight_condition")

d2 %>% 
  ggplot() +
  geom_violin(data = ppv_m43_weight_df,
              aes(x = weight_c, y = height, group = weight_c),
                fill = "grey80",
              width = 1) +
    geom_point(aes(x = weight_c, y = height)) +
  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = "blue")
```


Also: Je dicker die Violine, desto wahrscheinlicher $\mu|{\text{weight_c}_i}$.



### Die PPV visualisiert

Gerade eben haben wir bedingte PPVen angeschaut: Also eine PPV f√ºr einen bestimmten Pr√§diktorwert, z.B. bei einer Person mittleren Gewichts.

Wir k√∂nnen auch den Mittelwert √ºber alle bedingten PPV anschauen, sozusagen die "Master-PPV" oder "unbedingte PPV" oder schlicht PPV.


Vergleichen wir die echten Werte f√ºr `height`, $h$, mit den von der PPV simulierten Werten f√ºr `height`, $h_{sim}$.

```{r ppv-plot1, eval = FALSE, echo = TRUE}
library(bayesplot)
h <- d2$height
h_sim <- 
  posterior_predict(m43a, 
                    draws = 50)
ppc_dens_overlay(
  h, h_sim)
```

`?posterior_predict` zeigt Hilfe f√ºr diese Funktion. 
Die Funktion zeigt die Vorhersagen f√ºr die AV laut der Posteriori-Verteilung.



Die zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.





### PPV plotten, von Hand


PPV berechnen (lassen):

```{r Post-Regression-befragen-27, echo = TRUE}
set.seed(42)
ppv_m43a <- posterior_predict(
  m43a,
  newdata = weight_df,
  draws = 100) %>% 
  as_tibble() %>% 
  pivot_longer(
    cols = everything(),
    names_to = "weight_condition",
    values_to = "height")
```

Und plotten:

```{r ppv-regr, echo = TRUE, eval = FALSE, fig.asp = .4}
ppv_m43a %>% 
  ggplot(aes(x = height)) +
  geom_density()
```







### Fragen an die PPV

- Wie gro√ü sind die !Kung im Schnitt?
- Welche Gr√∂√üe wird von 90% der Personen nicht √ºberschritten?
- Wie gro√ü sind die 10% kleinsten?

```{r Post-Regression-befragen-29, echo = TRUE }
ppv_m43a %>% 
  summarise(
    q_10 = quantile(height, prob = .1),
    height_mean = mean(height),
    q_50 = quantile(height, prob = .5),
    q_90 = quantile(height, prob = .9)
  )
```


Was ist der 50% Bereich der K√∂rpergr√∂√üe?

```{r Post-Regression-befragen-30, echo = TRUE}
ppv_m43a %>% 
  summarise(pi_50 = quantile(height,prob = c(.25, .75)))
```


