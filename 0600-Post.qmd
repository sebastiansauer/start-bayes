
# Die Post befragen



![Bayes:Start!](img/Golem_hex.png){width=5%}




## Lernsteuerung

### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.



### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...


- die Post-Verteilung anhand einer Stichprobenverteilung auslesen
- Fragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten
- Fragen nach Quantilen anhand der Stichprobenverteilung beantworten


### Begleitliteratur

Der Stoff dieses Kapitels orientiert sich an @mcelreath2020, Kap. 3.1 und 3.2.



### Vorbereitung im Eigenstudium

- [Statistik1, Kap. "Daten umformen"](https://statistik1.netlify.app/030-aufbereiten)
- [Statistik1, Kap. "Daten zusammenfassen"](https://statistik1.netlify.app/050-zusammenfassen)



### Ben√∂tigte R-Pakete



```{r libs-hidden307}
#| include: false

library(tidyverse)
library(easystats)
library(gt)
library(ggpubr)
library(plotly)

theme_set(theme_modern())
```



```{r}
#| eval: false
library(tidyverse)
library(easystats)
library(ggpubr)  # optional
```


### Begleitvideos

- [Playlist QM2](https://www.youtube.com/watch?v=QNMVi6IqQ90&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN)


<!-- - []() -->





## Zur Erinnerung: Gitterwerte in R berechnen

Berechnen wir mit der Gittermethode ("Bayes-Box") die Postverteilung f√ºr den Globusversuch.

Die Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele n√ºtzliche Informationen.

Modell: $W=6$ Wasser, $N=9$ W√ºrfen, bei Apriori-Indifferenz gegen√ºber den Parameterwerten. Und sagen wir $k=11$ Gitterwerten^[Die Anzahl der Gitterwerte ist nicht Teil des Modells, streng genommen; die Anzahl der Gitterwerte entscheiden nur √ºber die Genauigkeit der Post-Verteilung.],
also mit 10 Wasseranteilswerten zwischen 0 und 1. 


:::{#exr-globe69}
### Welcher Paramterwert hat die h√∂chste Posteriori-Wahrscheinlichkeit?

::: {.callout-tip appearance="minimal" collapse="true"}

### L√∂sung

Aufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die h√∂chste Wahrscheinlichkeit (d.h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. @lst-bayes1. $\square$
:::
:::



```{r QM2-Thema2-kleineModelle-28}
#| lst-cap: Bayes-Box mit 6 Wasser bei 9 Versuchen
#| lst-label: lst-bayes1
n_success <- 6          
n_trials  <- 9
p_grid <- seq(from = 0, to = 1, by = .1)                # <1>
L <- dbinom(n_success, size = n_trials, prob = p_grid)  # <2>

d <-                                                    # <3>
  tibble(p_grid = p_grid,prior  = 1) %>% 
  mutate(likelihood = L) %>% 
  mutate(unstand_post = (likelihood * prior),
         post = unstand_post / sum(unstand_post))
```
1. *Seq*uenz von 0 bis 1 mit Schritten der Gr√∂√üe  0.1.
2. *L*ikelihood mit 6 Treffern bei 9 W√ºrfen und das Ganze jeweils f√ºr alle 11 Parameterwerte
3. Dann packen wir alles in eine Tabelle.

::::: {.columns}

:::: {.column width="50%"}


```{r}
#| eval: false
library(ggpubr)
ggline(d, x = "p_grid", y = "post") 
```

::: {.content-visible when-format="html"}
Abb. @fig-post1 zeigt die resultierende Bayes-Box; 
vor allem ist die Post-Verteilung wichtig.

```{r plot-post-d}
#| echo: false
#| label: fig-post1
#| fig-cap: Die Postverteilung f√ºr W=6, N=9, k=10


p_d <-
d %>% 
  ggplot() +
  aes(x = p_grid, y = post) +
  geom_point(alpha = .5, size = 3) +
  geom_line() +
  scale_y_continuous("Posterior-Wahrscheinlichkeit", 
                     breaks = NULL) +
  theme_minimal()  +
  annotate("point", x = .7, 
           y = .2668, 
           color = "red", 
           alpha = .7,
           size = 5) 

  
ggplotly(p_d)
```

:::

::: {.content-visible unless-format="html"}
Abb. @fig-post1a zeigt die resultierende Bayes-Box; vor allem ist die Post-Verteilung wichtig.
```{r plot-post-d}
#| echo: false
#| label: fig-post1a
#| fig-cap: Die Postverteilung f√ºr W=6, N=9, k=10
#

p_d <-
d %>% 
  ggplot() +
  aes(x = p_grid, y = post) +
  geom_point(alpha = .5, size = 3) +
  geom_line() +
  scale_y_continuous("Posterior-Wahrscheinlichkeit", 
                     breaks = NULL) +
  theme_minimal()  
```

:::
::::

:::: {.column width="50%"}



Voil√†, die Post-Verteilung als Tabelle, auch "Bayes-Box" (oder Bayes-Gitter) genannt: s. @tbl-post1.


```{r QM2-Thema3-Teil1-1}
#| echo: false
#| tbl-cap: Postverteilung mit der Gittermethode berechnet
#| label: tbl-post1
d %>% 
  mutate_all(round, 2) %>% 
  gt::gt()
```


::::

:::::


### Bayes-Box automatisiert

√úbrigens kann man die Berechnung der Bayes-Box auch automatisieren, s. @tbl-bayes-fun und @lst-bayesfun, z.B. so:^[Alternativ kann man auf die Funktion √ºber das [R-Paket {prada}](https://github.com/sebastiansauer/prada) zugreifen.]


Entweder so:

```{r}
#| eval: false
source("https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R") 
bayesbox(hyps = p_grid, priors = 1, liks = L)
```

Mit `source` importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code f√ºr die Funktion `bayesbox`.

Oder Sie starten das R-Paket, wo die Funktion wohnt:

```{r}
#| label: tbl-bayes-fun
#| tbl-cap: "Eine Bayes-Box 'automatisiert' erstellt, mit Hilfe der Funktion `bayesbox`"
#| lst-label: lst-bayesfun
#| lst-cap: Funktion `bayesbox`, auch im Paket `prada` erh√§ltlich

library(prada)  # <1>
bayesbox(hyps = p_grid, priors = 1, liks = L)  # <3>
```
1. Das Paket `prada` steht nicht im Standard-R-App-Store ("CRAN"), sondern auf Github. Sie k√∂nnnen es so installieren: `devtools::install_github("sebastiansauer/prada")`.
2. Die Funktion verh√§lt sich wie eine gew√∂hnliche Bayes-Box: Bei `hyps` schreibt man die Hypothesen (bzw. Parameterwerte) auf. Bei `priors` die Priori-Werte und bei `liks` die Likelihoods der jeweiligen Hypothesn.





<!-- ```{r QM2-Thema3-Post-befragen-2} -->
<!-- #| echo: false -->
<!-- #| eval: false -->
<!-- d %>%  -->
<!--   head() %>%  -->
<!--   gt::gt() %>%  -->
<!--   #fmt_number(columns = 3, decimals = 3) %>%  -->
<!--   gt::fmt_scientific(columns = c(1,3, 4,5), -->
<!--              decimals = 0) %>%  -->
<!--   gt::tab_header(gt::md("Tabelle *d* mit Daten zur Posteriori-Verteilung")) -->

<!-- ``` -->


Viele n√ºtzliche Fragen (und Antworten) leiten sich ab aus Abb. @fig-post1.


:::{#exm-post}
### Beispiele f√ºr Fragen an die Post-Verteilung

- Mit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?
- Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?
- Mit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?
- Welcher Parameterwert hat die h√∂chste Wahrscheinlichkeit?
- Wie ungewiss ist das Modell √ºber die Parameterwerte?

etc. $\square$
:::

Solche Fragen kann man in zwei Gruppen aufteilen:

1. Fragen zu Parametern
3. Fragen zu Wahrscheinlichkeiten


### Bayes-Box f√ºr komplexe Modelle

Bisher, f√ºr einfache Fragestellungen hat unsere Bayes-Box, das hei√üt die Gittermethode bestens funktioniert: einfach, robust, formsch√∂n^[naja, nicht unbedingt formsch√∂n, aber mir fiel kein dritter Vorzug ein.].
Allerdings: Funktioniert sie auch bei komplexeren Modellen?
Schlie√ülich wollen wir ja auch irgendwann Regressionsmodelle berechnen.
Angenommen, wir haben ein Regressionsmodell mit 1 Pr√§diktor,
dann haben wir folgende drei Gr√∂√üen^[Modellparameter genannt] zu sch√§tzen: $\beta_0, \beta_1, \sigma$.
H√∂rt sich gar nicht so viel an. 
Aber Moment, wir m√ºssten dann z.B. die Frage beantworten, 
wie wahrscheinlich die Daten aposteriori sind,
wenn z.B. $\beta_0 = -3.14$ und $\beta_1 = 2.71$ und $\sigma = 0.70$.
Demnach m√ºssen wir alle Auspr√§gungen ("Gitterwerte") der Variablen multiplizieren.
Puh, das wird eine gro√üe Zahl. 
Wenn wir f√ºr die drei Gr√∂√üen jeweils 10 Auspr√§gungen annehmen, was wenig ist,
k√§men wir $10\cdot10\cdot10= 1000=10^3$ Kombinationen.
Bei 100 Auspr√§gungen w√§ren es schon $100^3=10^6$ Kombinationen.
Das w√§re doch eine recht lange Tabelle.^[Vorsicht beim Ausdrucken.]

Bei einer multiplen Regression mit sagen wir 10 Pr√§diktoren mit jeweils 100 Auspr√§gungen rechnet das arme R bis zum j√ºngsten Tag: $10^{100}$.

>    ü§ñ Bitte tue mir das nicht an!

>    üë®‚Äçüè´ Schon gut, das k√∂nnen wir R nicht zumuten. Wir brauchen eine andere L√∂sung!




## Mit Stichproben die Post-Verteilung zusammenfassen

### Wir arbeiten jetzt mit H√§ufigkeit, nicht mit Wahrscheinlichkeit

Kurz gesagt: Komplexere Bayes-Modelle k√∂nnen nicht mehr "einfach mal eben" ausgerechnet werden; die Mathematik wird zu rechenintensiv.
Gl√ºcklicherwei√üe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.
Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit *H√§ufigkeiten.*
Praktischerweise werden wir in K√ºrze einen R-Golem kennenlernen,
der das f√ºr uns erledigt. 
Dieser Golem liefert uns Stichproben aus der Post-Verteilung zur√ºck.
Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.


:::callout-important
Die Post-Verteilung mit H√§ufigkeiten (d.h. in *Stichprobenform*) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen f√ºr Bayes auf Stichproben eingestellt.
:::

Die Bayes-Box-Methode^[auch Grid-Methode genannt] ist bei gr√∂√üeren Datens√§tzen (oder gr√∂√üeren Modellen) zu unpraktisch.
In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC).
Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses.
Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein.^[Eine gute Einf√ºhrung in die Hintergr√ºnde findet sich bei @mcelreath2020.]


### H√§ufigkeiten sind einfacher als Wahrscheinlichkeiten


Wie gesagt, typische R-Werkzeuge ("R-Golems") liefern uns die Post-Verteilung in Stichprobenform zur√ºck.
Bevor wir uns aber mit diesen R-Werkzeugen besch√§ftigen,
sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.
Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle `d`), s. @lst-post-sample.



```{#lst-post-sample .r lst-cap="Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung"}
samples <-
  d %>%  # nimmt die Tabelle mit Posteriori-Daten,
  slice_sample(  # Ziehe daraus eine Stichprobe,
    n = 1e4,  # mit insgesamt n=10000 Zeilen,
    weight_by = post,  # Gewichte nach Post-Wskt.,
    replace = T)  %>%  # Ziehe mit Zur√ºcklegen
  select(p_grid)
```



```{r lst-post-sample2}
#| lst-cap: "Wir erstellen die 'Stichproben-Bayesbox': eine Tabelle mit Stichproben aus der Post-Verteilung"
#| lst-label: lst-post-sample
#| echo: false
samples <-
  d %>%  # nimmt die Tabelle mit Posteriori-Daten,
  slice_sample(  # Ziehe daraus eine Stichprobe,
    n = 1e4,  # mit insgesamt n=10000 Zeilen,
    weight_by = post,  # Gewichte nach Post-Wskt.,
    replace = T)  %>%  # Ziehe mit Zur√ºcklegen
  select(p_grid)
```



Die Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte `p_grid`) aus Tabelle `d` zu ziehen, 
ist proportional zur Posteriori-Wahrscheinlichkeit (`post`) dieses Werts. 
Ziehen mit Zur√ºcklegen h√§lt die Wahrscheinlichkeiten w√§hrend des Ziehens konstant.
Das Argument `weight_by` legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird.
Wir begn√ºgen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), `p_grid`, 
die anderen Spalten brauchen wir nicht.
Das Ergebnis, Tabelle `samples`, die aus Stichproben aus der Post-Verteilung besteht, ist (in Ausz√ºgen) in @tbl-postsample1 dargestellt.


Wenn Sie jetzt denken: "Warum machen wir das jetzt? Brauchen wir doch gar nicht!" - Dann haben Sie Recht.
K√ºnftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.



:::: {.columns}

::: {.column width="50%"}
@tbl-postsample1 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.
```{r QM2-Thema3-Post-befragen-4}
#| echo: false
#| label: tbl-postsample1
#| tbl-cap: Stichproben-Post-Verteilung
samples %>% 
  slice_head(n = 5) %>% 
  gt() %>% 
  fmt_number(columns = c(1),
             decimals = 3) 
```
:::

::: {.column width="50%"}


Hier erstmal die ersten 100 gesampelten Gitterwerte (`p_grid`):

```{r QM2-Thema3-Teil1-2}
#| echo: false
samples$p_grid[1:100] %>% round(2)
```
:::

::::








So sieht unsere "Stichproben-Bayesbox" als Balkendiagramm aus, s.  @fig-samples1.

::: {.panel-tabset}
### Syntax
```{r QM2-Thema3-Teil1-3}
#| eval: false
#| message: false
#| fig-asp: 0.4
samples |> 
  count(p_grid) |> 
  ggbarplot(x = "p_grid", y = "n") 
```



### Output
```{r QM2-Thema3-Teil1-3}
#| echo: false
#| message: false
#| fig-cap: Stichprobenverteilung auf Basis von Stichproben
#| label: fig-samples1

samples |> 
  count(p_grid) |> 
  ggbarplot(x = "p_grid", y = "n") 
```
:::


Aus @fig-samples1 k√∂nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind.
So sehen wir, dass das Modell Parameterwerte (Wasseranteil, $\pi$) zwischen ca. 50% und 70% f√ºr am wahrscheinlichsten h√§lt.
Aber auch kleine Anteile wie 25% sind nicht auszuschlie√üen (auf Basis der Daten und der Modellannahmen).

Vergleichen Sie  @fig-samples1 mit @fig-gitter: beide sind sehr √§hnlich!
Das Stichprobenziehen (@fig-samples1) n√§hert sich recht gut an die exakte Berechnung an (@fig-gitter).





### Visualisierung der Stichprobendaten mit $k=100$ Gitterwerten

$k=10$ Gitterwerte ist ein grobes Raster.
Drehen wir mal die Aufl√∂sung auf $k=100$ Gitterwerte (Auspr√§gungen) nach oben.




```{r QM2-Thema2-kleineModelle-28a}
#| echo: true
k <- 100   # <1>
n_success <- 6  # <2>
n_trials  <- 9  # <3>

d_k100 <-
  tibble(p_grid = seq(from = 0, 
                      to = 1, 
                      length.out = k),  # <4>
         prior  = 1) %>%   # <5>
  mutate(likelihood = dbinom(n_success,   # <6>
                             size = n_trials, 
                             prob = p_grid)) %>% 
  mutate(unstand_post = (likelihood * prior),  # <7>
         post = unstand_post / sum(unstand_post))
```
1. $k=100$ Gitterwerte
2. 6 Treffer (Wasser)
3. 9 Versuche
4. Bayes-Box anlegen mit 100 Zeilen, d.h. 100 Parameterwerten
5. Apriori indifferent: Alle Hypothesen haben die gleiche Apriori-Plausibilit√§t
6. Die Likelihood ist binomialverteilt.
7. Post-Verteilung berechnen wie gewohnt.




$d_k100$ ist eine Bayes-Box mit $W=6, N=9, k=100$.

Und daraus ziehen wir uns $n=1000$ Stichproben:


```{r QM2-Thema3-Teil1-4}
samples_k100 <-
  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,
  slice_sample(  # Ziehe daraus eine Stichprobe,
    n = 1000,  # mit insgesamt n=1000 Elementen,
    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,
    replace = T)  # Ziehe mit Zur√ºcklegen
```


@fig-post100 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. 
Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt.
Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt.
In allen F√§llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der "typische" Wert des Modells zu sein.
Au√üerdem erkennt man, dass das Modell durchaus einige Streuung in der Sch√§tzung des Wasseranteils bereith√§lt.
Das Modell ist sich nicht sehr sicher, k√∂nnte man sagen.


```{r samplesplot}
#| echo: false
#| fig-cap: Post-Verteilung mit 100 Gitterwerten, exakt vs. auf Basis von Stichproben
#| label: fig-post100
#| out-width: 90%


p0 <- 
  d_k100 %>% 
  ggplot(aes(x = p_grid, y= post)) +
  geom_line() +
  geom_point() +
  labs(title = "Post-Verteilung \nexakt") +
  theme_minimal()

p1 <-
  samples_k100 %>% 
  mutate(sample_number = 1:n()) %>% 
  ggplot(aes(x = sample_number, y = p_grid)) +
  geom_point(alpha = 1/10) +
  scale_y_continuous("Anteil Wasser  (p)", 
                     limits = c(0, 1)) +
  labs(x = "Nummer der Stichprobe",
       title = "Stichproben \naus der Post")  +
  theme_minimal()

p2 <-
samples_k100 %>% 
  ggplot(aes(x = p_grid)) +
  geom_density(fill = "black") +
  scale_x_continuous("Anteil Wasser (p)", 
                     limits = c(0, 1)) +
  labs(y = "Wahrscheinlichkeitsdichte",
       title = "Stichproben \naus der Post") +
  theme_minimal()


plots(p0, p1, p2)
```

Die Stichprobendaten n√§hern sich der "echten" Posteriori-Verteilung an:
Die Stichproben-Post-Verteilung hat jetzt "glattere" R√§nder.


::: callout-note
Mehr Stichproben und mehr Gitterwerte gl√§tten die Verteilung.
:::

Jetzt die Post-Verteilung noch mal mit mehr Stichproben: $n=10^6$ Stichproben bei $k=100$ Gitterwerten aus der Posteriori-Verteilung, s. @fig-post-dk100.

```{r QM2-Thema3-Post-befragen-5}
#| echo: false
#| label: fig-post-dk100
#| fig-cap: "Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): sch√∂n 'glatt'. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist."


d_k100_samples <- 
  d_k100 %>% 
  slice_sample(n = 1e6, weight_by = post, replace = T) 


mode_df <- bayestestR::map_estimate(d_k100_samples$p_grid) 
mode_rounded <- mode_df$MAP_Estimate %>% round(2)
mavg <- mean(d_k100_samples$p_grid) %>% round(2)
md <- median(d_k100_samples$p_grid) %>% round(2)

p_100_samples <-
  d_k100_samples %>%   
ggplot(aes(x = p_grid)) +
  geom_density(fill = "grey40") +
  scale_x_continuous("Anteil Wasser (p)", limits = c(0, 1)) +
  labs(y = "",
       caption = paste0("Modus: ", mode_rounded, "; MW: ", mavg, "; Md: ", md)) +
  geom_vline(xintercept = c(mode_rounded), color = "#E69F00FF")  +
  geom_vline(xintercept = c(mavg), color = "#56B4E9FF")  +
  geom_vline(xintercept = c(md), color = "#009E73FF")  +
  theme_minimal() +
  annotate("label", x = mode_rounded, y = 0, label = glue::glue("Modus: {mode_rounded}"), fill = "#E69F00FF") +
  annotate("label", x = mavg, y = 1, label = glue::glue("MW: {mavg}"), fill = "#56B4E9FF") +
  annotate("label", x = md, y = 2, label = glue::glue("Median: {md}"), fill = "#009E73FF")

p_100_samples
```


## Die Post-Verteilung befragen



So, jetzt befragen wir die Post-Verteilung.


üì∫ [Die Post-Verteilung auslesen](https://www.youtube.com/watch?v=yjCMgf6VkLs)


:::callout-important
Die Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse.
Wir k√∂nnen viele n√ºtzliche Fragen an sie stellen.
:::

Es gibt zwei Arten von Fragen:

1. nach Wahrscheinlichkeiten (p)
2. nach Parameterwerten (Quantilen, q)


Der Unterschied zwischen beiden Arten von Fragen ist in  @fig-p-vs-q schematisch illustriert.

![Fragen nach p vs. Fragen nach q](img/p-vs-q.png){#fig-p-vs-q width="90%" fig-align="center"}

Im linken Teildiagramm von @fig-p-vs-q fragen wir: "Wie wahrscheinlich ist ein Wasseranteil von h√∂chstens 80%?".
Im rechten Teildiagramm fragen wir: "Welcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht √ºberschritten?".


### Fragen nach Wahrscheinlichkeiten




Sagen wir, dass sei unsere Forschungsfrage: *Wie gro√ü ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?*
Um diese Frage zu beantworten, z√§hlen wir einfach, wie viele Stichproben die Bedingung erf√ºllen,
und summieren die Wahrscheinlichkeiten dieser Stichproben.
Wir z√§hlen (`count`) also die Stichproben, die sich f√ºr einen Wasseranteil (`p_grid`) von weniger als 50% aussprechen.

```{r QM2-Thema3-Post-befragen-7}
#| eval: false
samples %>%
  count(p_grid < .5) 
```

Da wir insgesamt 10000 (1e4) Stichproben gezogen haben, k√∂nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen.
Dieser Anteil ist die Antwort auf die Forschungsfrage: 
Wie Wahrscheinlichkeit (laut Modell) f√ºr einen Wasseranteil kleiner als 50%.


:::{#exm-count}
### Was macht die Funktion `count `? 

Der Befehl `count` macht Folgendes: Er gruppiert die Stichprobe nach dem Pr√ºfkriterium, Wasseranteil h√∂chstens 50%. Dann z√§hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zur√ºck. $\square$
:::

:::: {.columns}

::: {.column width="50%"}
Wir z√§hlen wie oft der Wasseranteil weniger als 50% betr√§gt.


```{r}
samples %>%
  count(p_grid < .5) 
```
:::


::: {.column width="50%"}
Nat√ºrlich gibt es verschiedene Wege, die gleiche Frage zu beantworten.

```{r QM2-Thema3-Post-befragen-6}
d %>%
  filter(p_grid < .5) %>%
  summarise(sum = sum(post))
```

:::

::::






:::{#exm-param2}

### Wasseranteil zwischen 50 und 75%?

Noch eine Forschungsfrage: *Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?*


Wir z√§hlen die Stichproben, die diesen Kriterien entsprechen.

```{r QM2-Thema3-Post-befragen-8}
samples %>% 
  count(p_grid > .5 & p_grid < .75)
```

>    ü§ñ Ich w√ºrde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.

>    üë®‚Äçüè´ Das wollte ich auch gerade sagen...

```{r QM2-Thema3-Post-befragen-8a}
samples %>% 
  count(p_grid > .5 & p_grid < .75) %>% 
  summarise(Anteil = n / 1e4,
            Prozent = 100 * n / 1e4)  # In Prozent
```

Anteile von `count()` k√∂nnte man, wenn man m√∂chte, auch `filter()` verwenden.


```{r}
samples %>% 
  filter(p_grid > .5 & p_grid < .75) %>% 
  summarise(sum     =       n() / 1e4,
            anteil = 100 * n() / 1e4)  # In Prozent
```

Fertig üòÑ  $\square$

:::

:::{#exm-param3}

### Wasseranteil zwischen 90& und 100%?

Noch ein Beispiel f√ºr eine Forschungsfrage: *Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1*? 

::: {.panel-tabset}
### Syntax


```{r QM2-Thema3-Post-befragen-9}
#| eval: false
samples %>% 
  count(p_grid >= .9 & p_grid <= 1) %>% 
  summarise(prop = 100 * n() / 1e4)  # prop wie "proportion", Anteil
```
### Output
```{r QM2-Thema3-Post-befragen-9a}
#| echo: false
samples %>% 
  count(p_grid >= .9 & p_grid <= 1) %>% 
  summarise(prop = 100 * n() / 1e4)  # prop wie "proportion", Anteil
```
:::


Laut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind.  90% betr√§gt.  $\square$


:::


:::{#exr-wasser50}
### Wasseranteil h√∂chstens 50%?

>   üë©‚Äçüî¨ Mit welcher Wahrscheinlichkeit ist der Planet h√∂chstens zur H√§lfte mit Wasser bedeckt?




::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung
```{r}
samples %>% count(p_grid <= .5)
```
:::
:::


Wir k√∂nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist;
dieser Wert entspricht dem "Gipfel" des Berges, s.  @fig-post-dk100.


F√ºr unsere Stichproben-Postverteilung, `samples`, s. @fig-samples1, l√§sst sich der Modus so berechnen:


```{r}
map_estimate(samples$p_grid)  
```


Dabei steht `map` f√ºr [Maximum Aposteriori](https://easystats.github.io/bayestestR/reference/map_estimate.html), also das Maximum der Post-Verteilung.



:::{#exr-mw-med-wasser}
Bei der Gelegenheit k√∂nnten wir folgende, √§hnliche Fragen stellen:

- Was ist der mittlere Sch√§tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?
- Was ist der mediane Sch√§tzwert (Median)?


::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung
```{r}
samples %>% 
  summarise(mean(p_grid),
            median(p_grid))
```
:::
:::



### Fragen nach Parameterwerten

::: callout-important
Sch√§tzbereiche von Parameterwerten nennt man auch *Konfidenz- oder Vertrauensintervall*^[Tats√§chlich gibt es eine Vielzahl an Begriffen, die in der Literatur nicht immer konsistent verwendet werden, etwa Kompatibilit√§tsintervall, Ungewissheitsintervall, Passungsbereich.].
:::



Welcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht √ºberschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit)
Wir m√∂chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist^[Vielleicht damit es genug Berge zum Schifahren gibt.].


```{r QM2-Thema3-Post-befragen-11}
samples %>% 
  summarise(quantil90 = quantile(p_grid, p = .9))
```


Laut unserem Modell k√∂nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.

Es hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu f√ºhren, s. @fig-post-dk100.


<!-- ```{r} -->
<!-- #| label: fig-post99 -->
<!-- #| fig-cap: Die Post-Verteilung im Globusversuch -->
<!-- #| fig-asp: .5 -->
<!-- #| out-width: "50%" -->
<!-- samples %>%  -->
<!--   ggplot(aes(x = p_grid)) + -->
<!--   geom_bar() -->
<!-- ``` -->




Was ist das *mittlere* Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enth√§lt, laut dem Modell?

Daf√ºr "schneiden" wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:

```{r QM2-Thema3-Post-befragen-12, echo = TRUE}
samples %>% 
  summarise(
    quant_05 = quantile(p_grid, 0.05),
    quant_95 = quantile(p_grid, 0.95))

```


Solche Fragen lassen sich also mit Hilfe von *Quantilen* beantworten.




### Zur Erinnerung: Quantile

Beispiel: Wie gro√ü sind die Studentis ([Quelle des Datensatzes](https://rdrr.io/cran/openintro/man/speed_gender_height.html))? 

Das Quantil von z.B. 25% zeigt die K√∂rpergr√∂√üe der 25% kleinsten Studentis an, analog f√ºr 50%, 75%, in Inches bzw. in Zentimetern^[1 Inch entspricht 2.54cm].

```{r QM2-Thema3-Teil1-5}
#| message: false
#| echo: true
# speed_gender_height <- read.csv("https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv")
data("speed_gender_height", package = "openintro")  # <1>

height_summary <- 
  speed_gender_height %>% 
  mutate(height_cm = height*2.54) %>%  # <2>
  select(height_inch = height, height_cm) %>% 
  drop_na() %>%   # <3>
  pivot_longer(everything(), names_to = "Einheit", values_to = "Messwert") %>%   # <4>
  group_by(Einheit) %>%   # <5>
  summarise(q25 = quantile(Messwert, prob = .25),  # <6>
            q50 = quantile(Messwert, prob = .5),
            q75 = quantile(Messwert, prob = .75))

height_summary
```
1. Daten importieren
2. Inch in Zentimeter umrechnen
3. Zeilen mit fehlenden Werten l√∂schen
4. In die Langform pivotieren
5. Gruppieren nach Einheit (Inch, Zentimeter)
6. Quantile berechnen  (Q1, Q2, Q3)


Das 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.


@fig-stud-height visualisiert die Quantile und die H√§ufigkeitsverteilung.

```{r QM2-Thema3-Teil1-6}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Gr√∂√üenverteilung von 1325 amerikanischen Studentis
#| label: fig-stud-height
#| fig-width: 10

speed_gender_height <-
  speed_gender_height |> 
   mutate(height_cm = height*2.54)

p1 <- speed_gender_height %>% 
  ggplot() +
  aes(x = 1, y = height_cm) +
  geom_boxplot() +
  labs(x = "",
       y = "Gr√∂√üe in cm",
       title = "Die Box zeigt das 25%-, 50%- und 75%-Quantil") +
  theme_minimal()

height_summary_long <- 
  speed_gender_height %>% 
  select(height_cm) %>% 
  drop_na() %>% 
  summarise(q25 = quantile(height_cm, prob = .25),
            q50 = quantile(height_cm, prob = .5),
            q75 = quantile(height_cm, prob = .75)) %>% 
  pivot_longer(everything(),
               names_to = "q",
               values_to = "height_cm") 

p2 <- 
  speed_gender_height %>% 
  ggplot() +
  aes(x = height_cm) +
  geom_histogram() +
  geom_vline(data = height_summary_long,
             aes(xintercept = height_cm)) +
  geom_text(data = height_summary_long,
             aes(x = height_cm+1,
                 y = 0,
                 label = paste0(q, ": ", height_cm)),
             angle = 90,
            hjust = 0,
            color = "white"
             ) +
  labs(title = "Die vertikalen Striche zeigen die Quantile",
       y = "H√§ufigkeit")  +
  theme_minimal()

plots(p1, p2)
```





:::{#exr-quant1}
### Welcher Parameterwert ist der wahrscheinlich gr√∂√üte?

√úbersetzen wir "wahrscheinlich" gr√∂√üte in "mit einer Wahrscheinlichkeit von 99% gibt es keinen gr√∂√üeren".


::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r}
samples |> 
  summarise(quant99 = quantile(p_grid, p = .99))
```
Mit einer Wahrscheinlichkeit von 99% ist der h√∂chste zu erwartende Wasseranteil 0.9.
:::
:::

:::{#exr-quant2}
### Welcher Parameterwert ist der wahrscheinlich kleinste?

√úbersetzen wir "wahrscheinlich" kleinste in "mit einer Wahrscheinlichkeit von 99% gibt es keinen kleineren".


::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r}
samples |> 
  summarise(wahrscheinlich_kleinste = 
              quantile(p_grid, p = .01))
```
Mit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 -- immer auf Basis unserer beobachteten Daten und der Vorannahmen.
:::
:::



:::{#exr-quant3}
### Welcher Parameterwert ist der "vermutlich" kleinste?

In der "wirklichen" Welt sind Aussagen nicht immer pr√§zise.
Sagen wir, die Chefin der Weltraumbeh√∂rde hat in einem Presse-Statement von der "vermutlichen Untergrenze" hinsichtlich des Wasseranteils gesprochen.

√úbersetzen wir "vermutlich" kleinste in "mit einer Wahrscheinlichkeit von 90% gibt es keinen kleineren".


::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r}
samples |> 
  summarise(wahrscheinlich_kleinste = 
              quantile(p_grid, p = .1))
```
Mit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 -- immer auf Basis unserer beobachteten Daten und der Vorannahmen.
:::
:::




###  Den Quantilen unter die Motorhaube geschaut

Den R-Befehl `quantile()` kann man sich, wenn man will, einfach nachbauen und entmystifizieren.

Angenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht √ºberschritten wird.
Das k√∂nnen wir mit im Datensatz `samples` so erreichen.

1. Sortiere die Stichproben aufsteigend.
2. Schneide die oberen 10% (von 10000) ab (entferne sie).
3. Schaue, was der gr√∂√üte verbleibende Wert ist.

```{r}
samples %>% 
  arrange(p_grid) %>%   # sortiere
  slice_head(n = 9000) %>%  # nur die ersten 90%
  summarise(p90 = max(p_grid))
```


Das (ann√§hernd) gleiche Ergebnis liefert `quantile()`:

```{r}
samples %>% 
  summarise(q90 = quantile(p_grid, .9))
```


### Visualisierung der Intervalle


::: {#def-eti}

### Perzentilintervall (PI)

Intervalle (Bereiche), die die "abzuschneidende" Wahrscheinlichkeitsmasse h√§lftig auf die beiden R√§nder aufteilen, nennen wir *Perzentilintervalle* oder (synonym) *Equal-Tails-Intervalle* (ETI), s. Abb. @fig-eti, rechtes Teildiagramm.^[Hier auf Basis  der Post-Verteilung `samples`.] $\square$
:::





```{r piplot}
#| echo: false
#| fig-cap: Perzintilintervalle
#| label: fig-eti
#| layout-ncol: 2
#| fig-subcap:
#|   - Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit 
#|   - Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit
q_80 <- quantile(samples$p_grid, prob = .8)
q_10_and_90 <- quantile(samples$p_grid, prob = c(.1, .9))

p1 <-
  d_k100 %>% 
  ggplot(aes(x = p_grid, y = post)) +
  geom_line() +
  labs(title="Untere 80%",
       caption = paste0("q80: ", round(q_80, 2))) +
  geom_area(data = d_k100 %>% 
              filter(p_grid < q_80))   +
  theme_minimal() +
  annotate("label", x = q_80, y = 0, label = q_80)

# lower right panel
p2 <-
  d_k100 %>% 
  ggplot(aes(x = p_grid, y = post)) +
  geom_line() +
  geom_area(data = d_k100 %>% 
              filter(p_grid > q_10_and_90[1] & p_grid < q_10_and_90[2])) +
  labs(title = "Mittlere 80%",
       caption = paste0("q10: ", round(q_10_and_90[1], 2), 
                        "; q90: ",
                        round(q_10_and_90[2]), 2))  +
  theme_minimal() +
  annotate("label", label = round(q_10_and_90[1], 2),
           x = round(q_10_and_90[1], 2), y = 0) +
  annotate("label", label = round(q_10_and_90[2], 2),
           x = round(q_10_and_90[2], 2), y = 0)  

p1
p2
```




```{r}
#| echo: false
d_anim <-
  samples_k100 |> 
  select(p_grid, post) |>
  mutate(decile = cut(post, 
                      breaks = quantile(samples_k100$p_grid, probs = seq(0, 1, 0.1)), 
                      include.lowest = TRUE),
         decile2 = cut(p_grid, 
                      breaks = quantile(samples_k100$p_grid, probs = seq(0, 1, 0.1)), 
                      include.lowest = TRUE, labels = 1:10)) |> 
  group_by(decile2) |> 
  mutate(post_max = max(p_grid))

d_anim2 <-
  d_anim |> 
  ungroup() |> 
  select(p_grid)

p_quantiles  <- 
d_anim |> 
  ggplot(aes(x = p_grid)) +
  geom_density(data = d_anim2) + 
  geom_vline(aes(xintercept = post_max)) +
  geom_label(aes(label = decile2, x = post_max), y = 0)

```


```{r}
#| echo: false
#| eval: false

library(gganimate)
p_quantiles_anim <-
  p_quantiles +
  transition_states(decile2, transition_length = 2, state_length = 1) +
  ggtitle("Dezil: {closest_state}") +
  enter_fade() +
  exit_fade()

anim_save("img/p_quantiles_anim.gif", p_quantiles_anim, renderer = gifski_renderer())
```


::: {.content-visible when-format="html"}

Das 10%, 20%, ... 100%-Quantil^[d.h. die *Dezile*] (auf Basis von `samples_k100`) sind in @fig-quantiles-anim illustriert.


![Quantile in 10%-Schritenn durch die Verteilung von `samples_k100`](img/p_deciles.gif){#fig-quantiles-anim width=50%}
:::

## Schiefe Posteriori-Verteilungen sind m√∂glich


Noch einmal zum Globusversuch: Gehen wir von 3 W√ºrfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlie√üen?

Vermutlich ziemlich hohe.

Erstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 W√ºrfe), s. @lst-d33.

```{r QM2-Thema3-Post-befragen-13}
#| lst-cap: Schiefe Post-Verteilung in einer Bayes-Box
#| lst-label: lst-d33
d_33 <- 
  tibble(p_grid = seq(0,1, by =.01),
         prior = 1) %>% 
  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% 
  mutate(unstand_post = likelihood * prior) %>% 
  mutate(post_33  = unstand_post / sum(unstand_post)) 

samples_33 <- 
  d_33 %>% 
    slice_sample(n = 1e6, 
                 weight_by = post_33, 
                 replace = T)
```

So sehen die ersten paar Zeilen der Post-Verteilung, `samples_33`, aus.

```{r QM2-Thema3-Post-befragen-14}
#| echo: false
samples_33 %>% 
  select(-post_33) %>% 
  head() %>% 
  gt() %>% 
  fmt_number(columns = c(1,3,4), decimals = 2)
```


Mit dieser "schiefen" Post-Verteilung k√∂nnen wir gut die Auswirkungen auf das Perzentil- und das H√∂chste-Dichte-Intervall anschauen.


### Perzentilintervall

Hier z.B. ein 50%-Perzentilintervall, s. Abb. @fig-schief.



```{r QM2-Thema3-Post-befragen-15}
#| echo: false
#| fig-cap: "Schiefe Intervalle: Das PI enth√§lt den wahrscheinlichsten Parameterwert nicht, das HDI schon."
#| label: fig-schief

qi_50_low <- eti(samples_33$p_grid, ci = .5)$CI_low
qi_50_up <- eti(samples_33$p_grid, ci = .5)$CI_high
p1 <-
  d_33 %>% 
  ggplot(aes(x = p_grid, y = post_33)) +
  # check out our sweet `qi()` indexing
  geom_area(data = . %>% 
              filter(p_grid > qi_50_low &  
                    p_grid < qi_50_up),
            fill = "grey75") +
  geom_line() +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = .1)) +
  theme_minimal()




hdi_50_low <- bayestestR::hdi(samples_33$p_grid, 
                                  ci = .5)$CI_low
hdi_50_up <- 1
# hdi_50_up <- bayestestR::hdi(samples_33$p_grid, 
#                                   ci = .5)$CI_high

p2 <-
  d_33 %>% 
  ggplot(aes(x = p_grid, y = post_33)) +
  geom_area(data = . %>% 
              filter(p_grid > hdi_50_low & 
                     p_grid < hdi_50_up),
            fill = "grey75") +
  geom_line()  +
  theme_minimal()


plots(p1, 
      p2,
      n_rows = 1,
      title= c("PI vs HDI"),
      tags = c("PI", "HDI"))
```

Ein *Perzentilintervall* (ETI, PI) kann, wenn es dumm l√§uft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zur√ºckweisen. Das ist nicht so toll.

Ein *Highest-Density-Intervall* (HDI^[Auch als *Highest Hensity Posterior Interval* (HDPI) bezeichnet.]) ist schm√§ler als der Perzintilintervall und enth√§lt immer den wahrscheinlichsten Parameterwert.

:::: {.columns}

::: {.column width="50%"}
Die Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. mit dem Befehl `eti` ausgeben lassen.

```{r}
#| eval: false
samples_33 %>% 
  select(p_grid) %>% 
  eti(ci = .5)  # Paket `easystats`
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
samples_33 %>% 
  select(p_grid) %>% 
  eti(ci = .5)  # Paket `easystats`
```
:::

::::






Der wahrscheinlichste Parameterwert (1) ist *nicht* im Intervall enthalten.
Das ist ein Nachteil der ETI.




### Intervalle h√∂chster Dichte


::: {#def-hdi}

Intervalle h√∂chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das *schm√§lste* Intervall, das den gesuchten Parameter enth√§lt (in Bezug auf ein gegebenes Modell).

:::







Der wahrscheinlichste Parameterwert ($1$) *ist* im Intervall enthalten, was Sinn macht.
Bei einem HDI sind die abgeschnitten R√§nder nicht mehr gleich gro√ü, im Sinne von enthalten nicht (zwangsl√§ufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen R√§ndern hingegen gleich gro√ü.


Je symmetrischer die Verteilung, desto n√§her liegen die Punktsch√§tzer aneinander (und umgekehrt), s. Abb. @fig-post-pointestimates.


```{r pointestimators}
#| echo: false
#| fig-cap: Visualisierung der Punktsch√§tzer bei einer schiefen Post-Verteilung
#| label: fig-post-pointestimates
#| message: false
#| fig-asp: 0.5

point_estimates <-
  bind_rows(samples_33 %>% tidybayes::mean_qi(p_grid),
            samples_33 %>% tidybayes::median_qi(p_grid),
            samples_33 %>% tidybayes::mode_qi(p_grid)) %>% 
  select(p_grid, .point) %>% 
  # these last two columns will help us annotate  
  mutate(x = p_grid + c(-.03, .03, -.03),
         y = c(.005, .012, .02))

d_33 %>% 
  ggplot(aes(x = p_grid)) +
  geom_area(aes(y = post_33),
            fill = "grey75") +
  geom_vline(xintercept = point_estimates$p_grid) +
  geom_text(data = point_estimates,
            aes(x = x, y = y, label = .point),
            angle = 90) +
  labs(x = "Anteil Wasser (p)",
       y = "Wahrscheinlichkeitsdichte") +
  theme(panel.grid = element_blank()) +
  theme_minimal()
```




Mit dem Befehl `hdi` kann man sich die Grenzwerte eines HDI, z.B. eines 50%-HDI, ausgeben lassen, s. @tbl-samples-hdi.


```{r hdi-samples-50}
#| eval: false
samples %>% 
  select(p_grid) %>% 
  hdi(ci = .5)  # aus dem Paket `{easystats}`
```

```{r hdi-samples-51}
#| echo: false
#| label: tbl-samples-hdi
#| tbl-cap: "50%-HDI f√ºr unser Globusmodell"
samples %>% 
  select(p_grid) %>% 
  bayestestR::hdi(ci = .5)  # aus dem Paket `{easystats}`
```



Das Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfl√§che) sich im  von ca. .67 bis .78 befindet (auf Basis eines HDI).


## Fazit


### Intervalle h√∂chster Dichte vs. Perzentilintervalle

- Bei symmetrischer Posteriori-Verteilung sind beide Intervalle √§hnlich
- Perzentilintervalle sind verbreiteter
- *Intervalle h√∂chster Dichte* (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen
- Intervalle h√∂chster Dichte sind die *schmalsten* Intervalle f√ºr eine gegebene Wahrscheinlichkeitsmasse




### Zusammenfassung

Fassen wir zentrale Punkte an einem Beispiel zusammen.

Im Globusversuch, Datensatz `samples`, s. @lst-post-sample. Sagen wir, wir haben 6 Treffer bei 9 W√ºrfen erzielt.




*Lageparameter*: Welchen mittleren Wasseranteil kann man erwarten?

```{r QM2-Thema3-Post-befragen-19}
samples %>% 
  summarise(
    mean   = mean(p_grid),
    median = median(p_grid))  
```

*Streuungsparameter*: Wie unsicher sind wir in der Sch√§tzung des Wasseranteils?

```{r QM2-Thema3-Post-befragen-20}
samples %>% 
  summarise(
    p_sd   = sd(p_grid),
    p_iqr = IQR(p_grid),
    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler
```

Anstelle der Streuungsparameter ist es aber √ºblicher, ein HDI oder PI anzugeben.



:::callout-important
Alles Wasser oder was?
Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. 
Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel f√ºr einen *Parameter*, einer unbekannten Gr√∂√ües eines Modells.
:::





## Aufgaben


### Papier-und-Bleistift-Aufgaben

1. [Wskt-Schluckspecht2](https://datenwerk.netlify.app/posts/wskt-schluckspecht2/)
14. [kekse03](https://datenwerk.netlify.app/posts/kekse03/index.qmd)
14. [bfi10](https://datenwerk.netlify.app/posts/bfi10/)
14. [Kaefer2](https://datenwerk.netlify.app/posts/kaefer2/kaefer2)
3. [mtcars-post2a](https://datenwerk.netlify.app/posts/mtcars-post2a/)
3. [rethink3e1-7-paper](https://datenwerk.netlify.app/posts/rethink3e1-7-paper/)
14. [mtcars-post3a](https://datenwerk.netlify.app/posts/mtcars-post3a/)
14. [mtcars-post3a](https://datenwerk.netlify.app/posts/mtcars-post3a/)
14. [mtcars-post_paper](https://datenwerk.netlify.app/posts/https://datenwerk.netlify.app/posts/mtcars-post_paper/)
1. [fattails1](https://datenwerk.netlify.app/posts/fattails01/fattails01.html)
10. [fattails2](https://datenwerk.netlify.app/posts/fattails02/fattails02.html)
11. [eti-hdi](https://datenwerk.netlify.app/posts/eti-hdi/)

### Aufgaben, bei denen man einen Computer ben√∂tigt

1. [iq01](https://datenwerk.netlify.app/posts/iq01/iq01.html)
2. [iq02](https://datenwerk.netlify.app/posts/iq02/iq02.html)
3. [iq03](https://datenwerk.netlify.app/posts/iq03/iq03.html)
4. [iq04](https://datenwerk.netlify.app/posts/iq04/iq04.html)
5. [iq05](https://datenwerk.netlify.app/posts/iq05/iq05.html)
6. [iq06](https://datenwerk.netlify.app/posts/iq06/iq06.html)
7. [iq07](https://datenwerk.netlify.app/posts/iq07/iq07.html)
8. [iq08](https://datenwerk.netlify.app/posts/iq08/iq08.html)
8. [iq10](https://datenwerk.netlify.app/posts/iq10/iq10.html)
11. [ReThink3e1-7](https://datenwerk.netlify.app/posts/rethink3e1-7/rethink3e1-7)
12. [Weinhaendler](https://datenwerk.netlify.app/posts/weinhaendler/weinhaendler)
13. [Rethink3m1](https://datenwerk.netlify.app/posts/rethink3m1/rethink3m1)
13. [Rethink3m2](https://datenwerk.netlify.app/posts/rethink3m2/rethink3m2)
15. [groesse2](https://datenwerk.netlify.app/posts/groesse02/groesse02)
16. [groesse1](https://datenwerk.netlify.app/posts/groesse01/groesse01)
17. [Anteil-Apple](https://datenwerk.netlify.app/posts/anteil-apple/anteil-apple)
18. [Kung-height](https://datenwerk.netlify.app/posts/kung-height/kung-height)
19. [zwielichter-dozent-bayes](https://datenwerk.netlify.app/posts/zwielichter-dozent-bayes/zwielichter-dozent-bayes)







## ---



![](img/outro-06.jpg){width=100%}


