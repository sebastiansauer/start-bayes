
# Die Post befragen



![Bayes:Start!](img/Golem_hex.png){width=5%}




## Lernsteuerung


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie können ...


- die Post-Verteilung anhand einer Stichprobenverteilung auslesen
- Fragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten
- Fragen nach Quantilen anhand der Stichprobenverteilung beantworten


### Vorbereitung im Eigenstudium

- [Statistik1, Kap. "Daten umformen"](https://statistik1.netlify.app/030-aufbereiten)
- [Statistik1, Kap. "Daten zusammenfassen"](https://statistik1.netlify.app/050-zusammenfassen)



### Benötigte R-Pakete



```{r libs-hidden307}
#| include: false
library(tidyverse)
#library(gt)
#library(patchwork)
library(easystats)
library(gt)

```


```{r}
#| echo: false
theme_set(theme_modern())
```



```{r}
library(tidyverse)
```


<!-- ### Begleitvideos -->


<!-- - []() -->


## Mit Stichproben die Post-Verteilung zusammenfassen


### Zur Erinnerung: Gitterwerte in R berechnen

Berechnen wir mit der Gittermethode ("Bayes-Box") die Postverteilung für den Globusversuch.

Die Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nützliche Informationen.

Modell: $W=6$ Wasser, $N=9$ Würfen und $k=10$ Gitterwerten,
also mit 10 Wasseranteilswerten zwischen 0 und 1. 

Abb. @fig-post1 zeigt die resultierende Post-Verteilung.


```{r QM2-Thema2-kleineModelle-28}
n <- 10
n_success <- 6
n_trials  <- 9

d <-
  tibble(p_grid = seq(from = 0, to = 1, length.out = n),
         prior  = 1) %>% 
  mutate(likelihood = dbinom(n_success, 
                             size = n_trials, 
                             prob = p_grid)) %>% 
  mutate(unstand_post = (likelihood * prior),
         post = unstand_post / sum(unstand_post))
```


Voilà, die Post-Verteilung als Tabelle, auch "Bayes-Box" (oder Bayes-Gitter) genannt: s. @tbl-post1.


```{r QM2-Thema3-Teil1-1}
#| echo: false
#| tbl-cap: Postverteilung mit der Gittermethode berechnet
#| label: tbl-post1
d %>% 
  mutate_all(round, 2) %>% 
  gt::gt()
```



```{r plot-post-d}
#| echo: false
#| label: fig-post1
#| fig-cap: Die Postverteilung für W=6, N=9, k=10
d %>% 
  ggplot() +
  aes(x = p_grid, y = post) +
  geom_point(alpha = .5, size = 3) +
  geom_line() +
  scale_y_continuous("Posterior-Wahrscheinlichkeit", 
                     breaks = NULL)
```

```{r QM2-Thema3-Post-befragen-2}
#| echo: false
#| eval: false
d %>% 
  head() %>% 
  gt::gt() %>% 
  #fmt_number(columns = 3, decimals = 3) %>% 
  gt::fmt_scientific(columns = c(1,3, 4,5),
             decimals = 0) %>% 
  gt::tab_header(gt::md("Tabelle *d* mit Daten zur Posteriori-Verteilung"))

```


Viele nützliche Fragen (und Antworten) leiten sich ab aus Abb. @fig-post1.


### Beispiele für Fragen an die Post-Verteilung

- Mit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?
- Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?
- Mit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?
- Welcher Parameterwert hat die höchste Wahrscheinlichkeit?
- Wie ungewiss ist das Modell über die Parameterwerte?


Solche Fragen kann man in zwei Gruppen aufteilen:

1. Fragen zu Parametern
3. Fragen zu Wahrscheinlichkeiten


### Bayes-Box für komplexe Modelle

Bisher, für einfache Fragestellungen hat unsere Bayes-Box, das heißt die Gittermethode bestens funktioniert: einfach, robust, formschön^[naja, nicht unbedingt formschön, aber mir fiel kein dritter Vorzug ein.].
Allerdings: Funktioniert sie auch bei komplexeren Modellen?
Schließlich wollen wir ja auch irgendwann Regressionsmodelle berechnen.
Angenommen, wir haben ein Regressionsmodell mit 1 Prädiktor,
dann haben wir folgende drei Größen^[Modellparameter genannt] zu schätzen: $\beta_0, \beta_1, \sigma$.
Hört sich gar nicht so viel an. 
Aber Moment, wir müssten dann z.B. die Frage beantworten, 
wie wahrscheinlich die Daten aposteriori sind,
wenn z.B. $\beta_0 = -3.14$ und $\beta_1 = 2.71$ und $\sigma = 0.70$.
Demnach müssen wir alle Ausprägungen ("Gitterwerte") der Variablen multiplizieren.
Puh, das wird eine große Zahl. 
Wenn wir für die drei Größen jeweils 10 Ausprägungen annehmen, was wenig ist,
kämen wir $10\cdot10\cdot10= 1000=10^3$ Kombinationen.
Bei 100 Ausprägungen wären es schon $100^3=10^6$ Kombinationen.
Das wäre doch eine recht lange Tabelle.

Bei einer multiplen Regression mit sagen wir 10 Prädiktoren mit jeweils 100 Ausprägungen rechnet das arme R bis zum jüngsten Tag: $10^{100}.
Nein, das können wir R nicht zumuten.
Wir brauchen eine andere Lösung!


### Wir arbeiten jetzt mit Häufigkeit, nicht mit Wahrscheinlichkeit

Kurz gesagt: Komplexere Bayes-Modelle können nicht mehr "einfach mal eben" ausgerechnet werden; die Mathematik wird so umfangreich bzw. zu komplex.

Glücklicherweiße gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.

Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit *Häufigkeiten.*


Praktischerweise werden wir in Kürze einen R-Golem kennenlernen,
der das für uns erledigt. 
Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurück.

Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.


:::callout-important
Die Post-Verteilung in Stichprobenform ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen für Bayes auf Stichproben eingestellt.
:::

Die Grid-Methode ist bei größeren Datensätzen (oder größeren Modellen) zu rechenintensiv.
In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC).
Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses.
Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein[Eine gute Einführung in die Hintergründe findet sich bei @mcelreath_statistical_2020.]


### Häufigkeiten sind einfacher als Wahrscheinlichkeiten


Wie gesagt, typische R-Werkzeuge ("R-Golems") liefern uns die Post-Verteilung in Stichprobenform zurück.

Bevor wir uns aber mit diesen R-Werkzeugen beschäftigen,
sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.


Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle `d`), s. @lst-post-sample.



```{#lst-post-sample .r lst-cap="Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung"}
samples <-
  d %>%  # nimmt die Tabelle mit Posteriori-Daten,
  slice_sample(  # Ziehe daraus eine Stichprobe,
    n = 1e4,  # mit insgesamt n=10000 Zeilen,
    weight_by = post,  # Gewichte nach Post-Wskt.,
    replace = T)  %>%  # Ziehe mit Zurücklegen
  select(p_grid)
```



```{r lst-post-sample2}
#| lst-cap: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung
#| lst-label: lst-post-sample
#| echo: false
samples <-
  d %>%  # nimmt die Tabelle mit Posteriori-Daten,
  slice_sample(  # Ziehe daraus eine Stichprobe,
    n = 1e4,  # mit insgesamt n=10000 Zeilen,
    weight_by = post,  # Gewichte nach Post-Wskt.,
    replace = T)  %>%  # Ziehe mit Zurücklegen
  select(p_grid)
```

Die Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte `p_grid`) aus Tabelle `d` zu ziehen, 
ist proportional zur Posteriori-Wahrscheinlichkeit (`post`) dieses Werts. 
Ziehen mit Zurücklegen hält die Wahrscheinlichkeiten während des Ziehens konstant.
Das Argument `weight_by` legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird.

Wir begnügen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), `p_grid`, 
die anderen Spalten brauchen wir nicht.


Das Ergebnis, Tabelle `samples`, die aus Stichproben aus der Post-Verteilung besteht, ist (in Auszügen) in @tbl-postsample1 dargestellt.


```{r QM2-Thema3-Post-befragen-4}
#| echo: false
#| label: tbl-postsample1
#| tbl-cap: Die ersten Zeilen der Stichproben aus der Post-Verteilung
samples %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(columns = c(1),
             decimals = 3) 
```


Wenn Sie jetzt denken: "Warum machen wir das jetzt? Brauchen wir doch gar nicht!" - Dann haben Sie Recht.
Künftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.






Hier erstmal die ersten 100 gesampelten Gitterwerte (`p_grid`):

```{r QM2-Thema3-Teil1-2}
#| echo: false
samples$p_grid[1:100] %>% round(2)
```



Wie sieht diese Tabelle wohl als Histogramm^[hier als Balkendiagramm, kommt fast aufs selbe raus, sieht aber etwas schöner aus in diesem Fall, da er nur wenige Balken sind] aus?


So sieht die Post-Verteilung auf Basis von Stichproben dann aus, s.  @fig-samples1.

```{r QM2-Thema3-Teil1-3}
#| echo: false
#| message: false
#| fig-cap: Stichprobenverteilung auf Basis von Stichproben
#| label: fig-samples1
samples %>% 
  ggplot() +
  aes(x = p_grid) +
  geom_bar()
```

Aus @fig-samples1 können wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind.
So sehen wir, dass das Modell Parameterwerte (Wasseranteil, $\pi$) zwischen ca. 50% und 70% für am wahrscheinlichsten hält.
Aber auch kleine Anteile wie 25% sind nicht auszuschließen (auf Basis der Daten und der Modellannahmen).

Vergleichen Sie  @fig-samples1 mit @fig-gitter: beide sind sehr ähnlich!
Das Stichprobenziehen (@fig-samples1) nähert sich recht gut an die exakte Berechnung an (@fig-gitter).


### Visualisierung der Stichprobendaten mit $k=100$ Gitterwerten

$k=10$ Gitterwerte ist ein grobes Raster.
Drehen wir mal die Auflösung auf $k=100$ Gitterwerte (Ausprägungen) nach oben.




```{r QM2-Thema2-kleineModelle-28a}
#| echo: true
k <- 100
n_success <- 6
n_trials  <- 9

d_k100 <-
  tibble(p_grid = seq(from = 0, 
                      to = 1, 
                      length.out = k),  # 100 Gitterwerte
         prior  = 1) %>% 
  mutate(likelihood = dbinom(n_success, 
                             size = n_trials, 
                             prob = p_grid)) %>% 
  mutate(unstand_post = (likelihood * prior),
         post = unstand_post / sum(unstand_post))
```





$d_k100$ ist eine Bayes-Box mit $W=6, N=9, k=100$.

Und daraus ziehen wir uns $n=1000$ Stichproben:


```{r QM2-Thema3-Teil1-4}
samples_k100 <-
  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,
  slice_sample(  # Ziehe daraus eine Stichprobe,
    n = 1000,  # mit insgesamt n=1000 Elementen,
    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,
    replace = T)  # Ziehe mit Zurücklegen
```


@fig-post100 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. 
Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt.
Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt.
In allen Fällen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der "typische" Wert des Modells zu sein.
Außerdem erkennt man, dass das Modell durchaus einige Streuung in der Schätzung des Wasseranteils bereithält.
Das Modell ist sich nicht sehr sicher, könnte man sagen.


```{r samplesplot}
#| echo: false
#| fig-cap: Post-Verteilung mit 100 Gitterwerten, exakt vs. auf Basis von Stichproben
#| label: fig-post100


p0 <- 
  d_k100 %>% 
  ggplot(aes(x = p_grid, y= post)) +
  geom_line() +
  geom_point() +
  labs(title = "Post-Verteilung exakt")

p1 <-
  samples_k100 %>% 
  mutate(sample_number = 1:n()) %>% 
  ggplot(aes(x = sample_number, y = p_grid)) +
  geom_point(alpha = 1/10) +
  scale_y_continuous("Anteil Wasser  (p)", 
                     limits = c(0, 1)) +
  labs(x = "Nummer der Stichprobe",
       title = "Stichproben aus der Post")

p2 <-
samples_k100 %>% 
  ggplot(aes(x = p_grid)) +
  geom_density(fill = "black") +
  scale_x_continuous("Anteil Wasser (p)", 
                     limits = c(0, 1)) +
  labs(y = "Wahrscheinlichkeitsdichte",
       title = "Stichproben aus der Post")


plots(p0, p1, p2)
```

Die Stichprobendaten nähern sich der "echten" Posteriori-Verteilung an:
Die Stichproben-Post-Verteilung hat jetzt "glattere" Ränder.


::: callout-note
Mehr Stichproben und mehr Gitterwerte glätten die Verteilung.
:::

Jetzt noch mal mit mehr Stichproben: $n=10^6$ Stichproben bei $k=100$ Gitterwerten aus der Posteriori-Verteilung, s. @fig-post-dk100.

```{r QM2-Thema3-Post-befragen-5}
#| echo: false
#| label: fig-post-dk100
#| fig-cap: "Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schön 'glatt'. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist."


d_k100_samples <- 
  d_k100 %>% 
  slice_sample(n = 1e6, weight_by = post, replace = T) 


mode <- map_estimate(d_k100_samples$p_grid) %>% round(2)
avg <- mean(d_k100_samples$p_grid) %>% round(2)
md <- median(d_k100_samples$p_grid) %>% round(2)

d_k100_samples %>%   
ggplot(aes(x = p_grid)) +
  geom_density(fill = "grey40") +
  scale_x_continuous("Anteil Wasser (p)", limits = c(0, 1)) +
  labs(y = "",
       caption = paste0("Modus: ", mode, "; MW: ", avg, "; Md: ", md)) +
  geom_vline(xintercept = c(mode, avg, md))
```


## Die Post-Verteilung befragen



So, jetzt befragen wir die Post-Verteilung.


:::callout-important
Die Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse.
Wir können viele nützliche Fragen an sie stellen.
:::

Es gibt zwei Arten von Fragen:

1. nach Wahrscheinlichkeiten (p)
2. nach Parameterwerten (Quantilen, q)


Der Unterschied zwischen beiden Arten von Fragen ist in  @fig-p-vs-q illustriert.

![Fragen nach p vs. Fragen nach q](img/p-vs-q.png){#fig-p-vs-q width="50%" fig-align="center"}

Im linken Teildiagramm von @fig-p-vs-q fragen wir: "Wie wahrscheinlich ist ein Wasseranteil von höchstens 80%?".
Im rechten Teildiagramm fragen wir: "Welcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht überschritten?".


### Fragen nach Wahrscheinlichkeiten




Sagen wir, dass sei unsere Forschungsfrage: *Wie groß ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?*


Um diese Frage zu beantworten, zählen wir einfach, wie viele Stichproben die Bedingung erfüllen:

und und summieren die Wahrscheinlichkeiten dieser Stichproben:





Wir zählen (`count`) also die Stichproben, die sich für einen Wasseranteil (`p_grid`) von weniger als 50% aussprechen:

```{r QM2-Thema3-Post-befragen-7}
samples %>%
  count(p_grid < .5) 
```

Da wir insgesamt 10000 (1e4) Stichproben gezogen haben, können wir noch durch diese Zahl teilen, um einen Anteil zu bekommen.
Dieser Anteil ist die Antwort auf die Forschungsfrage: 
Wie Wahrscheinlichkeit (laut Modell) für einen Wasseranteil kleiner als 50%.^[Der Befehl `count` macht Folgendes: Er gruppiert die Stichprobe nach dem Prüfkriterium, Wasseranteil höchstens 50%. Dann zählt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurück. Man könnte also auch in etwa schreiben:

```{r QM2-Thema3-Post-befragen-6}
d %>%
  filter(p_grid < .5) %>%
  summarise(sum = sum(post))
```


Einfach wie `r emojifont::emoji("cake")` essen.





:::{#exm-param2}

## Wasseranteil zwischen 50 und 75%?

Noch eine Forschungsfrage: *Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?*


```{r QM2-Thema3-Post-befragen-8}
samples %>% 
  count(p_grid > .5 & p_grid < .75)
```



```{r QM2-Thema3-Post-befragen-8a}
samples %>% 
  count(p_grid > .5 & p_grid < .75) %>% 
  summarise(Anteil = n / 1e4,
            Prozent = 100 * n / 1e4)  # In Prozent
```

Anteile von `count()` könnte man, wenn man möchte, auch `filter()` verwenden:


```{r}
samples %>% 
  filter(p_grid > .5 & p_grid < .75) %>% 
  summarise(sum     =       n() / 1e4,
            anteil = 100 * n() / 1e4)  # In Prozent
```


:::

:::{#exm-param3}

## Wasseranteil zwischen 90 und 100%?

Noch ein Beispiel für eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?

```{r QM2-Thema3-Post-befragen-9}
samples %>% 
  count(p_grid >= .9 & p_grid <= 1) %>% 
  summarise(prop = 100 * n() / 1e4)  # prop wie "proportion", Anteil
```

Laut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind.  90% beträgt.


:::


Wir können auch fragen, welcher Parameterwert am wahrscheinlichsten ist;
dieser Wert entspricht dem "Gipfel" des Berges, s.  @fig-post-dk100.


Für unsere Stichproben-Postverteilung, `samples`, s. @fig-samples1, lässt sich der Modus so berechnen:


```{r}
map_estimate(samples$p_grid)  
```


Dabei steht `map` für [Maximum Aposteriori](https://easystats.github.io/bayestestR/reference/map_estimate.html), also das Maximum der Post-Verteilung.


Bei der Gelegenheit könnten wir folgende, ähnliche Fragen stellen:

- Was ist der mittlere Schätzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?
- Was ist der mediane Schätzwert (Median)?


Auf Errisch:

```{r}
samples %>% 
  summarise(mean(p_grid),
            median(p_grid))
```


### Fragen nach Parameterwerten

::: callout-important
Schätzbereiche von Parameterwerten nennt man auch *Konfidenz- oder Vertrauensintervall*^[Tatsächlich gibt es eine Vielzahl an Begriffen, die in der Literatur nicht immer konsistent verwendet werden, etwa Kompatibilitätsintervall, Ungewissheitsintervall, Passungsbereich.].
:::



Welcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht überschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit)
Wir möchten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist^[Vielleicht damit es genug Berge zum Schifahren gibt.].


```{r QM2-Thema3-Post-befragen-11}
samples %>% 
  summarise(quantil90 = quantile(p_grid, p = .9))
```


Laut unserem Modell können wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.

Es hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu führen, s. @fig-post99.

```{r}
#| label: fig-post99
#| fig-cap: Die Post-Verteilung im Globusversuch
#| fig-asp: .5
#| out-width: "50%"
samples %>% 
  ggplot(aes(x = p_grid)) +
  geom_bar()
```




Was ist das *mittlere* Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthält, laut dem Modell?

Dafür "schneiden" wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:

```{r QM2-Thema3-Post-befragen-12, echo = TRUE}
samples %>% 
  summarise(
    quant_05 = quantile(p_grid, 0.05),
    quant_95 = quantile(p_grid, 0.95))

```


Solche Fragen lassen sich also mit Hilfe von *Quantilen* beantworten.



### Zur Erinnerung: Quantile

Beispiel: Wie groß sind die Studentis ([Quelle des Datensatzes](https://rdrr.io/cran/openintro/man/speed_gender_height.html))? 

Das Quantil von z.B. 25% zeigt die Körpergröße der 25% kleinsten Studentis an, analog für 50%, 75%, in Inches^[1 Inch entspricht 2.54cm]:

```{r QM2-Thema3-Teil1-5}
#| message: false
#| echo: true
speed_gender_height <- read_csv("https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv")

height_summary <- 
  speed_gender_height %>% 
  mutate(height_cm = height*2.54) %>% 
  select(height_inch = height, height_cm) %>% 
  drop_na() %>% 
  pivot_longer(everything(), names_to = "Einheit", values_to = "Messwert") %>% 
  group_by(Einheit) %>% 
  summarise(q25 = quantile(Messwert, prob = .25),
            q50 = quantile(Messwert, prob = .5),
            q75 = quantile(Messwert, prob = .75))

height_summary
```

Das 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.


@fig-stud-height visualisiert die Quantile und die Häufigkeitsverteilung.

```{r QM2-Thema3-Teil1-6}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Größenverteilung von 1325 amerikanischen Studentis
#| label: fig-stud-height
#| fig-width: 10
p1 <- speed_gender_height %>% 
  ggplot() +
  aes(x = 1, y = height) +
  geom_boxplot() +
  labs(x = "",
       y = "Größe in Inch",
       title = "Die Box zeigt das 25%-, 50%- und 75%-Quantil")

height_summary_long <- 
  speed_gender_height %>% 
  select(height) %>% 
  drop_na() %>% 
  summarise(q25 = quantile(height, prob = .25),
            q50 = quantile(height, prob = .5),
            q75 = quantile(height, prob = .75)) %>% 
  pivot_longer(everything(),
               names_to = "q",
               values_to = "height")

p2 <- 
  speed_gender_height %>% 
  ggplot() +
  aes(x = height) +
  geom_histogram() +
  geom_vline(data = height_summary_long,
             aes(xintercept = height)) +
  geom_text(data = height_summary_long,
             aes(x = height+1,
                 y = 0,
                 label = paste0(q, ": ", height)),
             angle = 90,
            hjust = 0,
            color = "white"
             ) +
  labs(title = "Die vertikalen Striche zeigen die Quantile",
       y = "Häufigkeit")

plots(p1, p2)
```


###  Den Quantilen unter die Motorhaube geschaut

Den R-Befehl `quantile()` kann man sich, wenn man will, einfach nachbauen und entmystifizieren.

Angenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht überschritten wird.
Das können wir mit im Datensatz `samples` so erreichen.

1. Sortiere die Stichproben aufsteigend.
2. Schneide die oberen 10% (von 10000) ab (entferne sie).
3. Schaue, was der größte verbleibende Wert ist.

```{r}
samples %>% 
  arrange(p_grid) %>%   # sortiere
  slice_head(n = 9000) %>%  # nur die ersten 90000
  summarise(p90 = max(p_grid))
```


Das (annähernd) gleiche Ergebnis liefert `quantile()`:

```{r}
samples %>% 
  summarise(q90 = quantile(p_grid, .9))
```


### Visualisierung der Intervalle


::: {#def-eti}

## Perzentilintervall (PI)

Intervalle (Bereiche), die die "abzuschneidende" Wahrscheinlichkeitsmasse hälftig auf die beiden Ränder aufteilen, nennen wir *Perzentilintervalle* oder (synonym) *Equal-Tails-Intervalle* (ETI), s. Abb. @fig-eti, rechtes Teildiagramm.

:::



```{r piplot}
#| echo: false
#| fig-cap: Perzintilintervalle
#| label: fig-eti
q_80 <- quantile(samples$p_grid, prob = .8)
q_10_and_90 <- quantile(samples$p_grid, prob = c(.1, .9))

p1 <-
  d_k100 %>% 
  ggplot(aes(x = p_grid, y = post)) +
  geom_line() +
  labs(title="Untere 80%",
       caption = paste0("q80: ", round(q_80, 2))) +
  geom_area(data = d_k100 %>% 
              filter(p_grid < q_80)) 

# lower right panel
p2 <-
  d_k100 %>% 
  ggplot(aes(x = p_grid, y = post)) +
  geom_line() +
  geom_area(data = d_k100 %>% 
              filter(p_grid > q_10_and_90[1] & p_grid < q_10_and_90[2])) +
  labs(subtitle = "Perzentilintervall",
       title = "Mittlere 80%",
       caption = paste0("q10: ", round(q_10_and_90[1], 2), 
                        "; q90: ",
                        round(q_10_and_90[2]), 2))

plots(p1, p2)
```



## Schiefe Posteriori-Verteilungen sind möglich


Noch einmal zum Globusversuch: Gehen wir von 3 Würfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schließen?

Vermutlich ziemlich hohe.

Erstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 Würfe):

```{r QM2-Thema3-Post-befragen-13}
d_33 <- 
  tibble(p_grid = seq(0,1, by =.01),
         prior = 1) %>% 
  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% 
  mutate(unstand_post = likelihood * prior) %>% 
  mutate(post_33  = unstand_post / sum(unstand_post)) 

samples_33 <- 
  d_33 %>% 
    slice_sample(n = 1e4, 
                 weight_by = post_33, 
                 replace = T)
```

So sehen die ersten paar Zeilen der Post-Verteilung, `samples_33`, aus.

```{r QM2-Thema3-Post-befragen-14}
#| echo: false
samples_33 %>% 
  select(-post_33) %>% 
  head() %>% 
  gt() %>% 
  fmt_number(columns = c(1,3,4), decimals = 2)
```


Mit dieser "schiefen" Post-Verteilung können wir gut die Auswirkungen auf das Perzentil- und das Höchste-Dichte-Intervall anschauen.


### Perzentil-Intervall

Hier z.B. ein 50%-Perzentilintervall, s. Abb. @fig-schief.



```{r QM2-Thema3-Post-befragen-15}
#| echo: false
#| fig-cap: "Schiefe Intervalle"
#| label: fig-schief

qi_50_low <- eti(samples_33$p_grid, ci = .5)$CI_low
qi_50_up <- eti(samples_33$p_grid, ci = .5)$CI_high
p1 <-
  d_33 %>% 
  ggplot(aes(x = p_grid, y = post_33)) +
  # check out our sweet `qi()` indexing
  geom_area(data = . %>% 
              filter(p_grid > qi_50_low &  
                    p_grid < qi_50_up),
            fill = "grey75") +
  geom_line() +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = .1))




hdi_50_low <- bayestestR::hdi(samples_33$p_grid, 
                                  ci = .5)$CI_low
hdi_50_up <- bayestestR::hdi(samples_33$p_grid, 
                                  ci = .5)$CI_high

p2 <-
  d_33 %>% 
  ggplot(aes(x = p_grid, y = post_33)) +
  geom_area(data = . %>% 
              filter(p_grid > hdi_50_low & 
                     p_grid < hdi_50_up),
            fill = "grey75") +
  geom_line()


plots(p1, 
      p2,
      n_rows = 1,
      title= c("Ein Perzentilintervall kann, wenn es dumm läuft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zurückweisen. Das ist nicht so toll.",
        "Ein Highest-Density-Intervall ist schmäler als der Perzintilintervall und enthält den wahrscheinlichsten Parameterwert"))
```





Die Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:

```{r}
library(easystats)

samples_33 %>% 
  select(p_grid) %>% 
  eti(ci = .5)
```



Der wahrscheinlichste Parameterwert (1) ist *nicht* im Intervall enthalten.
Das ist ein Nachteil der ETI.




### Intervalle höchster Dichte


::: {#def-hdi}

Intervalle höchster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das *schmälste* Intervall, das den gesuchten Parameter enthält (in Bezug auf ein gegebenes Modell).

:::







Der wahrscheinlichste Parameterwert ($1$) *ist* im Intervall enthalten, was Sinn macht.
Bei einem HDI sind die abgeschnitten Ränder nicht mehr gleich groß, im Sinne von enthalten nicht (zwangsläufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen Rändern hingegen gleich groß.


Je symmetrischer die Verteilung, desto näher liegen die Punktschätzer aneinander (und umgekehrt), s. Abb. @fig-post-pointestimates.


```{r pointestimators}
#| echo: false
#| fig-cap: Visualisierung der Punktschätzer bei einer schiefen Post-Verteilung
#| label: fig-post-pointestimates
#| message: false
#| fig-asp: 0.5

point_estimates <-
  bind_rows(samples_33 %>% tidybayes::mean_qi(p_grid),
            samples_33 %>% tidybayes::median_qi(p_grid),
            samples_33 %>% tidybayes::mode_qi(p_grid)) %>% 
  select(p_grid, .point) %>% 
  # these last two columns will help us annotate  
  mutate(x = p_grid + c(-.03, .03, -.03),
         y = c(.005, .012, .02))

d_33 %>% 
  ggplot(aes(x = p_grid)) +
  geom_area(aes(y = post_33),
            fill = "grey75") +
  geom_vline(xintercept = point_estimates$p_grid) +
  geom_text(data = point_estimates,
            aes(x = x, y = y, label = .point),
            angle = 90) +
  labs(x = "Anteil Wasser (p)",
       y = "Wahrscheinlichkeitsdichte") +
  theme(panel.grid = element_blank())
```




So kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen, s. @tbl-samples-hdi.


```{r hdi-samples-50}
#| eval: false
samples %>% 
  select(p_grid) %>% 
  hdi(ci = .5)  # aus dem Paket `{easystats}`
```

```{r hdi-samples-51}
#| echo: false
#| label: tbl-samples-hdi
#| tbl-cap: "50%-HDI für unser Globusmodell"
samples %>% 
  select(p_grid) %>% 
  bayestestR::hdi(ci = .5)  # aus dem Paket `{easystats}`
```



Das Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfläche) sich im  von ca. .67 bis .78 befindet (auf Basis eines HDI).


## Fazit


### Intervalle höchster Dichte vs. Perzentilintervalle

- Bei symmetrischer Posteriori-Verteilung sind beide Intervalle ähnlich
- Perzentilintervalle sind verbreiteter
- *Intervalle höchster Dichte* (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen
- Intervalle höchster Dichte sind die *schmalsten* Intervalle für eine gegebene Wahrscheinlichkeitsmasse




### Zusammenfassung

Fassen wir zentrale Punkte an einem Beispiel zusammen.

Im Globusversuch, Datendatz `samples`, s. @lst-post-sample. Sagen wir, wir haben 6 Treffer bei 9 Würfen erzielt.




Lageparmameter: Welchen mittleren Wasseranteil muss man annehmen?

```{r QM2-Thema3-Post-befragen-19}
samples %>% 
  summarise(
    mean   = mean(p_grid),
    median = median(p_grid))  
```

Streuungsparameter: Wie unsicher sind wir in der Schätzung des Wasseranteils?

```{r QM2-Thema3-Post-befragen-20}
samples %>% 
  summarise(
    p_sd   = sd(p_grid),
    p_iqr = IQR(p_grid),
    p_mad = mad(p_grid))  
```

Anstelle der Streuungsparameter ist es aber üblicher, ein HDI oder PI anzugeben.



:::callout-important
Alles Wasser oder was?
Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. 
Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel für einen *Parameter*, einer unbekannten Größes eines Modells.
:::





## Aufgaben


1. [iq01](https://datenwerk.netlify.app/posts/iq01/iq01.html)
2. [iq02](https://datenwerk.netlify.app/posts/iq02/iq02.html)
3. [iq03](https://datenwerk.netlify.app/posts/iq03/iq03.html)
4. [iq04](https://datenwerk.netlify.app/posts/iq04/iq04.html)
5. [iq05](https://datenwerk.netlify.app/posts/iq05/iq05.html)
6. [iq06](https://datenwerk.netlify.app/posts/iq06/iq06.html)
7. [iq07](https://datenwerk.netlify.app/posts/iq07/iq07.html)
8. [iq08](https://datenwerk.netlify.app/posts/iq08/iq08.html)
8. [iq10](https://datenwerk.netlify.app/posts/iq10/iq10.html)
9. [fattails1](https://datenwerk.netlify.app/posts/fattails01/fattails01.html)
10. [fattails2](https://datenwerk.netlify.app/posts/fattails02/fattails02.html)
11. [ReThink3e1-7](https://datenwerk.netlify.app/posts/rethink3e1-7/rethink3e1-7)













## ---



![](img/outro-06.jpg){width=100%}


