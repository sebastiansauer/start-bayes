







## Prior-Pr√§diktiv-Verteilung

üèéüèéÔ∏è VERTIEFUNG (nicht pr√ºfungsrelevant ) üèéüèé




### Moment

 ü§î Moment. Dieser Prior, $\beta_1$ in `m43` erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!

Sind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Gr√∂√üe positiv oder negativ ist? [Nein, sind wir nicht.](https://media.giphy.com/media/daPCSjwus6UR2JxRX1/giphy.gif) 
    


### Priori-Pr√§diktiv-Verteilung f√ºr `m43`



Was denkt [wir](https://media.giphy.com/media/Aausss8uUBIe3bZ3d2/giphy.gif) bzw. unser Golem *apriori* √ºber den Zusammenhang von Gr√∂√üe und Gewicht?
Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also f√ºr $\beta_0$, $\beta_1$ und $\sigma$.



```{r m43-prior-pred}
m43_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),
             prior_intercept = normal(178, 20),  # mu
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # Schalter f√ºr Prior-Pred-Verteilung
             data = d3)


m43_prior_pred_draws <- 
  m43_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```



```{r}
#| echo: false
m43_prior_pred_draws %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```



Jede Zeile definiert eine Regressionsgerade.



### Prior-Pr√§diktiv-Simulation f√ºr `m43` mit `stan_glm()` 




```{r echo = TRUE, eval = FALSE}
m43_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),  # beta
             prior_intercept = normal(178, 20),  # alpha
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # DIESER Schalter macht's
             data = d3)

m43_prior_pred_draws <- 
  m43_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```



```{r echo = FALSE, eval = FALSE}
m43a_prior_pred <-
    stan_glm(height ~ weight_c, 
             prior = normal(0, 10),  # beta
             prior_intercept = normal(0, 20),  # alpha
             prior_aux = exponential(0.1),  # sigma
             refresh = FALSE, 
             prior_PD = TRUE,  # DIESER Schalter machts
             data = d3)

m43a_prior_pred_draws <- 
  m43a_prior_pred %>% 
  as_tibble() %>% 
  rename(a = `(Intercept)`,
         b = weight_c) %>% 
  slice_sample(n = 50)
```









### Visualisieren der Prior-Pr√§diktiv-Verteilung



```{r prior-pv1, echo = TRUE, eval = FALSE, fig.asp = .5}
d3 %>% ggplot() +
  geom_point(aes(x = weight_c, y = height)) + 
  geom_abline(data = m43_prior_pred_draws,
aes(intercept = a, slope = b), color = "skyblue", size = 0.2) +
  scale_y_continuous(limits = c(0, 500)) +
  geom_hline(yintercept = 272, size = .5) +
  geom_hline(yintercept = 0, linetype = "dashed")
```



ü§Ø Einige dieser Regressionsgeraden sind unsinnig!


```{r ref.label = "prior-pv1", eval = TRUE, fig.asp = .3}

```


Die durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.





### Ein positiver Wert f√ºr $\beta_1$ ist plausibler


#### Oh no

Eine Normalverteilung mit viel Streuung:

```{r Post-Regression-16, fig.asp = .5}
#| echo: false
d <-
  tibble(
    x = seq(-30,30,.1),
    y = dnorm(x, mean = 0, sd = 10)
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  scale_y_continuous(breaks = NULL) +
  labs(title = "mu=0, s=10")
```

üëé $\beta=-20$ w√§re mit diesem Prior gut m√∂glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.




#### Oh yes

Wir br√§uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):

```{r Post-Regression-17, fig.asp=.5}
#| echo: false
d <-
  tibble(
    x = seq(-30,30,.1),
    y = dnorm(x, mean = 3, sd = 2)
  )

d %>% 
  ggplot(aes(x,y)) +
  geom_line() +
  scale_y_continuous(breaks = NULL) +
  labs(title = "mu=5, sd = 3")
```

üëç Vermutlich besser: Ein Gro√üteil der Wahrscheinlichkeitsmasse ist $X>0$. Allerdings gibt's keine Gew√§hr, dass unser Prior "richtig" ist.




### Priori-Pr√§diktiv-Simulation, 2. Versuch





```{r echo = TRUE}
m43a_prior_pred <-
    stan_glm(
      height ~ weight_c, 
      prior = normal(2, 2),  # Regressionsgewicht
      prior_intercept = normal(178, 20),  # mu
      prior_aux = exponential(0.1),  # sigma
      refresh = FALSE, 
      # Schalter f√ºr Prior-Pred-Verteilung:
      prior_PD = TRUE, 
      data = d3)


m43a_prior_pred_draws <- 
  m43a_prior_pred %>% 
  as_tibble() %>% 
  # Spaltennamen k√ºrzen: 
  rename(a = `(Intercept)`) %>%  
  rename(b = weight_c,
         s = sigma)
```





```{r}
#| echo: false
m43a_prior_pred_draws %>% 
  slice_head(n=5) %>% 
  gt() %>% 
  fmt_number(everything(), decimals = 1)
```



Das Argument `prior_PD = TRUE` sorgt daf√ºr, dass keine Posteriori-Verteilung, sondern eine Prior-Pr√§diktiv-Verteilung berechnet wird.




### Visualisieren der Prior-Pr√§diktiv-Verteilung, `m43a`


Unsere Priori-Werte scheinen einigerma√üen vern√ºnftige Vorhersagen zu t√§tigen. Allerdings erwartet unser Golem einige Riesen.


```{r, eval = TRUE, fig.asp=.5}
d3 %>% 
  ggplot(aes(x = weight_c, y = height)) +
  geom_point() +
  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},
              aes(slope = b,
                  intercept = a),
              color = "skyblue",
              size = .2,
              alpha = .7) +
  geom_hline(yintercept = 272, size = .5) +
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_y_continuous(limits = c(0, 500)) 
```


Die durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.








### Moment, kann hier jeder machen, was er will?



Es doch den einen, richtigen, objektiven Priori-Wert geben?!

Kann denn jeder hier machen, was er will?! Wo kommen wir da hin?!


>    This is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.  

@mcelreath2020, p. 96.





### Hier ist unser Modell, `m43a`




\begin{align}
\text{height}_i &\sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot  \text{weight}_i\\
\alpha &\sim \operatorname{Normal}(178, 20)\\
\beta &\sim \operatorname{Normal}(5,3)\\
\sigma &\sim \operatorname{Exp}(0.1)
\end{align}



```{r Post-Regression-25, echo = TRUE}
# Posteriori-Vert. berechnen:
m43a <-
  stan_glm(
    height ~ weight_c,  # Regressionsformel
    prior = normal(5, 3),  # Regressionsgewicht (beta 1)
    prior_intercept = normal(178, 20),  # mu
    prior_aux = exponential(0.1),  # sigma
    refresh = 0,  # zeig mir keine Details
    seed = 42,  # Zufallszahlen festlegen
    data = d3)
```





### Eine Zusammenfassung der Posteriori-Verteilung f√ºr `m43a`


```{r}
#| eval: false
m43a %>% 
  parameters()
```



```{r}
#| echo: false
m43a %>% 
  parameters() %>% 
  display()
```



Unser Modell `m43a` sch√§tzt die typische K√∂rpergr√∂√üe einer !Kung-Person *mittleren Gewichts* (`weight_c = 0`) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher.
Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise;
auch hier ist sich das Modell ziemlich sicher, da dass zugeh√∂rige 95%-CI keine 20 Zentimenter umfasst.







