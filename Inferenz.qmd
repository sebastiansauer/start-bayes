# Inferenz

```{r}
#| echo: false
#| message: false
library(tidyverse)
library(easystats)
theme_set(theme_minimal())
```



![Bayes:Start!](img/Golem_hex.png){width=10%}








## Lernsteuerung

### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...



- die Definition von Inferenzstatistik sowie Beispiele f√ºr inferenzstatistische Fragestellungen nennen
- zentrale Begriffe nennen und in Grundz√ºgen erkl√§ren
- den Nutzen von Inferenzstatistik nennen
- erl√§utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht
- auch anhand von Beispielen erkl√§ren, was ein statistisches Modell ist
- die Grundkonzepte der Regression angeben
- Unterschiede zwischen klassischer und Bayes-Inferenz benennen
- Vor- und Nachteile der klassischen vs. Bayes-Inferenz diskutieren
- Die grundlegende Herangehensweise zur Berechnung des p-Werts informell erkl√§ren k√∂nnen


### Begleitvideos

- [Video zur Inferenz, Teil 1](https://youtu.be/gcwWwBy0kPI)
- [Video zur Inferenz, Teil 2](https://https://youtu.be/QNMVi6IqQ90)


## Wozu ist Statistik √ºberhaupt da?

Ja, diese Frage haben Sie sich auch schon mal gestellt? 

Abb. @fig-goals gibt einen √úberblick √ºber die Ziele der Statistik.

```{mermaid}
%%| label: fig-goals
%%| fig-cap: A taxonomy of statistical goals
flowchart LR
  A{Goals} --> B(describe)
  A --> C(predict)
  A --> D(explain)
  B --> E(distribution)
  B --> F(assocation)
  B --> G(extrapolation)
  C --> H(point estimate)
  C --> I(interval)
  D --> J(causal inference)
  D --> K(population)
  D --> L(latent construct)

```

::: callout-note
Ziele existieren nicht "in echt" in der Welt. 
Wir denken sie uns aus.
Ziele haben also keine ontologische Wirklichkeit,
sie sind epistemologische Dinge (existieren nur in unserem Kopf).
Das hei√üt, dass man sich nach Beliebem Ziele ausdenken kann.
Allerdings h√ºlfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen √ºberzeugen kann.
:::





## Was ist Inferenz?

```{r}
#| include: false
library(kableExtra)
library(tidyverse)
library(knitr)
library(easystats)
```




### Inferenz als Generalisieren

Statistische Inferenz sieht sich drei "Herausforderungen" gegen√ºber, laut  @gelman_regression_2021, Kap. 1.1. 
Diese betreffen das Schlie√üen (oder Generalisieren) vom Einzelfall auf das Allgemeine:

1. Von der Stichprobe aus die Grundgesamtheit (Population)
2. Von der Experimental- auf die Kontrollgruppe (Kausalinferenz)
3. Von einem Messwert auf das zugrundeliegende Konstrukt

In diesem Kurs besch√§ftigen wir uns mit den ersten beiden Herausforderungen.



::: callout-important
Statistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlie√üen, bzw. vom Konrketen auf das Abstrakte.
:::

## Stichprobe vs. Population


Nehmen wir an, wir m√∂chten herausfinden, wie gro√ü der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit `A`^[~~Meistens~~ Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?].

Das *Grundproblem der Inferenzstatistik* ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.

Wir m√ºssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe f√ºr die Grundgesamtheit schlie√üen:
Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. @fig-pop-sample.


::: {#fig-pop-sample layout-ncol="2"}
![Population](img/pvoll.png){#fig-pop}

![Sample](img/psti.png){#fig-sample}

Population vs. sample (Image credit: Karsten Luebke)
:::



H√§ufig ist das praktische Vorgehen recht simpel: 
Ah, in unserer Stichprobe sind 42% R-Fans!^[Mancheiner h√§tte mit mehr gerechnet]. Man schreibt: $p = 0.42$ (`p` wie `proportion`). Die Stichprobe sei repr√§sentativ f√ºr die Grundgesamtheit aller Studierender. 
Messerscharf schlie√üen wir:
In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, $\pi=0.42$.



### Deskriptiv- vs. Inferenzstatistik

Statistik gibt es in zwei Geschmacksrichtungen, k√∂nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. @fig-inf1.
Einteilungen in Schubladen existieren nicht auf der Welt,
sondern in unserem Kopf:
Sie besitzen keine ontologische Realit√§t, sondern eine epistemologische.
Sie sind frei, sich andere Einteilungen der Statistik auszudenken.
Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee √ºberzeugen kann.

![Deskriptiv- vs. Inferenzstatistik](img/desk_vs_inf-crop.png){#fig-inf1}


*Deskriptivstastistik* fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.

*Inferenzstatistik* schlie√üt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).

üèã Schlie√üen Sie die Augen und zeichnen Sie obiges Diagramm!



### Wozu ist die Inferenstatistik gut?

::: callout-note
Inferenz bedeutet Schlie√üen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.
:::

Inferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schl√ºsse zu ziehen.






üèãÔ∏èÔ∏è Heute Nacht vor dem Schlafen wiederholen Sie die Definition. √úben Sie jetzt schon mal.


### Deskriptiv- und Inferenzstatistik gehen Hand in Hand

F√ºr jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle @tbl-kennwerte.

```{r}
#| echo: false
#| label: tbl-kennwerte
#| tbl-cap: Bezeichnungen f√ºr Kennwerte
#| message: false
x <- tribble(
    ~Kennwert, ~Stichprobe, ~Grundgesamtheit,
  "Mittelwert", "$\\bar{X}$", "$\\mu$",
  "Streuung", "$sd$", "$\\sigma$",
  "Anteil", "$p$", "$\\pi$",
  "Korrelation", "$r$", "$\\rho$" ,
  "Regression", "$b$", "$\\beta$"

)

kable(x, escape = FALSE, booktabs = TRUE, format = "simple") 
```

F√ºr Statistiken (Daten einer Stichprobe) verwendet man *lateinische* Buchstaben; 
f√ºr Parameter (Population) verwendet man *griechische* Buchstaben.

üèãÔ∏è Geben Sie die griechischen Buchstaben f√ºr typische Statistiken an!



### Sch√§tzen von Parametern einer Grundgesamtheit

Meist begn√ºgt man sich  beim Analysieren von Daten nicht mit Aussagen f√ºr eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.

Leider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit *Sch√§tzungen* begn√ºgen.

Sch√§tzwerte werden mit einem "Dach" √ºber dem Kennwert gekennzeichnet, z.B.

```{r}
#| echo: false
x <- tribble(
    ~Kennwert, ~Stichprobe, ~Grundgesamtheit, ~Sch√§tzwert,
  "Mittelwert", "$\\bar{X}$", "$\\mu$", "$\\hat{\\mu}$",
  "Streuung", "$sd$", "$\\sigma$", "$\\hat{\\sigma}$",
  "Anteil", "$p$", "$\\pi$", "$\\hat{\\pi}$",
  "Korrelation", "$r$", "$\\rho$", "$\\hat{\\rho}$" ,
  "Regression", "$b$", "$\\beta$", "$\\hat{\\beta}$"

)

kable(x, escape = FALSE, booktabs = TRUE, format = "simple") 
```

### Beispiele f√ºr inferenzstatistische Fragestellungen

Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?

-   Dazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, $\bar{X}_{V1}$ und $\bar{X}_{V2}$.

-   Die Mittelwerte unterscheiden sich etwas, $\bar{X}_{V1} > \bar{X}_{V2}$

-   Sind diese Unterschiede "zuf√§llig" oder "substanziell"? Gilt also $\mu_{V1} > \mu_{V2}$ oder gilt $\mu_{V1} \le \mu_{V2}$?

-   Wie gro√ü ist die Wahrscheinlichkeit[^inferenz-1] $Pr(\mu_{V1} > \mu_{V2})$?

[^inferenz-1]: oft mit *Pr* oder *p* abgek√ºrzt, f√ºr *probability*

üèãÔ∏è *Predictive Maintenance* ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 [dieses Berichts](https://www.rolandberger.com/publications/publication_pdf/roland_berger_vdma_predictive_maintenance_d_1.pdf)!


## Modellieren

### Modellieren als Grundraster des Erkennens

In der Wissenschaft - wie auch oft in der Technik, Wirtschaft oder im Alltag - betrachtet man einen Teil der Welt n√§her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.

Nun ist die Welt ein weites Feld. 
Jedes Detail zu ber√ºcksichtigen ist nicht m√∂glich.
Wir m√ºssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend n√∂tig sind.
Aber gleichzeitig die Strukturelemente der wirklichen Welt, die f√ºr unsere Fragestellung zentral ist, beibehalten.

Dieses Tun nennt man *Modellieren*: Man erstellt sich ein Modell.

::: callout-important
Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit.
:::


Auf die Statistik bezogen hei√üt das,
dass man einen Datensatz zu zusammenfasst,
dass man das Wesentliche erkennt.
Was ist das "Wesentliche"? Meist interessiert man sich f√ºr die Ursachen eines Ph√§nomens? Etwa: "Wie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?"^[Das ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.]
Noch allgemeiner ist vom h√§ufig am Zusammenhang von `X ` und `Y` interessiert, s. @fig-xy, linker Teil, die ein Sinnbild eines statistischen Modells widergibt.





:::{#fig-xy fig-align="center"}


```{mermaid}
flowchart LR
X --> Y


X1 --> Y2
X2 --> Y2
```

oben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)


:::



Das Diagramm hat Sie nicht so vom Hocker?
Okay, ein statistisches Modell kann nat√ºrlich komplexer sein, z.B. wie in Abb. @fig-xy, rechter Teil, dargestellt.




Es h√∂rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren:
Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet,
macht man sich ein Modell:
man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl,
die das forschungsleitende Interesse zusammenfasst.

### Vertiefung

Lesen Sie die Einf√ºhrung zum Thema Modellieren bei @poldrack_statistical_2022 (Kap. 5.1).


:::callout-note
Nutzen Sie die √úbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.
:::


## Regression

Einflussreiche Leute schw√∂ren auf die Regressionsanalyse (@fig-gandalf).

![One regression](img/einring.jpg){width="50%" #fig-gandalf fig-align="center"}



### Regression zum Modellieren

Die Regression ist eine Art Schweizer Taschenmessen: F√ºr vieles gut einsetzbar.

Anstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden.
Das ist nicht nur einfacher, sondern auch sch√∂ner. 
Wir werden im Folgenden stets die Regression zum Modellieren verwenden.


Dann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.


:::callout-note
Regression + Inferenz = üíñ
:::



Alternativ zur Regression k√∂nnte man sich in den Wald der statistischen Verfahren begeben, [wie hier von der Uni M√ºnster als Ausschnitt (!) aufgef√ºhrt](https://web.archive.org/web/20091029162244/http://www.wiwi.uni-muenster.de/ioeb/en/organisation/pfaff/stat_overview_table.html).

Auf dieser Basis kann man meditieren,
welches statistischen Verfahren man f√ºr eine bestimmte Fragestellung verwenden sollte, s. Abb.  @fig-choose-test.

![W√§hle deine Statistik mit Bedacht](img/choose-test.png){#fig-choose-test}

### Viele statistische Verfahren sind Spezialf√§lle der Regression

Wie Jonas Kristoffer Lindel√∏v uns erkl√§rt, sind viele statistische Verfahren, wie der sog. t-Test Spezialf√§lle der Regression, s. Abb. @fig-lindeloev.


![Common statistical tests as linear models](img/linear_tests_cheat_sheet.png){#fig-lindeloev}



### In voller Pracht


Hier ist die Regressionsgleichung in voller Pracht; Abb. @fig-regr-rules.


$$y = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_k + \epsilon$$


Anhan der Gleichung erkennt man auch, warum man von einem *linearen Modell* spricht: 
Y wird als gewichteter Mittelwert mehrerer Summanden berechnet.
Dabei wird X nicht mit "fortgeschrittenen" Transformationen wie Quadradieren oder Exponenzieren begl√ºckt, sondern nur mit den Regressiongewichten multipliziert.


```{r}
#| message: false
#| echo: false
#| label: fig-regr-rules
#| fig-cap: Die Regressionsgerade in voller Pracht
data(mtcars)
ggplot(mtcars) +
  aes(x = hp, y = mpg) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal()

```



## Unsicherheit

### Inferenz beinhaltet Unsicherheit

Inferenzstatistische Schl√ºsse sind mit Unsicherheit behaftet: Schlie√ülich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), m√∂chte aber vom Teil auf das Ganze schlie√üen.



:::callout-important
Nichts Genaues wei√ü man nicht: Schlie√üt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen √ºber das Ganze betrifft.
:::


Schlie√üt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit.
Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger.
Schlie√ülich hat man *nicht* die ganze Population gesehen bzw. vermessen. 
*Sicher* ist man sich hingegen f√ºr die Stichprobe (Messfehler einmal ausgeblendet).


Zur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer m√∂glich).

Die Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.

::: callout-note
Unter einem zuf√§lligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres n√§chsten W√ºrfelwurfs. Zuf√§llig bedeutet nicht (zwangsl√§ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines W√ºrfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.
:::

üèã Welche physikalischen Randbedingungen wirken wohl auf einen M√ºnzwurf ein?

### Beispiele zur Quantifizierung von Ungewissheit

Aussagen mit Unsicherheit k√∂nnen unterschiedlich pr√§zise formuliert sein.

-   Morgen regnet's $\Leftrightarrow$ Morgen wird es hier mehr als 0 mm Niederschlag geben ($p=97\%$).

-   Methode $A$ ist besser als Methode $B$ $\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert f√ºr Methode $A$ h√∂her als f√ºr Methode $B$.

-   Die Maschine f√§llt demn√§chst aus $\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den n√§chsten 1-3 Tagen ausfallen, laut unserem Modell.

-   Die Investition lohnt sich $\Leftrightarrow$ Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.

üèã Geben Sie weitere Beispiele an!




### Zwei Arten von Ungewissheit

Im Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. @fig-zwei-arten.


1. Wie (un)gewiss ist man sich √ºber den Wert des Regressionsgewichts?

2. Wie (un)gewiss ist man sich √ºber den Wert von Y? Schlie√ülich k√∂nnte es ja Einfl√ºsse (X) geben, die man nicht ber√ºcksichtigt hat.


```{mermaid}
%%| label: fig-zwei-arten
%%| fig-cap: Zwei Arten der Ungewissheit beim Modellieren
flowchart LR
X1 -->|Wie stark ist der Einfluss?|B
X2 -. Haben wir vielleicht X2 √ºbersehen? .-> B

```




### Ich wei√ü, was ich nicht wei√ü: Ungewissheit angeben


Streng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der Sch√§tzung) wertlos.
Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% sch√§tzt, l√§sst aber offen wie *sicher* (pr√§zise) die Sch√§tzung ist.
Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Sch√§tzung schlie√üt sogar 41% oder 43% aus.

:::callout-important
Eine Inferenz nennt man auch Sch√§tzung. 
Es sollte immer die Genauigkeit (Ungewissheit) der Sch√§tzung angegeben werden.
:::



Im Rahmen der Regressionsanalyse schl√§gt sich die Ungewissheit an zwei Stellen nieder:

1.  zur Lage der Regressionsgeraden ($\beta_0$, $\beta_1$)
2.  zu Einfl√ºssen (X), die unser Modell nicht kennt ($\epsilon, \sigma$)



### Visualisierung von Ungewissheit

Gibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem *Punktsch√§tzer*.
Punktsch√§ter beinhalten *keine Angabe* der Sch√§tz(un)genauigkeit, s. Abb. @fig-punktschaetzer2, links. Rot markiert: Die Punktsch√§tzung von `mpg` f√ºr `hp=200`.





```{r fig-punktschaetzer}
#| echo: false
#| fig-cap: "Eine Punktsch√§tzung und ihre Ungewissheit"
#| label: fig-punktschaetzer2
#| message: false




lm1_glm <- lm(mpg ~ hp, data = mtcars)

mtcars <-
  mtcars %>%
  mutate(pred = 30 - hp*0.07)


pred_interval <-
  tibble(
    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),
    mpg = predict(lm1_glm, newdata = data.frame(hp)),
    lwr = mpg - 2*3,
    upr = mpg + 2*3
  )

plot1 <-
  ggplot(mtcars,
       aes(x = hp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200,
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)


lm1_glm <- lm(mpg ~ hp, data = mtcars)

mtcars <- 
  mtcars %>% 
  mutate(pred = 30 - hp*0.07)


pred_interval <-
  tibble(
    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),
    mpg = predict(lm1_glm, newdata = data.frame(hp)),
    lwr = mpg - 2*3,
    upr = mpg + 2*3
  )


plot2 <-
  ggplot(mtcars,
       aes(x = hp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  annotate("point", x = 200,
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)


plots(plot1, plot2, n_rows = 1,
      title = c("Eine Punktsch√§tzung mittels einer Regressionsanalyse \nohne (links) bzw. mit Ungewissheitsintervall (rechts, in grau)"))

```









In Abb. @fig-punktschaetzer, rechts, ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur St√§rke des Zusammenhangs von X und Y?



Auch wenn wir uns *sicher* im Hinblick auf die Regressionsgewichte in Abb. @fig-ungewiss2 *bliebe eine Restungewissheit*:
Unsere Sch√§tzungen w√§ren auch dann nicht sicher, nicht fehlerfrei.
Das liegt daran, da das Modell nicht alle Einfl√ºsse auf Y ber√ºcksichtigt, sondern nur einen, hier als X bezeichnet.

In Abb. @fig-ungewiss2 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die "Restungewissheit" dargestellt. In diesem Fall spricht man von einem "Vorhersageintervall", da man nicht nur von "typischen F√§llen" auf der Regressiongeraden spricht, sondern f√ºr echte F√§lle Vorhersagen (Sch√§tzungen) t√§tigt, wo auch die zweite Art von Ungewissheit relevant ist.


```{r p-zweifach}
#| echo: false
#| fig-cap: "Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall"
#| label: fig-ungewiss2
#| message: false

pred_interval2 <-
  predict(lm1_glm,
          newdata = data.frame(hp = pred_interval$hp),
          interval = "prediction") %>%
  as_tibble() %>%
  rename(mpg = fit) %>% 
  mutate(hp = pred_interval$hp)


ggplot(mtcars) +
  aes(x = hp, y = mpg) +
  geom_point()+
  geom_ribbon(data = pred_interval2,
              aes(ymin = lwr, ymax = upr,
                  y = mpg,
                  x = hp),
              fill = "blue",
              alpha = .1) +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("point", x = 200,
           y = predict(lm1_glm, newdata = data.frame(hp = 200)),
           color = "red",
           alpha = .5,
           size = 5)
```




Wie man sieht, wird die Ungewissheit *gr√∂√üer*, wenn man beide Arten der Ungewissheit ber√ºcksichtigt. Das Vorhersage-Intervall ber√ºcksichtigt Ungewissheit in $\beta_0, \beta_1, \epsilon$ bei der Vorhersage von $\hat{y_i}$.


üèã Geben Sie ein vergleichbares Beispiel an!

### Konfidenzintervall


Wir sehen hier, dass ein "Ungewissheitskorridor" angegeben wird. 
Entsprechend wird nicht ein *Punktsch√§tzer*, sondern ein *Sch√§tzbereich* angegeben.
Man spricht auch von einem *Konfidenzintervall* oder *Unsicherheitsbereich*^[Tats√§chlich gibt es mehrere Synonyme oder √§hnliche Begriffe f√ºr Konfidenzintervall. Wir kommen sp√§ter darauf detaillierter zu sprechen.]

Ein Konfidenzintervall wird h√§ufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse ist das einfach zu interpretieren. 
Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall f√ºr den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.
Dieser Befund l√§√üt sich so interpretieren: "Laut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten."


::: callout-important
Ein Konfidenzintervall gibt einen Sch√§tzbereich plausibler Werte f√ºr den gesuchten Wert in der Population (den Parameter) an.
:::




üèã Interpretieren Sie den Ungewissheitskorridor!

## Klassische vs. Bayes-Inferenz

### Klassische Inferenz: Frequentismus

-   Die Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zur√ºckgewiesen.
-   Nur die Daten selber fliesen in die Ergebnisse ein
-   Wahrscheinlichkeit wird √ºber relative H√§ufigkeiten definiert.
-   Es ist nicht m√∂glich, die Wahrscheinlichkeit einer Hypothese anzugeben.
-   Stattdessen wird angegeben, wie h√§ufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr h√§ufig wiederholt ist.
-   Ein Gro√üteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.

### Bayesianische Inferenz

-   Vorwissen (Priori-Wissen) flie√üt explizit in die Analyse ein (zusammen mit den Daten).
-   *Wenn* das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.
-   Die Wahl des Vorwissens muss explizit (kritisierbar) sein.
-   In der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen f√ºr Hypothesen m√∂glich.
-   Die Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (f√ºr g√§ngige Computer) komfortabel geworden.

### Vergleich von Wahrscheinlichkeitsaussagen

#### Frequentismus

Die zentrale Statistik hei√üt der *p-Wert*

Der p-Wert ist so definiert: "Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zuf√§llig verschieden und auf Basis unseres Modells)?"

Findet man $p<.05$ (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von "(statistischer) Signifikanz" und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.

#### Bayes-Statistik

Die zentrale Statistik ist die *Posteriori-Verteilung*.

Die Posteriori-Verteilung beantwortet uns die Frage: "Wie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?"

üèã Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.


[In diesem Post](https://data-se.netlify.app/2022/01/27/warum-bayes/) wird f√ºr Bayes geworben und (vielleicht einseitig) Stellung pro Bayes bezogen.



### Frequentist und Bayesianer


Im Cartoon 1132 [von xkcd](https://xkcd.com/) wird sich √ºber das Nicht-Ber√ºcksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. @fig-xkcd-bayes.

![Frequentist wettet mit Bayesianer](img/frequentists_vs_bayesians_2x.png){#fig-xkcd-bayes width=50%}

[Quelle](https://xkcd.com/1132/)

### Der p-Wert ist wenig intuitiv

<a href="https://imgflip.com/i/6m29tz"><img src="https://i.imgflip.com/6m29tz.jpg" title="made at imgflip.com" width="250"/></a>

<div>

<a href="https://imgflip.com/memegenerator">from Imgflip Meme Generator</a>

</div>

### Beispiel zum Nutzen von Apriori-Wissen 1

Ein Betrunkener behauptet, er k√∂nne hellsehen.
Er wirft eine M√ºnze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.

 Die Wahrscheinlichkeit dieses Ergebnisses ist sehr gering ($2^{-10}$) unter der Hypothese, dass die M√ºnze fair ist, dass Ergebnis also "zuf√§llig" ist.

Unser Vorwissen l√§sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zuf√§lligkeit des Ergebnisses wohl nicht verwerfen.

### Beispiel zum Nutzen von Apriori-Wissen 2

Eine Studie (vgl. @gelman_regression_2021) fand einen "gro√üen Effekt" auf das Einkommen von Babies, eine Stunde pro Woche w√§hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), $n=127$.

Nach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% h√∂her (als in der Kontrollgruppe) mit einem Konfidenzintervall von \[+2%,+98%\].

Allerdings l√§sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln l√§sst. Wir w√ºrden den Effekt lieber in einem konservativeren Intervall sch√§tzen (enger um Null).



## Literatur

Bei @gelman_regression_2021, Kap. 1 findet sich eine Darstellung √§hnlich zu der in diesem Kapitel.


## Aufgaben


1. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz/)
2. [korr-als-regr](https://datenwerk.netlify.app/posts/korr-als-regr/korr-als-regr/)
3. [ttest-als-regr](https://datenwerk.netlify.app/posts/ttest-als-regr/ttest-als-regr/)
4. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau/)
5. [adjustieren2](https://datenwerk.netlify.app/posts/adjustieren2/adjustieren2/)
6. [inferenz-fuer-alle](https://datenwerk.netlify.app/posts/inferenz-fuer-alle/inferenz-fuer-alle)
7. [adjustieren1](https://datenwerk.netlify.app/posts/adjustieren1/adjustieren1.html)
8. [ungewiss-arten-regr](https://datenwerk.netlify.app/posts/ungewiss-arten-regr/ungewiss-arten-regr.html)
9. [vorhersageintervall1](https://datenwerk.netlify.app/posts/vorhersageintervall1/vorhersageintervall1.html)
10. [lm-standardfehler](https://datenwerk.netlify.app/posts/lm-standardfehler/lm-standardfehler)
11. [punktschaetzer-reicht-nicht](https://datenwerk.netlify.app/posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html)





## ---



![](img/outro-02.jpg){width=100%}





