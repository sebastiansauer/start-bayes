[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "Bayes:Start!\n\n\n\nğŸš§WORK IN PROGRESSğŸš§\n\n\n\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n\n\n\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\n\n\n\n\nInstallieren Sie R und seine Freunde.\nInstallieren Sie die folgende R-Pakete:\n\ntidyverse\nrstanarm\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\n\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.\n\n\n\n\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen wÃ¤hrend des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von ArbeitsbeitrÃ¤gen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      Nr\n      Thema\n      Datum\n      Kommentar\n    \n  \n  \n    1\nWas ist Inferenz?\n3. - 7. Okt. 2022\nDie erste Unterrichtsstunde fÃ¤llt auf den 7. Okt. 2023.\n    2\nWahrscheinlichkeit\n10. - 14. Okt. 22\nNA\n    3\nHallo, Bayes\n17. - 21. Okt. 22\nNA\n    4\nDie Post befragen\n24. - 28. Okt. 22\nNA\n    5\nGauss-Modelle\n31. Okt. - 4. Nov. 22\nNA\n    6\nLineare Modelle\n7. - 11. Nov. 22\nNA\n    NA\nBLOCKWOCKE\n14. - 18. Nov. 22\nKein regulÃ¤rer Unterricht\n    7\nMetrische AV\n21. - 25. Nov. 22\nNA\n    8\nFallstudien\n28. Nov. - 2. Dez. 22\nNA\n    9\nKausalinferenz 1\n5. Dez. - 9. Dez. 22\nNA\n    10\nKausalinferenz 2\n12. - 16. Dez. 22\nNA\n    11\nBinÃ¤re AV\n19. - 23. Dez. 22\nNA\n    NA\nWEIHNACHTSFERIEN\nNA\nKein Unterricht\n    12\nAbschluss\n9. Jan. 23 - 13. Jan. 23\nNA\n  \n  \n  \n\n\n\n\n\n\n\nPro Thema wird Literatur ausgewiesen.\n\n\n\nDieses Dokument wurde erzeut am/um 2022-09-08 00:00:41.\n\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2022-09-08\n pandoc   2.19.2 @ /usr/local/bin/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.2.0)\n cli           3.3.0      2022-04-25 [1] CRAN (R 4.2.0)\n colorout    * 1.2-2      2022-06-13 [1] local\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.0)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.16       2022-08-09 [1] CRAN (R 4.2.0)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n ggplot2       3.3.6.9000 2022-09-05 [1] Github (tidyverse/ggplot2@a58b48c)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt            0.7.0      2022-08-25 [1] CRAN (R 4.2.0)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.0      2022-02-22 [1] CRAN (R 4.2.0)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.0)\n lifecycle     1.0.2      2022-09-05 [1] Github (r-lib/lifecycle@f92faf7)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n purrr         0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n readxl        1.4.1      2022-08-17 [1] CRAN (R 4.2.0)\n rlang         1.0.5      2022-08-31 [1] CRAN (R 4.2.0)\n rmarkdown     2.16       2022-08-24 [1] CRAN (R 4.2.0)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.0)\n sass          0.4.2      2022-07-16 [1] CRAN (R 4.2.0)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyselect    1.1.2      2022-02-21 [1] CRAN (R 4.2.0)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n vctrs         0.4.1      2022-04-13 [1] CRAN (R 4.2.0)\n xfun          0.32       2022-08-10 [1] CRAN (R 4.2.0)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.0)\n\n [1] /Users/sebastiansaueruser/Rlibs\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "Pruefung.html",
    "href": "Pruefung.html",
    "title": "1Â  PrÃ¼fung",
    "section": "",
    "text": "Die PrÃ¼fungsleistung besteht aus einer Open-Book-PrÃ¼fung."
  },
  {
    "objectID": "Pruefung.html#grundsÃ¤tzlichkeit",
    "href": "Pruefung.html#grundsÃ¤tzlichkeit",
    "title": "1Â  PrÃ¼fung",
    "section": "1.2 GrundsÃ¤tzlichkeit",
    "text": "1.2 GrundsÃ¤tzlichkeit\nDie folgenden Hinweise gelten grundsÃ¤tzlich, d.h. soweit nicht anders in der jeweiligen PrÃ¼fung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von PrÃ¼fungshinweisen kann zu Punkteabzug oder Nichtbestehen fÃ¼hren."
  },
  {
    "objectID": "Pruefung.html#wiederholungsprÃ¼fungen",
    "href": "Pruefung.html#wiederholungsprÃ¼fungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.3 WiederholungsprÃ¼fungen",
    "text": "1.3 WiederholungsprÃ¼fungen\n\nWenn Sie bei einer PrÃ¼fung durchgefallen sein sollten, so haben Sie grundsÃ¤tzlich die MÃ¶glichkeit, die PrÃ¼fung zu wiederholen.\nDenken Sie daran, sich rechtzeitig fÃ¼r PrÃ¼fungsleistungen anzumelden; beachten Sie die Fristen.\nDie Termine fÃ¼r die WiederholungsprÃ¼fungen werden stets zusammen/zeitgleich mit denen der regulÃ¤ren PrÃ¼fungen in Primuss bekannt gegeben.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine WiederholungsprÃ¼fung nur fÃ¼r Studentis, die durchgefallen sind. Abweichend davon kann ei Dozenti die PrÃ¼fung fÃ¼r alle Studentis anbieten. Die Entscheidung, ob eine WiederholungsprÃ¼fung in diesem Fall angeboten wird, obliegt der Dozentin bzw. dem Dozenten des Moduls.\nRelevanter Stoff und formale Bedingungen (wie PrÃ¼fungsform) sind grundsÃ¤tzlich identisch zur letzten abgehaltenen PrÃ¼fung des Moduls (d.h. sofern nicht anders angegeben). Daher sind WiederholungsprÃ¼fungen vom Anspruch vergleichbar wie die regulÃ¤re Klausur. Die PrÃ¼fungen sollen mÃ¶glichst gleich vom Anspruch sein, um Fairness zu gewÃ¤hrleisten.\nBeachten Sie immer die Hinweise, die fÃ¼r die WiederholungsprÃ¼fung angegeben sind. Im Einzelfall keine eine WiederholungsprÃ¼fung von der vorherigen PrÃ¼fung stÃ¤rker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen WiederholungsprÃ¼fung verÃ¶ffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine WiederholungsprÃ¼fung. Stattdessen kÃ¶nnen Sie ggf. an der regulÃ¤ren Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist mÃ¶glich, dass der Stoff sich dann substanziell Ã¤ndert; meist halten sich die Ã„nderungen (im Stoff) aber in Rahmen.\nSprechen Sie die Moduldozentis an fÃ¼r Details zur PrÃ¼fung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine PrÃ¼fung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben, es kommt auf den Einzelfall an. GrundsÃ¤tzlich rate ich aber dazu, PrÃ¼fungen nicht zu verschieben: SchlieÃŸlich kÃ¶nnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum PrÃ¼fungsrecht sprechen Sie bitte die Studienberatung an."
  },
  {
    "objectID": "Pruefung.html#bearbeitungshinweise",
    "href": "Pruefung.html#bearbeitungshinweise",
    "title": "1Â  PrÃ¼fung",
    "section": "1.4 Bearbeitungshinweise",
    "text": "1.4 Bearbeitungshinweise\n\nVerwenden Sie Standardwerte (defaults) der R-Funktionen.\nRunden Sie ggf. auf eine Dezimalstelle.\nVerwenden Sie Methoden der Bayes-Statistik fÃ¼r inferenzstatistische Analysen.\nGeben Sie keine Prozentzahlen an, sondern Anteile (also nicht â€œ50%â€, sondern â€œ0.5â€ bzw. â€œ0,5â€).\nFindet sich in einer Auswahlliste mÃ¶glicher Antworten nicht die exakte LÃ¶sung, wÃ¤hlen Sie die am besten passende.\nTreffen Sie Annahmen, wo nÃ¶tig.\nDie PrÃ¼fung besteht zu einem groÃŸen Teil aus Multiple-Choice- (MC-)-Aufgaben mit mehreren Antwortoptionen.\nBei Multiple-Choice-Aufgaben (MC-Aufgaben) ist zumeist genau eine Antwortoption auszuwÃ¤hlen aus vier oder fÃ¼nf Antwortoptionen.\nIm Zweifel ist eine Aussage auf den Stoff, so wie im Unterricht behandelt, zu beziehen.\nBei Fragen zu R-Syntax spielen Aspekte wie Enter-Taste o.Ã„. bei der Beantwortung der Frage keine Rolle; diese Aspekte dÃ¼rfen zu ignorieren.\nJede Aussage einer MC-Aufgabe ist entweder richtig oder falsch (aber nicht beides oder keines).\nDie MC-Aufgaben sind nur mit Kreuzen zu beantworten; Text wird bei der Korrektur nicht berÃ¼cksichtigt.\nJede Aussage gilt ceteris paribus (unter sonst gleichen UmstÃ¤nden). Aussagen der Art â€A ist Bâ€œ (z.B. â€œMenschen sind sterblichâ€) sind nur dann als richtig auszuwÃ¤hlen, wenn die Aussage immer richtig ist.\nBei Aufgaben, die eine Zahl als Antwort verlangen, ist nur eine Zahl anzugeben (nicht etwa Buchstaben).\nFalls Sie bei einer Aufgabe mehrere Antworten finden, aber nur nach einer gefragt ist, geben Sie nur eine an.\nFalls mehrere (widersprÃ¼chliche) Antworten gegeben wurden, wird im Zweifel die erst genannte gewertet.\nDie Aufgabenstellung in einer Moodle-PrÃ¼fung wird erst sichtbar, wenn Sie den PrÃ¼fungsbedingungen zugestimmt haben und die PrÃ¼fungszeit begonnen hat.\nJe nach Spracheinstellung in Moodle kann es sein, dass Sie als Dezimaltrennzeichen ein Komma oder einen Punkt verwenden mÃ¼ssen. Moodle weist Sie, wenn Sie die Aufgabe verlassen, darauf hin, falls eine Zahl nicht als Zahl erkannt wurde."
  },
  {
    "objectID": "Pruefung.html#teilnahmebedingungen",
    "href": "Pruefung.html#teilnahmebedingungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.5 Teilnahmebedingungen",
    "text": "1.5 Teilnahmebedingungen\n\nDie PrÃ¼fung ist selbstÃ¤ndig, also alleine nur durch Sie, ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der PrÃ¼fung sind einzuhalten.\nEs dÃ¼rfen nur die explizit als zulÃ¤ssig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulÃ¤ssigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, BÃ¼cher sowie Quellen aus dem Internet.\nDie Ãœbernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wÃ¶rtliche Ãœbernahme (â€œcopy-pasteâ€) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulÃ¤ssig.\nBei technischen Problemen ist sofort der PrÃ¼fer bzw. die PrÃ¼ferin zu verstÃ¤ndigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die PrÃ¼fung bzw. Teile daraus (z.B. PrÃ¼fungsfragen) zu speichern oder weiterzugeben.\nIm Ãœbrigen gelten die allgemeinen PrÃ¼fungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht PrÃ¼flingen, kommuniziert werden wÃ¤hrend der PrÃ¼fung. Dies gilt auch fÃ¼r den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den PrÃ¼fer, wenn Sie meinen, es liege ein technisches Problem vor.\nDas Nichtbeachten der Regeln kann zu Notenabzug oder Nichtbestehen fÃ¼hren."
  },
  {
    "objectID": "Pruefung.html#organisatorische-hinweise",
    "href": "Pruefung.html#organisatorische-hinweise",
    "title": "1Â  PrÃ¼fung",
    "section": "1.6 Organisatorische Hinweise",
    "text": "1.6 Organisatorische Hinweise\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prÃ¼fungsrelevant.\nIm Ãœbrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung fÃ¼r formale oder rechtliche Fragen.\nWÃ¤hrend der PrÃ¼fung werden nur Fragen beantwortet, die fÃ¼r die Bearbeitung zwingend nÃ¶tig sind (etwa bei technischen Problemen).\nEs werden keine Fragen der Art â€œIst diese Aufgabe klar formuliert?â€ beantwortet wÃ¤hrend der PrÃ¼fung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der PrÃ¼fung=. Der PrÃ¼fer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der PrÃ¼fung ist nur mÃ¶glich, wenn Sie den Teilnahmebedingungen der PrÃ¼fung zustimmen.\nDie Aufgabenstellung der PrÃ¼fung wird nur wÃ¤hrend des PrÃ¼fungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppenteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte PrÃ¼fungsuhrzeit (Beginn, Ende).\nPrÃ¼fungszeitraum, Aufgabenstellung und sonstige Materialien kÃ¶nnen variieren zwischen den PrÃ¼flingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusÃ¤tzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der PrÃ¼fung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor erhÃ¶ht."
  },
  {
    "objectID": "Pruefung.html#open-book-prÃ¼fungen",
    "href": "Pruefung.html#open-book-prÃ¼fungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.7 Open-Book-PrÃ¼fungen",
    "text": "1.7 Open-Book-PrÃ¼fungen\nEinige PrÃ¼fungen werden als â€œTake-home-PrÃ¼fungâ€ im â€œOpen-Book-Formatâ€ geschrieben. Was bedeutet dies?\nâ€œTake-home-PrÃ¼fungâ€: Sie bearbeiten die PrÃ¼fung in Ihrem privaten Umgebung in Moodle oder in RÃ¤umlichkeiten der Hochschule. Eine Ãœberwachung per Kamera findet nicht statt.\nâ€œOpen-Book-PrÃ¼fungâ€: Sie dÃ¼rfen Hilfsmittel wie BÃ¼cher und Folien wÃ¤hrend der PrÃ¼fung nutzen.\nIhre PrÃ¼ferin/Ihr PrÃ¼fer informiert Sie Ã¼ber das Format Ihrer PrÃ¼fung."
  },
  {
    "objectID": "Pruefung.html#zeitrahmen-der-prÃ¼fung",
    "href": "Pruefung.html#zeitrahmen-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.8 Zeitrahmen der PrÃ¼fung",
    "text": "1.8 Zeitrahmen der PrÃ¼fung\nDie PrÃ¼fung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die PrÃ¼fung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). VerspÃ¤tete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der PrÃ¼fung wird Ihnen von Ihrer PrÃ¼ferin bzw. Ihrem PrÃ¼fer bekannt gegeben."
  },
  {
    "objectID": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prÃ¼fung",
    "href": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.9 Technische und organisatorische Anforderungen einer Open-Book-PrÃ¼fung",
    "text": "1.9 Technische und organisatorische Anforderungen einer Open-Book-PrÃ¼fung\nUm an einer Open-Book-PrÃ¼fung teilzunehmen, benÃ¶tigen Sie IT-Ausstattung sowie RÃ¤umlichkeiten. An IT-Ausstattung benÃ¶tigen Sie einen Computer mit Internetanschluss; ein Smartphone reicht nicht aus. Nutzen Sie Ihr eigenes GerÃ¤t (Computer) fÃ¼r die PrÃ¼fung; die Hochschule stellt Ihnen keinen Computer zur VerfÃ¼gung. Sie benÃ¶tigen keine Webcam und kein Mikrofon. Ein Tablett oder Smartphone reicht nicht fÃ¼r die PrÃ¼fung. An Software benÃ¶tigen Sie Zugang zu Ihrem Moodle-Konto, was einen aktuellen Internet-Browser voraussetzt. Zu den organisatorischen Anforderungen gehÃ¶ren ein Raum, in dem Sie die PrÃ¼fung ungestÃ¶rt bearbeiten kÃ¶nnen sowie ein Internetanschluss zum Bearbeiten der Klausur in Moodle. Bitte benutzen Sie wÃ¤hrend der PrÃ¼fung nicht den ZurÃ¼ck-Button in Ihrem Browser, wenn Sie zu einer vorherigen Frage zurÃ¼ckgehen wollen. Nutzen Sie die in der PrÃ¼fung zur VerfÃ¼gung gestellten Funktionen/Buttons dafÃ¼r."
  },
  {
    "objectID": "Pruefung.html#technische-probleme-wÃ¤hrend-der-prÃ¼fung",
    "href": "Pruefung.html#technische-probleme-wÃ¤hrend-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.10 Technische Probleme wÃ¤hrend der PrÃ¼fung",
    "text": "1.10 Technische Probleme wÃ¤hrend der PrÃ¼fung\nIm Falle eines technischen Problems auf Seiten der PrÃ¼fungsinfrastruktur ist sofort der PrÃ¼fer zu informieren. Ein Beispiel fÃ¼r so ein Problem wÃ¤re etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der PrÃ¼fer bzw. die Hochschule keine GewÃ¤hr Ã¼bernimmt fÃ¼r Probleme mit Ihrer eigenen Ausstattung."
  },
  {
    "objectID": "Pruefung.html#prÃ¼fungsrecht",
    "href": "Pruefung.html#prÃ¼fungsrecht",
    "title": "1Â  PrÃ¼fung",
    "section": "1.11 PrÃ¼fungsrecht",
    "text": "1.11 PrÃ¼fungsrecht\nFÃ¼r die Open-Book-PrÃ¼fungg gilt die aktuelle PrÃ¼fungsordnung; die Open-Book-PrÃ¼fung fÃ¤llt nicht unter die BayFEV."
  },
  {
    "objectID": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "href": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "title": "1Â  PrÃ¼fung",
    "section": "1.12 Bitte formulieren Sie Beanstandungen nachvollziehbar",
    "text": "1.12 Bitte formulieren Sie Beanstandungen nachvollziehbar\nFalls Sie einen Fehler in einer Aufgabenstellung finden (die der PrÃ¼fer zu bestanden hat): Freuen Sie sich! In diesem Fall wird zu Ihren Gunsten entschieden.\nDamit ich Ihre Beanstandung prÃ¼fen kann, ist es nÃ¶tig, dass ich Ihre Beanstandung nachprÃ¼fen kann: Zeigen Sie mir meinen Fehler. Es reicht nicht zu sagen â€œes hat bei mir nicht funktioniertâ€. Wenn Sie etwa der Meinung sind, dass es die Variable â€œyearâ€ im Datensatz â€œpenguinsâ€ nicht gebe, dann schicken Sie mir den R-Code, der an ansprechender Stelle einen Fehler aufwirft (aber ansonsten lauffÃ¤hig ist). Ein Screenshot kann in einigen Situationen helfen, wenn aber nur ein Teil der Syntax zu sehen ist, ist er nicht ausreichend: Wenn der Befehl data(penguins) nicht funktioniert, so ist zu prÃ¼fen, ob Sie vorab mit library(palmerpenguins) das relevante Paket gestartet haben. Andernfalls kann data(penguins) nicht funktionieren und der Fehler lÃ¤ge damit bei Ihnen.\nHier finden Sie Hinweise fÃ¼r einfache, reproduzierbare Beispiele (ERBies); vgl. Sauer (2019), Kap. 3.8.2 (S. 33).\nDie gleiche Messlatte lege ich an mich an: Ich stelle eine MusterlÃ¶sung (bei der Einsichtnahme) zur VerfÃ¼gung, die reproduzierbar die LÃ¶sung aufzeigt. Sprich: Wenn der R-Code bei mir durchlÃ¤uft, so wird er auch bei Ihnen durchlaufen."
  },
  {
    "objectID": "Pruefung.html#datenschutz",
    "href": "Pruefung.html#datenschutz",
    "title": "1Â  PrÃ¼fung",
    "section": "1.13 Datenschutz",
    "text": "1.13 Datenschutz\nPersÃ¶nliche Daten werden an eine Stellen Ã¼bermittelt: Moodle (Ã¼ber bzw. in Ihre Konto). Es findet keine Ãœberwachung statt, weder kamaragestÃ¼tzt, akustisch oder softwaregestÃ¼tzt."
  },
  {
    "objectID": "Pruefung.html#plagiatskontrolle",
    "href": "Pruefung.html#plagiatskontrolle",
    "title": "1Â  PrÃ¼fung",
    "section": "1.14 Plagiatskontrolle",
    "text": "1.14 Plagiatskontrolle\nIhre PrÃ¼fungsarbeiten kÃ¶nnen auf Plagiate hin untersucht werden. Dabei kommen auch automatisierte Verfahren zum Einsatz. Ihre Arbeiten werden dabei nicht online gestellt und auch nicht Dritten zugÃ¤nglich gemacht. Alle PrÃ¼fungen finden auf Rechnern statt, zu denen nur die PrÃ¼fer/innen Zugang habe. Es werden keine persÃ¶nlichen Daten (von Ihnen) weitergegeben.\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Ãœberlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getÃ¤uscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafÃ¼r bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit â€œnicht bestandenâ€ bewertet). Die genauen Konsequenzen legt die PrÃ¼fungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire PrÃ¼fung heiÃŸt: Gleiche Chancen fÃ¼r alle, und gute Leistung soll belohnt werden, TÃ¤uschung nicht."
  },
  {
    "objectID": "Pruefung.html#typische-fehler-in-der-prÃ¼fung",
    "href": "Pruefung.html#typische-fehler-in-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.15 Typische Fehler in der PrÃ¼fung",
    "text": "1.15 Typische Fehler in der PrÃ¼fung\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heiÃŸt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heiÃŸt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter â€œEnvironmentâ€ angezeigt wird. AuÃŸerdem kÃ¶nnen Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort kÃ¶nnen Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das Paket gestartet zu haben: Mit data(datensatz) kÃ¶nnen Sie den Datensatz datensatz nur dann verfÃ¼gbar machen, wenn das Paket, in dem datensatz â€œwohntâ€, mit library(paketname) gestartet worden ist. So â€œwohntâ€ z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Ãœbung (und weitere ErklÃ¤rung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins."
  },
  {
    "objectID": "Pruefung.html#hinweise-zu-scheinmÃ¤ngeln",
    "href": "Pruefung.html#hinweise-zu-scheinmÃ¤ngeln",
    "title": "1Â  PrÃ¼fung",
    "section": "1.16 Hinweise zu ScheinmÃ¤ngeln",
    "text": "1.16 Hinweise zu ScheinmÃ¤ngeln\nImmer wieder kommt es vor, dass Studierende Beanstandungen zu einer PrÃ¼fung vorbringen. Teilweise sind diese gerechtfertigt, teilweise nicht. Im Folgenden sehen Sie eine Auswahl an nicht gerechtfertigten Beanstandungen, also nur scheinbaren MÃ¤ngeln, keine wirklichen MÃ¤ngel, in einer PrÃ¼fung.\n\nâ€œDas zu wÃ¤hlende Vorgehen war nicht 100% klarâ€ â€“ Wenn Sie der Meinung sind, dass das zu wÃ¤hlende Vorgehen (zum LÃ¶sen der Aufgabe) nicht komplett klar ist, treffen Sie Annahmen und weisen Sie darauf hin, dass Sie Annahmen getroffen haben. Zum anderen halten Sie sich an das Vorgehen aus dem Unterricht (bzw. den Unterlagen und der Literatur, die im Unterricht verwendet wurde). Eine andere Situation lÃ¤ge vor, wenn die Aufgabe nicht lÃ¶sbar ist ohne weitere Angaben lÃ¶sbar ist(â€œIst ein Effekt bei n=100 signifikant?â€). Im Falle einer nicht lÃ¶sbaren Aufgabe liegt fer Fehler beim PrÃ¼fer.\nâ€œIch sollte einen Punkt (ein Komma) als Dezimaltrennzeichen verwenden, aber Moodle hat ein Komma (einen Punkt) verlangt!â€ â€“ Je nach Spracheinstellung in Moodle kann es sein, dass Moodle nur einen Punkt als Dezimaltrennzeichen bzw. ein Komma als Dezimaltrennzeichen verwendet. Moodle weist Sie aber darauf hin, wenn eine Zahl nicht als Zahl erkannt wird, und zwar wenn Sie zur nÃ¤chsten Aufgabe geben. Sie kÃ¶nnen also ohne Probleme den Fehler korrigieren. DarÃ¼ber hinaus ist bei den PrÃ¼fungshinweisen vorab auf diesen Punkt verwiesen."
  },
  {
    "objectID": "Inferenz.html",
    "href": "Inferenz.html",
    "title": "2Â  Inferenz",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Inferenz.html#lernsteuerung",
    "href": "Inferenz.html#lernsteuerung",
    "title": "2Â  Inferenz",
    "section": "2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Definition von Inferenzstatistik sowie Beispiele fÃ¼r inferenzstatistische Fragestellungen nennen\nzentrale Begriffe nennen und in GrundzÃ¼gen erklÃ¤ren\nden Nutzen von Inferenzstatistik nennen\nerlÃ¤utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nauch anhand von Beispielen erklÃ¤ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs.Â Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklÃ¤ren kÃ¶nnen"
  },
  {
    "objectID": "Inferenz.html#wozu-ist-statistik-Ã¼berhaupt-da",
    "href": "Inferenz.html#wozu-ist-statistik-Ã¼berhaupt-da",
    "title": "2Â  Inferenz",
    "section": "2.2 Wozu ist Statistik Ã¼berhaupt da?",
    "text": "2.2 Wozu ist Statistik Ã¼berhaupt da?\nJa, diese Frage haben Sie sich auch schon mal gestellt?\nAbb. FigureÂ 2.1 gibt einen Ãœberblick Ã¼ber die Ziele der Statistik.\n\n\n\n\n\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n\n\n\n\n\nFigureÂ 2.1: A taxonomy of statistical goals\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nZiele exsitieren nicht â€œin echtâ€ in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heiÃŸt, dass man sich nach Beliebem Ziele ausdenken kann. Allerdings hÃ¼lfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen Ã¼berzeugen kann."
  },
  {
    "objectID": "Inferenz.html#was-ist-inferenz",
    "href": "Inferenz.html#was-ist-inferenz",
    "title": "2Â  Inferenz",
    "section": "2.3 Was ist Inferenz?",
    "text": "2.3 Was ist Inferenz?\n\n2.3.1 Inferenz als Generalisieren\nStatistische Inferenz sieht sich drei â€œHerausforderungenâ€ gegenÃ¼ber, laut Gelman, Hill, and Vehtari (2021), Kap. 1.1. Diese betreffen das SchlieÃŸen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\nVon der Stichprobe aus die Grundgesamtheit (Population)\nVon der Experimental- auf die Kontrollgruppe (Kausalinferenz)\nVon einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs beschÃ¤ftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n\n\n\nImportant\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlieÃŸen, bzw. vom Konrketen auf das Abstrakte."
  },
  {
    "objectID": "Inferenz.html#stichprobe-vs.-population",
    "href": "Inferenz.html#stichprobe-vs.-population",
    "title": "2Â  Inferenz",
    "section": "2.4 Stichprobe vs.Â Population",
    "text": "2.4 Stichprobe vs.Â Population\nNehmen wir an, wir mÃ¶chten Herausfinden, wie groÃŸ der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A1\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\nWir mÃ¼ssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe fÃ¼r die Grundgesamtheit schlieÃŸen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. FigureÂ 2.2.\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nFigureÂ 2.2: Population vs.Â sample (Image credit: Karsten Luebke)\n\n\nHÃ¤ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!2. Man schreibt: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei reprÃ¤sentativ fÃ¼r die Grundgesamtheit aller Studierender. Messerscharf schlieÃŸen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n2.4.1 Deskriptiv- vs.Â Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtigungen kÃ¶nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. FigureÂ 2.3. Einteilungen in Schubladen existieren nicht auf der Welt, sondern in unserem Kopf: Sie besitzen keine ontologische RealitÃ¤t, sondern eine epistemologische. Sie sind frei, sich andere Einteilungen der Statistik auszudenken. Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee Ã¼berzeugen kann.\n\n\n\nFigureÂ 2.3: Deskriptiv- vs.Â Inferenzstatistik\n\n\nDeskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\nInferenzstatistik schlieÃŸt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\nğŸ‹ SchlieÃŸen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n2.4.2 Wozu ist die Inferenstatistik gut?\n\n\n\n\n\n\nNote\n\n\n\nInferenz bedeutet SchlieÃŸen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine SchlÃ¼sse zu ziehen.\nğŸ‹ï¸ï¸ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Ãœben Sie jetzt schon mal.\n\n\n2.4.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFÃ¼r jede Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle TableÂ 2.1.\n\n\n\n\nTableÂ 2.1: Bezeichnungen fÃ¼r Kennwerte\n\n\nKennwert\nStichprobe\nGrundgesamtheit\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\n\n\n\n\n\nFÃ¼r Statistiken (Stichprobe) verwendet man lateinische Buchstaben; fÃ¼r Parameter (Population) verwendet man griechische Buchstaben.\nğŸ‹ï¸ Geben Sie die griechischen Buchstaben fÃ¼r typische Statistiken an!\n\n\n2.4.4 SchÃ¤tzen von Parametern einer Grundgesamtheit\nMeist begnÃ¼gt man sich beim Analysieren von Daten nicht mit Aussagen fÃ¼r eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit SchÃ¤tzungen begnÃ¼gen.\nSchÃ¤tzwerte werden mit einem â€œDachâ€ Ã¼ber dem Kennwert gekennzeichnet, z.B.\n\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchÃ¤tzwert\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n2.4.5 Beispiele fÃ¼r inferenzstatistische Fragestellungen\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.Â V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\).\nDie Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} > \\bar{X}_{V2}\\)\nSind diese Unterschiede â€œzufÃ¤lligâ€ oder â€œsubstanziellâ€? Gilt also \\(\\mu_{V1} > \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)?\nWie groÃŸ ist die Wahrscheinlichkeit3 \\(Pr(\\mu_{V1} > \\mu_{V2})\\)?\n\nğŸ‹ï¸ Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!"
  },
  {
    "objectID": "Inferenz.html#modellieren",
    "href": "Inferenz.html#modellieren",
    "title": "2Â  Inferenz",
    "section": "2.5 Modellieren",
    "text": "2.5 Modellieren\n\n2.5.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft, wie auch oft in der Technik, Wirtschaft oder im Alltag, betrachtet man einen Teil der Welt nÃ¤her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berÃ¼cksichtigen ist nicht mÃ¶glich. Wir mÃ¼ssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nÃ¶tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die fÃ¼r unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\n\n\n\n\n\nImportant\n\n\n\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n\n\nAuf die Statistik bezogen heiÃŸt das, dass man einen Datensatz zu zusammenfasst, dass man das Wesentliche erkennt. Was ist das â€œWesentlicheâ€? Meist interessiert man sich fÃ¼r die Ursachen eines PhÃ¤nomens? Etwa: â€œWie kommt es bloÃŸ, dass ich ohne zu lernen die Klausur so gut bestanden habe?â€4 Noch allgemeiner ist vom hÃ¤ufig am Zusammenhang von X und Y interessiert, s. Abb. FigureÂ 2.4, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\nFigureÂ 2.4: Sinnbild eines stastistischen Modells\n\n\n\n\nDas Diagramm hat Sie nicht so vom Hocker? Okay, ein statistisches Modell kann natÃ¼rlich komplexer sein, z.B. wie in Abb. FigureÂ 2.5 dargestellt.\n\n\n\n\n\nflowchart LR\nX1 --> Y\nX2 --> Y\n\n\n\n\n\nFigureÂ 2.5: Sinnbild eines stastistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\n\n\nEs hÃ¶rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n\n2.5.2 Vertiefung\nLesen Sie die EinfÃ¼hrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nNote\n\n\n\nNutzen Sie die Ãœbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch."
  },
  {
    "objectID": "Inferenz.html#regression",
    "href": "Inferenz.html#regression",
    "title": "2Â  Inferenz",
    "section": "2.6 Regression",
    "text": "2.6 Regression\n\n\n\nOne regression\n\n\n\n2.6.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmessen: FÃ¼r vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schÃ¶ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nNote\n\n\n\nRegression + Inferenz = ğŸ’–\n\n\nAlternativ zur Regression kÃ¶nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni MÃ¼nster als Ausschnitt (!) aufgefÃ¼hrt.\nAuf dieser Basis kann man meditieren, welches statistischen Verfahren man fÃ¼r eine bestimmte Fragestellung verwenden sollte, s. Abb. FigureÂ 2.6.\n\n\n\nFigureÂ 2.6: WÃ¤hle deine Statistik mit Bedacht\n\n\n\n\n2.6.2 Viele statistische Verfahren sind SpezialfÃ¤lle der Regression\nWie Jonas Kristoffer LindelÃ¸v uns erklÃ¤rt, sind viele statistische Verfahren, wie der sog. t-Test SpezialfÃ¤lle der Regression, s. Abb. FigureÂ 2.7.\n\n\n\nFigureÂ 2.7: Common statistical tests as linear models\n\n\n\n\n2.6.3 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; Abb. FigureÂ 2.8.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nAnhan der Gleichung erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet. Dabei wird X nicht mit â€œfortgeschrittenenâ€ Transformationen wie Quadradieren oder Exponenzieren beglÃ¼ckt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n\n\n\nFigureÂ 2.8: Die Regressionsgerade in voller Pracht"
  },
  {
    "objectID": "Inferenz.html#unsicherheit",
    "href": "Inferenz.html#unsicherheit",
    "title": "2Â  Inferenz",
    "section": "2.7 Unsicherheit",
    "text": "2.7 Unsicherheit\n\n2.7.1 Inferenz beinhaltet Unsicherheit\nInferenzstatistische SchlÃ¼sse sind mit Unsicherheit behaftet: SchlieÃŸlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), mÃ¶chte aber vom Teil auf das Ganze schlieÃŸen.\n\n\n\n\n\n\nImportant\n\n\n\nNichts Genaues weiÃŸ man nicht: SchlieÃŸt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen Ã¼ber das Ganze betrifft.\n\n\nSchlieÃŸt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. SchlieÃŸlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen fÃ¼r die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer mÃ¶glich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n\n\n\n\n\nNote\n\n\n\nUnter einem zufÃ¤lligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nÃ¤chsten WÃ¼rfelwurfs. ZufÃ¤llig bedeutet nicht (zwangslÃ¤ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines WÃ¼rfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\nğŸ‹ Welche physikalischen Randbedingungen wirken wohl auf einen MÃ¼nzwurf ein?\n\n\n2.7.2 Beispiele zur Quantifizierung von Ungewissheit\nAussagen mit Unsicherheit kÃ¶nnen unterschiedlich prÃ¤zise formuliert sein.\n\nMorgen regnetâ€™s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert fÃ¼r Methode \\(A\\) hÃ¶her als fÃ¼r Methode \\(B\\).\nDie Maschine fÃ¤llt demnÃ¤chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nÃ¤chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\nğŸ‹ Geben Sie weitere Beispiele an!\n\n\n2.7.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. FigureÂ 2.9.\n\nWie (un)gewiss ist man sich Ã¼ber den Wert des Regressionsgewichts?\nWie (un)gewiss ist man sich Ã¼ber den Wert von Y? SchlieÃŸlich kÃ¶nnte es ja EinflÃ¼sse (X) geben, die man nicht berÃ¼cksichtigt hat.\n\n\n\n\n\n\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 Ã¼bersehen? .-> B\n\n\n\n\n\n\nFigureÂ 2.9: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n\n2.7.4 Ich weiÃŸ, was ich nicht weiÃŸ: Ungewissheit angeben\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der SchÃ¤tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schÃ¤tzt, lÃ¤sst aber offen wie sicher (prÃ¤zise) die SchÃ¤tzung ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die SchÃ¤tzung schlieÃŸt sogar 41% oder 43% aus.\n::callout-important Eine Inferenz nennt man auch SchÃ¤tzung. Es sollte immer die Genauigkeit (Ungewissheit) der SchÃ¤tzung angegeben werden. :::\nIm Rahmen der Regressionsanalyse schlÃ¤gt sich die Ungewissheit an zwei Stellen nieer:\n\nzur Lage der Regressionsgeraden (\\(\\beta_0\\), \\(\\beta_1\\))\nzu EinflÃ¼ssen (X), die unser Modell nicht kennt (\\(\\epsilon, \\sigma\\))\n\n\n\n2.7.5 Visualisierung von Ungewissheit\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem PunktschÃ¤tzer. PunktschÃ¤ter beinhalten keine Angabe der SchÃ¤tz(un)gen auigkeit, s. Abb. FigureÂ 2.10.\n\n\n\n\n\nFigureÂ 2.10: Eine PunktschÃ¤tzung\n\n\n\n\nRot markiert: Die PunktschÃ¤tzung von mpg fÃ¼r hp=200.\nğŸ‹ Geben Sie ein vergleichbares Beispiel an!\n\n\n\nIn Abb. FigureÂ 2.11 ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur StÃ¤rke des Zusammenhangs von X und Y?\n\n\n\n\n\nFigureÂ 2.11: Ungewissheit in den Regressionskoeffizienten\n\n\n\n\nAuch wenn wir uns sicher im Hinblick auf die Regressionsgewichte in Abb. FigureÂ 2.11 bliebe eine Restungewissheit: Unsere SchÃ¤tzungen wÃ¤ren nicht sicher, nicht fehlerfrei. Das liegt daran, da das Modell nicht alle EinflÃ¼sse auf Y berÃ¼cksichtigt, sondern nur einen, hier als X bezeichnet.\nIn Abb. FigureÂ 2.12 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die â€œRestungewissheitâ€ dargestellt. In diesem Fall spricht man von einem â€œVorhersageintervallâ€, da man nicht nur von â€œtypischen FÃ¤llenâ€ auf der Regressiongeraden spricht, sondern fÃ¼r echte FÃ¤lle Vorhersagen (SchÃ¤tzungen) tÃ¤tigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n\n\n\nFigureÂ 2.12: Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\n\n\n\n\nWie man sieht, wird die Ungewissheit grÃ¶ÃŸer, wenn man beide Arten der Ungewissheit berÃ¼cksichtigt.\nDas Vorhersage-Intervall berÃ¼cksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\n\n2.7.6 Konfidenzintervall\nWir sehen hier, dass ein â€œUngewissheitskorridorâ€ angegeben wird. Entsprechend wird nicht ein PunktschÃ¤tzer, sondern ein SchÃ¤tzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich5\nEin Konfidenzintervall wird hÃ¤ufig mit 90% oder 95% Genauigkeit angegeben.\nIm Kontext der Bayes-Analyse ist das einfach zu interpretieren.\nSagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall fÃ¼r den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.\nDieser Befund lÃ¤ÃŸt sich so interpretieren:\nâ€œLaut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.â€\n\n\n\n\n\n\nImportant\n\n\n\nEin Konfidenzintervall gibt einen SchÃ¤tzbereich plausibler Werte fÃ¼r den gesuchten Wert in der Population (den Parameter) an.\n\n\nğŸ‹ Interpretieren Sie den Ungewissheitskorridor!"
  },
  {
    "objectID": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "2Â  Inferenz",
    "section": "2.8 Klassische vs.Â Bayes-Inferenz",
    "text": "2.8 Klassische vs.Â Bayes-Inferenz\n\n2.8.1 Klassische Inferenz: Frequentismus\n\nDie BerÃ¼cksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurÃ¼ckgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein\nWahrscheinlichkeit wird Ã¼ber relative HÃ¤ufigkeiten definiert.\nEs ist nicht mÃ¶glich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie hÃ¤ufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr hÃ¤ufig wiederholt ist.\nEin GroÃŸteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.8.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) flieÃŸt explizit in die Analyse ein (zusammen mit den Daten).\nWenn das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen fÃ¼r Hypothesen mÃ¶glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (fÃ¼r gÃ¤ngige Computer) komfortabel geworden.\n\n\n\n2.8.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.8.3.1 Frequentismus\n\nzentrale Statistik: p-Wert\nâ€œWie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufÃ¤llig verschieden und auf Basis unseres Modells)?â€\nFindet man \\(p<.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von â€œ(statistischer) Signifikanzâ€ und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n\n\n2.8.3.2 Bayes-Statistik\n\nzentrale Statistik: Posteriori-Verteilung\nâ€œWie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Baiss unseres Modells?â€\n\nğŸ‹ Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\n\n\n\n2.8.4 Frequentist und Bayesianer\n\n\n\nFrequentist wettet mit Bayesianer\n\n\nQuelle\n\n\n2.8.5 Der p-Wert ist wenig intuitiv\n\n\nfrom Imgflip Meme Generator\n\n\n\n2.8.6 Beispiel zum Nutzen von Apriori-Wissen 1\n\nEin Betrunkener behauptet, er kÃ¶nne hellsehen.\nEr wirft eine MÃ¼nze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die MÃ¼nze fair ist, dass Ergebnis also â€œzufÃ¤lligâ€ ist.\nUnser Vorwissen lÃ¤sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der ZufÃ¤lligkeit des Ergebnisses wohl nicht verwerfen.\n\n\n\n2.8.7 Beispiel zum Nutzen von Apriori-Wissen 2\n\nEine Studie fand einen â€œgroÃŸen Effektâ€ auf das Einkommen von Babies, eine Stunde pro Woche wÃ¤hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\).\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% hÃ¶her (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lÃ¤sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lÃ¤sst. Wir wÃ¼rden den Effekt lieber in einem konservativeren Intervall schÃ¤tzen (enger um Null)."
  },
  {
    "objectID": "Inferenz.html#literatur",
    "href": "Inferenz.html#literatur",
    "title": "2Â  Inferenz",
    "section": "2.9 Literatur",
    "text": "2.9 Literatur\nBei Gelman, Hill, and Vehtari (2021), Kap. 1 findet sich eine Darstellung Ã¤hnlich zu der in diesem Kapitel."
  },
  {
    "objectID": "Inferenz.html#aufgaben",
    "href": "Inferenz.html#aufgaben",
    "title": "2Â  Inferenz",
    "section": "2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2\ninferenz-fuer-alle\nadjustieren1\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  },
  {
    "objectID": "Wskt.html",
    "href": "Wskt.html",
    "title": "3Â  Wahrscheinlichkeit",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2013. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung ; Mit Aufgaben Und LÃ¶sungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Verteilungen.html",
    "href": "Verteilungen.html",
    "title": "4Â  Verteilungen",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2013. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung ; Mit Aufgaben Und LÃ¶sungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Globusversuch.html",
    "href": "Globusversuch.html",
    "title": "5Â  Globusversuch",
    "section": "",
    "text": "Bayes:Start"
  },
  {
    "objectID": "Globusversuch.html#von-welten-und-golems",
    "href": "Globusversuch.html#von-welten-und-golems",
    "title": "5Â  Globusversuch",
    "section": "5.1 Von Welten und Golems",
    "text": "5.1 Von Welten und Golems\n\n5.1.1 Kleine Welt, groÃŸe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb FigureÂ 5.1.\n\n\n\nFigureÂ 5.1: Behaims Globus: Kein Amerika\n\n\nDie kleine Welt des Modells entsprach hier nicht der groÃŸen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.\n\nKleine Welt vs.Â groÃŸe Welt\n\n\n\n\n\n\nKleine Welt\nGroÃŸe Welt\n\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit\nentspricht nicht (zwangslÃ¤ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt ist nicht die groÃŸe Welt.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.\nğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n\n5.1.2 Der Golem von Prag\n\n\n\nDer Golem von Prag\n\n\nQuelle\nDer Golem von Prag, eine vom Menschen geschaffene Kreatur gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt.\nBei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen.\nBei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.\n\n\n5.1.3 Wissenschaftliche Modelle sind wie Golems\nGolem\n\n\nBesteht aus Lehm\nBelebt durch â€œWahrheitâ€\nMÃ¤chtig\ndumm\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nMÃ¤rchen\n\nModell\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\n\n\n\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mÃ¤chtig\nsimpler als die RealitÃ¤t\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nNicht einmal falsch\n\n\n\n\n\n\n\nImportant\n\n\n\nWir bauen Golems.\n\n\n\n\n5.1.4 So denkt unser Bayes-Golem\n\n\n\nSo denkt unser Bayes-Golem\n\n\nğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!"
  },
  {
    "objectID": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "5Â  Globusversuch",
    "section": "5.2 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.2 Ein erster Versuch: Wir werfen den Globus\n\n5.2.1 Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?\nUnsere Hypothese bzw. unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist?\n\n\n\nDer Erdball\n\n\nQuelle CC 4.0 BY-NC\nSie werden einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie 9 Mal.\nSo sah mein Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!\n\n\n5.2.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten fÃ¼hrt, nennt man den den datengenierende Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der ErdoberflÃ¤che ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie WÃ¼rfe des Globusballes sind unabhÃ¤ngig voneinander.\nWir haben kein Vorwissen Ã¼ber \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\nğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?\n\n\n5.2.3 Ein paar Fachbegriffe\n\nFÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: Priori-Verteilung.\nFÃ¼r jede Hypothese (d.h. jeden Parameterwert \\(p\\)) mÃ¶chten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung1 bekommen.\n\n\n\n\nUpdating mit Bayes\n\n\n\n\n5.2.4 Die Binomialverteilung\nWir nehmen an, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert2.\nDann kann man die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser \\(p\\) betrÃ¤gt, mit der Binomialverteilung berechnen.\nDie Binomialverteilung zeigt die Verteilung der HÃ¤ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten): â€œMÃ¼nzwurfverteilungâ€\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L\\]\n\n\n5.2.5 Binomialverteilung mit R\nWas ist der Anteil der gÃ¼ltigen Pfade (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\ndbinom(x = 6, size = 9, prob = 1/2)\n\n[1] 0.1640625\n\n\nWas ist die Wahrscheinlichkeit fÃ¼r \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\ndbinom(x = 9, size = 9, prob = 1/2)\n\n[1] 0.001953125\n\n\n\n\n5.2.6 Beispiele zur Berechnung einer binomial verteilten Wahrscheinlichkeit\nEi Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?3.\n\ndbinom(x = 15, size = 20, prob = .5)\n\n[1] 0.01478577\n\n\nWas ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen?\n\ndbinom(3, 3, 1/2)\n\n[1] 0.125\n\n\n\n\n5.2.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: â€œW ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)â€. \\(N\\) gibt die Anzahl der GlobuswÃ¼rfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (â€œuniformâ€):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: â€œ\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1â€.\n\n\n5.2.8 So sehen die Verteilungen aus\nAbb. FigureÂ 5.2 zeigt die Binomialverteilung.\n\n\n\n\n\nFigureÂ 5.2: Ein Beispiel fÃ¼r eine Binomialverteilung\n\n\n\n\n\\(N=9, p = 1/2\\)\nAbb. FigureÂ 5.3 zeigt ein Beispiel fÃ¼r eine Gleichverteilung (uniform distribution).\n\n\n\n\n\nFigureÂ 5.3: Gleichverteilung\n\n\n\n\n\\(Min = 0, Max = 1\\)\nğŸ‹ï¸ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear? Was fÃ¤llt Ihnen bei der Gleichverteilung auf?"
  },
  {
    "objectID": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "5Â  Globusversuch",
    "section": "5.3 Zur Erinnerung: Bayes Theorem",
    "text": "5.3 Zur Erinnerung: Bayes Theorem\n\n5.3.1 Herleitung Bayesâ€™ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit fÃ¼r Regen und kalt ist gleich der Wahrscheinlihckeit von Regen, gegeben kalt mal der Wahrscheinlicht von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wennâ€™s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n\n5.3.2 Herleitung Bayesâ€™ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lÃ¶sen auf nach der Posteriori-Wahrscheinlichkeit, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods Ã¼ber alle Werte von \\(p\\). Die Aufgabe dieser GrÃ¶ÃŸe ist nur dafÃ¼r zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n\n5.3.3 Bayesâ€™ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)}\\]\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayesâ€™ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) fÃ¼ttert.\nBayesâ€™ Theorem wird hÃ¤ufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n\n\n5.3.4 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]\n\n\n\nPrior mal Likelihood = Post\n\n\n\n\n5.3.5 Wissen updaten: Wir fÃ¼ttern Daten in das Modell\n\n\n\n\n\n\nUnser Golem lernt\n\n\nUnser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "href": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "title": "5Â  Globusversuch",
    "section": "5.4 Bayes berechnen mit mit der Gitter-Methode",
    "text": "5.4 Bayes berechnen mit mit der Gitter-Methode\nDie Methode Gitter-AnnÃ¤herung nennt man auch Grid Approximation*.\n\n5.4.1 Idee\n\nTeile den Wertebereich des Parameter in ein â€œGitterâ€ auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (â€œGitterwerteâ€).\nBestimme den Priori-Wert des Parameters fÃ¼r jeden Gitterwert.\nBerechne den Likelihood fÃ¼r Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\n\n\n5.4.2 Gitterwerte in R berechnen\n\nd <-\n  tibble(\n    # definiere das Gitter: \n    p_Gitter = seq(from = 0, to = 1, length.out = 10),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %>%  \n    mutate(\n      # berechne Likelihood fÃ¼r jeden Gitterwert:\n      Likelihood = dbinom(6, size = 9, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\nSo sehen unsere â€œGitterdatenâ€ aus:\n\n# | echo: false\nd %>% \n  knitr::kable(digits = 2)\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\nğŸ‹ï¸ Was wohl mit Post passiert, wenn wir Priori Ã¤ndern?\n\n\n5.4.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: â€œPost-Verteilungâ€), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\n\n\n\nJe mehr Gittewerte, desto genauer wird die Verteilung wiedergegeben.\n\n\nMehr Gitterwerte glÃ¤tten die AnnÃ¤herung.\nJe grÃ¶ÃŸer die Stichprobe (\\(N\\)), desto zuverlÃ¤ssiger wird unsere Berechnung.\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer TrÃ¤ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung kÃ¶nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nÃ¤chsten Kapitels.\n\n\n\n5.4.4 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.\n\nğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r \\(W\\) tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)?"
  },
  {
    "objectID": "Post.html",
    "href": "Post.html",
    "title": "6Â  Die Post befragen",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6Â  Die Post befragen",
    "section": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.1.1 Zur Erinnerung: Gitterwerte in R berechnen\n\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nVoilÃ , die Post-Verteilung als Tabelle:\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n6.1.2 Zur Erinnerung, die Gittermethode\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen und \\(k=10\\) Gitterwerten.\nAbb. FigureÂ 6.1 zeigt die resultierende Post-Verteilung.\n\n\n\n\n\nFigureÂ 6.1: Die Postverteilung fÃ¼r W=6, N=9, k=10\n\n\n\n\n\n\n\n\n\n\n  \n    \n      Tabelle d mit Daten zur Posteriori-Verteilung\n    \n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0\n1\n0\n0\n0\n    1 Ã— 10âˆ’1\n1\n1 Ã— 10âˆ’4\n1 Ã— 10âˆ’4\n1 Ã— 10âˆ’4\n    2 Ã— 10âˆ’1\n1\n5 Ã— 10âˆ’3\n5 Ã— 10âˆ’3\n5 Ã— 10âˆ’3\n    3 Ã— 10âˆ’1\n1\n3 Ã— 10âˆ’2\n3 Ã— 10âˆ’2\n4 Ã— 10âˆ’2\n    4 Ã— 10âˆ’1\n1\n1 Ã— 10âˆ’1\n1 Ã— 10âˆ’1\n1 Ã— 10âˆ’1\n    6 Ã— 10âˆ’1\n1\n2 Ã— 10âˆ’1\n2 Ã— 10âˆ’1\n2 Ã— 10âˆ’1\n  \n  \n  \n\n\n\n\n\n\n6.1.3 Beispiele fÃ¼r Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.1.4 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKomplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Integrale, auf die man dabei stÃ¶ÃŸt, treiben einem gestandenen Mathematiker die SchweiÃŸperlen auf die Stirn.\nGlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten.\nPraktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der uns das meiste an Arbeit abnimmt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck.\nLernen wir jetz also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handbaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Diese Verfahren sind aber nicht mehr Gegenstand dieses Kurses.\n\n\n6.1.5 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck.\nBevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErsstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d):\n\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\nDie Wahrscheinlichkeit, einen Parameterwert aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant.\n\n\n\n\n\n\n  \n    \n      Stichprobendaten aus der Post-Verteilung\n    \n    \n      Nur die ersten Zeilen abgebildet\n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0.778\n1\n0.204\n2 Ã— 10âˆ’1\n0.227\n    0.444\n1\n0.111\n1 Ã— 10âˆ’1\n0.123\n    0.667\n1\n0.273\n3 Ã— 10âˆ’1\n0.303\n  \n  \n  \n\n\n\n\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten.\nWie sieht diese Tabelle dann als Histogramm1 aus?\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n\n  [1] 0.78 0.44 0.67 0.56 0.44 0.78 0.89 0.67 0.67 0.33 0.67 0.78 0.67 0.78 0.67\n [16] 0.56 0.67 0.78 0.67 0.33 0.78 0.56 0.67 0.78 0.78 0.78 0.44 0.56 0.89 0.78\n [31] 0.67 0.67 0.67 0.56 0.78 0.67 0.78 0.78 0.44 0.56 0.33 0.67 0.78 0.78 0.78\n [46] 0.78 0.78 0.56 0.67 0.56 0.78 0.67 0.56 0.56 0.78 0.56 0.33 0.67 0.44 0.33\n [61] 0.67 0.78 0.67 0.67 0.44 0.44 0.44 0.67 0.56 0.56 0.78 0.78 0.78 0.78 0.67\n [76] 0.78 0.56 0.78 0.44 0.56 0.67 0.89 0.56 0.56 0.67 0.67 0.33 0.67 0.67 0.67\n [91] 0.67 0.67 0.67 0.67 0.44 0.44 0.56 0.67 0.44 0.78\n\n\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. Abb. FigureÂ 6.2.\n\n\n\n\n\nFigureÂ 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n6.1.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) nach oeben.\nDatensatz samples, \\(n=10^3\\), \\(k=100\\) Gitterwerte, basierend auf dem Modell oben.\n\n\n\n\nsamples_k100 <-\n  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = n,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\n\n\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder.\n\n\n\n\n\n\nNote\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung.\n\nd_k100 %>% \n  slice_sample(n = 1e6, weight_by = post, replace = T) %>% \n  ggplot(aes(x = p_grid)) +\n  geom_density(fill = \"black\") +\n  scale_x_continuous(\"Anteil Wasser (p)\", limits = c(0, 1)) +\n  labs(y = \"\")"
  },
  {
    "objectID": "Post.html#die-post-verteilung-befragen",
    "href": "Post.html#die-post-verteilung-befragen",
    "title": "6Â  Die Post befragen",
    "section": "6.2 Die Post-Verteilung befragen",
    "text": "6.2 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeit (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abb. FigureÂ 6.3 illustriert.\n\n\n\nFigureÂ 6.3: Fragen nach p vs.Â Fragen nach q\n\n\n\n6.2.1 Fragen zu Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nWir filtern einfach die passenden Stichproben und und summieren die Wahrscheinlichkeiten dieser Stichproben:\n\n\n\n\n\nWir zÃ¤hlen (count) einfach die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %>%\n  count(p_grid < .5) \n\n# A tibble: 2 Ã— 2\n  `p_grid < 0.5`     n\n  <lgl>          <int>\n1 FALSE           8348\n2 TRUE            1652\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.\nEinfach wie ğŸ° essen.\nNoch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.5 und 0.75?\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75)\n\n# A tibble: 2 Ã— 2\n  `p_grid > 0.5 & p_grid < 0.75`     n\n  <lgl>                          <int>\n1 FALSE                           4530\n2 TRUE                            5470\n\n\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75) %>% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n# A tibble: 2 Ã— 2\n  Anteil Prozent\n   <dbl>   <dbl>\n1  0.453    45.3\n2  0.547    54.7\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden:\n\nsamples %>% \n  filter(p_grid > .5 & p_grid < .75) %>% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n# A tibble: 1 Ã— 2\n    sum anteil\n  <dbl>  <dbl>\n1 0.547   54.7\n\n\nNoch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nsamples %>% \n  count(p_grid >= .9 & p_grid <= 1) %>% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n# A tibble: 1 Ã— 1\n   prop\n  <dbl>\n1  0.01\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt.\n\n\n6.2.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nImportant\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall (synonym: KompatibilitÃ¤tsintervall oder Passungsbereich).\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% Posteriori-Wahrscheinlichkeit)\n\nsamples %>% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n# A tibble: 1 Ã— 1\n  quantil90\n      <dbl>\n1     0.778\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren:\n\nsamples %>% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchem Parameterwert wir landen:\n\nsamples %>% \n  summarise(\n    quant_10 = quantile(p_grid, 0.05),\n    quant_90 = quantile(p_grid, 0.95))\n\n# A tibble: 1 Ã— 2\n  quant_10 quant_90\n     <dbl>    <dbl>\n1    0.444    0.889\n\n\nSolche Fragen lassen sich mit Hilfe von Quantilen beantworten.\n\n\n6.2.3 Zur Erinnerung: Quantile\nBeispiel: Wie groÃŸ sind die Studentis (Quelle des Datensatzes)? Das Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%:\n\nspeed_gender_height <- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary <- \n  speed_gender_height %>% \n  drop_na(height) %>% \n  summarise(q25 = quantile(height, prob = .25),\n            q50 = quantile(height, prob = .5),\n            q75 = quantile(height, prob = .75))\n\nheight_summary\n\n# A tibble: 1 Ã— 3\n    q25   q50   q75\n  <dbl> <dbl> <dbl>\n1    63    66    69\n\n\nVisualisierung der Quantile:\n\n\n\n\n\n\n\n6.2.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht Ã¼berschritten wird:\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% ab.\nSchaue, was der grÃ¶ÃŸte verbleibende Wert ist.\n\n\nsamples %>% \n  arrange(p_grid) %>%   # sortiere\n  slice_head(n = 9000) %>%  # nur die ersten 90000, also die obersten 1000 abschneiden\n  summarise(p90 = max(p_grid))\n\n# A tibble: 1 Ã— 1\n    p90\n  <dbl>\n1 0.778\n\n\nDas (annÃ¤hernd) gleiche Ergebnis liefert quantile():\n\nsamples %>% \n  summarise(q90 = quantile(p_grid, .9))\n\n# A tibble: 1 Ã— 1\n    q90\n  <dbl>\n1 0.778\n\n\n\n\n6.2.5 Visualisierung der Intervalle\nIntervalle (Bereiche), die die Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle oder Equal-Tails-Intervalle (ETI):"
  },
  {
    "objectID": "Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "href": "Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "title": "6Â  Die Post befragen",
    "section": "6.3 Schiefe Posteriori-Verteilungen sind mÃ¶glich",
    "text": "6.3 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nGehen wir von 3 WÃ¼rfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe):\n\nd_33 <- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %>% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% \n  mutate(unstand_post = likelihood * prior) %>% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 <- \n  d_33 %>% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n    \n  \n  \n    0.68\n1\n0.31\n0.31\n    0.55\n1\n0.17\n0.17\n    0.90\n1\n0.73\n0.73\n    0.96\n1\n0.88\n0.88\n    0.95\n1\n0.86\n0.86\n    0.96\n1\n0.88\n0.88\n  \n  \n  \n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\n\n6.3.1 50%-Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall (PI, auch Equal-Tails-Intervall, ETI, genannt):\n\nqi_50_low <- eti(samples_33$p_grid, ci = .5)$CI_low\nqi_50_up <- eti(samples_33$p_grid, ci = .5)$CI_high\np1 <-\n  d_33 %>% \n  ggplot(aes(x = p_grid, y = post_33)) +\n  # check out our sweet `qi()` indexing\n  geom_area(data = . %>% \n              filter(p_grid > qi_50_low &  \n                    p_grid < qi_50_up),\n            fill = \"grey75\") +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 0, to = 1, by = .1))\n\np1\n\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\nlibrary(easystats)\n\nsamples_33 %>% \n  select(p_grid) %>% \n  eti(ci = .5)\n\nEqual-Tailed Interval\n\nParameter |      50% ETI\n------------------------\np_grid    | [0.72, 0.94]\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.3.2 50%-Intervall hÃ¶chster Dichte\nIntervalle hÃ¶chster Dichte (Highest density Intervals) sind definiert als die schmÃ¤lsten Intervalle, die den gesuchten Parameter enthalten.\n\n\n\n\n\nDer wahrscheinlichste Paramterwert (1) ist im Intervall enthalten, was Sinn macht.\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen:\n\nsamples %>% \n  select(p_grid) %>% \n  bayestestR::hdi(ci = .5)  # aus dem Paket `bayestestR`\n\nWarning: Identical densities found along different segments of the distribution,\nchoosing rightmost.\n\n\nHighest Density Interval\n\nParameter |      50% HDI\n------------------------\np_grid    | [0.67, 0.78]\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich in diesem Bereich befindet (auf Basis eines HDI).\n\n\n\n\n\n\nNote\n\n\n\nDas R-Paket {bayestestR} ist Teil des Meta-Pakets {easystats}. Es reicht, wenn Sie easystats laden, damit wird bayestestR automatisch geladen."
  },
  {
    "objectID": "Post.html#intervalle-hÃ¶chster-dichte-vs.-perzentilintervalle",
    "href": "Post.html#intervalle-hÃ¶chster-dichte-vs.-perzentilintervalle",
    "title": "6Â  Die Post befragen",
    "section": "6.4 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle",
    "text": "6.4 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich\nPerzentilintervalle sind verbreiteter\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse"
  },
  {
    "objectID": "Post.html#punktschÃ¤tzungen",
    "href": "Post.html#punktschÃ¤tzungen",
    "title": "6Â  Die Post befragen",
    "section": "6.5 PunktschÃ¤tzungen",
    "text": "6.5 PunktschÃ¤tzungen\nDatendatz samples, 6 Treffer bei 9 WÃ¼rfen.\n\n6.5.1 Lageparameter\nZ.B. Welchen mittleren Wasseranteil muss man annehmen?\n\nsamples %>% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n# A tibble: 1 Ã— 2\n   mean median\n  <dbl>  <dbl>\n1 0.636  0.667\n\n\n\n\n6.5.2 Streuungsparameter\nZ.B. â€œWie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?â€\n\nsamples %>% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n# A tibble: 1 Ã— 3\n   p_sd p_iqr p_mad\n  <dbl> <dbl> <dbl>\n1 0.138 0.222 0.165\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben.\n\n\n6.5.3 Visualisierungen der PunktschÃ¤tzer\n\n\n\n\n\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt)."
  },
  {
    "objectID": "ppv.html",
    "href": "ppv.html",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.1 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.",
    "text": "7.1 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem GlÃ¼cksspiel heraus: MÃ¼nzwurf; wenn er gewinnt, mÃ¼ssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? NatÃ¼rlich nehmen Sie sofort an.\nSie spielen also MÃ¼nzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal1.\nWÃ¼tend (und mit leeren Taschen) ziehen Sie von dannen.\nDaten: 9 von 10 Treffern beim MÃ¼nzwurf. Ist die MÃ¼nze fair?\n\ntibble(\n  Trefferzahl = rbinom(n = 1e4, size = 10, prob = 1/2)\n) %>% \n  mutate(signifikant = ifelse(Trefferzahl %in% c(9,10), TRUE, FALSE)) %>% \n  ggplot() +\n  aes(x = Trefferzahl, fill = signifikant) +\n  geom_bar() +\n  scale_x_continuous(breaks = 0:10) +\n  theme(legend.position = c(0.1, 0.8)) +\n  geom_vline(xintercept = 9) +\n  labs(title = \"Stichprobenverteilung fÃ¼r p=0.5\")\n\n\n\n\nDie Stichprobenverteilung zeigt, wie Wahrscheinlich der empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) ist gegeben eines Parameterwerts \\(p\\) (z.B. \\(p=0.5\\)): \\(Pr(D|p)\\).\n\n\n\n\n\n\n\n\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung."
  },
  {
    "objectID": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.2 Mit Stichproben neue Beobachtungen simulieren",
    "text": "7.2 Mit Stichproben neue Beobachtungen simulieren\n\n7.2.1 Wir simulieren die Wasserzahl bei GlobuswÃ¼rfen\nLikelihood (L): Wahrscheinlichkeit fÃ¼r \\(w=0,1,2\\) bei \\(N=2\\) und \\(p = 0.7\\):\n\nL <- dbinom(0:2, size = 2, prob = 0.7)\nL\n\n[1] 0.09 0.42 0.49\n\n\nWir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zÃ¤hlen die (Wasser-)Treffer:\n\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n\n[1] 0\n\n\nWarum nicht \\(n=10\\) neue Globusversuche simulieren:\n\nrbinom(n = 10, size = 2, prob = 0.7)\n\n [1] 0 2 1 1 1 1 2 1 1 2\n\n\nDiese Versuche geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann.\n\n\n7.2.2 Traue niemals einem Golem (einem Modell)\n\n\n\nNever trust a Golem\n\n\nQuelle: https://imgflip.com/i/5qmhmo\nImmer prÃ¼fen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsÃ¤chlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prÃ¼fen?"
  },
  {
    "objectID": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.3 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "7.3 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren:\n\ndraws <- \n  tibble(\n    draws = rbinom(1e6, size = 2, prob = .7))\n\ndraws %>% \n  count(draws) %>% \n  mutate(proportion = \n           n / nrow(d))\n\n# A tibble: 3 Ã— 3\n  draws      n proportion\n  <int>  <int>      <dbl>\n1     0  89770      8977 \n2     1 420629     42063.\n3     2 489601     48960.\n\n\nDiese simulierten HÃ¤ufigkeiten sind sehr Ã¤hnlich zu den theoretisch bestimmten HÃ¤ufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen.\n\ndbinom(0:2, size = 2, prob = .7)\n\n[1] 0.09 0.42 0.49"
  },
  {
    "objectID": "ppv.html#stichprobenverteilung",
    "href": "ppv.html#stichprobenverteilung",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.4 Stichprobenverteilung",
    "text": "7.4 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben fÃ¼r den Versuch \\(N=9\\) GlobuswÃ¼rfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise?\n\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = rbinom(n_draws, size = 9, prob = .7))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n\n\nn_draws <- 1e6\ndraws <- tibble(draws = rbinom(n_draws, \n                               size = 9, \n                               prob = .7))\n\n# the histogram\ndraws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", size = 1/10) +\n  scale_x_continuous(\"Anzahl Wasser (W) pro Versuch\",\n                     breaks = seq(from = 0, to = 9, by = 2)) +\n  scale_y_continuous(\"HÃ¤ufigkeit\",\n                     labels = scales::scientific) +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"Stichprobenverteilung fÃ¼r n=9 und p=.7 (binomial verteilt)\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir kÃ¶nnen jetzt prÃ¼fen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n7.4.1 Visualisierung der PPV\n\n\n\n\n\nQuelle: McElreath (2020)"
  },
  {
    "objectID": "ppv.html#so-viele-verteilungen",
    "href": "ppv.html#so-viele-verteilungen",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.5 So viele Verteilungenâ€¦",
    "text": "7.5 So viele Verteilungenâ€¦\n\nDie Posteriori-Verteilung gibt Aufschluss zur HÃ¤ufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass â€œin Wirklichkeitâ€ der Wasseranteil 70% betrÃ¤gt, also \\(\\pi=.7\\)\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\nDie PPV gibt Aufschluss zur HÃ¤ufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter DurchfÃ¼hrung, zu erwarten.\nFÃ¼r die Praxis kann das eine interessante Frage sein.\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklÃ¤rt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden.\n\n\n\n\n\n\nppv2_plot <- \nd_small %>%\n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", linewidth = 1/10) +\n  scale_x_continuous(\"Wasser\", breaks = seq(from = 0, to = 9, by = 3)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(subtitle = \"Stichprobenverteilungen\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ label, ncol = 9)"
  },
  {
    "objectID": "ppv.html#ppv-berechnen",
    "href": "ppv.html#ppv-berechnen",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.6 PPV berechnen",
    "text": "7.6 PPV berechnen\nFÃ¼r einen bestimmten Parameterwert sind verschiedene Stichprobenwerte mÃ¶glich. Das Spektrum dieser MÃ¶glichkeiten ist in einer Stichprobenverteilung (gegeben eines bestimmten Parameterwerts) dargestellt.\n\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nppv_plot2 <-\n  ppv %>% \n  ggplot() +\n  aes(x = value) +\n  geom_bar() +\n  scale_x_continuous(\n    breaks = 0:9)\n\n\nppv_plot2\n\n\n\n\n\nDie PPV unseres Modells zeigt uns, dass wir in kÃ¼nftigen Versuchen zumeist 6 Treffer zu erwarten haben.\nAber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar."
  },
  {
    "objectID": "ppv.html#vorhersagen-sind-schwierig",
    "href": "ppv.html#vorhersagen-sind-schwierig",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.7 Vorhersagen sind schwierig",
    "text": "7.7 Vorhersagen sind schwierig\nâ€¦ gerade wenn sie die Zukunft betreffen, so ein Sprichtwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der hÃ¤ufigste in unseren Stichproben, aber die Vorhersagen haben eine groÃŸe Streuung, birgt also hohe Ungewissheit.\nDie PPV zeigt also, welche Beobachtungen laut unserem Modell kÃ¼nftig zu erwarten sind.\n\n\n\n\n\nWÃ¼rde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hÃ¤tten die Vorhersagen zu wenig Streuung, wÃ¼rden also die Ungewissheit nicht ausreichend abbilden (Ãœbergewissheit, Overconfidence)."
  },
  {
    "objectID": "ppv.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "href": "ppv.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.8 Zwei Arten von Ungewissheit in Vorhersagen von Modellen",
    "text": "7.8 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells: Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiÃŸ, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nÃ¤chste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, mÃ¶chte man beide Arten von Ungewissheit berÃ¼cksichtigen: Das macht die Posteriori-PrÃ¤diktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prÃ¤diktiv) und mit welcher HÃ¤ufigkeit, basierend auf der Post-Verteilung."
  },
  {
    "objectID": "ppv.html#vergleich-der-verteilungen",
    "href": "ppv.html#vergleich-der-verteilungen",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.9 Vergleich der Verteilungen",
    "text": "7.9 Vergleich der Verteilungen\n\n\n\n\n\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-PrÃ¤diktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter BerÃ¼cksichtigung der Unsicherheit der Posteriori-Verteilung\n\nBild\nQuelle: R. McElreath\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "gauss.html",
    "href": "gauss.html",
    "title": "8Â  Gauss-Modelle",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "gauss.html#software",
    "href": "gauss.html#software",
    "title": "8Â  Gauss-Modelle",
    "section": "8.1 Software",
    "text": "8.1 Software\nFÃ¼r dieses Thema benÃ¶tigen Sie einige R-Pakete, die Sie wie folgt installieren kÃ¶nnen:\n\npakete <- c(\"tidyverse\", \"rstanarm\", \"easystats\")\n\ninstall.packages(pakete)\n\nFÃ¼r rstanarm wird weitere Software benÃ¶tigt.\n\n\n\n\n\n\nNote\n\n\n\nSoftware, und das sind R-Pakete, mÃ¼ssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio mÃ¼ssen Sie die (benÃ¶tigten!) Pakete starten.\n\n\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2 â”€â”€\nâœ” ggplot2 3.3.6.9000     âœ” purrr   0.3.4     \nâœ” tibble  3.1.8          âœ” dplyr   1.0.10    \nâœ” tidyr   1.2.0          âœ” stringr 1.4.1     \nâœ” readr   2.1.2          âœ” forcats 0.5.2     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\n\nlibrary(rstanarm)\n\nLoading required package: Rcpp\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nPlease use the `linewidth` argument instead.\n\n\nThis is rstanarm version 2.21.3\n- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!\n- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.\n- For execution on a local, multicore CPU with excess RAM we recommend calling\n  options(mc.cores = parallel::detectCores())\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.5.2\nâœ” insight     0.18.2     âœ” datawizard  0.5.1   \nâœ” bayestestR  0.12.1.1   âœ” performance 0.9.2   \nâœ” parameters  0.18.2     âœ” effectsize  0.7.0.5 \nâœ” modelbased  0.8.5      âœ” correlation 0.8.2   \nâœ” see         0.7.2      âœ” report      0.5.5"
  },
  {
    "objectID": "gauss.html#wie-groÃŸ-sind-die-kung-san",
    "href": "gauss.html#wie-groÃŸ-sind-die-kung-san",
    "title": "8Â  Gauss-Modelle",
    "section": "8.2 Wie groÃŸ sind die !Kung San?",
    "text": "8.2 Wie groÃŸ sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\n\n\n\n\n\nQuelle Internet Archive Book Images, No restrictions, via Wikimedia Commons]\n\n\n\n\n\nBy Andrewwik.0 - Own work, CC BY-SA 4.0, Quelle]\n\n\n8.2.2 !Kung Data\nDatenquelle\n\nKung_path <-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd <- read_csv(Kung_path)  \n\nRows: 544 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\ndbl (4): height, weight, age, male\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(d)\n\n# A tibble: 6 Ã— 4\n  height weight   age  male\n   <dbl>  <dbl> <dbl> <dbl>\n1   152.   47.8    63     1\n2   140.   36.5    63     0\n3   137.   31.9    65     0\n4   157.   53.0    41     1\n5   145.   41.3    51     0\n6   164.   63.0    35     1\n\n\nWir interessieren uns fÃ¼r die GrÃ¶ÃŸe der erwachsenen !Kung:\n\nd2 <- d %>% \n  filter(age >= 18)\n\n\\(N=352\\).\n\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n  \n  \n    \n      Variable\n      Mean\n      SD\n      IQR\n      Min\n      Max\n      Skewness\n      Kurtosis\n      n\n      n_Missing\n    \n  \n  \n    height\n154.59709\n7.74\n12.06\n136.53\n179.07\n0.15\nâˆ’0.48\n352.00\n0.00\n    weight\n44.99049\n6.46\n9.19\n31.07\n62.99\n0.13\nâˆ’0.51\n352.00\n0.00\n    age\n41.13849\n15.97\n23.00\n18.00\n88.00\n0.67\nâˆ’0.21\n352.00\n0.00\n    male\n0.46875\n0.50\n1.00\n0.00\n1.00\n0.13\nâˆ’2.00\n352.00\n0.00\n  \n  \n  \n\n\n\n\n\n\n8.2.3 Wir gehen apriori von normalverteilter GrÃ¶ÃŸe Der !Kung aus\n\n\n\n\n\nOwn alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA 3.0 https://creativecommons.org/licenses/by-sa/3.0, via Wikimedia Commons\n\\[\\mu \\sim \\mathcal{N}(178, 20)\\]\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen. In einer echten Untersuchung sollte man immer einen inhaltlichen Grund fÃ¼r einen Priori-Wert haben. Oder man wÃ¤hlt â€œschwach informativeâ€ Prioris, wie das {rstanarm} tut: Damit lÃ¤sst man kaum Vorab-Information in das Modell einflieÃŸen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).\n\n\n\n\n\n8.2.4 Unser Gauss-Modell der !Kung\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior fÃ¼r \\(\\mu\\):\n\\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior fÃ¼r \\(\\sigma\\):\n\\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\n \n\\(95\\%KI( \\mu):\\)\n\\(178 \\pm 40\\)\nHier sind unsere Priori-Verteilungen visualisiert:"
  },
  {
    "objectID": "gauss.html#priori-gewichtet-mit-likelihood-ergibt-posteriori",
    "href": "gauss.html#priori-gewichtet-mit-likelihood-ergibt-posteriori",
    "title": "8Â  Gauss-Modelle",
    "section": "8.3 Priori gewichtet mit Likelihood ergibt Posteriori",
    "text": "8.3 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\n\n8.3.1 Likelihood\nDie KÃ¶rpergrÃ¶ÃŸen der einzelnen Personen \\(h_i\\) sind normalverteilt mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})\\]\n\n\n8.3.2 Prioris\nMittelwert der GrÃ¶ÃŸe ist normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)}\\]\nDie Streuung \\(\\sigma\\) der GrÃ¶ÃŸen ist exponentialverteil mit \\(\\lambda = 0.1\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(0.1)}\\]"
  },
  {
    "objectID": "gauss.html#zufÃ¤llige-motivationsseite",
    "href": "gauss.html#zufÃ¤llige-motivationsseite",
    "title": "8Â  Gauss-Modelle",
    "section": "8.4 ZufÃ¤llige Motivationsseite",
    "text": "8.4 ZufÃ¤llige Motivationsseite"
  },
  {
    "objectID": "gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "href": "gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "title": "8Â  Gauss-Modelle",
    "section": "8.5 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41",
    "text": "8.5 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41\n\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)\nm41_post <- as_tibble(m41)\nnames(m41_post) <- c(\"mu\", \"sigma\")\n\nDas Argument refresh = 0 verhindert, dass die Dateils zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrÃ¼cke.\nFÃ¼r das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung der Prioris von rstanarm zurÃ¼ck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wÃ¤re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die Posteriori-Verteilung von m41:\n\nm41_post %>% \n  ggplot() +\n  aes(x = mu, y = sigma) %>% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\nDa das Modell zwei Parameter hat, kÃ¶nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen kÃ¶nnen die Parameter korreliert sein.\nHier noch eine andere Visualisierung:\n\np_m41_post <- \n  m41_post %>% \n  ggplot() +\n  aes(x = mu, y = sigma) +\n  geom_point(alpha = .1) \n\nggExtra::ggMarginal(p_m41_post, type = \"density\")\n\n\n\n\nNatÃ¼rlich kÃ¶nnen wir auch nur einen Parameter plotten:\n\nm41_post %>% \n  ggplot(aes(x = mu)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nWir bekommen eine Wahrscheinlichkeitsverteilung fÃ¼r \\(\\mu\\) und eine fÃ¼r \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, fÃ¼r die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte fÃ¼r \\(\\mu\\) und \\(\\sigma\\) klein: Die groÃŸe Stichprobe hat die Priori-Werte Ã¼berstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so kÃ¶nnen wir interessante Fragen stellen.\n\n\n8.5.1 Hallo, Posteriori-Verteilung\nâ€¦ wir hÃ¤tten da mal ein paar Fragen an Sie. ğŸ•µ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person grÃ¶ÃŸer als 1,55m?\nWelche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?\nWas ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?\n\nAntworten folgen etwas weiter unten.\nAbschliÃŸend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\):\n\nm41_post %>% \n  pivot_longer(mu:sigma) %>% \n  ggplot(aes(x = value)) + \n  geom_density(fill = \"grey33\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(NULL) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ name, scales = \"free\", \n             labeller = label_parsed,\n             nrow = 2)\n\n\n\n\n\n\n8.5.2 Posteriori-Stichproben mit stan_glm() berechnen\n\nMit stan_glm() kÃ¶nnen wir komfortabel die Posteriori-Verteilung berechnen.\nDie Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - Ã¤hnlich.\nEs werden aber auch viele Stichproben simuliert (sog. MCMC-Methode).\nGibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurÃ¼ck.\n\n\nlibrary(rstanarm)  # Paket muss gestartet sein.\n\n\n# berechnet Post.-Vert.:\nstan_glm(\n  # modelldefinition:\n  AV ~ UV,\n  # Datensatz:\n  data = meine_daten\n)\n\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior GrÃ¶ÃŸenmittelwert\n\\(\\sigma \\sim \\mathcal{E}(0.13)\\), Prior Streuung der GrÃ¶ÃŸen\n\n\n8.5.3 Ausgabe von stan_glm()\n\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket easystats\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\n\nparameters(m41)\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |                    Prior\n-------------------------------------------------------------------------------------------------------\n(Intercept) | 154.60 | [153.79, 155.44] | 100% |        0% | 1.000 | 2182.00 | Normal (154.60 +- 19.36)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation."
  },
  {
    "objectID": "gauss.html#wie-tickt-stan_glm",
    "href": "gauss.html#wie-tickt-stan_glm",
    "title": "8Â  Gauss-Modelle",
    "section": "8.6 Wie tickt stan_glm()?",
    "text": "8.6 Wie tickt stan_glm()?\n\n\n\n\n\nQuelle\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan fÃ¼r uns bereit.\nstan_glm() ist fÃ¼r die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schÃ¤tzen, so hat man man â€¦ eine Regression ohne PrÃ¤diktor.\nEine Regression ohne PrÃ¤diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also fÃ¼r die nicht vorhandene UV; y meint die AV (height).\nMAD_SD ist eine robuste Version der Streuung, mit inhaltlich gleicher Aussage\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\nDokumentation RstanArm\n\n8.6.1 Stichproben aus der Posteriori-Verteilung ziehen\nHier die ersten paar Zeilen von post_m41:\n\npost_m41 <- as_tibble(m41)\nhead(post_m41)\n\n# A tibble: 6 Ã— 2\n  `(Intercept)` sigma\n          <dbl> <dbl>\n1          154.  7.79\n2          154.  7.98\n3          154.  8.19\n4          155.  7.36\n5          154.  8.05\n6          156.  8.41\n\n\nMit welcher Wahrscheinlichkeit ist \\(\\mu>155\\)?\n\nnames(post_m41) <- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist kÃ¼rzher\n\npost_m41 %>% \n  count(mu > 155) %>% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 Ã— 3\n  `mu > 155`     n  prop\n  <lgl>      <int> <dbl>\n1 FALSE       3349 0.837\n2 TRUE         651 0.163\n\n\n\n\n8.6.2 Antworten von der Posteriori-Verteilung\nWelche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell m41?\n\npost_m41 %>% \n  summarise(q95 = quantile(mu, .95))\n\n# A tibble: 1 Ã— 1\n    q95\n  <dbl>\n1  155.\n\n\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\n\npost_m41 %>% \n  summarise(pi_90 = quantile(mu, c(0.05, 0.95)))\n\n# A tibble: 2 Ã— 1\n  pi_90\n  <dbl>\n1  154.\n2  155.\n\n\nMit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?\n\nm41 %>% \n  parameters()\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |                    Prior\n-------------------------------------------------------------------------------------------------------\n(Intercept) | 154.60 | [153.79, 155.44] | 100% |        0% | 1.000 | 2182.00 | Normal (154.60 +- 19.36)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren KÃ¶rpergrÃ¶ÃŸe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\nWas ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?\nparameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\nğŸ‹ï¸ Ã„hnliche Fragen bleiben als Ãœbung fÃ¼r die Lesis ğŸ¤“.\n\n\n8.6.3 Standard-Prioriwerte bei stan_glm()\n\nprior_summary(m41)\n\nPriors for model 'm41' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 155, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 155, scale = 19)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.13)\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben.\nEs werden dafÃ¼r die Stichproben-Daten als Priori-Daten verwendet.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden.\nDie Voreinstellung hat keinen tiefen Hintergrund; andere Werte wÃ¤ren auch denkbar.\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (fÃ¼r \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals â€œStreuungâ€, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen.\n\n\n\n\n8.6.4 Visualisierung verschiedener Exponentialverteilungen\nUm ein GefÃ¼hl zu bekommen, wieviel Ungewissheit in Exponentialverteilugnen mit verschiedener Streuung liegt, sind hier mal ein paar Varianten dargestellt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wÃ¤hlen, dass man nicht Ã¼bergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschleÃŸen.\n\\(\\lambda \\approx 0.1\\) scheint eine sinnvolle Ungewissheit anzugeben.\n\n\n\n\n\n\nImportant\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflieÃŸen zu lassen und eigene Entscheidungen zu begrÃ¼nden. HÃ¤ufig sind mehrere Entscheidungen mÃ¶glich. MÃ¶chte man lieber vorsichtig sein, weil man wenig Ã¼ber den Gegenstand weiÃŸ, dann kÃ¶nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die â€œschwachinformativâ€ ist, also nur wenig Priori-Information ind das Modell einflieÃŸen lÃ¤sst."
  },
  {
    "objectID": "gauss.html#modell-m42-unsere-priori-werte",
    "href": "gauss.html#modell-m42-unsere-priori-werte",
    "title": "8Â  Gauss-Modelle",
    "section": "8.7 Modell m42: unsere Priori-Werte",
    "text": "8.7 Modell m42: unsere Priori-Werte\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflieÃŸen, im Modell m42.\n\nd2 <- \n  d2 %>% \n  mutate(height_c = height - mean(height))  # zentrieren\n\n\nm42 <- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |              Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 154.60 | [153.81, 155.40] | 100% |        0% | 1.000 | 2550.00 | Normal (178 +- 20)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nWir haben noch nicht alle Informationen kennengelernt, die hier ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige FÃ¤higkeit im Studium ğŸ¤“.\n\n\n\n\n8.7.1 Posteriori-Verteilung und Parameter plotten\n\nm42 %>% \n  as_tibble() %>% \n  ggplot(aes(x = `(Intercept)`)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWie man sieht, sind sich die Post-Verteilungen von m41 und m42 ziemlich Ã¤hnlich, kommen also zu dem gleichen Schluss, was die mittlere KÃ¶rpergrÃ¶ÃŸe betrifft. Das ist ein Beispiel fÃ¼r eine Situation, wo eine ausreichend groÃŸe Stichprobe die Wahl der Prioris (sofern nicht extrem) aussticht.\nEin Vergleich mehererer Priori-Werte wÃ¤re auch nÃ¼tzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewÃ¤hlten Priori-Werte zu Ã¼berzeugen."
  },
  {
    "objectID": "gauss.html#fazit",
    "href": "gauss.html#fazit",
    "title": "8Â  Gauss-Modelle",
    "section": "8.8 Fazit",
    "text": "8.8 Fazit\n\nWir haben die Posteriori-Verteilung fÃ¼r ein Gauss-Modell berechnet.\nDabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne PrÃ¤diktoren, betrachtet.\nDie Zielvariable, KÃ¶rpergrÃ¶ÃŸe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen.\nFÃ¼r \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung fÃ¼r \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\nğŸ§¡ Bleiben Sie dran!"
  },
  {
    "objectID": "gauss.html#wahl-der-priori-werte",
    "href": "gauss.html#wahl-der-priori-werte",
    "title": "8Â  Gauss-Modelle",
    "section": "8.9 Wahl der Priori-Werte",
    "text": "8.9 Wahl der Priori-Werte\nğŸï¸ Dieser Abschnitt ist eine VERTIEFUNG. ğŸ\n\n8.9.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\nn <- 1e4\n\nsim <- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %>% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd <- \n  sd(sim$height) %>% round()\nheight_sim_mean <- \n  mean(sim$height) %>% round()\n\nğŸ’­ Was denkt der Golem (m41) apriori von der GrÃ¶ÃŸe der !Kung?\nğŸ¦¾ Ziehen wir mal ein paar Stichproben auf Basis des Modells. VoilÃ :\n\np3 <- \n  sim %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MWÂ±3SD\",\n       x = \"GrÃ¶ÃŸe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\nQuellcode\n\n\n8.9.2 Priori-Werte prÃ¼fen mit der Priori-PrÃ¤diktiv-Verteilung\n\nDie Priori-PrÃ¤diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo kÃ¶nnen wir prÃ¼fen, ob die Priori-Werte vernÃ¼nftig sind.\n\nDie Priori-PrÃ¤diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an GrÃ¶ÃŸenwerten zulassen:\n\np3\n\n\n\n\nAnteil \\(h_i > 200\\):\n\nanteil_groÃŸer_kung <- \nsim %>% \n  count( height > 200) %>% \n  mutate(prop = n/sum(n))\nanteil_groÃŸer_kung\n\n# A tibble: 2 Ã— 3\n  `height > 200`     n  prop\n  <lgl>          <int> <dbl>\n1 FALSE           8372 0.837\n2 TRUE            1628 0.163\n\n\nğŸ¤” Sehr groÃŸe Buschleute? 16 Prozent sind grÃ¶ÃŸer als 2 Meter. Das ist diskutabel, muss aber nicht zwangslÃ¤ufig ein schlechter Prior sein.\n\n\n8.9.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n8.9.4 Extrem vage Priori-Verteilung fÃ¼r die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n# simulate\nset.seed(4)\n\nsim2 <-\n  tibble(sample_mu    = rnorm(n, mean = 178, sd = 100),\n         sample_sigma = rexp(n, rate = .01)) %>% \n  mutate(height = rnorm(n, mean = sample_mu, sd = sample_sigma))\n\n# compute the values we'll use to break on our x axis\nbreaks <-\n  c(mean(sim2$height) - 3 * sd(sim2$height), 0, mean(sim2$height), mean(sim2$height) + 3 * sd(sim2$height)) %>% \n    round(digits = 0)\n\n# this is just for aesthetics\ntext <-\n  tibble(height = 272 - 25,\n         y      = .0013,\n         label  = \"grÃ¶ÃŸter Mann\",\n         angle  = 90)\n\n# plot\np4 <-\n  sim2 %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"black\") +\n  geom_vline(xintercept = 0, color = \"grey92\") +\n  geom_vline(xintercept = 272, color = \"grey92\", linetype = 3) +\n  geom_text(data = text,\n            aes(y = y, label = label, angle = angle),\n            color = \"grey92\") +\n  scale_x_continuous(breaks = breaks, \n                     limits = c(-400, 700)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\\nmu ~ dnorm(178, 100)\\nsigma ~ E(0.01)\",\n       x = \"GrÃ¶ÃŸe\",\n       caption = \"X-Achse zeigt MWÂ±3SD\") +\n  theme(panel.grid = element_blank()) \n\np4\n\nWarning: Removed 130 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nDie Streuung der GrÃ¶ÃŸen ist weit:\n\nd <- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\nğŸ¤” Das Modell geht apriori von ein paar Prozent Menschen mit negativer GrÃ¶ÃŸe aus. Ein Haufen Riesen ğŸ‘¹ werden auch erwartet.\nğŸ¤¯ Vage (flache, informationslose, â€œneutraleâ€, â€œobjektiveâ€) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "lineare-modelle.html",
    "href": "lineare-modelle.html",
    "title": "9Â  Lineare Modelle",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nPlease use the `linewidth` argument instead."
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-der-regression",
    "href": "lineare-modelle.html#post-verteilung-der-regression",
    "title": "9Â  Lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\n\nDie (einfache) Regression prÃ¼ft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhÃ¤ngen.\nJe mehr sie zusammenhÃ¤ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt).\nHÃ¤ngen \\(X\\) und \\(Y\\) zusammen, heiÃŸt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwische \\(X\\) und \\(Y\\) gibt.\nLinear bedeutet, der Zusammenhang ist additiv und konstant: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).\n\nDatenquelle, McElreath (2020).\n\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd <- read_csv(Kung_path)  \n\nRows: 544 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\ndbl (4): height, weight, age, male\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd2 <- \n  d %>% \n  filter(age > 18) \n\nd2 %>% \n  #select(weight, height) %>% \n  #drop_na() %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n9.2.2 Bei jedem PrÃ¤diktorwert eine Post-Verteilung fÃ¼r \\(\\mu\\)\nUnser Modell erlaubt uns fÃ¼r jeden beliebigen Wert des PrÃ¤diktors eine Post-Verteilung (von \\(mu\\)) zu berechnen.\nHier am Beispiel von m42:\n\n\n\n\n\n\n\n\n<ScaleContinuousPosition>\n Range:  \n Limits:    0 --   70\n\n\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      height ~ weight_c\n observations: 346\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 154.6    0.3 \nweight_c      0.9    0.0 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 5.1    0.2   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\n\n\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n9.2.3 Statistiken zum !Kung-Datensatz\nDatenquelle\n\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd <- read_csv(Kung_path)  \n\nd2 <- d %>% filter(age > 18)\n\ndescribe_distribution(d2)\n\n\n\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:correlation':\n\n    cor_test\n\n\nThe following object is masked from 'package:modelbased':\n\n    get_emmeans\n\n\nThe following objects are masked from 'package:effectsize':\n\n    cohens_d, eta_squared\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\n\n\n\n  \n  \n    \n      variable\n      n\n      min\n      max\n      median\n      q1\n      q3\n      iqr\n      mad\n      mean\n      sd\n      se\n      ci\n    \n  \n  \n    age\n346.0\n19.0\n88.0\n40.0\n29.0\n51.0\n22.0\n16.3\n41.5\n15.8\n0.8\n1.7\n    height\n346.0\n136.5\n179.1\n154.3\n148.6\n160.7\n12.1\n8.5\n154.6\n7.8\n0.4\n0.8\n    male\n346.0\n0.0\n1.0\n0.0\n0.0\n1.0\n1.0\n0.0\n0.5\n0.5\n0.0\n0.1\n    weight\n346.0\n31.5\n63.0\n45.0\n40.3\n49.4\n9.0\n6.7\n45.0\n6.5\n0.3\n0.7\n    weight_c\n346.0\nâˆ’13.5\n17.9\n0.0\nâˆ’4.7\n4.3\n9.0\n6.7\n0.0\n6.5\n0.3\n0.7\n  \n  \n  \n\n\n\n\nDas mittlere KÃ¶rpergewicht (weight) liegt bei ca. 45kg (sd 7 kg).\n\n\n9.2.4 Etwas mehr EDA\nDas Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanylse.\nWir brauchen das hier nicht wirklich, aber es ist praktisch:\n\nlibrary(DataExplorer)\n\n\n9.2.4.1 Gibt es fehlende Werte?\n\nd2 %>% plot_missing()\n\n\n\n\n\n\n9.2.4.2 Verteilung der numerischen Variablen\n\nd2 %>% plot_histogram()\n\n\n\n\n\n\n9.2.4.3 Verteilung der kategorialen Variablen\n\nd2 %>% plot_bar()\n\n\n\n\n\n\n9.2.4.4 Korrelationen\n\nd2 %>% plot_correlation()\n\n\n\n\n\n\n9.2.4.5 Bonus\nProbieren Sie mal diese Funktion aus:\n\ncreate_report(d2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.5 PrÃ¤diktor zentrieren\n\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (PrÃ¤diktor â€œzentrierenâ€).\nWenn man den PrÃ¤diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\alpha\\), einfacher zu verstehen.\nIn einem Modell mit zentriertem PrÃ¤diktor (weight) gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit durchschnittlichem Gewicht an.\nWÃ¼rde man weight nicht zentrieren, gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist.\n\nVgl. Gelman, Hill, and Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen:\n\nd3 <- \n  d2 %>% \n  center(weight)\n\nOder so, von Hand:\n\nd3 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\n  \n  \n    \n      height\n      weight\n      age\n      male\n      weight_c\n    \n  \n  \n    152\n48\n63\n1\n3\n    140\n36\n63\n0\nâˆ’9\n    137\n32\n65\n0\nâˆ’13\n  \n  \n  \n\n\n\n\nWie man sieht, bleibt die Form der Verteilung gleich, aber sie ist â€œzur Seite geschobenâ€: Der Mittelwert liegt jetzt eben bei 0.\n\nd3 %>% \n  select(weight, weight_c) %>% \n  pivot_longer(everything()) %>% \n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(~ name, scales = \"free\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem PrÃ¤diktor ist, nicht d2."
  },
  {
    "objectID": "lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "href": "lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "title": "9Â  Lineare Modelle",
    "section": "9.3 Modell m43: zentrierter PrÃ¤diktor",
    "text": "9.3 Modell m43: zentrierter PrÃ¤diktor\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wÃ¤re wohl die KÃ¶rpergrÃ¶ÃŸe? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa wÃ¤re es schÃ¶n, wenn wir die Daten so umformen kÃ¶nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum GlÃ¼ck geht das leicht: Wir zentrieren den PrÃ¤diktor (Gewicht)!\n\n\n\n\n\n\nImportant\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m43\n\nFÃ¼r jede AusprÃ¤gung des PrÃ¤diktors (weight), \\(h_i\\), wird eine Post-Verteilung fÃ¼r die abhÃ¤ngige Variable (height) berechnet.\nDer Mittelwert \\(\\mu\\) fÃ¼r jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel).\nDie Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel).\nWir brauchen Priori-Werte fÃ¼r die Steigung \\(\\beta\\) und den Achsenabschnitt \\(\\alpha\\) der Regressionsgeraden.\nAuÃŸerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der GrÃ¶ÃŸe (height) angibt; dieser Wert wird als exonentialverteilt angenommen.\nDer Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\).\n\n\\[\n\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\n\\]\n\n\n9.3.2 Likelihood, m43\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\n\nDer Likelihood von m43 ist Ã¤hnlich zu den vorherigen Modellen (m41, m42).\nNur gibt es jetzt ein kleines â€œIndex-iâ€ am \\(\\mu\\) und am \\(h\\) (h wie heights).\nEs gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern fÃ¼r jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\).\nLies etwa so:\n\n\nâ€œDie Wahrscheinlichkeit, eine bestimmte GrÃ¶ÃŸe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))â€.\n\n\n\n9.3.3 Regressionsformel, m43\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschÃ¤tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\alpha\\) und \\(\\beta\\) ist \\(\\mu\\) ohne Ungewissheit bekannt.\n\\(\\text{weight}_i\\) ist der PrÃ¤diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz).\nLies etwa so:\n\n\nâ€œDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\alpha\\) und \\(\\beta\\) mal \\(\\text{weight}_i\\)â€.\n\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight.\n\\(\\beta\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden).\n\\(\\alpha\\) gibt an, wie groÃŸ \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n\n9.3.4 Priori-Werte des Modells m43\n\\[\n\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\n\\]\n\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n\\(\\alpha\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine â€œRegression ohne PrÃ¤diktorenâ€ berechnet haben.\n\\(\\sigma\\) ist uns schon als Parameter bekannt und behÃ¤lt seine Bedeutung aus dem letzten Kapitel.\nDa height nicht zentriert ist, der Mittelwert von \\(\\alpha\\) bei 178 und nicht 0.\n\\(\\beta\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und GrÃ¶ÃŸe positiv (gleichsinnig) ist."
  },
  {
    "objectID": "lineare-modelle.html#vertiefung-prior-prÃ¤diktiv-verteilung",
    "href": "lineare-modelle.html#vertiefung-prior-prÃ¤diktiv-verteilung",
    "title": "9Â  Lineare Modelle",
    "section": "9.4 Vertiefung: Prior-PrÃ¤diktiv-Verteilung",
    "text": "9.4 Vertiefung: Prior-PrÃ¤diktiv-Verteilung\nğŸï¸ VERTIEFUNG ğŸï¸\n\n9.4.1 Moment\n\nğŸ¤” Moment. Dieser Prior, \\(\\beta\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und GrÃ¶ÃŸe positiv oder negativ ist? Nein, sind wir nicht.\n\n\n\n9.4.2 Priori-PrÃ¤diktiv-Verteilung fÃ¼r m43\n\nWas denkt wir bzw. unser Golem apriori Ã¼ber den Zusammenhang von GrÃ¶ÃŸe und Gewicht?\nUm diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also fÃ¼r \\(\\alpha\\), \\(\\beta\\) und \\(\\sigma\\).\n\n.pull-left[\n\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter fÃ¼r Prior-Pred-Verteilung\n             data = d2)\n\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\nm43_prior_pred_draws %>% \n  slice_head(n=5) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      sigma\n    \n  \n  \n    186.1\nâˆ’12.2\n5.9\n    169.6\n0.8\n18.7\n    144.6\n8.4\n3.5\n    189.8\nâˆ’3.4\n4.3\n    203.3\nâˆ’2.9\n2.8\n  \n  \n  \n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n9.4.3 Prior-PrÃ¤diktiv-Simulation fÃ¼r m43 mit stan_glm()\n\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d2)\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\n\n\n\n\n9.4.4 Visualisieren der Prior-PrÃ¤diktiv-Verteilung\n\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\nğŸ¤¯ Einige dieser Regressionsgeraden sind unsinnig!\n\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.5 Ein positiver Wert fÃ¼r \\(\\beta\\) ist plausibler\n\n9.4.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\nğŸ‘ \\(\\beta=-20\\) wÃ¤re mit diesem Prior gut mÃ¶glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n9.4.5.2 Oh yes\nWir brÃ¤uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):\n\n\n\n\n\nğŸ‘ Vermutlich besser: Ein GroÃŸteil der Wahrscheinlichkeitsmasse ist \\(X>0\\). Allerdings gibtâ€™s keine GewÃ¤hr, dass unser Prior â€œrichtigâ€ ist.\n\n\n\n9.4.6 Priori-PrÃ¤diktiv-Simulation, 2. Versuch\n\nm43a_prior_pred <-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter fÃ¼r Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d2)\n\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  # Spaltennamen kÃ¼rzen: \n  rename(a = `(Intercept)`) %>%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      s\n    \n  \n  \n    156.1\n1.5\n30.0\n    187.7\nâˆ’0.8\n4.1\n    181.7\nâˆ’0.8\n0.1\n    154.0\n4.2\n0.2\n    162.2\n4.6\n0.4\n  \n  \n  \n\n\n\n\nDas Argument prior_PD = TRUE sorgt dafÃ¼r, dass keine Posteriori-Verteilung, sondern eine Prior-PrÃ¤diktiv-Verteilung berechnet wird.\n\n\n9.4.7 Visualisieren der Prior-PrÃ¤diktiv-Verteilung, m43a\nUnsere Priori-Werte scheinen einigermaÃŸen vernÃ¼nftige Vorhersagen zu tÃ¤tigen. Allerdings erwartet unser Golem einige Riesen.\n\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p.Â 96.\n\n\n9.4.9 Hier ist unser Modell, m43a\n\\[\n\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\n\\]\n\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n\n\n\n9.4.10 Eine Zusammenfassung der Posteriori-Verteilung fÃ¼r m43a\n\nm43a %>% \n  parameters()\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |              Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 154.65 | [154.09, 155.21] | 100% |        0% | 0.999 | 4132.00 | Normal (178 +- 20)\nweight_c    |   0.91 | [  0.83,   0.99] | 100% |        0% | 1.000 | 3837.00 |    Normal (5 +- 3)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nUnser Modell m43a schÃ¤tzt die typische KÃ¶rpergrÃ¶ÃŸe einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugehÃ¶rige 95%-CI keine 20 Zentimenter umfasst."
  },
  {
    "objectID": "lineare-modelle.html#die-post-verteilung-befragen",
    "href": "lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9Â  Lineare Modelle",
    "section": "9.5 Die Post-Verteilung befragen",
    "text": "9.5 Die Post-Verteilung befragen\n\n9.5.1 m43a\nSagen wir, auf Basis gut geprÃ¼fter Evidenz haben wir folgendes Modell festgelegt:\n\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n\nWir nennen es m43a1.\n\n\n9.5.2 Mittelwerte von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n  \n  \n    \n      id\n      (Intercept)\n      weight_c\n      sigma\n    \n  \n  \n    1\n154.8\n0.9\n4.9\n    2\n154.7\n0.8\n4.8\n    3\n154.9\n1.0\n5.1\n  \n  \n  \n\n\n\n\n\nparameters(m43a)\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\n\nparameters(m43a) %>% \n  display()\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.09, 155.21)\n100%\n0%\n0.999\n4132.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.83, 0.99)\n100%\n0%\n1.000\n3837.00\nNormal (5 +- 3)\n\n\n\n\n\n\n\n9.5.3 Visualisieren der â€œmittlerenâ€ Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\):\n\nm43a %>% \n  as_tibble() %>% \n  head()\n\n# A tibble: 6 Ã— 3\n  `(Intercept)` weight_c sigma\n          <dbl>    <dbl> <dbl>\n1          155.    0.906  4.94\n2          155.    0.830  4.79\n3          155.    0.950  5.14\n4          155.    0.963  5.28\n5          154.    0.865  4.93\n6          154.    0.877  4.81\n\n\nWir kÃ¶nnen z.B. ein LagemaÃŸ wie den Median hernehmen, um die â€œmittlereâ€ Regressionsgerade zu betrachten:\n\nd2 %>% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n9.5.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\mu, \\beta, \\sigma\\).\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen kÃ¶nnen.\n\n9.5.4.1 LagemaÃŸe zu den Parametern\n\nWas ist die mittlere GrÃ¶ÃŸe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der SchÃ¤tzwert fÃ¼r den Zusammenhang von Gewicht und GrÃ¶ÃŸe? (\\(\\beta_1\\))\nWas ist der SchÃ¤tzwert fÃ¼r Ungewissheit in der SchÃ¤tzung der GrÃ¶ÃŸe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert fÃ¼r z.B: \\(\\beta_1\\)?\n\n\nm43a %>% \n  parameters()\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |              Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 154.65 | [154.09, 155.21] | 100% |        0% | 0.999 | 4132.00 | Normal (178 +- 20)\nweight_c    |   0.91 | [  0.83,   0.99] | 100% |        0% | 1.000 | 3837.00 |    Normal (5 +- 3)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\nm43a_post <- \n  m43a %>% \n  as_tibble()\n\nm43a_post %>% \n  head()\n\n# A tibble: 6 Ã— 3\n  `(Intercept)` weight_c sigma\n          <dbl>    <dbl> <dbl>\n1          155.    0.906  4.94\n2          155.    0.830  4.79\n3          155.    0.950  5.14\n4          155.    0.963  5.28\n5          154.    0.865  4.93\n6          154.    0.877  4.81\n\n\nWie wir gesehen haben, nutzen wir diese Tabeller der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post.\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle\nEine Visualisierung zeigt gut sowohl Lage- als auch StreuungsmaÃŸe der Parameter, zumindest grob:\n\nm43a_post %>% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den hÃ¤ufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\nDer Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\nm43a_post %>% \n  summarise(map_b1 = map_estimate(weight_c))\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert:\n\nm43a_post %>% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%.\n\nm43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\nErgÃ¤nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n\n\n9.5.5 StreuungsmaÃŸe zu den Parametern\n\nWie unsicher sind wir uns in den SchÃ¤tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nNote\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebrÃ¤uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen StabilitÃ¤t.\n\n\n\n\n9.5.6 Ungewissheit von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung visualisiert\nDie ersten 10 Stichproben\n\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\nDie ersten 100 Stichproben\n\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\nDie ersten 1e3 Stichproben\n\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\nDie ersten 1000000 â€¦ okay, lassen wir es gut sein2\n\n\n9.5.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nNote\n\n\n\nZur Erinnerung: Bei einem zentrierten PrÃ¤diktor misst der Achsenabschnitt die mittlere GrÃ¶ÃŸe.\n\n\n\nWelche mittlere GrÃ¶ÃŸe mit zu 50%, 90% Wskt. nicht Ã¼berschritten?\nWelche mittlere GrÃ¶ÃŸe mit zu 95% Wskt. nicht unterschritten?\nVon wo bis wo reicht der innere 50%-SchÃ¤tzbereich der mittleren GrÃ¶ÃŸe?\n\n\n\n# A tibble: 1 Ã— 3\n   q_50  q_90  q_05\n  <dbl> <dbl> <dbl>\n1  155.  155.  154.\n\n\n# A tibble: 2 Ã— 1\n  pi_50\n  <dbl>\n1  154.\n2  155.\n\n\n\n\n9.5.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe bei mind. 155 cm liegt?\n\nm43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 Ã— 3\n  gross     n  prop\n  <lgl> <int> <dbl>\n1 FALSE  3574 0.894\n2 TRUE    426 0.106\n\n\n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.11.\n\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe hÃ¶chstens 154.5 cm betrÃ¤gt?\n\n\nm43a_post %>% \n  count(klein = (`(Intercept)` <= 154.5)) %>% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 Ã— 3\n  klein     n  prop\n  <lgl> <int> <dbl>\n1 FALSE  2810 0.702\n2 TRUE   1190 0.298\n\n\n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.3."
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "href": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "title": "9Â  Lineare Modelle",
    "section": "9.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert",
    "text": "9.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert\n\n9.6.1 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der KÃ¶rpergrÃ¶ÃŸe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche KÃ¶rpergrÃ¶ÃŸe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns Ã¼ber diesen Mittelwert?\nEtwas formaler ausgedrÃ¼ckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten PrÃ¤diktorwerten aus, gilt in dem Fall weight_c = 0.\n\nmu_at_45 <-\n  m43a_post %>% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n# | echo: false\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 45\"])) +\n  scale_x_continuous(limits = c(150, 160))\n\n\n\n\nAnalog kÃ¶nnen wir fragen, wie groÃŸ wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns Ã¼ber diesen Mittelwert sind.\n50 kg, das sind 5 Ã¼ber dem Mittelwert, in zentrierten Einheiten ausgedrÃ¼ckt also weight_c = 5.\n\nmu_at_50 <-\n  m43a_post %>% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\n\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\nWarning: Removed 45 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n9.6.2 LagemaÃŸe und Streuungen\nWas ist das 90% PI fÃ¼r \\(\\mu|w=50\\) ?\n\nmu_at_50 %>% \n  summarise(pi = quantile(mu_at_50, prob = c(0.05, .95)))\n\n# A tibble: 2 Ã— 1\n     pi\n  <dbl>\n1  159.\n2  160.\n\n\nDie mittlere GrÃ¶ÃŸe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten.\nWelche mittlere GrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, wenn die Person 45kg wiegt?\n\nmu_at_45 %>% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n\n# A tibble: 1 Ã— 1\n   q_95\n  <dbl>\n1  155."
  },
  {
    "objectID": "lineare-modelle.html#die-ppv-befragen",
    "href": "lineare-modelle.html#die-ppv-befragen",
    "title": "9Â  Lineare Modelle",
    "section": "9.7 Die PPV befragen",
    "text": "9.7 Die PPV befragen\nğŸï¸ VERTIEFUNG ğŸï¸\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) gibt uns die MÃ¶glichkeit, nach der Wahrscheinlichkeit tatsÃ¤chlicher KÃ¶rpergrÃ¶ÃŸen zu fragen - und nicht nur nach mittleren KÃ¶rpergrÃ¶ÃŸen anhand der Post-Verteilung.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren KÃ¶rpergrÃ¶ÃŸe, denn das ist was wir modellieren wollten. MÃ¶chten wir Aussagen zur Wahrscheinlichkeit tatsÃ¤chlicher GrÃ¶ÃŸen treffen, brauchen wir die PPV.\n\n\n\n9.7.1 Perzentil-Intervalle fÃ¼r verschiedenen PrÃ¤diktor-Werte\nWir erstellen uns eine Sequenz an PrÃ¤diktorwerten, die uns interessieren:\n\nweight_df <- tibble(weight_c = seq(-20,20, by = 5))\n\nFÃ¼r diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\nmus <- \n  predictive_interval(\n    m43a, \n    newdata = weight_df) %>% \n  as_tibble() %>% \n  bind_cols(weight_df)\n\nUm die Perzentilintervalle zu erstellen, wird von predictive_interval() fÃ¼r jeden PrÃ¤diktorwert eine Posteriori-Verteilung erstellt und das 5%- sowie 95%-Quantil berechnet.\nWir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine KÃ¶rpergrÃ¶0e von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI). Hoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedrÃ¼ckt; die PPV gibt die Ungewissheit tatsÃ¤chlicher beobachtbarer KÃ¶rpergrÃ¶ÃŸen aus, nicht nur die Ungewissheit zum Mittelwert.\nHier ist ein Auszug aus der PPV-Tabelle:\n\n\n\n\n\n\n  \n  \n    \n      weight_c\n      5%\n      95%\n    \n  \n  \n    âˆ’20.0\n127.7\n145.4\n    âˆ’15.0\n132.3\n149.7\n    âˆ’10.0\n137.2\n154.2\n    âˆ’5.0\n141.4\n158.5\n    0.0\n146.1\n163.3\n    5.0\n150.9\n167.6\n  \n  \n  \n\n\n\n\n\n\n9.7.2 Perzentilintervalle fÃ¼r verschiedenen PrÃ¤diktorwerte visualisiert\n\nmus <- \n  mus %>% \n  mutate(height = 154.6 + 0.9*weight_c)\n\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = \"blue\") +\n  geom_errorbar(data = mus,\n                aes(ymin = `5%`,\n                    ymax = `95%`),\n                size = .5,\n                width = .5,\n                color = \"firebrick\")\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung; je dicker die Katzenaugen, desto mehr Samples liegen vor an der Stelle, und umso genauer ist die SchÃ¤tzung.\n\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu|\\text{weight_c}_i\\).\n\n\n9.7.3 Die PPV visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV fÃ¼r einen bestimmten PrÃ¤diktorwert, z.B. bei einer Person mittleren Gewichts.\nWir kÃ¶nnen auch den Mittelwert Ã¼ber alle bedingten PPV anschauen, sozusagen die â€œMaster-PPVâ€ oder â€œunbedingte PPVâ€ oder schlicht PPV.\nVergleichen wir die echten Werte fÃ¼r height, \\(h\\), mit den von der PPV simulierten Werten fÃ¼r height, \\(h_{sim}\\).\n\nlibrary(bayesplot)\nh <- d2$height\nh_sim <- \n  posterior_predict(m43a, \n                    draws = 50)\nppc_dens_overlay(\n  h, h_sim)\n\n?posterior_predict zeigt Hilfe fÃ¼r diese Funktion. Die Funktion zeigt die Vorhersagen fÃ¼r die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n9.7.4 PPV plotten, von Hand\nPPV berechnen (lassen):\n\nset.seed(42)\nppv_m43a <- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %>% \n  as_tibble() %>% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\nUnd plotten:\n\nppv_m43a %>% \n  ggplot(aes(x = height)) +\n  geom_density()\n\n\n\n9.7.5 Fragen an die PPV\n\nWie groÃŸ sind die !Kung im Schnitt?\nWelche GrÃ¶ÃŸe wird von 90% der Personen nicht Ã¼berschritten?\nWie groÃŸ sind die 10% kleinsten?\n\n\nppv_m43a %>% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n# A tibble: 1 Ã— 4\n   q_10 height_mean  q_50  q_90\n  <dbl>       <dbl> <dbl> <dbl>\n1  138.        154.  154.  172.\n\n\nWas ist der 50% Bereich der KÃ¶rpergrÃ¶ÃŸe?\n\nppv_m43a %>% \n  summarise(pi_50 = quantile(height,prob = c(.25, .75)))\n\n# A tibble: 2 Ã— 1\n  pi_50\n  <dbl>\n1  144.\n2  165.\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2013. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung ; Mit Aufgaben Und\nLÃ¶sungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer\nGabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. 2nd ed. CRC Texts in\nStatistical Science. Boca Raton: Taylor; Francis, CRC\nPress.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  }
]