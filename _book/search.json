[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "nicht gleich zu Beginn, aber nach 2-3 Wochenâ†©ï¸\nfalls Sie die Pakete schon installiert haben, kÃ¶nnten Sie mal in RStudio auf â€œupdate.packagesâ€ klickenâ†©ï¸"
  },
  {
    "objectID": "Pruefung.html",
    "href": "Pruefung.html",
    "title": "1Â  PrÃ¼fung",
    "section": "",
    "text": "Die PrÃ¼fungsleistung besteht aus einer Open-Book-PrÃ¼fung."
  },
  {
    "objectID": "Pruefung.html#grundsÃ¤tzliches",
    "href": "Pruefung.html#grundsÃ¤tzliches",
    "title": "1Â  PrÃ¼fung",
    "section": "1.2 GrundsÃ¤tzliches",
    "text": "1.2 GrundsÃ¤tzliches\nDie folgenden Hinweise gelten grundsÃ¤tzlich, d.h. soweit nicht anders in der jeweiligen PrÃ¼fung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von PrÃ¼fungshinweisen kann zu Punkteabzug oder Nichtbestehen fÃ¼hren."
  },
  {
    "objectID": "Pruefung.html#wiederholungsprÃ¼fungen",
    "href": "Pruefung.html#wiederholungsprÃ¼fungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.3 WiederholungsprÃ¼fungen",
    "text": "1.3 WiederholungsprÃ¼fungen\n\nWenn Sie bei einer PrÃ¼fung durchgefallen sein sollten, so haben Sie grundsÃ¤tzlich die MÃ¶glichkeit, die PrÃ¼fung zu wiederholen.\nDenken Sie daran, sich rechtzeitig fÃ¼r PrÃ¼fungsleistungen anzumelden; beachten Sie die Fristen.\nDie Termine fÃ¼r die WiederholungsprÃ¼fungen werden stets zusammen/zeitgleich mit denen der regulÃ¤ren PrÃ¼fungen bekannt gegeben.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine WiederholungsprÃ¼fung.\nRelevanter Stoff und formale Bedingungen (wie PrÃ¼fungsform) sind grundsÃ¤tzlich identisch zur letzten abgehaltenen PrÃ¼fung des Moduls (d.h. sofern nicht anders angegeben). Daher sind WiederholungsprÃ¼fungen vom Anspruch vergleichbar wie die regulÃ¤re Klausur. Die PrÃ¼fungen sollen mÃ¶glichst gleich vom Anspruch sein, um Fairness zu gewÃ¤hrleisten.\nBeachten Sie immer die Hinweise, die fÃ¼r die WiederholungsprÃ¼fung angegeben sind. Im Einzelfall keine eine WiederholungsprÃ¼fung von der vorherigen PrÃ¼fung stÃ¤rker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen WiederholungsprÃ¼fung verÃ¶ffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine WiederholungsprÃ¼fung. Stattdessen kÃ¶nnen Sie ggf. an der regulÃ¤ren Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist mÃ¶glich, dass der Stoff sich dann substanziell Ã¤ndert; meist halten sich die Ã„nderungen (im Stoff) aber in Rahmen.\nSprechen Sie die Moduldozentis an fÃ¼r Details zur PrÃ¼fung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine PrÃ¼fung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben, es kommt auf den Einzelfall an. GrundsÃ¤tzlich rate ich aber dazu, PrÃ¼fungen nicht zu verschieben: SchlieÃŸlich kÃ¶nnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum PrÃ¼fungsrecht sprechen Sie bitte die Studienberatung an."
  },
  {
    "objectID": "Pruefung.html#prÃ¼fungsstoff",
    "href": "Pruefung.html#prÃ¼fungsstoff",
    "title": "1Â  PrÃ¼fung",
    "section": "1.4 PrÃ¼fungsstoff",
    "text": "1.4 PrÃ¼fungsstoff\nPrÃ¼fungsrelevanter Stoff ist alles, was im Unterricht behandelt wurde, sofern es nicht explizit (und schriftlich) als â€œnicht prÃ¼fungsrelevantâ€ gekennzeichnet ist."
  },
  {
    "objectID": "Pruefung.html#bearbeitungshinweise",
    "href": "Pruefung.html#bearbeitungshinweise",
    "title": "1Â  PrÃ¼fung",
    "section": "1.5 Bearbeitungshinweise",
    "text": "1.5 Bearbeitungshinweise\n\n1.5.0.1 Allgemeine Hinweise\n\nVerwenden Sie Standardwerte (defaults) der R-Funktionen.\nFindet sich in einer Auswahlliste mÃ¶glicher Antworten nicht die exakte LÃ¶sung, wÃ¤hlen Sie die am besten passende.\nTreffen Sie Annahmen, wo nÃ¶tig.\nDie PrÃ¼fung besteht auch aus Single- bzw. Multiple-Choice- (MC-)-Aufgaben mit mehreren Antwortoptionen.\nBei Multiple-Choice-Aufgaben (MC-Aufgaben) ist zumeist genau eine Antwortoption auszuwÃ¤hlen aus vier oder fÃ¼nf Antwortoptionen.\nIm Zweifel ist eine Aussage auf den Stoff, so wie im Unterricht behandelt, zu beziehen.\nBei Fragen zu R-Syntax spielen Aspekte wie Enter-Taste o.Ã„. bei der Beantwortung der Frage keine Rolle; diese Aspekte dÃ¼rfen zu ignorieren.\nJede Aussage einer MC-Aufgabe ist entweder richtig oder falsch (aber nicht beides oder keines).\nDie MC-Aufgaben sind nur mit Kreuzen zu beantworten; Text wird bei der Korrektur nicht berÃ¼cksichtigt.\nJede Aussage gilt ceteris paribus (unter sonst gleichen UmstÃ¤nden). Aussagen der Art â€A ist Bâ€œ (z.B. â€œMenschen sind sterblichâ€) sind nur dann als richtig auszuwÃ¤hlen, wenn die Aussage immer richtig ist.\nFalls Sie bei einer Aufgabe mehrere Antworten finden, aber nur nach einer gefragt ist, geben Sie nur eine an.\nFalls mehrere (widersprÃ¼chliche) Antworten gegeben wurden, wird im Zweifel die erst genannte gewertet.\nDie Aufgabenstellung in einer Moodle-PrÃ¼fung wird erst sichtbar, wenn Sie den PrÃ¼fungsbedingungen zugestimmt haben und die PrÃ¼fungszeit begonnen hat.\n\n\n\n1.5.1 Aufgaben zur Datenanalyse\n\nJe nach Spracheinstellung in Moodle kann es sein, dass Sie als Dezimaltrennzeichen ein Komma oder einen Punkt verwenden mÃ¼ssen. Moodle weist Sie, wenn Sie die Aufgabe verlassen, darauf hin, falls eine Zahl nicht als Zahl erkannt wurde.\nRunden Sie ggf. auf eine Dezimalstelle.\nVerwenden Sie Methoden der Bayes-Statistik fÃ¼r inferenzstatistische Analysen.\nGeben Sie keine Prozentzahlen an, sondern Anteile (also nicht â€œ50%â€, sondern â€œ0.5â€ bzw. â€œ0,5â€).\nBei Aufgaben, die eine Zahl als Antwort verlangen, ist nur eine Zahl anzugeben (nicht etwa Buchstaben).\nBei Aufgaben zur â€œBayes-Boxâ€ (Erstellung einer Gitterwert-Tabelle) gelten folgende MaÃŸgaben:\n\nHandelt es sich um Parameter mit einem begrenzten Wertebereich (wie etwa Anteile), so ist der ganze Wertebereich zu modellieren. Es sind 100 verschiedene Parameterwerte zu berechnen.\nHandelt es sich um Parameter \\(X\\) mit einem unbegrenzten Wertebereich (wie normalverteilte Variablen), so ist der Wertebereich \\(X-2\\sigma \\le X \\le X+2\\sigma\\) zu simulieren.\n\nAlle Berechnungen, die Zufallszahlen beinhalten, sollen mit fixierten Startwert der Zufallszahlen durchgefÃ¼hrt werden. Es ist die Zahl 42 zu verwenden.\nWie auch bei den Ã¼brigen Hinweisen gelten diese MaÃŸgaben nur soweit in der PrÃ¼fung nicht explizit andere Hinweise gegeben wurden.\nWenn Stichproben simuliert werden sollen, ziehen Sie \\(10^3\\) Zufallsstichproben.\nIn einigen Aufgaben kann verlangt sein, dass Sie einen bestimmten Datensatz in R importieren sollen. In diesem Fall wird vorausgesetzt, dass Ihnen diese Bezugsquelle von DatensÃ¤tzen bekannt ist und dass Sie wissen, wie man einen Datensatz in R importiert."
  },
  {
    "objectID": "Pruefung.html#teilnahmebedingungen",
    "href": "Pruefung.html#teilnahmebedingungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.6 Teilnahmebedingungen",
    "text": "1.6 Teilnahmebedingungen\n\nDie PrÃ¼fung ist selbstÃ¤ndig, also alleine nur durch Sie, ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der PrÃ¼fung sind einzuhalten.\nEs dÃ¼rfen nur die explizit als zulÃ¤ssig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulÃ¤ssigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, BÃ¼cher sowie Quellen aus dem Internet.\nDie Ãœbernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wÃ¶rtliche Ãœbernahme (â€œcopy-pasteâ€) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulÃ¤ssig.\nBei technischen Problemen ist sofort der PrÃ¼fer bzw. die PrÃ¼ferin zu verstÃ¤ndigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die PrÃ¼fung bzw. Teile daraus (z.B. PrÃ¼fungsfragen) zu speichern oder weiterzugeben.\nIm Ãœbrigen gelten die allgemeinen PrÃ¼fungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht PrÃ¼flingen, kommuniziert werden wÃ¤hrend der PrÃ¼fung. Dies gilt auch fÃ¼r den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den PrÃ¼fer, wenn Sie meinen, es liege ein technisches Problem vor.\nDas Nichtbeachten der Regeln kann zu Notenabzug oder Nichtbestehen fÃ¼hren."
  },
  {
    "objectID": "Pruefung.html#organisatorische-hinweise",
    "href": "Pruefung.html#organisatorische-hinweise",
    "title": "1Â  PrÃ¼fung",
    "section": "1.7 Organisatorische Hinweise",
    "text": "1.7 Organisatorische Hinweise\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prÃ¼fungsrelevant.\nIm Ãœbrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung fÃ¼r formale oder rechtliche Fragen.\nWÃ¤hrend der PrÃ¼fung werden nur Fragen beantwortet, die fÃ¼r die Bearbeitung zwingend nÃ¶tig sind (etwa bei technischen Problemen).\nEs werden keine Fragen der Art â€œIst diese Aufgabe klar formuliert?â€ beantwortet wÃ¤hrend der PrÃ¼fung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der PrÃ¼fung=. Der PrÃ¼fer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der PrÃ¼fung ist nur mÃ¶glich, wenn Sie den Teilnahmebedingungen der PrÃ¼fung zustimmen.\nDie Aufgabenstellung der PrÃ¼fung wird nur wÃ¤hrend des PrÃ¼fungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppenteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte PrÃ¼fungsuhrzeit (Beginn, Ende).\nPrÃ¼fungszeitraum, Aufgabenstellung und sonstige Materialien kÃ¶nnen variieren zwischen den PrÃ¼flingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusÃ¤tzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der PrÃ¼fung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor erhÃ¶ht."
  },
  {
    "objectID": "Pruefung.html#open-book-prÃ¼fungen",
    "href": "Pruefung.html#open-book-prÃ¼fungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.8 Open-Book-PrÃ¼fungen",
    "text": "1.8 Open-Book-PrÃ¼fungen\nEinige PrÃ¼fungen werden als â€œTake-home-PrÃ¼fungâ€ im â€œOpen-Book-Formatâ€ geschrieben. Was bedeutet dies?\nâ€œTake-home-PrÃ¼fungâ€: Sie bearbeiten die PrÃ¼fung in Ihrem privaten Umgebung in Moodle oder in RÃ¤umlichkeiten der Hochschule. Eine Ãœberwachung per Kamera findet nicht statt.\nâ€œOpen-Book-PrÃ¼fungâ€: Sie dÃ¼rfen Hilfsmittel wie BÃ¼cher und Folien wÃ¤hrend der PrÃ¼fung nutzen.\nIhre PrÃ¼ferin/Ihr PrÃ¼fer informiert Sie Ã¼ber das Format Ihrer PrÃ¼fung."
  },
  {
    "objectID": "Pruefung.html#zeitrahmen-der-prÃ¼fung",
    "href": "Pruefung.html#zeitrahmen-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.9 Zeitrahmen der PrÃ¼fung",
    "text": "1.9 Zeitrahmen der PrÃ¼fung\nDie PrÃ¼fung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die PrÃ¼fung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). VerspÃ¤tete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der PrÃ¼fung wird Ihnen von Ihrer PrÃ¼ferin bzw. Ihrem PrÃ¼fer bekannt gegeben."
  },
  {
    "objectID": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prÃ¼fung",
    "href": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.10 Technische und organisatorische Anforderungen einer Open-Book-PrÃ¼fung",
    "text": "1.10 Technische und organisatorische Anforderungen einer Open-Book-PrÃ¼fung\nUm an einer Open-Book-PrÃ¼fung teilzunehmen, benÃ¶tigen Sie IT-Ausstattung sowie RÃ¤umlichkeiten. An IT-Ausstattung benÃ¶tigen Sie einen Computer mit Internetanschluss; ein Smartphone reicht nicht aus. Nutzen Sie Ihr eigenes GerÃ¤t (Computer) fÃ¼r die PrÃ¼fung; die Hochschule stellt Ihnen keinen Computer zur VerfÃ¼gung. Sie benÃ¶tigen keine Webcam und kein Mikrofon. Ein Tablett oder Smartphone reicht nicht fÃ¼r die PrÃ¼fung. An Software benÃ¶tigen Sie Zugang zu Ihrem Moodle-Konto, was einen aktuellen Internet-Browser voraussetzt. Zu den organisatorischen Anforderungen gehÃ¶ren ein Raum, in dem Sie die PrÃ¼fung ungestÃ¶rt bearbeiten kÃ¶nnen sowie ein Internetanschluss zum Bearbeiten der Klausur in Moodle. Bitte benutzen Sie wÃ¤hrend der PrÃ¼fung nicht den ZurÃ¼ck-Button in Ihrem Browser, wenn Sie zu einer vorherigen Frage zurÃ¼ckgehen wollen. Nutzen Sie die in der PrÃ¼fung zur VerfÃ¼gung gestellten Funktionen/Buttons dafÃ¼r."
  },
  {
    "objectID": "Pruefung.html#technische-probleme-wÃ¤hrend-der-prÃ¼fung",
    "href": "Pruefung.html#technische-probleme-wÃ¤hrend-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.11 Technische Probleme wÃ¤hrend der PrÃ¼fung",
    "text": "1.11 Technische Probleme wÃ¤hrend der PrÃ¼fung\nIm Falle eines technischen Problems auf Seiten der PrÃ¼fungsinfrastruktur ist sofort der PrÃ¼fer zu informieren. Ein Beispiel fÃ¼r so ein Problem wÃ¤re etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der PrÃ¼fer bzw. die Hochschule keine GewÃ¤hr Ã¼bernimmt fÃ¼r Probleme mit Ihrer eigenen Ausstattung."
  },
  {
    "objectID": "Pruefung.html#prÃ¼fungsrecht",
    "href": "Pruefung.html#prÃ¼fungsrecht",
    "title": "1Â  PrÃ¼fung",
    "section": "1.12 PrÃ¼fungsrecht",
    "text": "1.12 PrÃ¼fungsrecht\nFÃ¼r die Open-Book-PrÃ¼fungg gilt die aktuelle PrÃ¼fungsordnung; die Open-Book-PrÃ¼fung fÃ¤llt nicht unter die BayFEV."
  },
  {
    "objectID": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "href": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "title": "1Â  PrÃ¼fung",
    "section": "1.13 Bitte formulieren Sie Beanstandungen nachvollziehbar",
    "text": "1.13 Bitte formulieren Sie Beanstandungen nachvollziehbar\nFalls Sie einen Fehler in einer Aufgabenstellung finden (die der PrÃ¼fer zu bestanden hat): Freuen Sie sich! In diesem Fall wird zu Ihren Gunsten entschieden.\nDamit ich Ihre Beanstandung prÃ¼fen kann, ist es nÃ¶tig, dass ich Ihre Beanstandung nachprÃ¼fen kann: Zeigen Sie mir meinen Fehler. Es reicht nicht zu sagen â€œes hat bei mir nicht funktioniertâ€. Wenn Sie etwa der Meinung sind, dass es die Variable â€œyearâ€ im Datensatz â€œpenguinsâ€ nicht gebe, dann schicken Sie mir den R-Code, der an ansprechender Stelle einen Fehler aufwirft (aber ansonsten lauffÃ¤hig ist). Ein Screenshot kann in einigen Situationen helfen, wenn aber nur ein Teil der Syntax zu sehen ist, ist er nicht ausreichend: Wenn der Befehl data(penguins) nicht funktioniert, so ist zu prÃ¼fen, ob Sie vorab mit library(palmerpenguins) das relevante Paket gestartet haben. Andernfalls kann data(penguins) nicht funktionieren und der Fehler lÃ¤ge damit bei Ihnen.\nHier finden Sie Hinweise fÃ¼r einfache, reproduzierbare Beispiele (ERBies); vgl. Sauer (2019), Kap. 3.8.2 (S. 33).\nDie gleiche Messlatte lege ich an mich an: Ich stelle eine MusterlÃ¶sung (bei der Einsichtnahme) zur VerfÃ¼gung, die reproduzierbar die LÃ¶sung aufzeigt. Sprich: Wenn der R-Code bei mir durchlÃ¤uft, so wird er auch bei Ihnen durchlaufen."
  },
  {
    "objectID": "Pruefung.html#datenschutz",
    "href": "Pruefung.html#datenschutz",
    "title": "1Â  PrÃ¼fung",
    "section": "1.14 Datenschutz",
    "text": "1.14 Datenschutz\nPersÃ¶nliche Daten werden an eine Stellen Ã¼bermittelt: Moodle (Ã¼ber bzw. in Ihre Konto). Es findet keine Ãœberwachung statt, weder kamaragestÃ¼tzt, akustisch oder softwaregestÃ¼tzt."
  },
  {
    "objectID": "Pruefung.html#plagiatskontrolle",
    "href": "Pruefung.html#plagiatskontrolle",
    "title": "1Â  PrÃ¼fung",
    "section": "1.15 Plagiatskontrolle",
    "text": "1.15 Plagiatskontrolle\nIhre PrÃ¼fungsarbeiten kÃ¶nnen auf Plagiate hin untersucht werden. Dabei kommen auch automatisierte Verfahren zum Einsatz. Ihre Arbeiten werden dabei nicht online gestellt und auch nicht Dritten zugÃ¤nglich gemacht. Alle PrÃ¼fungen finden auf Rechnern statt, zu denen nur die PrÃ¼fer/innen Zugang habe. Es werden keine persÃ¶nlichen Daten (von Ihnen) weitergegeben.\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Ãœberlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getÃ¤uscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafÃ¼r bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit â€œnicht bestandenâ€ bewertet). Die genauen Konsequenzen legt die PrÃ¼fungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire PrÃ¼fung heiÃŸt: Gleiche Chancen fÃ¼r alle, und gute Leistung soll belohnt werden, TÃ¤uschung nicht."
  },
  {
    "objectID": "Pruefung.html#typische-fehler-in-der-prÃ¼fung",
    "href": "Pruefung.html#typische-fehler-in-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.16 Typische Fehler in der PrÃ¼fung",
    "text": "1.16 Typische Fehler in der PrÃ¼fung\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heiÃŸt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heiÃŸt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter â€œEnvironmentâ€ angezeigt wird. AuÃŸerdem kÃ¶nnen Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort kÃ¶nnen Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das zugehÃ¶rige R-Paket gestartet zu haben: Mit data(datensatz) kÃ¶nnen Sie den Datensatz datensatz nur dann verfÃ¼gbar machen, wenn das Paket, in dem datensatz â€œwohntâ€, mit library(paketname) gestartet worden ist. So â€œwohntâ€ z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Ãœbung (und weitere ErklÃ¤rung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins.\nVerwenden einer Funktion, ohne das zugehÃ¶rige R-Paket vorab gestartet zu haben.\nDas Laden zu vieler R-Pakete, die gar nicht benÃ¶tigt werden, mit dem Ergebnis, dass es mehrere Funktionen des gleichen Namens gibt (z.B. filter()). Das fÃ¼hrt dann zu Verwirrung, da dann z.B. nicht die Funktion filter aus tidyverse (dplyr) verwendet wird, wie Sie annehmen, sondern eine Funktion gleichen Namens aus einem anderen Paket, das Sie auch gestartet haben. Tipp: Starten Sie nur die Pakete, die Sie fÃ¼r die Aufgabe benÃ¶tigen. Zumeist sind das immer die gleichen wenigen Pakete."
  },
  {
    "objectID": "Pruefung.html#hinweise-zu-scheinmÃ¤ngeln",
    "href": "Pruefung.html#hinweise-zu-scheinmÃ¤ngeln",
    "title": "1Â  PrÃ¼fung",
    "section": "1.17 Hinweise zu ScheinmÃ¤ngeln",
    "text": "1.17 Hinweise zu ScheinmÃ¤ngeln\nImmer wieder kommt es vor, dass Studierende Beanstandungen zu einer PrÃ¼fung vorbringen. Teilweise sind diese gerechtfertigt, teilweise nicht. Im Folgenden sehen Sie eine Auswahl an nicht gerechtfertigten Beanstandungen, also nur scheinbaren MÃ¤ngeln, keine wirklichen MÃ¤ngel, in einer PrÃ¼fung.\n\nâ€œDas zu wÃ¤hlende Vorgehen war nicht 100% klarâ€ â€“ Wenn Sie der Meinung sind, dass das zu wÃ¤hlende Vorgehen (zum LÃ¶sen der Aufgabe) nicht komplett klar ist, treffen Sie Annahmen und weisen Sie darauf hin, dass Sie Annahmen getroffen haben. Zum anderen halten Sie sich an das Vorgehen aus dem Unterricht (bzw. den Unterlagen und der Literatur, die im Unterricht verwendet wurde). Eine andere Situation lÃ¤ge vor, wenn die Aufgabe nicht lÃ¶sbar ist ohne weitere Angaben lÃ¶sbar ist(â€œIst ein Effekt bei n=100 signifikant?â€). Im Falle einer nicht lÃ¶sbaren Aufgabe liegt fer Fehler beim PrÃ¼fer.\nâ€œIch sollte einen Punkt (ein Komma) als Dezimaltrennzeichen verwenden, aber Moodle hat ein Komma (einen Punkt) verlangt!â€ â€“ Je nach Spracheinstellung in Moodle kann es sein, dass Moodle nur einen Punkt als Dezimaltrennzeichen bzw. ein Komma als Dezimaltrennzeichen verwendet. Moodle weist Sie aber darauf hin, wenn eine Zahl nicht als Zahl erkannt wird, und zwar wenn Sie zur nÃ¤chsten Aufgabe geben. Sie kÃ¶nnen also ohne Probleme den Fehler korrigieren. DarÃ¼ber hinaus ist bei den PrÃ¼fungshinweisen vorab auf diesen Punkt verwiesen."
  },
  {
    "objectID": "Inferenz.html#lernsteuerung",
    "href": "Inferenz.html#lernsteuerung",
    "title": "2Â  Inferenz",
    "section": "2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Definition von Inferenzstatistik sowie Beispiele fÃ¼r inferenzstatistische Fragestellungen nennen\nzentrale Begriffe nennen und in GrundzÃ¼gen erklÃ¤ren\nden Nutzen von Inferenzstatistik nennen\nerlÃ¤utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nauch anhand von Beispielen erklÃ¤ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs.Â Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklÃ¤ren kÃ¶nnen\n\n\n\n2.1.2 Begleitvideos\n\nVideo zur Inferenz, Teil 1\nVideo zur Inferenz, Teil 2"
  },
  {
    "objectID": "Inferenz.html#wozu-ist-statistik-Ã¼berhaupt-da",
    "href": "Inferenz.html#wozu-ist-statistik-Ã¼berhaupt-da",
    "title": "2Â  Inferenz",
    "section": "2.2 Wozu ist Statistik Ã¼berhaupt da?",
    "text": "2.2 Wozu ist Statistik Ã¼berhaupt da?\nJa, diese Frage haben Sie sich auch schon mal gestellt?\nAbb. AbbildungÂ 2.1 gibt einen Ãœberblick Ã¼ber die Ziele der Statistik.\n\n\n\n\n\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n\n\n\n\n\nAbbildungÂ 2.1: A taxonomy of statistical goals\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nZiele existieren nicht â€œin echtâ€ in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heiÃŸt, dass man sich nach Beliebem Ziele ausdenken kann. Allerdings hÃ¼lfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen Ã¼berzeugen kann."
  },
  {
    "objectID": "Inferenz.html#was-ist-inferenz",
    "href": "Inferenz.html#was-ist-inferenz",
    "title": "2Â  Inferenz",
    "section": "2.3 Was ist Inferenz?",
    "text": "2.3 Was ist Inferenz?\n\n2.3.1 Inferenz als Generalisieren\nStatistische Inferenz sieht sich drei â€œHerausforderungenâ€ gegenÃ¼ber, laut Gelman, Hill, und Vehtari (2021), Kap. 1.1. Diese betreffen das SchlieÃŸen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\nVon der Stichprobe aus die Grundgesamtheit (Population)\nVon der Experimental- auf die Kontrollgruppe (Kausalinferenz)\nVon einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs beschÃ¤ftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n\n\n\nWichtig\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlieÃŸen, bzw. vom Konrketen auf das Abstrakte."
  },
  {
    "objectID": "Inferenz.html#stichprobe-vs.-population",
    "href": "Inferenz.html#stichprobe-vs.-population",
    "title": "2Â  Inferenz",
    "section": "2.4 Stichprobe vs.Â Population",
    "text": "2.4 Stichprobe vs.Â Population\nNehmen wir an, wir mÃ¶chten herausfinden, wie groÃŸ der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A1.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\nWir mÃ¼ssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe fÃ¼r die Grundgesamtheit schlieÃŸen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. AbbildungÂ 2.2.\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nAbbildungÂ 2.2: Population vs.Â sample (Image credit: Karsten Luebke)\n\n\nHÃ¤ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!2. Man schreibt: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei reprÃ¤sentativ fÃ¼r die Grundgesamtheit aller Studierender. Messerscharf schlieÃŸen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n2.4.1 Deskriptiv- vs.Â Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtungen, kÃ¶nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. AbbildungÂ 2.3. Einteilungen in Schubladen existieren nicht auf der Welt, sondern in unserem Kopf: Sie besitzen keine ontologische RealitÃ¤t, sondern eine epistemologische. Sie sind frei, sich andere Einteilungen der Statistik auszudenken. Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee Ã¼berzeugen kann.\n\n\n\nAbbildungÂ 2.3: Deskriptiv- vs.Â Inferenzstatistik\n\n\nDeskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\nInferenzstatistik schlieÃŸt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\nğŸ‹ SchlieÃŸen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n2.4.2 Wozu ist die Inferenstatistik gut?\n\n\n\n\n\n\nHinweis\n\n\n\nInferenz bedeutet SchlieÃŸen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine SchlÃ¼sse zu ziehen.\nğŸ‹ï¸ï¸ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Ãœben Sie jetzt schon mal.\n\n\n2.4.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFÃ¼r jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle TabelleÂ 2.1.\n\n\n\n\nTabelleÂ 2.1: Bezeichnungen fÃ¼r Kennwerte\n\n\nKennwert\nStichprobe\nGrundgesamtheit\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\n\n\n\n\n\nFÃ¼r Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; fÃ¼r Parameter (Population) verwendet man griechische Buchstaben.\nğŸ‹ï¸ Geben Sie die griechischen Buchstaben fÃ¼r typische Statistiken an!\n\n\n2.4.4 SchÃ¤tzen von Parametern einer Grundgesamtheit\nMeist begnÃ¼gt man sich beim Analysieren von Daten nicht mit Aussagen fÃ¼r eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit SchÃ¤tzungen begnÃ¼gen.\nSchÃ¤tzwerte werden mit einem â€œDachâ€ Ã¼ber dem Kennwert gekennzeichnet, z.B.\n\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchÃ¤tzwert\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n2.4.5 Beispiele fÃ¼r inferenzstatistische Fragestellungen\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.Â V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\).\nDie Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} > \\bar{X}_{V2}\\)\nSind diese Unterschiede â€œzufÃ¤lligâ€ oder â€œsubstanziellâ€? Gilt also \\(\\mu_{V1} > \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)?\nWie groÃŸ ist die Wahrscheinlichkeit3 \\(Pr(\\mu_{V1} > \\mu_{V2})\\)?\n\nğŸ‹ï¸ Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!"
  },
  {
    "objectID": "Inferenz.html#modellieren",
    "href": "Inferenz.html#modellieren",
    "title": "2Â  Inferenz",
    "section": "2.5 Modellieren",
    "text": "2.5 Modellieren\n\n2.5.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft - wie auch oft in der Technik, Wirtschaft oder im Alltag - betrachtet man einen Teil der Welt nÃ¤her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berÃ¼cksichtigen ist nicht mÃ¶glich. Wir mÃ¼ssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nÃ¶tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die fÃ¼r unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\n\n\n\n\n\nWichtig\n\n\n\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n\n\nAuf die Statistik bezogen heiÃŸt das, dass man einen Datensatz zu zusammenfasst, dass man das Wesentliche erkennt. Was ist das â€œWesentlicheâ€? Meist interessiert man sich fÃ¼r die Ursachen eines PhÃ¤nomens? Etwa: â€œWie kommt es bloÃŸ, dass ich ohne zu lernen die Klausur so gut bestanden habe?â€4 Noch allgemeiner ist vom hÃ¤ufig am Zusammenhang von X und Y interessiert, s. AbbildungÂ 2.4, linker Teil, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\n\nflowchart LR\nX --> Y\n\n\nX1 --> Y2\nX2 --> Y2\n\n\n\n\n\n\n\n\nAbbildungÂ 2.4: oben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\nDas Diagramm hat Sie nicht so vom Hocker? Okay, ein statistisches Modell kann natÃ¼rlich komplexer sein, z.B. wie in Abb. AbbildungÂ 2.4, rechter Teil, dargestellt.\nEs hÃ¶rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n\n2.5.2 Vertiefung\nLesen Sie die EinfÃ¼hrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nHinweis\n\n\n\nNutzen Sie die Ãœbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch."
  },
  {
    "objectID": "Inferenz.html#regression",
    "href": "Inferenz.html#regression",
    "title": "2Â  Inferenz",
    "section": "2.6 Regression",
    "text": "2.6 Regression\nEinflussreiche Leute schwÃ¶ren auf die Regressionsanalyse (AbbildungÂ 2.5).\n\n\n\nAbbildungÂ 2.5: One regression\n\n\n\n2.6.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmessen: FÃ¼r vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schÃ¶ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nHinweis\n\n\n\nRegression + Inferenz = ğŸ’–\n\n\nAlternativ zur Regression kÃ¶nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni MÃ¼nster als Ausschnitt (!) aufgefÃ¼hrt.\nAuf dieser Basis kann man meditieren, welches statistischen Verfahren man fÃ¼r eine bestimmte Fragestellung verwenden sollte, s. Abb. AbbildungÂ 2.6.\n\n\n\nAbbildungÂ 2.6: WÃ¤hle deine Statistik mit Bedacht\n\n\n\n\n2.6.2 Viele statistische Verfahren sind SpezialfÃ¤lle der Regression\nWie Jonas Kristoffer LindelÃ¸v uns erklÃ¤rt, sind viele statistische Verfahren, wie der sog. t-Test SpezialfÃ¤lle der Regression, s. Abb. AbbildungÂ 2.7.\n\n\n\nAbbildungÂ 2.7: Common statistical tests as linear models\n\n\n\n\n2.6.3 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; Abb. AbbildungÂ 2.8.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nAnhan der Gleichung erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet. Dabei wird X nicht mit â€œfortgeschrittenenâ€ Transformationen wie Quadradieren oder Exponenzieren beglÃ¼ckt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n\n\n\nAbbildungÂ 2.8: Die Regressionsgerade in voller Pracht"
  },
  {
    "objectID": "Inferenz.html#unsicherheit",
    "href": "Inferenz.html#unsicherheit",
    "title": "2Â  Inferenz",
    "section": "2.7 Unsicherheit",
    "text": "2.7 Unsicherheit\n\n2.7.1 Inferenz beinhaltet Unsicherheit\nInferenzstatistische SchlÃ¼sse sind mit Unsicherheit behaftet: SchlieÃŸlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), mÃ¶chte aber vom Teil auf das Ganze schlieÃŸen.\n\n\n\n\n\n\nWichtig\n\n\n\nNichts Genaues weiÃŸ man nicht: SchlieÃŸt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen Ã¼ber das Ganze betrifft.\n\n\nSchlieÃŸt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. SchlieÃŸlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen fÃ¼r die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer mÃ¶glich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n\n\n\n\n\nHinweis\n\n\n\nUnter einem zufÃ¤lligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nÃ¤chsten WÃ¼rfelwurfs. ZufÃ¤llig bedeutet nicht (zwangslÃ¤ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines WÃ¼rfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\nğŸ‹ Welche physikalischen Randbedingungen wirken wohl auf einen MÃ¼nzwurf ein?\n\n\n2.7.2 Beispiele zur Quantifizierung von Ungewissheit\nAussagen mit Unsicherheit kÃ¶nnen unterschiedlich prÃ¤zise formuliert sein.\n\nMorgen regnetâ€™s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert fÃ¼r Methode \\(A\\) hÃ¶her als fÃ¼r Methode \\(B\\).\nDie Maschine fÃ¤llt demnÃ¤chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nÃ¤chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\nğŸ‹ Geben Sie weitere Beispiele an!\n\n\n2.7.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. AbbildungÂ 2.9.\n\nWie (un)gewiss ist man sich Ã¼ber den Wert des Regressionsgewichts?\nWie (un)gewiss ist man sich Ã¼ber den Wert von Y? SchlieÃŸlich kÃ¶nnte es ja EinflÃ¼sse (X) geben, die man nicht berÃ¼cksichtigt hat.\n\n\n\n\n\n\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 Ã¼bersehen? .-> B\n\n\n\n\n\n\nAbbildungÂ 2.9: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n\n2.7.4 Ich weiÃŸ, was ich nicht weiÃŸ: Ungewissheit angeben\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der SchÃ¤tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schÃ¤tzt, lÃ¤sst aber offen wie sicher (prÃ¤zise) die SchÃ¤tzung ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die SchÃ¤tzung schlieÃŸt sogar 41% oder 43% aus.\n\n\n\n\n\n\nWichtig\n\n\n\nEine Inferenz nennt man auch SchÃ¤tzung. Es sollte immer die Genauigkeit (Ungewissheit) der SchÃ¤tzung angegeben werden.\n\n\nIm Rahmen der Regressionsanalyse schlÃ¤gt sich die Ungewissheit an zwei Stellen nieder:\n\nzur Lage der Regressionsgeraden (\\(\\beta_0\\), \\(\\beta_1\\))\nzu EinflÃ¼ssen (X), die unser Modell nicht kennt (\\(\\epsilon, \\sigma\\))\n\n\n\n2.7.5 Visualisierung von Ungewissheit\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem PunktschÃ¤tzer. PunktschÃ¤ter beinhalten keine Angabe der SchÃ¤tz(un)gen auigkeit, s. Abb. AbbildungÂ 2.10, links.\n\n\n\n\n\nAbbildungÂ 2.10: Eine PunktschÃ¤tzung und ihre Ungewissheit\n\n\n\n\nRot markiert: Die PunktschÃ¤tzung von mpg fÃ¼r hp=200.\nğŸ‹ Geben Sie ein vergleichbares Beispiel an!\nIn Abb. AbbildungÂ 2.10, rechts, ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur StÃ¤rke des Zusammenhangs von X und Y?\nAuch wenn wir uns sicher im Hinblick auf die Regressionsgewichte in Abb. AbbildungÂ 2.11 bliebe eine Restungewissheit: Unsere SchÃ¤tzungen wÃ¤ren auch dann nicht sicher, nicht fehlerfrei. Das liegt daran, da das Modell nicht alle EinflÃ¼sse auf Y berÃ¼cksichtigt, sondern nur einen, hier als X bezeichnet.\nIn Abb. AbbildungÂ 2.11 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die â€œRestungewissheitâ€ dargestellt. In diesem Fall spricht man von einem â€œVorhersageintervallâ€, da man nicht nur von â€œtypischen FÃ¤llenâ€ auf der Regressiongeraden spricht, sondern fÃ¼r echte FÃ¤lle Vorhersagen (SchÃ¤tzungen) tÃ¤tigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n\n\n\nAbbildungÂ 2.11: Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\n\n\n\n\nWie man sieht, wird die Ungewissheit grÃ¶ÃŸer, wenn man beide Arten der Ungewissheit berÃ¼cksichtigt. Das Vorhersage-Intervall berÃ¼cksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\n\n2.7.6 Konfidenzintervall\nWir sehen hier, dass ein â€œUngewissheitskorridorâ€ angegeben wird. Entsprechend wird nicht ein PunktschÃ¤tzer, sondern ein SchÃ¤tzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich5\nEin Konfidenzintervall wird hÃ¤ufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse ist das einfach zu interpretieren. Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall fÃ¼r den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt. Dieser Befund lÃ¤ÃŸt sich so interpretieren: â€œLaut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.â€\n\n\n\n\n\n\nWichtig\n\n\n\nEin Konfidenzintervall gibt einen SchÃ¤tzbereich plausibler Werte fÃ¼r den gesuchten Wert in der Population (den Parameter) an.\n\n\nğŸ‹ Interpretieren Sie den Ungewissheitskorridor!"
  },
  {
    "objectID": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "2Â  Inferenz",
    "section": "2.8 Klassische vs.Â Bayes-Inferenz",
    "text": "2.8 Klassische vs.Â Bayes-Inferenz\n\n2.8.1 Klassische Inferenz: Frequentismus\n\nDie BerÃ¼cksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurÃ¼ckgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein\nWahrscheinlichkeit wird Ã¼ber relative HÃ¤ufigkeiten definiert.\nEs ist nicht mÃ¶glich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie hÃ¤ufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr hÃ¤ufig wiederholt ist.\nEin GroÃŸteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.8.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) flieÃŸt explizit in die Analyse ein (zusammen mit den Daten).\nWenn das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen fÃ¼r Hypothesen mÃ¶glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (fÃ¼r gÃ¤ngige Computer) komfortabel geworden.\n\n\n\n2.8.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.8.3.1 Frequentismus\nDie zentrale Statistik heiÃŸt der p-Wert\nDer p-Wert ist so definiert: â€œWie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufÃ¤llig verschieden und auf Basis unseres Modells)?â€\nFindet man \\(p<.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von â€œ(statistischer) Signifikanzâ€ und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n\n2.8.3.2 Bayes-Statistik\nDie zentrale Statistik ist die Posteriori-Verteilung.\nDie Posteriori-Verteilung beantwortet uns die Frage: â€œWie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?â€\nğŸ‹ Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\nIn diesem Post wird fÃ¼r Bayes geworben und (vielleicht einseitig) Stellung pro Bayes bezogen.\n\n\n\n2.8.4 Frequentist und Bayesianer\nIm Cartoon 1132 von xkcd wird sich Ã¼ber das Nicht-BerÃ¼cksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. AbbildungÂ 2.12.\n\n\n\nAbbildungÂ 2.12: Frequentist wettet mit Bayesianer\n\n\nQuelle\n\n\n2.8.5 Der p-Wert ist wenig intuitiv\n\n\nfrom Imgflip Meme Generator\n\n\n\n2.8.6 Beispiel zum Nutzen von Apriori-Wissen 1\nEin Betrunkener behauptet, er kÃ¶nne hellsehen. Er wirft eine MÃ¼nze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die MÃ¼nze fair ist, dass Ergebnis also â€œzufÃ¤lligâ€ ist.\nUnser Vorwissen lÃ¤sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der ZufÃ¤lligkeit des Ergebnisses wohl nicht verwerfen.\n\n\n2.8.7 Beispiel zum Nutzen von Apriori-Wissen 2\nEine Studie (vgl. Gelman, Hill, und Vehtari (2021)) fand einen â€œgroÃŸen Effektâ€ auf das Einkommen von Babies, eine Stunde pro Woche wÃ¤hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\).\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% hÃ¶her (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lÃ¤sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lÃ¤sst. Wir wÃ¼rden den Effekt lieber in einem konservativeren Intervall schÃ¤tzen (enger um Null)."
  },
  {
    "objectID": "Inferenz.html#literatur",
    "href": "Inferenz.html#literatur",
    "title": "2Â  Inferenz",
    "section": "2.9 Literatur",
    "text": "2.9 Literatur\nBei Gelman, Hill, und Vehtari (2021), Kap. 1 findet sich eine Darstellung Ã¤hnlich zu der in diesem Kapitel."
  },
  {
    "objectID": "Inferenz.html#aufgaben",
    "href": "Inferenz.html#aufgaben",
    "title": "2Â  Inferenz",
    "section": "2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2\ninferenz-fuer-alle\nadjustieren1\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  },
  {
    "objectID": "Wskt.html#lernsteuerung",
    "href": "Wskt.html#lernsteuerung",
    "title": "3Â  Wahrscheinlichkeit",
    "section": "3.1 Lernsteuerung",
    "text": "3.1 Lernsteuerung\n\n3.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erlÃ¤uternd definieren\ndie drei Arten der direkten Ermittlung von Wahrscheinlichkeit erlÃ¤utern\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n\n\n3.1.2 PrÃ¼fungsrelevanter Stoff\nLesen Sie dazu Bourier (2018), Kap. 2-4. Weitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n\n3.1.3 Zentrale Begriffe\n\n3.1.3.1 Grundbegriffe\n\nZufallsvorgang (Zufallsexperiment)\nElementarereignis\nEreignisraum\nZufallsereignis (zufÃ¤lliges Ereignis)\nSicheres Ereignis\nUnmÃ¶gliches Ereignis\n\n\n\n3.1.3.2 Wahrscheinlichkeitsbegriffe\n\nKlassische Wahrscheinlichkeit (LaPlaceâ€™sche Wahrscheinlichkeit)\nStatistische (empirische) Wahrscheinlichkeitsermittlung\nSubjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n\n\n3.1.3.3 Wahrscheinlichkeitsrelationen\n\nVereinigung von Ereignissen\nSchnitt(menge) von Ereignissen\nKomplementÃ¤rereignis\nVollstÃ¤ndiges Ereignissystem\nKolmogorovs Definition von Wahrscheinlichkeit\n\n\n\n3.1.3.4 Wahrscheinlichkeitsrechnung\n\nAllgemeiner Additionsssatz\nDisjunkte Ereignisse\nAdditionssatz fÃ¼r disjunkte Ereignisse\nBedingte Wahrscheinlichkeit\n(Stochastische) UnabhÃ¤ngigkeit\nBaumdiagramm fÃ¼r gemeinsame Wahrscheinlichkeit\nAllgemeiner Multiplikationssatz\nMultiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse\nTotale Wahrscheinlichkeit\nSatz von Bayes\n\n\n\n\n3.1.4 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit"
  },
  {
    "objectID": "Wskt.html#unterstÃ¼tzung-wahrscheinlichkeit-in-bildern",
    "href": "Wskt.html#unterstÃ¼tzung-wahrscheinlichkeit-in-bildern",
    "title": "3Â  Wahrscheinlichkeit",
    "section": "3.2 UnterstÃ¼tzung: Wahrscheinlichkeit in Bildern",
    "text": "3.2 UnterstÃ¼tzung: Wahrscheinlichkeit in Bildern\nWahrscheinlichkeit in Bildern: zur einfachen ErschlieÃŸung des Materials, ein UnterstÃ¼tzungsangebot.\nIm Folgenden sind einige SchlÃ¼sselbegriffe und -regeln in (ver-)einfach(t)er Form schematisch bzw. visuell dargestellt mit dem Ziel, den Stoff einfacher zu erschlieÃŸen.\n\n3.2.1 Zufall\nWerfen Sie eine MÃ¼nze!\nDiese hier zum Beispiel:\n\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10, nein, 100, nein 1000, nein: \\(10^6\\) Mal.\nNotieren Sie das Ergebnis!\nOder probieren Sie die App der Brown University.\n\n\n3.2.2 Relationen von Mengen\nVenn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren.\n\n3.2.2.1 Ãœberblick\nDie folgenden Diagramme stammen von Wikipedia (En).\nWir gehen von Ereignisraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge: \\(A \\subset B\\).\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\n\n\n\n\n\n\n\\(A \\cup B\\)\n\n\n\n\n\n\n\n\n\n\\(\\bar{A}\\)\n\n\n\n\n\n\n\n\\(A \\setminus B\\)\n\n\n\n\nAbbildungÂ 3.1: Typische Mengenoperationen\n\n\n\n\n3.2.2.2 Disjunkte Ereignisse\n(Engl. disjoint events)\n\\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\)\n\\(A\\) und \\(B\\) sind disjunkt: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. ?fig-disjunkt\n\n\n\n\n\n\n\n3.2.2.3 EselsbrÃ¼cke zur Vereinigungs- und Schnittmenge\nDas Zeichen fÃ¼r eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen fÃ¼r einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine EselbrÃ¼cke gelesen, s. AbbildungÂ 3.2.\n\n\n\nAbbildungÂ 3.2: EselsbrÃ¼cke fÃ¼r Vereinigungs- und Schnittmenge\n\n\nQuelle: rither.de\n\n\n3.2.2.4 Animationen\nAnimation zu Mengenoperationen\nAnimation zur Vereinigung von Mengen\nQuelle\n\n\n\n3.2.3 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse eintritt.\n\n3.2.3.1 Diskunkte Ereignisse\n\\(\\Omega = {1,2,3,4,5,6}\\)\n\\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\)\nGesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\).\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\n\\(P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\n\n3.2.3.2 Allgemein (disjunkt oder nicht disjunkt)\nBei der Addition der Wahrscheinlichkeiten fÃ¼r \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) doppelt erfasst. Er muss daher noch abgezogen werden (vgl. AbbildungÂ 3.3):\n\\[P(A \\cup B) = P(A) + P(B) - P(A\\cap B)\\]\n\n\n\n\n\n\n\n\\(A \\cup B\\)\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\n\n\n\nAbbildungÂ 3.3: Die Schnittmenge muss beim Vereinigen abgezogen werden, damit sie nicht doppelt gezÃ¤hlt wird.\n\n\n\n\n\n3.2.4 Bedingte Wahrscheinlichkeit\n\n3.2.4.1 Animation\nSchauen Sie sich mal diese Wahnsinnsanimation von Victor Powell an. Hammer!\n\n\n3.2.4.2 Schema\nAbb. AbbildungÂ 3.4 illustriert gemeinsame Wahrscheinlichkeit, $P(A B) und bedingte Wahrscheinlichkeit, \\(P(A|B)\\).\n\n\n\n\n\nAbbildungÂ 3.4: Illustration von gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\n\nBedingte Wahrscheinlichkeit ist vergleichbar zu Filtern einer Tabelle:\n\n\nCode\nd <- \n  tibble::tribble(\n      ~id, ~A, ~B,\n      \"1\", 0L, 0L,\n      \"2\", 0L, 1L,\n      \"3\", 1L, 0L,\n      \"4\", 1L, 1L,\n  \"SUMME\", 2L, 2L\n  )\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(P(A) = 2/4\\)\n\\(P(B) = 2/4\\)\n\\(P(A \\cap B) = 1/4\\)\n\\(P(A|B) = 1/2\\)\n\n\n\n3.2.5 (Un-)AbhÃ¤ngigkeit\nStochastische UnabhÃ¤ngigkeit ist ein Spezialfall von AbhÃ¤ngigkeit: Es gibt sehr viele AusprÃ¤gungen fÃ¼r AbhÃ¤ngigkeit, aber nur eine fÃ¼r UnabhÃ¤ngigkeit. KÃ¶nnen wir UnabhÃ¤ngigkeit nachweisen, haben wir also eine starke Aussage getÃ¤tigt.\n\n\n\nAbhÃ¤ngig, s. AbbildungÂ 3.5, links: Ãœberleben auf der Titanic ist offenbar abhÃ¤ngig von der Passagierklasse. Auf der anderen Seite: Das Ereignis Ãœberleben auf der Titanic ist unabhÃ¤ngig vom Ereignis Alter ist eine Primzahl, s. AbbildungÂ 3.5, rechts.\n\n\n\n\n\nAbbildungÂ 3.5: AbhÃ¤ngigkeit und UnabhÃ¤ngigkeit zweier Ereignisse\n\n\n\n\nZur Ab- bzw. Un-AbhÃ¤ngigkeit zweier Variablen, an Beispielen illustriert.\n\nBeispiel 3.1 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land1 (\\(B\\)) voneinander abhÃ¤ngig (Abb. AbbildungÂ 3.6)?\n\n\n\n\n\nAbbildungÂ 3.6: Impfquote und Sterblichkeit sind voneinander abhÃ¤ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\n\n\nJa, da in beiden Diagrammen gilt: \\(P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\nDaten von Our World in Data.\n\n\n\n3.2.6 Multiplikationssatz\nDer Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass alle Ereignisse eintreten.\n\n3.2.6.1 UnabhÃ¤ngige Ereignisse\nWir werfen eine faire MÃ¼nze zwei Mal (Abb. AbbildungÂ 3.7).\n\n\n\nAbbildungÂ 3.7: Wir werfen 2 faire MÃ¼nzen\n\n\nAbb. AbbildungÂ 3.7 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom â€œStartâ€ (schwarzer Kreis) fÃ¼hren zwei mÃ¶gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch BlÃ¤tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen MÃ¼nzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der BlÃ¤tter. In diesen Diagramm gibt es vier Pfade (und BlÃ¤tter).\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\nWir werfen eine faire MÃ¼nze drei Mal (Abb. AbbildungÂ 3.8)\n\n\n\nAbbildungÂ 3.8: Wir werfen drei faire MÃ¼nzen\n\n\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n\n0K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n1K\n1/8 + 1/8 + 1/8 = 3/8\n\n\n2K\n3 * 1/8 = 3/8\n\n\n3K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n\n\n\n\n\\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%\\)\n\n\n\n\n\nAbbildungÂ 3.9: UnabhÃ¤ngige Ereignisse visualisiert\n\n\n\n\nAbb. AbbildungÂ 3.9 zeigt, dass gilt: \\(P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\).\n\n\n3.2.6.2 Kalt und Regen\nVon McElreath (2020) stammt diese Verdeutlichung der gmeinsamen Wahrscheinlichkeit:\nWas ist die Wahrscheinlichkeit fÃ¼r kalt â„ und Regen â›ˆï¸?\nDie Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von Regen â›ˆ, wennâ€™s kalt â„ ist mal die Wahrscheinlichkeit von KÃ¤lte â„.\nEbenfalls gilt:\nDie Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von KÃ¤lte â„, wennâ€™s regnet â›ˆï¸ mal die Wahrscheinlichkeit von Regen â›ˆï¸.\nDas Gesagte als Emoji-Gleichung:\n\\(P(â„ï¸ und â›ˆï¸) = P(â›ˆï¸ |â„ï¸ ) \\cdot P(â„ï¸) = P(â„ï¸ |â›ˆï¸ ) \\cdot P(â›ˆï¸) = P(â›ˆï¸ und â„ï¸)\\)\nAllgemein:\n\\(P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\nMan kann also die â€œGleichung drehenâ€.\n\n\n3.2.6.3 AbhÃ¤ngige Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung abhÃ¤ngiger Ereignisse an, s. Abb. AbbildungÂ 3.10. FÃ¼r unabhÃ¤ngige Ereignisse Ã¼brigens auch.\nIn einer Urne befinden sich fÃ¼nf Kugeln, von denen vier rot sind und eine blau ist.\nwie groÃŸ ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne ZurÃ¼cklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier 2018), S. 47.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. Abb. AbbildungÂ 3.10.\n\n\n\n\n\nflowchart LR\n  A[Start] -->|4/5|B[1. Zug: R]\n  A -->|1/5|C[1. Zug: B]\n  B -->|3/4|D[2. Zug: R]\n  B -->|1/4|E[2. Zug: B]\n  D --- H[Fazit: RR:  12/20]\n  E --- I[Fazit: RB: 4/20]\n  C -->|4/4|F[2. Zug: R]\n  C -->|0/4|G[2. Zug: B]\n  F --- J[Fazit: BR: 4/20]\n  G --- K[Fazit: BB: 0/20]\n\n\n\n\n\nAbbildungÂ 3.10: Baumdiagramm fÃ¼r ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abhÃ¤ngig ist vom 1. Zug.\n\n\n\n\nEs gilt also: \\(P(A\\cap B) = P(A) \\cdot P(B|A)\\).\n\n\n\n3.2.7 Totale Wahrscheinlichkeit\nAbbildungÂ 3.11 zeigt das Baumdiagramm fÃ¼r die Aufgabe Bourier (2018), S. 56.\n\n\n\n\n\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -->|0.1|C[A2]\n  A -->|0.3|D[A3]\n  B -->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n\n\n\n\n\nAbbildungÂ 3.11: Totale Wahrscheinlichkeit\n\n\n\n\nGesucht ist die Wahrscheinlichkeit \\(P(B)\\).\nDazu addieren wir die Warhscheinlichkeiten der relevanten Ã„ste.\n\n\nCode\nW_total <- 0.6 * 0.05 + 0.1 * 0.02 + 0.3 * 0.04\nW_total\n## [1] 0.044\n\n\nDie totale Wahrscheinlichkeit betrÃ¤gt also \\(P(B) = 4.4\\%\\).\nEinfacher noch ist es, wenn man anstelle von Wahrscheinlichkeiten absolute HÃ¤ufigkeiten verwendet.\n\n\n3.2.8 Bayes\n\n3.2.8.1 Bayes als Baum\nGesucht sei \\(P(A_1|B)\\).\nFÃ¼r Bayesâ€™ Formel setzt man die Wahrscheinlichkeit des gÃ¼nstigen Ast zur Wahrscheinlichkeit aller relevanten Ã„ste, \\(P(B)\\).\nDer gÃ¼nstige Ast ist hier schwarz gedruckt, die Ã¼brigen Ã„ste gestrichelt, s. AbbildungÂ 3.12.\n\n\n\n\n\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -.->|0.1|C[A2]\n  A -.->|0.3|D[A3]\n  B --->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -.->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -.->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n\n\n\n\n\nAbbildungÂ 3.12: GÃ¼nstige Pfade\n\n\n\n\n\\[P(A|B) = \\frac{P(A1 \\cap B)}{P(B)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(P(A|B)\\) betrÃ¤gt also ca. 68%.\nZur Erinnerung: \\(P(B)\\) ist die totale Wahrscheinlichkeit."
  },
  {
    "objectID": "Wskt.html#bayes-theorem",
    "href": "Wskt.html#bayes-theorem",
    "title": "3Â  Wahrscheinlichkeit",
    "section": "3.3 Bayesâ€™ Theorem",
    "text": "3.3 Bayesâ€™ Theorem\n\n3.3.1 Bayes als bedingte Wahrscheinlichkeit\nBayesâ€™ Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:\n\\(P(A|B) = \\frac{\\overbrace{ P(A\\cap B)}^\\text{umformen}}{P(B)}\\)\n\\(P(A\\cap B)\\) kann man umformen, s. GleichungÂ 3.1:\n\\[P(A|B) =\\frac{P(A\\cap B)}{P(B)} = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\tag{3.1}\\]\nMan kann sich Bayesâ€™ Theorem auch wie folgt herleiten:\n\\(P(A\\cap B) = P(B \\cap A) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\nDann lÃ¶sen wir nach P\\((A|B)\\) auf:\n\\(P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(B)}\\)\n\n\n3.3.2 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes hÃ¤ufig, wenn man Daten zu einer Wirkung \\(W\\) hat, und auf die Ursache \\(U\\) zurÃ¼ckschlieÃŸen mÃ¶chte, sinngemÃ¤ÃŸ:\n\\(W \\quad \\underrightarrow{Bayes} \\quad U\\).\nDann kann man GleichungÂ 3.1 so schreiben, s. GleichungÂ 3.2:\n\\[P(U|W) = \\frac{ P(U) \\cdot P(W|U) }{P(W)} \\tag{3.2}\\]\nEine Ã¤hnliche Situation, die in der Praxis hÃ¤ufig ist, dass man Daten \\(D\\) hat und auf die Wahrscheinlichkeit einer Hypothese \\(H\\) schlieÃŸen mÃ¶chte, s. GleichungÂ 3.3.\n\\(D \\quad \\underrightarrow{Bayes} \\quad H\\).\n\\[P(H|D) = \\frac{ P(H) \\cdot P(D|H) }{P(D)} \\tag{3.3}\\]\nGleichungÂ 3.3 fragt nach \\(P(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (GleichungÂ 3.3):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der PlausibilitÃ¤t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus StandardisierungsgrÃ¼nden dividiert man noch die totale Wahrscheinlichkeit der Daten Ã¼ber alle Hypothesen.\n\n\n\n3.3.3 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayesâ€™ Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel wÃ¤re: â€œWas ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?â€.\nDas sieht dann so aus, GleichungÂ 3.4:\n\\[\n\\begin{aligned}\nP(R \\cap B |K) &= \\frac{ P(R \\cap B) \\cdot P(K|R \\cap B) }{P(D)} \\\\\n&= \\frac{ P(R ) \\cdot P(B) \\cdot P(K|R \\cap B) }{P(D)}\n\\end{aligned}\n\\tag{3.4}\\]\nHier haben wir \\(P(R \\cap B)\\) aufgelÃ¶st in \\(P(R) \\cdot P(B)\\), das ist nur zulÃ¤ssig, wenn \\(R\\) und \\(B\\) unabhÃ¤ngig sind.\n\n3.3.3.1 Bayes-Video von 3b1b\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise."
  },
  {
    "objectID": "Wskt.html#aufgaben",
    "href": "Wskt.html#aufgaben",
    "title": "3Â  Wahrscheinlichkeit",
    "section": "3.4 Aufgaben",
    "text": "3.4 Aufgaben\nZusÃ¤tzlich zu den Aufgaben im Buch:\n\nmtcars-abhaengig\nvoll-normal\ncorona-blutgruppe\nBed-Wskt2\nGem-Wskt1\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung und schlieÃŸende Statistik: praxisorientierte EinfÃ¼hrung: mit Aufgaben und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "Verteilungen.html",
    "href": "Verteilungen.html",
    "title": "4Â  Verteilungen",
    "section": "",
    "text": "Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nden Begriff der Zufallsvariablen erlÃ¤utern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erlÃ¤utern und anhand einfacher Beispiele ausrechnen\nden Begriff einer Gleichverteilung erlÃ¤utern und einfache Fallbeispiele ausrechnen\ndie Parameter einer Normalverteilung nennen und erlÃ¤utern\n\n\n\n\nLesen Sie zusÃ¤tzlich zum Stoff dieses Kapitels noch Bourier (2018), folgende Abschnitte:\n\nKap. 6.1 (Zum Begriff Zufallsvariable)\nKap. 6.3 (Stetige Zufallsvariablen)\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung) und 7.2.3 (Normalverteilung)\n\nLÃ¶sen Sie auch die Ãœbungsaufgaben dazu.\nWeitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n\n\n\n\nCode\nlibrary(patchwork)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\nZufallsvariable (random variable)\nDiskret vs.Â stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n\n\n\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n\n\n\n\n\nVideo 1 zum Thema Verteilungen\nVideo 2 zum Thema Verteilungen"
  },
  {
    "objectID": "Verteilungen.html#verteilungen-1",
    "href": "Verteilungen.html#verteilungen-1",
    "title": "4Â  Verteilungen",
    "section": "4.2 Verteilungen",
    "text": "4.2 Verteilungen\n\n\n\n\n\n\nWichtig\n\n\n\nEine Verteilung zeigt, welche AusprÃ¤gungen eine Variable aufweist und wie hÃ¤ufig bzw. wahrscheinlich diese sind. Einfach gesprochen, veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet HÃ¤ufigkeitsverteilungen (s. Abb. AbbildungÂ 4.1) von Wahrscheinlichkeitsverteilungen (Abb. AbbildungÂ 4.2).\n\n\n\n4.2.1 HÃ¤ufigkeitsverteilung\nDie HÃ¤ufigkeitsverteilung eines diskreten Merkmals \\(X\\) mit \\(k\\) AusprÃ¤gungen zeigt, wie hÃ¤ufig die einzelnen AusprÃ¤gungen sind. So hat die Variable Zylinder (in einem Datensatz) etwa die AusprÃ¤gungen 4,6 und 8.\n\n\nCode\ndata(mtcars)\n  mtcars %>% \n    count(cyl)\n\n\n\n\n\n\ncyl\nn\n\n\n\n\n4\n11\n\n\n6\n7\n\n\n8\n14\n\n\n\n\n\n\nAbb. AbbildungÂ 4.1, links, visualisiert die HÃ¤ufigkeitsverteilung von cyl.\n\n\n\n\n\nAbbildungÂ 4.1: HÃ¤ufigkeitsverteilung von cyl und hp (diskretisiert in 10 KÃ¶rbe oder Gruppen)\n\n\n\n\n:::\nEin stetiges Merkmal, wie hp (PS-Zahl), lÃ¤sst sich durch Klassenbildung diskretisieren, s. Abb. ?fig-mtcars-freq-dens, rechts.\n\n\n4.2.2 Wahrscheinlichkeitsverteilung\nWahrscheinlichkeitsverteilungen dienen dazu, Ereignissen einer Zufallsvariable eine Wahrscheinlichkeit zuzuordnen.\nEine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) AusprÃ¤gungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu. So hat die Variable Geschlecht eines Babies die beiden AusprÃ¤gungen MÃ¤dchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\) (Gelman, Hill, und Vehtari 2021).\nBei stetigen Zufallsvarialben \\(X\\) geht man von unendlich vielen AusprÃ¤gungen aus; die Wahrscheinlichkeit einer bestimmten AusprÃ¤gung ist (praktisch) Null: \\(p(X=x_j)=0, \\quad j=1,...,+\\infty\\). So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666â€¦ cm groÃŸ ist, (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\)."
  },
  {
    "objectID": "Verteilungen.html#gleichverteilung",
    "href": "Verteilungen.html#gleichverteilung",
    "title": "4Â  Verteilungen",
    "section": "4.3 Gleichverteilung",
    "text": "4.3 Gleichverteilung\n\n4.3.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jeder Wert im Ergebnisraum der zugehÃ¶rigen Zufallsvariable gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine Realisation einer Zufallsvariablen fÃ¼r plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. AbbildungÂ 4.2 zeigt ein Beispiel fÃ¼r eine (stetige) Gleichverteilung.\n\n\n\n\n\nAbbildungÂ 4.2: Gleichverteilung min=-1, max=1\n\n\n\n\nBei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 50%.\nDefinierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.\n\n\n4.3.2 Simulation\nMÃ¶chte man die Verteilungsfunktion einer stetigen Zufallsvariablen berechnen, kann das ganz schÃ¶n kompliziert werden, schlieÃŸlich muss man Integrale lÃ¶sen. Aber es gibt einen Trick, wie man die Sache stark vereinfachen kann: man simuliert die Verteilung. Was bedeutet das?\nAngenommen, die Wartezeit auf einen Bus ist gleichverteilt (engl. uniform distribution); der Bus kommt regelmÃ¤ÃŸig und pÃ¼unktlich alle 10 Minuten. Die minimale Wartezeit betrÃ¤gt also 0 Minuten und die maximale 10 Minuten. Nennen wir die zugehÃ¶rige Zufallsvariable \\(X\\), das ist schÃ¶n kurz.\nDann schreibt man auch:\n\\[X \\sim Unif(0,10).\\]\nJa, das sieht fancy aus, aber wo ist der versprochene Trick zum Vereinfachen? Kommt gleich, Moment.\nEine Frage kÃ¶nnte nun lauten, wie groÃŸ ist die Wahrscheinlichkeit, dass man zwischen 3 und 5 Minuten auf den Bus warten muss?\nDer Trick ist, dass wir Integralrechnung gegen stumpfes ZÃ¤hlen eintauschen.\nComputer (und damit R) haben eingebaut Funktionen, die eine beliebige Zufallszahl ziehen kÃ¶nnen, zum Beispiel gleichverteilt\nAuf Errisch heiÃŸt das Zauberwort runif():\n\n\nCode\nrunif(n = 1, min = 0, max = 10)\n\n\n\n## [1] 9.14806\n\nAuf Deutsch heiÃŸt das: â€œHey R, ich hÃ¤tte gerne eine (daher n = 1) Zufallszahl r wie random, die gleichverteilt ist (uniform) mit min = 0 und max = 10.\n(Zu) anschaulich gesprochen: R hat den Bus kommen lassen und es hat gut 9.1 Minuten gedauert, bis er da war.\nAchtung, jetzt kommtâ€™s: Jetzt lassen wir R mal \\(10^5\\) (1e5 auf Computersprech) Busse vorfahren. R soll jedes Mal notieren, wie lange man auf den Bus warten musste.1\n\n\nCode\nx_simu <- runif(n = 1e5, min = 0, max = 10)\n\n\n\n\n\nSchauen wir uns die Verteilung an, AbbildungÂ 4.3.\n\n\nCode\nggplot(x_simu_df) +\n  aes(x = x_simu) +\n  geom_histogram(bins = 50)\n\n\n\n\n\nAbbildungÂ 4.3: Simulation einer gleichverteiluten Zufallsvariablen\n\n\n\n\nOkay, unsere Verteilung sieht nicht exakt gleichverteilt, aber einigermaÃŸen. Gut genug fÃ¼r unsere Zwecke!\nSo, und jetzt kommt das Ernten. Wir kÃ¶nnen jetzt nÃ¤mlich einfach zÃ¤hlen (count()), um die Antwort auf unsere Frage (der Wartezeit 3-5 Min.) zu erhalten.\n\n\nCode\nx_simu_df %>% \n  count(Schnittmenge = x > 3 & x < 5)\n\n\n\n\n\n\nSchnittmenge\nn\n\n\n\n\nFALSE\n80072\n\n\nTRUE\n19928\n\n\n\n\n\n\nDas Zeichen & ist das logische UND, also die Schnittmenge der zwei Mengen \\(A := \\{x|x>3\\}\\) und \\(B := \\{x|x<5\\}\\), also \\(A \\cap B\\).\nWie man sieht, fallen ca. 20% der Stichproben in den entsprechenden Bereich.\nDa viele Probleme, wenn sie komplexer werden, kaum noch analytisch (wie Integrieren) ausrechenbar sind, greift man in der modernen (Analyse-)Welt oft lieber auf Simulationsverfahren zurÃ¼ck - Dank sei den schnellen Rechnern. FÃ¼r uns Menschen ist damit die Aufgabe des Integrierens auf schnÃ¶des ZÃ¤hlen zurÃ¼ckgefÃ¼hrt."
  },
  {
    "objectID": "Verteilungen.html#sec-bin-distrib",
    "href": "Verteilungen.html#sec-bin-distrib",
    "title": "4Â  Verteilungen",
    "section": "4.4 Binomialverteilung",
    "text": "4.4 Binomialverteilung\n\n\n\n\n\n\nWichtig\n\n\n\nDie Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei Ergebnissen also. Typisches Beispiel ist ein MÃ¼nzwurf. Bei jeder Wiederholung des Zufallexperiments bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die MÃ¼nze verÃ¤ndert sich nicht durch die WÃ¼rfe (Ziehen mit ZurÃ¼cklegen). AuÃŸerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc.\n\n\n\n4.4.1 Veranschaulichung\nStellen wir uns eine Kistchen2 mit 5 Losen vor, darunter 2 Treffer (Gewinn) und 3 Nieten, s. Abb. AbbildungÂ 4.4. Der Versuch lÃ¤uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zurÃ¼ck und ziehen erneut.\n\n\n\n\n\nAbbildungÂ 4.4: Ein KÃ¤stchen mit 5 Losen, darunter 2 Treffer und 3 Nieten.\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nUm die Wahrscheinlichkeitsverteilung einer binomialverteilte Zufallsvariable ausrechnen zu kÃ¶nnen, muss man zwei Dinge wissen: Erstens die Anzahl der ZÃ¼ge, \\(n\\) (StichprobengrÃ¶ÃŸe) und zweitens die Trefferwahrscheinlichkeit, \\(p\\).\n\n\nWie groÃŸ ist die Wahrscheinlichkeit von \\(A^{\\prime}\\), d.h. bei \\(n=4\\) ZÃ¼gen \\(x=2\\) Treffer zu erzielen, gegeben dass die Trefferwahrscheinlichkeit bei \\(p=2/4\\) liegt?\nWir kÃ¶nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz), s. AbbildungÂ 3.8. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit, \\(W\\) (Additionssatz). Das ist einfach, dauert aber.\nIn diesem Fall ist die Wahrscheinlichkeit eines (gÃ¼nstigen) Pfades, \\(A\\):\n\\(P(A) = P(T)^2 \\cdot P(N)^2 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right) ^2\\).\n\n\nCode\np_a = (2/5)^2 * (3/5)^2\np_a\n## [1] 0.0576\n\n\nEtwas mÃ¼hevolles ZÃ¤hlen der Pfade wÃ¼rde uns zeigen, dass es \\(k=6\\) Pfade gibt, die alle die gleiche Wahrscheinlichkeit, \\(P(A)\\), aufweisen.\nDamit betrÃ¤gt die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 4 ZÃ¼gen):\n\\(P(A^{\\prime}) = 6 \\cdot P(A)\\).\n\n\nCode\np_a_strich = 6 * p_a\np_a_strich\n## [1] 0.3456\n\n\nMithilfe der Formel der Binomialverteilung lÃ¤sst sich das Ergebnis, die Wahrscheinlichkeit von \\(A^{\\prime}\\) schneller ausrechnen. Einfach gesprochen sieht sie so aus:\n\\[P(A^{\\prime}) = k \\cdot P(A)\\] Dabei steht \\(k\\) fÃ¼r die Anzahl der gÃ¼nstigen Pfade und \\(P(A)\\) fÃ¼r die Wahrscheinlichkeit eines gÃ¼nstigen Pfades (d.h. 2 Treffer und 2 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\nDie Anzahl der Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt:\n\\(\\tbinom{n}{k}\\)\nLies: â€œWÃ¤hle aus \\(n\\) mÃ¶glichen Ereignissen (Pfade im Baum) \\(k\\) gÃ¼nstige Ereignisse (gÃ¼nstige Pfade).\nAuf Errisch geht das so:\n\n\nCode\nchoose(4,2)\n## [1] 6\n\n\n\n\n4.4.2 Rechnen mit R\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen.\nDie Wahrscheinlichkeit, bei 4 ZÃ¼gen 2 Treffer zu erzielen mit \\(p=2/5\\) unter der Annahme einer Binomialverteilung lÃ¤sst sich so mit R berechnen:\n\n\nCode\ndbinom(x = 2, size = 4, prob = 2/5)\n## [1] 0.3456\n\n\n\nBeispiel 4.1 (Pumpstation-Beispiel zur Binomialverteilung) In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% fÃ¤llt ein Motor aus und ist fÃ¼r den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie groÃŸ ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb fÃ¤llt?\n\\(P(X=k)\\) (oder kurz: \\(P(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an fÃ¼r das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(P(X=5)\\) ausrechnen.\n\n\nCode\ndbinom(x = 5, size = 7, prob = .95)\n## [1] 0.0406235\n\n\nEs gilt also \\(P(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist relativ gering3.\ndbinom() steht fÃ¼r die Wahrscheinlichkeitsdichte (im diskreten Fall, also hier, Wahrscheinlichkeitsfunktion genannt) und binom fÃ¼r die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die StichprobengrÃ¶ÃŸe an (hier 7 Motoren).\nDamit gilt:\n\\(P(X\\ge 5) = P(X=5) + P(X=6) + P(X=7)\\)\n\n\nCode\np_5 <- dbinom(x = 5, size = 7, prob = .95)\np_6 <- dbinom(x = 6, size = 7, prob = .95)\np_7 <- dbinom(x = 7, size = 7, prob = .95)\n\np_mind_5 <- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 0.996243\n\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betrÃ¤gt also 0.9962.\nDas Komplement zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also hÃ¶chstens 4 und es daher zu einem Ausfall kommt.\nNatÃ¼rlich gilt \\(P(\\bar{X}) = 1- P(X)\\).\n\n\nCode\np_weniger_als_4 <- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.003757043\n\n\nAlternativ kann man mit der Verteilungsfunktion rechnen: \\(P(X \\le 4)\\).\nIn R kann man dafÃ¼r die Funktion pbinom() nutzen (p fÃ¼r (kumulierte) Wahrscheinlichkeit).\n\n\nCode\npbinom(q = 4, size = 7, prob = .95)\n## [1] 0.003757043\n\n\nq = 4 steht fÃ¼r \\(X \\le 4\\), also fÃ¼r hÃ¶chstens 4 Treffer (arbeitende Motoren); size = 7 meint die StichprobengrÃ¶ÃŸe, hier 7 Motoren.\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Funktion, die die Wahrscheinlichkeit dafÃ¼r angibt, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich (hÃ¶chstens) einem Wert \\(X=x\\) ist, heiÃŸt Verteilungsfunktion.\n\\(F(X=x) = P(X \\le x)\\)\n\n\n\n\n4.4.3 Simulieren\nDie Binomialverteilung lÃ¤sst sich gut als â€œMÃ¼nzwurf-Verteilungâ€ auffassen.\nWerfen wir eine MÃ¼nze und sehen wir, was passiert.\n\n\nCode\nsample(x = c(0, 1), size = 1)\n## [1] 1\n\n\nMit sample() ziehen wir eine Stichprobe aus dem Ereignisraum x, hier 0 und 1. Dabei vereinbaren wir (willkÃ¼rlich), dass 0 fÃ¼r â€œKopfâ€ steht und 1 fÃ¼r â€œZahlâ€. size = 1 bedeutet, wir werfen die MÃ¼nze ein Mal (d.h. StichprobengrÃ¶ÃŸe size ist 1).\nOkay, noch an Bord? Dann werfen wir die MÃ¼nze 10 Mal:\n\n\nCode\nsample(x = c(0, 1), size = 10, replace = TRUE)\n##  [1] 0 1 1 1 1 0 0 1 0 1\n\n\nreplace = TRUE heiÃŸt, wir legen die MÃ¼nze wieder zurÃ¼ck auf den Tisch, wenn wir sie geworfen haben. Oder anders ausgedrÃ¼ckt: Ziehen mit ZurÃ¼cklegen.\nR, mach dich bereit, wirf die MÃ¼nze 1000 (\\(n=10^3\\) oder 1e3) Mal4:\n\n\nCode\nn <- 1e3\n\nmuenze_oft <- \n  sample(x = c(0, 1), size = n, replace = TRUE) \n\n\nmuenze_oft %>% \n  sum()\n## [1] 539\n\n\nMit sum() nach dem Pfeifensymbol %>% haben wir aus dem Vektor muenze_oft, der aus der ersten Zeile resultiert, die Summe ausgerechnet.\nJetzt wissen wir, wie oft die MÃ¼nze â€œZahlâ€ gezeigt hat, nÃ¤mlich 539 Mal.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie einen Zufallsversuch wiederholen, muss nicht jedes Mal das gleiche Ergebnis resultieren. Entsprechend wird bei wiederholten AusfÃ¼hrung der Funktion sample() nicht immer das gleiche Ergebnis resultieren. Wundern Sie sich also nicht, wenn bei Ihrem Computer eine Ã¤hnliche, aber nicht gleiche, Zahl herauskommt.\n\n\nVisualisieren wir mal unsere MÃ¼nzwÃ¼rfe. Dazu erstellen wir zuerst eine geeignete Tabelle:\n\n\nCode\nmuenz_tab <-\n  tibble(\n    id = 1:n,\n    x = muenze_oft,\n    x_cumsum = cumsum(x) / id  # gibt Anteil von \"Zahl\" wieder\n  )\n\nhead(muenz_tab)\n\n\n\n\n\n\nid\nx\nx_cumsum\n\n\n\n\n1\n1\n1.0000000\n\n\n2\n1\n1.0000000\n\n\n3\n0\n0.6666667\n\n\n4\n0\n0.5000000\n\n\n5\n1\n0.6000000\n\n\n6\n1\n0.6666667\n\n\n\n\n\n\nUnd hier der Anteil von â€œZahlâ€ im Verlauf unserer MÃ¼nzwÃ¼rfe, s. AbbildungÂ 4.5.\n\n\nCode\nmuenz_tab %>% \n  slice_head(n = 1e3) %>% \n  ggplot() +\n  aes(x = id, y = x_cumsum) +\n  geom_line()\n\n\n\n\n\nAbbildungÂ 4.5: Das Gesetz der groÃŸen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten MÃ¼nzwurf\n\n\n\n\nGrob gesagt scheint sich ein MÃ¼nzwurf nach, naja, vielleicht 500 WÃ¼rfen â€œeinigermaÃŸenâ€ zu stabilisieren.5\n\n\n\n\n\n\nWichtig\n\n\n\nDas Gesetz der groÃŸen Zahl\nZieht man (zufÃ¤llig) immer mehr Werte aus einer Verteilung (mit endlichem Mittelwert), nÃ¤hert sich der Mittelwert der Stichprobe immer mehr mit dem Mittelwert (oft als Erwartungswert bezeichnet) der Verteilung an"
  },
  {
    "objectID": "Verteilungen.html#normalverteilung",
    "href": "Verteilungen.html#normalverteilung",
    "title": "4Â  Verteilungen",
    "section": "4.5 Normalverteilung",
    "text": "4.5 Normalverteilung\nNormalverteilungen haben eine charakteristische Glockenform. Normalverteilungen kÃ¶nnen sich unterscheiden in ihrem Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden GrÃ¶ÃŸen (â€œParameterâ€) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. AbbildungÂ 4.6. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\n\n\n\nAbbildungÂ 4.6: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\n\nBeispiel: Wie groÃŸ sind Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%:\n\n\n\n\n\n\n  \n  \n    \n      q25\n      q50\n      q75\n    \n  \n  \n    160.02\n167.64\n175.26\n  \n  \n  \n\n\n\n\nVisualisierung der Quantile:\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas 25%-Quantil nennt man 1. Quartil, das 50%-Quantil auch 2. Quartil, das 75%-Quantil das 3. Quartil, und das 100%-Quantil (Maximalwert) das 4. Quartil.\n\n\n\n4.5.1 Normal auf dem FuÃŸballfeld\nSie und 100 Ihrer besten Freunde stehen auf der Mittellinie eines FuÃŸballfelds. Auf Kommando werfen alle jeweils eine MÃ¼nze; bei Kopf geht man einen Schritt nach links, bei Zahl nach rechts. Das wird 16 Mal wiederholt. Wie wird die Verteilung der Positionen wohl aussehen?\n\n\n\n\n\n(McElreath 2020)\n\n\n4.5.2 Normal durch Addieren\nDie Summe vieler (gleich starker) Zufallswerte (aus der gleichen Verteilung) erzeugt eine Normalverteilung; egal aus welcher Verteilung die Zufallswerte kommen (Zentraler Grenzwertsatz), vgl. AbbildungÂ 4.7.\n\n\n\n\n\nAbbildungÂ 4.7: Entstehen einer Normalverteilung durch Addition vieler unabhgÃ¤ngiger Ereignisse\n\n\n\n\nNicht verwechseln:\n\n\n\n\n\n\n\n\n\n\n\n4.5.3 Normalverteilung vs.Â randlastige Verteilungen\n\n\n\n\n\nBei randlastigen Verteilungen (â€œfat tailsâ€) kommen Extremereignisse viel hÃ¤ufiger vor als bei Normalverteilungen. Deshalb ist es wichtig sein, zu wissen, ob eine Normalverteilung oder eine randlastige Verteilung vorliegt. Viele statistische Methoden sind nicht zuverlÃ¤ssig bei (stark) randlastigen Methoden.\n\n\n4.5.4 Beispiele fÃ¼r Normal- und randlastige Verteilungen\nNormal verteilt:\n\nGrÃ¶ÃŸe\nMÃ¼nzwÃ¼rfe\nGewicht\nIQ\nBlutdruck\nAusschuss einer Maschine\n\nRandlastig verteilt:\n\nVermÃ¶gen\nVerkaufte BÃ¼cher\nRuhm\nAktienkurse\nErdbeben\nPandemien\nKriege\nErfolg auf Tinder\nMeteroritengrÃ¶ÃŸe\nStadtgrÃ¶ÃŸen\n\n\n\n4.5.5 Formel der Normalverteilung\nVereinfacht ausgedrÃ¼ckt lÃ¤sst die Normalverteilung \\(\\mathcal{N}\\) durch Exponenzieren einer Quadratfunktion beschreiben:\n\\[\\mathcal{N} \\propto e^{-x^2}\\]\nmit \\(e=2.71...\\), der Eulerschen Zahl.6\n\n\nCode\nd <-\n  tibble(\n    x = seq(-3, 3, \n            length.out = 100),\n    y = exp(-x^2)\n  )\n\nd %>% \n  ggplot() +\n  aes(x = x, y = y) +\n  geom_line()\n\n\n\n\n\n\n\nEine Normalverteilung mit \\(\\mu=0\\) und \\(\\sigma=1\\) nennt man auch Standardnormalverteilung und man schreibt:\n\\[IQ \\sim \\mathcal{N}(0,1)\\]\nDie Normalverteilung wird auch Gauss-Verteilung oder Glockenkurve genannt.\n\n\n4.5.6 Simulation einer Normalverteilung\nR hat eine Funktion eingebaut zur Erzeugung von Zufallszahlen (Zufallszahlengenerator), z.B. normalverteilte. Man Ã¼bergibt dieser Funktion den gewÃ¼nschten Mittelwert und die gewÃ¼nschte Streuung und die Funktion zieht dann zufÃ¤llig Werte aus dieser Verteilung.\nDiesen Zufallszahlengenerator kann man mit einem Duschkopf vergleichen, s. AbbildungÂ 4.8. An diesem Duschkopf kann man einen Schwenker einstellen, der den Duschkopf ausrichtet, also steuert, ob die Wassertropfen weit in die eine oder die andere Richtugn fallen. Zweitens hat unser Duschkopf noch einen Streuregler, der den Wasserstrahl entweder eng bÃ¼ndelt7 oder weit auseinanderfÃ¤chert. Im ersten Fall fÃ¤llt der Wasserstrahl eng und schmal aus. Im zweiten Fall fÃ¤llt der Wasserstrahl breit aus.\n\n\n\nAbbildungÂ 4.8: Zufallszahlengenerator als Duschkopf\n\n\nQuelle: John Kruschke.\nEine Zufallszahl (random number), die normalverteilt ist, mit \\(\\mu=0\\) und \\(\\sigma=1\\) kann man in R so erzeugen:\n\n\nCode\nrnorm(n = 1, mean = 0, sd = 1)\n## [1] 0.2664096\n\n\nEin Fallbeispiel: Der Inhalt einer TÃ¼te mit Zucker, \\(X\\), sei normalverteilt mit \\(\\mu = 10002\\) g und \\(\\sigma=1.5\\) g. Aus vertragsrechtlichen GrÃ¼nden darf das FÃ¼llgewicht von 1000g nicht unterschritten werden, sonst drohen Konventionalstrafen.\nWie groÃŸ ist die Wahrscheinlichkeit, dass 1000g unterschritten werden?\nSimulieren wir uns 1e4 ZuckertÃ¼ten!\n\n\nCode\nn <- 1e4\nd <- \n  tibble(\n    id = 1:n,\n    x = rnorm(n = n, mean = 1002, sd = 1.5)\n  )\n\nhead(d)\n\n\n\n\n\n\nid\nx\n\n\n\n\n1\n1002.479\n\n\n2\n1001.216\n\n\n3\n1003.320\n\n\n4\n1001.173\n\n\n5\n1001.465\n\n\n6\n1003.843\n\n\n\n\n\n\nZÃ¤hlen wir, viele der ZuckertÃ¼ten ein Gewicht von weniger als 1000g aufweisen:\n\n\nCode\nd %>% \n  count(x < 1000)\n\n\n\n\n\n\nx < 1000\nn\n\n\n\n\nFALSE\n9013\n\n\nTRUE\n987\n\n\n\n\n\n\nEin ziemlich8 kleiner Anteil. Rechnen wir uns noch die Anteile (proportion) aus:\n\n\nCode\nd %>% \n  count(x < 1000) %>% \n  mutate(prop = n/1e4)\n\n\n\n\n\n\nx < 1000\nn\nprop\n\n\n\n\nFALSE\n9013\n0.9013\n\n\nTRUE\n987\n0.0987\n\n\n\n\n\n\n\n\n4.5.7 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. AbbildungÂ 4.9:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu gehÃ¶ren?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, â€¦ der Leute nicht Ã¼berschritten?\n\n\n\n\nAbbildungÂ 4.9: Visualisierung der theoretischen IQ-Verteilung\n\n\nQuelle:: John Kruschke.\nZiehen wir zufÃ¤llig \\(1e4\\) Stichproben aus \\(\\mathcal{N}(100,15)\\) und berechnen die Quantile:\n\n\nCode\nd <-\n  tibble(\n  iq = rnorm(n = 1e4, \n             mean = 100, \n             sd = 15))\n\nprobs <- c(0.75,.5,.25,.05,.01)\n\nd_summary <- d %>% \n  summarise(p = probs,\n            q = quantile(iq, probs))\n\n\n\n\n\n\n\n\n  \n  \n    \n      p\n      q\n    \n  \n  \n    0.75\n110\n    0.50\n100\n    0.25\n90\n    0.05\n75\n    0.01\n65\n  \n  \n  \n\n\n\n\nDas Quantil \\(q\\) zur kumulierten Wahrscheinlichkeit \\(p=75\\) ist 110, etc.\nUmgekehrt kÃ¶nnen wir uns auch fragen: Gegeben einer Realisation der Zufallsvariablen (z.B. IQ), was ist die zugehÃ¶rige Wahrscheinlichkeit (Wert der Verteilungsfunktion?)\n\nWelcher Anteil der FlÃ¤che unter der Kurve \\(p\\) gehÃ¶rt zu den IQ-Werten 75, 100, 115, 130?\nAnders gesagt: Welcher Anteil der Wahrscheinlichkeitsmasse der Verteilung liegt unter IQ=75, IQ=100, etc.?\n\nZiehen wir Stichproben aus \\(\\mathcal{N}(100,15)\\):\n\n\nCode\nd <-\n  tibble(\n    iq = rnorm(1e4, \n               mean = 100, \n               sd = 15)) %>% \n  mutate(iq = round(iq))\n\nqs <- c(75,100,115,130)\n\nd %>% \n  count(p_100 = iq < 100) %>% \n  mutate(prop = n / sum(n)) \n\n\n\n\n\n\n\n\n  \n  \n    \n      p_100\n      n\n      prop\n    \n  \n  \n    FALSE\n5143\n0.51\n    TRUE\n4857\n0.49\n  \n  \n  \n\n\n\n\nAnstelle von iq < 100 kann man iq < 115 einsetzen, etc.\n\n\n\nDie Verteilungsfunktion (der Anteil der Wahrscheinlichkeitsmasse), p, fÃ¼r IQ-Werte nicht grÃ¶ÃŸer als 100, \\(IQ\\le100\\), ist 50%, etc.\n\n\n4.5.8 Quantile der Normalverteilung\n\nQuantile teilen eine Verteilung so ein, dass ein Anteil \\(p\\) kleiner oder gleich und der andere Teil \\(1-p\\) grÃ¶ÃŸer dem Quantil \\(q\\) ist.\n\nBeispiel: â€œ50%-Quantil = 100â€ meint, dass 50% der Elemente der Verteilung einen Wert kleiner oder gleich als 100 haben.\n\nDie Verteilungsfunktion F (fÃ¼r einen Wert \\(x\\)) gibt die Wahrscheinlichkeit an, dass die zugehÃ¶rige Zufallsvariable \\(X\\) einen Wert hÃ¶chstens so groÃŸ wie \\(x\\) annimmt. Sie zeigt also die kumulierte Wahrscheinlichkeit \\([-\\infty, q)\\).\n\nBeispiel: â€œF(100) = 50%â€ meint: Die Wahrscheinlichkeit fÃ¼r eine AusprÃ¤gung von hÃ¶chstens als 100 betrÃ¤gt 50%.\n\n\nSchauen wir uns die Quartile der Normalverteilung einmal nÃ¤her an. Wir gehen von einer Normalverteilung aus, wie sie zur Beschreibung von Intelligenz (IQ) verwendet wird, s. AbbildungÂ 4.10.\n\n\n\n\n\nAbbildungÂ 4.10: Quantile der Normalverteiltung\n\n\n\n\n\\[IQ \\sim \\mathcal{N}(100, 15)\\] Mit R kann man sich die beiden GrÃ¶ÃŸen komfortabel berechnen lassen:\n\n\nCode\nqnorm(.50, mean = 100, sd = 15)  # 50%-Quantil\npnorm(100, mean = 100, sd = 15)  # Verteilungsfunktion fÃ¼r IQ=100\n\n\nBetrachten wir einige wichtigen Quantile, s. AbbildungÂ 4.11.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.11: Verschiedene Quantil der Normalverteilung\n\n\n\n\n\n\n4.5.9 Standardnormalverteilung\n\n\n\n\n\nBei \\(X=0\\):\n\nhat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 40% (Wahrscheinlichkeitsdichte)\nsind 50% der Wahrscheinlichkeitsmasse (FlÃ¤che unter der Kurve) kleiner als dieser Wert (Verteilungsfunktion).\n\nIn Summe liegen 100% der Wahrscheinlichkeitsmasse unter der Kurve.\n\n\n4.5.10 Normalverteilung als konservative Wahl\nDem Mathematiker Carl Friedrich Gauss (s. AbbildungÂ 4.12) wird die Ehre zuerkannt, die Normalverteilung eingefÃ¼hrt zu haben.\n\n\n\n\n\nAbbildungÂ 4.12: Zehn-Mark-Geldschein mit Gauss und Normalverteilung\n\n\n\n\nQuelle: Uni Greifswald, Public domain, via Wikimedia Commons\n\n\n\n\n\n\nHinweis\n\n\n\nOntologische BegrÃ¼ndung\n\nWirken viele, gleichstarke EinflÃ¼sse additiv zusammen, entsteht eine Normalverteilung (McElreath 2020), Kap. 4.1.4.\n\nEpistemologische BegrÃ¼ndung\n\nWenn wir nur wissen, dass eine Variable Ã¼ber einen endlichen Mittelwert und eine endliche Varianz verfÃ¼gt und wir keine weiteren Annahmen treffen bzw. Ã¼ber kein weiteres Vorwissen verfÃ¼gen, dann ist die Normalverteilung die plausibelste Verteilung (maximale Entropie) (McElreath 2020), Kap. 7 und 10."
  },
  {
    "objectID": "Verteilungen.html#aufgaben",
    "href": "Verteilungen.html#aufgaben",
    "title": "4Â  Verteilungen",
    "section": "4.6 Aufgaben",
    "text": "4.6 Aufgaben\nZusÃ¤tzlich zu den Aufgaben im Buch:\n\nLose-Nieten-Binomial-Grid\nBsp-Binomial\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung und schlieÃŸende Statistik: praxisorientierte EinfÃ¼hrung: mit Aufgaben und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "Globusversuch.html",
    "href": "Globusversuch.html",
    "title": "5Â  Globusversuch",
    "section": "",
    "text": "Bayes:Start"
  },
  {
    "objectID": "Globusversuch.html#lernsteuerung",
    "href": "Globusversuch.html#lernsteuerung",
    "title": "5Â  Globusversuch",
    "section": "5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nUnterschiede zwischen Modellen und der RealitÃ¤t erlÃ¤utern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\nPost-Wahrscheinlichkeiten anhand der Gittermethode berechnen\n\n\n\n5.1.2 BenÃ¶tigte R-Pakete\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\n5.1.3 Begleitvideos\n\nVideo zum Thema Globusversuch\nVideo zum Thema Ãœbungen zum Globusversuch"
  },
  {
    "objectID": "Globusversuch.html#von-welten-und-golems",
    "href": "Globusversuch.html#von-welten-und-golems",
    "title": "5Â  Globusversuch",
    "section": "5.2 Von Welten und Golems",
    "text": "5.2 Von Welten und Golems\n\n5.2.1 Kleine Welt, groÃŸe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb AbbildungÂ 5.1.\n\n\n\nAbbildungÂ 5.1: Behaims Globus: Kein Amerika\n\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der groÃŸen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die groÃŸe Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.\nğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n\n5.2.2 Der Golem von Prag\n\n\n\nAbbildungÂ 5.2: Der Golem von Prag\n\n\nQuelle\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt, s@fig-golem-prag. Die Geschichte besagt, dass ein Rabbi mit ZauberkrÃ¤ften den Golem aus Lehm erschuf, um die jÃ¼dische BevÃ¶lkerung der Stadt zu schÃ¤tzen. Bei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen. Bei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.\n\n\n5.2.3 Wissenschaftliche Modelle sind wie Golems\nGolem\n\n\n\nâ€œYeah, ich bin ein Golem!â€ - Bildquelle: Klara Schaumann\n\n\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch â€œWahrheitâ€\nMÃ¤chtig\ndumm\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nMÃ¤rchen\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mÃ¤chtig\nsimpler als die RealitÃ¤t\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nNicht einmal falsch\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildungÂ 2.4 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen, wie Behaims Globus, mit der GroÃŸen Welt, die Kolumbus und wir befahren.\n\nKleine Welt vs.Â groÃŸe Welt\n\n\n\n\n\n\nKleine Welt\nGroÃŸe Welt\n\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit\nentspricht nicht (zwangslÃ¤ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n5.2.4 So denkt unser Bayes-Golem\n\n\n\nSo denkt unser Bayes-Golem\n\n\nğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!"
  },
  {
    "objectID": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "5Â  Globusversuch",
    "section": "5.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.3 Ein erster Versuch: Wir werfen den Globus\n\n5.3.1 Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?\nUnsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (AbbildungÂ 5.3)?\n\n\n\nAbbildungÂ 5.3: Die Erde\n\n\nQuelle CC 4.0 BY-NC\nAnalog kÃ¶nnen wir uns vorstellen, 11 Wissenschaftlis haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus â€¦ die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.\nSo sah mein2 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!\n\n\n5.3.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten fÃ¼hrt, nennt man den datengenierenden Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der ErdoberflÃ¤che ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie WÃ¼rfe des Globusballes sind unabhÃ¤ngig voneinander.\nWir haben kein Vorwissen Ã¼ber \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\nğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?\n\n\n5.3.3 Ein paar Fachbegriffe\n\nFÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: Priori-Verteilung.\nFÃ¼r jede Hypothese (d.h. jeden Parameterwert \\(p\\)) mÃ¶chten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung3 bekommen.\n\n\n\n5.3.4 Bayes-Updates\nDer Golem denkt eigentlich ganz vernÃ¼nftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugehÃ¶rige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung. In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als nÃ¤chstes beschaut sich der Golem die Daten und Ã¼berlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 10% betrÃ¤gt. Die zugehÃ¶rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die4 Likelihood. Als letztes bildet sich der Golem eine abschlieÃŸende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder geupatedet, s. AbbildungÂ 5.4.\n\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]-->B[Likelihood]-->C[Post-Vert.]-->A\n\n\n\n\n\nAbbildungÂ 5.4: Updating mit Bayes\n\n\n\n\n\n\n5.3.5 Likelihood mit Binomialverteilung\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer, (bei 9) WÃ¼rfen zu bekommen, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 70%) annimmt? Diese Wahrscheinlichkeit hat einen eigenen Namen, weil sie eine wichtige Sache ist. Man mennt sie die Likelihood, \\(L\\)5.\nGeht man von einer Binomialverteilng aus, ist die Likelihood einfach zu berechnen6.\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert7. Der Wasseranteil der Erde bleibt wÃ¤hrend des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser \\(p\\) betrÃ¤gt, so bezeichnen: \\((Pr(W,L | p))\\). Diese Wahrscheinlichkeit, \\((Pr(W,L | p))\\), kann man mit der Binomialverteilung berechnen.\nMÃ¶chte man die Wahrscheinlichkeit ansprechen fÃ¼r das Ereignis â€œ5 mal Wasser und 2 mal Land, wenn wir von einem Wasseranteil von 70% ausgehenâ€, so wÃ¼rden wir kurz schreiben: \\(Pr(W=5, L=2 | p=.7)\\).\nDie Binomialverteilung zeigt die Verteilung der HÃ¤ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten): â€œMÃ¼nzwurfverteilungâ€, s. Kap. KapitelÂ 4.4.\nDie Formel der Binomialverteilung sieht so aus:\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L = k \\cdot P(A) \\tag{5.1}\\]\nFormel GleichungÂ 5.1 kann wie folgt auf Deutsch Ã¼bersetzen:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œW,Lâ€ gegeben p berechnet als Produkt von zwei Termen. Erstens der Quotient von der FakultÃ¤t von W plus L im ZÃ¤hler und im Nenner das Produkt von erstens der FakultÃ¤t von W mit zweitens der FakultÃ¤t von L. Der zweite Term ist das Produkt von p hoch W mal der komplementÃ¤ren Wahrscheinlichkeit von p hoch L.\n\nOder noch kÃ¼rzer:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œW,Lâ€ gegeben p berechnet als Produkt von zwei Termen. Erstens der Anzahl der gÃ¼nstigen Pfade, k und zweitens der Wahrscheinlichkeit fÃ¼r einen gÃ¼nstigen Pfad, P(A).\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange Ãœbersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und fÃ¼r uns ausrechnen. Los, R, mach mal.\n\n\n5.3.6 Binomialverteilung mit R\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(N=W+L=3\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?8.\n\n\nCode\ndbinom(x = 2, size = 3, prob = 1/2)\n## [1] 0.375\n\n\nVon den 8 Endkonten bzw. Pfaden sind 3 gÃ¼nstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 WÃ¼rfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-> B[B - 0]\n  A -. 1/2 .-> C[C - 1]\n  B -. 1/2 .-> D[D - 0]\n  B -. 1/2 .-> E[E - 1]\n  C -. 1/2 .-> F[F - 0]\n  C -. 1/2 .-> G[G - 1]\n  D -. 1/2 .-> H[H - 0]\n  D -. 1/2 .-> J[I - 1]\n  E -. 1/2 .-> K[K - 0]\n  E -. 1/2 .-> L[L - 1]\n  F -. 1/2 .-> M[M - 0]\n  F -. 1/2 .-> N[N - 1]\n  G -. 1/2 .-> O[O - 0]\n  G -. 1/2 .-> P[P - 1]\n\n\n\n\n\nAbbildungÂ 5.5: Wir werfen den Globus (oder eine MÃ¼nze) 3 Mal\n\n\n\n\nAbb. AbbildungÂ 5.5 stellt einen einfachen Baum fÃ¼r 3 GlobuswÃ¼rfe mit je zwei mÃ¶glichen Ereignissen (W vs.Â L) dar. In der ersten (obersten) Zeile (Knoten A; â€œStartâ€) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) mÃ¶gliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nFÃ¼r mehr WÃ¼rfe wÃ¼rde das Diagramm irgendwann unÃ¼bersichtlich werden.\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\n\nCode\ndbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.1640625\n\n\nAbb AbbildungÂ 5.6 ist ein vergeblicher Versuch, so einen groÃŸen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum VerstÃ¤ndnis, kommen aber bei grÃ¶ÃŸeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\n\nAbbildungÂ 5.6: Wir werfen den Globus (oder eine MÃ¼nze) 3 Mal\n\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 5.1 (Globus mit 9 Treffern bei 9 WÃ¼rfen) Was ist die Wahrscheinlichkeit fÃ¼r \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\n\nCode\ndbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.001953125\n\n\nDas ist 1 gÃ¼nstiger Pfad von 512 Pfaden.\n\n\nBeispiel 5.2 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?9.\n\n\nCode\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.01478577\n\n\nUm hÃ¶chstens 15 Treffer zu erzielen, mÃ¼ssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern addieren.\nPraktischerweise gibt es einen R-Befehl, der das fÃ¼r uns Ã¼bernimmt:\n\n\nCode\npbinom(q = 15, size = 20, prob = .5)\n## [1] 0.994091\n\n\nDie Wahrscheinlichkeit 0, 1, 2, â€¦ oder 15 Treffer zu erzielen, liegt also bei gut 99%.\n\n\nBeispiel 5.3 (3 MÃ¼nzwÃ¼rfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\n\nCode\ndbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.125\n\n\n\ndbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zurÃ¼ck, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\n\n\n5.3.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: â€œW ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)â€. \\(N\\) gibt die Anzahl der GlobuswÃ¼rfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (â€œuniformâ€):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: â€œ\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1â€.\nMan kÃ¶nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (aprior) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich.\n\n\n5.3.8 Visualisierungen\nAbb. AbbildungÂ 5.7 zeigt die Binomialverteilung \\(X \\sim Bin(9, 1/2)\\).\n\n\n\n\n\nAbbildungÂ 5.7: Ein Beispiel fÃ¼r eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\n\n\n\n\n\n\nğŸ‹ï¸ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear?"
  },
  {
    "objectID": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "5Â  Globusversuch",
    "section": "5.4 Zur Erinnerung: Bayes Theorem",
    "text": "5.4 Zur Erinnerung: Bayes Theorem\n\n5.4.1 Herleitung Bayesâ€™ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit fÃ¼r Regen und kalt ist gleich der Wahrscheinlichkeit von Regen, gegeben kalt mal der Wahrscheinlichkeit von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wennâ€™s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n\n5.4.2 Herleitung Bayesâ€™ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lÃ¶sen auf nach der Posteriori-Wahrscheinlichkeit10, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods Ã¼ber alle Werte von \\(p\\). Die Aufgabe dieser GrÃ¶ÃŸe ist nur dafÃ¼r zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n\n5.4.3 Bayesâ€™ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)} = \\frac{\\text{Likelihood}  \\cdot \\text{Priori}}{\\text{Evidenz}}\\]\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayesâ€™ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) fÃ¼ttert.\nBayesâ€™ Theorem wird hÃ¤ufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n\n\n5.4.4 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Post-Wahrscheinlichkeit ist einfach das Produkt von Likelihood und Priori.\nDas Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung GleichungÂ 5.2.\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}} \\tag{5.2}\\]\nAbb. AbbildungÂ 5.8 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\n\nAbbildungÂ 5.8: Prior mal Likelihood = Post\n\n\n\n\n5.4.5 Wissen updaten: Wir fÃ¼ttern Daten in das Modell\nGolems kÃ¶nnen lernen?! AbbildungÂ 5.9 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. WÃ¼rfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich fÃ¼r den Golem (das Modell). Je nach Ergebnis des Wurfes verÃ¤ndert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung verÃ¤ndert sich in AbhÃ¤ngigkeit von den Daten.\n\n\n\nAbbildungÂ 5.9: Unser Golem lernt\n\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "href": "Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "title": "5Â  Globusversuch",
    "section": "5.5 Bayes berechnen mit mit dem Bayes-Gitter",
    "text": "5.5 Bayes berechnen mit mit dem Bayes-Gitter\nWir erstellen uns eine kleine Tabelle, die man â€œBayes-Gitterâ€ nennen kÃ¶nnte. Dazu gehen wir so vor:\n\n5.5.1 Idee\n\nTeile den Wertebereich des Parameter in ein â€œGitterâ€ auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (â€œGitterwerteâ€).\nWÃ¤hle den Priori-Wert des Parameters fÃ¼r jeden Gitterwert.\nBerechne den Likelihood fÃ¼r Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nFÃ¼r jeden â€œGitterwertâ€ berechnen wir eine (Post-)Wahrscheinlichkeit. Ein Gitterwert ist eine mÃ¶gliche AusprÃ¤gung des Parameters. HÃ¤ufig entspricht eine Hypothese einem Gitterwert, etwa wenn man sagt: â€œIch glaube, die MÃ¼nze ist fairâ€, was auf einem Parameterwert von 50% herauslÃ¤uft. Dazu geben wir an, fÃ¼r wie wahrscheinlich wie apriori11 - also bevor wir irgendwelche Daten erheben - jeden einzelnen Gitterwert halten. Wir machen es uns hier einfach und halten jeden Gitterwert fÃ¼r gleich wahrscheinlich. TatsÃ¤chlich ist der konkrete Wert hier egal, entscheidend ist das VerhÃ¤ltnis der Apriori-Werte zueinander: Geben wir einigen Gitterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere fÃ¼r (apriori) doppelt so plauibel wie Letztere. Der Likelihood wird in diesem Fall mit der Binomialverteilung berechnet. Der Likelihood gibt an, wie wahrscheinlich ein Gitterwert ist gegeben einem bestimmten apriori gewÃ¤hlten Parameterwert. Die â€œEnd-Wahrscheinlichkeitâ€, die unstandardisierte Post-Wahrscheinlichkeit, die â€œhinten rauskommtâ€ ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet12. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen mÃ¶chten teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die Kolmogorov-AnsprÃ¼che an eine Wahrscheinlichkeitsverteilung erfÃ¼llt.\n\n\n5.5.2 Bayes-Gitter in R berechnen\nLegen wir uns eine Tabelle mit Gitterwerten an, um deren Posteriori-Wahrscheinlichkeit zu berechnen.\n\n\nCode\nd <-\n  tibble(\n    # definiere die Hypothesen (das \"Gitter\"): \n    p_Gitter = seq(from = 0, to = 1, by = 0.1),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %>%  \n    mutate(\n      # berechne Likelihood fÃ¼r jeden Gitterwert:\n      Likelihood = dbinom(6, size = 9, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\n\nDas â€œBayes-Gitterâ€ (TabelleÂ 5.1) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\n\nTabelleÂ 5.1: Die Bayes-Box fÃ¼r den Globusversuch\n\n\nid\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n1\n0.0\n1\n0.00\n0.00\n0.00\n\n\n2\n0.1\n1\n0.00\n0.00\n0.00\n\n\n3\n0.2\n1\n0.00\n0.00\n0.00\n\n\n4\n0.3\n1\n0.02\n0.02\n0.02\n\n\n5\n0.4\n1\n0.07\n0.07\n0.07\n\n\n6\n0.5\n1\n0.16\n0.16\n0.16\n\n\n7\n0.6\n1\n0.25\n0.25\n0.25\n\n\n8\n0.7\n1\n0.27\n0.27\n0.27\n\n\n9\n0.8\n1\n0.18\n0.18\n0.18\n\n\n10\n0.9\n1\n0.04\n0.04\n0.04\n\n\n11\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\nFÃ¼r jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood:\n\\(\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood}\\)\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Gitterbox (also fÃ¼r jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten.\nğŸ‹ï¸ Was wohl mit Post passiert, wenn wir Priori Ã¤ndern?\n\n\n5.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: â€œPost-Verteilungâ€), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\nAbbildungÂ 5.10 zeigt die Post-Wahrscheinlichkeit fÃ¼r 5, 10 und 20 Gitterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben.\n\n\n\nAbbildungÂ 5.10: Je mehr Gitterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen UmstÃ¤nden gilt:\n\nMehr Gitterwerte glÃ¤tten die AnnÃ¤herung.\nJe grÃ¶ÃŸer die Stichprobe (\\(N\\)), desto zuverlÃ¤ssiger wird unsere Berechnung.\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer TrÃ¤ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung kÃ¶nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nÃ¤chsten Kapitels."
  },
  {
    "objectID": "Globusversuch.html#aufgaben",
    "href": "Globusversuch.html#aufgaben",
    "title": "5Â  Globusversuch",
    "section": "5.6 Aufgaben",
    "text": "5.6 Aufgaben\n\nRethink_2E4\nRethink_2m1\nRethink_2m2\nRethink_2m3\nRethink_2m4\nRethink_2m5\nRethink_2m6\nRethink_2m7\nkekse01\nkekse02\neuro-bayes"
  },
  {
    "objectID": "Globusversuch.html#abschluss",
    "href": "Globusversuch.html#abschluss",
    "title": "5Â  Globusversuch",
    "section": "5.7 Abschluss",
    "text": "5.7 Abschluss\n\n5.7.1 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.\n\nğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r \\(W\\) tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)?\n\n\n5.7.2 Vertiefung\nDas â€œBayes-Paradox-Videoâ€ von 3b1b prÃ¤sentiert eine gut verstÃ¤ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber Ã¤hnlichen Darstellung wie in diesem Kapitel.\n\n\n5.7.3 Literatur\nBourier (2018), Kap. 6.2 und 7.1 erlÃ¤utern einige (grundlegende) theoretische HintergrÃ¼nde zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar ist dabei die Binomialverteilung. McElreath (2020), Kap. 2, stellt das Globusmodell mit mehr ErlÃ¤uterung und etwas mehr theoretischem Hintergrund vor.\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung und schlieÃŸende Statistik: praxisorientierte EinfÃ¼hrung: mit Aufgaben und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "Post.html",
    "href": "Post.html",
    "title": "6Â  Die Post befragen",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Post.html#lernsteuerung",
    "href": "Post.html#lernsteuerung",
    "title": "6Â  Die Post befragen",
    "section": "6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n6.1.2 BenÃ¶tigte R-Pakete\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\n6.1.3 Begleitvideos"
  },
  {
    "objectID": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6Â  Die Post befragen",
    "section": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.2.1 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (â€œBayes-Boxâ€) die Postverteilung fÃ¼r den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen und \\(k=10\\) Gitterwerten, also mit 10 Wasseranteilswerten zwischen 0 und 1.\nAbb. AbbildungÂ 6.1 zeigt die resultierende Post-Verteilung.\n\n\nCode\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\nVoilÃ , die Post-Verteilung als Tabelle, auch â€œBayes-Boxâ€ (oder Bayes-Gitter) genannt: s. TabelleÂ 6.1.\n\n\n\n\n\n\nTabelleÂ 6.1:  Postverteilung mit der Gittermethode berechnet \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0.00\n1\n0.00\n0.00\n0.00\n    0.11\n1\n0.00\n0.00\n0.00\n    0.22\n1\n0.00\n0.00\n0.01\n    0.33\n1\n0.03\n0.03\n0.04\n    0.44\n1\n0.11\n0.11\n0.12\n    0.56\n1\n0.22\n0.22\n0.24\n    0.67\n1\n0.27\n0.27\n0.30\n    0.78\n1\n0.20\n0.20\n0.23\n    0.89\n1\n0.06\n0.06\n0.06\n    1.00\n1\n0.00\n0.00\n0.00\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.1: Die Postverteilung fÃ¼r W=6, N=9, k=10\n\n\n\n\n\n\n\nViele nÃ¼tzliche Fragen (und Antworten) leiten sich ab aus Abb. AbbildungÂ 6.1.\n\n\n6.2.2 Beispiele fÃ¼r Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.2.3 Bayes-Box fÃ¼r komplexe Modelle\nBisher, fÃ¼r einfache Fragestellungen hat unsere Bayes-Box, das heiÃŸt die Gittermethode bestens funktioniert: einfach, robust, formschÃ¶n1. Allerdings: Funktioniert sie auch bei komplexeren Modellen? SchlieÃŸlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 PrÃ¤diktor, dann haben wir folgende drei GrÃ¶ÃŸen2 zu schÃ¤tzen: \\(\\beta_0, \\beta_1, \\sigma\\). HÃ¶rt sich gar nicht so viel an. Aber Moment, wir mÃ¼ssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach mÃ¼ssen wir alle AusprÃ¤gungen (â€œGitterwerteâ€) der Variablen multiplizieren. Puh, das wird eine groÃŸe Zahl. Wenn wir fÃ¼r die drei GrÃ¶ÃŸen jeweils 10 AusprÃ¤gungen annehmen, was wenig ist, kÃ¤men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 AusprÃ¤gungen wÃ¤ren es schon \\(100^3=10^6\\) Kombinationen. Das wÃ¤re doch eine recht lange Tabelle.\nBei einer multiplen Regression mit sagen wir 10 PrÃ¤diktoren mit jeweils 100 AusprÃ¤gungen rechnet das arme R bis zum jÃ¼ngsten Tag: $10^{100}. Nein, das kÃ¶nnen wir R nicht zumuten. Wir brauchen eine andere LÃ¶sung!\n\n\n6.2.4 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Mathematik wird so umfangreich bzw. zu komplex.\nGlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten.\nPraktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der das fÃ¼r uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck.\nLernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein(Eine gute EinfÃ¼hrung in die HintergrÃ¼nde findet sich bei McElreath 2020.)\n\n\n6.2.5 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck.\nBevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. ListingÂ 6.1.\n\nListingÂ 6.1: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %>%  # Ziehe mit ZurÃ¼cklegen\n  select(p_grid)\n\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird.\nWir begnÃ¼gen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht.\nDas Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 6.2 dargestellt.\n\n\n\n\n\n\nTabelleÂ 6.2:  Die ersten Zeilen der Stichproben aus der Post-Verteilung \n  \n  \n    \n      p_grid\n    \n  \n  \n    0.333\n    0.667\n    0.667\n    0.667\n    0.667\n  \n  \n  \n\n\n\n\n\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.33 0.67 0.67 0.67 0.67 0.56 0.78 0.78 0.78 0.56 0.67 0.56 0.67 0.44 0.44\n##  [16] 0.56 0.67 0.67 0.67 0.56 0.78 0.67 0.56 0.56 0.78 0.56 0.67 0.33 0.67 0.44\n##  [31] 0.67 0.56 0.56 0.67 0.78 0.67 0.67 0.89 0.67 0.89 0.89 0.44 0.44 0.89 0.67\n##  [46] 0.78 0.56 0.44 0.78 0.67 0.56 0.56 0.67 0.56 0.56 0.78 0.56 0.56 0.56 0.89\n##  [61] 0.78 0.56 0.67 0.44 0.78 0.67 0.78 0.67 0.56 0.56 0.56 0.56 0.33 0.56 0.56\n##  [76] 0.67 0.67 0.67 0.78 0.56 0.78 0.67 0.78 0.67 0.44 0.67 0.56 0.89 0.67 0.89\n##  [91] 0.56 0.89 0.67 0.78 0.67 0.67 0.44 0.56 0.56 0.67\n\nWie sieht diese Tabelle wohl als Histogramm3 aus?\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. AbbildungÂ 6.2.\n\n\n\n\n\nAbbildungÂ 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\nAus AbbildungÂ 6.2 kÃ¶nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% fÃ¼r am wahrscheinlichsten hÃ¤lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlieÃŸen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie AbbildungÂ 6.2 mit AbbildungÂ 5.10: beide sind sehr Ã¤hnlich! Das Stichprobenziehen (AbbildungÂ 6.2) nÃ¤hert sich recht gut an die exakte Berechnung an (AbbildungÂ 5.10).\n\n\n6.2.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) Gitterwerte (AusprÃ¤gungen) nach oben.\n\n\nCode\nk <- 100\nn_success <- 6\nn_trials  <- 9\n\nd_k100 <-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n                      length.out = k),  # 100 Gitterwerte\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\n\nCode\nsamples_k100 <-\n  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\n\nAbbildungÂ 6.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen FÃ¤llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der â€œtypischeâ€ Wert des Modells zu sein. AuÃŸerdem erkennt man, dass das Modell durchaus einige Streuung in der SchÃ¤tzung des Wasseranteils bereithÃ¤lt. Das Modell ist sich nicht sehr sicher, kÃ¶nnte man sagen.\n\n\n\n\n\nAbbildungÂ 6.3: Post-Verteilung mit 100 Gitterwerten, exakt vs.Â auf Basis von Stichproben\n\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. AbbildungÂ 6.4.\n\n\n\n\n\nAbbildungÂ 6.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schÃ¶n â€˜glattâ€™. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist."
  },
  {
    "objectID": "Post.html#die-post-verteilung-befragen",
    "href": "Post.html#die-post-verteilung-befragen",
    "title": "6Â  Die Post befragen",
    "section": "6.3 Die Post-Verteilung befragen",
    "text": "6.3 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in AbbildungÂ 6.5 illustriert.\n\n\n\nAbbildungÂ 6.5: Fragen nach p vs.Â Fragen nach q\n\n\nIm linken Teildiagramm von AbbildungÂ 6.5 fragen wir: â€œWie wahrscheinlich ist ein Wasseranteil von hÃ¶chstens 80%?â€. Im rechten Teildiagramm fragen wir: â€œWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht Ã¼berschritten?â€.\n\n6.3.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nUm diese Frage zu beantworten, zÃ¤hlen wir einfach, wie viele Stichproben die Bedingung erfÃ¼llen:\nund und summieren die Wahrscheinlichkeiten dieser Stichproben:\nWir zÃ¤hlen (count) also die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\n\nCode\nsamples %>%\n  count(p_grid < .5) \n\n\n\n\n\n\np_grid < 0.5\nn\n\n\n\n\nFALSE\n8362\n\n\nTRUE\n1638\n\n\n\n\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.^[Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem PrÃ¼fkriterium, Wasseranteil hÃ¶chstens 50%. Dann zÃ¤hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurÃ¼ck. Man kÃ¶nnte also auch in etwa schreiben:\n\n\nCode\nd %>%\n  filter(p_grid < .5) %>%\n  summarise(sum = sum(post))\n\n\n\n\n\n\nsum\n\n\n\n\n0.16653\n\n\n\n\n\n\nEinfach wie ğŸ° essen.\n\nBeispiel 6.1 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\n\n\nCode\nsamples %>% \n  count(p_grid > .5 & p_grid < .75)\n\n\n\n\n\n\np_grid > 0.5 & p_grid < 0.75\nn\n\n\n\n\nFALSE\n4563\n\n\nTRUE\n5437\n\n\n\n\n\n\n\n\nCode\nsamples %>% \n  count(p_grid > .5 & p_grid < .75) %>% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n\n\n\n\nAnteil\nProzent\n\n\n\n\n0.4563\n45.63\n\n\n0.5437\n54.37\n\n\n\n\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden:\n\n\nCode\nsamples %>% \n  filter(p_grid > .5 & p_grid < .75) %>% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n\n\n\n\nsum\nanteil\n\n\n\n\n0.5437\n54.37\n\n\n\n\n\n\n\n\nBeispiel 6.2 (Wasseranteil zwischen 90 und 100%?) Noch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\n\nCode\nsamples %>% \n  count(p_grid >= .9 & p_grid <= 1) %>% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\nprop\n\n\n\n\n0.01\n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt.\n\nWir kÃ¶nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem â€œGipfelâ€ des Berges, s. AbbildungÂ 6.4.\nFÃ¼r unsere Stichproben-Postverteilung, samples, s. AbbildungÂ 6.2, lÃ¤sst sich der Modus so berechnen:\n\n\nCode\nmap_estimate(samples$p_grid)  \n## MAP Estimate: 0.67\n\n\nDabei steht map fÃ¼r Maximum Aposteriori, also das Maximum der Post-Verteilung.\nBei der Gelegenheit kÃ¶nnten wir folgende, Ã¤hnliche Fragen stellen:\n\nWas ist der mittlere SchÃ¤tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane SchÃ¤tzwert (Median)?\n\nAuf Errisch:\n\n\nCode\nsamples %>% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n\n\n\n\nmean(p_grid)\nmedian(p_grid)\n\n\n\n\n0.6369333\n0.6666667\n\n\n\n\n\n\n\n\n6.3.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall4.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir mÃ¶chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist5.\n\n\nCode\nsamples %>% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n\n\n\n\nquantil90\n\n\n\n\n0.7777778\n\n\n\n\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren, s. fig-post99.\n\n\nCode\nsamples %>% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\n\n\nAbbildungÂ 6.6: Die Post-Verteilung im Globusversuch\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\n\nCode\nsamples %>% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n\n\n\n\nquant_05\nquant_95\n\n\n\n\n0.4444444\n0.8888889\n\n\n\n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n\n6.3.3 Zur Erinnerung: Quantile\nBeispiel: Wie groÃŸ sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%, in Inches6:\n\n\nCode\nspeed_gender_height <- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary <- \n  speed_gender_height %>% \n  mutate(height_cm = height*2.54) %>% \n  select(height_inch = height, height_cm) %>% \n  drop_na() %>% \n  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %>% \n  group_by(Einheit) %>% \n  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n\n\n\n\nEinheit\nq25\nq50\nq75\n\n\n\n\nheight_cm\n160.02\n167.64\n175.26\n\n\nheight_inch\n63.00\n66.00\n69.00\n\n\n\n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildungÂ 6.7 visualisiert die Quantile und die HÃ¤ufigkeitsverteilung.\n\n\n\n\n\nAbbildungÂ 6.7: GrÃ¶ÃŸenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n\n\n6.3.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht Ã¼berschritten wird. Das kÃ¶nnen wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% ab.\nSchaue, was der grÃ¶ÃŸte verbleibende Wert ist.\n\n\n\nCode\nsamples %>% \n  arrange(p_grid) %>%   # sortiere\n  slice_head(n = 9000) %>%  # nur die ersten 90000, also die obersten 1000 abschneiden\n  summarise(p90 = max(p_grid))\n\n\n\n\n\n\np90\n\n\n\n\n0.7777778\n\n\n\n\n\n\nDas (annÃ¤hernd) gleiche Ergebnis liefert quantile():\n\n\nCode\nsamples %>% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n\n\n\n\nq90\n\n\n\n\n0.7777778\n\n\n\n\n\n\n\n\n6.3.5 Visualisierung der Intervalle\nIntervalle (Bereiche), die die â€œabzuschneidendeâ€ Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle oder Equal-Tails-Intervalle (ETI), s. Abb. AbbildungÂ 6.8, rechtes Teildiagramm.\n\n\n\n\n\nAbbildungÂ 6.8: Perzintilintervalle"
  },
  {
    "objectID": "Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "href": "Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "title": "6Â  Die Post befragen",
    "section": "6.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich",
    "text": "6.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nNoch einmal zum Globusversuch: Gehen wir von 3 WÃ¼rfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe):\n\n\nCode\nd_33 <- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %>% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% \n  mutate(unstand_post = likelihood * prior) %>% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 <- \n  d_33 %>% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n    \n  \n  \n    0.95\n1\n0.86\n0.86\n    0.56\n1\n0.18\n0.18\n    0.84\n1\n0.59\n0.59\n    0.91\n1\n0.75\n0.75\n    0.98\n1\n0.94\n0.94\n    0.33\n1\n0.04\n0.04\n  \n  \n  \n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\n\n6.4.1 50%-Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall, s. Abb. AbbildungÂ 6.9.\n\n\n\n\n\nAbbildungÂ 6.9: Schiefe Intervalle\n\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\n\nCode\nlibrary(easystats)\n\nsamples_33 %>% \n  select(p_grid) %>% \n  eti(ci = .5)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np_grid\n0.5\n0.71\n0.93\n\n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.4.2 50%-Intervall hÃ¶chster Dichte\nIntervalle hÃ¶chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als die schmÃ¤lsten Intervalle, die den gesuchten Parameter enthalten.\nDer wahrscheinlichste Parameterwert (1) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten RÃ¤nder nicht mehr gleich groÃŸ, im Sinne von enthalten nicht (zwangslÃ¤ufig) die gleiche Wahrscheinlichkeitsmasse.\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt), s. Abb. AbbildungÂ 6.10.\n\n\n\n\n\nAbbildungÂ 6.10: Visualisierung der PunktschÃ¤tzer bei einer schiefen Post-Verteilung\n\n\n\n\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen:\n\n\nCode\nsamples %>% \n  select(p_grid) %>% \n  bayestestR::hdi(ci = .5)  # aus dem Paket `bayestestR`\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np_grid\n0.5\n0.6666667\n0.7777778\n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich in diesem Bereich befindet (auf Basis eines HDI).\n\n\n\n\n\n\nHinweis\n\n\n\nDas R-Paket {bayestestR} ist Teil des Meta-Pakets {easystats}. Es reicht, wenn Sie easystats laden, damit wird bayestestR automatisch geladen."
  },
  {
    "objectID": "Post.html#fazit",
    "href": "Post.html#fazit",
    "title": "6Â  Die Post befragen",
    "section": "6.5 Fazit",
    "text": "6.5 Fazit\n\n6.5.1 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich\nPerzentilintervalle sind verbreiteter\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n6.5.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datendatz samples, s. ListingÂ 6.1. Sagen wir, wir haben 6 Treffer bei 9 WÃ¼rfen erzielt.\nLageparmameter: Welchen mittleren Wasseranteil muss man annehmen?\n\n\nCode\nsamples %>% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n\n\n\n\nmean\nmedian\n\n\n\n\n0.6369333\n0.6666667\n\n\n\n\n\n\nStreuungsparameter: Wie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?\n\n\nCode\nsamples %>% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n\n\n\n\n\np_sd\np_iqr\np_mad\n\n\n\n\n0.1389354\n0.2222222\n0.1647333\n\n\n\n\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel fÃ¼r einen Parameter, einer unbekannten GrÃ¶ÃŸes eines Modells."
  },
  {
    "objectID": "Post.html#aufgaben",
    "href": "Post.html#aufgaben",
    "title": "6Â  Die Post befragen",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nfattails1\nfattails2\nReThink3e1-7\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "ppv.html",
    "href": "ppv.html",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "ppv.html#lernsteuerung",
    "href": "ppv.html#lernsteuerung",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, was eine Posteriori-PrÃ¤diktiv-Verteilung (PPV) ist, und inwiefern Sie vor Ãœbergewissheit schÃ¼tzt\neine informelle ModellprÃ¼fung fÃ¼r das Beispiel aus dem Unterricht anhand der Posteriori-PrÃ¤diktiv-Verteilung durchfÃ¼hren\n\n\n\n7.1.2 BenÃ¶tigte R-Pakete\n\n\nCode\nlibrary(tidyverse)"
  },
  {
    "objectID": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.2 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.",
    "text": "7.2 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem GlÃ¼cksspiel heraus1. MÃ¼nzwurf; wenn er gewinnt, mÃ¼ssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? NatÃ¼rlich nehmen Sie sofort an.\nSie spielen also MÃ¼nzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal2.\nIst die MÃ¼nze fair oder zieht der mich Ã¼ber den Tisch?, das ist die Frage, die Ihnen brennend durch den Kopf zieht.\nâ€œSind 9 von 10 Treffern noch realistisch erwartbar, wenn es mit rechten Dingen zugeht, oder beweist das Ergebnis, dass die MÃ¼nze gezinkt ist?â€\nWÃ¼tend (und mit leeren Taschen) ziehen Sie von dannen.\nZusammengefasst: Daten: 9 von 10 Treffern beim MÃ¼nzwurf. Forschungsfrage: Ist die MÃ¼nze fair?\nSchauen wir uns zunÃ¤chst einmal an, wie wahrscheinlich 9 von 10 Treffern sind, wenn die MÃ¼nze fair ist, s. AbbildungÂ 7.1.\n\n\n\n\n\nAbbildungÂ 7.1: Stichprobenverteilung einer fairen MÃ¼nze\n\n\n\n\nDie Stichprobenverteilung zeigt, wie wahrscheinlich die empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) sind, gegeben eines Parameterwerts \\(\\pi\\) (z.B. \\(p=0.5\\)): \\(Pr(D|\\pi)\\)3.\nAnders gesagt, die Stichprobenverteilung zeigt die Verteilung der Likelihoods eines bestimmten Parameterwerts.\n\n\n\n\n\n\nHinweis\n\n\n\nDer p-Wert\nDer p-Wert ist die zentrale Statistik der Inferenzstatistik. Er wird genutzt, um Ã¼ber die Ablehnung einer Hypothese zu entscheiden. In diesem Fall entspricht der p-Wert dem tÃ¼rkis markierten FlÃ¤chenanteil in AbbildungÂ 7.1. Ist dieser Anteil kleiner als 5% (der GesamtflÃ¤che im Balkendiagramm), so wird die Hypothese (hier: faire MÃ¼nze) verworfen. Allgemeiner gesprochne berechnet sich der p-Wert als Summe der Likelihoods, die mindestens so extrem sind wie das beobachtete empirische Ergebnis.\n\n\nIn der Bayes-Statistik ist die Post-Verteilung Dreh- und Angelpunkt der Entscheidung Ã¼ber eine Hypothese. In AbbildungÂ 7.2 ist die Posteriori-Verteilung fÃ¼r die Daten zum zwielichten Dozent dargestellt.\n\n\nCode\n# Post-Verteilung:\nd_zwielicht <-\n  tibble(\n    p_grid = seq( from=0 , to=1 , length.out=100),\n    prior = 1,  # Priori-Gewichte\n    likelihood = dbinom(8, size = 10, prob=p_grid) ,\n    unstandardisierte_posterior = likelihood * prior ,\n    posterior = unstandardisierte_posterior / sum(unstandardisierte_posterior))\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples_zwielicht <- \n  tibble(\n    gewinnchance_muenze = sample(\n      d_zwielicht$p_grid , \n      prob=d_zwielicht$posterior, \n      size=1e4, \n      replace=TRUE)) %>% \n  mutate(\n    id = row_number())\n\n\n\n\n\n\n\nAbbildungÂ 7.2: Post-Verteilung zu den Daten des zwielichten Dozenten (9 von 10 Treffern im wiederholten MÃ¼nzwurf)\n\n\n\n\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung.\nJetzt kÃ¶nnen wir wieder die Post-Verteilung auslesen, um die Hypothese zu beantworten. Schauen wir uns einige Beispiel dazu an.\n\nBeispiel 7.1 (EinigermaÃŸen fair?) Wie wahrscheinlich ist es, dass die MÃ¼nze â€œeinigermaÃŸenâ€ fair ist, sagen wir, eine Trefferwahrscheinlichkeit \\(0.45 < \\pi < 0.55\\)4 aufweist?\n\n\nCode\nsamples_zwielicht %>% \n  count(gewinnchance_muenze > 0.45 & gewinnchance_muenze < 0.55) %>% \n  mutate(prop = n/sum(n))\n\n\n\n\n\n\ngewinnchance_muenze > 0.45 & gewinnchance_muenze < 0.55\nn\nprop\n\n\n\n\nFALSE\n9506\n0.9506\n\n\nTRUE\n494\n0.0494\n\n\n\n\n\n\nDie Wahrscheinlichkeit fÃ¼r eine â€œeinigermaÃŸen faireâ€ MÃ¼nze ist klein, etwa 5%!\n\n\nBeispiel 7.2 (MÃ¼nze gezinkt?) Schauen wir uns an, wie wahrscheinlich es ist - gegeben der Daten und unserem Modell - dass die MÃ¼nze massiv gezinkt ist. â€œMassivâ€ definieren wir dabei mit â€œmindestens 70% Trefferwahrscheinlichkeitâ€5, also \\(\\pi >= .7\\)6.\n\n\nCode\nsamples_zwielicht %>% \n  count(gewinnchance_muenze > .7) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\ngewinnchance_muenze > 0.7\nn\nprop\n\n\n\n\nFALSE\n3159\n0.3159\n\n\nTRUE\n6841\n0.6841\n\n\n\n\n\n\nWir finden eine recht hohe Wahrscheinlichkeit fÃ¼r eine â€œmassiveâ€ Manipulation der MÃ¼nze.\n\n\n\n\n\n\n\nWichtig\n\n\n\nIst es nicht einfach und schÃ¶n, wie wir mit Hilfe des Stichprobenziehens allerlei Forschungsfragen beantworten kÃ¶nnen? Eine Post-Verteilung aus Stichproben erlaubt uns, viele Fragen mit einfachen Methoden, nÃ¤mlich schlichtes ZÃ¤hlen, zu beantworten.\n\n\nNatÃ¼rlich kÃ¶nnte (und sollte?) man unser Modell kritisieren. Ist es wirklich sinnvoll, die Trefferwahrscheinlichkeit apriori als gleichverteilt anzunehmen? Das heiÃŸt ja, wir glauben, dass eine Trefferwahrscheinlichkeit von 99,99999% genauso wahrscheinlich ist wie 50,55555%. Auf der anderen Seite: Der Charme einer Gleichverteilung ist, dass sie objektiv ist, in dem Sinne, dass wir keinerlei Information einflieÃŸen lassen. Wir sind indifferent gegenÃ¼ber dem Parameter \\(\\pi\\), der Trefferwahrscheinlichkeit.\n\n\n\n\n\n\nHinweis\n\n\n\nIn einem zweiten Versuch kÃ¶nnten wir jetzt unsere Post-Verteilung als Priori-Verteilung nutzen. Das Ergebnis des ersten Versuchs wird dann hergenommen als Ausgangspunkt fÃ¼r einen zweiten Versuch. Damit wird das Wissen der Wissenschaft weitergegeben7, so wie es sein sollte."
  },
  {
    "objectID": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.3 Mit Stichproben neue Beobachtungen simulieren",
    "text": "7.3 Mit Stichproben neue Beobachtungen simulieren\nZur Erinnerung: Der Likelihood (L) zeigt die Wahrscheinlichkeit eine Trefferzahl gegeben eines bestimmten Parameterwerts. In unseren Beispiel kÃ¶nnten wir z.B. die drei Likelihoods fÃ¼r \\(w=0,1,2\\) ausrechnen, gegeben \\(N=2\\) und \\(p = 0.5\\):\n\n\nCode\nL <- dbinom(0:2, size = 2, prob = 0.5)\nL\n## [1] 0.25 0.50 0.25\n\n\nAh, die Wahrscheinlichkeit fÃ¼r 0 oder 2 Treffer betrÃ¤gt 50%, wenn \\(pi=1/2\\); fÃ¼r 1 Treffer betrÃ¤gt sie entsprechend 50%8.\n\n7.3.1 Wir simulieren die Wasserzahl bei GlobuswÃ¼rfen\nZurÃ¼ck zu unserem Globusversuch!\nWir kÃ¶nnten uns jetzt GlobusbÃ¤lle basteln mit verschiedenen Wasseranteilen, und diese oft hochwerfen. Damit kÃ¶nnten wir herausfinden, welche Trefferzahlen sich bei verschiedenen Wasseranteilen finden lassen wÃ¼rden.\nWer gerne bastelt, freut sich darauf. Kritischere Geister9 wÃ¼rden den Aufwand bemÃ¤ngeln und die Frage nach dem Zweck der Ãœbung stellen10.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn wir wissen, welche Trefferzahlen laut einem Modell zu erwarten sind, kÃ¶nnen wir die echten (beobachteten) Trefferzahlen mit den laut Modell zu erwartenden vergleichen. Damit haben wir eine Methode, mit dem wir ein Modell auf Herz und Nieren prÃ¼fen kÃ¶nnen. Ein schlechtes Modell wird mit seinen Vorhersagen an der RealitÃ¤t scheitern: Erwartung des Modells und beobachtete Daten passen nicht zusammen. Sagt ein Modell etwa \\(W=9\\) vorher bei \\(N=9\\), aber wir finden \\(W=0\\), so wird unser Vertrauen in das Modell erschÃ¼ttert sein. Simulation von Trefferzahlen sind also ein Modell, um die GlaubwÃ¼rdigkeit unseres Golems zu prÃ¼fen. (Nicht nur) bei Golems gilt: Vertrauen ist gut, Kontrolle ist besser.\n\n\nLos gehtâ€™s: Wir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zÃ¤hlen die (Wasser-)Treffer:\n\n\nCode\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n## [1] 0\n\n\nDas geht wie man sieht mit rbinom: r wie random (zufÃ¤llig) und binom wie binomial verteilt, die MÃ¼nzwurfverteilung.\nHier sind die Argumente der Funktion rbinom noch etwas nÃ¤her erklÃ¤rt:\n\n\nCode\nrbinom(n = Wie oft soll der Versuch wiederholt werden?,\n       size = Wie viele GlobuswÃ¼rfe pro Versuch (StichprobengrÃ¶ÃŸe),\n       prob = Wie hoch ist die Wahrscheinlichkeit fÃ¼r Wasser (bzw. fÃ¼r einen Treffer))\n\n\nWeiter: Warum nicht \\(n=10\\) neue Globusversuche simulieren?\n\n\nCode\nrbinom(n = 10, size = 2, prob = 0.7)\n##  [1] 0 2 1 1 1 1 2 1 1 2\n\n\nâ€œSimulierenâ€ heiÃŸt hier, wir lassen den Computer den Globus werfen, ganz anschaulich gesprochen. NatÃ¼rlich wirft der Computer nicht in Wirklichkeit einen Globus oder eine MÃ¼nze, sondern er zieht aus der Menge {0,1} eine Zahl, und wir geben die Wahrscheinlichkeit fÃ¼r jedes der beiden Elemente vor, z.B. jeweils 50%.11.\n\n\n\n\n\n\nWichtig\n\n\n\nSimulationsdaten geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann. MÃ¼nzwÃ¼rfe - und analoge Versuche, wie GlobuswÃ¼rfe - kann man in R mit rbinom erstellen (simulieren).\n\n\n\n\n7.3.2 Traue niemals einem Golem (einem Modell)\n\n\n\nNever trust a Golem\n\n\nQuelle: https://imgflip.com/i/5qmhmo\nImmer prÃ¼fen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsÃ¤chlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prÃ¼fen?"
  },
  {
    "objectID": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.4 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "7.4 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren12:\n\n\nCode\ndraws <- \n  tibble(\n    draws = rbinom(1e6, size = 2, prob = .7))\n\ndraws %>% \n  count(draws) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\ndraws\nn\nprop\n\n\n\n\n0\n89770\n0.089770\n\n\n1\n420629\n0.420629\n\n\n2\n489601\n0.489601\n\n\n\n\n\n\nDiese simulierten HÃ¤ufigkeiten sind sehr Ã¤hnlich zu den theoretisch bestimmten HÃ¤ufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen13.\n\n\nCode\ndbinom(0:2, size = 2, prob = .7)\n## [1] 0.09 0.42 0.49"
  },
  {
    "objectID": "ppv.html#stichprobenverteilung",
    "href": "ppv.html#stichprobenverteilung",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.5 Stichprobenverteilung",
    "text": "7.5 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben fÃ¼r unseren typischen Globusversuch: \\(N=9\\) GlobuswÃ¼rfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise in diesem Versuch? Die Verteilung der zu erwartenden Treffer ist in AbbildungÂ 7.3 dargestellt.\n\n\nCode\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = rbinom(n_draws, size = 9, prob = .7))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n\n\n\n\n\n\n\nAbbildungÂ 7.3: Anteile (Wahrscheinlichkeit), die man fÃ¼r jede Wasserzahl in unserem Globusversuch erwarten kann\n\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir kÃ¶nnen jetzt prÃ¼fen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Stichprobenverteilung ist keine empirische Verteilung: Wir fÃ¼hren diese vielen Versuche nicht wirklich durch14, wir simulieren sie nur am Computer."
  },
  {
    "objectID": "ppv.html#die-posterior-prÃ¤diktiv-verteilung-ppv",
    "href": "ppv.html#die-posterior-prÃ¤diktiv-verteilung-ppv",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.6 Die Posterior-PrÃ¤diktiv-Verteilung (PPV)",
    "text": "7.6 Die Posterior-PrÃ¤diktiv-Verteilung (PPV)\n\n7.6.1 Was ist die PPV und wozu ist sie gut?\nUnsere Stichprobenverteilung zeigt, welche Trefferzahlen bei einem bestimmten Parameterwert, z.B. \\(\\pi=.7\\) in welchen Anteilen zu erwarten sind. Allerdings sind wir uns ja nicht sicher, dass der Wasseranteil genau 70% betrÃ¤gt. Unser (Un-)Wissen Ã¼ber den Wasseranteil wird ja gerade in der Post-Verteilung gespeichert.\nUm eine ehrliche(re) Antwort auf die Frage zu erhalten, wie viele Treffer15 zu erhalten ist, mÃ¼ssen wir die Post-Verteilung berÃ¼cksichtigen.\nWir brauche ein Stichprobenverteilung fÃ¼r jeden Wert der Post-Verteilung. Wenn wir dann die resultierenden Strichprobenverteilungen mitteln, haben wir einen ehrlichen Ãœberblick Ã¼ber die zu erwartenden Trefferzahlen. Dabei sollten wir natÃ¼rlich wahrscheinliche Parameterwerte hÃ¶her gewichten als unwahrscheinliche. So sollte etwa der (hoch wahrscheinliche) Wasseranteil von 70% ein hohes Gewicht beim Mitteln der Stichprobenverteilung erhalten; der sehr unwahrscheinliche Wasseranteil16 von 1% Wasser, sollte entsprechend weniger gewichtet werden, beim Zusammenfassen (d.h. Mittelwert bilden) der Stichprobenverteilungen.\nDie resultierende Verteilung - gemittelte Stichprobenverteilungen Ã¼ber alle Werte der Post-Verteilungen - nennt man Posterior-PrÃ¤diktiv-Verteilung (PPV).\n\n\n\n\n\n\nWichtig\n\n\n\nDie PPV entsteht als gewichteter Mittelwert der Stichprobenverteilungen. Die Gewichte sind die Wahrscheinlichkeiten (bzw. Wahrscheinlichkeitsdichten) der Post-Verteilung.\n\n\n\nBeispiel 7.3 (Magnus Lagrande braucht die PVV) Im Jahre \\(10^{99}\\) wird das Universum von Magnus Lagrande regiert. Die WeltraumbehÃ¶rde, fÃ¼r die Sie arbeiten, ist ihm unterstellt. Der Regent findet Ihre Untersuchungen zwar ganz nett, aber leider versteht er keine Wahrscheinlichkeit. Ist ihm zu abstrakt, sagt er. â€œOder kÃ¶nnen Sie mir mal so eine Wahrscheinlichkeit in die Hand geben? KÃ¶nnen Sie sagen, Achtung, da hinten rennt eine Wahrscheinlichkeit, fang sie!â€ Magnus ist also ein Freund fÃ¼r des Konkreten. Einige einflussreiche Gruppen an Statistiks unterstÃ¼tzen diese Haltung\nJedenfalls hÃ¤tte Magnus gerne eine Aussage wie â€œVermutlich sehen wir beim nÃ¤chsten Versuch irgendwas zwischen 4 und 7 Treffernâ€.\nNatÃ¼rlich haben Sie den Anspruch, eine wissenschaftlich belastbare Aussage zu tÃ¤tigen.\nWas nun? Sie mÃ¼ssen sozusagen die Post-Verteilung in eine Post-Verteilung der Beobachtungen, also der konkreten Werte - in diesem Fall die Anzahl der Wassertreffer - Ã¼bersetzen. Genau das macht die PPV fÃ¼r Sie!\n\n\n\n7.6.2 Visualisierung der PPV\nDer Prozess des gewichteten Zusammenfassens der Stichprobenverteilungen ist in AbbildungÂ 7.4 dargestellt.\n\n\n\nAbbildungÂ 7.4: PPV als gewichtetes Kombinieren der Stichprobenverteilungen\n\n\nQuelle: McElreath (2020)\n\n\n7.6.3 PPV berechnen\nDie PPV fÃ¼r unseren Standard-Globusversuch (\\(N=9\\)) berechnen wir so:\nWir berechnen viele (z.B. \\(10^4\\)) Stichprobenverteilungen. Dabei mÃ¼ssen wir jedes Mal fragen, wie groÃŸ die Wahrscheinlichkeit \\(\\pi\\) fÃ¼r Wasser17 ist. Wasseranteile \\(\\pi\\), die laut Post-Verteilung wahrscheinlich sind, mÃ¼ssen wir entsprechend oft als Parameterwert (\\(\\pi\\)) der Stichprobenverteilung verwenden; umgekehrt dÃ¼rfen wir nur wenige Stichprobenverteilungen fÃ¼r unwahrscheinliche Parameterwerte erstellen.\nBeispielsweise wÃ¼rden wir viele Stichprobenverteilungen fÃ¼r \\(\\pi=.7\\) erstellen; fÃ¼r \\(\\pi=0.01\\) wÃ¼rden wir wenige Stichprobenverteilungen erstellen, s. AbbildungÂ 7.4.\nGlÃ¼cklicherweise spiegelt unsere Stichproben-Postverteilung samples wahrscheinlichere Parameterwerte wieder, indem wahrscheinlichere Parameterwerte hÃ¤ufiger vorkommen.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinliche Parameterwerte kommen in der Stichproben-Postverteilung samples hÃ¤ufiger vor. Die HÃ¤ufigkeit der Parameterwerte spiegelt die Wahrscheinlichkeit der jeweiligen Parameterwerte in der (theoretischen) Postverteilung wider.\n\n\nSchauen Sie sich vielleicht zur Erinnerung noch einmal die Definition von samples an, s. ListingÂ 6.1. Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 6.2 dargestellt. Wie die Post-Verteilung auf Basis von Stichproben dann aussieht sieht man in AbbildungÂ 6.2. Globusversuche kann man mit rbinom simulieren, s. KapitelÂ 7.3.1.\nWir simulieren also viele (z.B \\(10^4\\)) Globusversuche, jeweils mit \\(N=9\\) WÃ¼rfen. Wahrscheinliche Parameterwerte, etwa \\(\\pi=7\\), sollen hÃ¤ufiger verwendet werden (bei unseren vielen Globusversuchen) als unwahrscheinliche.\nPraktischerweise sind die Werte in der Spalte p_grid in samples so hÃ¤ufig vertreten, wie ihre Wahrscheinlichkeit es erwarten lÃ¤sst. Hier ist ein Auszug aus samples:\n\n\nCode\nsamples %>% \n  select(p_grid) %>% \n  slice_head(n = 10)\n\n\n\n\n\n\np_grid\n\n\n\n\n0.6666667\n\n\n0.4444444\n\n\n0.7777778\n\n\n0.6666667\n\n\n0.6666667\n\n\n0.7777778\n\n\n0.6666667\n\n\n0.6666667\n\n\n0.8888889\n\n\n0.8888889\n\n\n\n\n\n\nWie man sieht, sind wahrscheinliche Parameterwerte hÃ¤ufiger vertreten.18\np_grid ist also eine Liste19 von Parameterwerten, deren HÃ¤ufigkeit die Wahrscheinlichkeit der Parameterwerte gewichtet.\nAuf dieser Basis kÃ¶nnen wir die PPV erstellen:\n\n\nCode\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nhead(ppv)\n\n\n\n\n\n\nvalue\n\n\n\n\n7\n\n\n5\n\n\n7\n\n\n6\n\n\n5\n\n\n5\n\n\n\n\n\n\nSchauen wir uns ein Histogramm aller Trefferzahlen an, s. AbbildungÂ 7.5.20\n\n\n\n\n\nAbbildungÂ 7.5: Die PPV fÃ¼r unseren Standard-Globusversuch (N=9)\n\n\n\n\nDie PPV unseres Modells zeigt uns (AbbildungÂ 7.5), dass wir in kÃ¼nftigen Versuchen zumeist 6 Treffer zu erwarten haben. Aber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar.\n\n\n\n\n\n\nWichtig\n\n\n\nDie PPV zeigt, welche Beobachtungen laut unserem Modell hÃ¤ufig und welche selten sind. Die PPV zeigt keine Parameterwerte, sondern welche Daten (Beobachtungen, Wasserzahlen) wir in kÃ¼nftigen Versuchen wie hÃ¤ufig erwarten kÃ¶nnen.\n\n\n\nBeispiel 7.4 (Der nÃ¤chste Planet) Nur zum SpaÃŸ spulen wir kurz die Zeit im Universum vor, sagen wir so \\(10^{99}\\) Jahre. Sie arbeiten bei einer RaumfahrtbehÃ¶rde, die nach neuen Planeten sucht. Nun wurde ein aussichtsreicher Planet gesichtet. Ihre BehÃ¶rde hat eine Studie gestartet, im Rahmen derer 9 Sonden zu diesem (weit entfernten) Planeten geschossen sind. Von den 9 Sonden sind 6 im Wasser gelandet, was aus GrÃ¼nden intergalaktischer Wasserknappheit eine gute Nachricht ist.\n\nâ€œDer nÃ¤chste Planet wird sicher 6 von 9 Wassertreffer erzielen!â€\n\nâ€“ Presse-Chefi der intergalaktischer SpaceY RaumfahrtsbehÃ¶rde\nJetzt plant Ihre BehÃ¶rde den Versuch zu wiederholen: Wieder sollen 9 Sonden zu diesem Planeten geschossen werden. Dis Presse-Chefi21 tÃ¶nt vollmundig: â€œIch bin sicher, dass wir wieder 6 von 9 Treffer, also 6 von 9 Mal Wasser, haben werden!â€.\nKann man diese Aussage mit (hoher) Sicherheit leisten? Perfekte Sicherheit gibt es bekanntlich nur, was Tod und Steuern betrifft, aber kann diese Aussage mit zumindest hoher Sicherheit geleistet werden?\nNein, die PPV (AbbildungÂ 7.5) zeigt deutlich, dass unser Wissen nicht ausreicht, um prÃ¤zise Vorhersagen Ã¼ber kÃ¼nftige AusgÃ¤nge des Versuchs zu leisten. So sind auch 5 oder 7 Treffer gut mÃ¶glich. Auch 4 oder 8 Treffer sind nicht so selten. Sogar 9 Treffer sind nicht super selten.\nDis Presse-Chefi Ihrer BehÃ¶rde sollte also den Mund nicht so voll nehmen."
  },
  {
    "objectID": "ppv.html#fazit",
    "href": "ppv.html#fazit",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.7 Fazit",
    "text": "7.7 Fazit\n\n7.7.1 Vorhersagen sind schwierig\nâ€¦ gerade wenn sie die Zukunft betreffen, so ein Sprichwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der hÃ¤ufigste in unseren Stichproben, aber die Vorhersagen haben eine groÃŸe Streuung, bergen also recht hohe Ungewissheit. Die PPV zeigt also, welche Beobachtungen laut unserem Modell kÃ¼nftig zu erwarten sind, s. AbbildungÂ 7.5.\nWÃ¼rde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hÃ¤tten die Vorhersagen zu wenig Streuung in den Vorhersagen, wÃ¼rden also die Ungewissheit nicht ausreichend abbilden. Es wÃ¼rde Ãœbergewissheit (Overconfidence, Overfitting) resultieren.\nWir brauchen die PPV. Ohne die PPV kÃ¶nnen wir nicht seriÃ¶s abschÃ¤tzen, wie viel Ungewissheit in unseren Vorhersagen steckt.\n\n\n7.7.2 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells (â€œintrinsischeâ€ Ungewissheit): Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiÃŸ, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nÃ¤chste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, mÃ¶chte man beide Arten von Ungewissheit berÃ¼cksichtigen: Das macht die Posteriori-PrÃ¤diktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prÃ¤diktiv) und mit welcher HÃ¤ufigkeit, basierend auf der Post-Verteilung.\n\n\n\n\n\n\nHinweis\n\n\n\nDer Unterschied zwischen der Post-Verteilung und der PPV ist erstmal, dass die PPV AusprÃ¤gungen in ihrer Wahrscheinlichkeit bemisst, also z.B. wie wahrscheinlich 4 von 9 Wassertreffern sind. Die Post-Verteilung bemisst die Wahrscheinlichkeit von Parameterwerten, also z.B. des Wasseranteils.\nEtwas tiefer betrachtet zeigt die PPV zwei Arten von Ungewissheit, die Post-Verteilung nur eine. Die PPV zeigt erstens die Ungewissheit zur Verteilung des Parameters (wie die Post-Verteilung), aber auch noch die intrinsische Ungewissheit. Denn auch wenn wir keine Ungewissheit zum Parameter hÃ¤tten, bliebe Ungewissheit, welche Beobachtungen sich manifestieren. Insofern ist die PVV â€œehrlicherâ€, sie spiegelt die Ungewissheit zu den Beobachtungen wider.\n\n\n\n\n7.7.3 Vergleich der Verteilungen\nAbbildungÂ 7.6 stellt die in diesem Kapitel diskutierten Verteilungen gegenÃ¼ber:\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-PrÃ¤diktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter BerÃ¼cksichtigung der Unsicherheit der Posteriori-Verteilung\n\n\n\n\n\n\nAbbildungÂ 7.6: Post- vs.Â Stichproben- vs.Â PP-Verteilungen\n\n\n\n\nQuelle: R. McElreath\n\n\n7.7.4 So viele Verteilungenâ€¦\n\nDie Posteriori-Verteilung gibt Aufschluss zur HÃ¤ufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass â€œin Wirklichkeitâ€ der Wasseranteil 70% betrÃ¤gt, also \\(\\pi=.7\\)\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\nDie PPV gibt Aufschluss zur HÃ¤ufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter DurchfÃ¼hrung, zu erwarten.\nFÃ¼r die Praxis kann das eine interessante Frage sein.\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklÃ¤rt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden."
  },
  {
    "objectID": "ppv.html#aufgaben",
    "href": "ppv.html#aufgaben",
    "title": "7Â  Vorhersage-Verteilung",
    "section": "7.8 Aufgaben",
    "text": "7.8 Aufgaben\n\nZwielichter Dozent-Bayes\nWarum Bayes?\nsubjektiv-Bayes\nLikelihood2\nAnteil-Apple\nReThink3m1\nReThink3m2\nReThink3m3\nReThink3m4\nReThink3m5\nQuiz zu Verteilungen\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "gauss.html",
    "href": "gauss.html",
    "title": "8Â  Gauss-Modelle",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "gauss.html#lernsteuerung",
    "href": "gauss.html#lernsteuerung",
    "title": "8Â  Gauss-Modelle",
    "section": "8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nein Gaussmodell spezifizieren und inR berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n8.1.2 BenÃ¶tigte R-Pakete\nFÃ¼r rstanarm wird ggf. weitere Software benÃ¶tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, mÃ¼ssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio mÃ¼ssen Sie die (benÃ¶tigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n\n8.1.3 Begleitvideos\n\nTeil 1\nTeil 2"
  },
  {
    "objectID": "gauss.html#wie-groÃŸ-sind-die-kung-san",
    "href": "gauss.html#wie-groÃŸ-sind-die-kung-san",
    "title": "8Â  Gauss-Modelle",
    "section": "8.2 Wie groÃŸ sind die !Kung San?",
    "text": "8.2 Wie groÃŸ sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. AbbildungÂ 8.1.\nThe ÇƒKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names ÇƒKung (ÇƒXun) and Ju are variant words for â€˜peopleâ€™, preferred by different ÇƒKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of ÇƒKung people live in the villages of Bantu pastoralists and European ranchers.\nQuelle\n\n\n\n\n\n\n\n(a) Kung People\n\n\n\n\n\n\n\n(b) Verbreitung der Kung-Sprachen\n\n\n\n\nAbbildungÂ 8.1: Die !Kung im sÃ¼dlichen Afrika\n\n\nQuelle: Internet Archive Book Images, No restrictions, via Wikimedia Commons\nQuelle: By Andrewwik.0 - Own work, CC BY-SA 4.0,]\n\n\n8.2.2 !Kung Data\nZuerst laden wir die Daten; Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\nDatenquelle\n\n\nCode\nKung_path <-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd <- data_read(Kung_path)  # aus dem Paket `easystats`\n\nhead(d)\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n151.765\n47.82561\n63\n1\n\n\n139.700\n36.48581\n63\n0\n\n\n136.525\n31.86484\n65\n0\n\n\n156.845\n53.04191\n41\n1\n\n\n145.415\n41.27687\n51\n0\n\n\n163.830\n62.99259\n35\n1\n\n\n\n\n\n\nWir interessieren uns fÃ¼r die GrÃ¶ÃŸe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als d2.\n\n\nCode\nd2 <- d %>% \n  filter(age >= 18)\n\nnrow(d2)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tatsÃ¤chlich recht easy.\n\n\nCode\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n\n  \n  \n    \n      Variable\n      Mean\n      SD\n      IQR\n      Min\n      Max\n      Skewness\n      Kurtosis\n      n\n      n_Missing\n    \n  \n  \n    height\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\nâˆ’0.48\n352.00\n0\n    weight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\nâˆ’0.51\n352.00\n0\n    age\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\nâˆ’0.21\n352.00\n0\n    male\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\nâˆ’2.00\n352.00\n0\n  \n  \n  \n\n\n\n\n\n\n8.2.3 Wir gehen apriori von normalverteilter GrÃ¶ÃŸe Der !Kung aus\nForschungsfrage: Wie groÃŸ sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also fÃ¼r den Mittelwert der KÃ¶rpergrÃ¶ÃŸe (erwachsener Kung beider Geschlechter), \\(\\mu\\).\n\n\n\nMensch\n\n\nQuelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, via Wikimedia Commons 3.0\nWir sind uns Ã¼ber diesen Mittelwert nicht sicher1, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178cm und Streuung von 20 cm:\n\\[\\mu \\sim \\mathcal{N}(178, 20)\\]\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.2 In einer echten Untersuchung sollte man immer einen inhaltlichen Grund fÃ¼r einen Priori-Wert haben. Oder man wÃ¤hlt â€œschwach informativeâ€ Prioris, wie das {rstanarm} tut: Damit lÃ¤sst man kaum Vorab-Information in das Modell einflieÃŸen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der KÃ¶rpergrÃ¶ÃŸen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. DarÃ¼ber hinaus ist eine Normalverteilung nicht unplausibel."
  },
  {
    "objectID": "gauss.html#die-exponentialverteilung",
    "href": "gauss.html#die-exponentialverteilung",
    "title": "8Â  Gauss-Modelle",
    "section": "8.3 Die Exponentialverteilung",
    "text": "8.3 Die Exponentialverteilung\n\n8.3.1 Die Apfel-fÃ¤llt-nicht-weit-vom-Stamm-Verteilung\nDarf ich vorstellen â€¦\nBevor wir unser Kung-Modell spezifizieren kÃ¶nnen, sollten wir noch Ã¼berlegen, welches Vorab-Wissen wir zur Streuung um den Mittelwert herum haben. Da wir uns nicht 100% sicher zur gesuchten GrÃ¶ÃŸe sind, mÃ¼ssen wir angeben, wie groÃŸ die Streuung um den Mittelwert sein soll. Hier werden wir eingestehen, dass wir uns auch nicht 100% sicher sind, wie groÃŸ die Streuung exakt ist. Also geben wir eine Verteilung fÃ¼r die Streuung an.\nEtwas Wissen Ã¼ber diese Verteilung haben wir:\n\nEine Streuung muss positiv sein (es gibt keine negative Streuung).\nEine Gleichverteilung der Streuung ist vielleicht mÃ¶glich, aber nicht sehr plausibel.\nWenn wir der Meinung sind, der Mittelwert betrage â€œungefÃ¤hr 178cmâ€, so halten wir 180cm fÃ¼r plausibel, aber 18000 cm fÃ¼r unmÃ¶glich und schon 200 fÃ¼r sehr unplausibel. Also: Je grÃ¶ÃŸer die die Abweichung vom Mittelwert desto unplausibler.\n\nDiese Anforderungen3 spiegeln sich in AbbildungÂ 8.2 wider. AuÃŸerdem zeigt die Abbilung verschiedene Quantile, wie das 95%-Quantil, das bei 3 liegt; 95% der Werte dieser Verteilung sind also nicht grÃ¶ÃŸer als 3.\n\n\nCode\nd <-\n  tibble(\n    x = seq(0, 5,.1),\n    y = dexp(x, rate = 1)\n  )\n\n\nd_qs <-\n  tibble(\n    prob = c(0.05, .25, .50, .75, .95),\n    q = qexp(prob) \n  )\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line() +\n  geom_area(fill = \"grey60\") +\n  geom_vline(data = d_qs,\n             aes(xintercept = q)) +\n  geom_label(data = d_qs,\n             aes(x = q, \n                 label = prob,\n                 y = prob)) +\n  labs(\n       caption = \"Vertikale Striche zeigen die Quantile fÃ¼r 5%, 25%, 50%, 75%, 95%\",\n       y = \"Dichte\")\n\n\n\n\n\nAbbildungÂ 8.2: Die Exponentialverteilung mit einigen ihrer Quantilen\n\n\n\n\nFÃ¼r eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung.\n\nEine Exponentialverteilung ist nur fÃ¼r positive Werte, \\(x>0\\), definiert.\nSteigt X um eine Einheit, so Ã¤ndert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (â€œlambdaâ€).\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (â€œGestrecktheitâ€) der Verteilung an.\nJe grÃ¶ÃŸer die Rate \\(\\lambda\\), desto kleiner die Streuung und der Mittelwert der Verteilung.\nJe grÃ¶ÃŸer \\(1/\\lambda\\), desto grÃ¶ÃŸer die Streuung und der Mittelwert der Verteilung.\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren PlÃ¤nen passt.\n\n\n8.3.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zurÃ¼ckzufÃ¼hren, s. AbbildungÂ 8.3.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.3: Beispiele von Expnentialverteilungen mit unterschiedlichem lambda\n\n\n\n\nWie wir in AbbildungÂ 8.3 sehen, kÃ¶nnte eine Exponentialverteilung mit \\(\\lambda=1/8\\) grob passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie â€œrichtigenâ€ Priori-Verteilung zu finden, bzw. die richtigen Parameter fÃ¼r die Priori-Verteilung zu wÃ¤hlen, ist nicht mÃ¶glichn, denn es gibt nicht die eine, richtige Priori-Verteilung. Eine â€œgut passendeâ€ Verteilung zu finden, ist hÃ¤ufig nicht leicht. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu wÃ¤hlen, die einen breiteren Raum an mÃ¶glichen Werten zulÃ¤sst. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie mehrere Meter KÃ¶rpergrÃ¶ÃŸe Streuung, erlauben.\n\n\nMan kann sich die Quantile der Exponentialverteilung mit qexp ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, fÃ¼r den man das Quantil haben mÃ¶chte. Mit rate wird \\(\\lambda\\) bezeichnet.\nDieser Aufruf zum Beispiel:\n\n\nCode\nqexp(p = .5, rate = 1/8)\n## [1] 5.545177\n\n\nGibt uns die Verteilungsfunktion einer Exponentialverteilung mit Rate (\\(\\lambda\\)) von 1/8 zurÃ¼ck, ca. 5.5.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich so ausgeben lassen:\n\n\nCode\nqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2025425 29.5110356\n\n\nDiese Grenzen scheinen hinreichend weit, das wir noch von den Daten Ã¼berrascht werden kÃ¶nnen, aber schmal genug, um unsinnige Werte auszuschlieÃŸen. Ein guter Start! Weiter gehtâ€™s!"
  },
  {
    "objectID": "gauss.html#unser-gauss-modell-der-kung",
    "href": "gauss.html#unser-gauss-modell-der-kung",
    "title": "8Â  Gauss-Modelle",
    "section": "8.4 Unser Gauss-Modell der !Kung",
    "text": "8.4 Unser Gauss-Modell der !Kung\n\n8.4.1 Modelldefinition\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior fÃ¼r \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior fÃ¼r \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn AbbildungÂ 8.4 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\nAbbildungÂ 8.4: Unser (erstes) Kung-Modell\n\n\n\n\n\n\n8.4.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie KÃ¶rpergrÃ¶ÃŸen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})\\]\n\n\n8.4.3 Prioris\nMittelwert der GrÃ¶ÃŸe ist normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)}\\]\nDie Streuung \\(\\sigma\\) der GrÃ¶ÃŸen ist exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)}\\]\n\n\n8.4.4 Fertig!\nJetzt haben wir unser Modell definiert!\nWeil es so schÃ¶n ist, schreiben wir es hier noch einmal auf, GleichungÂ 8.1.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) \\\\\n\\sigma &\\sim \\mathcal{E}(1/8)\n\\end{aligned}\n\\tag{8.1}\\]\nZur Berechnung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich krÃ¤ftig der Bursche, der soll die Arbeit fÃ¼r uns tun. Der Golem hÃ¶rt auf den Namen rstanarm4."
  },
  {
    "objectID": "gauss.html#zufÃ¤llige-motivationsseite",
    "href": "gauss.html#zufÃ¤llige-motivationsseite",
    "title": "8Â  Gauss-Modelle",
    "section": "8.5 ZufÃ¤llige Motivationsseite",
    "text": "8.5 ZufÃ¤llige Motivationsseite"
  },
  {
    "objectID": "gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "href": "gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "title": "8Â  Gauss-Modelle",
    "section": "8.6 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41",
    "text": "8.6 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m415.\n\n\nCode\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)\nm41_post <- as_tibble(m41)  # Modellergebnis in Tabelle umwandeln\nnames(m41_post) <- c(\"mu\", \"sigma\")  # schÃ¶nere Namen fÃ¼r die Spalten\n\n\nDas Argument refresh = 0 verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrÃ¼cke.\nstan_glm ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein â€œrichtigesâ€ Regressionsmodell. Man kÃ¶nnte sagen, wir haben eine AV (KÃ¶rpergrÃ¶ÃŸe), aber keine UV (keine PrÃ¤diktoren). GlÃ¼cklicherweise kÃ¶nnen wir auch solche â€œarmenâ€ Regressionsmodelle formulieren:\nav ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen mÃ¶chte, aber keine PrÃ¤diktoren hat (das soll die 1 symbolisieren).\nFÃ¼r das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung der Prioris von rstanarm zurÃ¼ck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wÃ¤re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die Posteriori-Verteilung von m41, s. AbbildungÂ 8.5.\n\n\nCode\nm41_post %>% \n  ggplot() +\n  aes(x = mu, y = sigma) %>% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\nAbbildungÂ 8.5: Die gemeinsame Verteilung von Mittelwert und Streuung.\n\n\n\n\nDa das Modell zwei Parameter hat, kÃ¶nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen kÃ¶nnen die Parameter korreliert sein.\nAbbildungÂ 8.5 erlaubt uns, fÃ¼r jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m42, s. AbbildungÂ 8.6.\n\n\n\n\n\nAbbildungÂ 8.6: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\nNatÃ¼rlich kÃ¶nnen wir auch nur einen Parameter plotten.\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung fÃ¼r \\(\\mu\\) und eine fÃ¼r \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, fÃ¼r die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte fÃ¼r \\(\\mu\\) und \\(\\sigma\\) klein: Die groÃŸe Stichprobe hat die Priori-Werte Ã¼berstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so kÃ¶nnen wir interessante Fragen stellen.\n\n\n8.6.1 Hallo, Posteriori-Verteilung\nâ€¦ wir hÃ¤tten da mal ein paar Fragen an Sie. ğŸ•µ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person grÃ¶ÃŸer als 1,55m?\nWelche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?\nWas ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?\n\nAntworten folgen etwas weiter unten.\nAbschlieÃŸend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), AbbildungÂ 8.7.\n\n\n\n\n\nAbbildungÂ 8.7: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen fÃ¼r mu und fÃ¼r sigma\n\n\n\n\n\n\n8.6.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() kÃ¶nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - Ã¤hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurÃ¼ck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so:\n\n\nCode\nlibrary(rstanarm)  # Paket muss gestartet sein.\n\n# berechnet Post.-Vert.:\nstan_glm(\n  # modelldefinition:\n  AV ~ UV,\n  # Datensatz:\n  data = meine_daten\n)\n\n\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum GrÃ¶ÃŸenmittelwert\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der GrÃ¶ÃŸen\n\n\n8.6.3 Ausgabe von stan_glm()\nWir kÃ¶nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir kÃ¶nnen es aber auch komfortabler haben â€¦ Mit dem Befehl parameters kann man sich die geschÃ¤tzten Parameterwerte einfach ausgeben lassen.\n\n\nCode\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket `easystats`\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.79, 155.35)\n100%\n1.001\n3030.00\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem schÃ¤tzt den GrÃ¶ÃŸenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.7875529 bis 155.3477557 schÃ¤tzt.\nInformativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu spÃ¤ter mehr.\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren :-)\nWer NÃ¤heres wissen will, findet hier einen Anfang. AuÃŸerdem sei an McElreath (2020) und Gelman, Hill, und Vehtari (2021) verwiesen."
  },
  {
    "objectID": "gauss.html#wie-tickt-stan_glm",
    "href": "gauss.html#wie-tickt-stan_glm",
    "title": "8Â  Gauss-Modelle",
    "section": "8.7 Wie tickt stan_glm()?",
    "text": "8.7 Wie tickt stan_glm()?\n\n\n\n\n\nQuelle\nHier ein paar Kernimnfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan fÃ¼r uns bereit.\nstan_glm() ist fÃ¼r die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schÃ¤tzen, so hat man man â€¦ eine Regression ohne PrÃ¤diktor.\nEine Regression ohne PrÃ¤diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also fÃ¼r die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n8.7.1 SchÃ¤tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die GrÃ¶ÃŸen, fÃ¼r die wir eine Priori-Verteilung annehmen sowie einen Likelihood und dann aus den Daten schÃ¤tzen. Ich sage schÃ¤tzen um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren.\nWie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren SchÃ¤tzungen) einfach mit parameters(modellname) auslesen.\n\n\n8.7.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, kÃ¶nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_m41:\n\n\nCode\npost_m41 <- as_tibble(m41)\nhead(post_m41)\n\n\n\n\n\n\n(Intercept)\nsigma\n\n\n\n\n154.6373\n8.317947\n\n\n154.9276\n7.638285\n\n\n154.4969\n7.023710\n\n\n154.7020\n7.918491\n\n\n155.1503\n7.580628\n\n\n153.9865\n7.471944\n\n\n\n\n\n\nIn einer Regression ohne PrÃ¤diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss Ã¼ber unsere SchÃ¤tzwerte zu \\(\\mu\\) (der KÃ¶rpergrÃ¶ÃŸe).\n\n\nBeispiel 8.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu>155\\)?) \n\nCode\nnames(post_m41) <- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_m41 %>% \n  count(mu > 155) %>% \n  mutate(prop = n/sum(n))\n\n\n\n\n\n\nmu > 155\nn\nprop\n\n\n\n\nFALSE\n3374\n0.8435\n\n\nTRUE\n626\n0.1565\n\n\n\n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlieÃŸen, dass die Kung im Schnitt grÃ¶ÃŸer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind.\n\n\n\nBeispiel 8.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu>165\\)?) \n\nCode\nnames(post_m41) <- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_m41 %>% \n  count(mu > 165) %>% \n  mutate(prop = n/sum(n))\n\n\n\n\n\n\nmu > 165\nn\nprop\n\n\n\n\nFALSE\n4000\n1\n\n\n\n\n\n\nOh, diese Hypothese kÃ¶nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlieÃŸen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu > 165\\) auszuschlieÃŸen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\nBeispiel 8.3 (Welche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell m41?) \n\nCode\npost_m41 %>% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n\n\n\nq95\n\n\n\n\n155.2329\n\n\n\n\n\n\n\n\n\nBeispiel 8.4 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) \n\nCode\npost_m41 %>% \n  eti()\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\nmu\n0.95\n153.787553\n155.347756\n\n\nsigma\n0.95\n7.202283\n8.358525\n\n\n\n\n\n\nEin ETI ist synonym zu PI.\n\n\n\nBeispiel 8.5 (Mit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?) \n\nCode\nm41 %>% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n154.5979\n0.95\n153.7876\n155.3478\n1\n1.000545\n3030.146\nnormal\n154.5971\n19.35583\n\n\n\n\n\n\nSeeing is believing:\n\n\nCode\nm41 %>% \n  parameters() %>% \n  plot(show_intercept = TRUE)\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren KÃ¶rpergrÃ¶ÃŸe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\nBeispiel 8.6 (Was ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?) parameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\nğŸ‹ï¸ Ã„hnliche Fragen bleiben als Ãœbung fÃ¼r die Lesis ğŸ¤“.\n\n\n8.7.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt fÃ¼r uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m41)\n## Priors for model 'm41' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden dafÃ¼r die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage fÃ¼r die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht â€œpures Bayesâ€, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte wÃ¤ren auch denkbar.\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (fÃ¼r \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals â€œStreuungâ€, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen.\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wÃ¤hlen, dass man nicht Ã¼bergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlieÃŸen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflieÃŸen zu lassen und eigene Entscheidungen zu begrÃ¼nden. HÃ¤ufig sind mehrere Entscheidungen mÃ¶glich. MÃ¶chte man lieber vorsichtig sein, weil man wenig Ã¼ber den Gegenstand weiÃŸ, dann kÃ¶nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die â€œschwachinformativâ€ ist, also nur wenig Priori-Information ind das Modell einflieÃŸen lÃ¤sst."
  },
  {
    "objectID": "gauss.html#modell-m42-unsere-priori-werte",
    "href": "gauss.html#modell-m42-unsere-priori-werte",
    "title": "8Â  Gauss-Modelle",
    "section": "8.8 Modell m42: unsere Priori-Werte",
    "text": "8.8 Modell m42: unsere Priori-Werte\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflieÃŸen, in unserem zweiten Kung-Modell, m42.\n\n8.8.1 m42\nDann lassen wir stan_glm() unser zweites Modell berechnen. Dieses Mal geben wir die Priori-Werte explizit an.\n\n\nCode\nm42 <- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n154.6083\n0.95\n153.8345\n155.3875\n1\n1.00001\n2901.489\nnormal\n178\n20\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die hier ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige FÃ¤higkeit im Studium ğŸ¤“.\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m41 und m42! Was fÃ¤llt Ihnen auf? Nichts? Gut! TatsÃ¤chlich liefern beide Modelle sehr Ã¤hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigermaÃŸen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gewÃ¤hlt waren.\n\n\n\n\n\n\n\n8.8.2 Posteriori-Verteilung und Parameter plotten\n\n\nCode\nm42 %>% \n  as_tibble() %>% \n  ggplot(aes(x = `(Intercept)`)) +\n  geom_histogram()\n\n\n\n\n\nEin Vergleich mehrerer Priori-Werte wÃ¤re auch nÃ¼tzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewÃ¤hlten Priori-Werte zu Ã¼berzeugen."
  },
  {
    "objectID": "gauss.html#fazit",
    "href": "gauss.html#fazit",
    "title": "8Â  Gauss-Modelle",
    "section": "8.9 Fazit",
    "text": "8.9 Fazit\nWir haben die Posteriori-Verteilung fÃ¼r ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne PrÃ¤diktoren, betrachtet. Die Zielvariable, KÃ¶rpergrÃ¶ÃŸe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. FÃ¼r \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung fÃ¼r \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n\nğŸ§¡ Bleiben Sie dran!"
  },
  {
    "objectID": "gauss.html#wahl-der-priori-werte",
    "href": "gauss.html#wahl-der-priori-werte",
    "title": "8Â  Gauss-Modelle",
    "section": "8.10 Wahl der Priori-Werte",
    "text": "8.10 Wahl der Priori-Werte\nğŸï¸ Dieser Abschnitt ist eine VERTIEFUNG und nicht prÃ¼fungsrelevant. ğŸ\n\n8.10.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn <- 1e4\n\nsim <- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %>% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd <- \n  sd(sim$height) %>% round()\nheight_sim_mean <- \n  mean(sim$height) %>% round()\n\n\nğŸ’­ Was denkt der Golem (m41) apriori von der GrÃ¶ÃŸe der !Kung?\nğŸ¦¾ Ziehen wir mal ein paar Stichproben auf Basis des Modells. VoilÃ :\n\n\nCode\np3 <- \n  sim %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MWÂ±3SD\",\n       x = \"GrÃ¶ÃŸe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\nQuellcode\n\n\n8.10.2 Priori-Werte prÃ¼fen mit der Priori-PrÃ¤diktiv-Verteilung\n\nDie Priori-PrÃ¤diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo kÃ¶nnen wir prÃ¼fen, ob die Priori-Werte vernÃ¼nftig sind.\n\nDie Priori-PrÃ¤diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an GrÃ¶ÃŸenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\nAnteil \\(h_i > 200\\):\n\n\nCode\nanteil_groÃŸer_kung <- \nsim %>% \n  count( height > 200) %>% \n  mutate(prop = n/sum(n))\nanteil_groÃŸer_kung\n\n\n\n\n\n\nheight > 200\nn\nprop\n\n\n\n\nFALSE\n8296\n0.8296\n\n\nTRUE\n1704\n0.1704\n\n\n\n\n\n\nğŸ¤” Sehr groÃŸe Buschleute? 17 Prozent sind grÃ¶ÃŸer als 2 Meter. Das ist diskutabel, muss aber nicht zwangslÃ¤ufig ein schlechter Prior sein.\n\n\n8.10.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n8.10.4 Extrem vage Priori-Verteilung fÃ¼r die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\nCode\n# simulate\nset.seed(4)\n\nsim2 <-\n  tibble(sample_mu    = rnorm(n, mean = 178, sd = 100),\n         sample_sigma = rexp(n, rate = .01)) %>% \n  mutate(height = rnorm(n, mean = sample_mu, sd = sample_sigma))\n\n# compute the values we'll use to break on our x axis\nbreaks <-\n  c(mean(sim2$height) - 3 * sd(sim2$height), 0, mean(sim2$height), mean(sim2$height) + 3 * sd(sim2$height)) %>% \n    round(digits = 0)\n\n# this is just for aesthetics\ntext <-\n  tibble(height = 272 - 25,\n         y      = .0013,\n         label  = \"grÃ¶ÃŸter Mann\",\n         angle  = 90)\n\n# plot\np4 <-\n  sim2 %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"black\") +\n  geom_vline(xintercept = 0, color = \"grey92\") +\n  geom_vline(xintercept = 272, color = \"grey92\", linetype = 3) +\n  geom_text(data = text,\n            aes(y = y, label = label, angle = angle),\n            color = \"grey92\") +\n  scale_x_continuous(breaks = breaks, \n                     limits = c(-400, 700)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\\nmu ~ dnorm(178, 100)\\nsigma ~ E(0.01)\",\n       x = \"GrÃ¶ÃŸe\",\n       caption = \"X-Achse zeigt MWÂ±3SD\") +\n  theme(panel.grid = element_blank()) \n\np4\n\n\n\n\n\nDie Streuung der GrÃ¶ÃŸen ist weit:\n\n\nCode\nd <- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\nğŸ¤” Das Modell geht apriori von ein paar Prozent Menschen mit negativer GrÃ¶ÃŸe aus. Ein Haufen Riesen ğŸ‘¹ werden auch erwartet.\nğŸ¤¯ Vage (flache, informationslose, â€œneutraleâ€, â€œobjektiveâ€) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen."
  },
  {
    "objectID": "gauss.html#aufgaben",
    "href": "gauss.html#aufgaben",
    "title": "8Â  Gauss-Modelle",
    "section": "8.11 Aufgaben",
    "text": "8.11 Aufgaben\n\nstan_glm01\nReThink4e1\nReThink4e2\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung\nPriorwahl1\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "lineare-modelle.html",
    "href": "lineare-modelle.html",
    "title": "9Â  Lineare Modelle",
    "section": "",
    "text": "Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung fÃ¼r einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder StreuungsmaÃŸe und auch SchÃ¤tzintervalle - aus der Post-Verteilung herauslesen\nkÃ¼nftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine Ãœbersicht aller Funktionen des Pakets.1\n\n\n\n\nPrÃ¤diktoren zentrieren"
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-der-regression",
    "href": "lineare-modelle.html#post-verteilung-der-regression",
    "title": "9Â  Lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\nDie (einfache) Regression prÃ¼ft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhÃ¤ngen. Je mehr sie zusammenhÃ¤ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). HÃ¤ngen \\(X\\) und \\(Y\\) zusammen, heiÃŸt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).\nDatenquelle, McElreath (2020).\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und GrÃ¶ÃŸe (Y), AbbildungÂ 9.1.\n\n\nCode\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd <- read_csv(Kung_path)  \n\nd2 <- \n  d %>% \n  filter(age > 18) \n\nd2 %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nAbbildungÂ 9.1: Der Zusammenhang von GrÃ¶ÃŸe und Gewicht im !Kung-Datensatz\n\n\n\n\n\n\n9.2.2 Bei jedem PrÃ¤diktorwert eine Post-Verteilung fÃ¼r \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns fÃ¼r jeden beliebigen Wert des PrÃ¤diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m42, s. AbbildungÂ 9.2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.2: FÃ¼r jeden beliebigen PrÃ¤diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgewÃ¤hlten Gewichtswerten. B: FÃ¼r jeden beliebigen Gewichtswert bekommt man eine Post-Verteilung\n\n\n\n\n\n\n9.2.3 Statistiken zum !Kung-Datensatz\nDatenquelle\nHier sind die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd <- read_csv(Kung_path)  \n\nd2 <- d %>% filter(age > 18)\n\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.6443688\n7.7735641\n12.065000\n136.52500\n179.07000\n0.1434736\n-0.4973852\n346\n0\n\n\nweight\n45.0455429\n6.4552197\n9.135626\n31.52464\n62.99259\n0.1398158\n-0.5317283\n346\n0\n\n\nage\n41.5397399\n15.8093044\n22.000000\n19.00000\n88.00000\n0.6758624\n-0.2014534\n346\n0\n\n\nmale\n0.4739884\n0.5000461\n1.000000\n0.00000\n1.00000\n0.1046415\n-2.0006483\n346\n0\n\n\nweight_c\n0.0000000\n6.4552197\n9.135626\n-13.52090\n17.94705\n0.1398158\n-0.5317283\n346\n0\n\n\n\n\n\n\nDas mittlere KÃ¶rpergewicht (weight) liegt bei ca. 45kg (sd 7 kg).\n\n\n9.2.4 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n9.2.4.1 Gibt es fehlende Werte?\nNein, s. Abb. AbbildungÂ 9.3.\n\n\nCode\nd2 %>% plot_missing()\n\n\n\n\n\nAbbildungÂ 9.3: Fehlende Werte - fehlen.\n\n\n\n\n\n\n9.2.4.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. AbbildungÂ 9.4.\n\n\nCode\nd2 %>% plot_histogram()\n\n\n\n\n\nAbbildungÂ 9.4: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n9.2.4.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. AbbildungÂ 9.5.\n\n\nCode\nd2 %>% plot_bar()\n\n\n\n\n\nAbbildungÂ 9.5: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n9.2.4.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in AbbildungÂ 9.6 dargestellt.\n\n\nCode\nd2 %>% plot_correlation()\n\n\n\n\n\nAbbildungÂ 9.6: Korrelationsmatrix\n\n\n\n\n\n\n9.2.4.5 Bonus\nProbieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(d2).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.5 PrÃ¤diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (PrÃ¤diktor â€œzentrierenâ€). Wenn man den PrÃ¤diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\alpha\\), einfacher zu verstehen. In einem Modell mit zentriertem PrÃ¤diktor (weight) gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit durchschnittlichem Gewicht an. WÃ¼rde man weight nicht zentrieren, gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist.\nVgl. Gelman, Hill, und Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen:\n\n\nCode\nd3 <- \n  d2 %>% \n  center(weight)\n\n\nOder so, von Hand:\n\n\nCode\nd3 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\n\n  \n  \n    \n      height\n      weight\n      age\n      male\n      weight_c\n    \n  \n  \n    152\n48\n63\n1\n3\n    140\n36\n63\n0\nâˆ’9\n    137\n32\n65\n0\nâˆ’13\n  \n  \n  \n\n\n\n\nWie man sieht, ist die Verteilung â€œzur Seite geschobenâ€: Der Mittelwert liegt jetzt eben bei 0.\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem PrÃ¤diktor ist, nicht d2."
  },
  {
    "objectID": "lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "href": "lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "title": "9Â  Lineare Modelle",
    "section": "9.3 Modell m43: zentrierter PrÃ¤diktor",
    "text": "9.3 Modell m43: zentrierter PrÃ¤diktor\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wÃ¤re wohl die KÃ¶rpergrÃ¶ÃŸe? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa wÃ¤re es schÃ¶n, wenn wir die Daten so umformen kÃ¶nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum GlÃ¼ck geht das leicht: Wir zentrieren den PrÃ¤diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m43\nFÃ¼r jede AusprÃ¤gung des PrÃ¤diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung fÃ¼r die abhÃ¤ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) fÃ¼r jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte fÃ¼r die Steigung \\(\\beta\\) und den Achsenabschnitt \\(\\alpha\\) der Regressionsgeraden. AuÃŸerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der GrÃ¶ÃŸe (height) angibt; dieser Wert wird als exonentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\).\n\\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnit (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ğŸ¤·\n\n\n\n\n9.3.2 Likelihood, m43\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m43 ist Ã¤hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines â€œIndex-iâ€ am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern fÃ¼r jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\nâ€œDie Wahrscheinlichkeit, eine bestimmte GrÃ¶ÃŸe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))â€.\n\n\n\n9.3.3 Regressionsformel, m43\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschÃ¤tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\alpha\\) und \\(\\beta\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der PrÃ¤diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\nâ€œDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\alpha\\) und \\(\\beta\\) mal \\(\\text{weight}_i\\)â€.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\alpha\\) gibt an, wie groÃŸ \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n9.3.4 Priori-Werte des Modells m43\n\\[\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\n\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n\\(\\alpha\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine â€œRegression ohne PrÃ¤diktorenâ€ berechnet haben.\n\\(\\sigma\\) ist uns schon als Parameter bekannt und behÃ¤lt seine Bedeutung aus dem letzten Kapitel.\nDa height nicht zentriert ist, der Mittelwert von \\(\\alpha\\) bei 178 und nicht 0.\n\\(\\beta\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und GrÃ¶ÃŸe positiv (gleichsinnig) ist."
  },
  {
    "objectID": "lineare-modelle.html#vertiefung-prior-prÃ¤diktiv-verteilung",
    "href": "lineare-modelle.html#vertiefung-prior-prÃ¤diktiv-verteilung",
    "title": "9Â  Lineare Modelle",
    "section": "9.4 Vertiefung: Prior-PrÃ¤diktiv-Verteilung",
    "text": "9.4 Vertiefung: Prior-PrÃ¤diktiv-Verteilung\nğŸï¸ VERTIEFUNG, nicht prÃ¼fungsrelevant ğŸï¸\n\n9.4.1 Moment\nğŸ¤” Moment. Dieser Prior, \\(\\beta\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und GrÃ¶ÃŸe positiv oder negativ ist? Nein, sind wir nicht.\n\n\n9.4.2 Priori-PrÃ¤diktiv-Verteilung fÃ¼r m43\nWas denkt wir bzw. unser Golem apriori Ã¼ber den Zusammenhang von GrÃ¶ÃŸe und Gewicht? Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also fÃ¼r \\(\\alpha\\), \\(\\beta\\) und \\(\\sigma\\).\n\n\nCode\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter fÃ¼r Prior-Pred-Verteilung\n             data = d2)\n\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      sigma\n    \n  \n  \n    177.9\n4.3\n2.8\n    158.4\nâˆ’6.0\n2.3\n    173.9\n6.4\n22.1\n    155.8\nâˆ’8.6\n3.7\n    189.0\nâˆ’12.6\n3.8\n  \n  \n  \n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n9.4.3 Prior-PrÃ¤diktiv-Simulation fÃ¼r m43 mit stan_glm()\n\n\nCode\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d2)\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n9.4.4 Visualisieren der Prior-PrÃ¤diktiv-Verteilung\n\n\nCode\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\nğŸ¤¯ Einige dieser Regressionsgeraden sind unsinnig!\n\n\nCode\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.5 Ein positiver Wert fÃ¼r \\(\\beta\\) ist plausibler\n\n9.4.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\nğŸ‘ \\(\\beta=-20\\) wÃ¤re mit diesem Prior gut mÃ¶glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n9.4.5.2 Oh yes\nWir brÃ¤uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):\n\n\n\n\n\nğŸ‘ Vermutlich besser: Ein GroÃŸteil der Wahrscheinlichkeitsmasse ist \\(X>0\\). Allerdings gibtâ€™s keine GewÃ¤hr, dass unser Prior â€œrichtigâ€ ist.\n\n\n\n9.4.6 Priori-PrÃ¤diktiv-Simulation, 2. Versuch\n\n\nCode\nm43a_prior_pred <-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter fÃ¼r Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d2)\n\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  # Spaltennamen kÃ¼rzen: \n  rename(a = `(Intercept)`) %>%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      s\n    \n  \n  \n    222.6\n0.8\n7.0\n    187.7\n3.8\n5.2\n    194.1\n2.7\n20.5\n    172.9\n1.1\n5.6\n    180.6\n1.0\n3.4\n  \n  \n  \n\n\n\n\nDas Argument prior_PD = TRUE sorgt dafÃ¼r, dass keine Posteriori-Verteilung, sondern eine Prior-PrÃ¤diktiv-Verteilung berechnet wird.\n\n\n9.4.7 Visualisieren der Prior-PrÃ¤diktiv-Verteilung, m43a\nUnsere Priori-Werte scheinen einigermaÃŸen vernÃ¼nftige Vorhersagen zu tÃ¤tigen. Allerdings erwartet unser Golem einige Riesen.\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p.Â 96.\n\n\n9.4.9 Hier ist unser Modell, m43a\n\\[\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\\]\n\n\nCode\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n\n\n\n\n9.4.10 Eine Zusammenfassung der Posteriori-Verteilung fÃ¼r m43a\n\n\nCode\nm43a %>% \n  parameters()\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.09, 155.21)\n100%\n0.999\n4132.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.83, 0.99)\n100%\n1.000\n3837.00\nNormal (5 +- 3)\n\n\n\n\n\nUnser Modell m43a schÃ¤tzt die typische KÃ¶rpergrÃ¶ÃŸe einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugehÃ¶rige 95%-CI keine 20 Zentimenter umfasst."
  },
  {
    "objectID": "lineare-modelle.html#die-post-verteilung-befragen",
    "href": "lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9Â  Lineare Modelle",
    "section": "9.5 Die Post-Verteilung befragen",
    "text": "9.5 Die Post-Verteilung befragen\n\n9.5.1 m43a\nSagen wir, auf Basis gut geprÃ¼fter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. GleichungÂ 9.1.\nPrioris:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{9.1}\\]\nWir nennen das Modell m43a2, s. ListingÂ 9.1.\n\nListingÂ 9.1: Modelldefinition von m43a in R\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest fÃ¼r Reproduzierbarkeit\n    data = d3)\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die NachprÃ¼fbarkeit der Ergebnisse (â€œReproduzierbarkeitâ€) sichergestellt3. Welche Wert fÃ¼r seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung schÃ¤tzen.\n\n\n\n\n9.5.2 Mittelwerte von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n  \n  \n    \n      id\n      (Intercept)\n      weight_c\n      sigma\n    \n  \n  \n    1\n155.1\n0.9\n5.0\n    2\n155.5\n0.8\n5.1\n    3\n155.5\n0.9\n5.1\n  \n  \n  \n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters:\n\n\nCode\nparameters(m43a)\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nDie Kennzahl pd (propability of direction) gibt die Wahrscheinlichkeit an, dass der Effekt positiv (also grÃ¶ÃŸer als Null) oder negativ ist (jenachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) Ã„hnliches wie der p-Wert in der Frequentistischen Statistik (Makowski u.Â a. 2019).\nAm besten das Diagramm dazu anschauen, s AbbildungÂ 9.7.\n\n\nCode\nplot(p_direction(m43a))\n\n\n\n\n\nAbbildungÂ 9.7: Diagramm zur Probability of Direction, Modell m43a\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) grÃ¶ÃŸer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschÃ¤ftigen in diesem Kurs.\n\n\n9.5.3 Visualisieren der â€œmittlerenâ€ Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). Ãœberzeugen wir uns mit einem Blick in die Post-Verteilung von m43a:\n\n\nCode\nm43a %>% \n  as_tibble() %>% \n  head()\n\n\n\n\n\n\n(Intercept)\nweight_c\nsigma\n\n\n\n\n155.1421\n0.8581434\n5.042898\n\n\n155.4658\n0.8348727\n5.071101\n\n\n155.4522\n0.8549260\n5.144382\n\n\n155.2342\n0.8816371\n5.352756\n\n\n155.3172\n0.8745051\n5.349856\n\n\n154.9315\n0.9030495\n5.207581\n\n\n\n\n\n\nWir kÃ¶nnen z.B. ein LagemaÃŸ wie den Median hernehmen, um die â€œmittlereâ€ Regressionsgerade zu betrachten:\n\n\nCode\nd2 %>% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. AbbildungÂ 9.8. Mit â€œexpectationâ€ sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\nCode\nm43_expect <- estimate_expectation(m43a)\nplot(m43_expect)\n\n\n\n\n\nAbbildungÂ 9.8: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n\n\n\n\n\n\n9.5.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\alpha, \\beta, \\sigma\\).\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen kÃ¶nnen.\n\n9.5.4.1 LagemaÃŸe zu den Parametern\n\nWas ist die mittlere GrÃ¶ÃŸe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der SchÃ¤tzwert fÃ¼r den Zusammenhang von Gewicht und GrÃ¶ÃŸe? (\\(\\beta_1\\))\nWas ist der SchÃ¤tzwert fÃ¼r Ungewissheit in der SchÃ¤tzung der GrÃ¶ÃŸe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert fÃ¼r z.B: \\(\\beta_1\\)?\n\nEine nÃ¼tzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell):\n\n\nCode\nm43a %>% \n  parameters()\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m43a, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm43a_post <- \n  m43a %>% \n  as_tibble()\n\nm43a_post %>% \n  head()\n\n\n\n\n\n\n(Intercept)\nweight_c\nsigma\n\n\n\n\n155.1421\n0.8581434\n5.042898\n\n\n155.4658\n0.8348727\n5.071101\n\n\n155.4522\n0.8549260\n5.144382\n\n\n155.2342\n0.8816371\n5.352756\n\n\n155.3172\n0.8745051\n5.349856\n\n\n154.9315\n0.9030495\n5.207581\n\n\n\n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post.\nJetzt haben wir wieder eine schÃ¶ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen kÃ¶nnen.\nEine Visualisierung zeigt gut sowohl Lage- als auch StreuungsmaÃŸe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot.\n\n\nCode\nm43a_post %>% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den hÃ¤ufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\nDer Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm43a_post %>% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. AbbildungÂ 9.9.\n\n\nCode\nm43a_post %>% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\nAbbildungÂ 9.9: Die Post-Verteilung fÃ¼r den Parameter sigma, m43a\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s.@fig-m43a-plot.\n\n\nCode\nm43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\n\nAbbildungÂ 9.10: Die Parameter Gewicht (zentriert) und sigma des Modells m43a\n\n\n\n\nErgÃ¤nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n\n\n9.5.5 StreuungsmaÃŸe zu den Parametern\n\nWie unsicher sind wir uns in den SchÃ¤tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebrÃ¤uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen StabilitÃ¤t.\n\n\n\n\n9.5.6 Ungewissheit von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung visualisiert\nDie ersten 10 Stichproben:\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\n\nDie ersten 100 Stichproben:\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\nDie ersten 1000000 â€¦ okay, lassen wir es gut sein4.\nEinfacher ist die Visualisierung mit estimate_expectation:\n\n\nCode\nestimate_expectation(m43a) %>% plot()\n\n\n\n\n\n\n\n9.5.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten PrÃ¤diktor misst der Achsenabschnitt die mittlere GrÃ¶ÃŸe.\n\n\n\nWelche mittlere GrÃ¶ÃŸe wird mit zu 50%, 90% bzw. 95% Wahrscheinlichkeit nicht Ã¼berschritten?\nWelche mittlere GrÃ¶ÃŸe mit zu 95% Wskt. nicht unterschritten?\nVon wo bis wo reicht der innere 50%-SchÃ¤tzbereich der mittleren GrÃ¶ÃŸe?\n\nQuantile:\n\n\nCode\nm43a_post %>% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n\n\n\nq_50\nq_90\nq_05\n\n\n\n\n154.6548\n155.0032\n155.0951\n\n\n\n\n\n\n50%-PI:\n\n\nCode\nm43a %>% \n  eti(ci = .5)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.5\n154.4632928\n154.8373635\nfixed\nconditional\n\n\nweight_c\n0.5\n0.8772824\n0.9354291\nfixed\nconditional\n\n\n\n\n\n\n\n\n9.5.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe bei mind. 155 cm liegt?\n\n\nCode\nm43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\ngross\nn\nprop\n\n\n\n\nFALSE\n3593\n0.89825\n\n\nTRUE\n407\n0.10175\n\n\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe hÃ¶chstens 154.5 cm betrÃ¤gt?\n\n\nCode\nm43a_post %>% \n  count(klein = (`(Intercept)` <= 154.5)) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\nklein\nn\nprop\n\n\n\n\nFALSE\n2833\n0.70825\n\n\nTRUE\n1167\n0.29175\n\n\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nâ€š \n\n\n9.5.9 Typischer Bayes-Nutzer in Aktion\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle"
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "href": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "title": "9Â  Lineare Modelle",
    "section": "9.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert",
    "text": "9.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert\n\n9.6.1 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der KÃ¶rpergrÃ¶ÃŸe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche KÃ¶rpergrÃ¶ÃŸe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns Ã¼ber diesen Mittelwert?\nEtwas formaler ausgedrÃ¼ckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten PrÃ¤diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 <-\n  m43a_post %>% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. AbbildungÂ 9.11.\n\n\nCode\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\nAbbildungÂ 9.11: Post-Verteilung der GrÃ¶ÃŸe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\nAnalog kÃ¶nnen wir fragen, wie groÃŸ wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns Ã¼ber diesen Mittelwert sind.\n50 kg, das sind 5 Ã¼ber dem Mittelwert, in zentrierten Einheiten ausgedrÃ¼ckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle.\n\n\nCode\nmu_at_50 <-\n  mu_at_45 %>% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\n\n\n(Intercept)\nweight_c\nsigma\nmu_at_45\nmu_at_50\n\n\n\n\n155.1421\n0.8581434\n5.042898\n155.1421\n159.4329\n\n\n155.4658\n0.8348727\n5.071101\n155.4658\n159.6402\n\n\n155.4522\n0.8549260\n5.144382\n155.4522\n159.7269\n\n\n155.2342\n0.8816371\n5.352756\n155.2342\n159.6424\n\n\n155.3172\n0.8745051\n5.349856\n155.3172\n159.6897\n\n\n154.9315\n0.9030495\n5.207581\n154.9315\n159.4467\n\n\n\n\n\n\nDie Verteilung der mittleren GrÃ¶ÃŸe bei einem Gewicht von 50kg ist weiter â€œrechtsâ€ (Richtung hÃ¶here GrÃ¶ÃŸe) zentriert, s. AbbildungÂ 9.12.\n\n\nCode\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\nAbbildungÂ 9.12: Post-Verteilung der mittleren GrÃ¶ÃŸe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n9.6.2 LagemaÃŸe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der KÃ¶rpergrÃ¶ÃŸe.\nWas ist das 90% PI fÃ¼r \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %>% \n  eti(mu_at_50, ci = .9)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\n(Intercept)\n0.9\n154.2144131\n155.0950875\n\n\nweight_c\n0.9\n0.8358413\n0.9763181\n\n\nsigma\n0.9\n4.8298399\n5.4758137\n\n\nmu_at_45\n0.9\n154.2144131\n155.0950875\n\n\nmu_at_50\n0.9\n158.6294638\n159.7578370\n\n\n\n\n\n\nDie mittlere GrÃ¶ÃŸe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere GrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %>% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n\n\n\n\n\n\nq_95\n\n\n\n\n155.0951"
  },
  {
    "objectID": "lineare-modelle.html#die-ppv-befragen",
    "href": "lineare-modelle.html#die-ppv-befragen",
    "title": "9Â  Lineare Modelle",
    "section": "9.7 Die PPV befragen",
    "text": "9.7 Die PPV befragen\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) gibt uns die MÃ¶glichkeit, nach der Wahrscheinlichkeit tatsÃ¤chlicher KÃ¶rpergrÃ¶ÃŸen zu fragen - und nicht nur nach mittleren KÃ¶rpergrÃ¶ÃŸen anhand der Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren KÃ¶rpergrÃ¶ÃŸe, denn das ist was wir modellieren wollten. MÃ¶chten wir Aussagen zur Wahrscheinlichkeit tatsÃ¤chlicher GrÃ¶ÃŸen treffen, brauchen wir die PPV.\n\n\n\n9.7.1 Perzentil-Intervalle fÃ¼r verschiedenen PrÃ¤diktor-Werte\nWir erstellen uns eine Sequenz an PrÃ¤diktorwerten, die uns interessieren, weight_df:\n\n\nCode\nweight_df <- tibble(weight_c = seq(-20,20, by = 5))\n\n\nFÃ¼r diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\n\nCode\nmus <- \n  predictive_interval(\n    m43a, \n    seed = 42,\n    newdata = weight_df) %>% \n  as_tibble() %>% \n  bind_cols(weight_df)\n\nhead(mus)\n\n\n\n\n\n\n5%\n95%\nweight_c\n\n\n\n\n128.1147\n145.1597\n-20\n\n\n132.4176\n149.6384\n-15\n\n\n136.9562\n154.3366\n-10\n\n\n141.3568\n158.6287\n-5\n\n\n146.0105\n163.4098\n0\n\n\n150.4892\n167.5851\n5\n\n\n\n\n\n\nUm die Perzentilintervalle zu erstellen, wird von predictive_interval() fÃ¼r jeden PrÃ¤diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil dafÃ¼r berechnet. Sie kÃ¶nnen die Voreinstellung Ã¤ndern mittels des Arguments prob; um ein 89%-PI zu berechnen, wÃ¼rde man z.B. schreiben prob = .89.\nUm Reproduzierbarkeit sicherzustellen, haben wir mit seed = 42 die Zufallszahlen fixiert.\nWir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine KÃ¶rpergrÃ¶ÃŸe von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI). Hoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedrÃ¼ckt; die PPV gibt die Ungewissheit tatsÃ¤chlicher beobachtbarer KÃ¶rpergrÃ¶ÃŸen aus, nicht nur die Ungewissheit zum Mittelwert.\nBerechnen wir die PPV fÃ¼r m43a:\n\n\nCode\nppv_m43a <- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %>% \n  as_tibble() %>% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\n\nHier ist ein Auszug aus der PPV-Tabelle:\n\n\n\n\n\n\n  \n  \n    \n      weight_c\n      5%\n      95%\n    \n  \n  \n    âˆ’20.0\n128.1\n145.2\n    âˆ’15.0\n132.4\n149.6\n    âˆ’10.0\n137.0\n154.3\n    âˆ’5.0\n141.4\n158.6\n    0.0\n146.0\n163.4\n    5.0\n150.5\n167.6\n  \n  \n  \n\n\n\n\n\n\n9.7.2 Perzentilintervalle fÃ¼r verschiedenen PrÃ¤diktorwerte visualisiert\n?fig-m43a-nochmal visualisiert die Ungewissheit von Vorhersagen laut der PPV. Die Ungewissheit in ?fig-m43a-nochmal ist die Antwort auf die Frage: â€œWie sicher sind wir uns, zur GrÃ¶ÃŸe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?â€ Eine Vorhersage bezeichnet man auch als â€œbedingte Verteilungâ€, da man den Wert einer Verteilung voraussagt, gegeben einer Bedingung, z.B. weight_c = 10.\n\n\n\n\n\nVisualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV grÃ¶ÃŸer als die der Post-Verteilung.\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung, s. AbbildungÂ 9.13; je dicker die â€œKatzenaugenâ€, desto mehr Stichproben (samples) liegen vor an der Stelle, und umso genauer ist die SchÃ¤tzung.\n\n\n\n\n\nAbbildungÂ 9.13: Die PPV fÃ¼r bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu | w_i\\).\n\n\n9.7.3 Die PPV visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV fÃ¼r einen bestimmten PrÃ¤diktorwert, z.B. bei einer Person mittleren Gewichts. Wir kÃ¶nnen auch den Mittelwert Ã¼ber alle bedingten PPV anschauen, sozusagen die â€œMaster-PPVâ€ oder â€œunbedingte PPVâ€ oder schlicht PPV. Vergleichen wir die echten Werte fÃ¼r height, \\(y\\), mit den von der PPV simulierten Werten fÃ¼r height, \\(y_{rep}\\), s. AbbildungÂ 9.14.\n\n\nCode\ncheck_predictions(m43a) \n\n\n\n\n\nAbbildungÂ 9.14: Vergleich der Vorhersagen fÃ¼r y (leichte, blaue Linien) mit der beobachteten Verteilung von y\n\n\n\n\n?check_predictions zeigt Hilfe fÃ¼r diese Funktion. Die Funktion zeigt die Vorhersagen fÃ¼r die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n9.7.4 Fragen an die PPV\n\nWie groÃŸ sind die !Kung im Schnitt?\nWelche GrÃ¶ÃŸe wird von 90% der Personen nicht Ã¼berschritten?\nWie groÃŸ sind die 10% kleinsten?\n\n\n\nCode\nppv_m43a %>% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n\n\n\n\n\nq_10\nheight_mean\nq_50\nq_90\n\n\n\n\n137.0299\n154.6521\n154.6775\n171.8119\n\n\n\n\n\n\nWas ist der 50% Bereich der KÃ¶rpergrÃ¶ÃŸe?\n\n\nCode\nppv_m43a %>% \n  eti(ci = .5)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\nheight\n0.5\n144.8201\n165.2368"
  },
  {
    "objectID": "lineare-modelle.html#aufgaben",
    "href": "lineare-modelle.html#aufgaben",
    "title": "9Â  Lineare Modelle",
    "section": "9.8 Aufgaben",
    "text": "9.8 Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nLikelihood2\nPost-befragen1\nPostvert-Regr-01\nregression1a\nRegression2\nBed-Post-Wskt1\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\npenguins-stan-01\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel LÃ¼decke. 2019. â€Indices of Effect Existence and Significance in the Bayesian Frameworkâ€œ. Frontiers in Psychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "metrische-AV.html",
    "href": "metrische-AV.html",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "",
    "text": "BenÃ¶tigte R-Pakete fÃ¼r dieses Thema:\n\n\nCode\nsuppressPackageStartupMessages(\"rstanarm\")\n## [1] \"rstanarm\"\n#| message: false\n#| results: \"hide\"\n#| warnings: false\nlibrary(rstanarm)\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme Ã¼bersetzen\ntypische Forschungsfragen auswerten\n\n\n\n\n\nTeil 1\nTeil 2"
  },
  {
    "objectID": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "href": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.2 Wissenschaft als Gerechtigkeitsprojekt",
    "text": "10.2 Wissenschaft als Gerechtigkeitsprojekt\n\n10.2.1 Meinungen als Grundlage der KonfliktlÃ¶sung ?\nContra:\n\nâ€œIch find Masken doof!â€\nâ€œImpfen ist schÃ¤dlich!â€\nâ€œCorona gibtâ€™s gar nicht!â€\n\n\n\n  \n\n\nPro:\n\nâ€œIch find Masken gut!â€\nâ€œImpfen ist nÃ¼tzlich!â€\nâ€œCorona ist gefÃ¤hrlich!â€\n\n\n\n  \n\n\nMeinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte kÃ¶nnen auf Basis von Meinungen nur schwer gelÃ¶st werden.\n\n\n10.2.2 Fakten als Grundlage der KonfliktlÃ¶sung\nWissenschaft produziert Fakten. Da Fakten universell sind (sein kÃ¶nnen), ist Wissenschaft potenziell ein Weg zur KonfliktlÃ¶sung. Warum helfen Fakten bei Konflikten?\nFakten sind neutral gegenÃ¼ber Personen. Fakten bieten daher eine Chance zur fairen Einigung.\nWann ist ein Fakt ein Fakt?\nFakten mÃ¼ssen vor allem nachprÃ¼fbar sein (Daten, Analyse und Bericht mÃ¼ssen offen zugÃ¤nglich sein).\n\n\n10.2.3 Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung\n\nThe effectiveness of full messenger RNA (mRNA) vaccination (â‰¥14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.\n\nThompson u.Â a. (2021); vgl. auch Nasreen u.Â a. (2021); Pormohammad u.Â a. (2021)\nDrei Anforderungen an die QualitÃ¤t von Studien:\n\nhandwerklich gut: z.B. vergleichbare Gruppen, genaue Messinstrumente\nbescheiden: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche QualitÃ¤t der Studie zulÃ¤sst. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage berÃ¼cksichtigt.\ntransparent: Das Vorgehen, die HintergrÃ¼nde und Ziele werden offengelegt. Das betrifft auch mÃ¶glich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen\n\n\n\n10.2.4 Psychologische Intervention zur ErhÃ¶hung der Impfquote\nDai u.Â a. (2021) zeigen den Effekt einer psychologischen Intervention zur ErhÃ¶hung der Impfquote, s. AbbildungÂ 10.1.\n\nHere we present two sequential randomized controlled trials to test the effect of behavioural interventions on the uptake of COVID-19 vaccines. â€¦ We designed text-based reminders that make vaccination salient and easy, and delivered them to participants drawn from a healthcare system one day (first randomized controlled trial) (n = 93,354 participants; clinicaltrials number NCT04800965) and eight days (second randomized controlled trial) (n = 67,092 individuals; clinicaltrials number NCT04801524) after they received a notification of vaccine eligibility. The first reminder boosted appointment and vaccination rates within the healthcare system by 6.07 (84%) and 3.57 (26%) percentage points, respectively; the second reminder increased those outcomes by 1.65 and 1.06 percentage points, respectively. The first reminder had a greater effect when it was designed to make participants feel ownership of the vaccine dose.\n\n\n\n\n\n\nAbbildungÂ 10.1: a, b, Proportion of participants in each condition who scheduled an appointment for the first dose of the COVID-19 vaccine at UCLA Health between 15:00 h on the first reminder date and 23:59 h on the fifth day following the first reminder date (a) and the proportion of participants in each condition who obtained the first dose of the COVID-19 vaccine at UCLA Health within four weeks of the first reminder date (b). Error bars represent Â± 1 s.e.m. The number of participants in each condition (from left to right in each panel) is 18,629, 18,592, 18,757, 18,627 and 18,749.\n\n\n\n\nQuelle/Volltext\n\n\n10.2.5 Was heiÃŸt â€œist effektivâ€?\nNasreen u.Â a. (2021) definieren effectivity, \\(e\\), so:\n\\[e = 1 - C; C= \\frac{n_{vacc|pos}}{n_{vacc|neg}}\\]\n\n\\(C\\) nennt man das ChancenverhÃ¤ltnis (odds ratio), es beschreibt einen Bruchterm: \\(\\frac{x}{y}\\).\n\\(n_{vacc|pos}\\): Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose\n\\(n_{vacc|neg}\\): Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose\n\nBeispiel: Von den 100 Personen mit positiver Corona-Diagnose sind 10 geimpft, \\(n_{vacc|pos}=10\\). Von den 100 Personen mit negativer Corona-Diagnose sind 90 geimpft, \\(n_{vacc|neg}=90\\)\n\\[C= \\frac{10}{90} = \\frac{1}{9}; e = 1 - \\frac{1}{9} = \\frac{8}{9} \\approx 0.88\\]\nIn diesem Beispiel liegt die EffektvititÃ¤t \\(e\\) bei knapp 90%."
  },
  {
    "objectID": "metrische-AV.html#arten-von-forschungsfragen",
    "href": "metrische-AV.html#arten-von-forschungsfragen",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.3 Arten von Forschungsfragen",
    "text": "10.3 Arten von Forschungsfragen\n\n10.3.1 Nach dem Erkenntnisziel\nDeskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\nPrÃ¤diktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der GrÃ¶ÃŸe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts fÃ¼r die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhÃ¤lt?\n\nPrÃ¤skriptiv (erklÃ¤rend, kausal)\n\nIst GrÃ¶ÃŸe eine Ursache von Gewicht (bei deutschen MÃ¤nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklÃ¤rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehÃ¶rt.\n\n\n\n\n10.3.2 Nach dem Skalenniveau\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus.\nFÃ¼r die UV(s) sind nominale und metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt."
  },
  {
    "objectID": "metrische-AV.html#eine-binÃ¤re-uv",
    "href": "metrische-AV.html#eine-binÃ¤re-uv",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.4 Eine binÃ¤re UV",
    "text": "10.4 Eine binÃ¤re UV\n\n10.4.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im Ã¶ffentlichen Dienst arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwÃ¤ndigen Studie die Intelligenz vieler Kinder gemessen. ZusÃ¤tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, â€œRisikofaktorenâ€ fÃ¼r geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in AbhÃ¤ngigkeit davon, ob ihre jeweilige Mutter Ã¼ber einen Schlusabschluss (mom_hs) verfÃ¼gt? (ceteris paribus)\n\n\n\n10.4.2 IQ von Kindern, binÃ¤rer PrÃ¤diktor\n\n\nCode\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 <- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nAlternativ kÃ¶nnen Sie die Daten hier herunterladen.\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. TabelleÂ 10.1.\n\n\n\n\nTabelleÂ 10.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt)\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nIn AbbildungÂ 10.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\n\nCode\nggplot(kidiq) +\n  aes(x = mom_hs, y = kid_score) +\n  geom_jitter(width = 0.1, alpha = .5) +\n  geom_abline(slope = coef(m10.1)[2],\n              intercept = coef(m10.1)[1])  +\n  scale_x_continuous(breaks = c(0, 1))\n\n\n\n\n\nAbbildungÂ 10.2: Kinder, deren MÃ¼tter Ã¼ber einen Schulabschluss verfÃ¼gen, haben im Mittel einen hÃ¶heren Intelligenztestwert, laut dem vorliegenden Modell\n\n\n\n\n\n\n10.4.3 Interpretation von m10.1\nm10.1: kid_score = 78 + 12*mom_hs + error\n\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss (mom_hs = 0) verfÃ¼gen:\n\nkid_score = 78 + 0*12 + error\n\nDas Regressionsgewicht (slope, \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit MÃ¼tter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit MÃ¼tter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\nkid_score = 78 + 1*12 + error = 90 + error\n\nDie GrÃ¶ÃŸer der Konfidenzintervalle zeigt, wie genau die SchÃ¤tzung (Vorhersage) ist bzw. wie stark PrÃ¤diktor (UV) und Kriterium (AV) zusammenhÃ¤ngen.\n\n\n\n10.4.4 m10.1 als Mittelwertsdifferenz\n\nUV: binÃ¤r (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\nHey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heiÃŸen kid_score_avg. An die Arbeit!\n\n\nCode\nkidiq %>% \n  group_by(mom_hs) %>% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n\n0\n77.54839\n\n\n1\n89.31965\n\n\n\n\n\n\nIn der klassischen Statistik untersucht man diese Datensituation mit einem t-Test. Der t-Test ist ein inferenzstatistisches Verfahren, dass prÃ¼ft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\). In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von MÃ¼ttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.\n\n\n10.4.5 Antwort auf die Forschungsfrage, m10.1\nBetrachten wir die Ergebnisse von m10.1. Hier sind die ersten paar Zeilen.\n\n\nCode\nm10.1_post <-\n  m10.1 %>% \n  as_tibble() \n\nnames(m10.1_post) <- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schÃ¶nere Namen\n\n\n\n\n\n\n\n\n  \n    \n      Stichprobe aus der Post-Verteilung\n    \n    \n  \n  \n    \n      Achsenabschnitt\n      momhs\n      sigma\n    \n  \n  \n    80.7\n9.4\n20.3\n    78.2\n12.2\n19.0\n    73.8\n16.0\n19.7\n    75.2\n13.6\n18.4\n    79.6\n11.1\n20.4\n  \n  \n  \n\n\n\n\nBerechnen wir ein 95%-PI von Hand:1\n\n\nCode\npi_mom_hs <-\n  m10.1_post %>% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n\n\n\n\npi_95\n\n\n\n\n7.177759\n\n\n16.482883\n\n\n\n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlieÃŸend die Posteriori-Verteilung, s. AbbildungÂ 10.3.\n\n\nCode\nplot(eti(m10.1))\n\n\n\n\n\nAbbildungÂ 10.3: Das 95% ETI zum (statistischen) Effekt des mÃ¼tterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem â€œEffektâ€ zu sprechen, lÃ¤sst in den meisten KÃ¶pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang."
  },
  {
    "objectID": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.5 Eine metrische plus eine nominale UV",
    "text": "10.5 Eine metrische plus eine nominale UV\n\n10.5.1 Forschungsfrage\n\nWie stark ist der Zusammenhang von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle TabelleÂ 10.2 dargestellt.\n\n\nCode\ndata(\"kidiq\")  # Paket rstanarm, alternativ Ã¼ber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\n\nTabelleÂ 10.2: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\nDatenquelle\n\n\n10.5.2 1 metrischer PrÃ¤diktor\nBerechnen wir folgendens Modell: kid_score ~ mom_iq (m10.2), s. Tab. TabelleÂ 10.3.\n\n\nCode\nm10.2 <-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %>% \n  parameters()\n\n\n\n\n\n\nTabelleÂ 10.3: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\nVisualisieren wir uns noch das Modell m10.2, s. AbbildungÂ 10.4.\n\n\nCode\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\nAbbildungÂ 10.4: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, s. AbbildungÂ 10.5\n\n\nCode\nplot(estimate_expectation(m10.2))\n\n\n\n\n\nAbbildungÂ 10.5: Die geschÃ¤tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder fÃ¼r verschiedene IQ-Werte der MÃ¼tter. Vergleicht man Teilpopulationen von MÃ¼ttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n\n10.5.3 Beide PrÃ¤diktoren, m10.3\nBerechnen wir als nÃ¤chstes ein Modell mit beiden PrÃ¤diktoren: kid_score ~ mom_hs + mom_iq, s. TabelleÂ 10.4.\n\n\nCode\nm10.3 <- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\n\nTabelleÂ 10.4: Parameter des Modells m10.3 (ohne sigma)\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. PunktschÃ¤tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\n\nCode\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\n\nm10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error\nMÃ¶chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\n\nCode\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\n\nAber natÃ¼rlich ist es mÃ¶glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. AbbildungÂ 10.6.2\n\n\nCode\nkidiq %>% \n  mutate(mom_hs = factor(mom_hs)) %>%  \n  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.3)[3],  # den 3. Wert aus dem Vector, den `coef()` zurÃ¼ckgibt\n              intercept = 26,\n              linewidth = 1,\n              color = \"blue\") +\n  geom_abline(slope = coef(m10.3)[3],\n              intercept = 32,\n              color = \"red\",\n              linewidth = 2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme(legend.position = \"bottom\") +\n  scale_x_continuous(limits = c(0, 140))\n\n\n\n\n\nAbbildungÂ 10.6: Der Effekt von sowohl mÃ¼tterlicher Intelligenz als auch mÃ¼tterlichem Schulabschluss. Es ist gut zu erkennen, dass der Achsenabschnitt fÃ¼r die Daten nicht interpretierbar ist.\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schÃ¤tzt das Modell den IQ-Wert des Kindes auf 26.\nKoeffizient zum mÃ¼tterlichen Schulabschluss: Vergleicht man Kinder von MÃ¼ttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\nKoeffizient zur mÃ¼tterlichen IQ: Vergleicht man Kinder von MÃ¼ttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus."
  },
  {
    "objectID": "metrische-AV.html#interaktion",
    "href": "metrische-AV.html#interaktion",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.6 Interaktion",
    "text": "10.6 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.\n\n\nWir berechnen mit m10.4 folgendes Modell: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. AbbildungÂ 10.7 und TabelleÂ 10.5\n\n\nCode\nm10.4 <- \n  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\n\nTabelleÂ 10.5: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-10.59\n(-37.44, 16.30)\n77.62%\n1.001\n1427.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n49.76\n(21.49, 79.27)\n100%\n1.003\n1401.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.001\n1412.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq\n-0.47\n(-0.78, -0.17)\n99.85%\n1.003\n1367.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.7: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt fÃ¼r diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n10.6.1 Interpretation von m10.4\n\nAchsenabschnitt: IQ-SchÃ¤tzwerte fÃ¼r Kinder mit MÃ¼tter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\nmom_hs: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\nmom_iq: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit MÃ¼ttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\nInteraktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten fÃ¼r mom_iq zwischen MÃ¼tter mit bzw. ohne Schulabschluss.\n\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\nGelman, Hill, und Vehtari (2021), Kap. 10.3\n\n\n10.6.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "href": "metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.7 Zentrieren von PrÃ¤diktoren",
    "text": "10.7 Zentrieren von PrÃ¤diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert. Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq.\nMan kÃ¶nnte auch mom_hs zentrieren, aber fÃ¼r eine einfache Interpretation ist es meist nÃ¼tzlich, nur metrische PrÃ¤diktoren zu zentrieren.\n\n\nCode\nkidiq <-\n  kidiq %>% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n\n\n\n## NULL\n\n\n10.7.1 Interpretation von m10.5\n\nDer Achsenabschnitt (Intercept) gibt den geschÃ¤tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\nmom_hs gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\nmom_iq_c gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten fÃ¼r mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nm10.5 ist in AbbildungÂ 10.8 dargestellt.\n\n\n\n\n\nAbbildungÂ 10.8: m10.5: Interaktionsmodell mit zentriertem PrÃ¤diktor fÃ¼r mÃ¼tterlicher Intelligenz\n\n\n\n\n\n\n10.7.2 Zentrieren Ã¤ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4:\n\n\nCode\nnew <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new <- posterior_predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.07282\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5:\n\n\nCode\nnew <- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new <- posterior_predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.30389\n\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren Ã¤ndert auch nicht die Regressionskoeffizienten, da die Streuungen der PrÃ¤diktoren nicht verÃ¤ndert wurden.\n\n\n10.7.3 Perzentilintervalle aus der Posterori-Verteilung\n?tbl-m105 zeigt die PunktschÃ¤tzer der Parameter fÃ¼r m10.5 sowie ihre Perzentilintervalle3. Nutzen Sie dafÃ¼r parameters(m10.5).\n\n\nTabelleÂ 10.6: ?(caption)\n\n\n\n\n(a) Fixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n85.31\n(80.99, 89.72)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.69)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.67, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\nParameter von m10.5 und ETIs\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. ?tbl-m105-hdi\n\n\nCode\nparameters(m10.5, ci_method = \"hdi\") %>% \n  display()\n\n\n\nParameter von m10.5 und HDIs \n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n85.31\n(81.26, 89.88)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.70)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.79, -0.17)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n\n10.7.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei MÃ¼ttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mÃ¼tterlichen Intelligenz; pro Punkt Unterschied in mÃ¼ttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). AuÃŸerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei MÃ¼tter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n  \n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. ZusammenhÃ¤nge beschrieben. FÃ¼r kausale Aussagen ist mehr nÃ¶tig, als einen Zusammenhang festzustellen."
  },
  {
    "objectID": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.8 Eine nominale UV mit mehreren Stufen",
    "text": "10.8 Eine nominale UV mit mehreren Stufen\n\n10.8.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in; Ihre Kompetenz als Wirtschaftspsychologi war heiÃŸ begehrt. Von Statistik wollte niemand etwas wissenâ€¦ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt fÃ¼hrte Sie in die Antarktisâ€¦ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um GrÃ¶ÃŸenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren KÃ¶rpergewichte der drei Pinguinarten?\n\n\n\n10.8.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ğŸ¤” Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere KÃ¶rpergewichte in AbhÃ¤ngigkeit von der Pinguinart?\n\nAlternativ kÃ¶nnen wir die Hypothese prÃ¼fen, ob die Mittelwerte â€œpraktischâ€ gleich sind, also sich â€œkaumâ€ unterscheiden. Der Grenzwert fÃ¼r â€œpraktisch gleichâ€ bzw. â€œkaum unterschiedlichâ€ ist subjektiv. Dazu in KapitelÂ 10.11 mehr.\n\n\n10.8.3 Erster Blick in den Datensatz penguins\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Quelle der Daten:\n\n\nCode\npenguins_url <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\n#| results: \"hide\"\n#| message: false\npenguins <- \n  read_csv(penguins_url)\n\n\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz:\n\n\nCode\npenguins %>% \n  select(body_mass_g, species) %>% \n  group_by(species) %>% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nSkewness\nKurtosis\nn\nn_Missing\n.group\n\n\n\n\nbody_mass_g\n3700.662\n458.5661\n0.2853361\n-0.5737376\n151\n1\nspecies=Adelie\n\n\nbody_mass_g\n3733.088\n384.3351\n0.2474331\n0.5933789\n68\n0\nspecies=Chinstrap\n\n\nbody_mass_g\n5076.016\n504.1162\n0.0696349\n-0.7227912\n123\n1\nspecies=Gentoo\n\n\n\n\n\n\nWas fÃ¤llt Ihnen auf?\n\n\n10.8.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. AbbildungÂ 10.9, AbbildungÂ 10.10, AbbildungÂ 10.11 ?\n\n\n\n\n\nAbbildungÂ 10.9: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\nAbbildungÂ 10.10 zeigt die Gewichtsverteilung pro Spezies als â€œBergrÃ¼ckenâ€ (geom_ridges).\n\n\n\n\n\nAbbildungÂ 10.10: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Ridges\n\n\n\n\nAbbildungÂ 10.11 zeigt die Gewichtsverteilung pro Spezies als â€œhalbe Violinenâ€ (geom_ridges), sozusagen Dichtediagramme um 90 Grad gedreht.\n\n\nCode\npenguins %>% \n  ggplot(aes(x = species, y = body_mass_g, fill = species)) +\n  geom_violindot(fill_dots = \"black\")\n\n\n\n\n\nAbbildungÂ 10.11: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Violindot\n\n\n\n\n\n\n10.8.5 Mittlere Gewichtsunterschiede in der Population\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und TabelleÂ 10.7.\n\n\nCode\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 <- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42)\n\n\nm10.6 %>% \n  parameters()\n\n\n\n\n\n\nTabelleÂ 10.7: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n3700.35\n(3629.70, 3774.26)\n100%\n1.000\n4156.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n33.23\n(-101.11, 164.89)\n68.08%\n1.000\n4139.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.51\n(1265.81, 1486.61)\n100%\n1.000\n4201.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n10.8.6 Interpretation von m10.6\nDie UV hat drei verschiedene Stufen (Werte, AusprÃ¤gungen; hier: Spezies), aber es werden in TabelleÂ 10.7 nur zwei Stufen angezeigt (also eine weniger) zusÃ¤tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrÃ¼ckt (Intercept). Die Koeffizienten fÃ¼r species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in AbbildungÂ 10.12 verdeutlicht.\n\n\nCode\nplot(hdi(m10.6))\n\n\n\n\n\nAbbildungÂ 10.12: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\n\n\n10.8.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich hÃ¶her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich Ã¤hnlich.\nWie in AbbildungÂ 10.12 ersichtlich, Ã¼berlappt sich der SchÃ¤tzbereich fÃ¼r den Parameter von Gentoo nicht mit der Null; hingegen Ã¼berlappt sich der SchÃ¤tzbereich des Parameters fÃ¼r Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells schlieÃŸen wir also (mit hoher Sicherheit) aus, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hÃ¤tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prÃ¼fen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primÃ¤r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen."
  },
  {
    "objectID": "metrische-AV.html#priori-werte",
    "href": "metrische-AV.html#priori-werte",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.9 Priori-Werte",
    "text": "10.9 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. FÃ¼r Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfÃ¼r Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: prior_summary(modell):\n\n\nCode\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man Ã¼ber mehr inhaltliches Wissen verfÃ¼gt, so wird man die Prioris anpassen wollen, z.B.:\n\n\nCode\nm10.6b <- stan_glm(body_mass_g ~ species, \n                   data = penguins, \n                   refresh = 0,\n                   seed = 42,\n                   prior = normal(location = c(0, 0),  # betas, Mittelwert\n                                  scale = c(500, 500)),  # betas, Streuung\n                   prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n                   prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3704.89008         22.93895       1356.65099\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\n\nCode\nm10.6c <- stan_glm(body_mass_g ~ species, \n                   data = penguins, \n                   refresh = 0,\n                   seed = 42,\n                   prior = normal(location = c(0, 0),  # betas, Mittelwert\n                                  scale = c(2.5, 2.5),  # betas, Streuung\n                                  autoscale = TRUE),  # in z-Einheiten\n                   prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                                            autoscale = TRUE), \n                   prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.99471         32.08176       1374.15711\n\n\nDen Parameter fÃ¼r die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\n\nCode\nsigma(m10.6b)\n## [1] 463.7358\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die GrÃ¶ÃŸe der Konfidenzintervalle.\nÃœbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren4.\n\n10.9.1 Wechsel der Referenzkategorie\n\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\n\n\nCode\npenguins <- penguins %>% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge Ã¤ndern.\n\n\nCode\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\n\nCode\nlibrary(forcats)\npenguins <- penguins %>% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verfÃ¼gbar sein muss.\nJetzt haben wir die Referenzkategorie geÃ¤ndert:\n\n\nCode\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie Ã¤ndert nichts Wesentliches am Modell:\n\n\nCode\nm10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n4994.870\n5155.267\nfixed\nconditional\n\n\nspeciesAdelie\n0.95\n-1478.109\n-1262.373\nfixed\nconditional\n\n\nspeciesChinstrap\n0.95\n-1471.435\n-1203.731\nfixed\nconditional"
  },
  {
    "objectID": "metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "href": "metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.10 ModellgÃ¼te mit R-Quadrat bestimmen",
    "text": "10.10 ModellgÃ¼te mit R-Quadrat bestimmen\n\n10.10.1 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt. - HÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt. \\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert. Solch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor. Daher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\n\n\n\n\nCode\nr2(m10.6)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.667 (95% CI [0.619, 0.712])\n\n\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. ?fig-m106-r2.\n\n\nCode\nm10.6_r2 <-\nm10.6 %>% \n  r2_posterior() %>% \n  as_tibble()\n\nhdi(m10.6_r2) %>% \n  plot()\n\n\n\n\n\nAbbildungÂ 10.13: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n\n10.10.2 Definition vom â€œklassischenâ€ \\(R^2\\)\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die â€œtypischeâ€ Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nÃ¼tzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklÃ¤rten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck Ã¤quivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen AusdrÃ¼cke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlÃ¤ssigen Ungewissheit; sie sind Ã¼bergewiss aus Bayes-Sicht.\n\n\n10.10.3 Bayesâ€™ \\(R^2\\)\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der ModellgÃ¼te miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkÃ¤rte Varianz}}{\\text{ErklÃ¤rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. FÃ¼r jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklÃ¤rten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u.Â a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7."
  },
  {
    "objectID": "metrische-AV.html#sec-rope",
    "href": "metrische-AV.html#sec-rope",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.11 Nullhypothesen sind praktisch immer falsch",
    "text": "10.11 Nullhypothesen sind praktisch immer falsch\nNullhypothesen sind fast immer falsch, s. AbbildungÂ 10.14.\n\n\n\n\n\nAbbildungÂ 10.14: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, und Vehtari (2021)\n\n10.11.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist5\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen sind:\n- Posteriori-Intervalle (PI oder HDI)  berichten\n- Rope-Konzept, @kruschke_rejecting_2018\n- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\n- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n\n10.11.2 â€œPraktischâ€ kein Unterschied: Das Rope-Konzept\nSagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar. Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt. Unter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroÃŸteil liegt innerhalb von Rope â¡ï¸ Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\nGroÃŸteil liegt auÃŸerhalb von Rope â¡ï¸ Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\nAnsonsten â¡ï¸ keine Entscheidung\n\n\n\n10.11.3 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\nKruschke (2018), Abbildung 1, S. 272\n\n\n10.11.4 Rope berechnen\nDen Rope berechnet man mit rope(model).\n\n\nCode\nrope(m10.6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-80.19545\n80.19545\n0.0000000\nfixed\nconditional\n\n\nspeciesChinstrap\n0.95\n-80.19545\n80.19545\n0.7434211\nfixed\nconditional\n\n\nspeciesGentoo\n0.95\n-80.19545\n80.19545\n0.0000000\nfixed\nconditional\n\n\n\n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir kÃ¶nnen daher fÃ¼r diese Gruppe das ROPE nicht verwerfen.\nAber: Gentoo liegt zu 0% im Rope. FÃ¼r Gentoo kÃ¶nnen wir das Rope verwerfen.\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n\n10.11.5 Visualisierung unserer Rope-Werte, m10.6\n\nEin GroÃŸteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut.\n\n\n\nCode\nrope(m10.6) %>% plot()\n\n\n\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung fÃ¼r Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir kÃ¶nnen das Rope fÃ¼r Chinstrap nicht verwerfen, aber auch nicht bestÃ¤tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom â€œblauen Flussâ€ des Rope: Gentoo liegt auÃŸerhalb des Rope. Es gibt einen â€œsubstanziellenâ€ Unterschied, grÃ¶ÃŸer als das ROPE. Wir verwerfen die â€œPraktisch-Null-Hypotheseâ€ in diesem Fall.\n\n\n10.11.6 Finetuning des Rope\nWir kÃ¶nnen festlegen, was wir unter â€œpraktischer Ã„quivalenzâ€ verstehen, also die Grenzen des Ropes verÃ¤ndern. Sagen wir, 100 Gramm sind unsere Grenze fÃ¼r einen vernachlÃ¤ssigbaren Effekt, s. AbbildungÂ 10.15.\n\n\nCode\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100)))\n\n\n\n\n\nAbbildungÂ 10.15: ROPE mit selber eingestellter Grenze von Â±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\n\nCode\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht fÃ¼r ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.\n\n\n10.11.7 Beantwortung der Forschungsfrage\nFÃ¼r die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. FÃ¼r Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt."
  },
  {
    "objectID": "metrische-AV.html#mehrere-metrische-uv",
    "href": "metrische-AV.html#mehrere-metrische-uv",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.12 Mehrere metrische UV",
    "text": "10.12 Mehrere metrische UV\n\n10.12.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhÃ¤ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa â€œIQ der Mutter ist die Ursache zum IQ des Kindesâ€) wird impliziert.\nEs geht rein darum, ZusammenhÃ¤nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. FÃ¼r solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nÃ¶tig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\n\nCode\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n\n\n10.12.2 Was heiÃŸt, X hÃ¤ngt mit Y zusammen?\n\nDer Begriff â€œZusammenhangâ€ ist nicht exakt.\nHÃ¤ufig wird er (fÃ¼r metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groÃŸ der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem â€œEffekt von X auf Yâ€ Ã¼bersetzt. Vorsicht: â€œEffektâ€ klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende BegrÃ¼ndung fÃ¼r einen Kausalzusammenhang.\n\nDer Korrelationskoeffizient\n\nmisst eine Art der StÃ¤rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehÃ¶rigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n\n10.12.3 Korrelationen zur Forschungsfrage\n\n\nCode\nkidiq %>% \n  correlation()\n\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n< .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n< .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n< .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n< .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\nOder als Korrelationsmatrix:\n\n\nCode\nkidiq %>% \n  correlation() %>% \n  summary()\n\n\n\n\n\n\nParameter\nmom_age\nmom_iq\nmom_hs\n\n\n\n\nkid_score\n0.0919982\n0.4482758\n0.2369164\n\n\nmom_hs\n0.2145284\n0.2827094\nNA\n\n\nmom_iq\n0.0916084\nNA\nNA\n\n\n\n\n\n\n\n\nCode\nkidiq %>% \n  correlation() %>% \n  summary() %>% \n  plot()\n\n\n\n\n\n\n\n10.12.4 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro PrÃ¤diktor, also eine fÃ¼r mom_iq und eine fÃ¼r mom_age.\n\n\nCode\nm10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nHier die Ergebnisse fÃ¼r mom_iq:\n\n\nCode\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.7778123   0.6108659\n\n\nHier die Ergebnisse fÃ¼r mom_age:\n\n\nCode\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.0528981   0.6914317\n\n\n\n\n10.12.5 Visualisierung der univariaten Regressionen\nIn AbbildungÂ 10.16 ist die univariate Regression mit jeweils einem der beiden PrÃ¤diktoren dargestellt.\nm10.7: Die Steigung betrÃ¤gt 0.6. m10.8: Die Steigung betrÃ¤gt 0.7.\n\n\nCode\np1 <- \n  kidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.7)[1],\n              slope = coef(m10.7)[2],\n              color = \"blue\") \n\np2 <- \nkidiq %>% \n  ggplot(aes(x = mom_age, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.8)[1],\n              slope = coef(m10.8)[2],\n              color = \"blue\")\n\nplots(p1, p2,\n      title = c(\"m10.7: Die univariate Regression mit dem Alter der Mutter als PrÃ¤diktor\",\n        \"m10.8: Die univariate Regression mit dem IQ der Mutter als PrÃ¤diktor\"))\n\n\n\n\n\nAbbildungÂ 10.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n\n10.12.6 Multiples Modell (beide PrÃ¤diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein PrÃ¤diktor im Modell aufgenommen ist.\n\n\nCode\nm10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.5161986   0.6040883   0.3804400\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils â€œbereinigtâ€ vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines PrÃ¤diktors mit der AV, wobei man gleichzeitig den anderen PrÃ¤diktor konstant hÃ¤lt.\n\n\n\nCode\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.5161986   0.6040883   0.3804400\n\n\n\n\n10.12.7 3D-Visualisierung eines Modells mit zwei PrÃ¤diktoren 1\nIn AbbildungÂ 10.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\nAbbildungÂ 10.17: 3D-Visualisierung von m10.9 (zwei PrÃ¤diktoren)\n\n\n\n\n\n10.12.8 Visualisierung mit Farbe statt 3. Dimension\n3D-Visualisierungen haben Vorteile, aber auch Nachteile; AbbildungÂ 10.18 zeigt eine alternative Visualisierung, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\nAbbildungÂ 10.18: Modell m10.9; die FarbverlÃ¤ufe zeigen der Wert der abhÃ¤ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der FarbÃ¤nderung) die VerÃ¤nderung fÃ¼r die AV (kid_score). Auf der Achse fÃ¼r mom_age sieht man, dass sich die AV kaum Ã¤ndert, wenn sich mom_age Ã¤ndert.\n\n\n10.12.9 Visualisierung in 10 Dimensionen\nAbbildungÂ 10.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\nAbbildungÂ 10.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere SchwÃ¤chen, eine groÃŸe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n\n10.12.10 Relevanz der PrÃ¤diktoren\nWoher weiÃŸ man, welcher PrÃ¤diktor am stÃ¤rksten mit der AV zusammenhÃ¤ngt? Man kÃ¶nnte auch sagen: Welcher PrÃ¤diktor (welche UV) am â€œwichtigstenâ€ ist oder den â€œstÃ¤rksten Einflussâ€ auf die AV ausÃ¼bt? Bei solchen kausal konnotierten AusdrÃ¼cken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann fÃ¼r sich nur Muster in den Daten, also ZusammenhÃ¤nge bzw. Unterschiede, entdecken, s. AbbildungÂ 10.20.\n\n\n\nAbbildungÂ 10.20: Made at imgflip.com\n\n\nWelcher PrÃ¤diktor ist nun â€œwichtigerâ€ oder â€œstÃ¤rkerâ€ in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)?\n\nmom_iq hat den grÃ¶ÃŸeren Koeffizienten.\nmom_age hat weniger Streuung.\n\nUm die Relevanz der PrÃ¤diktoren vergleichen zu kÃ¶nnen, mÃ¼sste man vielleicht die VerÃ¤nderung von kid_score betrachten, wenn man von kleinsten zum grÃ¶ÃŸten PrÃ¤diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die VerÃ¤nderung in der AV zu betrachten, wenn man den PrÃ¤diktor von â€œunterdurchschnittlichâ€ auf â€œÃ¼berdurchschnittlichâ€ Ã¤ndert. Das kann man mit z-Standardisierung erreichen.\n\n\n10.12.11 z-Standardisierung\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie Ã¼ber einen Mittelwert von 0 und eine SD von 1 verfÃ¼gt:\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\n\nCode\ndata(\"kidiq\")\nkidiq2 <- \n  kidiq %>% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% \n  select(mom_iq, mom_iq_z) %>% \n  head()\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten6. Die Standardisierung ist Ã¤hnlich zur Vergabe von ProzentrÃ¤ngen: â€œDieser Messwert gehÃ¶rt zu den Top-3-Prozentâ€. Diese Aussage ist bedeutsam fÃ¼r Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen fÃ¼r verschiedene Verteilungen mÃ¶glich.\n\n\n10.12.12 Statistiken zu den z-transformierten Variablen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\nMan kann auch die z-Transformation (â€œSkalierungâ€) mit standardize durchfÃ¼hren:\n\n\nCode\nkidiq <- \n  standardize(kidiq, append = TRUE)\n\nhead(kidiq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafÃ¼r, dass die ursprÃ¼nglichen Variablen beim Z-Standardisieren nicht Ã¼berschrieben werden, sondern angehÃ¤ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren.\n\n\nCode\nkidiq %>% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket:\n\n\nCode\n#data(kidiq)\nkidiq %>% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score)) %>% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_z2\nmom_age_z2\nkid_score_z2\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n1.4078352\n1.5602285\n-1.06793237\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n-0.7092079\n0.8197811\n0.54886757\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n1.0295443\n1.5602285\n-0.08805362\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n-0.0366907\n0.8197811\n-0.18604150\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n-0.4836193\n1.5602285\n1.38176451\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n0.5267892\n-1.7717849\n0.54886757"
  },
  {
    "objectID": "metrische-AV.html#modell-m10.10",
    "href": "metrische-AV.html#modell-m10.10",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.13 Modell m10.10",
    "text": "10.13 Modell m10.10\nIm Modell m10.10 sind die PrÃ¤diktoren z-standardisiesrt. Das Standardisieren der AV, kid_score ist nicht nÃ¶tig, um den Effekt der PrÃ¤diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darÃ¼ber, um wie viele SD-Einheiten sich die AV verÃ¤ndert, wenn sich ein PrÃ¤diktor um eine SD-Einheit verÃ¤ndert.\n\n\nCode\nm10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq, \n                   refresh = 0)\ncoef(m10.10)\n##   (Intercept)      mom_iq_z     mom_age_z \n## -0.0007527543  0.4434725898  0.0511782491\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient fÃ¼r mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_iq um eine SD-Einheit Ã¤ndert.\nDer Koeffizient fÃ¼r mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_age um eine SD-Einheit Ã¤ndert.\n\nJetzt sind die PrÃ¤diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n10.13.1 95%-PI\nMit parameters kÃ¶nnen wir uns ein PI fÃ¼r m10.10 ausgeben lassen, s. AbbildungÂ 10.21; im Standard wird ein ETI berichtet.\n\n\nCode\nparameters(m10.10) \n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-7.53e-04\n(-0.09, 0.09)\n50.50%\n0.999\n5170.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0.999\n5501.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.72%\n0.999\n4884.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\n\nCode\nplot(eti(m10.10))\n\n\n\n\n\nAbbildungÂ 10.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI fÃ¼r m10.10\n\n\n\n\n\n\n10.13.2 Was ist ein kleiner, was ein groÃŸer Effekt?\nCohen (1988) definiert EffektstÃ¤rken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\). FÃ¼r kleine, mittlere und groÃŸe Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\nmittel: \\(d \\approx 0.5\\)\ngroÃŸ: \\(d \\approx 0.8\\)\n\nAuf dieser Basis schlÃ¤gt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor. FÃ¤llt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als â€œpraktisch nullâ€. Richtlinien fÃ¼r EffektstÃ¤rken sind nur NotlÃ¶sungen, die durch Sachverstand ersetzt werden sollen, wo immer mÃ¶glich. Man kann EffektstÃ¤rken ineinander Ã¼berfÃ¼hren, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n\n10.13.3 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat. Ein vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n\n10.13.4 ModellgÃ¼te\n\n\nCode\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.144, 0.270])\n\n\nIst dieser Wert von \\(R2\\) â€œgutâ€? Diese Frage ist Ã¤hnlich zur Frage â€œIst das viel Geld?â€; man kann die Frage nur im Kontext beantworten.\nEine einfache LÃ¶sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklÃ¤rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufÃ¤llig hohen Werten der ModellgÃ¼te im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine â€œobjektiveâ€ Antwort auf die Frage â€œwie viel ist viel?â€ haben wollen, ziehen wir Herrn Cohen zu Rate:\n\n\nCode\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n\n10.13.5 Priori-Verteilung fÃ¼r m10.10 und Modelldefinition\nStan hat fÃ¼r uns folgende Prioris ausgesucht:\n\n\nCode\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWie gesagt, Stan nimmt dafÃ¼r einfach die empirischen Mittelwerte und Streuungen her7.\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. GleichungÂ 10.1.\n\\[\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{10.1}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.10. Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzufÃ¼hren.\n\n\n10.13.6 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar fÃ¼r einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkÃ¤rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich u.Â a. 2022) zurÃ¼ck (s. Anhang fÃ¼r Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem â€œstatistischen Effektâ€ gesprochen, um klar zu machen, dass es sich lediglich um assoziative ZusammenhÃ¤nge, und nicht um kausale ZusammenhÃ¤nge, handelt. Kausale ZusammenhÃ¤nge dÃ¼rfen wir nur verkÃ¼nden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafÃ¼r finden oder c) wir ein Experiment fachgerecht durchgefÃ¼hrt haben."
  },
  {
    "objectID": "metrische-AV.html#vertiefung",
    "href": "metrische-AV.html#vertiefung",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.14 Vertiefung",
    "text": "10.14 Vertiefung\nğŸï¸VERTIEFUNG, nicht prÃ¼fungsrelevantğŸï¸\n\n10.14.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\\[b = r \\frac{sd_x}{sd_y}\\]\n\n\nCode\nm10.11 <- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq, refresh = 0)\ncoef(m10.11)\n##   (Intercept)      mom_iq_z \n## -0.0006129979  0.4472294200\n\n\n\n\nCode\nkidiq %>% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nkid_score\nmom_iq\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nkid_score\nkid_score_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nkid_score_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nmom_iq_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score_z\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\n\n\n\n\n\n\n10.14.2 PrÃ¼fen der LinearitÃ¤tsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen PrÃ¤diktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression hÃ¤ufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schÃ¤tzen (Gelman, Hill, und Vehtari 2021).\nIst die LinearitÃ¤tsannahme erfÃ¼llt, so sollte der Residualplot nur zufÃ¤llige Streuung um \\(y=0\\) herum zeigen, s. AbbildungÂ 10.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsÃ¤chlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\n\nCode\nkidiq <-\n  kidiq %>% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\n\n\nCode\nkidiq %>% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\nAbbildungÂ 10.22: Die Verteilung der Fehler scheint keinem starken Trend (in AbhÃ¤ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine grÃ¶ÃŸeren AuffÃ¤lligkeiten.\n\n\n10.14.3 ModellprÃ¼fung mit der PPV\n\n\nCode\npp_check(m10.10)\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht hÃ¤ufig.\n\n\n10.14.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\nCode\nset.seed(42)\ndata(kidiq)\nkidiq3 <- \n  kidiq %>% \n  standardize(append = TRUE) %>% \n  sample_n(size = 300)\n\n#| results: \"hide\"\nm10.10a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)\nm10.10b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(mom_age_resid = resid(m10.10a)) %>% \n  mutate(mom_iq_resid = resid(m10.10b))\n\n\nm10.10c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)\nm10.10d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)\n\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(m10.10c_resid = resid(m10.10c)) %>% \n  mutate(m10.10d_resid = resid(m10.10d))\n\n\n\n\n\n\n\nCode\n#(m10.10a_plot + m10.10b_plot) / (m10.10c_plot + m10.10d_plot)\nplots(m10.10a_plot, m10.10b_plot, m10.10c_plot, m10.10d_plot, \n      n_rows = 2, tags = \"A\",\n      guides = \"collect\")\n\n\n\n\n\nDie vertikalen Balken zeigen die Residuen.\nObere Reihe: Regression eines PrÃ¤diktors auf den anderen PrÃ¤diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-7.53e-04\n(-0.09, 0.09)\n50.50%\n0.999\n5170.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0.999\n5501.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.72%\n0.999\n4884.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\n\n10.14.5 Bereinigte Regressionskoeffizienten fÃ¼r mtcars\n\n\nCode\nmtcars2 <-\n  mtcars %>% \n  standardize()\n\nm12a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)\nm12b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)\n\nmtcars2 <-\n  mtcars %>% \n  mutate(m12a_resid = resid(m12a)) %>% \n  mutate(m12b_resid = resid(m12b))\n\n\nm12c <- stan_glm(mpg ~ m12a_resid, data = mtcars2, refresh = 0, chains = 1)\nm12d <- stan_glm(mpg ~ m12b_resid, data = mtcars2, refresh = 0, chains = 1)\n\n\nmtcars2 <-\n  mtcars2 %>% \n  mutate(m12c_resid = resid(m12c)) %>% \n  mutate(m12d_resid = resid(m12d))\n\n\n\n\n\n\n\n\n\n\nÃœbrigens liefern stan_glm() und lm oft Ã¤hnliche Parameterwerte (bei schwach informativen Prioriwerten):\n\n\nCode\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %>% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Parameterwerte eines Frequentistischen und Bayes-Modell numerisch Ã¤hnlich sein kÃ¶nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.\n\n\n\n\n10.14.6 Post: Bayes in fÃ¼nf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem."
  },
  {
    "objectID": "metrische-AV.html#ausblick-binÃ¤re-av",
    "href": "metrische-AV.html#ausblick-binÃ¤re-av",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.15 Ausblick: BinÃ¤re AV",
    "text": "10.15 Ausblick: BinÃ¤re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\n\nCode\ndata(mtcars)\nmtcars2 <-\n  mtcars %>% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m13: am ~ mpg_z:\n\n\nCode\nm13 <-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\n\nCode\nmtcars2 %>% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\nCode\nneg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))\n\n\nFÃ¼r kleine Werte von mpg_z (<1.3) sagt unser Modell negative Werte fÃ¼r am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. MÃ¼ssen wir mal bei Gelegenheit besser machen.\nWir waren fleiÃŸig â€¦\n\n\n\n\n\nQuelle\nGenug fÃ¼r heute. ğŸ‘"
  },
  {
    "objectID": "metrische-AV.html#aufgaben",
    "href": "metrische-AV.html#aufgaben",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.16 Aufgaben",
    "text": "10.16 Aufgaben\n\nAnova-skalenniveau\nNullhyp-Beispiel\nttest-skalenniveau\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\nRegression3  \ndiamonds-nullhyp-mws\nstan_glm_parameterzahl\nstan_glm_prioriwerte\nzwert-berechnen\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope-regr\nrope1\nrope2\nrope3\nrope4\n\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja, Sitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, und Daniel M. Croymans. 2021. â€Behavioural Nudges Increase COVID-19 Vaccinationsâ€œ. Nature 597 (7876): 404â€“9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. â€R-Squared for Bayesian Regression Modelsâ€œ. The American Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, und Sam Brilleman. 2022. â€rstanarm: Bayesian applied regression modeling via Stan.â€œ https://mc-stan.org/rstanarm/.\n\n\nKruschke, John K. 2018. â€Rejecting or Accepting Parameter Values in Bayesian Estimationâ€œ. Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B. Gubbay, Sarah A. Buchan, Deshayne B. Fell, u.Â a. 2021. â€Effectiveness of mRNA and ChAdOx1 COVID-19 Vaccines Against Symptomatic SARS-CoV-2 Infection and Severe Outcomes with Variants of Concern in Ontarioâ€œ. https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi, Mohammad Hossein Razizadeh, Diana L. Turner, und Raymond J. Turner. 2021. â€Efficacy and Safety of COVID-19 Vaccines: A Systematic Review and Meta-Analysis of Randomized Clinical Trialsâ€œ. Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball, Allison L. Naleway, Toan C. Ong, Malini B. DeSilva, u.Â a. 2021. â€Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient Care Settingsâ€œ. New England Journal of Medicine 385 (15): 1355â€“71. https://doi.org/10.1056/NEJMoa2110362."
  },
  {
    "objectID": "kausal.html",
    "href": "kausal.html",
    "title": "11Â  Kausalinferenz",
    "section": "",
    "text": "FÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\n\nCode\nlibrary(dagitty)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n\n\n\n\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nrklÃ¤ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\ndie â€œAtomeâ€ der KausalitÃ¤t eines DAGs benennen\nâ€œkausale HintertÃ¼renâ€ schlieÃŸen"
  },
  {
    "objectID": "kausal.html#statistik-was-soll-ich-tun",
    "href": "kausal.html#statistik-was-soll-ich-tun",
    "title": "11Â  Kausalinferenz",
    "section": "11.2 Statistik, was soll ich tun?",
    "text": "11.2 Statistik, was soll ich tun?\n\n11.2.1 Studie A: Ã–strogen\nMit Blick auf TabelleÂ 11.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\n\n\n\nTabelleÂ 11.1:  Daten zur Studie A \n  \n  \n    \n      Gruppe\n      Mit Medikament\n      Ohne Medikament\n    \n  \n  \n    MÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n    Frauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n    Gesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n  \n  \n  \n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt Pearl, Glymour, und Jewell (2016)?\n\n\n11.2.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 11.1 dargestellt.\n\n\n\n\n\nAbbildungÂ 11.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg.\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nAchtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung.\n\n\n\n\n11.2.3 Studie B: Blutdruck\nMit Blick auf TabelleÂ 11.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\n\n\nTabelleÂ 11.2:  Daten zur Wirksamkeit eines Medikaments (Studie B) \n  \n  \n    \n      Gruppe\n      Ohne Medikament\n      Mit Medikament\n    \n  \n  \n    geringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n    hoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n    Gesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n  \n  \n  \n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? Pearl, Glymour, und Jewell (2016)\n\n\n11.2.4 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell ist in AbbildungÂ 11.2 dargestellt.\n\n\n\n\n\nAbbildungÂ 11.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n\n11.2.5 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 11.1 und AbbildungÂ 11.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n\n11.2.6 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ Statistik plus Theorie erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n\n11.2.7 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ã„rzte tendieren zu Behandlung A bei groÃŸen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ã„rzte zu Behandlung B.\nSollte ein Patient, der nicht weiÃŸ, ob sein Nierenstein groÃŸ oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratiï¬zierten Daten (Teildaten nach SteingrÃ¶ÃŸe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wÃ¤hlt?\n\n\n11.2.8 Kausalmodell zur Studie C\nDie GrÃ¶ÃŸe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (â€œKetteâ€) von GrÃ¶ÃŸe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. DarÃ¼ber hinaus gibt es noch einen Einfluss von GrÃ¶ÃŸe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in AbbildungÂ 11.3 dargestellt; @AbbildungÂ 11.3 visualisiert alternativ.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schÃ¤tzen mÃ¶chte? Oder lieber nicht kontrollieren?\n\n\n\n\n\nAbbildungÂ 11.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. WÃ¼rde man nicht size kontrollieren, bekÃ¤me man den â€œvermengtenâ€ Effekt von size und treatment, also keine (belastbare) Aussage Ã¼ber den Effekt der Behandlung.\n\n\n11.2.9 Mehr Beispiele\nNehmen Sie Bezug zu folgenden Aussagen:\n\nStudien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhÃ¶hen, wenn du heiratest.\n\n\nStudien zeigen, dass Leute, die sich beeilen, zu spÃ¤t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spÃ¤t zu deiner Besprechung."
  },
  {
    "objectID": "kausal.html#konfundierung",
    "href": "kausal.html#konfundierung",
    "title": "11Â  Kausalinferenz",
    "section": "11.3 Konfundierung",
    "text": "11.3 Konfundierung\n\n11.3.1 Datensatz â€˜Hauspreise im Saratoga Countyâ€™\nDatenquelle; Beschreibung des Datensatzes\n\n\nCode\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.3.2 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\nFinden Sie den Wert meiner Immobilie heraus!  Die muss viel wert sein!â€\n\nğŸ§‘ Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich. ğŸ‘© ğŸ”¬\n\nDas ist Angie, Data Scientistin.\n\n\n11.3.3 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\nâ€œHey Don! Mehr Zimmer, mehr Kohle!â€ ğŸ‘© ğŸ”¬\n\n\n\n\n\n\n\n\n11.3.4 Posteriori-Verteilung von Modell 1\n\nâ€œJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend.â€\n\nğŸ‘©\n\nZu wenig! ğŸ¤¬\n\nğŸ§‘\nBerechnen wir das Modell:\n\n\nCode\nm1 <- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               data = d)\nhdi(m1)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n43840.61\n77124.87\nfixed\nconditional\n\n\nbedrooms\n0.95\n43079.51\n53288.92\nfixed\nconditional\n\n\n\n\n\n\nMit estimate_preditioncs kÃ¶nnen wir Vorhersagen berechnen (bzw. schÃ¤tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist â€œschÃ¤tzenâ€ vielleicht das treffendere Wort):\n\n\nCode\ndons_house <- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\n\n\nbedrooms\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n2\n157442.5\n92828.53\n-17127.16\n342171.7\n\n\n\n\n\n\n\n\n11.3.5 Don hat eine Idee\n\nâ€œIch bau eine Mauer! Genial! An die Arbeit, Angie!  ğŸ§‘\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\nDas ist keine gute Idee, Don.â€\n\nğŸ‘©\nBerechnen wir die Vorhersagen fÃ¼r Dons neues Haus (mit den durch Mauern halbierten Zimmern).\n\n\nCode\ndons_new_house <- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\n\n\n\n\n\n\nbedrooms\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n4\n254045.5\n90376.97\n75213.52\n438559.8\n\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1.\n\nVolltreffer! Jetzt verdien ich 100 Tausend mehr! ğŸ¤‘ Ich bin der GrÃ¶ÃŸte! ğŸ§‘\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: â€œ4e+05â€ ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n\n11.3.6 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berÃ¼cksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im â€œStrukturmodellâ€: Wenn also z.B. in unserem Modell ein wichtiger PrÃ¤diktor fehlt, so kann die Vorhersagen nicht prÃ¤zise sein. Fehler im Strukturmodell schlagen sich in breiten SchÃ¤tzintervallen (bedingt durch ein groÃŸes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berÃ¼cksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\n\nDie SchÃ¤tzbereiche sind in dem Fall deutlich kleiner:\n\n\nCode\nestimate_expectation(m1, dons_new_house)\n\n\n\n\n\n\nbedrooms\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n4\n252750.8\n3180.447\n247013\n259149.6\n\n\n\n\n\n\n\n\n11.3.7 Modell 2: price ~ bedrooms + livingArea\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea.\n\n\nCode\nm2 <- stan_glm(price ~ bedrooms + livingArea, data = d, refresh = 0)\n\nhdi(m2)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n23858.8853\n49287.0975\nfixed\nconditional\n\n\nbedrooms\n0.95\n-19765.5040\n-9083.4058\nfixed\nconditional\n\n\nlivingArea\n0.95\n118.4447\n132.5536\nfixed\nconditional\n\n\n\n\n\n\nWas sind die Vorhersgaen des Modell?\n\n\nCode\nestimate_prediction(m2, data = tibble(bedrooms = 4, livingArea = 1200))\n\n\n\n\n\n\nbedrooms\nlivingArea\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n4\n1200\n129757.5\n69715.05\n-12376.63\n259215.2\n\n\n\n\n\n\nAndere, aber Ã¤hnliche Frage: Wieviel Haus kostet ein Haus mit sagen wir 4 Zimmer gemittelt Ã¼ber die verschiedenen GrÃ¶ÃŸen von livingArea? Stellen Sie sich alle HÃ¤user mit 4 Zimmern vor (also mit verschiedenen WohnflÃ¤chen). Wir mÃ¶chten nur wissen, was so ein Haus â€œim Mittelâ€ kostet. Wir mÃ¶chten also die Mittelwerte pro bedroom schÃ¤tzen, gemittelt fÃ¼r jeden Wert von bedroom Ã¼ber livingArea:\n\n\nCode\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\n\n\n\n\nbedrooms\nMean\nCI_low\nCI_high\n\n\n\n\n1\n242519.3\n230510.6\n254479.7\n\n\n2\n228300.7\n221405.8\n235327.4\n\n\n3\n214140.5\n210800.1\n217293.3\n\n\n4\n199960.6\n194346.5\n205417.3\n\n\n5\n185766.2\n175301.2\n195983.9\n\n\n6\n171661.4\n155680.4\n186894.2\n\n\n7\n157538.4\n136179.1\n177991.5\n\n\n\n\n\n\n\nâ€œDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!â€\n\nğŸ‘©\n\nâ€œVerringert!? Weniger Geld?! Oh nein!â€ ğŸ§‘\n\n\n\n11.3.8 Die Zimmerzahl ist negativ mit dem Preis korreliert\nâ€¦ wenn man die WohnflÃ¤che (Quadratmeter) kontrolliert.\n\nâ€œNe-Ga-Tiv!â€\n\nğŸ‘©\nHauspreis stratifizieren\nQuellcode"
  },
  {
    "objectID": "kausal.html#kontrollieren-von-variablen",
    "href": "kausal.html#kontrollieren-von-variablen",
    "title": "11Â  Kausalinferenz",
    "section": "11.4 Kontrollieren von Variablen",
    "text": "11.4 Kontrollieren von Variablen\nğŸ’¡ Durch das Aufnehmen von PrÃ¤diktoren in die multiple Regression werden die PrÃ¤diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen PrÃ¤diktors mit \\(y\\), wenn man den (oder die) anderen PrÃ¤diktoren statistisch konstant hÃ¤lt.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom â€œNetto-Effektâ€ eines PrÃ¤diktors, oder davon, dass ein PrÃ¤diktor â€œbereinigtâ€ wurde vom (linearen) Einfluss der anderen PrÃ¤diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des PrÃ¤diktors \\(x_1\\) auf \\(y\\) anzeigen unabhÃ¤ngig vom Effekt der anderen PrÃ¤diktoren, \\(x_2,x_3,...\\) auf \\(y\\)\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines PrÃ¤diktors \\(x_1\\) wird fÃ¼r jede AusprÃ¤gung (Gruppe) des PrÃ¤diktors \\(x_2\\) berechnet.\n\n11.4.1 Das HinzufÃ¼gen von PrÃ¤diktoren kann die Gewichte der Ã¼brigen PrÃ¤diktoren Ã¤ndern\n\nAber welche und wie viele PrÃ¤diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nğŸ§‘\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nğŸ‘©\n\nWozu ist sie dann gut?!\n\nğŸ§‘\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur ErklÃ¤rung der Ursachen heranzuziehen."
  },
  {
    "objectID": "kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "href": "kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "title": "11Â  Kausalinferenz",
    "section": "11.5 Welches Modell richtig ist, kann die Statistik nicht sagen",
    "text": "11.5 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, weâ€™d like to know wheter an effect is â€œrealâ€ or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical â€œtestsâ€ on its way to acceptance.\n\nMcElreath (2020), S. 139\n\n11.5.1 Kausalmodell fÃ¼r Konfundierung, km1\n\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms.\nEine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht.\nd_connected heiÃŸt, dass die betreffenden Variablen â€œverbundenâ€ sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flieÃŸt ğŸŒŠ. d_separated heiÃŸt, dass sie nicht d_connected sind.\n\n\n11.5.2 m2 kontrolliert die Konfundierungsvariable livingArea\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloÃŸ?! Oh jeh!\n\nğŸ§‘\n\nWir mÃ¼ssen die Konfundierungsvariable kontrollieren.\n\nğŸ‘©\n\n\n\n\n\nDurch das Kontrollieren (â€œadjustierenâ€), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separeted.\n\n\n11.5.3 Konfundierer kontrollieren\n\n\n\n\nOhne Kontrollieren der Konfundierungsvariablen\n\nRegressionsmodell: y ~ x\n\n\n\n\n\nEs wird (fÃ¤lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation.\nM2. it Kontrollieren der Konfundierungsvariablen\nRegressionsmodell: y ~ x + group\n\n\n\n\n\nEs wird korrekt gezeigt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird.\nQuellcode\n\n\n11.5.4 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\n\n\n\n\n\nLaut km1 dÃ¼rfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n\n11.5.5 Kausalmodell 2, km2\nUnser Modell m2 sagt uns, dass beide PrÃ¤diktoren jeweils einen eigenen Beitrag zur ErklÃ¤rung der AV haben.\nDaher kÃ¶nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei KausaleinflÃ¼sse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) Ã¼ber den Mediator (b) zur AV (p) auch Mediation.\n\n\n\n\n\n\n\n11.5.6 Schoki macht Nobelpreis! (?)\nEine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen (HÃ¶he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli 2012).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation!\n\n\n\n\n11.5.7 Kausalmodell fÃ¼r die Schoki-Studie\nDer â€œSchoki-DAGâ€ in AbbildungÂ 11.5 zeigt den DAG fÃ¼r das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\n\nAbbildungÂ 11.5: Macht Schokolade Nobelpreise?\n\n\n\n\n\n\n11.5.8 Dons Kausalmodell, km3\nSo sieht Dons Kausalmodell aus, s. AbbildungÂ 11.6.\n\n\n\n\n\nAbbildungÂ 11.6: Dons Kausalmodell\n\n\n\n\n\nIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das grÃ¶ÃŸte! Alle anderen Kausalmodelle sind ein Disaster!â€\n\nğŸ§‘\n\n\nâ€œDon, nach deinem Kausalmodell mÃ¼ssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.â€\n\nRechne doch selber, die Korrelation aus, Don:\n\n\nCode\nd %>% \n  summarise(cor(bedrooms, livingArea))\n\n\n\n\n\n\ncor(bedrooms, livingArea)\n\n\n\n\n0.6561957\n\n\n\n\n\n\nğŸ‘©\n\n\n11.5.9 UnabhÃ¤ngigkeiten laut km1\nb: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.7.\n\n\n\n\n\nAbbildungÂ 11.7: ?(caption)\n\n\n\n\n\\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhÃ¤ngig von price, wenn man livingArea kontrolliert.\nâ›ˆï¸ Passt nicht zu den Daten/zum Modell!\n\n\n11.5.10 UnabhÃ¤ngigkeiten laut km2\nb: bedrooms, p: price, a area (living area)\n\n\n\n\n\nkeine UnabhÃ¤ngigkeiten\nâ“ Passt zu den Daten/zum Modell\n\n\n11.5.11 UnabhÃ¤ngigkeiten laut km3\nb: bedrooms, p: price, a area (living area)\n\n\n\n\n\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhÃ¤ngig von livingArea (a)\nâ›ˆï¸ Passt nicht zu den Daten/zum Modell!"
  },
  {
    "objectID": "kausal.html#dags-directed-acyclic-graphs",
    "href": "kausal.html#dags-directed-acyclic-graphs",
    "title": "11Â  Kausalinferenz",
    "section": "11.6 DAGs: Directed Acyclic Graphs",
    "text": "11.6 DAGs: Directed Acyclic Graphs\nWas sind DAGs?\n\nDAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.\nEin Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.\nDAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).\nDAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurÃ¼ckfÃ¼hren.\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten Ã¼ber die Kanten, unabhÃ¤ngig von der Pfeilrichtung.\n\n\n11.6.1 DAG von km1\n\n\n\n\n\n\n\n11.6.2 Leider passen potenziell viele DAGs zu einer Datenlage\nb: bedrooms, p: price, a area (living area)\n\n\n\n\n\n\n\n11.6.3 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (ziemlich hochtrabend) als â€œKausationâ€ verwenden.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiÃŸ man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\n\n\n\n\n\n\n\n\n\nQuelle und ErklÃ¤rung\n\n\n11.6.4 Fazit\nSind zwei Variablen korreliert (abhÃ¤ngig, assoziiert), so kann es dafÃ¼r zwei GrÃ¼nde geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (â€œScheinkorrelationâ€)\n\nEine mÃ¶gliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als PrÃ¤diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so lÃ¶st sich der Scheinzusammenhang nach dem Adjustieren auf.\nLÃ¶st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der ZusammenhÃ¤nge nach Adjustieren um, so spricht man einem Simpson Paradox.\nDie Daten alleine kÃ¶nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nÃ¶tig, um DAGs auszuschlieÃŸen."
  },
  {
    "objectID": "kausal.html#kollision",
    "href": "kausal.html#kollision",
    "title": "11Â  Kausalinferenz",
    "section": "11.7 Kollision",
    "text": "11.7 Kollision\n\n11.7.1 Kein Zusammenhang von Intelligenz und SchÃ¶nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und SchÃ¶nheit (looks), wie AbbildungÂ 11.8 illustriert. FÃ¼r geringe Intelligenzwerte gibt es eine breites Spektrum von SchÃ¶nheitswerten und fÃ¼r hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\nAbbildungÂ 11.8: Kein Zusammenhang von Intelligenz und SchÃ¶nheit in den Daten\n\n\n\n\nGott ist gerecht (?)\n\n\n11.7.2 Aber Ihre Dates sind entweder schlau oder schÃ¶n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schÃ¶n sind oder schlau - aber seltens beides gleichzeitig (schade), s. AbbildungÂ 11.9.\n\n\n\n\n\nAbbildungÂ 11.9: Ihre Datingpartner sind komischerweise entweder schlau oder schÃ¶n (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?"
  },
  {
    "objectID": "kausal.html#dag-zur-rettung",
    "href": "kausal.html#dag-zur-rettung",
    "title": "11Â  Kausalinferenz",
    "section": "11.8 DAG zur Rettung",
    "text": "11.8 DAG zur Rettung\nğŸ¦¹ ğŸ¦¸\nDer DAG in AbbildungÂ 11.10 bietet eine rettende ErklÃ¤rung.\n\n\n\n\n\nAbbildungÂ 11.10: Date als gemeinsame Wirkung von SchÃ¶nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen SchÃ¶nheit und Intelligenz.\n\n\n\n\nIn Ã¤hnlicher Weise, s. AbbildungÂ 11.11.\n\n\n\n\n\nAbbildungÂ 11.11: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n\n\n\n11.8.1 Was ist eine Kollision?\nAls Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen). Kontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. AbbildungÂ 11.10, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche PrÃ¤diktoren einer Regression hinzufÃ¼gen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n11.8.2 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchÃ¶ne Menschen\nReiche Menschen\n\nehen wir davon aus, dass SchÃ¶nheit und Reichtum unabhÃ¤ngig voneinander sind.\nWenn ich Ihnen sage, dass Don nicht schÃ¶n ist, aber in der Glitzer hÃ¤ufig auftaucht, was lernen wir dann Ã¼ber seine finanzielle Situation?1\n\nâ€œIch bin schÃ¶n, unglaublich schÃ¶n, und groÃŸ, groÃŸartig, tolle Gene!!!â€ ğŸ§‘\n\n\n\n11.8.3 Noch ein einfaches Beispiel zur Kollision\n\nâ€œSo langsam check ichâ€™s!â€\n\nSei Z = X + Y, wobei X und Y unabhÃ¤ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts Ã¼ber Y, da die beiden Variablen unabhÃ¤ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhÃ¤ngig â€“ gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).\n\n\n11.8.4 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildungÂ 11.10 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursacxhen.\nKontrollieren kann z.B. bedeuten:\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\nKontrollieren mit Regressioin: Durch Aufnahme von date als PrÃ¤diktor in eine Regression zusÃ¤tzlich zu looks mit talent als PrÃ¤dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (â€œFlussâ€) von Looks Ã¼ber date nach Talent ist blockiert.\nKontrolliert man date, so Ã¶ffnet sich der Pfad Looks -> date -> talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr â€œblockiertâ€, die Korrelation kann â€œflieÃŸenâ€ - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n\n11.8.5 IQ, Fleiss und Eignung fÃ¼rs Studium\nSagen wir, Ã¼ber die Eignung fÃ¼r ein Studium wÃ¼rden nur (die individuellen AusprÃ¤gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in AbbildungÂ 11.12.\n\n\n\n\n\nAbbildungÂ 11.12: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fÃ¼rs Studium) sei definiert als die Summe von iq und fleiss, plus etwas GlÃ¼ck:\n\n\nCode\nset.seed(42)  # Reproduzierbarkeit\nN <- 1e03  \n\nd_eignung <-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung > 0, 1, 0) \n  )\n\n\nLaut unserem Modell setzt sich Eignung zur HÃ¤lfte aus Intelligenz und zur HÃ¤lfte aus Fleiss zusammen, plus etwas GlÃ¼ck.\n\n\n11.8.6 Schlagzeile â€œSchlauheit macht Studentis faul!â€\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und FleiÃŸ (f) bei Studentis (s).\nErgebnis: Ein negativer Zusammenhang!?\nBerechnen wir das â€œEignungsmodellâ€, aber nur mit Studis (studium == 1):\n\n\nCode\nm_eignung <-\n  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n0.7004608\n0.8596029\nfixed\nconditional\n\n\nfleiss\n0.95\n-0.5266816\n-0.3634545\nfixed\nconditional\n\n\n\n\n\n\nAbbildungÂ 11.13 zeigt das Modell und die Daten.\n\n\n\n\n\nAbbildungÂ 11.13: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhÃ¤ngig von FleiÃŸ in unseren Daten, sondern abhÃ¤ngig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde Ã¼ber ZusammenhÃ¤nge auf und interpretieren die ZusammenhÃ¤nge - oft vorschnell - als kausal.2\n\n\n11.8.7 Kollisionsverzerrung nur bei Stratifizierung\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. AbbildungÂ 11.14.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\nAbbildungÂ 11.14: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nÃ¼tzen.\nNur Kenntnis des DAGs verrÃ¤t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten PrÃ¤diktor auf, so â€œkontrolliertâ€ man diese Variable. Das Regressiongewicht des ersten PrÃ¤diktors wird â€œbereinigtâ€ um den Einfluss des zweiten PrÃ¤diktors; insofern ist der zweite PrÃ¤diktor dann â€œkontrolliertâ€.\n\n\n\n\n11.8.8 Einfluss von GroÃŸeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und GroÃŸeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von GroÃŸeltern auf ihre Enkel, s. AbbildungÂ 11.15, Kurz (2021).\n\n\n\n\n\nAbbildungÂ 11.15: ?(caption)\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable Ã¼bersehen haben? (S. nÃ¤chster Abschnitt ğŸ‘»)"
  },
  {
    "objectID": "kausal.html#vertiefung",
    "href": "kausal.html#vertiefung",
    "title": "11Â  Kausalinferenz",
    "section": "11.9 Vertiefung",
    "text": "11.9 Vertiefung\nğŸï¸VERTIEFUNGğŸï¸\n\n11.9.1 Der Gespenster-DAG\nğŸ‘»\nEs gibt â€œunheilbareâ€ DAGs, nennen wir sie â€œGespenster-DAGsâ€, in denen es nicht mÃ¶glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. AbbildungÂ 11.16. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: â€œDeine Theorie ist nicht gut, zurÃ¼ck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.â€\n\n\n\n\n\nAbbildungÂ 11.16: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollstÃ¤ndig) mÃ¶glich.\n\n\n\n\n\nU kÃ¶nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft.\nDie GroÃŸeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\nE ist sowohl fÃ¼r G als auch fÃ¼r U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\n\nDie Sache ist in diesem Fall chancenlos. Wir mÃ¼ssen diesen DAG verloren geben, McElreath (2020), S. 180."
  },
  {
    "objectID": "kausal.html#die-hintertÃ¼r-schlieÃŸen",
    "href": "kausal.html#die-hintertÃ¼r-schlieÃŸen",
    "title": "11Â  Kausalinferenz",
    "section": "11.10 Die HintertÃ¼r schlieÃŸen",
    "text": "11.10 Die HintertÃ¼r schlieÃŸen\n\n11.10.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groÃŸ ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in AbbildungÂ 11.17 dargestellt.\n\n\n\n\n\nAbbildungÂ 11.17: Der Preis wird sowohl von der Zimmerzahl als auch der WohnflÃ¤che beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund fÃ¼r die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\rightarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. GÃ¤be es nur nur den zweiten Pfad und wir wÃ¼rden b Ã¤ndern, so wÃ¼rde sich p nicht Ã¤ndern.\n\n\n11.10.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildungÂ 11.18 zeigt eine erfreuliche Situation: Die â€œHintertÃ¼râ€ zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die HintertÃ¼r geschlossen - fÃ¼hren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\nAbbildungÂ 11.18: Unverzerrte SchÃ¤tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere PrÃ¤diktor im Modell enthalten ist. Da die beiden PrÃ¤diktoren unkorreliert sind, hat die Aufnahme des einen PrÃ¤diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie â€œHintertÃ¼râ€ der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berÃ¼hmte LÃ¶sung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment. Wenn wir den HÃ¤usern zufÃ¤llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen kÃ¶nnten (unabhÃ¤ngig von ihrer Quadratmeterzahl, a), wÃ¼rde sich der Graph so Ã¤ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\rightarrow a \\rightarrow p\\) geschlossen (â€œblockiertâ€).\n\n\n11.10.3 HintertÃ¼r schlieÃŸen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die HintertÃ¼r schlieÃŸen (backdoor criterion).\nWir wollen die HintertÃ¼re schlieÃŸen, da wir sonst nicht den wahren, kausalen Effekt bestimmen kÃ¶nnen.\nZum GlÃ¼ck gibt es neben Experimenten noch andere Wege, die HintertÃ¼r zu schlieÃŸen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis Ã¼ber b kein zusÃ¤tzliches Wissen Ã¼ber p. Wissen Sie hingegen nichts Ã¼ber a, lernen Sie bei Kenntnis von b auch etwas Ã¼ber p. Konditionieren ist wie â€œgegeben, dass Sie a schon kennenâ€¦â€.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)\n\n\n11.10.4 Die vier Atome der Kausalanalyse\nAbbildungÂ 11.19 stellt die vier â€œAtomeâ€ der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so kÃ¶nnen Sie jedes beliebige Kausalsystem (DAG) entschlÃ¼sseln.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.19: Die vier Atome der Kausalinferenz\n\n\n\n\n\n\n11.10.5 Mediation\nDie Mediation (Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation, auch â€œKetteâ€ oder â€œWirkketteâ€ genannt, ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. AbbildungÂ 11.20. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y â€œvermitteltâ€ oder Ã¼betrÃ¤gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\nAbbildungÂ 11.20: Das Kausalmodell der Mediation.\n\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation â€œflieÃŸtâ€ den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlieÃŸt) die Kette (genau wie bei der Gabel)."
  },
  {
    "objectID": "kausal.html#der-nachfahre",
    "href": "kausal.html#der-nachfahre",
    "title": "11Â  Kausalinferenz",
    "section": "11.11 Der Nachfahre",
    "text": "11.11 Der Nachfahre\nEin Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. fig-dag-nachfahre. Kontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet Ã¼ber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise Ã¶ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\nAbbildungÂ 11.21: Ein Nachfahre verhÃ¤lt sich Ã¤hnlich wie sein Vorfahreâ€¦\n\n\n\n\n\n11.11.1 Kochrezept zur Analyse von DAGs\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geÃ¶ffnet ist.\nBeurteilen Sie fÃ¼r jeden Pfad, ob er ein HintertÃ¼rpfad ist (HintertÃ¼rpfade haben einen Pfeil, der zur UV fÃ¼hrt).\nWenn es geÃ¶ffnete Hinterpfade gibt, prÃ¼fen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlieÃŸen (falls mÃ¶glich)."
  },
  {
    "objectID": "kausal.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich-bsp1",
    "href": "kausal.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich-bsp1",
    "title": "11Â  Kausalinferenz",
    "section": "11.12 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp1",
    "text": "11.12 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp1\nUV: \\(X\\), AV: \\(Y\\), drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\nAbbildungÂ 11.22: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei HintertÃ¼rpfade in AbbildungÂ 11.22:\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlieÃŸt die offene HintertÃ¼r.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n11.12.1 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp2\nS. DAG in AbbildungÂ 11.23: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\nAbbildungÂ 11.23: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen HintertÃ¼ren zu schlieÃŸen:\n\nentweder \\(A\\) und \\(M\\)\noder \\(S\\)\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), â€šS. 188.\n\n\n11.12.2 Implizierte bedingte UnabhÃ¤ngigkeiten von bsp2\nEin Graph ohne Us ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme. Auch wenn die Daten nicht sagen kÃ¶nnen, welcher DAG der richtige ist, kÃ¶nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten UnabhÃ¤ngigkeiten geben uns MÃ¶glichkeiten, zu prÃ¼fen, ob wir einen DAG verwerfen (ausschlieÃŸen) kÃ¶nnen. Bedingten UnabhÃ¤ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhÃ¤ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte UnabhÃ¤ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S\n\n\n\n11.12.3 Fazit\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren kÃ¶nnen, hÃ¤ngt von der epistemologischen Zielrichting der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen kÃ¶nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. â€œDer Unterschied zwischen beiden Gruppen betrÃ¤gt etwa â€¦â€. Allerdings ist eine kausale Interpretation nicht zulÃ¤ssig.\nBei prognostischen Fragestellungen spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht mÃ¶glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dÃ¼rfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten Ã¤ndern sich (oft), wenn man PrÃ¤diktoren zum Modell hinzufÃ¼gt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, mÃ¶glichst viele PrÃ¤diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der â€œkausalen Atomeâ€ ist Voraussetzung zur Ableitung von KausalschlÃ¼sse in Beobachtungsstudien.\n\n\n\n\nKurz, A. Solomon. 2021. Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition. https://bookdown.org/content/4857/.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. â€Chocolate Consumption, Cognitive Function, and Nobel Laureatesâ€œ. New England Journal of Medicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal inference in statistics: a primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629."
  },
  {
    "objectID": "abschluss.html",
    "href": "abschluss.html",
    "title": "12Â  Abschluss",
    "section": "",
    "text": "Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische â€œLieblingsfehlerâ€ benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik Ã¼bersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n\n\n\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)"
  },
  {
    "objectID": "abschluss.html#lieblinglingsfehler",
    "href": "abschluss.html#lieblinglingsfehler",
    "title": "12Â  Abschluss",
    "section": "12.2 Lieblinglingsfehler",
    "text": "12.2 Lieblinglingsfehler\nLieblingsfehler im Ãœberblick ğŸ¤·:\n\nPost-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrÃ¤diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt"
  },
  {
    "objectID": "abschluss.html#post-prÃ¤d-verteilung-ppv-und-post-verteilung-verwechseln",
    "href": "abschluss.html#post-prÃ¤d-verteilung-ppv-und-post-verteilung-verwechseln",
    "title": "12Â  Abschluss",
    "section": "12.3 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·",
    "text": "12.3 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·\nBerechen wir das Standard-mtcars-Modell: mpg ~ hp.\n\n\nCode\nm1 <- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten.\n\n\nCode\npost_verteilung <- m1 %>% \n  as_tibble()\nhead(post_verteilung)\n\n\n\n\n\n\n(Intercept)\nhp\nsigma\n\n\n\n\n27.99734\n-0.0625998\n4.004573\n\n\n28.41831\n-0.0648228\n4.248156\n\n\n32.35498\n-0.0766825\n3.539327\n\n\n26.64150\n-0.0527664\n4.268596\n\n\n27.85701\n-0.0622692\n4.176046\n\n\n28.17933\n-0.0638320\n4.115600\n\n\n\n\n\n\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n\n\n\nname\nvalue\n\n\n\n\nMazda RX4\n25.65092\n\n\nMazda RX4 Wag\n21.33374\n\n\nDatsun 710\n16.10424\n\n\nHornet 4 Drive\n17.52942\n\n\nHornet Sportabout\n11.22213"
  },
  {
    "objectID": "abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "href": "abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "title": "12Â  Abschluss",
    "section": "12.4 Quantile und Verteilungsfuntion verwechseln ğŸ¤·",
    "text": "12.4 Quantile und Verteilungsfuntion verwechseln ğŸ¤·\n\n12.4.1 Quantil fÃ¼r \\(p\\)\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind.\n\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betrÃ¤gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist grÃ¶ÃŸer oder gleich dem \\(p\\)-Quantil.\n\n\n12.4.2 Verteilungsfunktion \\(F\\)\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt.\n\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betrÃ¤gt hier 50%, dass \\(x\\) nicht grÃ¶ÃŸer ist als 0."
  },
  {
    "objectID": "abschluss.html#interaktion-falsch-interpretieren",
    "href": "abschluss.html#interaktion-falsch-interpretieren",
    "title": "12Â  Abschluss",
    "section": "12.5 Interaktion falsch interpretieren ğŸ¤·",
    "text": "12.5 Interaktion falsch interpretieren ğŸ¤·\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kÃ¼rzer als) mpg ~ hp + vs + hp:vs.\n\n\n\n\nCode\nm2 <- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten:\n\n\nCode\nparameters(m2)\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n24.64\n(18.96, 30.09)\n100%\n1.001\n2384.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.75%\n1.001\n2367.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.98\n(4.80, 23.02)\n99.90%\n1.000\n1654.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.19, -0.03)\n99.50%\n1.000\n1781.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\nCode\nplot(parameters(m2))\n\n\n\n\n\nFalsch ğŸ˜ˆ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11.\nRichtig ğŸ‘¼ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11 â€“ wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte PrÃ¤diktoren wÃ¤ren hier eine sinnvolle LÃ¶sung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8"
  },
  {
    "objectID": "abschluss.html#kochrezepte",
    "href": "abschluss.html#kochrezepte",
    "title": "12Â  Abschluss",
    "section": "12.6 Kochrezepte ğŸ²",
    "text": "12.6 Kochrezepte ğŸ²\n\n12.6.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen Ã¼ber ein PhÃ¤nomen, \\(y\\), Kausalfrage finden 2. Literatur wÃ¤lzen, um mÃ¶gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese prÃ¤zisieren 4. Modell prÃ¤zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prÃ¼fen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n\n12.6.2 Parameter schÃ¤tzen vs.Â Hypothesen prÃ¼fen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schÃ¤tzen. Beispiel HypothesenprÃ¼fung: â€œFrauen parken im Durchschnitt schneller ein als MÃ¤nnerâ€. Beispiel ParameterschÃ¤tzung: â€œWie groÃŸ ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und MÃ¤nnern?â€\nJe ausgereifter ein Forschungsfeld, desto kÃ¼hnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nÃ¤chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nÃ¤chste Sonnenfinsternis wird in den nÃ¤chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen fÃ¼r den Klausurerfolg. KÃ¼hne Hypothesen sind wÃ¼nschenswert ğŸ¦¹\n\n\n12.6.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist hÃ¶her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist grÃ¶ÃŸer als Null):\n\\[\\mu_1 > \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 > 0 \\Leftrightarrow \\mu_d > 0\\]"
  },
  {
    "objectID": "abschluss.html#kerngedanken-bayes",
    "href": "abschluss.html#kerngedanken-bayes",
    "title": "12Â  Abschluss",
    "section": "12.7 Kerngedanken Bayes",
    "text": "12.7 Kerngedanken Bayes\n\n12.7.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\n\nCode\nm3 <- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI:\n\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist mÃ¶glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind mÃ¶glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings Ã¼bermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n\n12.7.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]"
  },
  {
    "objectID": "abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "href": "abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "title": "12Â  Abschluss",
    "section": "12.8 Beispiele fÃ¼r PrÃ¼fungsaufgaben",
    "text": "12.8 Beispiele fÃ¼r PrÃ¼fungsaufgaben\n\n12.8.1 Geben Sie den korrekten Begriff an!\nğŸŒ¬ğŸš™ğŸ™‹ï¸ğŸ‘¨â¬…ï¸Hans ğŸ‘§â¬…ï¸Anna ğŸ‘©â¬…ï¸Lise\nPuh, wie erstelle ich fÃ¼r alle Studis ein anderes RÃ¤tsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-PrÃ¼fung bekommen alle Studentis eine eigene, jeweils andere PrÃ¼fung. Teamarbeit bleibt natÃ¼rlich trotzdem untersagt.\n\n\n\n\n12.8.2 DAG mit doppelter Konfundierung\n\n\n\n\n\nâ“Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\nâ— Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\n\n\n12.8.3 DAG mit vielen Variablen\n\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\n\n\n12.8.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nKampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\n\n\n12.8.5 DAG von van Kampen (2014) zu den Symptomen der Schizophrenie\n\n\n\n\n\nMinimales Adjustment-Set fÃ¼r den totalen Kausaleffekt: {AIS, ALN}\n\n\n12.8.6 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrÃ¼fungsfragen zu Modellen kÃ¶nnten z.B. sein:\n\nGeben Sie den PunktschÃ¤tzer (Median) fÃ¼r den PrÃ¤diktor X im Modell Y an!\nGeben Sie ein 89%-HDI fÃ¼r den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris â€¦\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI fÃ¼r den PrÃ¤diktor X im Modell Y?\nWas verÃ¤ndert sich an den Parametern, wenn Sie die PrÃ¤diktoren zentrieren/z-standardisieren?\nâ€¦"
  },
  {
    "objectID": "abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "href": "abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "title": "12Â  Abschluss",
    "section": "12.9 Viel Erfolg bei der PrÃ¼fung!",
    "text": "12.9 Viel Erfolg bei der PrÃ¼fung!\nğŸ¥³ğŸ†\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. â€The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphsâ€œ. European Psychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer\nGabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja,\nSitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and\nDaniel M. Croymans. 2021. â€œBehavioural Nudges Increase\nCOVID-19 Vaccinations.â€ Nature 597 (7876):\n404â€“9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\nâ€œR-Squared for Bayesian Regression Models.â€ The\nAmerican Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022.\nâ€œRstanarm: Bayesian Applied Regression Modeling via\nStan.â€ https://mc-stan.org/rstanarm/.\n\n\nKampen, D. van. 2014. â€œThe SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal Chains Based on\nthe Language of Directed Graphs.â€ European Psychiatry 29\n(7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter Values\nin Bayesian Estimation.â€ Advances in Methods and Practices in\nPsychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel LÃ¼decke. 2019. â€œIndices of Effect Existence and\nSignificance in the Bayesian Framework.â€ Frontiers in\nPsychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. 2nd ed. CRC Texts in\nStatistical Science. Boca Raton: Taylor; Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. â€œChocolate Consumption, Cognitive\nFunction, and Nobel Laureates.â€ New England Journal of\nMedicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B.\nGubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021.\nâ€œEffectiveness of mRNA and\nChAdOx1 COVID-19 Vaccines Against Symptomatic\nSARS-CoV-2 Infection and Severe Outcomes with\nVariants of Concern in Ontario.â€ https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi,\nMohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner.\n2021. â€œEfficacy and Safety of COVID-19 Vaccines: A\nSystematic Review and Meta-Analysis of Randomized Clinical\nTrials.â€ Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nRohrer, Julia M. 2018. â€œThinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational Data.â€\nAdvances in Methods and Practices in Psychological Science 1\n(1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball,\nAllison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021.\nâ€œEffectiveness of Covid-19 Vaccines in Ambulatory and Inpatient\nCare Settings.â€ New England Journal of Medicine 385\n(15): 1355â€“71. https://doi.org/10.1056/NEJMoa2110362."
  }
]