[
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können…\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme übersetzen\ntypische Forschungsfragen auswerten\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman, Hill, und Vehtari (2021), Kap. 7 und 10.\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. “Geradenmodelle 2”\n\n9.1.5 R-Pakete\nIn diesem Kapite lwerden folgende R-Pakete benötigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.6 Benötigte Daten\nWir benötigen in diesem Kapitel folgende Datensätz: kidiq, penguins.\n\n9.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\ndata(\"kidiq\", package = \"rstanarm\")\n\nAlternativ können Sie die Daten hier herunterladen.\n Download \n\n9.1.6.2 penguins\n\nSie können den Datensatz penguins entweder via dem Pfad importieren:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n Download \nOder via dem zugehörigen R-Paket:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nBeide Möglichkeit sind okay.\n\n9.1.7 Einstieg\n\nBeispiel 9.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, müssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 9.2 (Was war noch einmal die Interaktion?) Erkären Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n9.1.8 Überblick\nWenn Sie die Skalenniveaus wissen, können Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und ähnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, …) lernen müssen. Außerdem ist die Regressionsanalyse (für viele Situationen) die beste Heransgehensweise, da sie viele Möglichkeiten für Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels gängige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. Natürlich würzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-Küche. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#lernsteuerung",
    "href": "1150-konfundierung.html#lernsteuerung",
    "title": "10  Konfundierung",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 R-Pakete\nFür dieses Kapitel benötigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n10.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. Tabelle 10.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie können ihn entweder über die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber über das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kürzerer Name, das ist leichter zu tippen\n\n\n10.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerklären, was eine Konfundierung ist\nDAGs lesen und zeichen\nKonfundierung in einem DAG erkennen\n\n10.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ähnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).\n\n10.1.6 Überblick\nIn diesem Kapitel steigen wir ein in das Themengebiet Kausalanalyse (oder synonym Kausalinferenz). Wir beschäftigen uns also mit der für die Wissenschaft (und den Rest des Universums) zentralen Frage, was die Ursache eines Phänomens ist. In diesem ersten Kapitel zu dem Thema geht es um einen häufigen Fall von “Scheinkorrelation”, also eines Zusammenhangs zwischen UV und AV, der aber gar kein echter kausaler ist, sondern nur Schein. Bei diesem Scheinzusammenhang handelt es sich um die Konfundierung. Im nächsten Kapitel schauen wir uns die verbleibenden Grundbausteine der Kausalinferenz an.\n\n10.1.7 Einstieg\n\n10.1.8 Von Störchen und Babies\nKennen Sie die Geschichte von Störchen und Babies? Ich meine nicht die aus dem Biologieunterricht in der fünften Klasse, sondern in einem statistischen Zusammenhang. Was war da noch mal die Moral von der Geschichte?1 \\(\\square\\)\n\n10.1.9 Erlaubt eine Regressionsanalyse Kausalschlüsse?\nFindet man in einer Regressionsanalyse einen “Effekt”, also ein Regressionsgewicht ungleich Null, heißt das dann, dass die UV die Ursache der AV ist?2 Erklären Sie diesen Sachverhalt genauer. \\(\\square\\)",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "href": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "title": "10  Konfundierung",
    "section": "\n10.2 Statistik, was soll ich tun?",
    "text": "10.2 Statistik, was soll ich tun?\n\n10.2.1 Studie A: Östrogen\n\n10.2.1.1 Medikament einnehmen?\nMit Blick auf Tabelle 10.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelle 10.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMänner\n81/87 überlebt (93%)\n234/270 überlebt (87%)\n\n\nFrauen\n192/263 überlebt (73%)\n55/80 überlebt (69%)\n\n\nGesamt\n273/350 überlebt (78%)\n289/350 überlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualität (Beobachtungsstudie). Bei Männern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und Männern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n10.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Östrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Östrogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in Abbildung 10.1 dargestellt.\n\n\n\n\n\n\n\nAbbildung 10.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender über drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige Lösung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder “Schichten” (“Strata”)\n\n\n\n10.2.2 Studie B: Blutdruck\n\n10.2.2.1 Medikament einnehmen?\nMit Blick auf Tabelle 10.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelle 10.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 überlebt (93%)\n234/270 überlebt (87%)\n\n\nhoher Blutdruck\n192/263 überlebt (73%)\n55/80 überlebt (69%)\n\n\nGesamt\n273/350 überlebt (78%)\n289/350 überlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualität (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe über beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? Pearl, Glymour, und Jewell (2016)\n\n10.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schädlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in Abbildung 10.2 dargestellt.\n\n\n\n\n\n\n\nAbbildung 10.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schädlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nützlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wäre falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wäre.\n\n\n\n10.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs Abbildung 10.1 und Abbildung 10.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen für Handlungen - war nur möglich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n10.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht für Kausalschlüsse. 🧟\nStatistik plus Theorie erlaubt Kausalschlüsse. 📚➕📊 🟰 🤩\n\n\n\n\n\n\nWichtig\n\n\n\nFür Entscheidungen (“Was soll ich tun?”) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n10.2.5 Vertiefung3\n\n\n10.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ärzte tendieren zu Behandlung A bei großen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ärzte zu Behandlung B.\nSollte ein Patient, der nicht weiß, ob sein Nierenstein groß oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach Steingröße) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wählt?\nDie Größe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (“Kette”) von Größe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. Darüber hinaus gibt es noch einen Einfluss von Größe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in Abbildung 10.3 dargestellt; Abbildung 10.4 visualisiert alternativ.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schätzen möchte? Oder lieber nicht kontrollieren?\n\n\n\n\n\n\n\nAbbildung 10.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 10.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. Würde man nicht size kontrollieren, bekäme man den “vermengten” Effekt von size und treatment, also keine (belastbare) Aussage über den Effekt der Behandlung.\n\n10.2.5.2 Mehr Beispiele\n\nBeispiel 10.1 Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhöhen, wenn du heiratest. \\(\\square\\)\n\n\nBeispiel 10.2 Studien zeigen, dass Leute, die sich beeilen, zu spät zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spät zu deiner Besprechung. \\(\\square\\)\n\n\n10.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zusätzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht nötig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafür, dass es keine Konfundierung gibt.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#konfundierung",
    "href": "1150-konfundierung.html#konfundierung",
    "title": "10  Konfundierung",
    "section": "\n10.3 Konfundierung",
    "text": "10.3 Konfundierung\n\n10.3.1 Datensatz ‘Hauspreise im Saratoga County’\n📺 Don und Angie\nImportieren Sie den Datensatz SaratogaHouses, s. Kapitel 10.1.3.\n\n\n\nTabelle 10.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n10.3.2 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\n“Finden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!”\n\n🧑 Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\n👩 🔬 Das ist Angie, Data Scientistin.\n\n10.3.3 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\n“Hey Don! Mehr Zimmer, mehr Kohle!” 👩 🔬\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. Abbildung 10.5.\n\n\n\n\n\n\n\nAbbildung 10.5: Modell m1\n\n\n\n\n\n“Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.”\n\n👩\n\nZu wenig! 🤬\n\n🧑\nBerechnen wir das Modell m1; der Punktschätzer des Parameters bedroom steht in Tabelle 10.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\nTabelle 10.4: Parameter für m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die Punktschätzer der Parameter eines Modells zurück, aber nicht die Schätzbereiche. Möchten Sie beides, können Sie die Funktion parameters(modell) nutzen.4\nMit estimate_predictions können wir Vorhersagen berechnen (bzw. schätzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist “schätzen” vielleicht das treffendere Wort). Tabelle 10.5 zeigt den laut m1 vorhergesagten Hauspreis für ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\nTabelle 10.5: Vorhersage des Hauspreises für ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.55e+05\n92273.66\n(-20256.77, 3.34e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n10.3.4 Don hat eine Idee\n\n“Ich bau eine Mauer! Genial! An die Arbeit, Angie!” 🧑\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\n“Das ist keine gute Idee, Don.”\n\n👩\nBerechnen wir die Vorhersagen für Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. Tabelle 10.6.5\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\nTabelle 10.6: Vorhergesagter Hauspreis laut m1 für ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n91169.55\n(71537.64, 4.26e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, s. Abbildung 10.5.\n\n“Volltreffer! Jetzt verdien ich 100 Tausend mehr! 🤑 Ich bin der Größte!” 🧑\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: “4e+05” ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n10.3.5 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berücksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im “Strukturmodell”: Wenn also z.B. in unserem Modell ein wichtiger Prädiktor fehlt, so kann die Vorhersagen nicht präzise sein. Fehler im Strukturmodell schlagen sich in breiten Schätzintervallen (bedingt durch ein großes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berücksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\n\nDie Schätzbereiche sind in dem Fall deutlich kleiner, s. Tabelle 10.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\n\nTabelle 10.7: Model-based Expectation\n\n\n\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3104.98\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\nUngewissheit für die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\n\n\n\n10.3.6 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. Tabelle 10.8 gibt den Punktschätzer für die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\nTabelle 10.8: Parameter (Punktschätzer, keine Schätzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36311.05\n\n\nbedrooms\n-14077.64\n\n\nlivingArea\n125.32\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? Tabelle 10.9 gibt Aufschluss für den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 Quadratfuß Wohnfläche; Tabelle 10.10 gibt die Schätzung (laut m2) für den Preis eines Hauses mit 2 Zimmern (und der gleichen Wohnfläche). Die Vorhersage erhält man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130423.8\n\n\n\n\nTabelle 10.9: Vorhersage von m2 für ein Haus mit 4 Zimmern und 1200 Einheiten Wohnfläche\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelle 10.10: Vorhersage von m2 für ein Haus mit 2 Zimmern und 1200 Einheiten Wohnfläche\n\n\n\n  \n\n\n\n\n\n\nAndere, aber ähnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt über die verschiedenen Größen von livingArea? Stellen Sie sich alle Häuser mit 4 Zimmern vor (also mit verschiedenen Wohnflächen). Wir möchten nur wissen, was so ein Haus “im Mittel” kostet. Wir möchten also die Mittelwerte pro bedroom schätzen, gemittelt für jeden Wert von bedroom über livingArea. Die Ergebnisse stehen in Tabelle 10.11 und sind in Abbildung 10.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelle 10.11: Vorhersagen des Preises von Häusern mit verschiedener Zimmerzahl gemittelt über die verschiedenen Werte der Wohnfläche; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 10.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\n“Die Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!”\n\n👩\n\n“Verringert!? Weniger Geld?! Oh nein!”\n\n🧑\n\n10.3.7 Die Zimmerzahl ist negativ mit dem Preis korreliert\n… wenn man die Wohnfläche (Quadratmeter) kontrolliert, s. Abbildung 10.7.\n\n“Ne-Ga-Tiv!”\n\n👩\n\n\n\n\n\nAbbildung 10.7: Hauspreis stratifizieren\n\n\nQuellcode\n\n\n\n\n\n\nHinweis\n\n\n\nAussagen, gleich ob sie statistischer, wissenshaftlicher oder sonstiger Couleur sind, können immer nur dann richtig sein, wenn ihre Annahmen richtig sind. Behauptet etwa ein Modell, dass der Wert einer Immobilie steigt, wenn man mehr Zimmer hat, so ist das kein Naturgesetz, sondern eine Aussage, die nur richtig sein kann, wenn das zugrundeliegende Modell richtig ist. \\(\\square\\)\n\n\n\n10.3.8 Kontrollieren von Variablen\n💡 Durch das Aufnehmen von Prädiktoren in die multiple Regression werden die Prädiktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen Prädiktors mit \\(y\\), wenn man den (oder die) anderen Prädiktoren statistisch konstant hält.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom “Netto-Effekt” eines Prädiktors, oder davon, dass ein Prädiktor “bereinigt” wurde vom (linearen) Einfluss der anderen Prädiktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Prädiktors \\(x_1\\) auf \\(y\\) anzeigen unabhängig vom Effekt der anderen Prädiktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Prädiktors \\(x_1\\) wird für jede Ausprägung (Gruppe) des Prädiktors \\(x_2\\) berechnet.\n\n\n\n\n\n\nWichtig\n\n\n\nDas Hinzufügen von Prädiktoren kann die Gewichte der übrigen Prädiktoren ändern. \\(\\square\\)\n\n\n\nAber welche und wie viele Prädiktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\n🧑\n\nLeider kann die Statistik keine Antwort darauf geben.\n\n👩\n\nWozu ist sie dann gut?!\n\n🧑\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erklärung der Ursachen heranzuziehen: Die Regressionskoeffizienten können sich wild ändern, wenn man Prädiktoren hinzufügt oder weglässt. Es können sich sogar die Vorzeichen der Regressionsgewichte ändern; in dem Fall spricht man von einem Simpson-Paradox.\n\n\n\n10.3.9 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, we’d like to know wheter an effect is “real” or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical “tests” on its way to acceptance.\n\n– McElreath (2020), S. 139\n\n10.3.10 Kausalmodell für Konfundierung, km1\n\nDas Kausalmodell km1 ist in Abbildung 10.8 dargestellt; vgl. Abbildung 10.7.\n\n\n\n\n\n\n\nAbbildung 10.8: Kausalmodell km1 - Eine Erklärung (von mehreren) für m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms. Eine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht. d_connected heißt, dass die betreffenden Variablen “verbunden” sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss fließt 🌊. d_separated heißt, dass sie nicht d_connected sind.\n\n10.3.11 m2 kontrolliert die Konfundierungsvariable livingArea\n\n\nBeispiel 10.3 In Abbildung 10.8 ist living area eine Konfundierungsvariable für den Zusammenhang von bedrooms und price. \\(\\square\\)\n\n\nDefinition 10.1 (Konfundierungsvariable) Eine Konfundierungsvariable (Konfundierer) ist eine Variable, die den Zusammenhang zwischen UV und AV verzerrt, wenn sie nicht kontrolliert wird (VanderWeele und Shpitser 2013). \\(\\square\\)\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloß?! Oh jeh!\n\n🧑\n\nWir müssen die Konfundierungsvariable kontrollieren.\n\n👩\nAbbildung 10.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildung 10.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (“adjustieren”), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separated.\n\nDefinition 10.2 (Blockieren) Das Kontrollieren eines Konfundierers (wie living_area) “blockt” den betreffenden Pfad, führt also dazu, dass über diesen Pfad keine Assoziation (z.B. Korrelation) zwischwen UV (bedrooms) und AV (price) mehr vorhanden ist. UV und AV sind dann d_separated (“getrennt”). \\(\\square\\)\n\n\n10.3.12 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, Abbildung 10.10, links: Es wird (fälschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, Abbildung 10.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildung 10.10: Konfundierung von y und x!\n\n\nAbbildung 10.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. Außerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als Prädiktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\nWichtig\n\n\n\nKontrollieren Sie Konfundierer. \\(\\square\\)\n\n\n\n10.3.13 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 dürfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in Abbildung 10.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n10.3.14 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide Prädiktoren jeweils einen eigenen Beitrag zur Erklärung der AV haben.\nDaher könnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei Kausaleinflüsse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) über den Mediator (b) zur AV (p) auch Mediation, s. Abbildung 10.11.\n\n\n\n\n\n\n\nAbbildung 10.11: Der Effekt von livingArea wird über den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n10.3.15 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. Abbildung 10.12.\n\n\n\n\n\n\n\nAbbildung 10.12: Dons Kausalmodell\n\n\n\n\n\n“Ich glaube aber an mein Kausalmodell. Mein Kausalmodell ist das größte! Alle anderen Kausalmodelle sind ein Disaster!”\n\n🧑\n\n\n“Don, nach deinem Kausalmodell müssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.”\n\n🧑\nRechne doch selber die Korrelation aus, Don:\n\n“Äh, wie ging das nochmal?”\n\n🧑\nSo könntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\n“Bitte, gerne hab ich dir geholfen, Don.”\n\n👩\n\n10.3.16 Unabhängigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. Abbildung 10.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhängig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zusätzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete Unabhängigkeit findet sich nicht in den Daten wieder, s. Tabelle 10.8. Also: ⛈️ Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. Abbildung 10.11.\nDas Kausalmodell km2 postuliert keine Unabhängigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 beträgt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so ähnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. 🥱\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. Abbildung 10.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhängig von livingArea (a)\n⛈️ km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "href": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "title": "10  Konfundierung",
    "section": "\n10.4 DAGs: Directed Acyclic Graphs",
    "text": "10.4 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B. Abbildung 10.12.\n\nDefinition 10.3 (DAG) DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen. Ein Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden. DAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung). DAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurückführen. \\(\\square\\)\n\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten über die Kanten, unabhängig von der Pfeilrichtung.\nDer DAG von km1 ist in Abbildung 10.8 zu sehen.\n\n10.4.1 Leider passen potenziell viele DAGs zu einer Datenlage\nb: bedrooms, p: price, a area (living area)\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach wäre, die Kausalstruktur der Phänomene zu entdecken, wären sie längst erkannt, und alle Probleme der Menschheit gelöst.\nIn Abbildung 10.13 sind mögliche Kausalmodelle für Dons Studie dargestellt.\n\n\n\n\n\n\n\nAbbildung 10.13: Kausalmodelle, die potenziell geeignet sind für Dons Fragestellung\n\n\n\n\nAlle diese DAgs in Abbildung 10.8 haben die gleichen Implikationen hinsichtlich der (Un-)Abhängigkeiten zwischen der Variablen. Wir können also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, bräuchten wir z.B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n10.4.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als “Kausation” bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiß man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\nViele Menschen denken - fälschlich - dass Korrelation Kausation bedeuten muss, s. Abbildung 10.14.\n\n\n\n\n\n\n\nAbbildung 10.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und Erklärung\nDer “Schoki-DAG” in Abbildung 10.15 zeigt den DAG für das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\n\n\n\nAbbildung 10.15: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#fazit",
    "href": "1150-konfundierung.html#fazit",
    "title": "10  Konfundierung",
    "section": "\n10.5 Fazit",
    "text": "10.5 Fazit\n\n10.5.1 Zusammenfassung\nSind zwei Variablen korreliert (abhängig, assoziiert), so kann es dafür zwei Gründe geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (“Scheinkorrelation”)\n\nEine mögliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Prädiktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so löst sich der Scheinzusammenhang nach dem Adjustieren auf.\nLöst sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenhänge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine können nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nötig, um DAGs auszuschließen.\n\n10.5.2 Ausstieg\n\nBeispiel 10.4 (Schoki macht Nobelpreis!?) Eine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen der Höhe des Schokoladenkonsums eines Landes und der Anzahl der Nobelpreise eines Landes (Messerli 2012), s. Abbildung 10.16.\n\n\n\n\n\n\n\nAbbildung 10.16: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle überprüfen, so wie wir das hier tun.\n\n\n\n\n10.5.3 Vertiefung\nEs gibt viel Literatur zu dem Thema Kausalinferenz. Ein Artikel, der einen vertieften Einblick in das Thema Konfundierung liefert z.B. Tennant u. a. (2020) oder Suttorp u. a. (2015). Allerdings sollte man neben Konfundierung noch die drei anderen “Atome” der Kausalinferenz - Kollision, Mediation (und Nachfahre) - kennen, um gängige Fragen der Kausalinferenz bearbeiten zu können.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#aufgaben",
    "href": "1150-konfundierung.html#aufgaben",
    "title": "10  Konfundierung",
    "section": "\n10.6 Aufgaben",
    "text": "10.6 Aufgaben\n\nSammlung “kausal”",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#section",
    "href": "1150-konfundierung.html#section",
    "title": "10  Konfundierung",
    "section": "\n10.7 —",
    "text": "10.7 —\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. „Chocolate Consumption, Cognitive Function, and Nobel Laureates“. New England Journal of Medicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. „Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data“. Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n\n\nSuttorp, Marit M., Bob Siegerink, Kitty J. Jager, Carmine Zoccali, und Friedo W. Dekker. 2015. „Graphical Presentation of Confounding in Directed Acyclic Graphs“. Nephrology Dialysis Transplantation 30 (9): 1418–23. https://doi.org/10.1093/ndt/gfu325.\n\n\nTennant, Peter W G, Eleanor J Murray, Kellyn F Arnold, Laurie Berrie, Matthew P Fox, Sarah C Gadd, Wendy J Harrison, u. a. 2020. „Use of Directed Acyclic Graphs (DAGs) to Identify Confounders in Applied Health Research: Review and Recommendations“. International Journal of Epidemiology 50 (2): 620–32. https://doi.org/10.1093/ije/dyaa213.\n\n\nVanderWeele, Tyler J., und Ilya Shpitser. 2013. „On the Definition of a Confounder“. Annals of statistics 41 (1): 196–220. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#lernsteuerung",
    "href": "1180-kausalatome.html#lernsteuerung",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 R-Pakete\nFür dieses Kapitel benötigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n11.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. Tabelle 10.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie können ihn entweder über die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber über das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kürzerer Name, das ist leichter zu tippen\n\n\n11.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerklären, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\nerklären, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\ndie “Atome” der Kausalität eines DAGs benennen\n“kausale Hintertüren” schließen\n\n11.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ähnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#kollision",
    "href": "1180-kausalatome.html#kollision",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.2 Kollision",
    "text": "11.2 Kollision\n📺 Kollision\n\n11.2.1 Kein Zusammenhang von Intelligenz und Schönheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und Schönheit (looks), wie Abbildung 11.1 illustriert. Für geringe Intelligenzwerte gibt es eine breites Spektrum von Schönheitswerten und für hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildung 11.1: Kein Zusammenhang von Intelligenz und Schönheit in den Daten\n\n\n\n\n\n11.2.2 Aber Ihre Dates sind entweder schlau oder schön\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schön sind oder schlau - aber seltens beides gleichzeitig (schade), s. Abbildung 11.2.\n\n\n\n\n\n\n\nAbbildung 11.2: Ihre Datingpartner sind komischerweise entweder schlau oder schön (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?\n\n11.2.3 DAG zur Rettung\n🦹 🦸\nDer DAG in Abbildung 11.3 bietet eine rettende Erklärung.\n\n\n\n\n\n\n\nAbbildung 11.3: Date als gemeinsame Wirkung von Schönheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Schönheit und Intelligenz.\n\n\n\n\nEine ähnliche Visualisierung des gleichen Sachverhalts zeigt Abbildung 11.4.\n\n\n\n\n\n\n\nAbbildung 11.4: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n11.2.4 Was ist eine Kollision?\n\nDefinition 11.1 (Kollision) Als Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) [Pearl, Glymour, und Jewell (2016); p. 40]0 \\(\\square\\)\n\n. Kontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. Abbildung 11.3, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche Prädiktoren einer Regression hinzufügen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n\n\n\n\nTipp\n\n\n\n🙅‍♀️ Kontrollieren Sie keine Kollisionsvariablen. \\(\\square\\)\n\n\n\n11.2.5 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchöne Menschen 🪞\nReiche Menschen 🤑\n\nSehen wir davon aus, dass Schönheit und Reichtum unabhängig voneinander sind.\n\nÜbungsaufgabe 11.1 Wenn ich Ihnen sage, dass Don nicht schön ist, aber in der Glitzer häufig auftaucht, was lernen wir dann über seine finanzielle Situation?1 \\(\\square\\)\n\n\n“Ich bin schön, unglaublich schön, und groß, großartig, tolle Gene!!!” 🧑\n\n\n11.2.6 Noch ein einfaches Beispiel zur Kollision\n\n“So langsam check ich’s!” 🧑2\n\nSei Z = X + Y, wobei X und Y unabhängig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts über Y, da die beiden Variablen unabhängig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhängig, gegeben Z: \\(X \\not\\indep Y \\,|\\, Z\\).3\n\n11.2.7 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildung 11.3 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als Prädiktor in eine Regression zusätzlich zu looks mit talent als Prädikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (“Fluss”) von Looks über date nach Talent ist blockiert.\nKontrolliert man date, so öffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr “blockiert”, die Korrelation kann “fließen” - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n11.2.8 IQ, Fleiss und Eignung fürs Studium\nSagen wir, über die Eignung für ein Studium würden nur (die individuellen Ausprägungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in Abbildung 11.5.\n\n\n\n\n\n\n\nAbbildung 11.5: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fürs Studium) sei definiert als die Summe von iq und fleiss, plus etwas Glück:\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\nLaut unserem Modell setzt sich Eignung zur Hälfte aus Intelligenz und zur Hälfte aus Fleiss zusammen, plus etwas Glück.\n\n11.2.9 Schlagzeile “Schlauheit macht Studentis faul!”\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Fleiß (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das “Eignungsmodell”, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. Tabelle 11.1.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\nTabelle 11.1: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildung 11.6 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildung 11.6: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhängig von Fleiß in unseren Daten, sondern abhängig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde über Zusammenhänge auf und interpretieren die Zusammenhänge – oft vorschnell – als kausal.4\n\n11.2.10 Kollisionsverzerrung nur bei Stratifizierung\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. Abbildung 11.7.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildung 11.7: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nützen.\nNur Kenntnis des DAGs verrät die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten Prädiktor auf, so “kontrolliert” man diese Variable. Das Regressiongewicht des ersten Prädiktors wird “bereinigt” um den Einfluss des zweiten Prädiktors; insofern ist der zweite Prädiktor dann “kontrolliert”.\n\n\n\n11.2.11 Einfluss von Großeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und Großeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von Großeltern auf ihre Enkel, s. Abbildung 11.8, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildung 11.8: Der kausale Effekt von Großeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable übersehen haben? (S. nächster Abschnitt). 👻\n\n11.2.12 Der Gespenster-DAG\n👻\nEs gibt “unheilbare” DAGs, nennen wir sie “Gespenster-DAGs”, in denen es nicht möglich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. Abbildung 11.9. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: “Deine Theorie ist nicht gut, zurück an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.”\n\n\n\n\n\n\n\nAbbildung 11.9: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollständig) möglich.\n\n\n\n\n\nU könnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft.\nDie Großeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\nE ist sowohl für G als auch für U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\n\nDie Sache ist in diesem Fall chancenlos. Wir müssen diesen DAG verloren geben, McElreath (2020), S. 180.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-hintertür-schließen",
    "href": "1180-kausalatome.html#die-hintertür-schließen",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.3 Die Hintertür schließen",
    "text": "11.3 Die Hintertür schließen\n\nDefinition 11.2 (Hintertür) Eine “Hintertür” ist ein nicht-kausaler Pfad zwischen einer UV und einer AV.\nEin Hintertürpfad entsteht, wenn es eine alternative Route über eine oder mehrere Variable gibt, dieUV mit der AV verbindet. Dieser Pfad verzerrt die Schätzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. \\(\\square\\)\n\n\n11.3.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groß ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in Abbildung 11.10 dargestellt.\n\n\n\n\n\n\n\nAbbildung 11.10: Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfläche beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund für die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\rightarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. Gäbe es nur nur den zweiten Pfad und wir würden b ändern, so würde sich p nicht ändern.\n\n11.3.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildung 11.11 zeigt eine erfreuliche Situation: Die “Hintertür” zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die Hintertür geschlossen - führen also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildung 11.11: Unverzerrte Schätzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Prädiktor im Modell enthalten ist. Da die beiden Prädiktoren unkorreliert sind, hat die Aufnahme des einen Prädiktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie “Hintertür” der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berühmte Lösung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment. Wenn wir den Häusern zufällig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen könnten (unabhängig von ihrer Quadratmeterzahl, a), würde sich der Graph so ändern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\rightarrow a \\rightarrow p\\) geschlossen (“blockiert”).\n\n\n\n\n\n\nWichtig\n\n\n\nDie Stärke (gut gemachter) Experimente ist, dass sie kausale Hintertüren schließen. \\(\\square\\)\n\n\n\n11.3.3 Hintertür schließen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die Hintertür schließen (backdoor criterion). Wir wollen die Hintertüre schließen, da wir sonst nicht den wahren, kausalen Effekt bestimmen können.\nZum Glück gibt es neben Experimenten noch andere Wege, die Hintertür zu schließen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie Konfundierer, um kausale Hintertüren zu schließen. \\(\\square\\)\n\n\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis über b kein zusätzliches Wissen über p. Wissen Sie hingegen nichts über a, lernen Sie bei Kenntnis von b auch etwas über p. Konditionieren ist wie “gegeben, dass Sie a schon kennen…”.\n\\(b \\indep p \\,|\\,a\\)",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "href": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.4 Die vier Atome der Kausalanalyse",
    "text": "11.4 Die vier Atome der Kausalanalyse\nAbbildung 11.12 stellt die vier “Atome” der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so können Sie jedes beliebige Kausalsystem (DAG) entschlüsseln.\n\n\n\n\n\n\n\nAbbildung 11.12: Die vier Atome der Kausalinferenz\n\n\n\n\n\n11.4.1 Mediation\n\nDefinition 11.3 (Mediator) Einen Pfad mit drei Knoten (Variablen), die über insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man Mediation. Der Mediator ist die Variable zwischen UV und AV [Pearl, Glymour, und Jewell (2016); p. 38]. \\(\\square\\)\n\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. Abbildung 11.13. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y “vermittelt” oder überträgt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildung 11.13: Das Kausalmodell der Mediation.\n\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation “fließt” den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schließt) die Kette (genau wie bei der Gabel).\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie den Mediator nicht. Der Pfad über den Mediator ist ein “echter” Kausalpfad, keine Scheinkorrelation. \\(\\square\\)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. \\(\\square\\)\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. Abbildung 11.14. In Abbildung 11.14 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\). Die Summe der Effekte beider Pfade nennt man den totalen (kausalen) Effekt. Den Effekt über den Mediatorpfad nennt man den indirekten (kausalen) Effekt und den Pfad \\(x\\rightarrow y\\) nennt man den direkten (kaudalen) Effekt.\n\n\n\n\n\n\n\nAbbildung 11.14: Partielle Mediation\n\n\n\n\n\n11.4.2 Der Nachfahre\n\nDefinition 11.4 (Nachfahre) Ein Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. Abbildung 11.15. \\(\\square\\)\n\nKontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet über m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise öffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildung 11.15: Ein Nachfahre verhält sich ähnlich wie sein Vorfahre…\n\n\n\n\n\n11.4.3 Kochrezept zur Analyse von DAGs 👨‍🍳\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: 📄\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geöffnet ist.\nBeurteilen Sie für jeden Pfad, ob er ein Hintertürpfad ist (Hintertürpfade haben einen Pfeil, der zur UV führt).\nWenn es geöffnete Hinterpfade gibt, prüfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schließen (falls möglich).",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#schließen-sie-die-hintertür-wenn-möglich-bsp1",
    "href": "1180-kausalatome.html#schließen-sie-die-hintertür-wenn-möglich-bsp1",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.5 Schließen Sie die Hintertür (wenn möglich)!, bsp1\n",
    "text": "11.5 Schließen Sie die Hintertür (wenn möglich)!, bsp1\n\n📺 Hintertür schließen\nUV: \\(X\\), AV: \\(Y\\), drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\nTipp\n\n\n\nSchließen Sie immer offene Hintertüren, um Verzerrungen der Kausaleffekte zu verhinden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildung 11.16: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei Hintertürpfade in Abbildung 11.16:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schließt die offene Hintertür.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n11.5.1 Schließen Sie die Hintertür (wenn möglich)!, bsp2\n\nS. DAG in Abbildung 11.17: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildung 11.17: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintertüren zu schließen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), ‚S. 188.\n\n11.5.2 Implizierte bedingte Unabhängigkeiten von bsp2\n\nEin Graph ohne Us ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme. Auch wenn die Daten nicht sagen können, welcher DAG der richtige ist, können wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten Unabhängigkeiten geben uns Möglichkeiten, zu prüfen, ob wir einen DAG verwerfen (ausschließen) können. Bedingten Unabhängigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhängig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte Unabhängigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#fazit",
    "href": "1180-kausalatome.html#fazit",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.6 Fazit",
    "text": "11.6 Fazit\n\n11.6.1 Ausstieg\n📺 Musterlösung für eine DAG-Prüfungsaufgabe\n📺 Musterlösung für schwierige DAG-Prüfungsaufgaben\n\nBeispiel 11.1 (PMI zum heutigen Stoff) Der Kreativitätsforscher Edward de Bono hat verschiedene “Denkmethoden” vorgestellt, die helfen sollen, Probleme besser zu lösen. Eine Methode ist die “PMI-Methode”. PMI steht für Plus, Minus, Interessant. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anführen. Bei Interessant verzichtet man aber explizit auf eine Bewertung (im Sinne von “gut” oder “schlecht”) und fokussiert sich auf Interessantes, Überraschendes, Bemerkenswertes (vgl. De Bono (1974)).\nFühren Sie die PMI-Methode zum heutigen Stoff durch!\n\nPlus: Was fanden Sie am heutigen Stoff gut, sinnvoll, nützlich?\nMinus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, nützlich?\nInteressant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! \\(\\square\\)\n\n\n11.6.2 Zusammenfassung\n📺 Kausalmodelle überprüfen\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren können, hängt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen können die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. “Der Unterschied zwischen beiden Gruppen beträgt etwa …”. Allerdings ist eine kausale Interpretation nicht zulässig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht möglich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dürfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten ändern sich (oft), wenn man Prädiktoren zum Modell hinzufügt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, möglichst viele Prädiktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der “kausalen Atome” ist Voraussetzung zur Ableitung von Kausalschlüsse in Beobachtungsstudien.\n\n11.6.3 Vertiefung\nAn weiterführender Literatur sei z.B. Cummiskey u. a. (2020), Lübke u. a. (2020), Pearl, Glymour, und Jewell (2016) und Dablander (2020) empfohlen. Es gibt viele Literatur zu dem Thema; relevante Suchterme sind z.B. “DAG”, “causal” oder “causal inference”.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#aufgaben",
    "href": "1180-kausalatome.html#aufgaben",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.7 Aufgaben",
    "text": "11.7 Aufgaben\n\nSammlung “kausal”",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#section",
    "href": "1180-kausalatome.html#section",
    "title": "11  Die Atome des Kausalität",
    "section": "\n11.8 —",
    "text": "11.8 —\n\n\n\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, und Krista Watts. 2020. „Causal Inference in Introductory Statistics Courses“. Journal of Statistics Education 0 (Januar): 1–16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. „An Introduction to Causal Inference“. Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische Denken. Rowohlt Taschenbuch Verlag.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLübke, Karsten, Matthias Gehrke, Jörg Horst, und Gero Szepannek. 2020. „Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Data“. Journal of Statistics Education, April, 1–17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. „Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data“. Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "12  Abschluss",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerläutern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische “Lieblingsfehler” benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik übersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n12.1.2 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n12.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "12  Abschluss",
    "section": "\n12.2 Lieblinglingsfehler",
    "text": "12.2 Lieblinglingsfehler\nLieblingsfehler im Überblick 🤷:\n\nPost-Präd-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrädiktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#post-präd-verteilung-ppv-und-post-verteilung-verwechseln",
    "href": "1200-abschluss.html#post-präd-verteilung-ppv-und-post-verteilung-verwechseln",
    "title": "12  Abschluss",
    "section": "\n12.3 Post-Präd-Verteilung (PPV) und Post-Verteilung verwechseln 🤷",
    "text": "12.3 Post-Präd-Verteilung (PPV) und Post-Verteilung verwechseln 🤷\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle 12.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle 12.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. Häufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und Punktschätzer auszulesen.\nDie Posterior-Prädiktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "href": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "title": "12  Abschluss",
    "section": "\n12.4 Quantile und Verteilungsfuntion verwechseln 🤷",
    "text": "12.4 Quantile und Verteilungsfuntion verwechseln 🤷\n\n12.4.1 Quantil für \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung 12.1.\n\n\n\n\n\n\n\nAbbildung 12.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) beträgt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist größer oder gleich dem \\(p\\)-Quantil.\n\n12.4.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung 12.2.\n\n\n\n\n\n\n\nAbbildung 12.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit beträgt hier 50%, dass \\(x\\) nicht größer ist als 0.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "href": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "title": "12  Abschluss",
    "section": "\n12.5 Interaktion falsch interpretieren 🤷",
    "text": "12.5 Interaktion falsch interpretieren 🤷\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kürzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. Tabelle 12.2.\n\nparameters(m2)\n\n\n\n\nTabelle 12.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.58\n(19.05, 30.23)\n100%\n0.999\n2272.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.58%\n1.000\n2257.00\nNormal (0.00 +- 0.22)\n\n\nvs\n14.03\n(4.82, 22.98)\n99.90%\n1.001\n1900.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.03)\n99.65%\n1.001\n2111.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle 12.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\n\n\n\nAbbildung 12.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch 😈 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11.\nRichtig 👼 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11 – wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Prädiktoren wären hier eine sinnvolle Lösung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "12  Abschluss",
    "section": "\n12.6 Kochrezepte 🍲",
    "text": "12.6 Kochrezepte 🍲\n\n12.6.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen über ein Phänomen, \\(y\\), Kausalfrage finden 2. Literatur wälzen, um mögliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese präzisieren 4. Modell präzisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prüfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n12.6.2 Parameter schätzen vs. Hypothesen prüfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schätzen. Beispiel Hypothesenprüfung: “Frauen parken im Durchschnitt schneller ein als Männer”. Beispiel Parameterschätzung: “Wie groß ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und Männern?”\nJe ausgereifter ein Forschungsfeld, desto kühnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nächste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nächste Sonnenfinsternis wird in den nächsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen für den Klausurerfolg. Kühne Hypothesen sind wünschenswert 🦹\n\n12.6.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist höher als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist größer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "12  Abschluss",
    "section": "\n12.7 Kerngedanken Bayes",
    "text": "12.7 Kerngedanken Bayes\n📺 Bayes in fünf Minuten\n📺 Bayes in zehn Minuten\n\n12.7.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung 12.4.\n\n\n\n\n\n\n\nAbbildung 12.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist möglich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind möglich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings übermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n12.7.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-für-prüfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-für-prüfungsaufgaben",
    "title": "12  Abschluss",
    "section": "\n12.8 Beispiele für Prüfungsaufgaben",
    "text": "12.8 Beispiele für Prüfungsaufgaben\n\n12.8.1 Geben Sie den korrekten Begriff an!\n🌬🚙🙋️👨⬅️Hans 👧⬅️Anna 👩⬅️Lise\nPuh, wie erstelle ich für alle Studis ein anderes Rätsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-Prüfung bekommen alle Studentis eine eigene, jeweils andere Prüfung. Teamarbeit bleibt natürlich trotzdem untersagt.\n\n\n\n12.8.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung 12.5.\n\n\n\n\n\n\n\nAbbildung 12.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n❓Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n❗ Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n12.8.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung 12.6.\n\n\n\n\n\n\n\nAbbildung 12.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n12.8.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung 12.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung 12.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set für den totalen Kausaleffekt: {AIS, ALN}\n\n12.8.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrüfungsfragen zu Modellen könnten z.B. sein:\n\nGeben Sie den Punktschätzer (Median) für den Prädiktor X im Modell Y an!\nGeben Sie ein 89%-HDI für den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris …\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI für den Prädiktor X im Modell Y?\nWas verändert sich an den Parametern, wenn Sie die Prädiktoren zentrieren/z-standardisieren?\n…",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "12  Abschluss",
    "section": "\n12.9 Aufgabensammlungen",
    "text": "12.9 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere “Prüfungsnähe” könnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prüfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prüfung",
    "title": "12  Abschluss",
    "section": "\n12.10 Viel Erfolg bei der Prüfung!",
    "text": "12.10 Viel Erfolg bei der Prüfung!\n🥳🏆🍀🍀🍀",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "12  Abschluss",
    "section": "\n12.11 —",
    "text": "12.11 —\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. „The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs“. European Psychiatry 29 (7): 437–48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. “Misconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.” Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, Günther. 2018. Wahrscheinlichkeitsrechnung Und Schließende\nStatistik: Praxisorientierte Einführung: Mit Aufgaben Und Lösungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik –\nWahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas\nClark, and Krista Watts. 2020. “Causal Inference in Introductory\nStatistics Courses.” Journal of Statistics Education 0\n(January): 1–16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. “An Introduction to Causal\nInference.” Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische\nDenken. Rowohlt Taschenbuch Verlag.\n\n\nForum, World Economic. 2020. “The Future of\nJobs Report 2020.” CH-1223 Cologny/Geneva\nSwitzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nHenze, Norbert. 2019. Stochastik: Eine Einführung mit Grundzügen der\nMaßtheorie: Inkl. zahlreicher Erklärvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of\nScience. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nKampen, D. van. 2014. “The SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.” European\nPsychiatry 29 (7): 437–48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLübke, Karsten, Matthias Gehrke, Jörg Horst, and Gero Szepannek. 2020.\n“Why We Should Teach Causal Inference: Examples in\nLinear Regression with Simulated Data.” Journal of Statistics\nEducation, April, 1–17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel Lüdecke. 2019. “Indices of Effect Existence\nand Significance in the Bayesian\nFramework.” Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. “Chocolate Consumption,\nCognitive Function, and Nobel\nLaureates.” New England Journal of Medicine 367\n(16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nMittag, Hans-Joachim, and Katharina Schüller. 2020. Statistik: Eine\nEinführung mit interaktiven Elementen. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly About\nCorrelations and Causation: Graphical Causal\nModels for Observational Data.” Advances\nin Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n\n\nSuttorp, Marit M., Bob Siegerink, Kitty J. Jager, Carmine Zoccali, and\nFriedo W. Dekker. 2015. “Graphical Presentation of Confounding in\nDirected Acyclic Graphs.” Nephrology Dialysis\nTransplantation 30 (9): 1418–23. https://doi.org/10.1093/ndt/gfu325.\n\n\nTennant, Peter W G, Eleanor J Murray, Kellyn F Arnold, Laurie Berrie,\nMatthew P Fox, Sarah C Gadd, Wendy J Harrison, et al. 2020. “Use\nof Directed Acyclic Graphs (DAGs) to Identify Confounders\nin Applied Health Research: Review and Recommendations.”\nInternational Journal of Epidemiology 50 (2): 620–32. https://doi.org/10.1093/ije/dyaa213.\n\n\nVanderWeele, Tyler J., and Ilya Shpitser. 2013. “On the Definition\nof a Confounder.” Annals of Statistics 41 (1): 196–220.\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. “The\nASA Statement on p-Values:\nContext, Process, and Purpose.” The American\nStatistician 70 (2): 129–33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 Einführung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie …\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden können\ngängige einschlägige Forschungsfragen in statistische Modelle übersetzen und mit R auswerten können\nkausale Forschungsfragen in statistische Modelle übersetzen und prüfen können\ndie Güte und Grenze von statistischen Modellen einschätzen können\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage für Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und Männer vor eine Einpark-Aufgabe gestellt (natürlich alles schön standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen können schneller einparken als Männer, im Durchschnitt. Das hätten wir also geklärt. Aber haben wir das ganz sicher geklärt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich weiß, das ist jetzt ein harter Schlag für Sie… Aber die gute Nachricht ist: Wir können angeben, wie (un)sicher wir bei mit einer Aussage (“Frauen parken schneller…”) sind. Zum Beispiel könnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie nächste Woche ei Fahri für Ihren neuen Rolls Royce anheuern, müssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, müssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen “laut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauen”. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es üblich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den “Top 20 job roles in increasing and decreasing demand across industries” (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 Modulüberblick\nAbbildung 1.1 gibt einen Überblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n  subgraph Kausalität\n    Kausalstart\n  end \n  Wskt --&gt; Bayes --&gt; Regression --&gt; Kausalität\n\n\n\n\nAbbildung 1.1: Modulverlauf im Überblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelle 1.1 gibt einen Überblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist nützlich für Sie, die Tabelle Tabelle 1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als nächstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelle 1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nInferenz\n2.-8. Okt.\nNA\n\n\n2\nWahrscheinlichkeit\n9.-15. Okt.\nNA\n\n\n3\nVerteilungen\n16.-22. Okt.\nNA\n\n\n4\nGlobusversuch\n23.-29. Okt.\nNA\n\n\n5\nAufhol-Woche\n30.-5. Nov.\nNA\n\n\n6\nDie Post befragen\n5.-12. Nov.\nNA\n\n\n7\nGauss-Modelle\n13.-19. Nov.\nNA\n\n\nNA\nNA\n20.-26. Nov.\nBlockwoche: Kein regulärer Unterricht\n\n\n8\nLineare Modelle\n27.-3. Dez.\nNA\n\n\n9\nMetrische AV\n4.-10. Dez.\nNA\n\n\n10\nKonfundierung\n11.-17. Dez\nNA\n\n\n11\nKausalatome\n18.-24. Dez.\nNA\n\n\nNA\nNA\nNA\nJahreswechsel: Kein Unterricht\n\n\n12\nAbschluss\n8.-14. Jan. 24\nNA\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nFür dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, möglichst auch mit dem tidyverse\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.B. im Online-Buch “Statistik1” vermittelt. Alle Inhalte daraus werden in diesem Kurs benötigt.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.2 Hinweise",
    "text": "1.2 Hinweise\n\n📺 Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#prüfung",
    "href": "index.html#prüfung",
    "title": "Start:Bayes!",
    "section": "\n1.3 Prüfung",
    "text": "1.3 Prüfung\nDas Prüfungsformat ist: Open-Book-Prüfung.\n\nAllgemeine Prüfungshinweise\nPrüfungsformat: Open-Book-Prüfung\nHinweise zu quantitativen Prüfungen\nPrüfungsvorbereitung\n\nIn Kapitel 12 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#faq",
    "href": "index.html#faq",
    "title": "Start:Bayes!",
    "section": "\n1.4 FAQ",
    "text": "1.4 FAQ\n\nFRAGE: Wo finde ich eine Probeklausur? – ANTWORT: Dieser Tag stellt Fragen einer Probeprüfung zusammen.\nFRAGE: Wie bereite ich mich gut auf die Prüfung vor? – ANTWORT: Hier finden Sie Tipps zur Prüfungsvorbereitung.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.5 Zitation",
    "text": "1.5 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\n@book{sauer_statistik1_2022,\n    title = {Statistik1},\n    rights = {All rights reserved},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2023},\n}\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Start:Bayes!",
    "section": "\n1.6 Technische Details",
    "text": "1.6 Technische Details\nDieses Dokument wurde erzeugt am/um 2023-12-08 11:49:08.\n\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Europe/Berlin\n##  date     2023-11-29\n##  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  ! package     * version date (UTC) lib source\n##  P cli           3.6.1   2023-03-23 [?] CRAN (R 4.2.0)\n##  P codetools     0.2-18  2020-11-04 [?] CRAN (R 4.2.1)\n##  P digest        0.6.33  2023-07-07 [?] CRAN (R 4.2.0)\n##  P dplyr         1.1.3   2023-09-03 [?] CRAN (R 4.2.0)\n##  P evaluate      0.21    2023-05-05 [?] CRAN (R 4.2.0)\n##  P fansi         1.0.5   2023-10-08 [?] CRAN (R 4.2.0)\n##  P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.2.0)\n##  P generics      0.1.3   2022-07-05 [?] CRAN (R 4.2.0)\n##  P glue          1.6.2   2022-02-24 [?] CRAN (R 4.2.0)\n##  P gt            0.10.0  2023-10-07 [?] CRAN (R 4.2.0)\n##  P htmltools     0.5.6.1 2023-10-06 [?] CRAN (R 4.2.0)\n##  P htmlwidgets   1.6.2   2023-03-17 [?] CRAN (R 4.2.0)\n##  P jsonlite      1.8.7   2023-06-29 [?] CRAN (R 4.2.0)\n##  P knitr         1.45    2023-10-30 [?] CRAN (R 4.2.1)\n##  P lifecycle     1.0.3   2022-10-07 [?] CRAN (R 4.2.0)\n##  P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.2.0)\n##  P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.2.0)\n##  P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.2.0)\n##  P R6            2.5.1   2021-08-19 [?] CRAN (R 4.2.0)\n##    renv          1.0.2   2023-08-15 [1] CRAN (R 4.2.0)\n##  P rlang         1.1.1   2023-04-28 [?] CRAN (R 4.2.0)\n##  P rmarkdown     2.25    2023-09-18 [?] CRAN (R 4.2.0)\n##  P rstudioapi    0.15.0  2023-07-07 [?] CRAN (R 4.2.0)\n##  P sass          0.4.7   2023-07-15 [?] CRAN (R 4.2.0)\n##  P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.2.0)\n##  P tibble        3.2.1   2023-03-20 [?] CRAN (R 4.2.0)\n##  P tidyselect    1.2.0   2022-10-10 [?] CRAN (R 4.2.0)\n##  P utf8          1.2.3   2023-01-31 [?] CRAN (R 4.2.0)\n##  P vctrs         0.6.4   2023-10-12 [?] CRAN (R 4.2.0)\n##  P withr         2.5.2   2023-10-30 [?] CRAN (R 4.2.1)\n##  P xfun          0.40    2023-08-09 [?] CRAN (R 4.2.0)\n##  P xml2          1.3.4   2023-04-27 [?] CRAN (R 4.2.0)\n##  P yaml          2.3.7   2023-01-23 [?] CRAN (R 4.2.0)\n## \n##  [1] /Users/sebastiansaueruser/github-repos/start-bayes/renv/library/R-4.2/x86_64-apple-darwin17.0\n##  [2] /Users/sebastiansaueruser/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.2/x86_64-apple-darwin17.0/fb4b0a46\n## \n##  P ── Loaded and on-disk path mismatch.\n## \n## ──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nForum, World Economic. 2020. „The Future of Jobs Report 2020“. CH-1223 Cologny/Geneva Switzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "href": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.2 Arten von Forschungsfragen",
    "text": "9.2 Arten von Forschungsfragen\n\n9.2.1 Nach dem Erkenntnisziel\n📄 Deskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von Größe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\n🔮 Prädiktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der Größe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts für die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhält?\n\n🔗 Präskriptiv (erklärend, kausal)\n\nIst Größe eine Ursache von Gewicht (bei deutschen Männern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklärend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehört.\n\n\n\n9.2.2 Nach dem Skalenniveau\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus.\nFür die UV(s) sind nominale und metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.\n\n9.2.3 Varianten von Forschungsfragen\nIm Folgenden sind beispielhafte, häufig verwendete Arten von Forschungsfragen aufgeführt. Für jede Variante ist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenmniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abhängige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabhängige Variable (querschnittlich)\n\nb: binäre Variable\n\nx: metrische unabhängige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#eine-binäre-uv",
    "href": "1000-metrische-AV.html#eine-binäre-uv",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.3 Eine binäre UV",
    "text": "9.3 Eine binäre UV\n\n9.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im öffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwändigen Studie die Intelligenz vieler Kinder gemessen. Zusätzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, “Risikofaktoren” für geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in Abhängigkeit davon, ob ihre jeweilige Mutter über einen Schlusabschluss (mom_hs, \\(x=1\\)) verfügt (bzw. nicht, \\(x=0\\))? (ceteris paribus)4.\n\nFormaler ausgedrückt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (Gleichung 9.1):\n\\[\\mu_{x=1|\\alpha, \\beta, \\sigma} \\ne \\mu_{x=0|\\alpha, \\beta, \\sigma} \\tag{9.1}\\]\nDie Modellformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in Abbildung 9.1 dargestellt. Y hat, laut unserem Modell, drei Ursachen:\n\nb\nx\nu, das steht für “unbekannt”5\n\n\n\n\n\n\n\n\n\nAbbildung 9.1: DAG für kid_iq ~ mom_hs\n\n\n\n\n\n9.3.2 IQ von Kindern, binärer Prädiktor\n\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. Tabelle 9.1.\n\n\n\nTabelle 9.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nIn Abbildung 9.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\nestimate_expectation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildung 9.2: Kinder, deren Mütter über einen Schulabschluss verfügen, haben im Mittel einen höheren Intelligenztestwert, laut dem vorliegenden Modell\n\n\n\n\n\n9.3.3 Interpretation von m10.1\n\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren Mütter über keinen Schulabschluss (mom_hs = 0) verfügen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit Mütter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit Mütter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die Schätzung (Vorhersage) ist bzw. wie stark Prädiktor (UV) und Kriterium (AV) zusammenhängen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tatsächlichen IQ-Wert des Kindes (\\(\\y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n9.3.4 m10.1 als Mittelwertsdifferenz\n\nUV: binär (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\n\n👨‍🏫 Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heißen kid_score_avg. An die Arbeit!\n\n\n🤖 Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nkidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von Müttern mit Abschluss.\n\n\n\n\n9.3.5 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation - Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das prüft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen z.B. die Posteriori-Verteilung (z.B. mit 95%PI).\n\n9.3.6 Antwort auf die Forschungsfrage, m10.1\n\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nm10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schönere Namen\n\n\n\nHier sind die ersten paar Zeilen, s. Tabelle 9.2.\n\n\n\nTabelle 9.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n75.9\n11.5\n19.3\n\n\n78.6\n10.8\n21.2\n\n\n79.0\n10.2\n18.7\n\n\n79.1\n9.5\n19.8\n\n\n80.3\n8.5\n19.8\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir ein 95%-PI von Hand:7\n\npi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von Müttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschließend die Posteriori-Verteilung, s. Abbildung 9.3.\n\nplot(eti(m10.1))\n\n\n\n\n\n\nAbbildung 9.3: Das 95% ETI zum (statistischen) Effekt des mütterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem “Effekt” zu sprechen, lässt in den meisten Köpfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang.\n\n\n\n\n\n\n\n\n\n\n9.3.7 Toleranzbereich\nBerechnet man ein Regressionsmodell mit stan_glm (🤖😁), dann zieht man dabei Zufallszahlen 🎲. Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zufällig. Das erklärt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen können.\nUm zu prüfen, ob Ihre Ergebnisse “ähnlich genug” oder “innerhalb eines Toleranzbereichs” sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nHinweis\n\n\n\nGröße des Toleranzbereichs Die Größe des relativen Toleranzbereichs ist auf 5% festgelegt. Das heißt, ein Unterschied von 5% zwischen einem Referenzwert (dem “wahren” Wert) und Ihrem Wert ist okay, also im Toleranzbereich. Außerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der größere der beiden Werte gilt. \\(\\square\\)\n\n\nZuerst müssen Sie das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN), das geht z.B. so:\n\nlibrary(remotes)  # dieses Paket können Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\n\nDann starten Sie es wie gewohnt:\n\nlibrary(prada)\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der “richtige” oder “wahre” Wert (oder schlicht der Wert einer Musterlösung) für \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. ✅",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "1000-metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.4 Eine metrische plus eine nominale UV",
    "text": "9.4 Eine metrische plus eine nominale UV\n\n9.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b.\nDer Kausalgraph8 zur Modellformel sieht aus in Abbildung 9.4 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) Einflüsse, b und u, wobei u für “unbekannt” steht, also für alle sonstigen Einflüsse.9\n\n\n\n\n\n\n\nAbbildung 9.4: DAG für y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle Tabelle 9.3 dargestellt.\n\ndata(\"kidiq\")  # Paket rstanarm, alternativ über CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\nTabelle 9.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n9.4.2 1 metrischer Prädiktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. Tabelle 9.4.\n\nm10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\nTabelle 9.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. Abbildung 9.5.\n\nkidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildung 9.5: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. Abbildung 9.6.\n\nplot(estimate_expectation(m10.2))\n\n\n\n\n\n\nAbbildung 9.6: Die geschätzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder für verschiedene IQ-Werte der Mütter. Vergleicht man Teilpopulationen von Müttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n9.4.3 Beide Prädiktoren, m10.3\n\nBerechnen wir als nächstes ein Modell mit beiden Prädiktoren: kid_score ~ mom_hs + mom_iq, s. Tabelle 9.5.\n\nm10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\nTabelle 9.5: Parameter des Modells m10.3 (ohne sigma)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktschätzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nMöchte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\nAber natürlich ist es möglich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. Abbildung 9.7.\n\nkidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\nplot(estimate_expectation(m10.3a))\n\n\n\n\n\n\nAbbildung 9.7: Der Effekt von sowohl mütterlicher Intelligenz als auch mütterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schätzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum mütterlichen Schulabschluss: Vergleicht man Kinder von Müttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur mütterlichen IQ: Vergleicht man Kinder von Müttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#interaktion",
    "href": "1000-metrische-AV.html#interaktion",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.5 Interaktion",
    "text": "9.5 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 folgendes Modell: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. Abbildung 9.8 und Tabelle 9.6.\n\nm10.4 &lt;- \n  stan_glm(kid_score ~  mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\nTabelle 9.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.10\n(-37.00, 17.79)\n77.10%\n1.000\n1416.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n49.01\n(20.09, 79.88)\n99.85%\n1.000\n1438.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq\n0.95\n(0.65, 1.24)\n100%\n1.000\n1362.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq\n-0.46\n(-0.78, -0.15)\n99.75%\n1.000\n1388.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_expectation(m10.4) |&gt; plot() kann man es sich visualisieren, s. Abbildung 9.8.\n\n\n\n\n\n\n\nAbbildung 9.8: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt für diese Daten kaum zu interpretieren ist.\n\n\n\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b.\nDer DAG zur Modellformel sieht aus in Abbildung 9.9 dargestellt.\n\n\n\n\n\n\n\nAbbildung 9.9: DAG für y ~ x + b + x:b\n\n\n\n\n\n9.5.1 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Schätzwerte für Kinder mit Mütter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-Schätzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-Schätzwerte zwischen Kindern mit Müttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten für mom_iq zwischen Mütter mit bzw. ohne Schulabschluss.\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\n\n9.5.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#zentrieren-von-prädiktoren",
    "href": "1000-metrische-AV.html#zentrieren-von-prädiktoren",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.6 Zentrieren von Prädiktoren",
    "text": "9.6 Zentrieren von Prädiktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq.\nMan könnte auch mom_hs zentrieren, aber für eine einfache Interpretation ist es meist nützlich, nur metrische Prädiktoren zu zentrieren.\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.31\n\n\nmom_hs\n2.91\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n9.6.1 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den geschätzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten für mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nm10.5 ist in Abbildung 9.10 dargestellt.\n\n\n\n\n\n\n\nAbbildung 9.10: m10.5: Interaktionsmodell mit zentriertem Prädiktor für mütterlicher Intelligenz. Wie man sieht, ist der Achsenabschnitt deutlich besser zu interpretieren als in m10.4, s. ?fig-m10.4.\n\n\n\n\n\n9.6.2 Zentrieren ändert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.34184\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.3592\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren ändert auch nicht die Regressionskoeffizienten, da die Streuungen der Prädiktoren nicht verändert wurden.\n\n9.6.3 Perzentilintervalle aus der Posterori-Verteilung\nTabelle 9.7 zeigt die Punktschätzer der Parameter für m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie dafür parameters(m10.5), s. Tabelle 9.7.\n\n\n\nTabelle 9.7: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(80.99, 89.72)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.69)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.67, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. Tabelle 9.8.\n\nparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelle 9.8: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(81.26, 89.88)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.70)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.79, -0.17)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n9.6.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei Müttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mütterlichen Intelligenz; pro Punkt Unterschied in müttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). Außerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei Mütter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. Zusammenhänge beschrieben. Für kausale Aussagen ist mehr nötig, als einen statistischen Zusammenhang festzustellen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "1000-metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.7 Eine nominale UV mit mehreren Stufen",
    "text": "9.7 Eine nominale UV mit mehreren Stufen\n\n9.7.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in; Ihre Kompetenz als Wirtschaftspsychologi war heiß begehrt. Von Statistik wollte niemand etwas wissen… Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt führte Sie in die Antarktis… Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um Größenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren Körpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in Abbildung 9.11 dargestellt.\n\n\n\n\n\n\n\nAbbildung 9.11: DAG für y ~ g\n\n\n\n\n\n9.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? 🤔 Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere Körpergewichte in Abhängigkeit von der Pinguinart?\n\nAlternativ können wir die Hypothese prüfen, ob die Mittelwerte “praktisch” gleich sind, also sich “kaum” unterscheiden. Der Grenzwert für “praktisch gleich” bzw. “kaum unterschiedlich” ist subjektiv. Dazu in Kapitel 9.10 mehr.\n\n9.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, Tabelle 9.9.\n\npenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\nTabelle 9.9: Die Verteilung des Körpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas fällt Ihnen auf?\n\n9.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. Abbildung 9.12?\n\n\n\n\n\n\n\nAbbildung 9.12: Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.7.5 Mittlere Gewichtsunterschiede in der Population\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und Tabelle 9.10.\n\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\nTabelle 9.10: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3699.92\n(3624.56, 3776.46)\n100%\n1.001\n4194.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.24\n(-100.80, 159.99)\n69.92%\n1.000\n4266.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.94\n(1265.80, 1486.83)\n100%\n1.001\n4187.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n9.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, Ausprägungen; hier: Spezies), aber es werden in Tabelle 9.10 nur zwei Stufen angezeigt (also eine weniger) zusätzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrückt (Intercept). Die Koeffizienten für species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in Abbildung 9.13 verdeutlicht.\n\nplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 9.13: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (d. Details hier).\n\n9.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich höher als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich ähnlich.\nWie in Abbildung 9.13 ersichtlich, überlappt sich der Schätzbereich für den Parameter von Gentoo nicht mit der Null; hingegen überlappt sich der Schätzbereich des Parameters für Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hätte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prüfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primär die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#priori-werte",
    "href": "1000-metrische-AV.html#priori-werte",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.8 Priori-Werte",
    "text": "9.8 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. Für Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfür Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: prior_summary(modell):\n\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWo man man über mehr inhaltliches Wissen verfügt, so wird man die Prioris anpassen wollen, z.B.:\n\nm10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3703.90575         26.67909       1360.23645\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nm10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.98554         30.95782       1375.37494\n\nDen Parameter für die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\nsigma(m10.6b)\n## [1] 462.6415\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die Größe der Konfidenzintervalle.\nÜbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren12.\n\n9.8.1 Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge ändern.\n\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nlibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\nBeachten Sie, dass dazu das Paket forcats verfügbar sein muss.\nJetzt haben wir die Referenzkategorie geändert:\n\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\nDer Wechsel der Referenzkategorie ändert nichts Wesentliches am Modell, s. Tabelle 9.11.\n\nm10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\nTabelle 9.11: m10.6a mit geänderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 5001.08, 5160.63]\n\n\nspeciesAdelie\n[-1477.80, -1264.23]\n\n\nspeciesChinstrap\n[-1475.95, -1204.52]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#modellgüte-mit-r-quadrat-bestimmen",
    "href": "1000-metrische-AV.html#modellgüte-mit-r-quadrat-bestimmen",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.9 Modellgüte mit R-Quadrat bestimmen",
    "text": "9.9 Modellgüte mit R-Quadrat bestimmen\n\n9.9.1 Modellgüte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklärt. - Höhere Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklärt. \\(R^2\\) wird normalerweise auf Basis eines Punktschätzers definiert. Solch eine Definition lässt aber viel Information - über die Ungewissheit der Schätzung - außen vor. Daher ist es wünschenswert, diese Information in \\(R^2\\) einfließen zu lassen: Bayes-R-Quadrat.\n\n\n\nr2(m10.6)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.668 (95% CI [0.618, 0.712])\n\nMöchte man es ausführlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. Abbildung 9.14.\n\nm10.6_r2 &lt;-\nm10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung 9.14: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n9.9.2 Definition vom “klassischen” \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die “typische” Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nützlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklärten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck äquivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen Ausdrücke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlässigen Ungewissheit; sie sind übergewiss aus Bayes-Sicht.\n\n9.9.3 Bayes’ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellgüte miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkärte Varianz}}{\\text{Erklärte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. Für jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklärten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u. a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#sec-rope",
    "href": "1000-metrische-AV.html#sec-rope",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.10 Nullhypothesen sind praktisch immer falsch",
    "text": "9.10 Nullhypothesen sind praktisch immer falsch\n📺 Teil 2\nNullhypothesen sind fast immer falsch, s. Abbildung 9.15.\n\n\n\n\n\n\n\nAbbildung 9.15: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, und Vehtari (2021)\n\n9.10.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest möglich ist13\nEin anderer Grund ist vermutlich, … wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n9.10.2 “Praktisch” kein Unterschied: Das Rope-Konzept\n📺 ROPE-Video\nSagen wir, wenn sich zwei Preismittelwerte um höchstens \\(d=100\\)€ unterscheiden, gilt dieser Unterschied für uns als “praktisch gleich”, “praktisch kein Unterschied” bzw. vernachlässigbar. Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Überlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Äquivalenzzone, Bereich eines vernachlässigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prüfen wir, ob ein “Großteil” der Posteriori-Stichproben im Rope liegt. Unter “Großteil” wird häufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroßteil liegt innerhalb von Rope ➡️ Annahme der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\n\nGroßteil liegt außerhalb von Rope ➡️ Ablehnung der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\n\nAnsonsten ➡️ keine Entscheidung\n\n9.10.3 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildung 9.16: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\n\nAbbildung 9.16 illustriert die Entscheidungsregel zum ROPE für mehrere Situatioenen (Kruschke 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett außerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung möglich; die Datenlage ist unklar.\n\n9.10.4 Rope berechnen\nDen Rope berechnet man mit rope(model).\n\nrope(m10.6)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen beträchtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir können daher für diese Gruppe das ROPE nicht verwerfen.\nAber: Gentoo liegt zu 0% im Rope. Für Gentoo können wir das Rope verwerfen.\nDas hört sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n9.10.5 Visualisierung unserer Rope-Werte, m10.6\n\nEin Großteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber können wir umgekehrt sagen, dass ein Großteil außerhalb liegt? Das erkennt man optisch ganz gut.\n\n\nplot(rope(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\n\nDas ROPE druchkreuzt die “Berge” der Posteriori-Verteilung für Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir können das Rope für Chinstrap nicht verwerfen, aber auch nicht bestätigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom “blauen Fluss” des Rope: Gentoo liegt außerhalb des Rope. Es gibt einen “substanziellen” Unterschied, größer als das ROPE. Wir verwerfen die “Praktisch-Null-Hypothese” in diesem Fall.\n\n9.10.6 Finetuning des Rope\nWir können festlegen, was wir unter “praktischer Äquivalenz” verstehen, also die Grenzen des Ropes verändern. Sagen wir, 100 Gramm sind unsere Grenze für einen vernachlässigbaren Effekt, s. Abbildung 9.17.\n\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 9.17: ROPE mit selber eingestellter Grenze von ±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so ändern, wenn man möchte:\n\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht für ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.\n\n9.10.7 Beantwortung der Forschungsfrage\nFür die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. Für Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs möglich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#mehrere-metrische-uv",
    "href": "1000-metrische-AV.html#mehrere-metrische-uv",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.11 Mehrere metrische UV",
    "text": "9.11 Mehrere metrische UV\n\n9.11.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhängig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa “IQ der Mutter ist die Ursache zum IQ des Kindes”) wird impliziert.\nEs geht rein darum, Zusammenhänge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. Für solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nötig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n9.11.2 Was heißt, X hängt mit Y zusammen?\n\nDer Begriff “Zusammenhang” ist nicht exakt.\nHäufig wird er (für metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groß der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem “Effekt von X auf Y” übersetzt. Vorsicht: “Effekt” klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begründung für einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der Stärke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehörigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n9.11.3 Korrelationen zur Forschungsfrage\n\nkidiq %&gt;% \n  correlation()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\nTabelle 9.12 zeigt die Korrelationsmatrix als Korrelationsmatrix:\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\nTabelle 9.12: Die Korrelationen zwischen den Variablen der Tabelle kidiq\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.21***\n0.28***\n\n\n\nmom_iq\n0.09\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nNützlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, Abbildung 9.18.\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung 9.18: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n9.11.4 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro Prädiktor, also eine für mom_iq und eine für mom_age.\n\nm10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\nHier die Ergebnisse für mom_iq:\n\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.8084927   0.6101706\n\nHier die Ergebnisse für mom_age:\n\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.1650562   0.6875296\n\n\n9.11.5 Visualisierung der univariaten Regressionen\nIn Abbildung 9.19 ist die univariate Regression mit jeweils einem der beiden Prädiktoren dargestellt.\nm10.7: Die Steigung beträgt 0.6. m10.8: Die Steigung beträgt 0.7.\n\n\n\n\n\n\n\nAbbildung 9.19: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n9.11.6 Multiples Modell (beide Prädiktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein Prädiktor im Modell aufgenommen ist.\n\nm10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils “bereinigt” vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines Prädiktors mit der AV, wobei man gleichzeitig den anderen Prädiktor konstant hält.\n\n\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n\n\n9.11.7 3D-Visualisierung eines Modells mit zwei Prädiktoren 1\nIn Abbildung 9.20 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildung 9.20: 3D-Visualisierung von m10.9 (zwei Prädiktoren)\n\n\n\n\n9.11.8 Visualisierung mit Farbe statt 3. Dimension\n3D-Visualisierungen haben Vorteile, aber auch Nachteile; Abbildung 9.21 zeigt eine alternative Visualisierung, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildung 9.21: Modell m10.9; die Farbverläufe zeigen der Wert der abhängigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farbänderung) die Veränderung für die AV (kid_score). Auf der Achse für mom_age sieht man, dass sich die AV kaum ändert, wenn sich mom_age ändert.\n\n9.11.9 Visualisierung in 10 Dimensionen\nAbbildung 9.22 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildung 9.22: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schwächen, eine große Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n9.11.10 Relevanz der Prädiktoren\nWoher weiß man, welcher Prädiktor am stärksten mit der AV zusammenhängt? Man könnte auch sagen: Welcher Prädiktor (welche UV) am “wichtigsten” ist oder den “stärksten Einfluss” auf die AV ausübt? Bei solchen kausal konnotierten Ausdrücken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann für sich nur Muster in den Daten, also Zusammenhänge bzw. Unterschiede, entdecken, s. Abbildung 9.23.\n\n\n\n\n\nAbbildung 9.23: Made at imgflip.com\n\n\nWelcher Prädiktor ist nun “wichtiger” oder “stärker” in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)?\n\n\nmom_iq hat den größeren Koeffizienten.\n\nmom_age hat weniger Streuung.\n\nUm die Relevanz der Prädiktoren vergleichen zu können, müsste man vielleicht die Veränderung von kid_score betrachten, wenn man von kleinsten zum größten Prädiktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die Veränderung in der AV zu betrachten, wenn man den Prädiktor von “unterdurchschnittlich” auf “überdurchschnittlich” ändert. Das kann man mit z-Standardisierung erreichen.\n\n9.11.11 z-Standardisierung\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie über einen Mittelwert von 0 und eine SD von 1 verfügt:\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\ndata(\"kidiq\")\nkidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;% \n  select(mom_iq, mom_iq_z) %&gt;% \n  head()\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten14. Die Standardisierung ist ähnlich zur Vergabe von Prozenträngen: “Dieser Messwert gehört zu den Top-3-Prozent”. Diese Aussage ist bedeutsam für Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen für verschiedene Verteilungen möglich.\n\n9.11.12 Statistiken zu den z-transformierten Variablen\nTabelle 9.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Ausprägung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener Prädiktoren sind einfacher in ihrer Größe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und ähnlich große Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (“Skalierung”) mit standardize (aus easystats) durchführen, s. Tabelle 9.13.\n\nkidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\nTabelle 9.13: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n65\n1\n121.12\n27\n-1.07\n0.52\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n0.55\n0.52\n-0.71\n0.82\n\n\n85\n1\n115.44\n27\n-0.09\n0.52\n1.03\n1.56\n\n\n83\n1\n99.45\n25\n-0.19\n0.52\n-0.04\n0.82\n\n\n115\n1\n92.75\n27\n1.38\n0.52\n-0.48\n1.56\n\n\n98\n0\n107.90\n18\n0.55\n-1.91\n0.53\n-1.77\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafür, dass die ursprünglichen Variablen beim z-Standardisieren nicht überschrieben werden, sondern angehängt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nkidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. Tabelle 9.14. Dazu verwendet man den Befehl scale().\n\nkidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\nTabelle 9.14: Z-Standardisierung ohne Extrapaket”",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#modell-m10.10",
    "href": "1000-metrische-AV.html#modell-m10.10",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.12 Modell m10.10\n",
    "text": "9.12 Modell m10.10\n\n\n9.12.1 AV z-transformieren\nIm Modell m10.10 sind die Prädiktoren z-transformiert (standardisiert) und die AV ebenfalls. Das Standardisieren der AV, kid_score ist zwar nicht nötig, um den Effekt der Prädiktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darüber, um wie viele SD-Einheiten sich die AV verändert, wenn sich ein Prädiktor um eine SD-Einheit verändert. Das kann auch eine interessante(re) Aussage sein.\n\nm10.10 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.10)\n## (Intercept)    mom_iq_z   mom_age_z \n## 0.001554359 0.443843346 0.050380199\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient für mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_iq um eine SD-Einheit ändert.\nDer Koeffizient für mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_age um eine SD-Einheit ändert.\n\nJetzt sind die Prädiktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n9.12.2 95%-PI\nMit parameters können wir uns ein PI für m10.10 ausgeben lassen, s. Abbildung 9.24; im Standard wird ein 95%-ETI berichtet15.\n\nparameters(m10.10) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n1.55e-03\n(-0.08, 0.08)\n51.12%\n0.999\n4683.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n5372.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.33%\n0.999\n4779.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nplot(eti(m10.10)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 9.24: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI für m10.10\n\n\n\n\n\n9.12.3 Was ist ein kleiner, was ein großer Effekt?\nCohen (1988) definiert Effektstärken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\). Für kleine, mittlere und große Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\n\nmittel: \\(d \\approx 0.5\\)\n\ngroß: \\(d \\approx 0.8\\)\n\n\nAuf dieser Basis schlägt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor. Fällt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als “praktisch null”. Richtlinien für Effektstärken sind nur Notlösungen, die durch Sachverstand ersetzt werden sollen, wo immer möglich. Man kann Effektstärken ineinander überführen, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n9.12.4 Vernachlässigbarer Regressionseffekt\nKruschke (2018) schlägt vor, einen Regressionskoeffizienten unter folgenden Umständen als “praktisch Null” zu bezeichnen:\nWenn eine Veränderung über “praktisch den ganzen Wertebereich” von \\(x\\) nur einen vernachlässigbaren Effekt auf \\(y\\) hat. Ein vernachlässigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der “praktisch ganze Wertebereich” von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Veränderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlässigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) für z-standardisierte Variablen.\n\n9.12.5 Modellgüte\n\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.204 (95% CI [0.142, 0.268])\n\nIst dieser Wert von \\(R2\\) “gut”? Diese Frage ist ähnlich zur Frage “Ist das viel Geld?”; man kann die Frage nur im Kontext beantworten.\nEine einfache Lösung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklärt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufällig hohen Werten der Modellgüte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine “objektive” Antwort auf die Frage “wie viel ist viel?” haben wollen, ziehen wir Herrn Cohen zu Rate:\n\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\nDanke, Herr Cohen!\n\n9.12.6 Priori-Verteilung für m10.10 und Modelldefinition\nStan hat für uns folgende Prioris ausgesucht:\n\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWie gesagt, Stan nimmt dafür einfach die empirischen Mittelwerte und Streuungen her16.\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. Gleichung 9.2.\n\\[\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{9.2}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.10. Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuführen.\n\n9.12.7 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar für einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkärt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich u. a. 2020) zurück (s. Anhang für Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem “statistischen Effekt” gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenhänge, und nicht um kausale Zusammenhänge, handelt. Kausale Zusammenhänge dürfen wir nur verkünden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafür finden oder c) wir ein Experiment fachgerecht durchgeführt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.13 Vertiefung",
    "text": "9.13 Vertiefung\n🏎️VERTIEFUNG, nicht prüfungsrelevant🏎️\n\n9.13.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\\[b = r \\frac{sd_x}{sd_y}\\]\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die Punktschätzer für die Regressionskoeffizienten:\n\nm10.11 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.11)\n##  (Intercept)     mom_iq_z \n## 0.0002786206 0.4483327620\n\nVergleichen Sie diese Werte mit der Korrelation, s. Tabelle 9.15.17\n\nkidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelle 9.15: Correlation Matrix (pearson-method)\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n9.13.2 Prüfen der Linearitätsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen Prädiktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression häufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schätzen (Gelman, Hill, und Vehtari 2021).\nIst die Linearitätsannahme erfüllt, so sollte der Residualplot nur zufällige Streuung um \\(y=0\\) herum zeigen, s. Abbildung 9.25.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsächlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\nkidiq %&gt;% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildung 9.25: Die Verteilung der Fehler scheint keinem starken Trend (in Abhängigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine größeren Auffälligkeiten.\n\n9.13.3 Modellprüfung mit der PPV\n\npp_check(m10.10)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht häufig.\n\n9.13.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildung 9.26: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildung 9.26 zeigt in der oberen Reihe die Regression eines Prädiktors auf den anderen Prädiktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhängt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhängt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n9.13.5 Bayesianisch gleich Frequentistisch?\nÜbrigens liefern stan_glm() und lm oft ähnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch ähnlich sein können, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.14 Fazit",
    "text": "9.14 Fazit\n\n9.14.1 Austieg: Bayes in fünf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\n📺 Musterlösung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\n📺 Musterlösung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n9.14.2 Ausblick: Binäre AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: Hängen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\ndata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m13: am ~ mpg_z:\n\nm13 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nmtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nneg_am &lt;- predict(m13, newdata = tibble(mpg_z = -1.3))\n\nFür kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte für am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. Müssen wir mal bei Gelegenheit besser machen.\n\n9.14.3 Weiterführende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman, Hill, und Vehtari (2021), Kap. 10, insbesondere 10.3.\n\n9.14.4 Genug für heute\nWir waren fleißig …\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der Schlüssel zum Erfolg.\n\n\nGenug für heute. 👍\n\n9.14.5 Vertiefung\nGelman, Hill, und Vehtari (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit führenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig überschaubarem mathematischen Aufwand.\nFür das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.15 Aufgaben",
    "text": "9.15 Aufgaben\n\nAnova-skalenniveau\nNullhyp-Beispiel\nttest-skalenniveau\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nstan_glm_parameterzahl\nstan_glm_prioriwerte\nzwert-berechnen\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope-regr\nrope1\nrope2\nrope3\nrope4",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n9  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.16 —",
    "text": "9.16 —\n\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. „R-Squared for Bayesian Regression Models“. The American Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, und Sam Brilleman. 2020. „Rstanarm: Bayesian Applied Regression Modeling via Stan.“ https://mc-stan.org/rstanarm.\n\n\nKruschke, John K. 2018. „Rejecting or Accepting Parameter Values in Bayesian Estimation“. Advances in Methods and Practices in Psychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  }
]