[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "Bayes:Start!\n\n\n\n\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n\n\n\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\n\n\n\n\nInstallieren Sie R und seine Freunde.\nInstallieren Sie die folgende R-Pakete:\n\ntidyverse\nrstanarm\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\n\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.\n\n\n\n\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen wÃ¤hrend des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von ArbeitsbeitrÃ¤gen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      Nr\n      Thema\n      Datum\n      Kommentar\n    \n  \n  \n    1\nWas ist Inferenz?\n3. - 7. Okt. 2022\nDie erste Unterrichtsstunde fÃ¤llt auf den 7. Okt. 2023.\n    2\nWahrscheinlichkeit\n10. - 14. Okt. 22\nNA\n    3\nHallo, Bayes\n17. - 21. Okt. 22\nNA\n    4\nDie Post befragen\n24. - 28. Okt. 22\nNA\n    5\nGauss-Modelle\n31. Okt. - 4. Nov. 22\nNA\n    6\nLineare Modelle\n7. - 11. Nov. 22\nNA\n    NA\nBLOCKWOCKE\n14. - 18. Nov. 22\nKein regulÃ¤rer Unterricht\n    7\nMetrische AV\n21. - 25. Nov. 22\nNA\n    8\nFallstudien\n28. Nov. - 2. Dez. 22\nNA\n    9\nKausalinferenz 1\n5. Dez. - 9. Dez. 22\nNA\n    10\nKausalinferenz 2\n12. - 16. Dez. 22\nNA\n    11\nBinÃ¤re AV\n19. - 23. Dez. 22\nNA\n    NA\nWEIHNACHTSFERIEN\nNA\nKein Unterricht\n    12\nAbschluss\n9. Jan. 23 - 13. Jan. 23\nNA\n  \n  \n  \n\n\n\n\n\n\n\nPro Thema wird Literatur ausgewiesen.\n\n\n\n\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2022-09-06\n pandoc   2.19.2 @ /usr/local/bin/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.2.0)\n cli           3.3.0      2022-04-25 [1] CRAN (R 4.2.0)\n colorout    * 1.2-2      2022-06-13 [1] local\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.0)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.16       2022-08-09 [1] CRAN (R 4.2.0)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n ggplot2       3.3.6.9000 2022-09-05 [1] Github (tidyverse/ggplot2@a58b48c)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt            0.7.0      2022-08-25 [1] CRAN (R 4.2.0)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.0      2022-02-22 [1] CRAN (R 4.2.0)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.0)\n lifecycle     1.0.2      2022-09-05 [1] Github (r-lib/lifecycle@f92faf7)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n purrr         0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n readxl        1.4.1      2022-08-17 [1] CRAN (R 4.2.0)\n rlang         1.0.5      2022-08-31 [1] CRAN (R 4.2.0)\n rmarkdown     2.16       2022-08-24 [1] CRAN (R 4.2.0)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.0)\n sass          0.4.2      2022-07-16 [1] CRAN (R 4.2.0)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyselect    1.1.2      2022-02-21 [1] CRAN (R 4.2.0)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n vctrs         0.4.1      2022-04-13 [1] CRAN (R 4.2.0)\n xfun          0.32       2022-08-10 [1] CRAN (R 4.2.0)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.0)\n\n [1] /Users/sebastiansaueruser/Rlibs\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "Pruefung.html",
    "href": "Pruefung.html",
    "title": "1Â  PrÃ¼fung",
    "section": "",
    "text": "Die PrÃ¼fungsleistung besteht aus einer Open-Book-PrÃ¼fung."
  },
  {
    "objectID": "Pruefung.html#grundsÃ¤tzlichkeit",
    "href": "Pruefung.html#grundsÃ¤tzlichkeit",
    "title": "1Â  PrÃ¼fung",
    "section": "1.2 GrundsÃ¤tzlichkeit",
    "text": "1.2 GrundsÃ¤tzlichkeit\nDie folgenden Hinweise gelten grundsÃ¤tzlich, d.h. soweit nicht anders in der jeweiligen PrÃ¼fung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von PrÃ¼fungshinweisen kann zu Punkteabzug oder Nichtbestehen fÃ¼hren."
  },
  {
    "objectID": "Pruefung.html#wiederholungsprÃ¼fungen",
    "href": "Pruefung.html#wiederholungsprÃ¼fungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.3 WiederholungsprÃ¼fungen",
    "text": "1.3 WiederholungsprÃ¼fungen\n\nWenn Sie bei einer PrÃ¼fung durchgefallen sein sollten, so haben Sie grundsÃ¤tzlich die MÃ¶glichkeit, die PrÃ¼fung zu wiederholen.\nDenken Sie daran, sich rechtzeitig fÃ¼r PrÃ¼fungsleistungen anzumelden; beachten Sie die Fristen.\nDie Termine fÃ¼r die WiederholungsprÃ¼fungen werden stets zusammen/zeitgleich mit denen der regulÃ¤ren PrÃ¼fungen in Primuss bekannt gegeben.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine WiederholungsprÃ¼fung nur fÃ¼r Studentis, die durchgefallen sind. Abweichend davon kann ei Dozenti die PrÃ¼fung fÃ¼r alle Studentis anbieten. Die Entscheidung, ob eine WiederholungsprÃ¼fung in diesem Fall angeboten wird, obliegt der Dozentin bzw. dem Dozenten des Moduls.\nRelevanter Stoff und formale Bedingungen (wie PrÃ¼fungsform) sind grundsÃ¤tzlich identisch zur letzten abgehaltenen PrÃ¼fung des Moduls (d.h. sofern nicht anders angegeben). Daher sind WiederholungsprÃ¼fungen vom Anspruch vergleichbar wie die regulÃ¤re Klausur. Die PrÃ¼fungen sollen mÃ¶glichst gleich vom Anspruch sein, um Fairness zu gewÃ¤hrleisten.\nBeachten Sie immer die Hinweise, die fÃ¼r die WiederholungsprÃ¼fung angegeben sind. Im Einzelfall keine eine WiederholungsprÃ¼fung von der vorherigen PrÃ¼fung stÃ¤rker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen WiederholungsprÃ¼fung verÃ¶ffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine WiederholungsprÃ¼fung. Stattdessen kÃ¶nnen Sie ggf. an der regulÃ¤ren Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist mÃ¶glich, dass der Stoff sich dann substanziell Ã¤ndert; meist halten sich die Ã„nderungen (im Stoff) aber in Rahmen.\nSprechen Sie die Moduldozentis an fÃ¼r Details zur PrÃ¼fung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine PrÃ¼fung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben, es kommt auf den Einzelfall an. GrundsÃ¤tzlich rate ich aber dazu, PrÃ¼fungen nicht zu verschieben: SchlieÃŸlich kÃ¶nnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum PrÃ¼fungsrecht sprechen Sie bitte die Studienberatung an."
  },
  {
    "objectID": "Pruefung.html#bearbeitungshinweise",
    "href": "Pruefung.html#bearbeitungshinweise",
    "title": "1Â  PrÃ¼fung",
    "section": "1.4 Bearbeitungshinweise",
    "text": "1.4 Bearbeitungshinweise\n\nVerwenden Sie Standardwerte (defaults) der R-Funktionen.\nRunden Sie ggf. auf eine Dezimalstelle.\nVerwenden Sie Methoden der Bayes-Statistik fÃ¼r inferenzstatistische Analysen.\nGeben Sie keine Prozentzahlen an, sondern Anteile (also nicht â€œ50%â€, sondern â€œ0.5â€ bzw. â€œ0,5â€).\nFindet sich in einer Auswahlliste mÃ¶glicher Antworten nicht die exakte LÃ¶sung, wÃ¤hlen Sie die am besten passende.\nTreffen Sie Annahmen, wo nÃ¶tig.\nDie PrÃ¼fung besteht zu einem groÃŸen Teil aus Multiple-Choice- (MC-)-Aufgaben mit mehreren Antwortoptionen.\nBei Multiple-Choice-Aufgaben (MC-Aufgaben) ist zumeist genau eine Antwortoption auszuwÃ¤hlen aus vier oder fÃ¼nf Antwortoptionen.\nIm Zweifel ist eine Aussage auf den Stoff, so wie im Unterricht behandelt, zu beziehen.\nBei Fragen zu R-Syntax spielen Aspekte wie Enter-Taste o.Ã„. bei der Beantwortung der Frage keine Rolle; diese Aspekte dÃ¼rfen zu ignorieren.\nJede Aussage einer MC-Aufgabe ist entweder richtig oder falsch (aber nicht beides oder keines).\nDie MC-Aufgaben sind nur mit Kreuzen zu beantworten; Text wird bei der Korrektur nicht berÃ¼cksichtigt.\nJede Aussage gilt ceteris paribus (unter sonst gleichen UmstÃ¤nden). Aussagen der Art â€A ist Bâ€œ (z.B. â€œMenschen sind sterblichâ€) sind nur dann als richtig auszuwÃ¤hlen, wenn die Aussage immer richtig ist.\nBei Aufgaben, die eine Zahl als Antwort verlangen, ist nur eine Zahl anzugeben (nicht etwa Buchstaben).\nFalls Sie bei einer Aufgabe mehrere Antworten finden, aber nur nach einer gefragt ist, geben Sie nur eine an.\nFalls mehrere (widersprÃ¼chliche) Antworten gegeben wurden, wird im Zweifel die erst genannte gewertet.\nDie Aufgabenstellung in einer Moodle-PrÃ¼fung wird erst sichtbar, wenn Sie den PrÃ¼fungsbedingungen zugestimmt haben und die PrÃ¼fungszeit begonnen hat.\nJe nach Spracheinstellung in Moodle kann es sein, dass Sie als Dezimaltrennzeichen ein Komma oder einen Punkt verwenden mÃ¼ssen. Moodle weist Sie, wenn Sie die Aufgabe verlassen, darauf hin, falls eine Zahl nicht als Zahl erkannt wurde."
  },
  {
    "objectID": "Pruefung.html#teilnahmebedingungen",
    "href": "Pruefung.html#teilnahmebedingungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.5 Teilnahmebedingungen",
    "text": "1.5 Teilnahmebedingungen\n\nDie PrÃ¼fung ist selbstÃ¤ndig, also alleine nur durch Sie, ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der PrÃ¼fung sind einzuhalten.\nEs dÃ¼rfen nur die explizit als zulÃ¤ssig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulÃ¤ssigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, BÃ¼cher sowie Quellen aus dem Internet.\nDie Ãœbernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wÃ¶rtliche Ãœbernahme (â€œcopy-pasteâ€) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulÃ¤ssig.\nBei technischen Problemen ist sofort der PrÃ¼fer bzw. die PrÃ¼ferin zu verstÃ¤ndigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die PrÃ¼fung bzw. Teile daraus (z.B. PrÃ¼fungsfragen) zu speichern oder weiterzugeben.\nIm Ãœbrigen gelten die allgemeinen PrÃ¼fungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht PrÃ¼flingen, kommuniziert werden wÃ¤hrend der PrÃ¼fung. Dies gilt auch fÃ¼r den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den PrÃ¼fer, wenn Sie meinen, es liege ein technisches Problem vor.\nDas Nichtbeachten der Regeln kann zu Notenabzug oder Nichtbestehen fÃ¼hren."
  },
  {
    "objectID": "Pruefung.html#organisatorische-hinweise",
    "href": "Pruefung.html#organisatorische-hinweise",
    "title": "1Â  PrÃ¼fung",
    "section": "1.6 Organisatorische Hinweise",
    "text": "1.6 Organisatorische Hinweise\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prÃ¼fungsrelevant.\nIm Ãœbrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung fÃ¼r formale oder rechtliche Fragen.\nWÃ¤hrend der PrÃ¼fung werden nur Fragen beantwortet, die fÃ¼r die Bearbeitung zwingend nÃ¶tig sind (etwa bei technischen Problemen).\nEs werden keine Fragen der Art â€œIst diese Aufgabe klar formuliert?â€ beantwortet wÃ¤hrend der PrÃ¼fung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der PrÃ¼fung=. Der PrÃ¼fer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der PrÃ¼fung ist nur mÃ¶glich, wenn Sie den Teilnahmebedingungen der PrÃ¼fung zustimmen.\nDie Aufgabenstellung der PrÃ¼fung wird nur wÃ¤hrend des PrÃ¼fungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppenteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte PrÃ¼fungsuhrzeit (Beginn, Ende).\nPrÃ¼fungszeitraum, Aufgabenstellung und sonstige Materialien kÃ¶nnen variieren zwischen den PrÃ¼flingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusÃ¤tzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der PrÃ¼fung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor erhÃ¶ht."
  },
  {
    "objectID": "Pruefung.html#open-book-prÃ¼fungen",
    "href": "Pruefung.html#open-book-prÃ¼fungen",
    "title": "1Â  PrÃ¼fung",
    "section": "1.7 Open-Book-PrÃ¼fungen",
    "text": "1.7 Open-Book-PrÃ¼fungen\nEinige PrÃ¼fungen werden als â€œTake-home-PrÃ¼fungâ€ im â€œOpen-Book-Formatâ€ geschrieben. Was bedeutet dies?\nâ€œTake-home-PrÃ¼fungâ€: Sie bearbeiten die PrÃ¼fung in Ihrem privaten Umgebung in Moodle oder in RÃ¤umlichkeiten der Hochschule. Eine Ãœberwachung per Kamera findet nicht statt.\nâ€œOpen-Book-PrÃ¼fungâ€: Sie dÃ¼rfen Hilfsmittel wie BÃ¼cher und Folien wÃ¤hrend der PrÃ¼fung nutzen.\nIhre PrÃ¼ferin/Ihr PrÃ¼fer informiert Sie Ã¼ber das Format Ihrer PrÃ¼fung."
  },
  {
    "objectID": "Pruefung.html#zeitrahmen-der-prÃ¼fung",
    "href": "Pruefung.html#zeitrahmen-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.8 Zeitrahmen der PrÃ¼fung",
    "text": "1.8 Zeitrahmen der PrÃ¼fung\nDie PrÃ¼fung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die PrÃ¼fung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). VerspÃ¤tete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der PrÃ¼fung wird Ihnen von Ihrer PrÃ¼ferin bzw. Ihrem PrÃ¼fer bekannt gegeben."
  },
  {
    "objectID": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prÃ¼fung",
    "href": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.9 Technische und organisatorische Anforderungen einer Open-Book-PrÃ¼fung",
    "text": "1.9 Technische und organisatorische Anforderungen einer Open-Book-PrÃ¼fung\nUm an einer Open-Book-PrÃ¼fung teilzunehmen, benÃ¶tigen Sie IT-Ausstattung sowie RÃ¤umlichkeiten. An IT-Ausstattung benÃ¶tigen Sie einen Computer mit Internetanschluss; ein Smartphone reicht nicht aus. Nutzen Sie Ihr eigenes GerÃ¤t (Computer) fÃ¼r die PrÃ¼fung; die Hochschule stellt Ihnen keinen Computer zur VerfÃ¼gung. Sie benÃ¶tigen keine Webcam und kein Mikrofon. Ein Tablett oder Smartphone reicht nicht fÃ¼r die PrÃ¼fung. An Software benÃ¶tigen Sie Zugang zu Ihrem Moodle-Konto, was einen aktuellen Internet-Browser voraussetzt. Zu den organisatorischen Anforderungen gehÃ¶ren ein Raum, in dem Sie die PrÃ¼fung ungestÃ¶rt bearbeiten kÃ¶nnen sowie ein Internetanschluss zum Bearbeiten der Klausur in Moodle. Bitte benutzen Sie wÃ¤hrend der PrÃ¼fung nicht den ZurÃ¼ck-Button in Ihrem Browser, wenn Sie zu einer vorherigen Frage zurÃ¼ckgehen wollen. Nutzen Sie die in der PrÃ¼fung zur VerfÃ¼gung gestellten Funktionen/Buttons dafÃ¼r."
  },
  {
    "objectID": "Pruefung.html#technische-probleme-wÃ¤hrend-der-prÃ¼fung",
    "href": "Pruefung.html#technische-probleme-wÃ¤hrend-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.10 Technische Probleme wÃ¤hrend der PrÃ¼fung",
    "text": "1.10 Technische Probleme wÃ¤hrend der PrÃ¼fung\nIm Falle eines technischen Problems auf Seiten der PrÃ¼fungsinfrastruktur ist sofort der PrÃ¼fer zu informieren. Ein Beispiel fÃ¼r so ein Problem wÃ¤re etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der PrÃ¼fer bzw. die Hochschule keine GewÃ¤hr Ã¼bernimmt fÃ¼r Probleme mit Ihrer eigenen Ausstattung."
  },
  {
    "objectID": "Pruefung.html#prÃ¼fungsrecht",
    "href": "Pruefung.html#prÃ¼fungsrecht",
    "title": "1Â  PrÃ¼fung",
    "section": "1.11 PrÃ¼fungsrecht",
    "text": "1.11 PrÃ¼fungsrecht\nFÃ¼r die Open-Book-PrÃ¼fungg gilt die aktuelle PrÃ¼fungsordnung; die Open-Book-PrÃ¼fung fÃ¤llt nicht unter die BayFEV."
  },
  {
    "objectID": "Pruefung.html#datenschutz",
    "href": "Pruefung.html#datenschutz",
    "title": "1Â  PrÃ¼fung",
    "section": "1.12 Datenschutz",
    "text": "1.12 Datenschutz\nPersÃ¶nliche Daten werden an eine Stellen Ã¼bermittelt: Moodle (Ã¼ber bzw. in Ihre Konto). Es findet keine Ãœberwachung statt, weder kamaragestÃ¼tzt, akustisch oder softwaregestÃ¼tzt."
  },
  {
    "objectID": "Pruefung.html#plagiatskontrolle",
    "href": "Pruefung.html#plagiatskontrolle",
    "title": "1Â  PrÃ¼fung",
    "section": "1.13 Plagiatskontrolle",
    "text": "1.13 Plagiatskontrolle\nIhre PrÃ¼fungsarbeiten kÃ¶nnen auf Plagiate hin untersucht werden. Dabei kommen auch automatisierte Verfahren zum Einsatz. Ihre Arbeiten werden dabei nicht online gestellt und auch nicht Dritten zugÃ¤nglich gemacht. Alle PrÃ¼fungen finden auf Rechnern statt, zu denen nur die PrÃ¼fer/innen Zugang habe. Es werden keine persÃ¶nlichen Daten (von Ihnen) weitergegeben.\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Ãœberlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getÃ¤uscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafÃ¼r bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit â€œnicht bestandenâ€ bewertet). Die genauen Konsequenzen legt die PrÃ¼fungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire PrÃ¼fung heiÃŸt: Gleiche Chancen fÃ¼r alle, und gute Leistung soll belohnt werden, TÃ¤uschung nicht."
  },
  {
    "objectID": "Pruefung.html#typische-fehler-in-der-prÃ¼fung",
    "href": "Pruefung.html#typische-fehler-in-der-prÃ¼fung",
    "title": "1Â  PrÃ¼fung",
    "section": "1.14 Typische Fehler in der PrÃ¼fung",
    "text": "1.14 Typische Fehler in der PrÃ¼fung\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heiÃŸt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heiÃŸt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter â€œEnvironmentâ€ angezeigt wird. AuÃŸerdem kÃ¶nnen Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort kÃ¶nnen Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das Paket gestartet zu haben: Mit data(datensatz) kÃ¶nnen Sie den Datensatz datensatz nur dann verfÃ¼gbar machen, wenn das Paket, in dem datensatz â€œwohntâ€, mit library(paketname) gestartet worden ist. So â€œwohntâ€ z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Ãœbung (und weitere ErklÃ¤rung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins."
  },
  {
    "objectID": "Pruefung.html#hinweise-zu-scheinmÃ¤ngeln",
    "href": "Pruefung.html#hinweise-zu-scheinmÃ¤ngeln",
    "title": "1Â  PrÃ¼fung",
    "section": "1.15 Hinweise zu ScheinmÃ¤ngeln",
    "text": "1.15 Hinweise zu ScheinmÃ¤ngeln\nImmer wieder kommt es vor, dass Studierende Beanstandungen zu einer PrÃ¼fung vorbringen. Teilweise sind diese gerechtfertigt, teilweise nicht. Im Folgenden sehen Sie eine Auswahl an nicht gerechtfertigten Beanstandungen, also nur scheinbaren MÃ¤ngeln, keine wirklichen MÃ¤ngel, in einer PrÃ¼fung.\n\nâ€œDas zu wÃ¤hlende Vorgehen war nicht 100% klarâ€ â€“ Wenn Sie der Meinung sind, dass das zu wÃ¤hlende Vorgehen (zum LÃ¶sen der Aufgabe) nicht komplett klar ist, treffen Sie Annahmen und weisen Sie darauf hin, dass Sie Annahmen getroffen haben. Zum anderen halten Sie sich an das Vorgehen aus dem Unterricht (bzw. den Unterlagen und der Literatur, die im Unterricht verwendet wurde). Eine andere Situation lÃ¤ge vor, wenn die Aufgabe nicht lÃ¶sbar ist ohne weitere Angaben lÃ¶sbar ist(â€œIst ein Effekt bei n=100 signifikant?â€). Im Falle einer nicht lÃ¶sbaren Aufgabe liegt fer Fehler beim PrÃ¼fer.\nâ€œIch sollte einen Punkt (ein Komma) als Dezimaltrennzeichen verwenden, aber Moodle hat ein Komma (einen Punkt) verlangt!â€ â€“ Je nach Spracheinstellung in Moodle kann es sein, dass Moodle nur einen Punkt als Dezimaltrennzeichen bzw. ein Komma als Dezimaltrennzeichen verwendet. Moodle weist Sie aber darauf hin, wenn eine Zahl nicht als Zahl erkannt wird, und zwar wenn Sie zur nÃ¤chsten Aufgabe geben. Sie kÃ¶nnen also ohne Probleme den Fehler korrigieren. DarÃ¼ber hinaus ist bei den PrÃ¼fungshinweisen vorab auf diesen Punkt verwiesen."
  },
  {
    "objectID": "Inferenz.html",
    "href": "Inferenz.html",
    "title": "2Â  Inferenz",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Inferenz.html#lernsteuerung",
    "href": "Inferenz.html#lernsteuerung",
    "title": "2Â  Inferenz",
    "section": "2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Definition von Inferenzstatistik sowie Beispiele fÃ¼r inferenzstatistische Fragestellungen nennen\nzentrale Begriffe nennen und in GrundzÃ¼gen erklÃ¤ren\nden Nutzen von Inferenzstatistik nennen\nerlÃ¤utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nauch anhand von Beispielen erklÃ¤ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs.Â Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklÃ¤ren kÃ¶nnen"
  },
  {
    "objectID": "Inferenz.html#wozu-ist-statistik-Ã¼berhaupt-da",
    "href": "Inferenz.html#wozu-ist-statistik-Ã¼berhaupt-da",
    "title": "2Â  Inferenz",
    "section": "2.2 Wozu ist Statistik Ã¼berhaupt da?",
    "text": "2.2 Wozu ist Statistik Ã¼berhaupt da?\nJa, diese Frage haben Sie sich auch schon mal gestellt?\nAbb. FigureÂ 2.1 gibt einen Ãœberblick Ã¼ber die Ziele der Statistik.\n\n\n\n\n\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n\n\n\n\n\nFigureÂ 2.1: A taxonomy of statistical goals\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nZiele exsitieren nicht â€œin echtâ€ in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heiÃŸt, dass man sich nach Beliebem Ziele ausdenken kann. Allerdings hÃ¼lfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen Ã¼berzeugen kann."
  },
  {
    "objectID": "Inferenz.html#was-ist-inferenz",
    "href": "Inferenz.html#was-ist-inferenz",
    "title": "2Â  Inferenz",
    "section": "2.3 Was ist Inferenz?",
    "text": "2.3 Was ist Inferenz?\n\n2.3.1 Inferenz als Generalisieren\nStatistische Inferenz sieht sich drei â€œHerausforderungenâ€ gegenÃ¼ber, laut Gelman, Hill, and Vehtari (2021), Kap. 1.1. Diese betreffen das SchlieÃŸen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\nVon der Stichprobe aus die Grundgesamtheit (Population)\nVon der Experimental- auf die Kontrollgruppe (Kausalinferenz)\nVon einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs beschÃ¤ftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n\n\n\nImportant\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlieÃŸen, bzw. vom Konrketen auf das Abstrakte."
  },
  {
    "objectID": "Inferenz.html#stichprobe-vs.-population",
    "href": "Inferenz.html#stichprobe-vs.-population",
    "title": "2Â  Inferenz",
    "section": "2.4 Stichprobe vs.Â Population",
    "text": "2.4 Stichprobe vs.Â Population\nNehmen wir an, wir mÃ¶chten Herausfinden, wie groÃŸ der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A1\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\nWir mÃ¼ssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe fÃ¼r die Grundgesamtheit schlieÃŸen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. FigureÂ 2.2.\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nFigureÂ 2.2: Population vs.Â sample (Image credit: Karsten Luebke)\n\n\nHÃ¤ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!2. Man schreibt: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei reprÃ¤sentativ fÃ¼r die Grundgesamtheit aller Studierender. Messerscharf schlieÃŸen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n2.4.1 Deskriptiv- vs.Â Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtigungen kÃ¶nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. FigureÂ 2.3. Einteilungen in Schubladen existieren nicht auf der Welt, sondern in unserem Kopf: Sie besitzen keine ontologische RealitÃ¤t, sondern eine epistemologische. Sie sind frei, sich andere Einteilungen der Statistik auszudenken. Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee Ã¼berzeugen kann.\n\n\n\nFigureÂ 2.3: Deskriptiv- vs.Â Inferenzstatistik\n\n\nDeskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\nInferenzstatistik schlieÃŸt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\nğŸ‹ SchlieÃŸen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n2.4.2 Wozu ist die Inferenstatistik gut?\n\n\n\n\n\n\nNote\n\n\n\nInferenz bedeutet SchlieÃŸen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine SchlÃ¼sse zu ziehen.\nğŸ‹ï¸ï¸ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Ãœben Sie jetzt schon mal.\n\n\n2.4.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFÃ¼r jede Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle TableÂ 2.1.\n\n\n\n\nTableÂ 2.1: Bezeichnungen fÃ¼r Kennwerte\n\n\nKennwert\nStichprobe\nGrundgesamtheit\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\n\n\n\n\n\nFÃ¼r Statistiken (Stichprobe) verwendet man lateinische Buchstaben; fÃ¼r Parameter (Population) verwendet man griechische Buchstaben.\nğŸ‹ï¸ Geben Sie die griechischen Buchstaben fÃ¼r typische Statistiken an!\n\n\n2.4.4 SchÃ¤tzen von Parametern einer Grundgesamtheit\nMeist begnÃ¼gt man sich beim Analysieren von Daten nicht mit Aussagen fÃ¼r eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit SchÃ¤tzungen begnÃ¼gen.\nSchÃ¤tzwerte werden mit einem â€œDachâ€ Ã¼ber dem Kennwert gekennzeichnet, z.B.\n\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchÃ¤tzwert\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n2.4.5 Beispiele fÃ¼r inferenzstatistische Fragestellungen\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.Â V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\).\nDie Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} > \\bar{X}_{V2}\\)\nSind diese Unterschiede â€œzufÃ¤lligâ€ oder â€œsubstanziellâ€? Gilt also \\(\\mu_{V1} > \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)?\nWie groÃŸ ist die Wahrscheinlichkeit3 \\(Pr(\\mu_{V1} > \\mu_{V2})\\)?\n\nğŸ‹ï¸ Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!"
  },
  {
    "objectID": "Inferenz.html#modellieren",
    "href": "Inferenz.html#modellieren",
    "title": "2Â  Inferenz",
    "section": "2.5 Modellieren",
    "text": "2.5 Modellieren\n\n2.5.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft, wie auch oft in der Technik, Wirtschaft oder im Alltag, betrachtet man einen Teil der Welt nÃ¤her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berÃ¼cksichtigen ist nicht mÃ¶glich. Wir mÃ¼ssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nÃ¶tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die fÃ¼r unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\n\n\n\n\n\nImportant\n\n\n\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n\n\nAuf die Statistik bezogen heiÃŸt das, dass man einen Datensatz zu zusammenfasst, dass man das Wesentliche erkennt. Was ist das â€œWesentlicheâ€? Meist interessiert man sich fÃ¼r die Ursachen eines PhÃ¤nomens? Etwa: â€œWie kommt es bloÃŸ, dass ich ohne zu lernen die Klausur so gut bestanden habe?â€4 Noch allgemeiner ist vom hÃ¤ufig am Zusammenhang von X und Y interessiert, s. Abb. FigureÂ 2.4, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\nFigureÂ 2.4: Sinnbild eines stastistischen Modells\n\n\n\n\nDas Diagramm hat Sie nicht so vom Hocker? Okay, ein statistisches Modell kann natÃ¼rlich komplexer sein, z.B. wie in Abb. FigureÂ 2.5 dargestellt.\n\n\n\n\n\nflowchart LR\nX1 --> Y\nX2 --> Y\n\n\n\n\n\nFigureÂ 2.5: Sinnbild eines stastistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\n\n\nEs hÃ¶rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n\n2.5.2 Vertiefung\nLesen Sie die EinfÃ¼hrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nNote\n\n\n\nNutzen Sie die Ãœbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch."
  },
  {
    "objectID": "Inferenz.html#regression",
    "href": "Inferenz.html#regression",
    "title": "2Â  Inferenz",
    "section": "2.6 Regression",
    "text": "2.6 Regression\n\n\n\nOne regression\n\n\n\n2.6.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmessen: FÃ¼r vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schÃ¶ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nNote\n\n\n\nRegression + Inferenz = ğŸ’–\n\n\nAlternativ zur Regression kÃ¶nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni MÃ¼nster als Ausschnitt (!) aufgefÃ¼hrt.\nAuf dieser Basis kann man meditieren, welches statistischen Verfahren man fÃ¼r eine bestimmte Fragestellung verwenden sollte, s. Abb. FigureÂ 2.6.\n\n\n\nFigureÂ 2.6: WÃ¤hle deine Statistik mit Bedacht\n\n\n\n\n2.6.2 Viele statistische Verfahren sind SpezialfÃ¤lle der Regression\nWie Jonas Kristoffer LindelÃ¸v uns erklÃ¤rt, sind viele statistische Verfahren, wie der sog. t-Test SpezialfÃ¤lle der Regression, s. Abb. FigureÂ 2.7.\n\n\n\nFigureÂ 2.7: Common statistical tests as linear models\n\n\n\n\n2.6.3 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; Abb. FigureÂ 2.8.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nAnhan der Gleichung erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet. Dabei wird X nicht mit â€œfortgeschrittenenâ€ Transformationen wie Quadradieren oder Exponenzieren beglÃ¼ckt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n\n\n\nFigureÂ 2.8: Die Regressionsgerade in voller Pracht"
  },
  {
    "objectID": "Inferenz.html#unsicherheit",
    "href": "Inferenz.html#unsicherheit",
    "title": "2Â  Inferenz",
    "section": "2.7 Unsicherheit",
    "text": "2.7 Unsicherheit\n\n2.7.1 Inferenz beinhaltet Unsicherheit\nInferenzstatistische SchlÃ¼sse sind mit Unsicherheit behaftet: SchlieÃŸlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), mÃ¶chte aber vom Teil auf das Ganze schlieÃŸen.\n\n\n\n\n\n\nImportant\n\n\n\nNichts Genaues weiÃŸ man nicht: SchlieÃŸt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen Ã¼ber das Ganze betrifft.\n\n\nSchlieÃŸt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. SchlieÃŸlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen fÃ¼r die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer mÃ¶glich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n\n\n\n\n\nNote\n\n\n\nUnter einem zufÃ¤lligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nÃ¤chsten WÃ¼rfelwurfs. ZufÃ¤llig bedeutet nicht (zwangslÃ¤ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines WÃ¼rfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\nğŸ‹ Welche physikalischen Randbedingungen wirken wohl auf einen MÃ¼nzwurf ein?\n\n\n2.7.2 Beispiele zur Quantifizierung von Ungewissheit\nAussagen mit Unsicherheit kÃ¶nnen unterschiedlich prÃ¤zise formuliert sein.\n\nMorgen regnetâ€™s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert fÃ¼r Methode \\(A\\) hÃ¶her als fÃ¼r Methode \\(B\\).\nDie Maschine fÃ¤llt demnÃ¤chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nÃ¤chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\nğŸ‹ Geben Sie weitere Beispiele an!\n\n\n2.7.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. FigureÂ 2.9.\n\nWie (un)gewiss ist man sich Ã¼ber den Wert des Regressionsgewichts?\nWie (un)gewiss ist man sich Ã¼ber den Wert von Y? SchlieÃŸlich kÃ¶nnte es ja EinflÃ¼sse (X) geben, die man nicht berÃ¼cksichtigt hat.\n\n\n\n\n\n\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 Ã¼bersehen? .-> B\n\n\n\n\n\n\nFigureÂ 2.9: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n\n2.7.4 Ich weiÃŸ, was ich nicht weiÃŸ: Ungewissheit angeben\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der SchÃ¤tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schÃ¤tzt, lÃ¤sst aber offen wie sicher (prÃ¤zise) die SchÃ¤tzung ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die SchÃ¤tzung schlieÃŸt sogar 41% oder 43% aus.\n::callout-important Eine Inferenz nennt man auch SchÃ¤tzung. Es sollte immer die Genauigkeit (Ungewissheit) der SchÃ¤tzung angegeben werden. :::\nIm Rahmen der Regressionsanalyse schlÃ¤gt sich die Ungewissheit an zwei Stellen nieer:\n\nzur Lage der Regressionsgeraden (\\(\\beta_0\\), \\(\\beta_1\\))\nzu EinflÃ¼ssen (X), die unser Modell nicht kennt (\\(\\epsilon, \\sigma\\))\n\n\n\n2.7.5 Visualisierung von Ungewissheit\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem PunktschÃ¤tzer. PunktschÃ¤ter beinhalten keine Angabe der SchÃ¤tz(un)gen auigkeit, s. Abb. FigureÂ 2.10.\n\n\n\n\n\nFigureÂ 2.10: Eine PunktschÃ¤tzung\n\n\n\n\nRot markiert: Die PunktschÃ¤tzung von mpg fÃ¼r hp=200.\nğŸ‹ Geben Sie ein vergleichbares Beispiel an!\n\n\n\nIn Abb. FigureÂ 2.11 ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur StÃ¤rke des Zusammenhangs von X und Y?\n\n\n\n\n\nFigureÂ 2.11: Ungewissheit in den Regressionskoeffizienten\n\n\n\n\nAuch wenn wir uns sicher im Hinblick auf die Regressionsgewichte in Abb. FigureÂ 2.11 bliebe eine Restungewissheit: Unsere SchÃ¤tzungen wÃ¤ren nicht sicher, nicht fehlerfrei. Das liegt daran, da das Modell nicht alle EinflÃ¼sse auf Y berÃ¼cksichtigt, sondern nur einen, hier als X bezeichnet.\nIn Abb. FigureÂ 2.12 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die â€œRestungewissheitâ€ dargestellt. In diesem Fall spricht man von einem â€œVorhersageintervallâ€, da man nicht nur von â€œtypischen FÃ¤llenâ€ auf der Regressiongeraden spricht, sondern fÃ¼r echte FÃ¤lle Vorhersagen (SchÃ¤tzungen) tÃ¤tigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n\n\n\nFigureÂ 2.12: Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\n\n\n\n\nWie man sieht, wird die Ungewissheit grÃ¶ÃŸer, wenn man beide Arten der Ungewissheit berÃ¼cksichtigt.\nDas Vorhersage-Intervall berÃ¼cksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\n\n2.7.6 Konfidenzintervall\nWir sehen hier, dass ein â€œUngewissheitskorridorâ€ angegeben wird. Entsprechend wird nicht ein PunktschÃ¤tzer, sondern ein SchÃ¤tzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich5\nEin Konfidenzintervall wird hÃ¤ufig mit 90% oder 95% Genauigkeit angegeben.\nIm Kontext der Bayes-Analyse ist das einfach zu interpretieren.\nSagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall fÃ¼r den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.\nDieser Befund lÃ¤ÃŸt sich so interpretieren:\nâ€œLaut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.â€\n\n\n\n\n\n\nImportant\n\n\n\nEin Konfidenzintervall gibt einen SchÃ¤tzbereich plausibler Werte fÃ¼r den gesuchten Wert in der Population (den Parameter) an.\n\n\nğŸ‹ Interpretieren Sie den Ungewissheitskorridor!"
  },
  {
    "objectID": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "2Â  Inferenz",
    "section": "2.8 Klassische vs.Â Bayes-Inferenz",
    "text": "2.8 Klassische vs.Â Bayes-Inferenz\n\n2.8.1 Klassische Inferenz: Frequentismus\n\nDie BerÃ¼cksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurÃ¼ckgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein\nWahrscheinlichkeit wird Ã¼ber relative HÃ¤ufigkeiten definiert.\nEs ist nicht mÃ¶glich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie hÃ¤ufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr hÃ¤ufig wiederholt ist.\nEin GroÃŸteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.8.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) flieÃŸt explizit in die Analyse ein (zusammen mit den Daten).\nWenn das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen fÃ¼r Hypothesen mÃ¶glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (fÃ¼r gÃ¤ngige Computer) komfortabel geworden.\n\n\n\n2.8.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.8.3.1 Frequentismus\n\nzentrale Statistik: p-Wert\nâ€œWie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufÃ¤llig verschieden und auf Basis unseres Modells)?â€\nFindet man \\(p<.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von â€œ(statistischer) Signifikanzâ€ und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n\n\n2.8.3.2 Bayes-Statistik\n\nzentrale Statistik: Posteriori-Verteilung\nâ€œWie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Baiss unseres Modells?â€\n\nğŸ‹ Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\n\n\n\n2.8.4 Frequentist und Bayesianer\n\n\n\nFrequentist wettet mit Bayesianer\n\n\nQuelle\n\n\n2.8.5 Der p-Wert ist wenig intuitiv\n\n\nfrom Imgflip Meme Generator\n\n\n\n2.8.6 Beispiel zum Nutzen von Apriori-Wissen 1\n\nEin Betrunkener behauptet, er kÃ¶nne hellsehen.\nEr wirft eine MÃ¼nze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die MÃ¼nze fair ist, dass Ergebnis also â€œzufÃ¤lligâ€ ist.\nUnser Vorwissen lÃ¤sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der ZufÃ¤lligkeit des Ergebnisses wohl nicht verwerfen.\n\n\n\n2.8.7 Beispiel zum Nutzen von Apriori-Wissen 2\n\nEine Studie fand einen â€œgroÃŸen Effektâ€ auf das Einkommen von Babies, eine Stunde pro Woche wÃ¤hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\).\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% hÃ¶her (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lÃ¤sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lÃ¤sst. Wir wÃ¼rden den Effekt lieber in einem konservativeren Intervall schÃ¤tzen (enger um Null)."
  },
  {
    "objectID": "Inferenz.html#literatur",
    "href": "Inferenz.html#literatur",
    "title": "2Â  Inferenz",
    "section": "2.9 Literatur",
    "text": "2.9 Literatur\nBei Gelman, Hill, and Vehtari (2021), Kap. 1 findet sich eine Darstellung Ã¤hnlich zu der in diesem Kapitel."
  },
  {
    "objectID": "Inferenz.html#aufgaben",
    "href": "Inferenz.html#aufgaben",
    "title": "2Â  Inferenz",
    "section": "2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2\ninferenz-fuer-alle\nadjustieren1\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  },
  {
    "objectID": "Wskt.html",
    "href": "Wskt.html",
    "title": "3Â  Wahrscheinlichkeit",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2013. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung ; Mit Aufgaben Und LÃ¶sungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Verteilungen.html",
    "href": "Verteilungen.html",
    "title": "4Â  Verteilungen",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2013. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung ; Mit Aufgaben Und LÃ¶sungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Globusversuch.html",
    "href": "Globusversuch.html",
    "title": "5Â  Globusversuch",
    "section": "",
    "text": "Bayes:Start"
  },
  {
    "objectID": "Globusversuch.html#von-welten-und-golems",
    "href": "Globusversuch.html#von-welten-und-golems",
    "title": "5Â  Globusversuch",
    "section": "5.1 Von Welten und Golems",
    "text": "5.1 Von Welten und Golems\n\n5.1.1 Kleine Welt, groÃŸe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb FigureÂ 5.1.\n\n\n\nFigureÂ 5.1: Behaims Globus: Kein Amerika\n\n\nDie kleine Welt des Modells entsprach hier nicht der groÃŸen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.\n\nKleine Welt vs.Â groÃŸe Welt\n\n\n\n\n\n\nKleine Welt\nGroÃŸe Welt\n\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit\nentspricht nicht (zwangslÃ¤ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt ist nicht die groÃŸe Welt.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.\nğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n\n5.1.2 Der Golem von Prag\n\n\n\nDer Golem von Prag\n\n\nQuelle\nDer Golem von Prag, eine vom Menschen geschaffene Kreatur gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt.\nBei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen.\nBei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.\n\n\n5.1.3 Wissenschaftliche Modelle sind wie Golems\nGolem\n\n\nBesteht aus Lehm\nBelebt durch â€œWahrheitâ€\nMÃ¤chtig\ndumm\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nMÃ¤rchen\n\nModell\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\n\n\n\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mÃ¤chtig\nsimpler als die RealitÃ¤t\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nNicht einmal falsch\n\n\n\n\n\n\n\nImportant\n\n\n\nWir bauen Golems.\n\n\n\n\n5.1.4 So denkt unser Bayes-Golem\n\n\n\nSo denkt unser Bayes-Golem\n\n\nğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!"
  },
  {
    "objectID": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "5Â  Globusversuch",
    "section": "5.2 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.2 Ein erster Versuch: Wir werfen den Globus\n\n5.2.1 Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?\nUnsere Hypothese bzw. unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist?\n\n\n\nDer Erdball\n\n\nQuelle CC 4.0 BY-NC\nSie werden einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie 9 Mal.\nSo sah mein Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!\n\n\n5.2.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten fÃ¼hrt, nennt man den den datengenierende Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der ErdoberflÃ¤che ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie WÃ¼rfe des Globusballes sind unabhÃ¤ngig voneinander.\nWir haben kein Vorwissen Ã¼ber \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\nğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?\n\n\n5.2.3 Ein paar Fachbegriffe\n\nFÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: Priori-Verteilung.\nFÃ¼r jede Hypothese (d.h. jeden Parameterwert \\(p\\)) mÃ¶chten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung1 bekommen.\n\n\n\n\nUpdating mit Bayes\n\n\n\n\n5.2.4 Die Binomialverteilung\nWir nehmen an, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert2.\nDann kann man die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser \\(p\\) betrÃ¤gt, mit der Binomialverteilung berechnen.\nDie Binomialverteilung zeigt die Verteilung der HÃ¤ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten): â€œMÃ¼nzwurfverteilungâ€\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L\\]\n\n\n5.2.5 Binomialverteilung mit R\nWas ist der Anteil der gÃ¼ltigen Pfade (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\ndbinom(x = 6, size = 9, prob = 1/2)\n\n[1] 0.1640625\n\n\nWas ist die Wahrscheinlichkeit fÃ¼r \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\ndbinom(x = 9, size = 9, prob = 1/2)\n\n[1] 0.001953125\n\n\n\n\n5.2.6 Beispiele zur Berechnung einer binomial verteilten Wahrscheinlichkeit\nEi Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?3.\n\ndbinom(x = 15, size = 20, prob = .5)\n\n[1] 0.01478577\n\n\nWas ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen?\n\ndbinom(3, 3, 1/2)\n\n[1] 0.125\n\n\n\n\n5.2.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: â€œW ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)â€. \\(N\\) gibt die Anzahl der GlobuswÃ¼rfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (â€œuniformâ€):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: â€œ\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1â€.\n\n\n5.2.8 So sehen die Verteilungen aus\nAbb. FigureÂ 5.2 zeigt die Binomialverteilung.\n\n\n\n\n\nFigureÂ 5.2: Ein Beispiel fÃ¼r eine Binomialverteilung\n\n\n\n\n\\(N=9, p = 1/2\\)\nAbb. FigureÂ 5.3 zeigt ein Beispiel fÃ¼r eine Gleichverteilung (uniform distribution).\n\n\n\n\n\nFigureÂ 5.3: Gleichverteilung\n\n\n\n\n\\(Min = 0, Max = 1\\)\nğŸ‹ï¸ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear? Was fÃ¤llt Ihnen bei der Gleichverteilung auf?"
  },
  {
    "objectID": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "5Â  Globusversuch",
    "section": "5.3 Zur Erinnerung: Bayes Theorem",
    "text": "5.3 Zur Erinnerung: Bayes Theorem\n\n5.3.1 Herleitung Bayesâ€™ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit fÃ¼r Regen und kalt ist gleich der Wahrscheinlihckeit von Regen, gegeben kalt mal der Wahrscheinlicht von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wennâ€™s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n\n5.3.2 Herleitung Bayesâ€™ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lÃ¶sen auf nach der Posteriori-Wahrscheinlichkeit, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods Ã¼ber alle Werte von \\(p\\). Die Aufgabe dieser GrÃ¶ÃŸe ist nur dafÃ¼r zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n\n5.3.3 Bayesâ€™ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)}\\]\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayesâ€™ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) fÃ¼ttert.\nBayesâ€™ Theorem wird hÃ¤ufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n\n\n5.3.4 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]\n\n\n\nPrior mal Likelihood = Post\n\n\n\n\n5.3.5 Wissen updaten: Wir fÃ¼ttern Daten in das Modell\n\n\n\n\n\n\nUnser Golem lernt\n\n\nUnser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "href": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "title": "5Â  Globusversuch",
    "section": "5.4 Bayes berechnen mit mit der Gitter-Methode",
    "text": "5.4 Bayes berechnen mit mit der Gitter-Methode\nDie Methode Gitter-AnnÃ¤herung nennt man auch Grid Approximation*.\n\n5.4.1 Idee\n\nTeile den Wertebereich des Parameter in ein â€œGitterâ€ auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (â€œGitterwerteâ€).\nBestimme den Priori-Wert des Parameters fÃ¼r jeden Gitterwert.\nBerechne den Likelihood fÃ¼r Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\n\n\n5.4.2 Gitterwerte in R berechnen\n\nd <-\n  tibble(\n    # definiere das Gitter: \n    p_Gitter = seq(from = 0, to = 1, length.out = 10),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %>%  \n    mutate(\n      # berechne Likelihood fÃ¼r jeden Gitterwert:\n      Likelihood = dbinom(6, size = 9, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\nSo sehen unsere â€œGitterdatenâ€ aus:\n\n# | echo: false\nd %>% \n  knitr::kable(digits = 2)\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\nğŸ‹ï¸ Was wohl mit Post passiert, wenn wir Priori Ã¤ndern?\n\n\n5.4.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: â€œPost-Verteilungâ€), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\n\n\n\nJe mehr Gittewerte, desto genauer wird die Verteilung wiedergegeben.\n\n\nMehr Gitterwerte glÃ¤tten die AnnÃ¤herung.\nJe grÃ¶ÃŸer die Stichprobe (\\(N\\)), desto zuverlÃ¤ssiger wird unsere Berechnung.\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer TrÃ¤ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung kÃ¶nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nÃ¤chsten Kapitels.\n\n\n\n5.4.4 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.\n\nğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r \\(W\\) tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)?"
  },
  {
    "objectID": "Post.html",
    "href": "Post.html",
    "title": "6Â  Die Post befragen",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6Â  Die Post befragen",
    "section": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.1.1 Zur Erinnerung: Gitterwerte in R berechnen\n\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nVoilÃ , die Post-Verteilung als Tabelle:\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n6.1.2 Zur Erinnerung, die Gittermethode\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen und \\(k=10\\) Gitterwerten.\nAbb. FigureÂ 6.1 zeigt die resultierende Post-Verteilung.\n\n\n\n\n\nFigureÂ 6.1: Die Postverteilung fÃ¼r W=6, N=9, k=10\n\n\n\n\n\n\n\n\n\n\n  \n    \n      Tabelle d mit Daten zur Posteriori-Verteilung\n    \n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0\n1\n0\n0\n0\n    1 Ã— 10âˆ’1\n1\n1 Ã— 10âˆ’4\n1 Ã— 10âˆ’4\n1 Ã— 10âˆ’4\n    2 Ã— 10âˆ’1\n1\n5 Ã— 10âˆ’3\n5 Ã— 10âˆ’3\n5 Ã— 10âˆ’3\n    3 Ã— 10âˆ’1\n1\n3 Ã— 10âˆ’2\n3 Ã— 10âˆ’2\n4 Ã— 10âˆ’2\n    4 Ã— 10âˆ’1\n1\n1 Ã— 10âˆ’1\n1 Ã— 10âˆ’1\n1 Ã— 10âˆ’1\n    6 Ã— 10âˆ’1\n1\n2 Ã— 10âˆ’1\n2 Ã— 10âˆ’1\n2 Ã— 10âˆ’1\n  \n  \n  \n\n\n\n\n\n\n6.1.3 Beispiele fÃ¼r Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.1.4 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKomplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Integrale, auf die man dabei stÃ¶ÃŸt, treiben einem gestandenen Mathematiker die SchweiÃŸperlen auf die Stirn.\nGlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten.\nPraktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der uns das meiste an Arbeit abnimmt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck.\nLernen wir jetz also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handbaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Diese Verfahren sind aber nicht mehr Gegenstand dieses Kurses.\n\n\n6.1.5 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck.\nBevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErsstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d):\n\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\nDie Wahrscheinlichkeit, einen Parameterwert aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant.\n\n\n\n\n\n\n  \n    \n      Stichprobendaten aus der Post-Verteilung\n    \n    \n      Nur die ersten Zeilen abgebildet\n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0.889\n1\n0.057\n6 Ã— 10âˆ’2\n0.063\n    0.778\n1\n0.204\n2 Ã— 10âˆ’1\n0.227\n    0.778\n1\n0.204\n2 Ã— 10âˆ’1\n0.227\n  \n  \n  \n\n\n\n\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten.\nWie sieht diese Tabelle dann als Histogramm1 aus?\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n\n  [1] 0.89 0.78 0.78 0.56 0.56 0.44 0.78 0.56 0.78 0.56 0.78 0.78 0.78 0.78 0.89\n [16] 0.67 0.78 0.56 0.67 0.56 0.44 0.56 0.67 0.56 0.78 0.44 0.44 0.67 0.67 0.67\n [31] 0.78 0.33 0.56 0.78 0.56 0.78 0.78 0.67 0.67 0.78 0.67 0.56 0.44 0.56 0.78\n [46] 0.67 0.22 0.67 0.56 0.67 0.67 0.78 0.67 0.67 0.11 0.56 0.89 0.67 0.67 0.56\n [61] 0.78 0.67 0.78 0.78 0.89 0.44 0.67 0.33 0.67 0.44 0.44 0.67 0.56 0.56 0.78\n [76] 0.78 0.67 0.89 0.56 0.78 0.78 0.56 0.67 0.67 0.56 0.67 0.44 0.33 0.67 0.56\n [91] 0.56 0.78 0.67 0.89 0.56 0.56 0.56 0.67 0.67 0.44\n\n\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. Abb. FigureÂ 6.2.\n\n\n\n\n\nFigureÂ 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n6.1.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) nach oeben.\nDatensatz samples, \\(n=10^3\\), \\(k=100\\) Gitterwerte, basierend auf dem Modell oben.\n\n\n\n\nsamples_k100 <-\n  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = n,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\n\n\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder.\n\n\n\n\n\n\nNote\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung.\n\nd_k100 %>% \n  slice_sample(n = 1e6, weight_by = post, replace = T) %>% \n  ggplot(aes(x = p_grid)) +\n  geom_density(fill = \"black\") +\n  scale_x_continuous(\"Anteil Wasser (p)\", limits = c(0, 1)) +\n  labs(y = \"\")"
  },
  {
    "objectID": "Post.html#die-post-verteilung-befragen",
    "href": "Post.html#die-post-verteilung-befragen",
    "title": "6Â  Die Post befragen",
    "section": "6.2 Die Post-Verteilung befragen",
    "text": "6.2 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeit (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abb. FigureÂ 6.3 illustriert.\n\n\n\nFigureÂ 6.3: Fragen nach p vs.Â Fragen nach q\n\n\n\n6.2.1 Fragen zu Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nWir filtern einfach die passenden Stichproben und und summieren die Wahrscheinlichkeiten dieser Stichproben:\n\n\n\n\n\nWir zÃ¤hlen (count) einfach die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %>%\n  count(p_grid < .5) \n\n# A tibble: 2 Ã— 2\n  `p_grid < 0.5`     n\n  <lgl>          <int>\n1 FALSE           8250\n2 TRUE            1750\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.\nEinfach wie ğŸ° essen.\nNoch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.5 und 0.75?\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75)\n\n# A tibble: 2 Ã— 2\n  `p_grid > 0.5 & p_grid < 0.75`     n\n  <lgl>                          <int>\n1 FALSE                           4610\n2 TRUE                            5390\n\n\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75) %>% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n# A tibble: 2 Ã— 2\n  Anteil Prozent\n   <dbl>   <dbl>\n1  0.461    46.1\n2  0.539    53.9\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden:\n\nsamples %>% \n  filter(p_grid > .5 & p_grid < .75) %>% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n# A tibble: 1 Ã— 2\n    sum anteil\n  <dbl>  <dbl>\n1 0.539   53.9\n\n\nNoch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nsamples %>% \n  count(p_grid >= .9 & p_grid <= 1) %>% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n# A tibble: 1 Ã— 1\n   prop\n  <dbl>\n1  0.01\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt.\n\n\n6.2.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nImportant\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall (synonym: KompatibilitÃ¤tsintervall oder Passungsbereich).\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% Posteriori-Wahrscheinlichkeit)\n\nsamples %>% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n# A tibble: 1 Ã— 1\n  quantil90\n      <dbl>\n1     0.778\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren:\n\nsamples %>% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchem Parameterwert wir landen:\n\nsamples %>% \n  summarise(\n    quant_10 = quantile(p_grid, 0.05),\n    quant_90 = quantile(p_grid, 0.95))\n\n# A tibble: 1 Ã— 2\n  quant_10 quant_90\n     <dbl>    <dbl>\n1    0.444    0.889\n\n\nSolche Fragen lassen sich mit Hilfe von Quantilen beantworten.\n\n\n6.2.3 Zur Erinnerung: Quantile\nBeispiel: Wie groÃŸ sind die Studentis (Quelle des Datensatzes)? Das Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%:\n\nspeed_gender_height <- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary <- \n  speed_gender_height %>% \n  drop_na(height) %>% \n  summarise(q25 = quantile(height, prob = .25),\n            q50 = quantile(height, prob = .5),\n            q75 = quantile(height, prob = .75))\n\nheight_summary\n\n# A tibble: 1 Ã— 3\n    q25   q50   q75\n  <dbl> <dbl> <dbl>\n1    63    66    69\n\n\nVisualisierung der Quantile:\n\n\n\n\n\n\n\n6.2.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht Ã¼berschritten wird:\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% ab.\nSchaue, was der grÃ¶ÃŸte verbleibende Wert ist.\n\n\nsamples %>% \n  arrange(p_grid) %>%   # sortiere\n  slice_head(n = 9000) %>%  # nur die ersten 90000, also die obersten 1000 abschneiden\n  summarise(p90 = max(p_grid))\n\n# A tibble: 1 Ã— 1\n    p90\n  <dbl>\n1 0.778\n\n\nDas (annÃ¤hernd) gleiche Ergebnis liefert quantile():\n\nsamples %>% \n  summarise(q90 = quantile(p_grid, .9))\n\n# A tibble: 1 Ã— 1\n    q90\n  <dbl>\n1 0.778\n\n\n\n\n6.2.5 Visualisierung der Intervalle\nIntervalle (Bereiche), die die Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle oder Equal-Tails-Intervalle (ETI):"
  },
  {
    "objectID": "Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "href": "Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "title": "6Â  Die Post befragen",
    "section": "6.3 Schiefe Posteriori-Verteilungen sind mÃ¶glich",
    "text": "6.3 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nGehen wir von 3 WÃ¼rfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe):\n\nd_33 <- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %>% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% \n  mutate(unstand_post = likelihood * prior) %>% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 <- \n  d_33 %>% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n    \n  \n  \n    0.99\n1\n0.97\n0.97\n    0.77\n1\n0.46\n0.46\n    0.95\n1\n0.86\n0.86\n    0.59\n1\n0.21\n0.21\n    0.81\n1\n0.53\n0.53\n    0.99\n1\n0.97\n0.97\n  \n  \n  \n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\n\n6.3.1 50%-Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall (PI, auch Equal-Tails-Intervall, ETI, genannt):\n\nqi_50_low <- eti(samples_33$p_grid, ci = .5)$CI_low\nqi_50_up <- eti(samples_33$p_grid, ci = .5)$CI_high\np1 <-\n  d_33 %>% \n  ggplot(aes(x = p_grid, y = post_33)) +\n  # check out our sweet `qi()` indexing\n  geom_area(data = . %>% \n              filter(p_grid > qi_50_low &  \n                    p_grid < qi_50_up),\n            fill = \"grey75\") +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 0, to = 1, by = .1))\n\np1\n\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\nlibrary(easystats)\n\nsamples_33 %>% \n  select(p_grid) %>% \n  eti(ci = .5)\n\nEqual-Tailed Interval\n\nParameter |      50% ETI\n------------------------\np_grid    | [0.71, 0.94]\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.3.2 50%-Intervall hÃ¶chster Dichte\nIntervalle hÃ¶chster Dichte (Highest density Intervals) sind definiert als die schmÃ¤lsten Intervalle, die den gesuchten Parameter enthalten.\n\n\n\n\n\nDer wahrscheinlichste Paramterwert (1) ist im Intervall enthalten, was Sinn macht.\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen:\n\nsamples %>% \n  select(p_grid) %>% \n  bayestestR::hdi(ci = .5)  # aus dem Paket `bayestestR`\n\nWarning: Identical densities found along different segments of the distribution,\nchoosing rightmost.\n\n\nHighest Density Interval\n\nParameter |      50% HDI\n------------------------\np_grid    | [0.67, 0.78]\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich in diesem Bereich befindet (auf Basis eines HDI).\n\n\n\n\n\n\nNote\n\n\n\nDas R-Paket {bayestestR} ist Teil des Meta-Pakets {easystats}. Es reicht, wenn Sie easystats laden, damit wird bayestestR automatisch geladen."
  },
  {
    "objectID": "Post.html#intervalle-hÃ¶chster-dichte-vs.-perzentilintervalle",
    "href": "Post.html#intervalle-hÃ¶chster-dichte-vs.-perzentilintervalle",
    "title": "6Â  Die Post befragen",
    "section": "6.4 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle",
    "text": "6.4 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich\nPerzentilintervalle sind verbreiteter\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse"
  },
  {
    "objectID": "Post.html#punktschÃ¤tzungen",
    "href": "Post.html#punktschÃ¤tzungen",
    "title": "6Â  Die Post befragen",
    "section": "6.5 PunktschÃ¤tzungen",
    "text": "6.5 PunktschÃ¤tzungen\nDatendatz samples, 6 Treffer bei 9 WÃ¼rfen.\n\n6.5.1 Lageparameter\nZ.B. Welchen mittleren Wasseranteil muss man annehmen?\n\nsamples %>% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n# A tibble: 1 Ã— 2\n   mean median\n  <dbl>  <dbl>\n1 0.634  0.667\n\n\n\n\n6.5.2 Streuungsparameter\nZ.B. â€œWie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?â€\n\nsamples %>% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n# A tibble: 1 Ã— 3\n   p_sd p_iqr p_mad\n  <dbl> <dbl> <dbl>\n1 0.140 0.222 0.165\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben."
  },
  {
    "objectID": "Post.html#visualisierungen-der-punktschÃ¤tzer",
    "href": "Post.html#visualisierungen-der-punktschÃ¤tzer",
    "title": "6Â  Die Post befragen",
    "section": "6.6 Visualisierungen der PunktschÃ¤tzer",
    "text": "6.6 Visualisierungen der PunktschÃ¤tzer\n\n\n\n\n\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt)."
  },
  {
    "objectID": "Post.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "Post.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "6Â  Die Post befragen",
    "section": "6.7 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.",
    "text": "6.7 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.\nDaten: 9 von 10 Treffern beim MÃ¼nzwurf. Ist die MÃ¼nze fair?\n\ntibble(\n  Trefferzahl = rbinom(n = 1e4, size = 10, prob = 1/2)\n) %>% \n  mutate(signifikant = ifelse(Trefferzahl %in% c(9,10), TRUE, FALSE)) %>% \n  ggplot() +\n  aes(x = Trefferzahl, fill = signifikant) +\n  geom_bar() +\n  scale_x_continuous(breaks = 0:10) +\n  theme(legend.position = c(0.1, 0.8)) +\n  geom_vline(xintercept = 9) +\n  labs(title = \"Stichprobenverteilung fÃ¼r p=0.5\")\n\n\n\n\nDie Stichprobenverteilung zeigt, wie Wahrscheinlich der empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) ist gegeben eines Parameterwerts \\(p\\) (z.B. \\(p=0.5\\)): \\(Pr(D|p)\\).\n\n\n\n\n\n\n\n\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung."
  },
  {
    "objectID": "Post.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "Post.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "6Â  Die Post befragen",
    "section": "6.8 Mit Stichproben neue Beobachtungen simulieren",
    "text": "6.8 Mit Stichproben neue Beobachtungen simulieren\n\n6.8.1 Wir simulieren die Wasserzahl bei GlobuswÃ¼rfen\nLikelihood (L): Wahrscheinlichkeit fÃ¼r \\(w=0,1,2\\) bei \\(N=2\\) und \\(p = 0.7\\):\n\nL <- dbinom(0:2, size = 2, prob = 0.7)\nL\n\n[1] 0.09 0.42 0.49\n\n\nWir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zÃ¤hlen die (Wasser-)Treffer:\n\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n\n[1] 0\n\n\nWarum nicht \\(n=10\\) neue Globusversuche simulieren:\n\nrbinom(n = 10, size = 2, prob = 0.7)\n\n [1] 0 2 1 1 1 1 2 1 1 2\n\n\nDiese Versuche geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann.\n\n\n6.8.2 Never trust a Golem\n\n\nfrom Imgflip Meme Generator\n\nQuelle: https://imgflip.com/i/5qmhmo\n\n\n6.8.3 Traue niemals einem Golem (einem Modell)\nImmer prÃ¼fen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsÃ¤chlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prÃ¼fen?"
  },
  {
    "objectID": "Post.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "Post.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "6Â  Die Post befragen",
    "section": "6.9 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "6.9 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren:\n\ndraws <- \n  tibble(\n    draws = \n      rbinom(1e6, \n             size = 2, \n             prob = .7))\ndraws %>% \n  count(draws) %>% \n  mutate(proportion = \n           n / nrow(d))\n\n# A tibble: 3 Ã— 3\n  draws      n proportion\n  <int>  <int>      <dbl>\n1     0  89770      8977 \n2     1 420629     42063.\n3     2 489601     48960.\n\n\nDiese simulierten HÃ¤ufigkeiten sind sehr Ã¤hnlich zu den theoretisch bestimmten HÃ¤ufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen.\n\ndbinom(0:2, size = 2, prob = .7)\n\n[1] 0.09 0.42 0.49"
  },
  {
    "objectID": "Post.html#stichprobenverteilung",
    "href": "Post.html#stichprobenverteilung",
    "title": "6Â  Die Post befragen",
    "section": "6.10 Stichprobenverteilung",
    "text": "6.10 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben fÃ¼r den Versuch \\(N=9\\) GlobuswÃ¼rfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise?\n\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = \n           rbinom(\n             n_draws, \n             size = 9, \n             prob = .7\n           ))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n\n\nn_draws <- 1e6\ndraws <- tibble(draws = rbinom(n_draws, \n                               size = 9, \n                               prob = .7))\n\n# the histogram\ndraws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", size = 1/10) +\n  scale_x_continuous(\"Anzahl Wasser (W) pro Versuch\",\n                     breaks = seq(from = 0, to = 9, by = 2)) +\n  scale_y_continuous(\"HÃ¤ufigkeit\",\n                     labels = scales::scientific) +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir kÃ¶nnen jetzt prÃ¼fen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n6.10.1 Visualisierung der PPV\n\nknitr::include_graphics(\"https://github.com/sebastiansauer/QM2-Folien/raw/main/img/ppv.png\")\n\n\n\n\nQuelle: McElreath (2020)"
  },
  {
    "objectID": "Post.html#so-viele-verteilungen",
    "href": "Post.html#so-viele-verteilungen",
    "title": "6Â  Die Post befragen",
    "section": "6.11 So viele Verteilungenâ€¦",
    "text": "6.11 So viele Verteilungenâ€¦\n\nDie Posteriori-Verteilung gibt Aufschluss zur HÃ¤ufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass â€œin Wirklichkeitâ€ der Wasseranteil 70% betrÃ¤gt, also \\(\\pi=.7\\)\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\nDie PPV gibt Aufschluss zur HÃ¤ufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter DurchfÃ¼hrung, zu erwarten.\nFÃ¼r die Praxis kann das eine interessante Frage sein.\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklÃ¤rt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden.\n\n\n\n\n\n\nppv2_plot <- \nd_small %>%\n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", linewidth = 1/10) +\n  scale_x_continuous(\"Wasser\", breaks = seq(from = 0, to = 9, by = 3)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(subtitle = \"Stichprobenverteilungen\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ label, ncol = 9)"
  },
  {
    "objectID": "Post.html#ppv-berechnen",
    "href": "Post.html#ppv-berechnen",
    "title": "6Â  Die Post befragen",
    "section": "6.12 PPV berechnen",
    "text": "6.12 PPV berechnen\n\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nppv_plot2 <-\n  ppv %>% \n  ggplot() +\n  aes(x = value) +\n  geom_bar() +\n  scale_x_continuous(\n    breaks = 0:9)\n\n\nppv_plot2\n\n\n\n\n\nDie PPV unseres Modells zeigt uns, dass wir in kÃ¼nftigen Versuchen zumeist 6 Treffer zu erwarten haben.\nAber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar."
  },
  {
    "objectID": "Post.html#vorhersagen-sind-schwierig",
    "href": "Post.html#vorhersagen-sind-schwierig",
    "title": "6Â  Die Post befragen",
    "section": "6.13 Vorhersagen sind schwierig",
    "text": "6.13 Vorhersagen sind schwierig\nâ€¦ gerade wenn sie die Zukunft betreffen, so ein Sprichtwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der hÃ¤ufigste in unseren Stichproben, aber die Vorhersagen haben eine groÃŸe Streuung, birgt also hohe Ungewissheit.\nDie PPV zeigt also, welche Beobachtungen laut unserem Modell kÃ¼nftig zu erwarten sind.\n\n\n\n\n\nWÃ¼rde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hÃ¤tten die Vorhersagen zu wenig Streuung, wÃ¼rden also die Ungewissheit nicht ausreichend abbilden (Ãœbergewissheit, Overconfidence)."
  },
  {
    "objectID": "Post.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "href": "Post.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "title": "6Â  Die Post befragen",
    "section": "6.14 Zwei Arten von Ungewissheit in Vorhersagen von Modellen",
    "text": "6.14 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells: Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiÃŸ, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nÃ¤chste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, mÃ¶chte man beide Arten von Ungewissheit berÃ¼cksichtigen: Das macht die Posteriori-PrÃ¤diktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prÃ¤diktiv) und mit welcher HÃ¤ufigkeit, basierend auf der Post-Verteilung."
  },
  {
    "objectID": "Post.html#vergleich-der-verteilungen",
    "href": "Post.html#vergleich-der-verteilungen",
    "title": "6Â  Die Post befragen",
    "section": "6.15 Vergleich der Verteilungen",
    "text": "6.15 Vergleich der Verteilungen\n\n\n\n\n\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-PrÃ¤diktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter BerÃ¼cksichtigung der Unsicherheit der Posteriori-Verteilung\n\nBild\nQuelle: R. McElreath\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bourier, GÃ¼nther. 2013. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung ; Mit Aufgaben Und\nLÃ¶sungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer\nGabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. 2nd ed. CRC Texts in\nStatistical Science. Boca Raton: Taylor; Francis, CRC\nPress.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  }
]