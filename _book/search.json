[
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\ndie Post-Verteilung f√ºr einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder Streuungsma√üe und auch Sch√§tzintervalle - aus der Post-Verteilung herauslesen\nk√ºnftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n8.1.3 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. ‚ÄúGeradenmodelle 1‚Äù\n\n8.1.4 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket easystats verwenden: Hier finden Sie eine √úbersicht aller Funktionen des Pakets.1\n\n8.1.5 Begleitvideso\n\nPr√§diktoren zentrieren",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.2 Post-Verteilung der Regression",
    "text": "8.2 Post-Verteilung der Regression\n\n8.2.1 Einfache Regression\nDie (einfache) Regression pr√ºft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenh√§ngen. Je mehr sie zusammenh√§ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). H√§ngen \\(X\\) und \\(Y\\) zusammen, hei√üt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).\nDatenquelle, McElreath (2020).\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y), ?fig-kung-zshg.\n\nKung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd &lt;- read_csv(Kung_path)  \n\nd2 &lt;- \n  d %&gt;% \n  filter(age &gt; 18) \n\n\n\nMit ggplot2\nMit ggpubr\n\n\n\n\nd2 %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nggscatter(d2,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\")\n\n\n\n\n\n\n\n\n8.2.2 Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr \\(\\mu\\)\n\nKomfort pur: Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m42, s. Abbildung¬†8.1.\n\n\n\n\n\n\n\nAbbildung¬†8.1: F√ºr jeden beliebigen Pr√§diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgew√§hlten Gewichtswerten. B: F√ºr jeden beliebigen Gewichtswert bekommt man eine Post-Verteilung\n\n\n\n\n\n8.2.3 Statistiken zum !Kung-Datensatz\nDatenquelle\nTabelle¬†8.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\nKung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd &lt;- read_csv(Kung_path)  \n\nd2 &lt;- d %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(d2)\n\n\n\n\nTabelle¬†8.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus Tabelle¬†8.1 abzulesen ist, betr√§gt das mittlere K√∂rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n8.2.4 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\nlibrary(DataExplorer)\n\n\n8.2.4.1 Gibt es fehlende Werte?\nNein, s. Abb. Abbildung¬†8.2.\n\nd2 %&gt;% plot_missing()\n\n\n\n\n\n\nAbbildung¬†8.2: Fehlende Werte - fehlen.\n\n\n\n\n\n8.2.4.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. Abbildung¬†8.3.\n\nd2 %&gt;% plot_histogram()\n\n\n\n\n\n\nAbbildung¬†8.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n8.2.4.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. Abbildung¬†8.4.\n\nd2 %&gt;% plot_bar()\n\n\n\n\n\n\nAbbildung¬†8.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n8.2.4.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in Abbildung¬†8.5 dargestellt.\n\nd2 %&gt;% plot_correlation()\n\n\n\n\n\n\nAbbildung¬†8.5: Korrelationsmatrix\n\n\n\n\n\n√úbungsaufgabe 8.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(d2). \\(\\square\\)\n\n\n8.2.5 Pr√§diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor ‚Äúzentrieren‚Äù, engl. to center). Wenn man den Pr√§diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\alpha\\), einfacher zu verstehen. In einem Modell mit zentriertem Pr√§diktor (weight) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. W√ºrde man weight nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman, Hill, und Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen (mit Hilfe von center aus easystats):\n\nd3 &lt;- \n  d2 %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\nOder so, von Hand:\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\n‚àí9\n\n\n137\n32\n65\n0\n‚àí13\n\n\n\n\n\n\nWie man sieht, ist die Verteilung ‚Äúzur Seite geschoben‚Äù: Der Mittelwert liegt jetzt eben bei 0, s. Abbildung¬†8.6.\n\n\n\n\n\n\n\nAbbildung¬†8.6: Das Zentrieren √§ndert die Verteilungsform nicht, sondern ‚Äúschiebt‚Äù die Verteilung nur zur Seite\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem Pr√§diktor ist, nicht d2.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m43-zentrierter-pr√§diktor",
    "href": "0900-lineare-modelle.html#modell-m43-zentrierter-pr√§diktor",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.3 Modell m43: zentrierter Pr√§diktor",
    "text": "8.3 Modell m43: zentrierter Pr√§diktor\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was w√§re wohl die K√∂rpergr√∂√üe? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n8.3.1 Modelldefinition von m43\n\nF√ºr jede Auspr√§gung des Pr√§diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung f√ºr die abh√§ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte f√ºr die Steigung \\(\\beta\\) und den Achsenabschnitt \\(\\alpha\\) der Regressionsgeraden. Au√üerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Gr√∂√üe (height) angibt; dieser Wert wird als exonentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\).\n\\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnit (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ü§∑\n\n\n\n8.3.2 Likelihood, m43\n\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m43 ist √§hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines ‚ÄúIndex-i‚Äù am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\n‚ÄúDie Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))‚Äù.\n\n\n8.3.3 Regressionsformel, m43\n\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\alpha\\) und \\(\\beta\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der Pr√§diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\n‚ÄúDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\alpha\\) und \\(\\beta\\) mal \\(\\text{weight}_i\\)‚Äù.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\alpha\\) gibt an, wie gro√ü \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n8.3.4 Priori-Werte des Modells m43\n\n\\[\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\n\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n\n\\(\\alpha\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine ‚ÄúRegression ohne Pr√§diktoren‚Äù berechnet haben.\n\n\\(\\sigma\\) ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel.\nDa height nicht zentriert ist, der Mittelwert von \\(\\alpha\\) bei 178 und nicht 0.\n\n\\(\\beta\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#vertiefung-prior-pr√§diktiv-verteilung",
    "href": "0900-lineare-modelle.html#vertiefung-prior-pr√§diktiv-verteilung",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.4 Vertiefung: Prior-Pr√§diktiv-Verteilung",
    "text": "8.4 Vertiefung: Prior-Pr√§diktiv-Verteilung\nüèéÔ∏è VERTIEFUNG, nicht pr√ºfungsrelevant üèéÔ∏è\n\n8.4.1 Moment\nü§î Moment. Dieser Prior, \\(\\beta\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Gr√∂√üe positiv oder negativ ist? Nein, sind wir nicht.\n\n8.4.2 Priori-Pr√§diktiv-Verteilung f√ºr m43\n\nWas denkt wir bzw. unser Golem apriori √ºber den Zusammenhang von Gr√∂√üe und Gewicht? Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also f√ºr \\(\\alpha\\), \\(\\beta\\) und \\(\\sigma\\).\n\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter f√ºr Prior-Pred-Verteilung\n             data = d3)\n\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\na\nb\nsigma\n\n\n\n168.9\n4.6\n13.7\n\n\n179.9\n12.5\n6.9\n\n\n187.1\n‚àí11.1\n3.7\n\n\n173.7\n1.9\n1.2\n\n\n202.3\n5.7\n1.2\n\n\n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n8.4.3 Prior-Pr√§diktiv-Simulation f√ºr m43 mit stan_glm()\n\n\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d3)\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n8.4.4 Visualisieren der Prior-Pr√§diktiv-Verteilung\n\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\nü§Ø Einige dieser Regressionsgeraden sind unsinnig!\n\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\nDie durchgezogene horizontale Linie gibt die Gr√∂√üe des gr√∂√üten Menschens, Robert Pershing Wadlow, an.\n\n8.4.5 Ein positiver Wert f√ºr \\(\\beta\\) ist plausibler\n\n8.4.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\nüëé \\(\\beta=-20\\) w√§re mit diesem Prior gut m√∂glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n8.4.5.2 Oh yes\nWir br√§uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x&gt;0):\n\n\n\n\n\nüëç Vermutlich besser: Ein Gro√üteil der Wahrscheinlichkeitsmasse ist \\(X&gt;0\\). Allerdings gibt‚Äôs keine Gew√§hr, dass unser Prior ‚Äúrichtig‚Äù ist.\n\n8.4.6 Priori-Pr√§diktiv-Simulation, 2. Versuch\n\nm43a_prior_pred &lt;-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter f√ºr Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d3)\n\n\nm43a_prior_pred_draws &lt;- \n  m43a_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  # Spaltennamen k√ºrzen: \n  rename(a = `(Intercept)`) %&gt;%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\na\nb\ns\n\n\n\n173.6\n1.5\n8.6\n\n\n155.7\n2.1\n15.8\n\n\n201.9\n1.5\n2.0\n\n\n206.5\n2.1\n1.2\n\n\n154.1\n1.9\n23.9\n\n\n\n\n\n\nDas Argument prior_PD = TRUE sorgt daf√ºr, dass keine Posteriori-Verteilung, sondern eine Prior-Pr√§diktiv-Verteilung berechnet wird.\n\n8.4.7 Visualisieren der Prior-Pr√§diktiv-Verteilung, m43a\n\nUnsere Priori-Werte scheinen einigerma√üen vern√ºnftige Vorhersagen zu t√§tigen. Allerdings erwartet unser Golem einige Riesen.\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %&gt;% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\nDie durchgezogene horizontale Linie gibt die Gr√∂√üe des gr√∂√üten Menschens, Robert Pershing Wadlow, an.\n\n8.4.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p.¬†96.\n\n8.4.9 Hier ist unser Modell, m43a\n\n\\[\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\\]\n\n# Posteriori-Vert. berechnen:\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # Zufallszahlen festlegen\n    data = d3)\n\n\n8.4.10 Eine Zusammenfassung der Posteriori-Verteilung f√ºr m43a\n\n\nm43a %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nUnser Modell m43a sch√§tzt die typische K√∂rpergr√∂√üe einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugeh√∂rige 95%-CI keine 20 Zentimenter umfasst.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.5 Die Post-Verteilung befragen",
    "text": "8.5 Die Post-Verteilung befragen\n\n8.5.1 m43a\nSagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. Gleichung¬†8.1.\nPrioris:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{8.1}\\]\nWir nennen das Modell m43a2, s. Listing¬†8.1.\n\n\nListing¬†8.1: Modelldefinition von m43a in R\n\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest f√ºr Reproduzierbarkeit\n    data = d3)\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die Nachpr√ºfbarkeit der Ergebnisse (‚ÄúReproduzierbarkeit‚Äù) sichergestellt3. Welche Wert f√ºr seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung sch√§tzen.\n\n\n\n8.5.2 Mittelwerte von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. Tabelle¬†8.2.\n\n\nTabelle¬†8.2: Parameter von m43a\n\nparameters(m43a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 8.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also gr√∂√üer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) √Ñhnliches wie der p-Wert in der Frequentistischen Statistik (Makowski u.¬†a. 2019).\n\nAm besten das Diagramm dazu anschauen, s Abbildung¬†8.7.\n\nplot(p_direction(m43a))\n\n\n\n\n\n\nAbbildung¬†8.7: Diagramm zur Probability of Direction, Modell m43a\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) gr√∂√üer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter besch√§ftigen in diesem Kurs.\n\n8.5.3 Visualisieren der ‚Äúmittleren‚Äù Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). √úberzeugen wir uns mit einem Blick in die Post-Verteilung von m43a:\n\nm43a %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n  \n\n\n\nWir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die ‚Äúmittlere‚Äù Regressionsgerade zu betrachten:\n\nd3 %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. Abbildung¬†8.8. Mit ‚Äúexpectation‚Äù sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\nm43_expect &lt;- estimate_expectation(m43a)\nplot(m43_expect)\n\n\n\n\n\n\nAbbildung¬†8.8: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n\n\n\n\n\n8.5.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).4 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.\n\n8.5.4.1 Lagema√üe zu den Parametern\n\nWas ist die mittlere Gr√∂√üe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? (\\(\\beta_1\\))\nWas ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert f√ºr z.B: \\(\\beta_1\\)?\n\nEine n√ºtzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. Tabelle¬†8.2.\n\n\n\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m43a, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\nm43a_post &lt;- \n  m43a %&gt;% \n  as_tibble()\n\nm43a_post %&gt;% \n  head()\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post. Jetzt haben wir wieder eine sch√∂ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen k√∂nnen. Eine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. Abbildung¬†8.9.\n\nm43a_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\nAbbildung¬†8.9: Postverteilung f√ºr den Parameter Gewicht (zentriert)\n\n\n\n\nAbbildung¬†8.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\nm43a_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. Abbildung¬†8.10.\n\nm43a_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\nAbbildung¬†8.10: Die Post-Verteilung f√ºr den Parameter sigma, m43a\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. Abbildung¬†8.11.\n\nm43a_hdi &lt;- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\n\n\nAbbildung¬†8.11: Die Parameter Gewicht (zentriert) und sigma des Modells m43a\n\n\n\n\nErg√§nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n8.5.5 Streuungsma√üe zu den Parametern\n\nWie unsicher sind wir uns in den Sch√§tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.\n\n\n\n8.5.6 Ungewissheit von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung visualisiert\nDie ersten 10 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\nDie ersten 100 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\nDie ersten 1e3 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\nDie ersten 1000000 ‚Ä¶ okay, lassen wir es gut sein5.\nEinfacher ist die Visualisierung mit estimate_expectation:\n\nestimate_expectation(m43a, seed = 42) %&gt;% plot()\n\n\n\n\n\n8.5.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe.\n\n\n\nWelche mittlere Gr√∂√üe wird mit zu 50%, 90% bzw. 95% Wahrscheinlichkeit nicht √ºberschritten?\nWelche mittlere Gr√∂√üe mit zu 95% Wskt. nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?\n\nQuantile:\n\nm43a_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n  \n\n\n\n50%-PI:\n\nm43a %&gt;% \n  eti(ci = .5)\n\n\n  \n\n\n\n\n8.5.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?\n\nm43a_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?\n\nm43a_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betr√§gt 0.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚Äö \n\n8.5.9 Typischer Bayes-Nutzer in Aktion\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-pr√§diktorwert",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.6 Post-Verteilung bedingt auf einen Pr√§diktorwert",
    "text": "8.6 Post-Verteilung bedingt auf einen Pr√§diktorwert\n\n8.6.1 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?\nEtwas formaler ausgedr√ºckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\nmu_at_45 &lt;-\n  m43a_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\nUnd plotten diese, s. Abbildung¬†8.12.\n\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\nAbbildung¬†8.12: Post-Verteilung der Gr√∂√üe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\nAnalog k√∂nnen wir fragen, wie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.\n50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. ?tbl-mu-at-50.\n\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\nTabelle¬†8.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren Gr√∂√üe bei einem Gewicht von 50kg ist weiter ‚Äúrechts‚Äù (Richtung h√∂here Gr√∂√üe) zentriert, s. Abbildung¬†8.13.\n\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\nAbbildung¬†8.13: Post-Verteilung der mittleren Gr√∂√üe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n8.6.2 Lagema√üe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der K√∂rpergr√∂√üe.\nWas ist das 90% PI f√ºr \\(\\mu|w=50\\) ?\n\nmu_at_50 %&gt;% \n  eti(mu_at_50, ci = .9)\n\n\n  \n\n\n\nDie mittlere Gr√∂√üe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?\n\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-ppv-befragen",
    "href": "0900-lineare-modelle.html#die-ppv-befragen",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.7 Die PPV befragen",
    "text": "8.7 Die PPV befragen\nDie Posterior-Pr√§diktiv-Verteilung (PPV) gibt uns die M√∂glichkeit, nach der Wahrscheinlichkeit tats√§chlicher K√∂rpergr√∂√üen zu fragen - und nicht nur nach mittleren K√∂rpergr√∂√üen anhand der Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren K√∂rpergr√∂√üe, denn das ist was wir modellieren wollten. M√∂chten wir Aussagen zur Wahrscheinlichkeit tats√§chlicher Gr√∂√üen treffen, brauchen wir die PPV. Allgemeiner gesagt: Die PPV macht Vorhersagen auf Basis eines Modells. F√ºr jede Vorhersage gibt es eine Verteilung, die wir zu einem Punktsch√§tzer (z.B. Median) und einem Sch√§tzbereich (z.B. 89%-HDI) zusammenfassen k√∂nnen.\n\n\nAn dieser Stelle sollten wir uns vor Augen f√ºhren, dass die PPV mehr Ungewissheit beinhaltet, denn sie ber√ºcksichtigt derer zweier Arten:\n\nUngewissheit bzgl. der Modellparameter (Steigung und Achsenabschnitt der Regressionsgeraden)\nUngewissheit der Vorhersagen (das Modell macht keine perfekten Vorhersagen)\n\nDie Post-Verteilung ber√ºcksichtigt nur die Ungewissheit in den Modellparametern, macht also nur Aussagen zur Regressionsgeraden.\nDie PPV macht Aussagen f√ºr konkrete Beobachtungen. Der Unterschied ist in Abbildung¬†8.14 dargestellt; die Funktionen stammen √ºbrigens aus easystats.\nestimate_prediction(m43a) %&gt;% plot()\nestimate_relation(m43a) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(a) PPV mit viel Ungewissheit\n\n\n\n\n\n\n\n\n\n(b) Post-Verteilung mit wenig(er) Ungewissheit\n\n\n\n\n\n\nAbbildung¬†8.14: PPV vs.¬†Post-Verteilung\n\n\n\n8.7.1 Perzentil-Intervalle f√ºr bestimmte Pr√§diktor-Werte\n\nWie gro√ü ist ein !Kung-Mann mit mittlerem Gewicht?\n\n\nset.seed(42)\nestimate_prediction(m43a, data = tibble(weight_c = 0), seed = 42)\n\n\n  \n\n\n\nUnser Modell, ma43a sch√§tzt ca. 145cm bis 165cm.\nWir k√∂nnen uns auch eine Sequenz an Pr√§diktorwerten, die uns interessieren, erstellen, s. weight_df:\n\nweight_df &lt;- tibble(weight_c = seq(-20,20, by = 5))\n\nF√ºr diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\nmus &lt;- \n  estimate_prediction(m43a, data = weight_df) \n\nhead(mus)\n\n\n  \n\n\n\nUm die Perzentilintervalle zu erstellen, wird von estimate_prediction() f√ºr jeden Pr√§diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil daf√ºr berechnet. Sie k√∂nnen die Voreinstellung √§ndern mittels des Arguments ci; um ein 89%-PI zu berechnen, w√ºrde man z.B. schreiben ci = .89.\nUm Reproduzierbarkeit sicherzustellen, haben wir mit set.seed(42) die Zufallszahlen fixiert.\nHoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedr√ºckt; die PPV gibt die Ungewissheit tats√§chlicher beobachtbarer K√∂rpergr√∂√üen aus, nicht nur die Ungewissheit zum Mittelwert.\nBerechnen wir die PPV f√ºr die bestehenden Beobachtungen aus m43a:\n\nppv_m43a &lt;- estimate_prediction(\n  m43a,\n  data = weight_df)\n\nmus \n\n\n  \n\n\n\n\n8.7.2 Perzentilintervalle f√ºr verschiedenen Pr√§diktorwerte visualisiert\nAbbildung¬†8.15 visualisiert die Ungewissheit von Vorhersagen laut der PPV. Die Ungewissheit in Abbildung¬†8.15 ist die Antwort auf die Frage: ‚ÄúWie sicher sind wir uns, zur Gr√∂√üe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?‚Äù Eine Vorhersage bezeichnet man auch als ‚Äúbedingte Verteilung‚Äù, da man den Wert einer Verteilung voraussagt, gegeben einer Bedingung, z.B. weight_c = 10.\n\n\n\n\n\n\n\nAbbildung¬†8.15: Visualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV gr√∂√üer als die der Post-Verteilung.\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung, s. Abbildung¬†8.16; je dicker die ‚ÄúKatzenaugen‚Äù, desto mehr Stichproben (samples) liegen vor an der Stelle, und umso genauer ist die Sch√§tzung.\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†8.16: Die PPV f√ºr bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\n\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu | w_i\\).\n\n8.7.3 Die PPV √ºber alle Beobachtungen visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV f√ºr einen bestimmten Pr√§diktorwert, z.B. bei einer Person mittleren Gewichts. Wir k√∂nnen auch den Mittelwert √ºber alle bedingten PPV anschauen, sozusagen die ‚ÄúMaster-PPV‚Äù oder ‚Äúunbedingte PPV‚Äù oder schlicht PPV. Vergleichen wir die echten Werte f√ºr height, \\(y\\), mit den von der PPV simulierten Werten f√ºr height, \\(y_{rep}\\), s. Abbildung¬†8.17.\n\ncheck_predictions(m43a)  # aus easystatss\n\n\n\n\n\n\nAbbildung¬†8.17: Vergleich der Vorhersagen f√ºr y (leichte, blaue Linien) mit der beobachteten Verteilung von y\n\n\n\n\n?check_predictions zeigt Hilfe f√ºr diese Funktion. Die Funktion zeigt die Vorhersagen f√ºr die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n8.7.4 Fragen an die Master-PPV\n\nWie gro√ü sind die !Kung im Schnitt?\nWelche Gr√∂√üe wird von 90% der Personen nicht √ºberschritten?\nWie gro√ü sind die 10% kleinsten?\n\n\nppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\nhead(ppv_m43a)\n\n\n  \n\n\n\n\nppv_m43a &lt;-\n  ppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\nhead(ppv_m43a)\n\n\n  \n\n\n\n\nppv_m43a %&gt;% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n\n  \n\n\n\nWas ist der 50% Bereich der K√∂rpergr√∂√üe?\n\nppv_m43a %&gt;% \n  eti(ci = .5)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.8 Aufgaben",
    "text": "8.8 Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nLikelihood2\nPost-befragen1\nPostvert-Regr-01\nregression1a\nRegression2\nBed-Post-Wskt1\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section",
    "href": "0900-lineare-modelle.html#section",
    "title": "\n8¬† Lineare Modelle\n",
    "section": "\n8.9 ‚Äî",
    "text": "8.9 ‚Äî\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel L√ºdecke. 2019. ‚ÄûIndices of Effect Existence and Significance in the Bayesian Framework‚Äú. Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Lineare Modelle</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#lernsteuerung",
    "href": "1100-kausal.html#lernsteuerung",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Position im Modulverlauf\nAbbildung¬†1.1 gibt einen √úberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 R-Pakete\nF√ºr dieses Kapitel ben√∂tigen Sie folgende R-Pakete:\n\nlibrary(dagitty)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n10.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerkl√§ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\ndie ‚ÄúAtome‚Äù der Kausalit√§t eines DAGs benennen\n‚Äúkausale Hintert√ºren‚Äù schlie√üen",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#statistik-was-soll-ich-tun",
    "href": "1100-kausal.html#statistik-was-soll-ich-tun",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.2 Statistik, was soll ich tun?",
    "text": "10.2 Statistik, was soll ich tun?\n\n10.2.1 Studie A: √ñstrogen\n\n10.2.1.1 Medikament einnehmen?\nMit Blick auf Tabelle¬†10.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelle¬†10.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nM√§nner\n81/87 √ºberlebt (93%)\n234/270 √ºberlebt (87%)\n\n\nFrauen\n192/263 √ºberlebt (73%)\n55/80 √ºberlebt (69%)\n\n\nGesamt\n273/350 √ºberlebt (78%)\n289/350 √ºberlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualit√§t (Beobachtungsstudie). Bei M√§nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und M√§nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n10.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (√ñstrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (√ñstrogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in Abbildung¬†10.1 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†10.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender √ºber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige L√∂sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder ‚ÄúSchichten‚Äù (‚ÄúStrata‚Äù)\n\n\n\n10.2.2 Studie B: Blutdruck\n\n10.2.2.1 Medikament einnehmen?\nMit Blick auf Tabelle¬†10.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelle¬†10.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 √ºberlebt (93%)\n234/270 √ºberlebt (87%)\n\n\nhoher Blutdruck\n192/263 √ºberlebt (73%)\n55/80 √ºberlebt (69%)\n\n\nGesamt\n273/350 √ºberlebt (78%)\n289/350 √ºberlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualit√§t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe √ºber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? Pearl, Glymour, und Jewell (2016)\n\n10.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament sch√§dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell ist in Abbildung¬†10.2 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†10.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer sch√§dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den n√ºtzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren w√§re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar w√§re.\n\n\n\n10.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs Abbildung¬†10.1 und Abbildung¬†10.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen f√ºr Handlungen - war nur m√∂glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n10.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht f√ºr Kausalschl√ºsse. üßü\nStatistik plus Theorie erlaubt Kausalschl√ºsse. üìö‚ûïüìä üü∞ ü§©\n\n\n\n\n\n\nWichtig\n\n\n\nF√ºr Entscheidungen (‚ÄúWas soll ich tun?‚Äù) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n10.2.5 Vertiefung1\n\n\n10.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. √Ñrzte tendieren zu Behandlung A bei gro√üen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die √Ñrzte zu Behandlung B.\nSollte ein Patient, der nicht wei√ü, ob sein Nierenstein gro√ü oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach Steingr√∂√üe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) w√§hlt?\nDie Gr√∂√üe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (‚ÄúKette‚Äù) von Gr√∂√üe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. Dar√ºber hinaus gibt es noch einen Einfluss von Gr√∂√üe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in Abbildung¬†10.3 dargestellt; Abbildung¬†10.4 visualisiert alternativ.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment sch√§tzen m√∂chte? Oder lieber nicht kontrollieren?\n\n\n\n\n\n\n\nAbbildung¬†10.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†10.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. W√ºrde man nicht size kontrollieren, bek√§me man den ‚Äúvermengten‚Äù Effekt von size und treatment, also keine (belastbare) Aussage √ºber den Effekt der Behandlung.\n\n10.2.5.2 Mehr Beispiele\nNehmen Sie Bezug zu folgenden Aussagen:\n\nStudien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erh√∂hen, wenn du heiratest.\n\n\nStudien zeigen, dass Leute, die sich beeilen, zu sp√§t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu sp√§t zu deiner Besprechung.\n\n\n10.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zus√§tzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht n√∂tig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen daf√ºr, dass es keine Konfundierung gibt.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#konfundierung",
    "href": "1100-kausal.html#konfundierung",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.3 Konfundierung",
    "text": "10.3 Konfundierung\n\n10.3.1 Datensatz ‚ÄòHauspreise im Saratoga County‚Äô\nWir nutzen den Datensatz Saratoga County; s. Tabelle¬†10.3. Hier gibt es eine Beschreibung des Datensatzes.\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\n\n\n\nTabelle¬†10.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n10.3.2 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\n‚ÄúFinden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!‚Äù\n\nüßë Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\nüë© üî¨ Das ist Angie, Data Scientistin.\n\n10.3.3 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\n‚ÄúHey Don! Mehr Zimmer, mehr Kohle!‚Äù üë© üî¨\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. Abbildung¬†10.5.\n\n\n\n\n\n\n\nAbbildung¬†10.5: Modell m1\n\n\n\n\n\n‚ÄúJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.‚Äù\n\nüë©\n\nZu wenig! ü§¨\n\nüßë\nBerechnen wir das Modell m1; der Punktsch√§tzer des Parameters bedroom steht in Tabelle¬†10.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\nTabelle¬†10.4: Parameter f√ºr m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die Punktsch√§tzer der Parameter eines Modells zur√ºck, aber nicht die Sch√§tzbereiche. M√∂chten Sie beides, k√∂nnen Sie die Funktion parameters(modell) nutzen.2\nMit estimate_predictions k√∂nnen wir Vorhersagen berechnen (bzw. sch√§tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist ‚Äúsch√§tzen‚Äù vielleicht das treffendere Wort). Tabelle¬†10.5 zeigt den laut m1 vorhergesagten Hauspreis f√ºr ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\nTabelle¬†10.5: Vorhersage des Hauspreises f√ºr ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.56e+05\n91416.43\n(-21676.42, 3.36e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n10.3.4 Don hat eine Idee\n\n‚ÄúIch bau eine Mauer! Genial! An die Arbeit, Angie!‚Äù üßë\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\n‚ÄúDas ist keine gute Idee, Don.‚Äù\n\nüë©\nBerechnen wir die Vorhersagen f√ºr Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. Tabelle¬†10.6.3\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\nTabelle¬†10.6: Vorhergesagter Hauspreis laut m1 f√ºr ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.50e+05\n89703.29\n(74381.91, 4.26e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, Abbildung¬†10.5.\n\n‚ÄúVolltreffer! Jetzt verdien ich 100 Tausend mehr! ü§ë Ich bin der Gr√∂√üte!‚Äù üßë\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: ‚Äú4e+05‚Äù ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n10.3.5 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, ber√ºcksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im ‚ÄúStrukturmodell‚Äù: Wenn also z.B. in unserem Modell ein wichtiger Pr√§diktor fehlt, so kann die Vorhersagen nicht pr√§zise sein. Fehler im Strukturmodell schlagen sich in breiten Sch√§tzintervallen (bedingt durch ein gro√ües \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. ber√ºcksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\n\nDie Sch√§tzbereiche sind in dem Fall deutlich kleiner, s. Tabelle¬†10.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\n\nTabelle¬†10.7: Model-based Expectation\n\n\n\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3104.98\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\nUngewissheit f√ºr die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\n\n\n\n10.3.6 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. Tabelle¬†10.8 gibt den Punktsch√§tzer f√ºr die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\nTabelle¬†10.8: Parameter (Punktsch√§tzer, keine Sch√§tzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36311.05\n\n\nbedrooms\n-14077.64\n\n\nlivingArea\n125.32\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? Tabelle¬†10.9 gibt Aufschluss f√ºr den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 Quadratfu√ü Wohnfl√§che; Tabelle¬†10.10 gibt die Sch√§tzung (laut m2) f√ºr den Preis eines Hauses mit 2 Zimmern (und der gleichen Wohnfl√§che). Die Vorhersage erh√§lt man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130423.8\n\n\n\n\nTabelle¬†10.9: Vorhersage von m2 f√ºr ein Haus mit 4 Zimmern und 1200 Einheiten Wohnfl√§che\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelle¬†10.10: Vorhersage von m2 f√ºr ein Haus mit 2 Zimmern und 1200 Einheiten Wohnfl√§che\n\n\n\n  \n\n\n\n\n\n\nAndere, aber √§hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt √ºber die verschiedenen Gr√∂√üen von livingArea? Stellen Sie sich alle H√§user mit 4 Zimmern vor (also mit verschiedenen Wohnfl√§chen). Wir m√∂chten nur wissen, was so ein Haus ‚Äúim Mittel‚Äù kostet. Wir m√∂chten also die Mittelwerte pro bedroom sch√§tzen, gemittelt f√ºr jeden Wert von bedroom √ºber livingArea. Die Ergebnisse stehen in Tabelle¬†10.11 und sind in Abbildung¬†10.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelle¬†10.11: Vorhersagen des Preises von H√§usern mit verschiedener Zimmerzahl gemittelt √ºber die verschiedenen Werte der Wohnfl√§che; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung¬†10.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\n‚ÄúDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!‚Äù\n\nüë©\n\n‚ÄúVerringert!? Weniger Geld?! Oh nein!‚Äù\n\nüßë\n\n10.3.7 Die Zimmerzahl ist negativ mit dem Preis korreliert\n‚Ä¶ wenn man die Wohnfl√§che (Quadratmeter) kontrolliert, s. Abbildung¬†10.7.\n\n‚ÄúNe-Ga-Tiv!‚Äù\n\nüë©\n\n\n\n\n\nAbbildung¬†10.7: Hauspreis stratifizieren\n\n\nQuellcode",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#kontrollieren-von-variablen",
    "href": "1100-kausal.html#kontrollieren-von-variablen",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.4 Kontrollieren von Variablen",
    "text": "10.4 Kontrollieren von Variablen\nüí° Durch das Aufnehmen von Pr√§diktoren in die multiple Regression werden die Pr√§diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen Pr√§diktors mit \\(y\\), wenn man den (oder die) anderen Pr√§diktoren statistisch konstant h√§lt.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom ‚ÄúNetto-Effekt‚Äù eines Pr√§diktors, oder davon, dass ein Pr√§diktor ‚Äúbereinigt‚Äù wurde vom (linearen) Einfluss der anderen Pr√§diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Pr√§diktors \\(x_1\\) auf \\(y\\) anzeigen unabh√§ngig vom Effekt der anderen Pr√§diktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Pr√§diktors \\(x_1\\) wird f√ºr jede Auspr√§gung (Gruppe) des Pr√§diktors \\(x_2\\) berechnet.\n\n10.4.1 Das Hinzuf√ºgen von Pr√§diktoren kann die Gewichte der √ºbrigen Pr√§diktoren √§ndern\n\nAber welche und wie viele Pr√§diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nüßë\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nüë©\n\nWozu ist sie dann gut?!\n\nüßë\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erkl√§rung der Ursachen heranzuziehen: Die Regressionskoeffizienten k√∂nnen sich wild √§ndern, wenn man Pr√§diktoren hinzuf√ºgt oder wegl√§sst. Es k√∂nnen sich sogar die Vorzeichen der Regressionsgewichte √§ndern; in dem Fall spricht man von einem Simpson-Paradox.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "href": "1100-kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.5 Welches Modell richtig ist, kann die Statistik nicht sagen",
    "text": "10.5 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, we‚Äôd like to know wheter an effect is ‚Äúreal‚Äù or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical ‚Äútests‚Äù on its way to acceptance.\n\nMcElreath (2020), S. 139\n\n10.5.1 Kausalmodell f√ºr Konfundierung, km1\n\nDas Kausalmodell km1 ist in Abbildung¬†10.8 dargestellt; vgl. Abbildung¬†10.7.\n\n\n\n\n\n\n\nAbbildung¬†10.8: Kausalmodell km1 - Eine Erkl√§rung (von mehreren) f√ºr m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms.\nEine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht.\nd_connected hei√üt, dass die betreffenden Variablen ‚Äúverbunden‚Äù sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flie√üt üåä. d_separated hei√üt, dass sie nicht d_connected sind.\n\n10.5.2 m2 kontrolliert die Konfundierungsvariable livingArea\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt blo√ü?! Oh jeh!\n\nüßë\n\nWir m√ºssen die Konfundierungsvariable kontrollieren.\n\nüë©\nAbbildung¬†10.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildung¬†10.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (‚Äúadjustieren‚Äù), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separeted.\n\n10.5.3 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, Abbildung¬†10.10, links: Es wird (f√§lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, Abbildung¬†10.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildung¬†10.10: Konfundierung von y und x!\n\n\nAbbildung¬†10.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. Au√üerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als Pr√§diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\nQuellcode\n\n10.5.4 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 d√ºrfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in Abbildung¬†10.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n10.5.5 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide Pr√§diktoren jeweils einen eigenen Beitrag zur Erkl√§rung der AV haben.\nDaher k√∂nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei Kausaleinfl√ºsse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) √ºber den Mediator (b) zur AV (p) auch Mediation, s. Abbildung¬†10.11.\n\n\n\n\n\n\n\nAbbildung¬†10.11: Der Effekt von livingArea wird √ºber den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n10.5.6 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. Abbildung¬†10.12.\n\n\n\n\n\n\n\nAbbildung¬†10.12: Dons Kausalmodell\n\n\n\n\n\n‚ÄúIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das gr√∂√üte! Alle anderen Kausalmodelle sind ein Disaster!‚Äù\n\nüßë\n\n\n‚ÄúDon, nach deinem Kausalmodell m√ºssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.‚Äù\n\nüßë\nRechne doch selber die Korrelation aus, Don:\n\n‚Äú√Ñh, wie ging das nochmal?‚Äù\n\nüßë\nSo k√∂nntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\n‚ÄúBitte, gerne hab ich dir geholfen, Don.‚Äù\n\nüë©\n\n10.5.7 Unabh√§ngigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. Abbildung¬†10.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabh√§ngig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zus√§tzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete Unabh√§ngigkeit findet sich nicht in den Daten wieder, s. Tabelle¬†10.8. Also: ‚õàÔ∏è Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. Abbildung¬†10.11.\nDas Kausalmodell km2 postuliert keine Unabh√§ngigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betr√§gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so √§hnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. ü•±\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. Abbildung¬†10.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabh√§ngig von livingArea (a)\n‚õàÔ∏è km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#dags-directed-acyclic-graphs",
    "href": "1100-kausal.html#dags-directed-acyclic-graphs",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.6 DAGs: Directed Acyclic Graphs",
    "text": "10.6 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B. Abbildung¬†10.12.\n\nDAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.\nEin Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.\nDAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).\nDAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zur√ºckf√ºhren.\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten √ºber die Kanten, unabh√§ngig von der Pfeilrichtung.\n\nDer DAG von km1 ist in Abbildung¬†10.8 zu sehen.\n\n10.6.1 Leider passen potenziell viele DAGs zu einer Datenlage\nb: bedrooms, p: price, a area (living area)\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach w√§re, die Kausalstruktur der Ph√§nomene zu entdecken, w√§ren sie l√§ngst erkannt, und alle Probleme der Menschheit gel√∂st.\nIn Abbildung¬†10.13 sind m√∂gliche Kausalmodelle f√ºr Dons Studie dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†10.13: Kausalmodelle, die potenziell geeignet sind f√ºr Dons Fragestellung\n\n\n\n\nAlle diese DAgs in Abbildung¬†10.8 haben die gleichen Implikationen hinsichtlich der (Un-)Abh√§ngigkeiten zwischen der Variablen. Wir k√∂nnen also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, br√§uchten wir z.B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n10.6.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als ‚ÄúKausation‚Äù bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWei√ü man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\nViele Menschen denken - f√§lschlich - dass Korrelation Kausation bedeuten muss, s. Abbildung¬†10.14.\n\n\n\n\n\n\n\nAbbildung¬†10.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und Erkl√§rung\n\n10.6.3 Zwischenfazit\nSind zwei Variablen korreliert (abh√§ngig, assoziiert), so kann es daf√ºr zwei Gr√ºnde geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (‚ÄúScheinkorrelation‚Äù)\n\nEine m√∂gliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Pr√§diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so l√∂st sich der Scheinzusammenhang nach dem Adjustieren auf.\nL√∂st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenh√§nge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine k√∂nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist n√∂tig, um DAGs auszuschlie√üen.\n\n10.6.4 Schoki macht Nobelpreis! (?)\nüèéÔ∏è Vertiefung üèéÔ∏è\nEine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen (H√∂he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli 2012), s. Abbildung¬†10.15.\n\n\n\n\n\n\n\nAbbildung¬†10.15: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle √ºberpr√ºfen, so wie wir das hier tun.\n\n\nDer ‚ÄúSchoki-DAG‚Äù in Abbildung¬†10.16 zeigt den DAG f√ºr das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\n\n\n\nAbbildung¬†10.16: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#kollision",
    "href": "1100-kausal.html#kollision",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.7 Kollision",
    "text": "10.7 Kollision\n\n10.7.1 Kein Zusammenhang von Intelligenz und Sch√∂nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und Sch√∂nheit (looks), wie Abbildung¬†10.17 illustriert. F√ºr geringe Intelligenzwerte gibt es eine breites Spektrum von Sch√∂nheitswerten und f√ºr hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildung¬†10.17: Kein Zusammenhang von Intelligenz und Sch√∂nheit in den Daten\n\n\n\n\nGott ist gerecht (?)\n\n10.7.2 Aber Ihre Dates sind entweder schlau oder sch√∂n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder sch√∂n sind oder schlau - aber seltens beides gleichzeitig (schade), s. Abbildung¬†10.18.\n\n\n\n\n\n\n\nAbbildung¬†10.18: Ihre Datingpartner sind komischerweise entweder schlau oder sch√∂n (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#dag-zur-rettung",
    "href": "1100-kausal.html#dag-zur-rettung",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.8 DAG zur Rettung",
    "text": "10.8 DAG zur Rettung\nü¶π ü¶∏\nDer DAG in Abbildung¬†10.19 bietet eine rettende Erkl√§rung.\n\n\n\n\n\n\n\nAbbildung¬†10.19: Date als gemeinsame Wirkung von Sch√∂nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Sch√∂nheit und Intelligenz.\n\n\n\n\nEine √§hnliche Visualisierung des gleichen Sachverhalts zeigt Abbildung¬†10.20.\n\n\n\n\n\n\n\nAbbildung¬†10.20: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n10.8.1 Was ist eine Kollision?\nAls Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen). Kontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. Abbildung¬†10.19, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche Pr√§diktoren einer Regression hinzuf√ºgen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n10.8.2 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSch√∂ne Menschen\nReiche Menschen\n\nSehen wir davon aus, dass Sch√∂nheit und Reichtum unabh√§ngig voneinander sind.\nWenn ich Ihnen sage, dass Don nicht sch√∂n ist, aber in der Glitzer h√§ufig auftaucht, was lernen wir dann √ºber seine finanzielle Situation?4\n\n‚ÄúIch bin sch√∂n, unglaublich sch√∂n, und gro√ü, gro√üartig, tolle Gene!!!‚Äù üßë\n\n\n10.8.3 Noch ein einfaches Beispiel zur Kollision\n\n‚ÄúSo langsam check ich‚Äôs!‚Äù üßë\n\nSei Z = X + Y, wobei X und Y unabh√§ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts √ºber Y, da die beiden Variablen unabh√§ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abh√§ngig, gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).5\n\n10.8.4 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildung¬†10.19 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als Pr√§diktor in eine Regression zus√§tzlich zu looks mit talent als Pr√§dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (‚ÄúFluss‚Äù) von Looks √ºber date nach Talent ist blockiert.\nKontrolliert man date, so √∂ffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr ‚Äúblockiert‚Äù, die Korrelation kann ‚Äúflie√üen‚Äù - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n10.8.5 IQ, Fleiss und Eignung f√ºrs Studium\nSagen wir, √ºber die Eignung f√ºr ein Studium w√ºrden nur (die individuellen Auspr√§gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in Abbildung¬†10.21.\n\n\n\n\n\n\n\nAbbildung¬†10.21: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (f√ºrs Studium) sei definiert als die Summe von iq und fleiss, plus etwas Gl√ºck:\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\nLaut unserem Modell setzt sich Eignung zur H√§lfte aus Intelligenz und zur H√§lfte aus Fleiss zusammen, plus etwas Gl√ºck.\n\n10.8.6 Schlagzeile ‚ÄúSchlauheit macht Studentis faul!‚Äù\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Flei√ü (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das ‚ÄúEignungsmodell‚Äù, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. Tabelle¬†10.12.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\nTabelle¬†10.12: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildung¬†10.22 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildung¬†10.22: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabh√§ngig von Flei√ü in unseren Daten, sondern abh√§ngig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde √ºber Zusammenh√§nge auf und interpretieren die Zusammenh√§nge ‚Äì oft vorschnell ‚Äì als kausal.6\n\n10.8.7 Kollisionsverzerrung nur bei Stratifizierung\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. Abbildung¬†10.23.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildung¬†10.23: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie n√ºtzen.\nNur Kenntnis des DAGs verr√§t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten Pr√§diktor auf, so ‚Äúkontrolliert‚Äù man diese Variable. Das Regressiongewicht des ersten Pr√§diktors wird ‚Äúbereinigt‚Äù um den Einfluss des zweiten Pr√§diktors; insofern ist der zweite Pr√§diktor dann ‚Äúkontrolliert‚Äù.\n\n\n\n10.8.8 Einfluss von Gro√üeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und Gro√üeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von Gro√üeltern auf ihre Enkel, s. Abbildung¬†10.24, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildung¬†10.24: Der kausale Effekt von Gro√üeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable √ºbersehen haben? (S. n√§chster Abschnitt). üëª\n\n10.8.9 Der Gespenster-DAG\nüëª\nEs gibt ‚Äúunheilbare‚Äù DAGs, nennen wir sie ‚ÄúGespenster-DAGs‚Äù, in denen es nicht m√∂glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. Abbildung¬†10.25. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: ‚ÄúDeine Theorie ist nicht gut, zur√ºck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.‚Äù\n\n\n\n\n\n\n\nAbbildung¬†10.25: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollst√§ndig) m√∂glich.\n\n\n\n\n\nU k√∂nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft.\nDie Gro√üeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\nE ist sowohl f√ºr G als auch f√ºr U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\n\nDie Sache ist in diesem Fall chancenlos. Wir m√ºssen diesen DAG verloren geben, McElreath (2020), S. 180.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#die-hintert√ºr-schlie√üen",
    "href": "1100-kausal.html#die-hintert√ºr-schlie√üen",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.9 Die Hintert√ºr schlie√üen",
    "text": "10.9 Die Hintert√ºr schlie√üen\n\n10.9.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie gro√ü ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in Abbildung¬†10.26 dargestellt.\n\n\n\n\n\n\n\nAbbildung¬†10.26: Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfl√§che beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund f√ºr die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\rightarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. G√§be es nur nur den zweiten Pfad und wir w√ºrden b √§ndern, so w√ºrde sich p nicht √§ndern.\n\n10.9.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildung¬†10.27 zeigt eine erfreuliche Situation: Die ‚ÄúHintert√ºr‚Äù zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die Hintert√ºr geschlossen - f√ºhren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildung¬†10.27: Unverzerrte Sch√§tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Pr√§diktor im Modell enthalten ist. Da die beiden Pr√§diktoren unkorreliert sind, hat die Aufnahme des einen Pr√§diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie ‚ÄúHintert√ºr‚Äù der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine ber√ºhmte L√∂sung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment. Wenn wir den H√§usern zuf√§llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen k√∂nnten (unabh√§ngig von ihrer Quadratmeterzahl, a), w√ºrde sich der Graph so √§ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\rightarrow a \\rightarrow p\\) geschlossen (‚Äúblockiert‚Äù).\n\n10.9.3 Hintert√ºr schlie√üen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die Hintert√ºr schlie√üen (backdoor criterion).\nWir wollen die Hintert√ºre schlie√üen, da wir sonst nicht den wahren, kausalen Effekt bestimmen k√∂nnen.\nZum Gl√ºck gibt es neben Experimenten noch andere Wege, die Hintert√ºr zu schlie√üen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis √ºber b kein zus√§tzliches Wissen √ºber p. Wissen Sie hingegen nichts √ºber a, lernen Sie bei Kenntnis von b auch etwas √ºber p. Konditionieren ist wie ‚Äúgegeben, dass Sie a schon kennen‚Ä¶‚Äù.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)\n\n10.9.4 Die vier Atome der Kausalanalyse\nAbbildung¬†10.28 stellt die vier ‚ÄúAtome‚Äù der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so k√∂nnen Sie jedes beliebige Kausalsystem (DAG) entschl√ºsseln.\n\n\n\n\n\n\n\nAbbildung¬†10.28: Die vier Atome der Kausalinferenz\n\n\n\n\n\n10.9.5 Mediation\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. Abbildung¬†10.29. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y ‚Äúvermittelt‚Äù oder √ºbertr√§gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildung¬†10.29: Das Kausalmodell der Mediation.\n\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation ‚Äúflie√üt‚Äù den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlie√üt) die Kette (genau wie bei der Gabel).\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. Abbildung¬†10.30. In Abbildung¬†10.30 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\). Die Summe der Effekte beider Pfade nennt man den totalen (kausalen) Effekt. Den Effekt √ºber den Mediatorpfad nennt man den indirekten (kausalen) Effekt und den Pfad \\(x\\rightarrow y\\) nennt man den direkten (kaudalen) Effekt.\n\n\n\n\n\n\n\nAbbildung¬†10.30: Partielle Mediation",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#der-nachfahre",
    "href": "1100-kausal.html#der-nachfahre",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.10 Der Nachfahre",
    "text": "10.10 Der Nachfahre\nEin Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. Abbildung¬†10.31. Kontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet √ºber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise √∂ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildung¬†10.31: Ein Nachfahre verh√§lt sich √§hnlich wie sein Vorfahre‚Ä¶\n\n\n\n\n\n10.10.1 Kochrezept zur Analyse von DAGs\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder ge√∂ffnet ist.\nBeurteilen Sie f√ºr jeden Pfad, ob er ein Hintert√ºrpfad ist (Hintert√ºrpfade haben einen Pfeil, der zur UV f√ºhrt).\nWenn es ge√∂ffnete Hinterpfade gibt, pr√ºfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlie√üen (falls m√∂glich).",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#schlie√üen-sie-die-hintert√ºr-wenn-m√∂glich-bsp1",
    "href": "1100-kausal.html#schlie√üen-sie-die-hintert√ºr-wenn-m√∂glich-bsp1",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.11 Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, bsp1\n",
    "text": "10.11 Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, bsp1\n\nUV: \\(X\\), AV: \\(Y\\), drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\n\nAbbildung¬†10.32: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei Hintert√ºrpfade in Abbildung¬†10.32:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlie√üt die offene Hintert√ºr.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n10.11.1 Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, bsp2\n\nS. DAG in Abbildung¬†10.33: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildung¬†10.33: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintert√ºren zu schlie√üen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), ‚ÄöS. 188.\n\n10.11.2 Implizierte bedingte Unabh√§ngigkeiten von bsp2\n\nEin Graph ohne Us ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme. Auch wenn die Daten nicht sagen k√∂nnen, welcher DAG der richtige ist, k√∂nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten Unabh√§ngigkeiten geben uns M√∂glichkeiten, zu pr√ºfen, ob wir einen DAG verwerfen (ausschlie√üen) k√∂nnen. Bedingten Unabh√§ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabh√§ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte Unabh√§ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#fazit",
    "href": "1100-kausal.html#fazit",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.12 Fazit",
    "text": "10.12 Fazit\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren k√∂nnen, h√§ngt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen k√∂nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. ‚ÄúDer Unterschied zwischen beiden Gruppen betr√§gt etwa ‚Ä¶‚Äù. Allerdings ist eine kausale Interpretation nicht zul√§ssig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht m√∂glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen d√ºrfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten √§ndern sich (oft), wenn man Pr√§diktoren zum Modell hinzuf√ºgt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, m√∂glichst viele Pr√§diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der ‚Äúkausalen Atome‚Äù ist Voraussetzung zur Ableitung von Kausalschl√ºsse in Beobachtungsstudien.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#aufgaben",
    "href": "1100-kausal.html#aufgaben",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.13 Aufgaben",
    "text": "10.13 Aufgaben\n\nSammlung ‚Äúkausal‚Äù",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1100-kausal.html#section",
    "href": "1100-kausal.html#section",
    "title": "10¬† Kausalinferenz",
    "section": "\n10.14 ‚Äî",
    "text": "10.14 ‚Äî\n\n\n\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. ‚ÄûChocolate Consumption, Cognitive Function, and Nobel Laureates‚Äú. New England Journal of Medicine 367 (16): 1562‚Äì64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. ‚ÄûThinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data‚Äú. Advances in Methods and Practices in Psychological Science 1 (1): 27‚Äì42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "Kausalit√§t",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Kausalinferenz</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie k√∂nnen ‚Ä¶\n\nerl√§utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische ‚ÄúLieblingsfehler‚Äù benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik √ºbersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n11.1.2 Ben√∂tigte R-Pakete\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.2 Lieblinglingsfehler",
    "text": "11.2 Lieblinglingsfehler\nLieblingsfehler im √úberblick ü§∑:\n\nPost-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPr√§diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#post-pr√§d-verteilung-ppv-und-post-verteilung-verwechseln",
    "href": "1200-abschluss.html#post-pr√§d-verteilung-ppv-und-post-verteilung-verwechseln",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.3 Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑",
    "text": "11.3 Post-Pr√§d-Verteilung (PPV) und Post-Verteilung verwechseln ü§∑\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle¬†11.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle¬†11.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. H√§ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und Punktsch√§tzer auszulesen.\nDie Posterior-Pr√§diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n\n\nname\nvalue\n\n\n\nMazda RX4\n24.37754\n\n\nMazda RX4 Wag\n27.79282\n\n\nDatsun 710\n22.27664\n\n\nHornet 4 Drive\n26.68591\n\n\nHornet Sportabout\n10.76491",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "href": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.4 Quantile und Verteilungsfuntion verwechseln ü§∑",
    "text": "11.4 Quantile und Verteilungsfuntion verwechseln ü§∑\n\n11.4.1 Quantil f√ºr \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung¬†11.1.\n\n\n\n\n\n\n\nAbbildung¬†11.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betr√§gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist gr√∂√üer oder gleich dem \\(p\\)-Quantil.\n\n11.4.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung¬†11.2.\n\n\n\n\n\n\n\nAbbildung¬†11.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betr√§gt hier 50%, dass \\(x\\) nicht gr√∂√üer ist als 0.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "href": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.5 Interaktion falsch interpretieren ü§∑",
    "text": "11.5 Interaktion falsch interpretieren ü§∑\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber k√ºrzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. Tabelle¬†11.2.\n\nparameters(m2)\n\n\n\n\nTabelle¬†11.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.65\n(18.91, 30.09)\n100%\n1.002\n2045.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.92%\n1.001\n2022.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.92\n(4.72, 23.05)\n99.88%\n1.002\n1378.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.03)\n99.52%\n1.002\n1540.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle¬†11.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\n\n\n\nAbbildung¬†11.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch üòà Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11.\nRichtig üëº Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betr√§gt ca. -0.11 ‚Äì wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Pr√§diktoren w√§ren hier eine sinnvolle L√∂sung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.6 Kochrezepte üç≤",
    "text": "11.6 Kochrezepte üç≤\n\n11.6.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen √ºber ein Ph√§nomen, \\(y\\), Kausalfrage finden 2. Literatur w√§lzen, um m√∂gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese pr√§zisieren 4. Modell pr√§zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell pr√ºfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n11.6.2 Parameter sch√§tzen vs.¬†Hypothesen pr√ºfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter sch√§tzen. Beispiel Hypothesenpr√ºfung: ‚ÄúFrauen parken im Durchschnitt schneller ein als M√§nner‚Äù. Beispiel Parametersch√§tzung: ‚ÄúWie gro√ü ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und M√§nnern?‚Äù\nJe ausgereifter ein Forschungsfeld, desto k√ºhnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die n√§chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die n√§chste Sonnenfinsternis wird in den n√§chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen f√ºr den Klausurerfolg. K√ºhne Hypothesen sind w√ºnschenswert ü¶π\n\n11.6.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist h√∂her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist gr√∂√üer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.7 Kerngedanken Bayes",
    "text": "11.7 Kerngedanken Bayes\n\n11.7.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung¬†11.4.\n\n\n\n\n\n\n\nAbbildung¬†11.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist m√∂glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind m√∂glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings √ºbermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n11.7.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-f√ºr-pr√ºfungsaufgaben",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.8 Beispiele f√ºr Pr√ºfungsaufgaben",
    "text": "11.8 Beispiele f√ºr Pr√ºfungsaufgaben\n\n11.8.1 Geben Sie den korrekten Begriff an!\nüå¨üöôüôãÔ∏èüë®‚¨ÖÔ∏èHans üëß‚¨ÖÔ∏èAnna üë©‚¨ÖÔ∏èLise\nPuh, wie erstelle ich f√ºr alle Studis ein anderes R√§tsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-Pr√ºfung bekommen alle Studentis eine eigene, jeweils andere Pr√ºfung. Teamarbeit bleibt nat√ºrlich trotzdem untersagt.\n\n\n\n11.8.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung¬†11.5.\n\n\n\n\n\n\n\nAbbildung¬†11.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n‚ùìGeben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n‚ùó Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n11.8.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung¬†11.6.\n\n\n\n\n\n\n\nAbbildung¬†11.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n11.8.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung¬†11.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung¬†11.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set f√ºr den totalen Kausaleffekt: {AIS, ALN}\n\n11.8.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPr√ºfungsfragen zu Modellen k√∂nnten z.B. sein:\n\nGeben Sie den Punktsch√§tzer (Median) f√ºr den Pr√§diktor X im Modell Y an!\nGeben Sie ein 89%-HDI f√ºr den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris ‚Ä¶\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI f√ºr den Pr√§diktor X im Modell Y?\nWas ver√§ndert sich an den Parametern, wenn Sie die Pr√§diktoren zentrieren/z-standardisieren?\n‚Ä¶",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-pr√ºfung",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.9 Viel Erfolg bei der Pr√ºfung!",
    "text": "11.9 Viel Erfolg bei der Pr√ºfung!\nü•≥üèÜ",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "\n11¬† Abschluss\n",
    "section": "\n11.10 ‚Äî",
    "text": "11.10 ‚Äî\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. ‚ÄûThe SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs‚Äú. European Psychiatry 29 (7): 437‚Äì48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. ‚ÄúMisconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.‚Äù Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, G√ºnther. 2018. Wahrscheinlichkeitsrechnung Und Schlie√üende\nStatistik: Praxisorientierte Einf√ºhrung: Mit Aufgaben Und L√∂sungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\n‚Äî‚Äî‚Äî. 2022. Statistik-√úbungen: Beschreibende Statistik ‚Äì\nWahrscheinlichkeitsrechnung ‚Äì Schlie√üende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the\nBehavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja,\nSitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and\nDaniel M. Croymans. 2021. ‚ÄúBehavioural Nudges Increase\nCOVID-19 Vaccinations.‚Äù Nature 597 (7876,\n7876): 404‚Äì9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nForum, World Economic. 2020. ‚ÄúThe Future of\nJobs Report 2020.‚Äù CH-1223 Cologny/Geneva\nSwitzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\n‚ÄúR-Squared for Bayesian Regression Models.‚Äù The\nAmerican Statistician 73 (3): 307‚Äì9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2020.\n‚ÄúRstanarm: Bayesian Applied Regression Modeling via\nStan.‚Äù https://mc-stan.org/rstanarm.\n\n\nHenze, Norbert. 2019. Stochastik: Eine Einf√ºhrung mit Grundz√ºgen der\nMa√ütheorie: Inkl. zahlreicher Erkl√§rvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of\nScience. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nKampen, D. van. 2014. ‚ÄúThe SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.‚Äù European\nPsychiatry 29 (7): 437‚Äì48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. ‚ÄúRejecting or Accepting Parameter\nValues in Bayesian Estimation.‚Äù Advances\nin Methods and Practices in Psychological Science 1 (2): 270‚Äì80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel L√ºdecke. 2019. ‚ÄúIndices of Effect Existence\nand Significance in the Bayesian\nFramework.‚Äù Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. ‚ÄúChocolate Consumption,\nCognitive Function, and Nobel\nLaureates.‚Äù New England Journal of Medicine 367\n(16): 1562‚Äì64. https://doi.org/10.1056/NEJMon1211064.\n\n\nMittag, Hans-Joachim, and Katharina Sch√ºller. 2020. Statistik: Eine\nEinf√ºhrung mit interaktiven Elementen. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B.\nGubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021.\n‚ÄúEffectiveness of mRNA and\nChAdOx1 COVID-19 Vaccines Against Symptomatic\nSARS-CoV-2 Infection and Severe Outcomes with Variants of\nConcern in Ontario,‚Äù September, 2021.06.28.21259420.\nhttps://doi.org/10.1101/2021.06.28.21259420.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi,\nMohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner.\n2021. ‚ÄúEfficacy and Safety of COVID-19\nVaccines: A Systematic Review and\nMeta-Analysis of Randomized Clinical\nTrials.‚Äù Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nRohrer, Julia M. 2018. ‚ÄúThinking Clearly About\nCorrelations and Causation: Graphical Causal\nModels for Observational Data.‚Äù Advances\nin Methods and Practices in Psychological Science 1 (1): 27‚Äì42. https://doi.org/10.1177/2515245917745629.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball,\nAllison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021.\n‚ÄúEffectiveness of Covid-19 Vaccines in\nAmbulatory and Inpatient Care\nSettings.‚Äù New England Journal of Medicine 385\n(15): 1355‚Äì71. https://doi.org/10.1056/NEJMoa2110362.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. ‚ÄúThe\nASA Statement on p-Values:\nContext, Process, and Purpose.‚Äù The American\nStatistician 70 (2): 129‚Äì33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]