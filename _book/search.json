[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "Bayes:Start!\n\n\n\n\nNach diesem Kurs sollten Sie …\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden können\ngängige einschlägige Forschungsfragen in statistische Modelle übersetzen und mit R auswerten können\nkausale Forschungsfragen in statistische Modelle übersetzen und prüfen können\ndie Güte und Grenze von statistischen Modellen einschätzen können\n\n\n\n\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, möglichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\n\n\n\n\nInstallieren Sie R und seine Freunde.\nInstallieren Sie die folgende R-Pakete:\n\ntidyverse\nrstanarm\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\n\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.\n\n\n\n\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen während des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeiträgen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      Nr\n      Thema\n      Datum\n      Kommentar\n    \n  \n  \n    1\nWas ist Inferenz?\n3. - 7. Okt. 2022\nDie erste Unterrichtsstunde fällt auf den 7. Okt. 2023.\n    2\nWahrscheinlichkeit\n10. - 14. Okt. 22\nNA\n    3\nHallo, Bayes\n17. - 21. Okt. 22\nNA\n    4\nDie Post befragen\n24. - 28. Okt. 22\nNA\n    5\nGauss-Modelle\n31. Okt. - 4. Nov. 22\nNA\n    6\nLineare Modelle\n7. - 11. Nov. 22\nNA\n    NA\nBLOCKWOCKE\n14. - 18. Nov. 22\nKein regulärer Unterricht\n    7\nMetrische AV\n21. - 25. Nov. 22\nNA\n    8\nFallstudien\n28. Nov. - 2. Dez. 22\nNA\n    9\nKausalinferenz 1\n5. Dez. - 9. Dez. 22\nNA\n    10\nKausalinferenz 2\n12. - 16. Dez. 22\nNA\n    11\nBinäre AV\n19. - 23. Dez. 22\nNA\n    NA\nWEIHNACHTSFERIEN\nNA\nKein Unterricht\n    12\nAbschluss\n9. Jan. 23 - 13. Jan. 23\nNA\n  \n  \n  \n\n\n\n\n\n\n\nPro Thema wird Literatur ausgewiesen.\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2022-09-06\n pandoc   2.19.2 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.2.0)\n cli           3.3.0      2022-04-25 [1] CRAN (R 4.2.0)\n colorout    * 1.2-2      2022-06-13 [1] local\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.0)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.16       2022-08-09 [1] CRAN (R 4.2.0)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n ggplot2       3.3.6.9000 2022-09-05 [1] Github (tidyverse/ggplot2@a58b48c)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt            0.7.0      2022-08-25 [1] CRAN (R 4.2.0)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.0      2022-02-22 [1] CRAN (R 4.2.0)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.0)\n lifecycle     1.0.2      2022-09-05 [1] Github (r-lib/lifecycle@f92faf7)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n purrr         0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n readxl        1.4.1      2022-08-17 [1] CRAN (R 4.2.0)\n rlang         1.0.5      2022-08-31 [1] CRAN (R 4.2.0)\n rmarkdown     2.16       2022-08-24 [1] CRAN (R 4.2.0)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.0)\n sass          0.4.2      2022-07-16 [1] CRAN (R 4.2.0)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyselect    1.1.2      2022-02-21 [1] CRAN (R 4.2.0)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n vctrs         0.4.1      2022-04-13 [1] CRAN (R 4.2.0)\n xfun          0.32       2022-08-10 [1] CRAN (R 4.2.0)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.0)\n\n [1] /Users/sebastiansaueruser/Rlibs\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Pruefung.html",
    "href": "Pruefung.html",
    "title": "1  Prüfung",
    "section": "",
    "text": "Die Prüfungsleistung besteht aus einer Open-Book-Prüfung."
  },
  {
    "objectID": "Pruefung.html#grundsätzlichkeit",
    "href": "Pruefung.html#grundsätzlichkeit",
    "title": "1  Prüfung",
    "section": "1.2 Grundsätzlichkeit",
    "text": "1.2 Grundsätzlichkeit\nDie folgenden Hinweise gelten grundsätzlich, d.h. soweit nicht anders in der jeweiligen Prüfung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von Prüfungshinweisen kann zu Punkteabzug oder Nichtbestehen führen."
  },
  {
    "objectID": "Pruefung.html#wiederholungsprüfungen",
    "href": "Pruefung.html#wiederholungsprüfungen",
    "title": "1  Prüfung",
    "section": "1.3 Wiederholungsprüfungen",
    "text": "1.3 Wiederholungsprüfungen\n\nWenn Sie bei einer Prüfung durchgefallen sein sollten, so haben Sie grundsätzlich die Möglichkeit, die Prüfung zu wiederholen.\nDenken Sie daran, sich rechtzeitig für Prüfungsleistungen anzumelden; beachten Sie die Fristen.\nDie Termine für die Wiederholungsprüfungen werden stets zusammen/zeitgleich mit denen der regulären Prüfungen in Primuss bekannt gegeben.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine Wiederholungsprüfung nur für Studentis, die durchgefallen sind. Abweichend davon kann ei Dozenti die Prüfung für alle Studentis anbieten. Die Entscheidung, ob eine Wiederholungsprüfung in diesem Fall angeboten wird, obliegt der Dozentin bzw. dem Dozenten des Moduls.\nRelevanter Stoff und formale Bedingungen (wie Prüfungsform) sind grundsätzlich identisch zur letzten abgehaltenen Prüfung des Moduls (d.h. sofern nicht anders angegeben). Daher sind Wiederholungsprüfungen vom Anspruch vergleichbar wie die reguläre Klausur. Die Prüfungen sollen möglichst gleich vom Anspruch sein, um Fairness zu gewährleisten.\nBeachten Sie immer die Hinweise, die für die Wiederholungsprüfung angegeben sind. Im Einzelfall keine eine Wiederholungsprüfung von der vorherigen Prüfung stärker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen Wiederholungsprüfung veröffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine Wiederholungsprüfung. Stattdessen können Sie ggf. an der regulären Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist möglich, dass der Stoff sich dann substanziell ändert; meist halten sich die Änderungen (im Stoff) aber in Rahmen.\nSprechen Sie die Moduldozentis an für Details zur Prüfung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine Prüfung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben, es kommt auf den Einzelfall an. Grundsätzlich rate ich aber dazu, Prüfungen nicht zu verschieben: Schließlich könnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum Prüfungsrecht sprechen Sie bitte die Studienberatung an."
  },
  {
    "objectID": "Pruefung.html#bearbeitungshinweise",
    "href": "Pruefung.html#bearbeitungshinweise",
    "title": "1  Prüfung",
    "section": "1.4 Bearbeitungshinweise",
    "text": "1.4 Bearbeitungshinweise\n\nVerwenden Sie Standardwerte (defaults) der R-Funktionen.\nRunden Sie ggf. auf eine Dezimalstelle.\nVerwenden Sie Methoden der Bayes-Statistik für inferenzstatistische Analysen.\nGeben Sie keine Prozentzahlen an, sondern Anteile (also nicht “50%”, sondern “0.5” bzw. “0,5”).\nFindet sich in einer Auswahlliste möglicher Antworten nicht die exakte Lösung, wählen Sie die am besten passende.\nTreffen Sie Annahmen, wo nötig.\nDie Prüfung besteht zu einem großen Teil aus Multiple-Choice- (MC-)-Aufgaben mit mehreren Antwortoptionen.\nBei Multiple-Choice-Aufgaben (MC-Aufgaben) ist zumeist genau eine Antwortoption auszuwählen aus vier oder fünf Antwortoptionen.\nIm Zweifel ist eine Aussage auf den Stoff, so wie im Unterricht behandelt, zu beziehen.\nBei Fragen zu R-Syntax spielen Aspekte wie Enter-Taste o.Ä. bei der Beantwortung der Frage keine Rolle; diese Aspekte dürfen zu ignorieren.\nJede Aussage einer MC-Aufgabe ist entweder richtig oder falsch (aber nicht beides oder keines).\nDie MC-Aufgaben sind nur mit Kreuzen zu beantworten; Text wird bei der Korrektur nicht berücksichtigt.\nJede Aussage gilt ceteris paribus (unter sonst gleichen Umständen). Aussagen der Art „A ist B“ (z.B. “Menschen sind sterblich”) sind nur dann als richtig auszuwählen, wenn die Aussage immer richtig ist.\nBei Aufgaben, die eine Zahl als Antwort verlangen, ist nur eine Zahl anzugeben (nicht etwa Buchstaben).\nFalls Sie bei einer Aufgabe mehrere Antworten finden, aber nur nach einer gefragt ist, geben Sie nur eine an.\nFalls mehrere (widersprüchliche) Antworten gegeben wurden, wird im Zweifel die erst genannte gewertet.\nDie Aufgabenstellung in einer Moodle-Prüfung wird erst sichtbar, wenn Sie den Prüfungsbedingungen zugestimmt haben und die Prüfungszeit begonnen hat.\nJe nach Spracheinstellung in Moodle kann es sein, dass Sie als Dezimaltrennzeichen ein Komma oder einen Punkt verwenden müssen. Moodle weist Sie, wenn Sie die Aufgabe verlassen, darauf hin, falls eine Zahl nicht als Zahl erkannt wurde."
  },
  {
    "objectID": "Pruefung.html#teilnahmebedingungen",
    "href": "Pruefung.html#teilnahmebedingungen",
    "title": "1  Prüfung",
    "section": "1.5 Teilnahmebedingungen",
    "text": "1.5 Teilnahmebedingungen\n\nDie Prüfung ist selbständig, also alleine nur durch Sie, ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der Prüfung sind einzuhalten.\nEs dürfen nur die explizit als zulässig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulässigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, Bücher sowie Quellen aus dem Internet.\nDie Übernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wörtliche Übernahme (“copy-paste”) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulässig.\nBei technischen Problemen ist sofort der Prüfer bzw. die Prüferin zu verständigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die Prüfung bzw. Teile daraus (z.B. Prüfungsfragen) zu speichern oder weiterzugeben.\nIm Übrigen gelten die allgemeinen Prüfungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht Prüflingen, kommuniziert werden während der Prüfung. Dies gilt auch für den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den Prüfer, wenn Sie meinen, es liege ein technisches Problem vor.\nDas Nichtbeachten der Regeln kann zu Notenabzug oder Nichtbestehen führen."
  },
  {
    "objectID": "Pruefung.html#organisatorische-hinweise",
    "href": "Pruefung.html#organisatorische-hinweise",
    "title": "1  Prüfung",
    "section": "1.6 Organisatorische Hinweise",
    "text": "1.6 Organisatorische Hinweise\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prüfungsrelevant.\nIm Übrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung für formale oder rechtliche Fragen.\nWährend der Prüfung werden nur Fragen beantwortet, die für die Bearbeitung zwingend nötig sind (etwa bei technischen Problemen).\nEs werden keine Fragen der Art “Ist diese Aufgabe klar formuliert?” beantwortet während der Prüfung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der Prüfung=. Der Prüfer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der Prüfung ist nur möglich, wenn Sie den Teilnahmebedingungen der Prüfung zustimmen.\nDie Aufgabenstellung der Prüfung wird nur während des Prüfungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppenteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte Prüfungsuhrzeit (Beginn, Ende).\nPrüfungszeitraum, Aufgabenstellung und sonstige Materialien können variieren zwischen den Prüflingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusätzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der Prüfung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor erhöht."
  },
  {
    "objectID": "Pruefung.html#open-book-prüfungen",
    "href": "Pruefung.html#open-book-prüfungen",
    "title": "1  Prüfung",
    "section": "1.7 Open-Book-Prüfungen",
    "text": "1.7 Open-Book-Prüfungen\nEinige Prüfungen werden als “Take-home-Prüfung” im “Open-Book-Format” geschrieben. Was bedeutet dies?\n“Take-home-Prüfung”: Sie bearbeiten die Prüfung in Ihrem privaten Umgebung in Moodle oder in Räumlichkeiten der Hochschule. Eine Überwachung per Kamera findet nicht statt.\n“Open-Book-Prüfung”: Sie dürfen Hilfsmittel wie Bücher und Folien während der Prüfung nutzen.\nIhre Prüferin/Ihr Prüfer informiert Sie über das Format Ihrer Prüfung."
  },
  {
    "objectID": "Pruefung.html#zeitrahmen-der-prüfung",
    "href": "Pruefung.html#zeitrahmen-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.8 Zeitrahmen der Prüfung",
    "text": "1.8 Zeitrahmen der Prüfung\nDie Prüfung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die Prüfung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). Verspätete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der Prüfung wird Ihnen von Ihrer Prüferin bzw. Ihrem Prüfer bekannt gegeben."
  },
  {
    "objectID": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prüfung",
    "href": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prüfung",
    "title": "1  Prüfung",
    "section": "1.9 Technische und organisatorische Anforderungen einer Open-Book-Prüfung",
    "text": "1.9 Technische und organisatorische Anforderungen einer Open-Book-Prüfung\nUm an einer Open-Book-Prüfung teilzunehmen, benötigen Sie IT-Ausstattung sowie Räumlichkeiten. An IT-Ausstattung benötigen Sie einen Computer mit Internetanschluss; ein Smartphone reicht nicht aus. Nutzen Sie Ihr eigenes Gerät (Computer) für die Prüfung; die Hochschule stellt Ihnen keinen Computer zur Verfügung. Sie benötigen keine Webcam und kein Mikrofon. Ein Tablett oder Smartphone reicht nicht für die Prüfung. An Software benötigen Sie Zugang zu Ihrem Moodle-Konto, was einen aktuellen Internet-Browser voraussetzt. Zu den organisatorischen Anforderungen gehören ein Raum, in dem Sie die Prüfung ungestört bearbeiten können sowie ein Internetanschluss zum Bearbeiten der Klausur in Moodle. Bitte benutzen Sie während der Prüfung nicht den Zurück-Button in Ihrem Browser, wenn Sie zu einer vorherigen Frage zurückgehen wollen. Nutzen Sie die in der Prüfung zur Verfügung gestellten Funktionen/Buttons dafür."
  },
  {
    "objectID": "Pruefung.html#technische-probleme-während-der-prüfung",
    "href": "Pruefung.html#technische-probleme-während-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.10 Technische Probleme während der Prüfung",
    "text": "1.10 Technische Probleme während der Prüfung\nIm Falle eines technischen Problems auf Seiten der Prüfungsinfrastruktur ist sofort der Prüfer zu informieren. Ein Beispiel für so ein Problem wäre etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der Prüfer bzw. die Hochschule keine Gewähr übernimmt für Probleme mit Ihrer eigenen Ausstattung."
  },
  {
    "objectID": "Pruefung.html#prüfungsrecht",
    "href": "Pruefung.html#prüfungsrecht",
    "title": "1  Prüfung",
    "section": "1.11 Prüfungsrecht",
    "text": "1.11 Prüfungsrecht\nFür die Open-Book-Prüfungg gilt die aktuelle Prüfungsordnung; die Open-Book-Prüfung fällt nicht unter die BayFEV."
  },
  {
    "objectID": "Pruefung.html#datenschutz",
    "href": "Pruefung.html#datenschutz",
    "title": "1  Prüfung",
    "section": "1.12 Datenschutz",
    "text": "1.12 Datenschutz\nPersönliche Daten werden an eine Stellen übermittelt: Moodle (über bzw. in Ihre Konto). Es findet keine Überwachung statt, weder kamaragestützt, akustisch oder softwaregestützt."
  },
  {
    "objectID": "Pruefung.html#plagiatskontrolle",
    "href": "Pruefung.html#plagiatskontrolle",
    "title": "1  Prüfung",
    "section": "1.13 Plagiatskontrolle",
    "text": "1.13 Plagiatskontrolle\nIhre Prüfungsarbeiten können auf Plagiate hin untersucht werden. Dabei kommen auch automatisierte Verfahren zum Einsatz. Ihre Arbeiten werden dabei nicht online gestellt und auch nicht Dritten zugänglich gemacht. Alle Prüfungen finden auf Rechnern statt, zu denen nur die Prüfer/innen Zugang habe. Es werden keine persönlichen Daten (von Ihnen) weitergegeben.\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Überlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getäuscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafür bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit “nicht bestanden” bewertet). Die genauen Konsequenzen legt die Prüfungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire Prüfung heißt: Gleiche Chancen für alle, und gute Leistung soll belohnt werden, Täuschung nicht."
  },
  {
    "objectID": "Pruefung.html#typische-fehler-in-der-prüfung",
    "href": "Pruefung.html#typische-fehler-in-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.14 Typische Fehler in der Prüfung",
    "text": "1.14 Typische Fehler in der Prüfung\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heißt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heißt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter “Environment” angezeigt wird. Außerdem können Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort können Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das Paket gestartet zu haben: Mit data(datensatz) können Sie den Datensatz datensatz nur dann verfügbar machen, wenn das Paket, in dem datensatz “wohnt”, mit library(paketname) gestartet worden ist. So “wohnt” z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Übung (und weitere Erklärung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins."
  },
  {
    "objectID": "Pruefung.html#hinweise-zu-scheinmängeln",
    "href": "Pruefung.html#hinweise-zu-scheinmängeln",
    "title": "1  Prüfung",
    "section": "1.15 Hinweise zu Scheinmängeln",
    "text": "1.15 Hinweise zu Scheinmängeln\nImmer wieder kommt es vor, dass Studierende Beanstandungen zu einer Prüfung vorbringen. Teilweise sind diese gerechtfertigt, teilweise nicht. Im Folgenden sehen Sie eine Auswahl an nicht gerechtfertigten Beanstandungen, also nur scheinbaren Mängeln, keine wirklichen Mängel, in einer Prüfung.\n\n“Das zu wählende Vorgehen war nicht 100% klar” – Wenn Sie der Meinung sind, dass das zu wählende Vorgehen (zum Lösen der Aufgabe) nicht komplett klar ist, treffen Sie Annahmen und weisen Sie darauf hin, dass Sie Annahmen getroffen haben. Zum anderen halten Sie sich an das Vorgehen aus dem Unterricht (bzw. den Unterlagen und der Literatur, die im Unterricht verwendet wurde). Eine andere Situation läge vor, wenn die Aufgabe nicht lösbar ist ohne weitere Angaben lösbar ist(“Ist ein Effekt bei n=100 signifikant?”). Im Falle einer nicht lösbaren Aufgabe liegt fer Fehler beim Prüfer.\n“Ich sollte einen Punkt (ein Komma) als Dezimaltrennzeichen verwenden, aber Moodle hat ein Komma (einen Punkt) verlangt!” – Je nach Spracheinstellung in Moodle kann es sein, dass Moodle nur einen Punkt als Dezimaltrennzeichen bzw. ein Komma als Dezimaltrennzeichen verwendet. Moodle weist Sie aber darauf hin, wenn eine Zahl nicht als Zahl erkannt wird, und zwar wenn Sie zur nächsten Aufgabe geben. Sie können also ohne Probleme den Fehler korrigieren. Darüber hinaus ist bei den Prüfungshinweisen vorab auf diesen Punkt verwiesen."
  },
  {
    "objectID": "Inferenz.html",
    "href": "Inferenz.html",
    "title": "2  Inferenz",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Inferenz.html#lernsteuerung",
    "href": "Inferenz.html#lernsteuerung",
    "title": "2  Inferenz",
    "section": "2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Definition von Inferenzstatistik sowie Beispiele für inferenzstatistische Fragestellungen nennen\nzentrale Begriffe nennen und in Grundzügen erklären\nden Nutzen von Inferenzstatistik nennen\nerläutern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nauch anhand von Beispielen erklären, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs. Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklären können"
  },
  {
    "objectID": "Inferenz.html#wozu-ist-statistik-überhaupt-da",
    "href": "Inferenz.html#wozu-ist-statistik-überhaupt-da",
    "title": "2  Inferenz",
    "section": "2.2 Wozu ist Statistik überhaupt da?",
    "text": "2.2 Wozu ist Statistik überhaupt da?\nJa, diese Frage haben Sie sich auch schon mal gestellt?\nAbb. Figure 2.1 gibt einen Überblick über die Ziele der Statistik.\n\n\n\n\n\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n\n\n\n\n\nFigure 2.1: A taxonomy of statistical goals\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nZiele exsitieren nicht “in echt” in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heißt, dass man sich nach Beliebem Ziele ausdenken kann. Allerdings hülfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen überzeugen kann."
  },
  {
    "objectID": "Inferenz.html#was-ist-inferenz",
    "href": "Inferenz.html#was-ist-inferenz",
    "title": "2  Inferenz",
    "section": "2.3 Was ist Inferenz?",
    "text": "2.3 Was ist Inferenz?\n\n2.3.1 Inferenz als Generalisieren\nStatistische Inferenz sieht sich drei “Herausforderungen” gegenüber, laut Gelman, Hill, and Vehtari (2021), Kap. 1.1. Diese betreffen das Schließen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\nVon der Stichprobe aus die Grundgesamtheit (Population)\nVon der Experimental- auf die Kontrollgruppe (Kausalinferenz)\nVon einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs beschäftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n\n\n\nImportant\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schließen, bzw. vom Konrketen auf das Abstrakte."
  },
  {
    "objectID": "Inferenz.html#stichprobe-vs.-population",
    "href": "Inferenz.html#stichprobe-vs.-population",
    "title": "2  Inferenz",
    "section": "2.4 Stichprobe vs. Population",
    "text": "2.4 Stichprobe vs. Population\nNehmen wir an, wir möchten Herausfinden, wie groß der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A1\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\nWir müssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe für die Grundgesamtheit schließen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. Figure 2.2.\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nFigure 2.2: Population vs. sample (Image credit: Karsten Luebke)\n\n\nHäufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!2. Man schreibt: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei repräsentativ für die Grundgesamtheit aller Studierender. Messerscharf schließen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n2.4.1 Deskriptiv- vs. Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtigungen könnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. Figure 2.3. Einteilungen in Schubladen existieren nicht auf der Welt, sondern in unserem Kopf: Sie besitzen keine ontologische Realität, sondern eine epistemologische. Sie sind frei, sich andere Einteilungen der Statistik auszudenken. Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee überzeugen kann.\n\n\n\nFigure 2.3: Deskriptiv- vs. Inferenzstatistik\n\n\nDeskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\nInferenzstatistik schließt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\n🏋 Schließen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n2.4.2 Wozu ist die Inferenstatistik gut?\n\n\n\n\n\n\nNote\n\n\n\nInferenz bedeutet Schließen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schlüsse zu ziehen.\n🏋️️ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Üben Sie jetzt schon mal.\n\n\n2.4.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFür jede Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle Table 2.1.\n\n\n\n\nTable 2.1: Bezeichnungen für Kennwerte\n\n\nKennwert\nStichprobe\nGrundgesamtheit\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\n\n\n\n\n\nFür Statistiken (Stichprobe) verwendet man lateinische Buchstaben; für Parameter (Population) verwendet man griechische Buchstaben.\n🏋️ Geben Sie die griechischen Buchstaben für typische Statistiken an!\n\n\n2.4.4 Schätzen von Parametern einer Grundgesamtheit\nMeist begnügt man sich beim Analysieren von Daten nicht mit Aussagen für eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit Schätzungen begnügen.\nSchätzwerte werden mit einem “Dach” über dem Kennwert gekennzeichnet, z.B.\n\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchätzwert\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n2.4.5 Beispiele für inferenzstatistische Fragestellungen\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\).\nDie Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} > \\bar{X}_{V2}\\)\nSind diese Unterschiede “zufällig” oder “substanziell”? Gilt also \\(\\mu_{V1} > \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)?\nWie groß ist die Wahrscheinlichkeit3 \\(Pr(\\mu_{V1} > \\mu_{V2})\\)?\n\n🏋️ Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!"
  },
  {
    "objectID": "Inferenz.html#modellieren",
    "href": "Inferenz.html#modellieren",
    "title": "2  Inferenz",
    "section": "2.5 Modellieren",
    "text": "2.5 Modellieren\n\n2.5.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft, wie auch oft in der Technik, Wirtschaft oder im Alltag, betrachtet man einen Teil der Welt näher, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berücksichtigen ist nicht möglich. Wir müssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nötig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die für unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\n\n\n\n\n\nImportant\n\n\n\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n\n\nAuf die Statistik bezogen heißt das, dass man einen Datensatz zu zusammenfasst, dass man das Wesentliche erkennt. Was ist das “Wesentliche”? Meist interessiert man sich für die Ursachen eines Phänomens? Etwa: “Wie kommt es bloß, dass ich ohne zu lernen die Klausur so gut bestanden habe?”4 Noch allgemeiner ist vom häufig am Zusammenhang von X und Y interessiert, s. Abb. Figure 2.4, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\nFigure 2.4: Sinnbild eines stastistischen Modells\n\n\n\n\nDas Diagramm hat Sie nicht so vom Hocker? Okay, ein statistisches Modell kann natürlich komplexer sein, z.B. wie in Abb. Figure 2.5 dargestellt.\n\n\n\n\n\nflowchart LR\nX1 --> Y\nX2 --> Y\n\n\n\n\n\nFigure 2.5: Sinnbild eines stastistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\n\n\nEs hört sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n\n2.5.2 Vertiefung\nLesen Sie die Einführung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nNote\n\n\n\nNutzen Sie die Übersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch."
  },
  {
    "objectID": "Inferenz.html#regression",
    "href": "Inferenz.html#regression",
    "title": "2  Inferenz",
    "section": "2.6 Regression",
    "text": "2.6 Regression\n\n\n\nOne regression\n\n\n\n2.6.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmessen: Für vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schöner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nNote\n\n\n\nRegression + Inferenz = 💖\n\n\nAlternativ zur Regression könnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni Münster als Ausschnitt (!) aufgeführt.\nAuf dieser Basis kann man meditieren, welches statistischen Verfahren man für eine bestimmte Fragestellung verwenden sollte, s. Abb. Figure 2.6.\n\n\n\nFigure 2.6: Wähle deine Statistik mit Bedacht\n\n\n\n\n2.6.2 Viele statistische Verfahren sind Spezialfälle der Regression\nWie Jonas Kristoffer Lindeløv uns erklärt, sind viele statistische Verfahren, wie der sog. t-Test Spezialfälle der Regression, s. Abb. Figure 2.7.\n\n\n\nFigure 2.7: Common statistical tests as linear models\n\n\n\n\n2.6.3 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; Abb. Figure 2.8.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nAnhan der Gleichung erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet. Dabei wird X nicht mit “fortgeschrittenen” Transformationen wie Quadradieren oder Exponenzieren beglückt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n\n\n\nFigure 2.8: Die Regressionsgerade in voller Pracht"
  },
  {
    "objectID": "Inferenz.html#unsicherheit",
    "href": "Inferenz.html#unsicherheit",
    "title": "2  Inferenz",
    "section": "2.7 Unsicherheit",
    "text": "2.7 Unsicherheit\n\n2.7.1 Inferenz beinhaltet Unsicherheit\nInferenzstatistische Schlüsse sind mit Unsicherheit behaftet: Schließlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), möchte aber vom Teil auf das Ganze schließen.\n\n\n\n\n\n\nImportant\n\n\n\nNichts Genaues weiß man nicht: Schließt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen über das Ganze betrifft.\n\n\nSchließt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. Schließlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen für die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer möglich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n\n\n\n\n\nNote\n\n\n\nUnter einem zufälligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nächsten Würfelwurfs. Zufällig bedeutet nicht (zwangsläufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines Würfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\n🏋 Welche physikalischen Randbedingungen wirken wohl auf einen Münzwurf ein?\n\n\n2.7.2 Beispiele zur Quantifizierung von Ungewissheit\nAussagen mit Unsicherheit können unterschiedlich präzise formuliert sein.\n\nMorgen regnet’s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert für Methode \\(A\\) höher als für Methode \\(B\\).\nDie Maschine fällt demnächst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nächsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n🏋 Geben Sie weitere Beispiele an!\n\n\n2.7.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. Figure 2.9.\n\nWie (un)gewiss ist man sich über den Wert des Regressionsgewichts?\nWie (un)gewiss ist man sich über den Wert von Y? Schließlich könnte es ja Einflüsse (X) geben, die man nicht berücksichtigt hat.\n\n\n\n\n\n\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 übersehen? .-> B\n\n\n\n\n\n\nFigure 2.9: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n\n2.7.4 Ich weiß, was ich nicht weiß: Ungewissheit angeben\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der Schätzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schätzt, lässt aber offen wie sicher (präzise) die Schätzung ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Schätzung schließt sogar 41% oder 43% aus.\n::callout-important Eine Inferenz nennt man auch Schätzung. Es sollte immer die Genauigkeit (Ungewissheit) der Schätzung angegeben werden. :::\nIm Rahmen der Regressionsanalyse schlägt sich die Ungewissheit an zwei Stellen nieer:\n\nzur Lage der Regressionsgeraden (\\(\\beta_0\\), \\(\\beta_1\\))\nzu Einflüssen (X), die unser Modell nicht kennt (\\(\\epsilon, \\sigma\\))\n\n\n\n2.7.5 Visualisierung von Ungewissheit\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem Punktschätzer. Punktschäter beinhalten keine Angabe der Schätz(un)gen auigkeit, s. Abb. Figure 2.10.\n\n\n\n\n\nFigure 2.10: Eine Punktschätzung\n\n\n\n\nRot markiert: Die Punktschätzung von mpg für hp=200.\n🏋 Geben Sie ein vergleichbares Beispiel an!\n\n\n\nIn Abb. Figure 2.11 ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur Stärke des Zusammenhangs von X und Y?\n\n\n\n\n\nFigure 2.11: Ungewissheit in den Regressionskoeffizienten\n\n\n\n\nAuch wenn wir uns sicher im Hinblick auf die Regressionsgewichte in Abb. Figure 2.11 bliebe eine Restungewissheit: Unsere Schätzungen wären nicht sicher, nicht fehlerfrei. Das liegt daran, da das Modell nicht alle Einflüsse auf Y berücksichtigt, sondern nur einen, hier als X bezeichnet.\nIn Abb. Figure 2.12 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die “Restungewissheit” dargestellt. In diesem Fall spricht man von einem “Vorhersageintervall”, da man nicht nur von “typischen Fällen” auf der Regressiongeraden spricht, sondern für echte Fälle Vorhersagen (Schätzungen) tätigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n\n\n\nFigure 2.12: Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\n\n\n\n\nWie man sieht, wird die Ungewissheit größer, wenn man beide Arten der Ungewissheit berücksichtigt.\nDas Vorhersage-Intervall berücksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\n\n2.7.6 Konfidenzintervall\nWir sehen hier, dass ein “Ungewissheitskorridor” angegeben wird. Entsprechend wird nicht ein Punktschätzer, sondern ein Schätzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich5\nEin Konfidenzintervall wird häufig mit 90% oder 95% Genauigkeit angegeben.\nIm Kontext der Bayes-Analyse ist das einfach zu interpretieren.\nSagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall für den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.\nDieser Befund läßt sich so interpretieren:\n“Laut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.”\n\n\n\n\n\n\nImportant\n\n\n\nEin Konfidenzintervall gibt einen Schätzbereich plausibler Werte für den gesuchten Wert in der Population (den Parameter) an.\n\n\n🏋 Interpretieren Sie den Ungewissheitskorridor!"
  },
  {
    "objectID": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "2  Inferenz",
    "section": "2.8 Klassische vs. Bayes-Inferenz",
    "text": "2.8 Klassische vs. Bayes-Inferenz\n\n2.8.1 Klassische Inferenz: Frequentismus\n\nDie Berücksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurückgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein\nWahrscheinlichkeit wird über relative Häufigkeiten definiert.\nEs ist nicht möglich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie häufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr häufig wiederholt ist.\nEin Großteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.8.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) fließt explizit in die Analyse ein (zusammen mit den Daten).\nWenn das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen für Hypothesen möglich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (für gängige Computer) komfortabel geworden.\n\n\n\n2.8.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.8.3.1 Frequentismus\n\nzentrale Statistik: p-Wert\n“Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufällig verschieden und auf Basis unseres Modells)?”\nFindet man \\(p<.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von “(statistischer) Signifikanz” und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n\n\n2.8.3.2 Bayes-Statistik\n\nzentrale Statistik: Posteriori-Verteilung\n“Wie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Baiss unseres Modells?”\n\n🏋 Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\n\n\n\n2.8.4 Frequentist und Bayesianer\n\n\n\nFrequentist wettet mit Bayesianer\n\n\nQuelle\n\n\n2.8.5 Der p-Wert ist wenig intuitiv\n\n\nfrom Imgflip Meme Generator\n\n\n\n2.8.6 Beispiel zum Nutzen von Apriori-Wissen 1\n\nEin Betrunkener behauptet, er könne hellsehen.\nEr wirft eine Münze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die Münze fair ist, dass Ergebnis also “zufällig” ist.\nUnser Vorwissen lässt uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zufälligkeit des Ergebnisses wohl nicht verwerfen.\n\n\n\n2.8.7 Beispiel zum Nutzen von Apriori-Wissen 2\n\nEine Studie fand einen “großen Effekt” auf das Einkommen von Babies, eine Stunde pro Woche während zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\).\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% höher (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lässt uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lässt. Wir würden den Effekt lieber in einem konservativeren Intervall schätzen (enger um Null)."
  },
  {
    "objectID": "Inferenz.html#literatur",
    "href": "Inferenz.html#literatur",
    "title": "2  Inferenz",
    "section": "2.9 Literatur",
    "text": "2.9 Literatur\nBei Gelman, Hill, and Vehtari (2021), Kap. 1 findet sich eine Darstellung ähnlich zu der in diesem Kapitel."
  },
  {
    "objectID": "Inferenz.html#aufgaben",
    "href": "Inferenz.html#aufgaben",
    "title": "2  Inferenz",
    "section": "2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2\ninferenz-fuer-alle\nadjustieren1\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  },
  {
    "objectID": "Wskt.html",
    "href": "Wskt.html",
    "title": "3  Wahrscheinlichkeit",
    "section": "",
    "text": "Bourier, Günther. 2013. Wahrscheinlichkeitsrechnung Und Schließende Statistik: Praxisorientierte Einführung ; Mit Aufgaben Und Lösungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik – Wahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Verteilungen.html",
    "href": "Verteilungen.html",
    "title": "4  Verteilungen",
    "section": "",
    "text": "Bourier, Günther. 2013. Wahrscheinlichkeitsrechnung Und Schließende Statistik: Praxisorientierte Einführung ; Mit Aufgaben Und Lösungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik – Wahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Globusversuch.html",
    "href": "Globusversuch.html",
    "title": "5  Globusversuch",
    "section": "",
    "text": "Bayes:Start"
  },
  {
    "objectID": "Globusversuch.html#von-welten-und-golems",
    "href": "Globusversuch.html#von-welten-und-golems",
    "title": "5  Globusversuch",
    "section": "5.1 Von Welten und Golems",
    "text": "5.1 Von Welten und Golems\n\n5.1.1 Kleine Welt, große Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika. Das war aber ein glücklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb Figure 5.1.\n\n\n\nFigure 5.1: Behaims Globus: Kein Amerika\n\n\nDie kleine Welt des Modells entsprach hier nicht der großen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel für, sagen wir, die Komplexität wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Glück gehört halt auch dazu.\n\nKleine Welt vs. große Welt\n\n\n\n\n\n\nKleine Welt\nGroße Welt\n\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangsläufig) die Wirklichkeit\nentspricht nicht (zwangsläufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt ist nicht die große Welt.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der großen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schlüssen und vermeintlicher Gewissheit.\n🏋 Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n\n5.1.2 Der Golem von Prag\n\n\n\nDer Golem von Prag\n\n\nQuelle\nDer Golem von Prag, eine vom Menschen geschaffene Kreatur gewaltiger Kraft, die Befehle wörtlich ausführt.\nBei kluger Führung kann ein Golem Nützliches vollbringen.\nBei unüberlegter Verwendung wird er jedoch großen Schaden anrichten.\n\n\n5.1.3 Wissenschaftliche Modelle sind wie Golems\nGolem\n\n\nBesteht aus Lehm\nBelebt durch “Wahrheit”\nMächtig\ndumm\nFührt Befehle wörtlich aus\nMissbrauch leicht möglich\nMärchen\n\nModell\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\n\n\n\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mächtig\nsimpler als die Realität\nFührt Befehle wörtlich aus\nMissbrauch leicht möglich\nNicht einmal falsch\n\n\n\n\n\n\n\nImportant\n\n\n\nWir bauen Golems.\n\n\n\n\n5.1.4 So denkt unser Bayes-Golem\n\n\n\nSo denkt unser Bayes-Golem\n\n\n🏋 Bayes-Inferenz ähnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess ähnelt!"
  },
  {
    "objectID": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "5  Globusversuch",
    "section": "5.2 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.2 Ein erster Versuch: Wir werfen den Globus\n\n5.2.1 Welcher Anteil der Erdoberfläche ist mit Wasser bedeckt?\nUnsere Hypothese bzw. unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist?\n\n\n\nDer Erdball\n\n\nQuelle CC 4.0 BY-NC\nSie werden einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie 9 Mal.\nSo sah mein Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\n🏋️️ Besorgen Sie sich einen Globus (zur Not eine Münze) und stellen Sie den Versuch nach!\n\n\n5.2.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten führt, nennt man den den datengenierende Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der Erdoberfläche ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie Würfe des Globusballes sind unabhängig voneinander.\nWir haben kein Vorwissen über \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\n🏋 Welche Annahmen würden Sie ändern? Welche könnte man wegnehmen? Welche hinzufügen? Was wären die Konsequenzen?\n\n\n5.2.3 Ein paar Fachbegriffe\n\nFür jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilität der Hypothese angibt: Priori-Verteilung.\nFür jede Hypothese (d.h. jeden Parameterwert \\(p\\)) möchten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung1 bekommen.\n\n\n\n\nUpdating mit Bayes\n\n\n\n\n5.2.4 Die Binomialverteilung\nWir nehmen an, dass die Daten unabhängig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich ändert2.\nDann kann man die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit für Wasser \\(p\\) beträgt, mit der Binomialverteilung berechnen.\nDie Binomialverteilung zeigt die Verteilung der Häufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten Münzwurf (und allen vergleichbaren Zufallsexperimenten): “Münzwurfverteilung”\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L\\]\n\n\n5.2.5 Binomialverteilung mit R\nWas ist der Anteil der gültigen Pfade (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) Würfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\ndbinom(x = 6, size = 9, prob = 1/2)\n\n[1] 0.1640625\n\n\nWas ist die Wahrscheinlichkeit für \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\ndbinom(x = 9, size = 9, prob = 1/2)\n\n[1] 0.001953125\n\n\n\n\n5.2.6 Beispiele zur Berechnung einer binomial verteilten Wahrscheinlichkeit\nEi Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groß ist die Wahrscheinlichkeit, durch bloßes Münze werfen genau 15 Fragen richtig zu raten?3.\n\ndbinom(x = 15, size = 20, prob = .5)\n\n[1] 0.01478577\n\n\nWas ist die Wahrscheinlichkeit bei 3 Münzwürfen (genau) 3 Treffer (Kopf) zu erzielen?\n\ndbinom(3, 3, 1/2)\n\n[1] 0.125\n\n\n\n\n5.2.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: “W ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)”. \\(N\\) gibt die Anzahl der Globuswürfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (“uniform”):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: “\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1”.\n\n\n5.2.8 So sehen die Verteilungen aus\nAbb. Figure 5.2 zeigt die Binomialverteilung.\n\n\n\n\n\nFigure 5.2: Ein Beispiel für eine Binomialverteilung\n\n\n\n\n\\(N=9, p = 1/2\\)\nAbb. Figure 5.3 zeigt ein Beispiel für eine Gleichverteilung (uniform distribution).\n\n\n\n\n\nFigure 5.3: Gleichverteilung\n\n\n\n\n\\(Min = 0, Max = 1\\)\n🏋️️ Was fällt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Verändert sich die Wahrscheinlichkeit linear? Was fällt Ihnen bei der Gleichverteilung auf?"
  },
  {
    "objectID": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "5  Globusversuch",
    "section": "5.3 Zur Erinnerung: Bayes Theorem",
    "text": "5.3 Zur Erinnerung: Bayes Theorem\n\n5.3.1 Herleitung Bayes’ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit für Regen und kalt ist gleich der Wahrscheinlihckeit von Regen, gegeben kalt mal der Wahrscheinlicht von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wenn’s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n\n5.3.2 Herleitung Bayes’ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lösen auf nach der Posteriori-Wahrscheinlichkeit, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods über alle Werte von \\(p\\). Die Aufgabe dieser Größe ist nur dafür zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n\n5.3.3 Bayes’ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)}\\]\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayes’ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) füttert.\nBayes’ Theorem wird häufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n\n\n5.3.4 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]\n\n\n\nPrior mal Likelihood = Post\n\n\n\n\n5.3.5 Wissen updaten: Wir füttern Daten in das Modell\n\n\n\n\n\n\nUnser Golem lernt\n\n\nUnser Golem (das Modell) lernt. Ob das Modell nützlich ist (präzise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "href": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "title": "5  Globusversuch",
    "section": "5.4 Bayes berechnen mit mit der Gitter-Methode",
    "text": "5.4 Bayes berechnen mit mit der Gitter-Methode\nDie Methode Gitter-Annäherung nennt man auch Grid Approximation*.\n\n5.4.1 Idee\n\nTeile den Wertebereich des Parameter in ein “Gitter” auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (“Gitterwerte”).\nBestimme den Priori-Wert des Parameters für jeden Gitterwert.\nBerechne den Likelihood für Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert für jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\n\n\n5.4.2 Gitterwerte in R berechnen\n\nd <-\n  tibble(\n    # definiere das Gitter: \n    p_Gitter = seq(from = 0, to = 1, length.out = 10),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %>%  \n    mutate(\n      # berechne Likelihood für jeden Gitterwert:\n      Likelihood = dbinom(6, size = 9, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\nSo sehen unsere “Gitterdaten” aus:\n\n# | echo: false\nd %>% \n  knitr::kable(digits = 2)\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n🏋️ Was wohl mit Post passiert, wenn wir Priori ändern?\n\n\n5.4.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: “Post-Verteilung”), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\n\n\n\nJe mehr Gittewerte, desto genauer wird die Verteilung wiedergegeben.\n\n\nMehr Gitterwerte glätten die Annäherung.\nJe größer die Stichprobe (\\(N\\)), desto zuverlässiger wird unsere Berechnung.\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer Träume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung können Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nächsten Kapitels.\n\n\n\n5.4.4 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der großen Welt nützlich ist, steht auf einem anderen Blatt.\n\n🏋️ Wenn Sie auf einen Prozentwert für \\(W\\) tippen müssten, welchen würden Sie nehmen, laut dem Modell (und gegeben der Daten)?"
  },
  {
    "objectID": "Post.html",
    "href": "Post.html",
    "title": "6  Die Post befragen",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6  Die Post befragen",
    "section": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.1.1 Zur Erinnerung: Gitterwerte in R berechnen\n\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nVoilà, die Post-Verteilung als Tabelle:\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n6.1.2 Zur Erinnerung, die Gittermethode\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nützliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) Würfen und \\(k=10\\) Gitterwerten.\nAbb. Figure 6.1 zeigt die resultierende Post-Verteilung.\n\n\n\n\n\nFigure 6.1: Die Postverteilung für W=6, N=9, k=10\n\n\n\n\n\n\n\n\n\n\n  \n    \n      Tabelle d mit Daten zur Posteriori-Verteilung\n    \n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0\n1\n0\n0\n0\n    1 × 10−1\n1\n1 × 10−4\n1 × 10−4\n1 × 10−4\n    2 × 10−1\n1\n5 × 10−3\n5 × 10−3\n5 × 10−3\n    3 × 10−1\n1\n3 × 10−2\n3 × 10−2\n4 × 10−2\n    4 × 10−1\n1\n1 × 10−1\n1 × 10−1\n1 × 10−1\n    6 × 10−1\n1\n2 × 10−1\n2 × 10−1\n2 × 10−1\n  \n  \n  \n\n\n\n\n\n\n6.1.3 Beispiele für Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die höchste Wahrscheinlichkeit?\nWie ungewiss ist das Modell über die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.1.4 Wir arbeiten jetzt mit Häufigkeit, nicht mit Wahrscheinlichkeit\nKomplexere Bayes-Modelle können nicht mehr “einfach mal eben” ausgerechnet werden; die Integrale, auf die man dabei stößt, treiben einem gestandenen Mathematiker die Schweißperlen auf die Stirn.\nGlücklicherweiße gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit Häufigkeiten.\nPraktischerweise werden wir in Kürze einen R-Golem kennenlernen, der uns das meiste an Arbeit abnimmt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurück.\nLernen wir jetz also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handbaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen für Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei größeren Datensätzen (oder größeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Diese Verfahren sind aber nicht mehr Gegenstand dieses Kurses.\n\n\n6.1.5 Häufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (“R-Golems”) liefern uns die Post-Verteilung in Stichprobenform zurück.\nBevor wir uns aber mit diesen R-Werkzeugen beschäftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErsstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d):\n\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\nDie Wahrscheinlichkeit, einen Parameterwert aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit Zurücklegen hält die Wahrscheinlichkeiten während des Ziehens konstant.\n\n\n\n\n\n\n  \n    \n      Stichprobendaten aus der Post-Verteilung\n    \n    \n      Nur die ersten Zeilen abgebildet\n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0.889\n1\n0.057\n6 × 10−2\n0.063\n    0.778\n1\n0.204\n2 × 10−1\n0.227\n    0.778\n1\n0.204\n2 × 10−1\n0.227\n  \n  \n  \n\n\n\n\nWenn Sie jetzt denken: “Warum machen wir das jetzt? Brauchen wir doch gar nicht!” - Dann haben Sie Recht. Künftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten.\nWie sieht diese Tabelle dann als Histogramm1 aus?\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n\n  [1] 0.89 0.78 0.78 0.56 0.56 0.44 0.78 0.56 0.78 0.56 0.78 0.78 0.78 0.78 0.89\n [16] 0.67 0.78 0.56 0.67 0.56 0.44 0.56 0.67 0.56 0.78 0.44 0.44 0.67 0.67 0.67\n [31] 0.78 0.33 0.56 0.78 0.56 0.78 0.78 0.67 0.67 0.78 0.67 0.56 0.44 0.56 0.78\n [46] 0.67 0.22 0.67 0.56 0.67 0.67 0.78 0.67 0.67 0.11 0.56 0.89 0.67 0.67 0.56\n [61] 0.78 0.67 0.78 0.78 0.89 0.44 0.67 0.33 0.67 0.44 0.44 0.67 0.56 0.56 0.78\n [76] 0.78 0.67 0.89 0.56 0.78 0.78 0.56 0.67 0.67 0.56 0.67 0.44 0.33 0.67 0.56\n [91] 0.56 0.78 0.67 0.89 0.56 0.56 0.56 0.67 0.67 0.44\n\n\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. Abb. Figure 6.2.\n\n\n\n\n\nFigure 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n6.1.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die Auflösung auf \\(k=100\\) nach oeben.\nDatensatz samples, \\(n=10^3\\), \\(k=100\\) Gitterwerte, basierend auf dem Modell oben.\n\n\n\n\nsamples_k100 <-\n  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = n,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\n\n\n\n\n\nDie Stichprobendaten nähern sich der “echten” Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt “glattere” Ränder.\n\n\n\n\n\n\nNote\n\n\n\nMehr Stichproben und mehr Gitterwerte glätten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung.\n\nd_k100 %>% \n  slice_sample(n = 1e6, weight_by = post, replace = T) %>% \n  ggplot(aes(x = p_grid)) +\n  geom_density(fill = \"black\") +\n  scale_x_continuous(\"Anteil Wasser (p)\", limits = c(0, 1)) +\n  labs(y = \"\")"
  },
  {
    "objectID": "Post.html#die-post-verteilung-befragen",
    "href": "Post.html#die-post-verteilung-befragen",
    "title": "6  Die Post befragen",
    "section": "6.2 Die Post-Verteilung befragen",
    "text": "6.2 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir können viele nützliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeit (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abb. Figure 6.3 illustriert.\n\n\n\nFigure 6.3: Fragen nach p vs. Fragen nach q\n\n\n\n6.2.1 Fragen zu Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groß ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nWir filtern einfach die passenden Stichproben und und summieren die Wahrscheinlichkeiten dieser Stichproben:\n\n\n\n\n\nWir zählen (count) einfach die Stichproben, die sich für einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %>%\n  count(p_grid < .5) \n\n# A tibble: 2 × 2\n  `p_grid < 0.5`     n\n  <lgl>          <int>\n1 FALSE           8250\n2 TRUE            1750\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, können wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) für einen Wasseranteil kleiner als 50%.\nEinfach wie 🍰 essen.\nNoch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.5 und 0.75?\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75)\n\n# A tibble: 2 × 2\n  `p_grid > 0.5 & p_grid < 0.75`     n\n  <lgl>                          <int>\n1 FALSE                           4610\n2 TRUE                            5390\n\n\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75) %>% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n# A tibble: 2 × 2\n  Anteil Prozent\n   <dbl>   <dbl>\n1  0.461    46.1\n2  0.539    53.9\n\n\nAnteile von count() könnte man, wenn man möchte, auch filter() verwenden:\n\nsamples %>% \n  filter(p_grid > .5 & p_grid < .75) %>% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n# A tibble: 1 × 2\n    sum anteil\n  <dbl>  <dbl>\n1 0.539   53.9\n\n\nNoch ein Beispiel für eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nsamples %>% \n  count(p_grid >= .9 & p_grid <= 1) %>% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n# A tibble: 1 × 1\n   prop\n  <dbl>\n1  0.01\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% beträgt.\n\n\n6.2.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nImportant\n\n\n\nSchätzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall (synonym: Kompatibilitätsintervall oder Passungsbereich).\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht überschritten, laut unserem Modell? (Gesucht sind also die unteren 90% Posteriori-Wahrscheinlichkeit)\n\nsamples %>% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n# A tibble: 1 × 1\n  quantil90\n      <dbl>\n1     0.778\n\n\nLaut unserem Modell können wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu führen:\n\nsamples %>% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthält, laut dem Modell?\nDafür “schneiden” wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchem Parameterwert wir landen:\n\nsamples %>% \n  summarise(\n    quant_10 = quantile(p_grid, 0.05),\n    quant_90 = quantile(p_grid, 0.95))\n\n# A tibble: 1 × 2\n  quant_10 quant_90\n     <dbl>    <dbl>\n1    0.444    0.889\n\n\nSolche Fragen lassen sich mit Hilfe von Quantilen beantworten.\n\n\n6.2.3 Zur Erinnerung: Quantile\nBeispiel: Wie groß sind die Studentis (Quelle des Datensatzes)? Das Quantil von z.B. 25% zeigt die Körpergröße der 25% kleinsten Studentis an, analog für 50%, 75%:\n\nspeed_gender_height <- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary <- \n  speed_gender_height %>% \n  drop_na(height) %>% \n  summarise(q25 = quantile(height, prob = .25),\n            q50 = quantile(height, prob = .5),\n            q75 = quantile(height, prob = .75))\n\nheight_summary\n\n# A tibble: 1 × 3\n    q25   q50   q75\n  <dbl> <dbl> <dbl>\n1    63    66    69\n\n\nVisualisierung der Quantile:\n\n\n\n\n\n\n\n6.2.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht überschritten wird:\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% ab.\nSchaue, was der größte verbleibende Wert ist.\n\n\nsamples %>% \n  arrange(p_grid) %>%   # sortiere\n  slice_head(n = 9000) %>%  # nur die ersten 90000, also die obersten 1000 abschneiden\n  summarise(p90 = max(p_grid))\n\n# A tibble: 1 × 1\n    p90\n  <dbl>\n1 0.778\n\n\nDas (annähernd) gleiche Ergebnis liefert quantile():\n\nsamples %>% \n  summarise(q90 = quantile(p_grid, .9))\n\n# A tibble: 1 × 1\n    q90\n  <dbl>\n1 0.778\n\n\n\n\n6.2.5 Visualisierung der Intervalle\nIntervalle (Bereiche), die die Wahrscheinlichkeitsmasse hälftig auf die beiden Ränder aufteilen, nennen wir Perzentilintervalle oder Equal-Tails-Intervalle (ETI):"
  },
  {
    "objectID": "Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "href": "Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "title": "6  Die Post befragen",
    "section": "6.3 Schiefe Posteriori-Verteilungen sind möglich",
    "text": "6.3 Schiefe Posteriori-Verteilungen sind möglich\nGehen wir von 3 Würfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schließen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 Würfe):\n\nd_33 <- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %>% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% \n  mutate(unstand_post = likelihood * prior) %>% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 <- \n  d_33 %>% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n    \n  \n  \n    0.99\n1\n0.97\n0.97\n    0.77\n1\n0.46\n0.46\n    0.95\n1\n0.86\n0.86\n    0.59\n1\n0.21\n0.21\n    0.81\n1\n0.53\n0.53\n    0.99\n1\n0.97\n0.97\n  \n  \n  \n\n\n\n\nMit dieser “schiefen” Post-Verteilung können wir gut die Auswirkungen auf das Perzentil- und das Höchste-Dichte-Intervall anschauen.\n\n6.3.1 50%-Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall (PI, auch Equal-Tails-Intervall, ETI, genannt):\n\nqi_50_low <- eti(samples_33$p_grid, ci = .5)$CI_low\nqi_50_up <- eti(samples_33$p_grid, ci = .5)$CI_high\np1 <-\n  d_33 %>% \n  ggplot(aes(x = p_grid, y = post_33)) +\n  # check out our sweet `qi()` indexing\n  geom_area(data = . %>% \n              filter(p_grid > qi_50_low &  \n                    p_grid < qi_50_up),\n            fill = \"grey75\") +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 0, to = 1, by = .1))\n\np1\n\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\nlibrary(easystats)\n\nsamples_33 %>% \n  select(p_grid) %>% \n  eti(ci = .5)\n\nEqual-Tailed Interval\n\nParameter |      50% ETI\n------------------------\np_grid    | [0.71, 0.94]\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.3.2 50%-Intervall höchster Dichte\nIntervalle höchster Dichte (Highest density Intervals) sind definiert als die schmälsten Intervalle, die den gesuchten Parameter enthalten.\n\n\n\n\n\nDer wahrscheinlichste Paramterwert (1) ist im Intervall enthalten, was Sinn macht.\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen:\n\nsamples %>% \n  select(p_grid) %>% \n  bayestestR::hdi(ci = .5)  # aus dem Paket `bayestestR`\n\nWarning: Identical densities found along different segments of the distribution,\nchoosing rightmost.\n\n\nHighest Density Interval\n\nParameter |      50% HDI\n------------------------\np_grid    | [0.67, 0.78]\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfläche) sich in diesem Bereich befindet (auf Basis eines HDI).\n\n\n\n\n\n\nNote\n\n\n\nDas R-Paket {bayestestR} ist Teil des Meta-Pakets {easystats}. Es reicht, wenn Sie easystats laden, damit wird bayestestR automatisch geladen."
  },
  {
    "objectID": "Post.html#intervalle-höchster-dichte-vs.-perzentilintervalle",
    "href": "Post.html#intervalle-höchster-dichte-vs.-perzentilintervalle",
    "title": "6  Die Post befragen",
    "section": "6.4 Intervalle höchster Dichte vs. Perzentilintervalle",
    "text": "6.4 Intervalle höchster Dichte vs. Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle ähnlich\nPerzentilintervalle sind verbreiteter\nIntervalle höchster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle höchster Dichte sind die schmalsten Intervalle für eine gegebene Wahrscheinlichkeitsmasse"
  },
  {
    "objectID": "Post.html#punktschätzungen",
    "href": "Post.html#punktschätzungen",
    "title": "6  Die Post befragen",
    "section": "6.5 Punktschätzungen",
    "text": "6.5 Punktschätzungen\nDatendatz samples, 6 Treffer bei 9 Würfen.\n\n6.5.1 Lageparameter\nZ.B. Welchen mittleren Wasseranteil muss man annehmen?\n\nsamples %>% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n# A tibble: 1 × 2\n   mean median\n  <dbl>  <dbl>\n1 0.634  0.667\n\n\n\n\n6.5.2 Streuungsparameter\nZ.B. “Wie unsicher sind wir in der Schätzung des Wasseranteils?”\n\nsamples %>% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n# A tibble: 1 × 3\n   p_sd p_iqr p_mad\n  <dbl> <dbl> <dbl>\n1 0.140 0.222 0.165\n\n\nAnstelle der Streuungsparameter ist es aber üblicher, ein HDI oder PI anzugeben."
  },
  {
    "objectID": "Post.html#visualisierungen-der-punktschätzer",
    "href": "Post.html#visualisierungen-der-punktschätzer",
    "title": "6  Die Post befragen",
    "section": "6.6 Visualisierungen der Punktschätzer",
    "text": "6.6 Visualisierungen der Punktschätzer\n\n\n\n\n\nJe symmetrischer die Verteilung, desto näher liegen die Punktschätzer aneinander (und umgekehrt)."
  },
  {
    "objectID": "Post.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "Post.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "6  Die Post befragen",
    "section": "6.7 Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.",
    "text": "6.7 Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.\nDaten: 9 von 10 Treffern beim Münzwurf. Ist die Münze fair?\n\ntibble(\n  Trefferzahl = rbinom(n = 1e4, size = 10, prob = 1/2)\n) %>% \n  mutate(signifikant = ifelse(Trefferzahl %in% c(9,10), TRUE, FALSE)) %>% \n  ggplot() +\n  aes(x = Trefferzahl, fill = signifikant) +\n  geom_bar() +\n  scale_x_continuous(breaks = 0:10) +\n  theme(legend.position = c(0.1, 0.8)) +\n  geom_vline(xintercept = 9) +\n  labs(title = \"Stichprobenverteilung für p=0.5\")\n\n\n\n\nDie Stichprobenverteilung zeigt, wie Wahrscheinlich der empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) ist gegeben eines Parameterwerts \\(p\\) (z.B. \\(p=0.5\\)): \\(Pr(D|p)\\).\n\n\n\n\n\n\n\n\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung."
  },
  {
    "objectID": "Post.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "Post.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "6  Die Post befragen",
    "section": "6.8 Mit Stichproben neue Beobachtungen simulieren",
    "text": "6.8 Mit Stichproben neue Beobachtungen simulieren\n\n6.8.1 Wir simulieren die Wasserzahl bei Globuswürfen\nLikelihood (L): Wahrscheinlichkeit für \\(w=0,1,2\\) bei \\(N=2\\) und \\(p = 0.7\\):\n\nL <- dbinom(0:2, size = 2, prob = 0.7)\nL\n\n[1] 0.09 0.42 0.49\n\n\nWir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zählen die (Wasser-)Treffer:\n\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n\n[1] 0\n\n\nWarum nicht \\(n=10\\) neue Globusversuche simulieren:\n\nrbinom(n = 10, size = 2, prob = 0.7)\n\n [1] 0 2 1 1 1 1 2 1 1 2\n\n\nDiese Versuche geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann.\n\n\n6.8.2 Never trust a Golem\n\n\nfrom Imgflip Meme Generator\n\nQuelle: https://imgflip.com/i/5qmhmo\n\n\n6.8.3 Traue niemals einem Golem (einem Modell)\nImmer prüfen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsächlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prüfen?"
  },
  {
    "objectID": "Post.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "Post.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "6  Die Post befragen",
    "section": "6.9 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "6.9 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren:\n\ndraws <- \n  tibble(\n    draws = \n      rbinom(1e6, \n             size = 2, \n             prob = .7))\ndraws %>% \n  count(draws) %>% \n  mutate(proportion = \n           n / nrow(d))\n\n# A tibble: 3 × 3\n  draws      n proportion\n  <int>  <int>      <dbl>\n1     0  89770      8977 \n2     1 420629     42063.\n3     2 489601     48960.\n\n\nDiese simulierten Häufigkeiten sind sehr ähnlich zu den theoretisch bestimmten Häufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen.\n\ndbinom(0:2, size = 2, prob = .7)\n\n[1] 0.09 0.42 0.49"
  },
  {
    "objectID": "Post.html#stichprobenverteilung",
    "href": "Post.html#stichprobenverteilung",
    "title": "6  Die Post befragen",
    "section": "6.10 Stichprobenverteilung",
    "text": "6.10 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben für den Versuch \\(N=9\\) Globuswürfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise?\n\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = \n           rbinom(\n             n_draws, \n             size = 9, \n             prob = .7\n           ))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n\n\nn_draws <- 1e6\ndraws <- tibble(draws = rbinom(n_draws, \n                               size = 9, \n                               prob = .7))\n\n# the histogram\ndraws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", size = 1/10) +\n  scale_x_continuous(\"Anzahl Wasser (W) pro Versuch\",\n                     breaks = seq(from = 0, to = 9, by = 2)) +\n  scale_y_continuous(\"Häufigkeit\",\n                     labels = scales::scientific) +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir können jetzt prüfen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n6.10.1 Visualisierung der PPV\n\nknitr::include_graphics(\"https://github.com/sebastiansauer/QM2-Folien/raw/main/img/ppv.png\")\n\n\n\n\nQuelle: McElreath (2020)"
  },
  {
    "objectID": "Post.html#so-viele-verteilungen",
    "href": "Post.html#so-viele-verteilungen",
    "title": "6  Die Post befragen",
    "section": "6.11 So viele Verteilungen…",
    "text": "6.11 So viele Verteilungen…\n\nDie Posteriori-Verteilung gibt Aufschluss zur Häufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass “in Wirklichkeit” der Wasseranteil 70% beträgt, also \\(\\pi=.7\\)\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\nDie PPV gibt Aufschluss zur Häufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter Durchführung, zu erwarten.\nFür die Praxis kann das eine interessante Frage sein.\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklärt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden.\n\n\n\n\n\n\nppv2_plot <- \nd_small %>%\n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", linewidth = 1/10) +\n  scale_x_continuous(\"Wasser\", breaks = seq(from = 0, to = 9, by = 3)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(subtitle = \"Stichprobenverteilungen\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ label, ncol = 9)"
  },
  {
    "objectID": "Post.html#ppv-berechnen",
    "href": "Post.html#ppv-berechnen",
    "title": "6  Die Post befragen",
    "section": "6.12 PPV berechnen",
    "text": "6.12 PPV berechnen\n\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nppv_plot2 <-\n  ppv %>% \n  ggplot() +\n  aes(x = value) +\n  geom_bar() +\n  scale_x_continuous(\n    breaks = 0:9)\n\n\nppv_plot2\n\n\n\n\n\nDie PPV unseres Modells zeigt uns, dass wir in künftigen Versuchen zumeist 6 Treffer zu erwarten haben.\nAber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar."
  },
  {
    "objectID": "Post.html#vorhersagen-sind-schwierig",
    "href": "Post.html#vorhersagen-sind-schwierig",
    "title": "6  Die Post befragen",
    "section": "6.13 Vorhersagen sind schwierig",
    "text": "6.13 Vorhersagen sind schwierig\n… gerade wenn sie die Zukunft betreffen, so ein Sprichtwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der häufigste in unseren Stichproben, aber die Vorhersagen haben eine große Streuung, birgt also hohe Ungewissheit.\nDie PPV zeigt also, welche Beobachtungen laut unserem Modell künftig zu erwarten sind.\n\n\n\n\n\nWürde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hätten die Vorhersagen zu wenig Streuung, würden also die Ungewissheit nicht ausreichend abbilden (Übergewissheit, Overconfidence)."
  },
  {
    "objectID": "Post.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "href": "Post.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "title": "6  Die Post befragen",
    "section": "6.14 Zwei Arten von Ungewissheit in Vorhersagen von Modellen",
    "text": "6.14 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells: Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiß, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nächste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, möchte man beide Arten von Ungewissheit berücksichtigen: Das macht die Posteriori-Prädiktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prädiktiv) und mit welcher Häufigkeit, basierend auf der Post-Verteilung."
  },
  {
    "objectID": "Post.html#vergleich-der-verteilungen",
    "href": "Post.html#vergleich-der-verteilungen",
    "title": "6  Die Post befragen",
    "section": "6.15 Vergleich der Verteilungen",
    "text": "6.15 Vergleich der Verteilungen\n\n\n\n\n\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-Prädiktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter Berücksichtigung der Unsicherheit der Posteriori-Verteilung\n\nBild\nQuelle: R. McElreath\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bourier, Günther. 2013. Wahrscheinlichkeitsrechnung Und Schließende\nStatistik: Praxisorientierte Einführung ; Mit Aufgaben Und\nLösungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer\nGabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik –\nWahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. 2nd ed. CRC Texts in\nStatistical Science. Boca Raton: Taylor; Francis, CRC\nPress.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  }
]