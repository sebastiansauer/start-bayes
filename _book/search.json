[
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\nden Unterschied zwischen dem SchÃ¤tzen von Modellparametern und dem Testen von Hypothesen erlÃ¤utern\nVor- und Nachteile des SchÃ¤tzens und Testens diskutieren\nDas ROPE-Konzept erlÃ¤utern und anwenden\nDie GÃ¼te von Regressionsmodellen einschÃ¤tzen und berechnen\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an (Kruschke 2018).\n\n9.1.4 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.5 BenÃ¶tigte Daten\nWir benÃ¶tigen in diesem Kapitel folgenden Datensatz: penguins.\nSie kÃ¶nnen den Datensatz penguins entweder via dem Pfad importieren:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n Download \nOder via dem zugehÃ¶rigen R-Paket:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nBeide MÃ¶glichkeit sind okay.\n\n9.1.6 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\nâ€œLernen fÃ¼r die Klausur bringt etwas!â€\nâ€œWie viel bringt Lernen fÃ¼r die Klausur?â€\n\n\nBeispiel 9.1 Diskutieren Sie die epistemologische Ausrichtung sowie mÃ¶gliches FÃ¼r und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#schÃ¤tzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#schÃ¤tzen-oder-testen",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.2 SchÃ¤tzen oder Testen?",
    "text": "9.2 SchÃ¤tzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen prÃ¼fend: â€œDie Daten widerlegen die Hypothese (nicht)â€\n\nParameter schÃ¤tzend: â€œDer Effekt von X auf Y liegt zwischen A und Bâ€.\n\n\n9.2.1 Hypothesen prÃ¼fen\nHypothesen prÃ¼fende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann natÃ¼rlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 9.2 (â€œLernen erhÃ¶ht den PrÃ¼fungserfolgâ€) Die Hypothese Lernen erhÃ¶ht den PrÃ¼fungserfolg kann durch eine Studie und eine entsprechende Analyse grundsÃ¤tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts fÃ¼r den Klausurerfolg. 2) Die Daten unterstÃ¼tzen die Hypothese: Lernen erhÃ¶ht den PrÃ¼fungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den PrÃ¼fungserfolg mÃ¶glich. \\(\\square\\)\n\nDas PrÃ¼fen einer Hypothese kann zu drei Arten von Ergebnissen fÃ¼hren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\nğŸŸ¢ Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die GlaubwÃ¼rdigkeit der Hypothese gelitten.\nğŸŸ¥ Die Daten unterstÃ¼tzen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an GlaubwÃ¼rdigkeit gewonnen.\nâ“ Die Datenlage ist unklar; zum Teil unterstÃ¼tzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum SchlÃ¼sse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen prÃ¼fen ist binÃ¤r in dem Sinne, dass sie zu â€œSchwarz-WeiÃŸ-Ergebnissenâ€ fÃ¼hren (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine gÃ¤ngige Variante des Hypothesen testen1 ist das Testen der Hypothese â€œkein Effektâ€ (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n9.2.2 Beispiele fÃ¼r Nullhypothesen\n\nâ€œLernen bringt nichtsâ€\nâ€œFrauen und MÃ¤nner parken gleich schnell einâ€\nâ€œEs gibt keinen Zusammenhang von Babies und StÃ¶rchenâ€\nâ€œFrÃ¼her war es auch nicht besser (sondern gleich gut)â€\nâ€œBei Frauen ist der Anteil, derer, die Statistik mÃ¶gen gleich hoch wie bei MÃ¤nnernâ€ (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterstÃ¼tzen kann, da es die KomplexitÃ¤t reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht bestÃ¤tigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht bestÃ¤tigen (verifizieren) kann, hat groÃŸen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausgeÃ¼bt (Popper 2013). Schlagend ist das Beispiel zur Hypothese â€œAlle SchwÃ¤ne sind weiÃŸâ€. Auch eine groÃŸe Stichprobe an weiÃŸen SchwÃ¤nen kann die Wahrheit der Hypothese nicht beweisen. SchlieÃŸlich ist es mÃ¶glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben.2 Umgekehrt reicht die (zuverlÃ¤ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im bestÃ¤tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverlÃ¤ssiger, reprÃ¤sentativer Daten erscheint plausibel, dass Hypothesen sowohl bestÃ¤tigt als auch widerlegt werden kÃ¶nnen (Kruschke 2018; Morey und Rouder 2011). \\(\\square\\)\n\n\n\n9.2.3 Parameter schÃ¤tzen\nBeim Parameter schÃ¤tzen untersucht man, wie groÃŸ ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein â€œja/neinâ€, was beim Hypothesen testen der Fall ist.\nBeim Parameter schÃ¤tzen gibt es zwei Varianten:\n\nâš«ï¸ PunktschÃ¤tzung: Das SchÃ¤tzen eines einzelnen Parameterwerts, sozusagen ein â€œBest Guessâ€\nğŸ“ BereichsschÃ¤tzung: Das SchÃ¤tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Parameter schÃ¤tzen auch wie einen Hypothesentest nutzen: Ist ein bestimmter Wert, etwa die Null, nicht im SchÃ¤tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 9.3 (ParameterschÃ¤tzen als Nullhypothesentest) Â \n\nForschungsfrage: Sind mÃ¤nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nGleichungÂ 9.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0 \\tag{9.1}\\]\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nm1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\nDann zÃ¤hlen wir einfach den Anteil der Stichproben in der Post-Verteilung fÃ¼r die UV sexmale, die einen Wert grÃ¶ÃŸer Null aufweisen:\n\nm1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert grÃ¶ÃŸer Null fÃ¼r sexmale, dass also weibliche Tiere leichter bzw. mÃ¤nnliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der fÃ¼r das Gegenteil spricht (das weibliche Tiere schwerer wÃ¤ren). Damit resÃ¼mieren wir, dass unser Modell 100% Wahrscheinlichkeit fÃ¼r die Hypothese einrÃ¤umt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der ParameterschÃ¤tzung ist die Nuanciertheit des Ergebnisses, die der KomplexitÃ¤t echter Systeme besser Rechnung trÃ¤gt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.3 ROPE: Bereich von â€œpraktisch Nullâ€",
    "text": "9.3 ROPE: Bereich von â€œpraktisch Nullâ€\nğŸ“º Teil 2\nNullhypothesen sind fast immer falsch, s. AbbildungÂ 9.1.\n\n\n\n\n\n\n\nAbbildungÂ 9.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman, Hill, und Vehtari 2021)\n\n\n9.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.â€‰B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist.3\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht. ğŸ¤·â€â™€ï¸\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n9.3.2 â€œPraktischâ€ kein Unterschied: Das Rope-Konzept\nğŸ“º ROPE-Video\n\nBeispiel 9.4 (Beispiele fÃ¼r ROPE) Sagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g â€œvernachlÃ¤ssigbar wenigâ€ ist.\nEine findige GeschÃ¤ftsfrau entscheidet fÃ¼r ihre Firma, dass ein Umssatzunterschied von 100k Euro â€œpraktisch irrelevantâ€ sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt. Unter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroÃŸteil liegt innerhalb von Rope â¡ï¸ Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nGroÃŸteil liegt auÃŸerhalb von Rope â¡ï¸ Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nAnsonsten â¡ï¸ keine Entscheidung\n\nMit â€œGroÃŸteilâ€ meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n9.3.3 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat. Ein vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die GrÃ¶ÃŸe des ROPE Â±5% der SD der AV. \\(\\square\\)\n\n\n\n9.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildungÂ 9.2: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\n\nAbbildungÂ 9.2 illustriert die Entscheidungsregel zum ROPE fÃ¼r mehrere Situatioenen (Kruschke 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett auÃŸerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung mÃ¶glich; die Datenlage ist unklar.\n\n9.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erklÃ¤rt (m10.6).\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nDen Rope berechnet man mit rope(model).\n\nrope(m10.6)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir kÃ¶nnen d.â€‰h.r fÃ¼r diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschlieÃŸende Entscheidung Ã¼ber die Hypothese mÃ¶glich.\nAber: Gentoo liegt zu 0% im Rope. FÃ¼r Gentoo kÃ¶nnen wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. ğŸ¨\n\n9.3.6 Visualisierung unserer Rope-Werte, m10.6\nEin GroÃŸteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope. Aber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut, s. AbbildungÂ 9.3.\n\nrope(m10.6) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.6) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.6) %&gt;% plot()\n\n\n\n\n\n\nAbbildungÂ 9.3: Rope und HDI Ã¼berlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung fÃ¼r Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir kÃ¶nnen das Nullhypothese fÃ¼r Chinstrap nicht verwerfen, aber auch nicht bestÃ¤tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom â€œblauen Flussâ€ des Rope: Gentoo liegt auÃŸerhalb des Rope. Es gibt einen â€œsubstanziellenâ€ Unterschied, grÃ¶ÃŸer als das ROPE. Wir verwerfen die â€œPraktisch-Null-Hypotheseâ€ in diesem Fall.\n\n9.3.7 Finetuning des Rope\nWir kÃ¶nnen festlegen, was wir unter â€œpraktischer Ã„quivalenzâ€ verstehen, also die Grenzen des Ropes verÃ¤ndern. Sagen wir, 100 Gramm sind unsere Grenze fÃ¼r einen vernachlÃ¤ssigbaren Effekt, s. AbbildungÂ 9.4.\n\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 9.4: ROPE mit selber eingestellter Grenze von Â±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht fÃ¼r ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n9.3.8 Beantwortung der Forschungsfrage\nFÃ¼r die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. FÃ¼r Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellgÃ¼te",
    "href": "1050-Schaetzen-Testen.html#modellgÃ¼te",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.4 ModellgÃ¼te",
    "text": "9.4 ModellgÃ¼te\n\n\n\n\n\n\n\n\n\n\n\n9.4.1 Wozu ModellgÃ¼te?\nHat man ein Modell aufgestellt und geprÃ¼ft und Ergebnisse erhalten, mÃ¶chte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der ModellgÃ¼te. Diese Kennwerte zielen z.â€‰B. darauf ab, wie prÃ¤zise die Aussagen des Modells sind. Je prÃ¤ziser die Aussagen eines Modells, desto nÃ¼tzlicher ist es natÃ¼rlich. Bei einer ParameterschÃ¤tzung erhÃ¤lt man auch Informationen zur PrÃ¤zision der SchÃ¤tzung: Ist der SchÃ¤tzbereich schmal, so ist die SchÃ¤tzung prÃ¤zise (und vice versa). Allerdings kÃ¶nnte ein Modell aus mehreren ParameterschÃ¤tzungen bestehen, die unterschiedlich prÃ¤zise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur PrÃ¤zision, oder allgemeiner zur GÃ¼te des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebrÃ¤uchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n9.4.2 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt. - HÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt. \\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert. Solch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor. Daher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\n\n\n\n\n\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. AbbildungÂ 9.5.\n\nm10.6_r2 &lt;-\n  m10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 9.5: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n9.4.3 Definition vom â€œklassischenâ€ \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die â€œtypischeâ€ Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nÃ¼tzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklÃ¤rten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck Ã¤quivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen AusdrÃ¼cke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlÃ¤ssigen Ungewissheit; sie sind Ã¼bergewiss aus Bayes-Sicht.\n\n9.4.4 Bayesâ€™ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der ModellgÃ¼te miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkÃ¤rte Varianz}}{\\text{ErklÃ¤rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. FÃ¼r jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklÃ¤rten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u.Â a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.5 Fazit",
    "text": "9.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der VorzÃ¼ge der ParameterschÃ¤tzung. MÃ¶chte man aber, um sich bestimmter bestehender Forschung anzunÃ¤hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.6 Aufgaben",
    "text": "9.6 Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope-regr\nrope1\nrope2\nrope3\n\n\n\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. â€R-Squared for Bayesian Regression Modelsâ€œ. The American Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKruschke, John K. 2018. â€Rejecting or Accepting Parameter Values in Bayesian Estimationâ€œ. Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nMorey, Richard D., und Jeffrey N. Rouder. 2011. â€Bayes Factor Approaches for Testing Interval Null Hypothesesâ€œ. Psychological Methods 16 (4): 406â€“19. https://doi.org/10.1037/a0024377.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Herausgegeben von Herbert Keuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "6Â  Die Post befragen",
    "section": "6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n6.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n6.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 3.1 und 3.2.\n\n\n6.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œDaten umformenâ€\nStatistik1, Kap. â€œDaten zusammenfassenâ€\n\n\n\n6.1.5 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # optional\n\n\n\n6.1.6 Begleitvideos\n\nPlaylist QM2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6Â  Die Post befragen",
    "section": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.2.1 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (â€œBayes-Boxâ€) die Postverteilung fÃ¼r den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen, bei Apriori-Indifferenz gegenÃ¼ber den Parameterwerten. Und sagen wir \\(k=11\\) Gitterwerten1, also mit 10 Wasseranteilswerten zwischen 0 und 1.\n\nÃœbungsaufgabe 6.1 (Welcher Paramterwert hat die hÃ¶chste Posteriori-Wahrscheinlichkeit?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\nAufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die hÃ¶chste Wahrscheinlichkeit (d.â€‰h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. ListingÂ 6.1. \\(\\square\\)\n\n\n\n\n\n\n\n\nListingÂ 6.1: Bayes-Box mit 6 Wasser bei 9 Versuchen\n\n\nn &lt;- 11\nn_success &lt;- 6          \nn_trials  &lt;- 9\np_grid &lt;- seq(from = 0, to = 1, length.out = n)\nL &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\n\nd &lt;-\n  tibble(p_grid = p_grid,prior  = 1) %&gt;% \n  mutate(likelihood = L) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n\n\nSequenz von 0 bis 1 mit der LÃ¤nge n=11 Schritte, das gibt uns die Parameterwerte\nLikelihood mit 6 Treffern bei 9 WÃ¼rfen und das Ganze jeweils fÃ¼r alle 11 Parameterwerte\nDann packen wir alles in eine Tabelle.\n\n\n\nAbb. AbbildungÂ 6.1 zeigt die resultierende Bayes-Box; vor allem ist die Post-Verteilung wichtig.\n\nlibrary(ggpubr)\nggline(d, x = \"p_grid\", y = \"post\") \n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.1: Die Postverteilung fÃ¼r W=6, N=9, k=10\n\n\n\n\n\nVoilÃ , die Post-Verteilung als Tabelle, auch â€œBayes-Boxâ€ (oder Bayes-Gitter) genannt: s. TabelleÂ 6.1.\n\n\n\n\nTabelleÂ 6.1: Postverteilung mit der Gittermethode berechnet\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.02\n0.02\n0.02\n\n\n0.4\n1\n0.07\n0.07\n0.07\n\n\n0.5\n1\n0.16\n0.16\n0.16\n\n\n0.6\n1\n0.25\n0.25\n0.25\n\n\n0.7\n1\n0.27\n0.27\n0.27\n\n\n0.8\n1\n0.18\n0.18\n0.18\n\n\n0.9\n1\n0.04\n0.04\n0.04\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.2 Bayes-Box automatisiert\nÃœbrigens kann man die Berechnung der Bayes-Box auch automatisieren, s. TabelleÂ 6.2 und ListingÂ 6.2, z.â€‰B. so:2\nEntweder so:\n\nsource(\"https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R\") \nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\nMit source importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code fÃ¼r die Funktion bayesbox.\nOder Sie starten das R-Paket, wo die Funktion wohnt:\n\n\n\n\nListingÂ 6.2: Funktion bayesbox, auch im Paket prada erhÃ¤ltlich\n\n\nlibrary(prada)\nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\n\n\n\n\nTabelleÂ 6.2: Eine Bayes-Box â€˜automatisiertâ€™ erstellt, mit Hilfe der Funktion bayesbox\n\n\n\n\n  \n\n\n\n\n\n\n\nDas Paket prada steht nicht im Standard-R-App-Store (â€œCRANâ€), sondern auf Github. Sie kÃ¶nnnen es so installieren: devtools::install_github(\"sebastiansauer/prada\").\nDie Funktion verhÃ¤lt sich wie eine gewÃ¶hnliche Bayes-Box: Bei hyps schreibt man die Hypothesen (bzw. Parameterwerte) auf. Bei priors die Priori-Werte und bei liks die Likelihoods der jeweiligen Hypothesn.\n\n\n\n\n\n\n\n\n\n\n\n\nViele nÃ¼tzliche Fragen (und Antworten) leiten sich ab aus Abb. AbbildungÂ 6.1.\n\nBeispiel 6.1 (Beispiele fÃ¼r Fragen an die Post-Verteilung) Â \n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\netc. \\(\\square\\)\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.2.3 Bayes-Box fÃ¼r komplexe Modelle\nBisher, fÃ¼r einfache Fragestellungen hat unsere Bayes-Box, das heiÃŸt die Gittermethode bestens funktioniert: einfach, robust, formschÃ¶n3. Allerdings: Funktioniert sie auch bei komplexeren Modellen? SchlieÃŸlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 PrÃ¤diktor, dann haben wir folgende drei GrÃ¶ÃŸen4 zu schÃ¤tzen: \\(\\beta_0, \\beta_1, \\sigma\\). HÃ¶rt sich gar nicht so viel an. Aber Moment, wir mÃ¼ssten dann z.â€‰B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.â€‰B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach mÃ¼ssen wir alle AusprÃ¤gungen (â€œGitterwerteâ€) der Variablen multiplizieren. Puh, das wird eine groÃŸe Zahl. Wenn wir fÃ¼r die drei GrÃ¶ÃŸen jeweils 10 AusprÃ¤gungen annehmen, was wenig ist, kÃ¤men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 AusprÃ¤gungen wÃ¤ren es schon \\(100^3=10^6\\) Kombinationen. Das wÃ¤re doch eine recht lange Tabelle.5\nBei einer multiplen Regression mit sagen wir 10 PrÃ¤diktoren mit jeweils 100 AusprÃ¤gungen rechnet das arme R bis zum jÃ¼ngsten Tag: \\(10^{100}\\).\n\nğŸ¤– Bitte tue mir das nicht an!\n\n\nğŸ‘¨â€ğŸ« Schon gut, das kÃ¶nnen wir R nicht zumuten. Wir brauchen eine andere LÃ¶sung!\n\n\n\n6.2.4 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Mathematik wird zu umfangreich bzw. zu komplex. GlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht. Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten. Praktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der das fÃ¼r uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck. Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung mit HÃ¤ufigkeiten (d.â€‰h. in Stichprobenform) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Bayes-Box-Methode6 ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu unpraktisch. In der Praxis werden d.â€‰h.r andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein7\n\n\n6.2.5 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck. Bevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform. Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. ListingÂ 6.3.\n\n\n\nListingÂ 6.3: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\n\n\nsamples &lt;-\n  d %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit ZurÃ¼cklegen\n  select(p_grid)\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.â€‰h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird. Wir begnÃ¼gen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht. Das Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 6.3 dargestellt.\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\n\n\nTabelleÂ 6.3 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.\n\n\n\n\nTabelleÂ 6.3: Stichproben-Post-Verteilung\n\n\n\n\n\n\n\n\n\np_grid\n\n\n\n\n0.500\n\n\n0.700\n\n\n0.800\n\n\n0.800\n\n\n0.800\n\n\n\n\n\n\n\n\n\n\n\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.5 0.7 0.8 0.8 0.8 0.5 0.4 0.6 0.3 0.6 0.6 0.7 0.7 0.8 0.7 0.6 0.8 0.6\n##  [19] 0.6 0.8 0.6 0.5 0.6 0.8 0.9 0.5 0.7 0.8 0.8 0.5 0.6 0.7 0.7 0.6 0.8 0.5\n##  [37] 0.7 0.8 0.5 0.8 0.7 0.6 0.8 0.5 0.3 0.4 0.7 0.4 0.4 0.6 0.8 0.4 0.3 0.6\n##  [55] 0.4 0.5 0.8 0.7 0.5 0.6 0.5 0.6 0.8 0.6 0.7 0.8 0.7 0.6 0.7 0.6 0.2 0.8\n##  [73] 0.6 0.7 0.7 0.6 0.4 0.4 0.6 0.4 0.7 0.6 0.8 0.6 0.6 0.6 0.6 0.7 0.7 0.6\n##  [91] 0.5 0.6 0.9 0.7 0.8 0.7 0.7 0.9 0.6 0.6\n\n\n\nSo sieht unsere â€œStichproben-Bayesboxâ€ als Balkendiagramm aus, s. AbbildungÂ 6.2.\n\nSyntaxOutput\n\n\n\nsamples |&gt; \n  count(p_grid) |&gt; \n  ggbarplot(x = \"p_grid\", y = \"n\") \n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n\n\nAus AbbildungÂ 6.2 kÃ¶nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% fÃ¼r am wahrscheinlichsten hÃ¤lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlieÃŸen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie AbbildungÂ 6.2 mit AbbildungÂ 5.10: beide sind sehr Ã¤hnlich! Das Stichprobenziehen (AbbildungÂ 6.2) nÃ¤hert sich recht gut an die exakte Berechnung an (AbbildungÂ 5.10).\n\n\n6.2.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) Gitterwerte (AusprÃ¤gungen) nach oben.\n\n1k &lt;- 100\n2n_success &lt;- 6\n3n_trials  &lt;- 9\n\nd_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n4                      length.out = k),\n5         prior  = 1) %&gt;%\n6  mutate(likelihood = dbinom(n_success,\n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n7  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n1\n\n\\(k=100\\) Gitterwerte\n\n2\n\n6 Treffer (Wasser)\n\n3\n\n9 Versuche\n\n4\n\nBayes-Box anlegen mit 100 Zeilen, d.â€‰h. 100 Parameterwerten\n\n5\n\nApriori indifferent: Alle Hypothesen haben die gleiche Apriori-PlausibilitÃ¤t\n\n6\n\nDie Likelihood ist binomialverteilt.\n\n7\n\nPost-Verteilung berechnen wie gewohnt.\n\n\n\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\nsamples_k100 &lt;-\n  d_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\nAbbildungÂ 6.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen FÃ¤llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der â€œtypischeâ€ Wert des Modells zu sein. AuÃŸerdem erkennt man, dass das Modell durchaus einige Streuung in der SchÃ¤tzung des Wasseranteils bereithÃ¤lt. Das Modell ist sich nicht sehr sicher, kÃ¶nnte man sagen.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.3: Post-Verteilung mit 100 Gitterwerten, exakt vs.Â auf Basis von Stichproben\n\n\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt die Post-Verteilung noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. AbbildungÂ 6.4.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schÃ¶n â€˜glattâ€™. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "6Â  Die Post befragen",
    "section": "6.3 Die Post-Verteilung befragen",
    "text": "6.3 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\nğŸ“º Die Post-Verteilung auslesen\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in AbbildungÂ 6.5 schematisch illustriert.\n\n\n\n\n\n\nAbbildungÂ 6.5: Fragen nach p vs.Â Fragen nach q\n\n\n\nIm linken Teildiagramm von AbbildungÂ 6.5 fragen wir: â€œWie wahrscheinlich ist ein Wasseranteil von hÃ¶chstens 80%?â€. Im rechten Teildiagramm fragen wir: â€œWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht Ã¼berschritten?â€.\n\n6.3.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt? Um diese Frage zu beantworten, zÃ¤hlen wir einfach, wie viele Stichproben die Bedingung erfÃ¼llen, und summieren die Wahrscheinlichkeiten dieser Stichproben. Wir zÃ¤hlen (count) also die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.\n\nBeispiel 6.2 (Was macht die Funktion count?) Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem PrÃ¼fkriterium, Wasseranteil hÃ¶chstens 50%. Dann zÃ¤hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurÃ¼ck. \\(\\square\\)\n\n\n\nWir zÃ¤hlen wie oft der Wasseranteil weniger als 50% betrÃ¤gt:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\n\n  \n\n\n\n\nMan kÃ¶nnte also alternativ auch schreiben:\n\nd %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n  \n\n\n\n\n\n\nBeispiel 6.3 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\nWir zÃ¤hlen die Stichproben, die diesen Kriterien entsprechen:\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n  \n\n\n\n\nğŸ¤– Ich wÃ¼rde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.\n\n\nğŸ‘¨â€ğŸ« Das wollte ich auch gerade sagenâ€¦\n\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n  \n\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden:\n\nsamples %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n  \n\n\n\nFertig ğŸ˜„ \\(\\square\\)\n\n\nBeispiel 6.4 (Wasseranteil zwischen 90& und 100%?) Noch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nSyntaxOutput\n\n\n\nsamples %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\n  \n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.2 (Wasseranteil hÃ¶chstens 50%?) Â \n\nğŸ‘©â€ğŸ”¬ Mit welcher Wahrscheinlichkeit ist der Planet hÃ¶chstens zur HÃ¤lfte mit Wasser bedeckt?\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples %&gt;% count(p_grid &lt;= .5)\n\n\n  \n\n\n\n\n\n\n\nWir kÃ¶nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem â€œGipfelâ€ des Berges, s. AbbildungÂ 6.4.\nFÃ¼r unsere Stichproben-Postverteilung, samples, s. AbbildungÂ 6.2, lÃ¤sst sich der Modus so berechnen:\n\nmap_estimate(samples$p_grid)  \n\n\n  \n\n\n\nDabei steht map fÃ¼r Maximum Aposteriori, also das Maximum der Post-Verteilung.\n\nÃœbungsaufgabe 6.3 Bei der Gelegenheit kÃ¶nnten wir folgende, Ã¤hnliche Fragen stellen:\n\nWas ist der mittlere SchÃ¤tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane SchÃ¤tzwert (Median)?\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n  \n\n\n\n\n\n\n\n\n\n6.3.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall8.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir mÃ¶chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist9.\n\nsamples %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n  \n\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren, s. AbbildungÂ 6.4.\n\n\n\n\n\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\nsamples %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n  \n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n\n6.3.3 Zur Erinnerung: Quantile\nBeispiel: Wie groÃŸ sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z.â€‰B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%, in Inches10:\n\n# speed_gender_height &lt;- read.csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n1data(\"speed_gender_height\", package = \"openintro\")\n\nheight_summary &lt;- \n  speed_gender_height %&gt;% \n2  mutate(height_cm = height*2.54) %&gt;%\n  select(height_inch = height, height_cm) %&gt;% \n3  drop_na() %&gt;%\n4  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %&gt;%\n5  group_by(Einheit) %&gt;%\n6  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n1\n\nDaten importieren\n\n2\n\nInch in Zentimeter umrechnen\n\n3\n\nZeilen mit fehlenden Werten lÃ¶schen\n\n4\n\nIn die Langform pivotieren\n\n5\n\nGruppieren nach Einheit (Inch, Zentimeter)\n\n6\n\nQuantile berechnen (Q1, Q2, Q3)\n\n\n\n\n\n  \n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildungÂ 6.6 visualisiert die Quantile und die HÃ¤ufigkeitsverteilung.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.6: GrÃ¶ÃŸenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n\n\nÃœbungsaufgabe 6.4 (Welcher Parameterwert ist der wahrscheinlich grÃ¶ÃŸte?) Ãœbersetzen wir â€œwahrscheinlichâ€ grÃ¶ÃŸte in â€œmit einer Wahrscheinlichkeit von 99% gibt es keinen grÃ¶ÃŸerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(quant99 = quantile(p_grid, p = .99))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der hÃ¶chste zu erwartende Wasseranteil 0.9.\n\n\n\n\n\nÃœbungsaufgabe 6.5 (Welcher Parameterwert ist der wahrscheinlich kleinste?) Ãœbersetzen wir â€œwahrscheinlichâ€ kleinste in â€œmit einer Wahrscheinlichkeit von 99% gibt es keinen kleinerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .01))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 â€“ immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\nÃœbungsaufgabe 6.6 (Welcher Parameterwert ist der â€œvermutlichâ€ kleinste?) In der â€œwirklichenâ€ Welt sind Aussagen nicht immer prÃ¤zise. Sagen wir, die Chefin der WeltraumbehÃ¶rde hat in einem Presse-Statement von der â€œvermutlichen Untergrenzeâ€ hinsichtlich des Wasseranteils gesprochen.\nÃœbersetzen wir â€œvermutlichâ€ kleinste in â€œmit einer Wahrscheinlichkeit von 90% gibt es keinen kleinerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .1))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 â€“ immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\n\n6.3.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht Ã¼berschritten wird. Das kÃ¶nnen wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% (von 10000) ab (entferne sie).\nSchaue, was der grÃ¶ÃŸte verbleibende Wert ist.\n\n\nsamples %&gt;% \n  arrange(p_grid) %&gt;%   # sortiere\n  slice_head(n = 9000) %&gt;%  # nur die ersten 90%\n  summarise(p90 = max(p_grid))\n\n\n  \n\n\n\nDas (annÃ¤hernd) gleiche Ergebnis liefert quantile():\n\nsamples %&gt;% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n  \n\n\n\n\n\n6.3.5 Visualisierung der Intervalle\n\nDefinition 6.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die â€œabzuschneidendeâ€ Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. AbbildungÂ 6.7, rechtes Teildiagramm.11 \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\n\n\n(b) Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\nAbbildungÂ 6.7: Perzintilintervalle\n\n\n\nDas 10%, 20%, â€¦ 100%-Quantil12 (auf Basis von samples_k100) sind in AbbildungÂ 6.8 illustriert.\n\n\n\n\n\n\nAbbildungÂ 6.8: Quantile in 10%-Schritenn durch die Verteilung von samples_k100",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "href": "0600-Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "title": "6Â  Die Post befragen",
    "section": "6.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich",
    "text": "6.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nNoch einmal zum Globusversuch: Gehen wir von 3 WÃ¼rfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe), s. ListingÂ 6.4:\n\n\n\n\nListingÂ 6.4: Schiefe Post-Verteilung in einer Bayes-Box\n\n\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\n\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\n\n\n\n\n0.93\n1\n0.80\n0.80\n\n\n0.87\n1\n0.66\n0.66\n\n\n0.51\n1\n0.13\n0.13\n\n\n0.53\n1\n0.15\n0.15\n\n\n0.70\n1\n0.34\n0.34\n\n\n0.24\n1\n0.01\n0.01\n\n\n\n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\n\n6.4.1 Perzentil-Intervall\nHier z.â€‰B. ein 50%-Perzentilintervall, s. Abb. AbbildungÂ 6.9.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.9: Schiefe Intervalle\n\n\n\n\n\nEin Perzentilintervall (ETI, PI) kann, wenn es dumm lÃ¤uft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zurÃ¼ckweisen. Das ist nicht so toll.\nEin Highest-Density-Intervall (HDI13) ist schmÃ¤ler als der Perzintilintervall und enthÃ¤lt immer den wahrscheinlichsten Parameterwert.\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.â€‰B. so ausgeben lassen:\n\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)  # Paket `easystats`\n\n\n\n\n\n  \n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.4.2 Intervalle hÃ¶chster Dichte\n\nDefinition 6.2 Intervalle hÃ¶chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schmÃ¤lste Intervall, das den gesuchten Parameter enthÃ¤lt (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten RÃ¤nder nicht mehr gleich groÃŸ, im Sinne von enthalten nicht (zwangslÃ¤ufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen RÃ¤ndern hingegen gleich groÃŸ.\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt), s. Abb. AbbildungÂ 6.10.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.10: Visualisierung der PunktschÃ¤tzer bei einer schiefen Post-Verteilung\n\n\n\n\n\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen, s. TabelleÂ 6.4.\n\nsamples %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\nTabelleÂ 6.4: 50%-HDI fÃ¼r unser Globusmodell\n\n\n\n\n  \n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI).",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "6Â  Die Post befragen",
    "section": "6.5 Fazit",
    "text": "6.5 Fazit\n\n6.5.1 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich\nPerzentilintervalle sind verbreiteter\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n6.5.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datensatz samples, s. ListingÂ 6.3. Sagen wir, wir haben 6 Treffer bei 9 WÃ¼rfen erzielt.\nLageparameter: Welchen mittleren Wasseranteil kann man erwarten?\n\nsamples %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n  \n\n\n\nStreuungsparameter: Wie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?\n\nsamples %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler\n\n\n  \n\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel fÃ¼r einen Parameter, einer unbekannten GrÃ¶ÃŸes eines Modells.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "6Â  Die Post befragen",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nfattails1\nfattails2\nReThink3e1-7\nWeinhaendler\nRethink3m1\nRethink3m2\nKaefer2\ngroesse2\ngroesse1\nAnteil-Apple\nKung-height\nzwielichter-dozent-bayes",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "6Â  Die Post befragen",
    "section": "6.7 â€”",
    "text": "6.7 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 EinfÃ¼hrung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage fÃ¼r Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und MÃ¤nner vor eine Einpark-Aufgabe gestellt (natÃ¼rlich alles schÃ¶n standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen kÃ¶nnen schneller einparken als MÃ¤nner, im Durchschnitt. Das hÃ¤tten wir also geklÃ¤rt. Aber haben wir das ganz sicher geklÃ¤rt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich weiÃŸ, das ist jetzt ein harter Schlag fÃ¼r Sieâ€¦ Aber die gute Nachricht ist: Wir kÃ¶nnen angeben, wie (un)sicher wir bei mit einer Aussage (â€œFrauen parken schnellerâ€¦â€) sind. Zum Beispiel kÃ¶nnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie nÃ¤chste Woche ei Fahri fÃ¼r Ihren neuen Rolls Royce anheuern, mÃ¼ssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, mÃ¼ssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen â€œlaut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauenâ€. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es Ã¼blich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den â€œTop 20 job roles in increasing and decreasing demand across industriesâ€ (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 ModulÃ¼berblick\nAbbildungÂ 1.1 gibt einen Ãœberblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n  subgraph KausalitÃ¤t\n    Kausalstart\n  end \n  Wskt --&gt; Bayes --&gt; Regression --&gt; KausalitÃ¤t\n\n\n\n\nAbbildungÂ 1.1: Modulverlauf im Ãœberblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelleÂ 1.1 gibt einen Ãœberblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist nÃ¼tzlich fÃ¼r Sie, die Tabelle TabelleÂ 1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als nÃ¤chstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelleÂ 1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nInferenz\n2.-8. Okt.\nNA\n\n\n2\nWahrscheinlichkeit\n9.-15. Okt.\nNA\n\n\n3\nVerteilungen\n16.-22. Okt.\nNA\n\n\n4\nGlobusversuch\n23.-29. Okt.\nNA\n\n\n5\nAufhol-Woche\n30.-5. Nov.\nNA\n\n\n6\nDie Post befragen\n5.-12. Nov.\nNA\n\n\n7\nGauss-Modelle\n13.-19. Nov.\nNA\n\n\nNA\nNA\n20.-26. Nov.\nBlockwoche: Kein regulÃ¤rer Unterricht\n\n\n8\nLineare Modelle\n27.-3. Dez.\nNA\n\n\n9\nMetrische AV\n4.-10. Dez.\nNA\n\n\n10\nKonfundierung\n11.-17. Dez\nNA\n\n\n11\nKausalatome\n18.-24. Dez.\nNA\n\n\nNA\nNA\nNA\nJahreswechsel: Kein Unterricht\n\n\n12\nAbschluss\n8.-14. Jan. 24\nNA\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nFÃ¼r dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\n\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.â€‰B. im Online-Buch â€œStatistik1â€ vermittelt. Alle Inhalte daraus werden in diesem Kurs benÃ¶tigt.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#lernhilfen",
    "href": "index.html#lernhilfen",
    "title": "Start:Bayes!",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nHier finden Sie einen Ãœberblick zu Lernhilfen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Start:Bayes!",
    "section": "\n1.3 Software",
    "text": "1.3 Software\nSie benÃ¶tigen R, RStudio und einige R-Pakete insbesondere rstanarm fÃ¼r diesen Kurs.\nHier finden Sie Installationshinweise.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.4 Hinweise",
    "text": "1.4 Hinweise\n\n\n\n\n\n\nHinweis\n\n\n\nAlle formalen Hinweise (PrÃ¼fung, Unterrichtsorganisation, â€¦) sind auf der Seite https://hinweisbuch.netlify.app/ zu finden. \\(\\square\\)\n\n\n\nğŸ“º Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine PrÃ¼fung in diesem Modul ist jedes Semester mÃ¶glich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#tutorium",
    "href": "index.html#tutorium",
    "title": "Start:Bayes!",
    "section": "\n1.5 Tutorium",
    "text": "1.5 Tutorium\nFÃ¼r dieses Modul wird ggf. ein Tutorium angeboten.\nDer Besuch des Tutoriums ist zu empfehlen. Arbeiten Sie auch das Materials auf der Webseite des Tutoriums durch.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#prÃ¼fung",
    "href": "index.html#prÃ¼fung",
    "title": "Start:Bayes!",
    "section": "\n1.6 PrÃ¼fung",
    "text": "1.6 PrÃ¼fung\nDas aktuelle PrÃ¼fungsformat ist: Open-Book-PrÃ¼fung.\n\nAllgemeine PrÃ¼fungshinweise\nPrÃ¼fungsformat: Open-Book-PrÃ¼fung\nHinweise zu quantitativen PrÃ¼fungen\nPrÃ¼fungsvorbereitung\n\nIn KapitelÂ 13 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren kÃ¶nnen:\n@book{sauer_startbayes,\n    title = {Start:Bayes},\n    rights = {CC-BY-NC},\n    url = {https://start-bayes.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2023},\n}\nHier ist die DOI:\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Start:Bayes!",
    "section": "\n1.8 Zum Autor",
    "text": "1.8 Zum Autor\nNÃ¤here Hinweise zum Autor, Sebastian Sauer, finden Sie hier.\n\n\n\n\nForum, World Economic. 2020. â€The Future of Jobs Report 2020â€œ. CH-1223 Cologny/Geneva Switzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#lernsteuerung",
    "href": "1150-konfundierung.html#lernsteuerung",
    "title": "11Â  Konfundierung",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n11.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie kÃ¶nnen ihn entweder Ã¼ber die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber Ã¼ber das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kÃ¼rzerer Name, das ist leichter zu tippen\n\n\n11.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, was eine Konfundierung ist\nDAGs lesen und zeichen\nKonfundierung in einem DAG erkennen\n\n11.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ã„hnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).\n\n11.1.6 Ãœberblick\nIn diesem Kapitel steigen wir ein in das Themengebiet Kausalanalyse (oder synonym Kausalinferenz). Wir beschÃ¤ftigen uns also mit der fÃ¼r die Wissenschaft (und den Rest des Universums) zentralen Frage, was die Ursache eines PhÃ¤nomens ist. In diesem ersten Kapitel zu dem Thema geht es um einen hÃ¤ufigen Fall von â€œScheinkorrelationâ€, also eines Zusammenhangs zwischen UV und AV, der aber gar kein echter kausaler ist, sondern nur Schein. Bei diesem Scheinzusammenhang handelt es sich um die Konfundierung. Im nÃ¤chsten Kapitel schauen wir uns die verbleibenden Grundbausteine der Kausalinferenz an.\n\n11.1.7 Einstieg\n\n11.1.8 Von StÃ¶rchen und Babies\nKennen Sie die Geschichte von StÃ¶rchen und Babies? Ich meine nicht die aus dem Biologieunterricht in der fÃ¼nften Klasse, sondern in einem statistischen Zusammenhang. Was war da noch mal die Moral von der Geschichte?1 \\(\\square\\)\n\n11.1.9 Erlaubt eine Regressionsanalyse KausalschlÃ¼sse?\nFindet man in einer Regressionsanalyse einen â€œEffektâ€, also ein Regressionsgewicht ungleich Null, heiÃŸt das dann, dass die UV die Ursache der AV ist?2 ErklÃ¤ren Sie diesen Sachverhalt genauer. \\(\\square\\)",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "href": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "title": "11Â  Konfundierung",
    "section": "\n11.2 Statistik, was soll ich tun?",
    "text": "11.2 Statistik, was soll ich tun?\n\n11.2.1 Studie A: Ã–strogen\n\n11.2.1.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 11.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelleÂ 11.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nFrauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n11.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 11.1 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.â€‰h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder â€œSchichtenâ€ (â€œStrataâ€).\n\n\n\n11.2.2 Studie B: Blutdruck\n\n11.2.2.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 11.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 11.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nhoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl, Glymour, und Jewell 2016)?\n\n11.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in AbbildungÂ 11.2 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n11.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 11.1 und AbbildungÂ 11.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n11.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ\nStatistik plus Theorie erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n11.2.5 Vertiefung3\n\n\n11.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ã„rzte tendieren zu Behandlung A bei groÃŸen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ã„rzte zu Behandlung B.\nSollte ein Patient, der nicht weiÃŸ, ob sein Nierenstein groÃŸ oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach SteingrÃ¶ÃŸe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wÃ¤hlt?\nDie GrÃ¶ÃŸe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (â€œKetteâ€) von GrÃ¶ÃŸe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. DarÃ¼ber hinaus gibt es noch einen Einfluss von GrÃ¶ÃŸe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in AbbildungÂ 11.3 dargestellt; AbbildungÂ 11.4 visualisiert alternativ. Beide Varianten zeigen das Gleiche. Sie kÃ¶nnen sich einen aussuchen. Hier sind beide Varianten gezeigt, damit Sie wissen, dass verschiedene Darstellungsformen mÃ¶glich sind.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schÃ¤tzen mÃ¶chte? Oder lieber nicht kontrollieren?\n\n\nDAG links-rechts\nDAG oben-unten\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. WÃ¼rde man nicht size kontrollieren, bekÃ¤me man den â€œvermengtenâ€ Effekt von size und treatment, also keine (belastbare) Aussage Ã¼ber den Effekt der Behandlung.\n\n11.2.5.2 Mehr Beispiele\n\nBeispiel 11.1 Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhÃ¶hen, wenn du heiratest. \\(\\square\\)\n\n\nBeispiel 11.2 Studien zeigen, dass Leute, die sich beeilen, zu spÃ¤t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spÃ¤t zu deiner Besprechung. \\(\\square\\)\n\n\n11.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zusÃ¤tzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht nÃ¶tig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafÃ¼r, dass es keine Konfundierung gibt.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#konfundierung",
    "href": "1150-konfundierung.html#konfundierung",
    "title": "11Â  Konfundierung",
    "section": "\n11.3 Konfundierung",
    "text": "11.3 Konfundierung\n\n11.3.1 Die Geschichte von Angie und Don\n\n\n\nğŸ§‘\n\nDon, Immobilienmogul, Auftraggeber\n\n\nğŸ‘©\n\nAngie, Data Scientistin.\n\n\nğŸ§\n\nWolfie, Post-Nerd, kommt in dieser Geschichte aber nicht vor\n\n\nğŸ“º Don und Angie\n\n11.3.2 Datensatz â€˜Hauspreise im Saratoga Countyâ€™\nImportieren Sie den Datensatz SaratogaHouses, s. KapitelÂ 11.1.3.\n\n\n\nTabelleÂ 11.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n11.3.3 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\nâ€œFinden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!â€\n\nğŸ§‘ Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\nğŸ‘© ğŸ”¬ Das ist Angie, Data Scientistin.\n\n11.3.4 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\nâ€œHey Don! Mehr Zimmer, mehr Kohle!â€ ğŸ‘© ğŸ”¬\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. AbbildungÂ 11.5.\n\n\n\n\n\n\n\nAbbildungÂ 11.5: Modell m1\n\n\n\n\n\nâ€œJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.â€\n\nğŸ‘©\n\nZu wenig! ğŸ¤¬\n\nğŸ§‘\nBerechnen wir das Modell m1; der PunktschÃ¤tzer des Parameters bedroom steht in TabelleÂ 11.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\nTabelleÂ 11.4: Parameter fÃ¼r m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die PunktschÃ¤tzer der Parameter eines Modells zurÃ¼ck, aber nicht die SchÃ¤tzbereiche. MÃ¶chten Sie beides, kÃ¶nnen Sie die Funktion parameters(modell) nutzen.4\nMit estimate_predictions kÃ¶nnen wir Vorhersagen berechnen (bzw. schÃ¤tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, d.â€‰h.r ist â€œschÃ¤tzenâ€ vielleicht das treffendere Wort). TabelleÂ 11.5 zeigt den laut m1 vorhergesagten Hauspreis fÃ¼r ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\nTabelleÂ 11.5: Vorhersage des Hauspreises fÃ¼r ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.56e+05\n91070.04\n(-20656.00, 3.36e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.5 Don hat eine Idee\n\nâ€œIch bau eine Mauer! Genial! An die Arbeit, Angie!â€ ğŸ§‘\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\nâ€œDas ist keine gute Idee, Don.â€\n\nğŸ‘©\nBerechnen wir die Vorhersagen fÃ¼r Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. TabelleÂ 11.6.5\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\nTabelleÂ 11.6: Vorhergesagter Hauspreis laut m1 fÃ¼r ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.54e+05\n89308.41\n(78344.42, 4.32e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, s. AbbildungÂ 11.5.\n\nâ€œVolltreffer! Jetzt verdien ich 100 Tausend mehr! ğŸ¤‘ Ich bin der GrÃ¶ÃŸte!â€ ğŸ§‘\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: â€œ4e+05â€ ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n11.3.6 R-Funktionen, um Beobachtungen vorhersagen\npredict(m1, dons_new_house) oder point_estimate(m1, dons_new_house) sagt einen einzelnen Wert vorher (den sog. PunktschÃ¤tzer der Vorhersage).6 Ein Intervall wird nicht ausgegeben.\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berÃ¼cksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im â€œStrukturmodellâ€: Wenn also z.â€‰B. in unserem Modell ein wichtiger PrÃ¤diktor fehlt, so kann die Vorhersagen nicht prÃ¤zise sein. Fehler im Strukturmodell schlagen sich in breiten SchÃ¤tzintervallen (bedingt durch ein groÃŸes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berÃ¼cksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten)\n\nDie SchÃ¤tzbereiche sind in dem Fall deutlich kleiner, s. TabelleÂ 11.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\n\nTabelleÂ 11.7: Ungewissheit fÃ¼r die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\nModel-based Expectation\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3168.87\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.7 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. TabelleÂ 11.8 gibt den PunktschÃ¤tzer fÃ¼r die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\nTabelleÂ 11.8: Parameter (PunktschÃ¤tzer, keine SchÃ¤tzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36533.15\n\n\nbedrooms\n-14138.79\n\n\nlivingArea\n125.35\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? TabelleÂ 11.9 gibt Aufschluss fÃ¼r den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 QuadratfuÃŸ WohnflÃ¤che; TabelleÂ 11.10 gibt die SchÃ¤tzung (laut m2) fÃ¼r den Preis eines Hauses mit 2 Zimmern (und der gleichen WohnflÃ¤che). Die Vorhersage erhÃ¤lt man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130463.8\n\n\n\n\nTabelleÂ 11.9: Vorhersage von m2 fÃ¼r ein Haus mit 4 Zimmern und 1200 Einheiten WohnflÃ¤che\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelleÂ 11.10: Vorhersage von m2 fÃ¼r ein Haus mit 2 Zimmern und 1200 Einheiten WohnflÃ¤che\n\n\n\n  \n\n\n\n\n\n\nAndere, aber Ã¤hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt Ã¼ber die verschiedenen GrÃ¶ÃŸen von livingArea? Stellen Sie sich alle HÃ¤user mit 4 Zimmern vor (also mit verschiedenen WohnflÃ¤chen). Wir mÃ¶chten nur wissen, was so ein Haus â€œim Mittelâ€ kostet. Wir mÃ¶chten also die Mittelwerte pro bedroom schÃ¤tzen, gemittelt fÃ¼r jeden Wert von bedroom Ã¼ber livingArea. Die Ergebnisse stehen in TabelleÂ 11.11 und sind in AbbildungÂ 11.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelleÂ 11.11: Vorhersagen des Preises von HÃ¤usern mit verschiedener Zimmerzahl gemittelt Ã¼ber die verschiedenen Werte der WohnflÃ¤che; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\nâ€œDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!â€\n\nğŸ‘©\n\nâ€œVerringert!? Weniger Geld?! Oh nein!â€\n\nğŸ§‘\n\n11.3.8 Die Zimmerzahl ist negativ mit dem Preis korreliert\nâ€¦ wenn man die WohnflÃ¤che (Quadratmeter) kontrolliert, s. AbbildungÂ 11.7.\n\nâ€œNe-Ga-Tiv!â€\n\nğŸ‘©\n\n\n\n\n\nAbbildungÂ 11.7: Hauspreis stratifizieren\n\n\nQuellcode\n\n\n\n\n\n\nHinweis\n\n\n\nAussagen, gleich ob sie statistischer, wissenshaftlicher oder sonstiger Couleur sind, kÃ¶nnen immer nur dann richtig sein, wenn ihre Annahmen richtig sind. Behauptet etwa ein Modell, dass der Wert einer Immobilie steigt, wenn man mehr Zimmer hat, so ist das kein Naturgesetz, sondern eine Aussage, die nur richtig sein kann, wenn das zugrundeliegende Modell richtig ist. \\(\\square\\)\n\n\n\n11.3.9 Kontrollieren von Variablen\nğŸ’¡ Durch das Aufnehmen von PrÃ¤diktoren in die multiple Regression werden die PrÃ¤diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen PrÃ¤diktors mit \\(y\\), wenn man den (oder die) anderen PrÃ¤diktoren statistisch konstant hÃ¤lt.\nMan nennt die Koeffizienten einer multiplen Regression d.â€‰h.r auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom â€œNetto-Effektâ€ eines PrÃ¤diktors, oder davon, dass ein PrÃ¤diktor â€œbereinigtâ€ wurde vom (linearen) Einfluss der anderen PrÃ¤diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des PrÃ¤diktors \\(x_1\\) auf \\(y\\) anzeigen unabhÃ¤ngig vom Effekt der anderen PrÃ¤diktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines PrÃ¤diktors \\(x_1\\) wird fÃ¼r jede AusprÃ¤gung (Gruppe) des PrÃ¤diktors \\(x_2\\) berechnet.\n\n\n\n\n\n\nWichtig\n\n\n\nDas HinzufÃ¼gen von PrÃ¤diktoren kann die Gewichte der Ã¼brigen PrÃ¤diktoren Ã¤ndern. \\(\\square\\)\n\n\n\nAber welche und wie viele PrÃ¤diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nğŸ§‘\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nğŸ‘©\n\nWozu ist sie dann gut?!\n\nğŸ§‘\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur ErklÃ¤rung der Ursachen heranzuziehen: Die Regressionskoeffizienten kÃ¶nnen sich wild Ã¤ndern, wenn man PrÃ¤diktoren hinzufÃ¼gt oder weglÃ¤sst. Es kÃ¶nnen sich sogar die Vorzeichen der Regressionsgewichte Ã¤ndern; in dem Fall spricht man von einem Simpson-Paradox.\n\n\n\n11.3.10 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, weâ€™d like to know wheter an effect is â€œrealâ€ or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical â€œtestsâ€ on its way to acceptance.\n\nâ€“ McElreath (2020), S. 139\n\n11.3.11 Kausalmodell fÃ¼r Konfundierung, km1\n\nDas Kausalmodell km1 ist in AbbildungÂ 11.8 dargestellt; vgl. AbbildungÂ 11.7.\n\n\n\n\n\n\n\nAbbildungÂ 11.8: Kausalmodell km1 - Eine ErklÃ¤rung (von mehreren) fÃ¼r m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms. Eine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht. d_connected heiÃŸt, dass die betreffenden Variablen â€œverbundenâ€ sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flieÃŸt ğŸŒŠ. d_separated heiÃŸt, dass sie nicht d_connected sind.\n\n11.3.12 m2 kontrolliert die Konfundierungsvariable livingArea\n\n\nBeispiel 11.3 In AbbildungÂ 11.8 ist living area eine Konfundierungsvariable fÃ¼r den Zusammenhang von bedrooms und price. \\(\\square\\)\n\n\nDefinition 11.1 (Konfundierungsvariable) Eine Konfundierungsvariable (Konfundierer) ist eine Variable, die den Zusammenhang zwischen UV und AV verzerrt, wenn sie nicht kontrolliert wird (vanderweele_definition_2013?). \\(\\square\\)\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloÃŸ?! Oh jeh!\n\nğŸ§‘\n\nWir mÃ¼ssen die Konfundierungsvariable kontrollieren.\n\nğŸ‘©\nAbbildungÂ 11.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildungÂ 11.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (â€œadjustierenâ€), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separated.\n\nDefinition 11.2 (Blockieren) Das Kontrollieren eines Konfundierers (wie living_area) â€œblocktâ€ den betreffenden Pfad, fÃ¼hrt also dazu, dass Ã¼ber diesen Pfad keine Assoziation (z.â€‰B. Korrelation) zwischwen UV (bedrooms) und AV (price) mehr vorhanden ist. UV und AV sind dann d_separated (â€œgetrenntâ€). \\(\\square\\)\n\n\n11.3.13 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, AbbildungÂ 11.10, links: Es wird (fÃ¤lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, AbbildungÂ 11.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildungÂ 11.10: Konfundierung von y und x!\n\n\nAbbildungÂ 11.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. AuÃŸerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als PrÃ¤diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\nWichtig\n\n\n\nKontrollieren Sie Konfundierer. \\(\\square\\)\n\n\n\n11.3.14 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 dÃ¼rfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in AbbildungÂ 11.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n11.3.15 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide PrÃ¤diktoren jeweils einen eigenen Beitrag zur ErklÃ¤rung der AV haben.\nDaher kÃ¶nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei KausaleinflÃ¼sse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) Ã¼ber den Mediator (b) zur AV (p) auch Mediation, s. AbbildungÂ 11.11.\n\n\n\n\n\n\n\nAbbildungÂ 11.11: Der Effekt von livingArea wird Ã¼ber den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n11.3.16 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. AbbildungÂ 11.12.\n\n\n\n\n\n\n\nAbbildungÂ 11.12: Dons Kausalmodell\n\n\n\n\n\nâ€œIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das grÃ¶ÃŸte! Alle anderen Kausalmodelle sind ein Disaster!â€\n\nğŸ§‘\n\n\nâ€œDon, nach deinem Kausalmodell mÃ¼ssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.â€\n\nğŸ§‘\nRechne doch selber die Korrelation aus, Don:\n\nâ€œÃ„h, wie ging das nochmal?â€\n\nğŸ§‘\nSo kÃ¶nntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.â€‰B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\nâ€œBitte, gerne hab ich dir geholfen, Don.â€\n\nğŸ‘©\n\n11.3.17 UnabhÃ¤ngigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhÃ¤ngig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zusÃ¤tzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete UnabhÃ¤ngigkeit findet sich nicht in den Daten wieder, s. TabelleÂ 11.8. Also: â›ˆï¸ Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.11.\nDas Kausalmodell km2 postuliert keine UnabhÃ¤ngigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betrÃ¤gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so Ã¤hnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. ğŸ¥±\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhÃ¤ngig von livingArea (a)\nâ›ˆï¸ km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "href": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "title": "11Â  Konfundierung",
    "section": "\n11.4 DAGs: Directed Acyclic Graphs",
    "text": "11.4 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.â€‰B. AbbildungÂ 11.12.\n\nDefinition 11.3 (DAG) DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen. Ein Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden. DAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung). DAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurÃ¼ckfÃ¼hren. \\(\\square\\)\n\n\nDefinition 11.4 (Pfad) Ein Pfad ist ein Weg durch den DAG, von Knoten zu Knoten Ã¼ber die Kanten, unabhÃ¤ngig von der Pfeilrichtung. \\(\\square\\)\n\nDer DAG von km1 ist in AbbildungÂ 11.8 zu sehen.\n\n11.4.1 Leider passen potenziell viele DAGs zu einer Datenlage\nAuf Basis der in Dons Modell dargestellten (Un-)AbhÃ¤ngigkeiten der Variablen sind noch weitere Kausalmodelle mÃ¶glich.\nIn AbbildungÂ 11.13 sind diesen weiteren, mÃ¶glichen Kausalmodelle fÃ¼r Dons Modell dargestellt. Dabei sind folgende AbkÃ¼rzungen verwendet: b: bedrooms, p: price, a area (living area).\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach wÃ¤re, die Kausalstruktur der PhÃ¤nomene zu entdecken, wÃ¤ren sie lÃ¤ngst erkannt, und alle Probleme der Menschheit gelÃ¶st.\n\n\n\n\n\n\n\nAbbildungÂ 11.13: Kausalmodelle, die potenziell geeignet sind fÃ¼r Dons Fragestellung\n\n\n\n\nAlle diese DAgs in AbbildungÂ 11.8 haben die gleichen Implikationen hinsichtlich der (Un-)AbhÃ¤ngigkeiten zwischen der Variablen. Wir kÃ¶nnen also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, brÃ¤uchten wir z.â€‰B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n11.4.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als â€œKausationâ€ bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiÃŸ man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt (McElreath 2020). \\(\\square\\)\n\n\n\nDefinition 11.5 (Kausale AbhÃ¤ngigkeit) Ist \\(X\\) die Ursache von \\(Y\\), so hÃ¤ngt \\(Y\\) von \\(X\\) ab: \\(Y\\) ist (kausal) abhÃ¤ngig von \\(X\\). \\(\\square\\)\n\nViele Menschen denken - fÃ¤lschlich - dass Korrelation Kausation bedeuten muss, s. AbbildungÂ 11.14.\n\n\n\n\n\n\n\nAbbildungÂ 11.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und ErklÃ¤rung\n\nBeispiel 11.4 (Der Schoki-Dag) Der â€œSchoki-DAGâ€ in AbbildungÂ 11.15 zeigt den DAG fÃ¼r das Schokoloaden-Nobelpreis-Modell. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 11.15: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#fazit",
    "href": "1150-konfundierung.html#fazit",
    "title": "11Â  Konfundierung",
    "section": "\n11.5 Fazit",
    "text": "11.5 Fazit\n\n11.5.1 Zusammenfassung\nSind zwei Variablen korreliert (abhÃ¤ngig, assoziiert), so kann es dafÃ¼r zwei GrÃ¼nde geben:\n\nKausaler (â€œechterâ€) Zusammenhang\nNichtkausaler Zusammenhang (â€œScheinkorrelationâ€)\n\nMan ist daran interessiert, echten (also kausalen) Zusammenhang aufzudecken7 und Scheinkorrelation auszuschlieÃŸen.\nEine von zwei mÃ¶glichen Ursachen einer Scheinkorrelation ist Konfundierung.8\nKonfundierung kann man aufdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.â€‰B. indem man ihn als PrÃ¤diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so lÃ¶st sich der Scheinzusammenhang nach dem Adjustieren auf.\nLÃ¶st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der ZusammenhÃ¤nge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine kÃ¶nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nÃ¶tig, um DAGs auszuschlieÃŸen.\n\n11.5.2 Ausstieg\n\nBeispiel 11.5 (Schoki macht Nobelpreis!?) Eine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen der HÃ¶he des Schokoladenkonsums eines Landes und der Anzahl der Nobelpreise eines Landes (Messerli 2012), s. AbbildungÂ 11.16.\n\n\n\n\n\n\n\nAbbildungÂ 11.16: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle Ã¼berprÃ¼fen, so wie wir das hier tun.\n\n\n\n\n11.5.3 Vertiefung\nEs gibt viel Literatur zu dem Thema Kausalinferenz. Ein Artikel, der einen vertieften Einblick in das Thema Konfundierung liefert z.â€‰B. (tennant_use_2020?) oder (suttorp_graphical_2015?). Allerdings sollte man neben Konfundierung noch die drei anderen â€œAtomeâ€ der Kausalinferenz - Kollision, Mediation (und Nachfahre) - kennen, um gÃ¤ngige Fragen der Kausalinferenz bearbeiten zu kÃ¶nnen.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#aufgaben",
    "href": "1150-konfundierung.html#aufgaben",
    "title": "11Â  Konfundierung",
    "section": "\n11.6 Aufgaben",
    "text": "11.6 Aufgaben\n\nSammlung â€œkausalâ€",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#section",
    "href": "1150-konfundierung.html#section",
    "title": "11Â  Konfundierung",
    "section": "\n11.7 â€”",
    "text": "11.7 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. â€Chocolate Consumption, Cognitive Function, and Nobel Laureatesâ€œ. New England Journal of Medicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#lernsteuerung",
    "href": "1180-kausalatome.html#lernsteuerung",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n12.1.2 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n12.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie kÃ¶nnen ihn entweder Ã¼ber die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber Ã¼ber das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kÃ¼rzerer Name, das ist leichter zu tippen\n\n\n12.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\nerklÃ¤ren, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\ndie â€œAtomeâ€ der KausalitÃ¤t eines DAGs benennen\nâ€œkausale HintertÃ¼renâ€ schlieÃŸen\n\n12.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ã„hnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#kollision",
    "href": "1180-kausalatome.html#kollision",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.2 Kollision",
    "text": "12.2 Kollision\nğŸ“º Kollision\n\n12.2.1 Kein Zusammenhang von Intelligenz und SchÃ¶nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und SchÃ¶nheit (looks), wie AbbildungÂ 12.1 illustriert. FÃ¼r geringe Intelligenzwerte gibt es eine breites Spektrum von SchÃ¶nheitswerten und fÃ¼r hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildungÂ 12.1: Kein Zusammenhang von Intelligenz und SchÃ¶nheit in den Daten\n\n\n\n\n\n12.2.2 Aber Ihre Dates sind entweder schlau oder schÃ¶n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schÃ¶n sind oder schlau - aber seltens beides gleichzeitig (schade), s. AbbildungÂ 12.2.\n\n\n\n\n\n\n\nAbbildungÂ 12.2: Ihre Datingpartner sind komischerweise entweder schlau oder schÃ¶n (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?\n\n12.2.3 DAG zur Rettung\nğŸ¦¹ ğŸ¦¸\nDer DAG in AbbildungÂ 12.3 bietet eine rettende ErklÃ¤rung.\n\n\n\n\n\n\n\nAbbildungÂ 12.3: Date als gemeinsame Wirkung von SchÃ¶nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen SchÃ¶nheit und Intelligenz.\n\n\n\n\nEine Ã¤hnliche Visualisierung des gleichen Sachverhalts zeigt AbbildungÂ 12.4.\n\n\n\n\n\n\n\nAbbildungÂ 12.4: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n12.2.4 Was ist eine Kollision?\n\nDefinition 12.1 (Kollision) Als Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) (Pearl, Glymour, und Jewell 2016, p.Â 40). \\(\\square\\)\n\nKontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. AbbildungÂ 12.3, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche PrÃ¤diktoren einer Regression hinzufÃ¼gen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nğŸ™…â€â™€ï¸ Kontrollieren Sie keine Kollisionsvariablen. \\(\\square\\)\n\n\n\n12.2.5 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchÃ¶ne Menschen ğŸª\nReiche Menschen ğŸ¤‘\n\nSehen wir davon aus, dass SchÃ¶nheit und Reichtum unabhÃ¤ngig voneinander sind.\n\nÃœbungsaufgabe 12.1 Wenn ich Ihnen sage, dass Don nicht schÃ¶n ist, aber in der Glitzer hÃ¤ufig auftaucht, was lernen wir dann Ã¼ber seine finanzielle Situation?1 \\(\\square\\)\n\n\nâ€œIch bin schÃ¶n, unglaublich schÃ¶n, und groÃŸ, groÃŸartig, tolle Gene!!!â€ ğŸ§‘\n\n\n12.2.6 Noch ein einfaches Beispiel zur Kollision\n\nâ€œSo langsam check ichâ€™s!â€ ğŸ§‘2\n\nSei Z = X + Y, wobei X und Y unabhÃ¤ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts Ã¼ber Y, da die beiden Variablen unabhÃ¤ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhÃ¤ngig, gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).3\n\n12.2.7 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildungÂ 12.3 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.â€‰B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als PrÃ¤diktor in eine Regression zusÃ¤tzlich zu looks mit talent als PrÃ¤dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (â€œFlussâ€) von Looks Ã¼ber date nach Talent ist blockiert.\nKontrolliert man date, so Ã¶ffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr â€œblockiertâ€, die Korrelation kann â€œflieÃŸenâ€ - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n12.2.8 IQ, Fleiss und Eignung fÃ¼rs Studium\nSagen wir, Ã¼ber die Eignung fÃ¼r ein Studium wÃ¼rden nur (die individuellen AusprÃ¤gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in AbbildungÂ 12.5.\n\n\n\n\n\n\n\nAbbildungÂ 12.5: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fÃ¼rs Studium) sei definiert als die Summe von iq und fleiss, plus etwas GlÃ¼ck, s. ListingÂ 12.1.\n\n\n\nListingÂ 12.1: Eignung ist die Summe von Fleiss und Intelligenz, plus ein Quentchen GlÃ¼ck\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\n\n\n\nLaut unserem Modell setzt sich Eignung zur HÃ¤lfte aus Intelligenz und zur HÃ¤lfte aus Fleiss zusammen, plus etwas GlÃ¼ck.\n\n12.2.9 Schlagzeile â€œFleiÃŸ macht blÃ¶d!â€\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und FleiÃŸ (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das â€œEignungsmodellâ€, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. TabelleÂ 12.1.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\nTabelleÂ 12.1: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildungÂ 12.6 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildungÂ 12.6: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhÃ¤ngig von FleiÃŸ in unseren Daten, sondern abhÃ¤ngig. Nichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde Ã¼ber ZusammenhÃ¤nge auf und interpretieren die ZusammenhÃ¤nge â€“ oft vorschnell â€“ als kausal.4\n\n12.2.10 Kollisionsverzerrung nur bei Stratifizierung\n\nDefinition 12.2 (Stratifizieren) Durch Stratifizieren wird eine Stichprobe in (homogene) Untergruppen unterteilt (sog. Strata). \\(\\square\\)\n\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. AbbildungÂ 12.7.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 12.7: Stratifizierung und Scheinkorrelation. A: Keine Stratifizierung und keine Scheinkorrelation. B: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nÃ¼tzen.\nNur Kenntnis des DAGs verrÃ¤t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten PrÃ¤diktor auf, so â€œkontrolliertâ€ man diese Variable. Das Regressiongewicht des ersten PrÃ¤diktors wird â€œbereinigtâ€ um den Einfluss des zweiten PrÃ¤diktors; insofern ist der zweite PrÃ¤diktor dann â€œkontrolliertâ€.\n\n\n\n12.2.11 Einfluss von GroÃŸeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und GroÃŸeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von GroÃŸeltern auf ihre Enkel, s. AbbildungÂ 12.8, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildungÂ 12.8: Der kausale Effekt von GroÃŸeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable Ã¼bersehen haben? (S. nÃ¤chster Abschnitt). ğŸ‘»\n\n12.2.12 Der Gespenster-DAG\nğŸ‘» Es gibt â€œunheilbareâ€ DAGs, nennen wir sie â€œGespenster-DAGsâ€, in denen es nicht mÃ¶glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. AbbildungÂ 12.9. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: â€œDeine Theorie ist nicht gut, zurÃ¼ck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.â€\n\n\n\n\n\n\n\nAbbildungÂ 12.9: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollstÃ¤ndig) mÃ¶glich.\n\n\n\n\nU kÃ¶nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft. Die GroÃŸeltern wohnen woanders (in Spanien), d.â€‰h.r wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie. E ist sowohl fÃ¼r G als auch fÃ¼r U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad. Wenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\nDie Sache ist in diesem Fall chancenlos. Wir mÃ¼ssen diesen DAG verloren geben, McElreath (2020), S. 180; ein Gespenster-DAG. ğŸ‘»",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-hintertÃ¼r-schlieÃŸen",
    "href": "1180-kausalatome.html#die-hintertÃ¼r-schlieÃŸen",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.3 Die HintertÃ¼r schlieÃŸen",
    "text": "12.3 Die HintertÃ¼r schlieÃŸen\n\nDefinition 12.3 (HintertÃ¼r) Eine â€œHintertÃ¼râ€ ist ein nicht-kausaler Pfad zwischen einer UV und einer AV. Ein HintertÃ¼rpfad entsteht, wenn es eine alternative Route Ã¼ber eine oder mehrere Variable gibt, die UV mit der AV verbindet. Dieser Pfad verzerrt die SchÃ¤tzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. \\(\\square\\)\n\n\n12.3.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groÃŸ ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in AbbildungÂ 12.10 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 12.10: Der Preis wird sowohl von der Zimmerzahl als auch der WohnflÃ¤che beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund fÃ¼r die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\leftarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. GÃ¤be es nur nur den zweiten Pfad und wir wÃ¼rden b Ã¤ndern, so wÃ¼rde sich p nicht Ã¤ndern.\n\n12.3.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildungÂ 12.11 zeigt eine erfreuliche Situation: Die â€œHintertÃ¼râ€ zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die HintertÃ¼r geschlossen - fÃ¼hren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildungÂ 12.11: Unverzerrte SchÃ¤tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere PrÃ¤diktor im Modell enthalten ist. Da die beiden PrÃ¤diktoren unkorreliert sind, hat die Aufnahme des einen PrÃ¤diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie â€œHintertÃ¼râ€ der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berÃ¼hmte LÃ¶sung, den kausalen Pfad zu isolieren, ist ein (randomisiertes, kontrolliertes5) Experiment. Wenn wir den HÃ¤usern zufÃ¤llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen kÃ¶nnten (unabhÃ¤ngig von ihrer Quadratmeterzahl, a), wÃ¼rde sich der Graph so Ã¤ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\leftarrow a \\rightarrow p\\) geschlossen (â€œblockiertâ€).\n\n\n\n\n\n\nWichtig\n\n\n\nDie StÃ¤rke von (gut gemachten) Experimente ist, dass sie kausale HintertÃ¼ren schlieÃŸen. Damit erlauben sie (korrekte) Kausalaussagen. \\(\\square\\)\n\n\n\n12.3.3 HintertÃ¼r schlieÃŸen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die HintertÃ¼r schlieÃŸen (backdoor criterion). Wir wollen die HintertÃ¼re schlieÃŸen, da wir sonst nicht den wahren, kausalen Effekt bestimmen kÃ¶nnen.\nZum GlÃ¼ck gibt es neben Experimenten noch andere Wege, die HintertÃ¼r zu schlieÃŸen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie Konfundierer, um kausale HintertÃ¼ren zu schlieÃŸen. \\(\\square\\)\n\n\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis Ã¼ber b kein zusÃ¤tzliches Wissen Ã¼ber p. Wissen Sie hingegen nichts Ã¼ber a, lernen Sie bei Kenntnis von b auch etwas Ã¼ber p. Konditionieren ist wie â€œgegeben, dass Sie a schon kennenâ€¦â€.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "href": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.4 Die vier Atome der Kausalanalyse",
    "text": "12.4 Die vier Atome der Kausalanalyse\nAbbildungÂ 12.12 stellt die vier â€œAtomeâ€ der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so kÃ¶nnen Sie jedes beliebige Kausalsystem (DAG) entschlÃ¼sseln.\n\n\n\n\n\n\n\nAbbildungÂ 12.12: Die vier Atome der Kausalinferenz\n\n\n\n\n\n12.4.1 Mediation\n\nDefinition 12.4 (Mediator) Einen Pfad mit drei Knoten (Variablen), die Ã¼ber insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man Mediation. Der Mediator ist die Variable zwischen UV und AV [Pearl, Glymour, und Jewell (2016); p.Â 38]. \\(\\square\\)\n\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. AbbildungÂ 12.13. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y â€œvermitteltâ€ oder Ã¼bertrÃ¤gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildungÂ 12.13: Das Kausalmodell der Mediation mit x als UV, m als Mediator und Y als AV.\n\n\n\n\n\nBeispiel 12.1 (Mediator kontrollieren?) Sollte man den Mediator m in AbbildungÂ 12.13 kontrollieren, wenn man den Kausaleffekt von x auf y schÃ¤tzen mÃ¶chte?6 \\(\\square\\)\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation â€œflieÃŸtâ€ den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlieÃŸt) die Kette (genau wie bei der Gabel).\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie den Mediator nicht. Der Pfad Ã¼ber den Mediator ist ein â€œechterâ€ Kausalpfad, keine Scheinkorrelation. \\(\\square\\)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. \\(\\square\\)\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. AbbildungÂ 12.14. In AbbildungÂ 12.14 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\).\n\nDefinition 12.5 (Effekt) Gibt es eine (von (praktisch) Null verschiedene) kausale Assoziation der UV auf die AV, so hÃ¤ngt die AV von der UV (kausal) ab. Man spricht von einem Effekt (der UV auf die AV). \\(\\square\\)\n\n\nDefinition 12.6 (Totaler Effekt) Die Summe der Effekte aller (kausalen) Pfade von UV zu AV nennt man den totalen (kausalen) Effekt. \\(\\square\\)\n\n\nDefinition 12.7 (Indirekter Effekt) Den (kausalen) Effekt Ã¼ber den Mediatorpfad (von \\(X\\) Ã¼ber \\(M\\) zu \\(Y\\)) nennt man den indirekten (kausalen) Effekt. \\(\\square\\)\n\n\nDefinition 12.8 (Direkter Effekt) Ein Effekt, der nur aus dem Pfad \\(x\\rightarrow y\\) besteht, also ohne keine Zwischenglieder, nennt man in Abgrenzung zum indirekten Effekt, direkten (kausalen) Effekt. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 12.14: Partielle Mediation: Es gibt einen direkten Effekt (X-&gt;Y) und einen indirekten Effekt (X-&gt;M-&gt;Y).\n\n\n\n\n\n12.4.2 Der Nachfahre\n\nDefinition 12.9 (Nachfahre) Ein Nachfahre (engl. descendent) ist eine Variable, die von einer anderen Variable beeinflusst7 wird, s. AbbildungÂ 12.15. \\(\\square\\)\n\nKontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet Ã¼ber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise Ã¶ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildungÂ 12.15: Ein Nachfahre verhÃ¤lt sich Ã¤hnlich wie sein Vorfahreâ€¦\n\n\n\n\n\n12.4.3 Kochrezept zur Analyse von DAGs ğŸ‘¨â€ğŸ³\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: ğŸ“„\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geÃ¶ffnet ist.\nBeurteilen Sie fÃ¼r jeden Pfad, ob er ein HintertÃ¼rpfad ist (HintertÃ¼rpfade haben einen Pfeil, der zur UV fÃ¼hrt).\nWenn es geÃ¶ffnete Hinterpfade gibt, prÃ¼fen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlieÃŸen (falls mÃ¶glich).",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich",
    "href": "1180-kausalatome.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.5 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!",
    "text": "12.5 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!\nğŸ“º HintertÃ¼r schlieÃŸen\n\n12.5.1 HintertÃ¼r: ja oder nein?\n\n12.5.1.1 Fall 1: x-&gt;\n\n\\(\\boxed{X \\rightarrow}\\)\nAlle Pfade, die von der UV (X) wegfÃ¼hren, sind entweder â€œguteâ€ Kausalpfade oder automatisch geblockte Nicht-Kausal-Pfade. In diesem Fall mÃ¼ssen wir nichts tun.8\n\n12.5.1.2 Fall 2: -&gt;x\n\n\\(\\boxed{\\rightarrow X}\\)\nAlle Pfade, die zur UV hinfÃ¼hren, sind immer Nicht-Kausal-Pfade, HintertÃ¼ren. Diese Pfade kÃ¶nnen offen sein, dann mÃ¼ssen wir sie schlieÃŸen. Sie kÃ¶nnen auch geschlossen sein, dann mÃ¼ssen wir nichts tun.\n\n\n\n\n\n\nTipp\n\n\n\nSchlieÃŸen Sie immer offene HintertÃ¼ren, um Verzerrungen der Kausaleffekte zu verhinden. \\(\\square\\)\n\n\n\n12.5.2 bsp1\n\nUV: \\(X\\), AV: \\(Y\\), drei Kovariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\n\nAbbildungÂ 12.16: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei HintertÃ¼rpfade in AbbildungÂ 12.16:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlieÃŸt die offene HintertÃ¼r.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n12.5.3 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp2\n\nS. DAG in AbbildungÂ 12.17: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildungÂ 12.17: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen HintertÃ¼ren zu schlieÃŸen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), S. 188.\n\n12.5.4 Implizierte bedingte UnabhÃ¤ngigkeiten von bsp2\n\n\nAuch wenn die Daten nicht sagen kÃ¶nnen, welcher DAG der richtige ist, kÃ¶nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten UnabhÃ¤ngigkeiten geben uns MÃ¶glichkeiten, zu prÃ¼fen, ob wir einen DAG verwerfen (ausschlieÃŸen) kÃ¶nnen. Bedingten UnabhÃ¤ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhÃ¤ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte UnabhÃ¤ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#fazit",
    "href": "1180-kausalatome.html#fazit",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.6 Fazit",
    "text": "12.6 Fazit\n\n12.6.1 Ausstieg\nğŸ“º MusterlÃ¶sung fÃ¼r eine DAG-PrÃ¼fungsaufgabe\nğŸ“º MusterlÃ¶sung fÃ¼r schwierige DAG-PrÃ¼fungsaufgaben\n\nBeispiel 12.2 (PMI zum heutigen Stoff) Der KreativitÃ¤tsforscher Edward de Bono hat verschiedene â€œDenkmethodenâ€ vorgestellt, die helfen sollen, Probleme besser zu lÃ¶sen. Eine Methode ist die â€œPMI-Methodeâ€. PMI steht fÃ¼r Plus, Minus, Interessant. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anfÃ¼hren. Bei Interessant verzichtet man aber explizit auf eine Bewertung (im Sinne von â€œgutâ€ oder â€œschlechtâ€) und fokussiert sich auf Interessantes, Ãœberraschendes, Bemerkenswertes (vgl. De Bono (1974)).\nFÃ¼hren Sie die PMI-Methode zum heutigen Stoff durch!\n\n\nPlus: Was fanden Sie am heutigen Stoff gut, sinnvoll, nÃ¼tzlich?\n\nMinus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, nÃ¼tzlich?\n\nInteressant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! \\(\\square\\)\n\n\n12.6.2 Zusammenfassung\nğŸ“º Kausalmodelle Ã¼berprÃ¼fen\nWie (und sogar ob) Sie statistische Ergebnisse (z.â€‰B. eines Regressionsmodells) interpretieren kÃ¶nnen, hÃ¤ngt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen kÃ¶nnen die Ergebnisse (z.â€‰B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. â€œDer Unterschied zwischen beiden Gruppen betrÃ¤gt etwa â€¦â€. Allerdings ist eine kausale Interpretation nicht zulÃ¤ssig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.â€‰B. auf Basis der PPV. Kausalaussagen sind zwar nicht mÃ¶glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dÃ¼rfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten Ã¤ndern sich (oft), wenn man PrÃ¤diktoren zum Modell hinzufÃ¼gt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, mÃ¶glichst viele PrÃ¤diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der â€œkausalen Atomeâ€ ist Voraussetzung zur Ableitung von KausalschlÃ¼sse in Beobachtungsstudien.\n\n12.6.3 Vertiefung\nAn weiterfÃ¼hrender Literatur sei z.â€‰B. Cummiskey u.Â a. (2020), LÃ¼bke u.Â a. (2020), Pearl, Glymour, und Jewell (2016) und Dablander (2020) empfohlen. Ein gutes Lehrbuch, das auf Kausalinferenz eingeht, ist Huntington-Klein (2022). Praktischerweise ist es Ã¶ffentlich lesbar. Das Web-Buch Causal Inference for the Brave and True sieht auch vielversprechend aus. Es gibt viele Literatur zu dem Thema; relevante Suchterme sind z.â€‰B. â€œDAGâ€, â€œcausalâ€ oder â€œcausal inferenceâ€.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#aufgaben",
    "href": "1180-kausalatome.html#aufgaben",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.7 Aufgaben",
    "text": "12.7 Aufgaben\n\nSammlung â€œkausalâ€",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#section",
    "href": "1180-kausalatome.html#section",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.8 â€”",
    "text": "12.8 â€”\n\n\n\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, und Krista Watts. 2020. â€Causal Inference in Introductory Statistics Coursesâ€œ. Journal of Statistics Education 0 (Januar): 1â€“16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. â€An Introduction to Causal Inferenceâ€œ. Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische Denken. Rowohlt Taschenbuch Verlag.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. Boca Raton: CRC Press, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLÃ¼bke, Karsten, Matthias Gehrke, JÃ¶rg Horst, und Gero Szepannek. 2020. â€Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Dataâ€œ. Journal of Statistics Education, April, 1â€“17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "13Â  Abschluss",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische â€œLieblingsfehlerâ€ benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik Ã¼bersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n13.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n13.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "13Â  Abschluss",
    "section": "\n13.2 Lieblinglingsfehler",
    "text": "13.2 Lieblinglingsfehler\nLieblingsfehler im Ãœberblick ğŸ¤·:\n\nPost-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrÃ¤diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n13.2.1 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·\nğŸ ğŸ Vertiefung: Dieser Abschnitt ist nicht prÃ¼fungsrelevant. ğŸï¸ ğŸ\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. TabelleÂ 13.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelleÂ 13.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. HÃ¤ufig ist es aber bequemer, z.â€‰B. mit parameters(m1) Post-Intervalle und PunktschÃ¤tzer auszulesen.\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n13.2.2 Quantile und Verteilungsfuntion verwechseln ğŸ¤·\n\n13.2.2.1 Quantil fÃ¼r \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. AbbildungÂ 13.1.\n\n\n\n\n\n\n\nAbbildungÂ 13.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betrÃ¤gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist grÃ¶ÃŸer oder gleich dem \\(p\\)-Quantil.\n\n13.2.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. AbbildungÂ 13.2.\n\n\n\n\n\n\n\nAbbildungÂ 13.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betrÃ¤gt hier 50%, dass \\(x\\) nicht grÃ¶ÃŸer ist als 0.\n\n13.2.3 Interaktion falsch interpretieren ğŸ¤·\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kÃ¼rzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. TabelleÂ 13.2.\n\nparameters(m2)\n\n\n\n\nTabelleÂ 13.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.58\n(19.10, 30.36)\n100%\n1.002\n1851.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.67%\n1.001\n1860.00\nNormal (0.00 +- 0.22)\n\n\nvs\n14.05\n(4.18, 23.19)\n99.72%\n1.001\n1517.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.02)\n99.28%\n1.000\n1668.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelleÂ 13.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\n\n\n\nAbbildungÂ 13.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch ğŸ˜ˆ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11.\nRichtig ğŸ‘¼ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11 â€“ wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte PrÃ¤diktoren wÃ¤ren hier eine sinnvolle LÃ¶sung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "13Â  Abschluss",
    "section": "\n13.3 Kochrezepte ğŸ²",
    "text": "13.3 Kochrezepte ğŸ²\n\n13.3.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen Ã¼ber ein PhÃ¤nomen, \\(y\\), Kausalfrage finden 2. Literatur wÃ¤lzen, um mÃ¶gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese prÃ¤zisieren 4. Modell prÃ¤zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prÃ¼fen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n13.3.2 Parameter schÃ¤tzen vs.Â Hypothesen prÃ¼fen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schÃ¤tzen. Beispiel HypothesenprÃ¼fung: â€œFrauen parken im Durchschnitt schneller ein als MÃ¤nnerâ€. Beispiel ParameterschÃ¤tzung: â€œWie groÃŸ ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und MÃ¤nnern?â€\nJe ausgereifter ein Forschungsfeld, desto kÃ¼hnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nÃ¤chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nÃ¤chste Sonnenfinsternis wird in den nÃ¤chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen fÃ¼r den Klausurerfolg. KÃ¼hne Hypothesen sind wÃ¼nschenswert ğŸ¦¹\n\n13.3.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist hÃ¶her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist grÃ¶ÃŸer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "13Â  Abschluss",
    "section": "\n13.4 Kerngedanken Bayes",
    "text": "13.4 Kerngedanken Bayes\nğŸ“º Bayes in fÃ¼nf Minuten\nğŸ“º Bayes in zehn Minuten\n\n13.4.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. AbbildungÂ 13.4.\n\n\n\n\n\n\n\nAbbildungÂ 13.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.â€‰B. zu einem 95%-PI) ist mÃ¶glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind mÃ¶glich, z.â€‰B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings Ã¼bermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n13.4.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "href": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "title": "13Â  Abschluss",
    "section": "\n13.5 Beispiele fÃ¼r PrÃ¼fungsaufgaben",
    "text": "13.5 Beispiele fÃ¼r PrÃ¼fungsaufgaben\n\n13.5.1 Geben Sie den korrekten Begriff an!\nğŸŒ¬ğŸš™ğŸ™‹ï¸ğŸ‘¨â¬…ï¸Hans ğŸ‘§â¬…ï¸Anna ğŸ‘©â¬…ï¸Lise\nPuh, wie erstelle ich fÃ¼r alle Studis ein anderes RÃ¤tsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-PrÃ¼fung bekommen alle Studentis eine eigene, jeweils andere PrÃ¼fung. Teamarbeit bleibt natÃ¼rlich trotzdem untersagt.\n\n\n\n13.5.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. AbbildungÂ 13.5.\n\n\n\n\n\n\n\nAbbildungÂ 13.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 13.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge fÃ¼r x und y gibt eine kleinstmÃ¶gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu â€œidentifizierenâ€). \\(\\square\\)\n\nâ“Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\nâ— Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n13.5.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. AbbildungÂ 13.6.\n\n\n\n\n\n\n\nAbbildungÂ 13.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n13.5.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildungÂ 13.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildungÂ 13.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set fÃ¼r den totalen Kausaleffekt: {AIS, ALN}\n\n13.5.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrÃ¼fungsfragen zu Modellen kÃ¶nnten z.â€‰B. sein:\n\nGeben Sie den PunktschÃ¤tzer (Median) fÃ¼r den PrÃ¤diktor X im Modell Y an!\nGeben Sie ein 89%-HDI fÃ¼r den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris â€¦\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI fÃ¼r den PrÃ¤diktor X im Modell Y?\nWas verÃ¤ndert sich an den Parametern, wenn Sie die PrÃ¤diktoren zentrieren/z-standardisieren?\nâ€¦",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "13Â  Abschluss",
    "section": "\n13.6 Aufgabensammlungen",
    "text": "13.6 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere â€œPrÃ¼fungsnÃ¤heâ€ kÃ¶nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#fragenspeicher",
    "href": "1200-abschluss.html#fragenspeicher",
    "title": "13Â  Abschluss",
    "section": "\n13.7 Fragenspeicher",
    "text": "13.7 Fragenspeicher\n\nFRAGE: Wo finde ich eine Probeklausur? â€“ ANTWORT: Dieser Tag stellt Fragen einer ProbeprÃ¼fung zusammen.\nFRAGE: Wie bereite ich mich gut auf die PrÃ¼fung vor? â€“ ANTWORT: Hier finden Sie Tipps zur PrÃ¼fungsvorbereitung.\nFRAGE: Wenn man â€˜(Intercept)â€™ benutzt, welche AnfÃ¼hrungszeichen sind die richtigen? Bei verschiedenen AnfÃ¼hrungszeichen, also â€™ oder ` oder Â´ kommen entweder keine oder sogar verschiedene Ergebnisse raus. â€“ ANTWORT: Normalerweise ist innerhalb von R-Befehlen aus dem Tidyverse keine AnfÃ¼hrungsstriche fÃ¼r Spaltennamen nÃ¶tig. Wenn es allerdings ein â€œverbotenerâ€ Name ist, muss man aufpassen. (Intercept) ist so ein verbotener Variablenname. Warum verboten? Ein â€œbraverâ€ Variablenname (in R) muss mit einem Buchstaben beginnen und darf keine Sonderzeichen ((, {, #, etc.) enthalten. Hat man aber einen an sich unerlaubten Variablennamen, so kann man den trotzdem verwenden, wenn man ihn mit Backticks (`) umgibt, also wie in \\(Intercept)\\). Doppelte und einfache AnfÃ¼hrungsstriche sind in R Ã¼brigens beide okay, wenn man etwa einen String (Text) auszeichnen will, aber im Rahmen von Tidyverse nicht nÃ¶tig fÃ¼r Variablennamen.\nFRAGE: Woher weiÃŸ ich, dass ich die PrÃ¤diktoren vorher zentrieren muss? Kann man das aus der Aufgabenstellung irgendwie herauslesen? Z.B. wie bei Tutorium Aufgabe 10.1 d). â€“ ANTWORT: Es gibt mehrere GrÃ¼nde, Variablen zu zentrieren, dazu zÃ¤hlen 1) bessere Interpretation des Intercepts, 2) bessere Interpretation von Interaktionseffekten, 3) Verringerung von KollinearitÃ¤t. Die Steigung (beta 1) verÃ¤ndert sich (fast immer) aber nicht durch das Zentrieren, ebenso wie R-Quadrat.\nFRAGE: Bei der Bearbeitung der PrÃ¼fung heute ist ein Fehler aufgekommen, den ich bis jetzt nicht verstehe. Deshalb war es auch fÃ¼r mich nicht mÃ¶glich die Aufgabe zu bearbeiten. Die AV high Aufteilung in die Werte 0 und 1 (0 = AV &lt;= median (AV)) (1 =AV &gt; median(AV) hat geklappt. Die UV high Aufteilung in die Werte 0 und 1 (0 = UV &lt;= median (UV)) (1 =UV &gt; median(UV) hat dabei aber nicht geklappt. Anstatt die Werte 0 und 1 bei der neuen UV_high Spalte zu bekommen, kommen nur Nas raus. Auch mit dem Befehl drop_na hat es nicht geklappt. Dies habe ich nicht nur mit dem RStudio auf meinem Computer versucht sondern auch Ã¼ber die Cloud Ã¼ber mein IPad. (Bei beiden GerÃ¤ten kam es zuvor noch nie zu Problemen) Hier mein R-Code:\n\n\nlibrary(tidyverse)\n#library(easystats)\n#library(rstanarm)\n\ndata(\"msleep\", package = \"ggplot2\")\n\nmsleep1 &lt;-\n  msleep |&gt; \n    mutate(av_high = case_when(awake &gt; median(awake) ~ 1,\n                               awake &lt;= median(awake) ~ 0))\n\nmsleep2 &lt;-\n  msleep1 |&gt; \n    mutate(uv_high = case_when(sleep_rem &gt; median(sleep_rem) ~ 1,\n                               sleep_rem &lt;= median(sleep_rem) ~ 0))\n  \nmsleep2 |&gt; \ncount(uv_high)\n\n\n  \n\n\n\nANTWORT: Sie haben nicht die fehlenden Werte ausgeschlossen. Wenn Sie die fehlenden Wert ausschlieÃŸen, dann klappt es:\n\nmsleep2 &lt;-\n  msleep1 |&gt; \n  drop_na(sleep_rem) |&gt;  # fehlende Werte aus `sleep_rem` entfernen\n    mutate(uv_high = case_when(sleep_rem &gt; median(sleep_rem) ~ 1,\n                               sleep_rem &lt;= median(sleep_rem) ~ 0))\n  \nmsleep2 |&gt; \ncount(uv_high)\n\n\n  \n\n\n\n\nFRAGE: Ich habe meine LÃ¶sungswege mit Ihren abgeglichen und finde keinen bedeutenden Unterschied. Dennoch erhalte ich andere Ergebnisse, welche nicht im Toleranzbereich liegen. Um das nochmals zu Ã¼berprÃ¼fen, habe ich Ihre LÃ¶sungswege 1:1 in mein RStudio Ã¼bertragen, aber auch dann erhalte ich nicht die angegebene LÃ¶sung. â€“ ANTWORT: Es sollte ein Modell berechnet werden mit z-transformierten Variablen. FÃ¼r die UV war der ROPE anzugeben. Leider haben Sie vergessen, die Daten zu z-transformieren.\n\nHier ist das Modell ohne z-Transformation:\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(dplyr)\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm1 &lt;- stan_glm(bill_length_mm ~ year, data = penguins)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 3.6e-05 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.09 seconds (Warm-up)\n## Chain 1:                0.133 seconds (Sampling)\n## Chain 1:                0.223 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 3.9e-05 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.115 seconds (Warm-up)\n## Chain 2:                0.18 seconds (Sampling)\n## Chain 2:                0.295 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 3.3e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.107 seconds (Warm-up)\n## Chain 3:                0.223 seconds (Sampling)\n## Chain 3:                0.33 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 0.000137 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.37 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.176 seconds (Warm-up)\n## Chain 4:                0.158 seconds (Sampling)\n## Chain 4:                0.334 seconds (Total)\n## Chain 4:\n\nrope(m1)\n\n\n  \n\n\n\nHier ist das Modell mit z-Transformation:\n\np2 &lt;- \n  penguins |&gt; \n  select(bill_length_mm, year) |&gt; \n  standardise()\n\nm2 &lt;- stan_glm(bill_length_mm ~ year, data = p2)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 8e-05 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.092 seconds (Warm-up)\n## Chain 1:                0.15 seconds (Sampling)\n## Chain 1:                0.242 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 0.000111 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.11 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.079 seconds (Warm-up)\n## Chain 2:                0.149 seconds (Sampling)\n## Chain 2:                0.228 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 3.7e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.087 seconds (Warm-up)\n## Chain 3:                0.129 seconds (Sampling)\n## Chain 3:                0.216 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 3.8e-05 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.095 seconds (Warm-up)\n## Chain 4:                0.134 seconds (Sampling)\n## Chain 4:                0.229 seconds (Total)\n## Chain 4:\n\nrope(m2)\n\n\n  \n\n\n\nDer Wert von m2 findet sich in der MusterlÃ¶sung. Man beachte, dass sich die Rope-Werte von m1 und m2 deutlich unterscheiden.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "title": "13Â  Abschluss",
    "section": "\n13.8 Viel Erfolg bei der PrÃ¼fung!",
    "text": "13.8 Viel Erfolg bei der PrÃ¼fung!\nğŸ¥³ğŸ†ğŸ€ğŸ€ğŸ€",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "13Â  Abschluss",
    "section": "\n13.9 â€”",
    "text": "13.9 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. â€The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphsâ€œ. European Psychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. â€œMisconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.â€ Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCohen, J. 1992. â€œA Power Primer.â€ Psychological\nBulletin 112 (1): 155â€“59.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas\nClark, and Krista Watts. 2020. â€œCausal Inference in Introductory\nStatistics Courses.â€ Journal of Statistics Education 0\n(January): 1â€“16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. â€œAn Introduction to Causal\nInference.â€ Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische\nDenken. Rowohlt Taschenbuch Verlag.\n\n\nForum, World Economic. 2020. â€œThe Future of Jobs Report\n2020.â€ CH-1223 Cologny/Geneva Switzerland:\nWorld Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\nâ€œR-Squared for Bayesian Regression Models.â€ The\nAmerican Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2020.\nâ€œRstanarm: Bayesian Applied Regression Modeling via\nStan.â€ https://mc-stan.org/rstanarm.\n\n\nHenze, Norbert. 2019. Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der\nMaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to\nResearch Design and Causality. Boca Raton: CRC\nPress, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of\nScience. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nKampen, D. van. 2014. â€œThe SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.â€ European\nPsychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter Values\nin Bayesian Estimation.â€ Advances in Methods and Practices in\nPsychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLÃ¼bke, Karsten, Matthias Gehrke, JÃ¶rg Horst, and Gero Szepannek. 2020.\nâ€œWhy We Should Teach Causal Inference: Examples in\nLinear Regression with Simulated Data.â€ Journal of Statistics\nEducation, April, 1â€“17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel LÃ¼decke. 2019. â€œIndices of Effect Existence and\nSignificance in the Bayesian Framework.â€ Frontiers in\nPsychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. â€œChocolate Consumption, Cognitive\nFunction, and Nobel Laureates.â€ New England Journal of\nMedicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nMorey, Richard D., and Jeffrey N. Rouder. 2011. â€œBayes Factor\nApproaches for Testing Interval Null Hypotheses.â€\nPsychological Methods 16 (4): 406â€“19. https://doi.org/10.1037/a0024377.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Edited by Herbert\nKeuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.\n\n\nRohrer, Julia M. 2018. â€œThinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational\nData.â€ Advances in Methods and Practices in Psychological\nScience 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. â€œThe\nASA Statement on p-Values:\nContext, Process, and Purpose.â€ The American\nStatistician 70 (2): 129â€“33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]