[
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme Ã¼bersetzen\ntypische Forschungsfragen auswerten\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman, Hill, und Vehtari (2021), Kap. 7 und 10.\n\n9.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 2â€\n\n9.1.5 R-Pakete\nIn diesem Kapite lwerden folgende R-Pakete benÃ¶tigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.6 BenÃ¶tigte Daten\nWir benÃ¶tigen in diesem Kapitel folgende DatensÃ¤tz: kidiq, penguins.\n\n9.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\ndata(\"kidiq\", package = \"rstanarm\")\n\nAlternativ kÃ¶nnen Sie die Daten hier herunterladen.\n Download \n\n9.1.6.2 penguins\n\nSie kÃ¶nnen den Datensatz penguins entweder via dem Pfad importieren:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n Download \nOder via dem zugehÃ¶rigen R-Paket:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nBeide MÃ¶glichkeit sind okay.\n\n9.1.7 Einstieg\n\nBeispiel 9.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, mÃ¼ssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 9.2 (Was war noch einmal die Interaktion?) ErkÃ¤ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n9.1.8 Ãœberblick\nWenn Sie die Skalenniveaus wissen, kÃ¶nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und Ã¤hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, â€¦) lernen mÃ¼ssen. AuÃŸerdem ist die Regressionsanalyse (fÃ¼r viele Situationen) die beste Heransgehensweise, da sie viele MÃ¶glichkeiten fÃ¼r Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels gÃ¤ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. NatÃ¼rlich wÃ¼rzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-KÃ¼che. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#lernsteuerung",
    "href": "1150-konfundierung.html#lernsteuerung",
    "title": "10Â  Konfundierung",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n10.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 10.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie kÃ¶nnen ihn entweder Ã¼ber die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber Ã¼ber das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kÃ¼rzerer Name, das ist leichter zu tippen\n\n\n10.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, was eine Konfundierung ist\nDAGs lesen und zeichen\nKonfundierung in einem DAG erkennen\n\n10.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ã„hnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).\n\n10.1.6 Ãœberblick\nIn diesem Kapitel steigen wir ein in das Themengebiet Kausalanalyse (oder synonym Kausalinferenz). Wir beschÃ¤ftigen uns also mit der fÃ¼r die Wissenschaft (und den Rest des Universums) zentralen Frage, was die Ursache eines PhÃ¤nomens ist. In diesem ersten Kapitel zu dem Thema geht es um einen hÃ¤ufigen Fall von â€œScheinkorrelationâ€, also eines Zusammenhangs zwischen UV und AV, der aber gar kein echter kausaler ist, sondern nur Schein. Bei diesem Scheinzusammenhang handelt es sich um die Konfundierung. Im nÃ¤chsten Kapitel schauen wir uns die verbleibenden Grundbausteine der Kausalinferenz an.\n\n10.1.7 Einstieg\n\n10.1.8 Von StÃ¶rchen und Babies\nKennen Sie die Geschichte von StÃ¶rchen und Babies? Ich meine nicht die aus dem Biologieunterricht in der fÃ¼nften Klasse, sondern in einem statistischen Zusammenhang. Was war da noch mal die Moral von der Geschichte?1 \\(\\square\\)\n\n10.1.9 Erlaubt eine Regressionsanalyse KausalschlÃ¼sse?\nFindet man in einer Regressionsanalyse einen â€œEffektâ€, also ein Regressionsgewicht ungleich Null, heiÃŸt das dann, dass die UV die Ursache der AV ist?2 ErklÃ¤ren Sie diesen Sachverhalt genauer. \\(\\square\\)",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "href": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "title": "10Â  Konfundierung",
    "section": "\n10.2 Statistik, was soll ich tun?",
    "text": "10.2 Statistik, was soll ich tun?\n\n10.2.1 Studie A: Ã–strogen\n\n10.2.1.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 10.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelleÂ 10.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nFrauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n10.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 10.1 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 10.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder â€œSchichtenâ€ (â€œStrataâ€)\n\n\n\n10.2.2 Studie B: Blutdruck\n\n10.2.2.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 10.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 10.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nhoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? Pearl, Glymour, und Jewell (2016)\n\n10.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in AbbildungÂ 10.2 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 10.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n10.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 10.1 und AbbildungÂ 10.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n10.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ\nStatistik plus Theorie erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n10.2.5 Vertiefung3\n\n\n10.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ã„rzte tendieren zu Behandlung A bei groÃŸen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ã„rzte zu Behandlung B.\nSollte ein Patient, der nicht weiÃŸ, ob sein Nierenstein groÃŸ oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach SteingrÃ¶ÃŸe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wÃ¤hlt?\nDie GrÃ¶ÃŸe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (â€œKetteâ€) von GrÃ¶ÃŸe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. DarÃ¼ber hinaus gibt es noch einen Einfluss von GrÃ¶ÃŸe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in AbbildungÂ 10.3 dargestellt; AbbildungÂ 10.4 visualisiert alternativ.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schÃ¤tzen mÃ¶chte? Oder lieber nicht kontrollieren?\n\n\n\n\n\n\n\nAbbildungÂ 10.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. WÃ¼rde man nicht size kontrollieren, bekÃ¤me man den â€œvermengtenâ€ Effekt von size und treatment, also keine (belastbare) Aussage Ã¼ber den Effekt der Behandlung.\n\n10.2.5.2 Mehr Beispiele\n\nBeispiel 10.1 Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhÃ¶hen, wenn du heiratest. \\(\\square\\)\n\n\nBeispiel 10.2 Studien zeigen, dass Leute, die sich beeilen, zu spÃ¤t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spÃ¤t zu deiner Besprechung. \\(\\square\\)\n\n\n10.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zusÃ¤tzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht nÃ¶tig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafÃ¼r, dass es keine Konfundierung gibt.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#konfundierung",
    "href": "1150-konfundierung.html#konfundierung",
    "title": "10Â  Konfundierung",
    "section": "\n10.3 Konfundierung",
    "text": "10.3 Konfundierung\n\n10.3.1 Datensatz â€˜Hauspreise im Saratoga Countyâ€™\nğŸ“º Don und Angie\nImportieren Sie den Datensatz SaratogaHouses, s. KapitelÂ 10.1.3.\n\n\n\nTabelleÂ 10.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n10.3.2 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\nâ€œFinden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!â€\n\nğŸ§‘ Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\nğŸ‘© ğŸ”¬ Das ist Angie, Data Scientistin.\n\n10.3.3 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\nâ€œHey Don! Mehr Zimmer, mehr Kohle!â€ ğŸ‘© ğŸ”¬\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. AbbildungÂ 10.5.\n\n\n\n\n\n\n\nAbbildungÂ 10.5: Modell m1\n\n\n\n\n\nâ€œJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.â€\n\nğŸ‘©\n\nZu wenig! ğŸ¤¬\n\nğŸ§‘\nBerechnen wir das Modell m1; der PunktschÃ¤tzer des Parameters bedroom steht in TabelleÂ 10.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\nTabelleÂ 10.4: Parameter fÃ¼r m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die PunktschÃ¤tzer der Parameter eines Modells zurÃ¼ck, aber nicht die SchÃ¤tzbereiche. MÃ¶chten Sie beides, kÃ¶nnen Sie die Funktion parameters(modell) nutzen.4\nMit estimate_predictions kÃ¶nnen wir Vorhersagen berechnen (bzw. schÃ¤tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist â€œschÃ¤tzenâ€ vielleicht das treffendere Wort). TabelleÂ 10.5 zeigt den laut m1 vorhergesagten Hauspreis fÃ¼r ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\nTabelleÂ 10.5: Vorhersage des Hauspreises fÃ¼r ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.55e+05\n92273.66\n(-20256.77, 3.34e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n10.3.4 Don hat eine Idee\n\nâ€œIch bau eine Mauer! Genial! An die Arbeit, Angie!â€ ğŸ§‘\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\nâ€œDas ist keine gute Idee, Don.â€\n\nğŸ‘©\nBerechnen wir die Vorhersagen fÃ¼r Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. TabelleÂ 10.6.5\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\nTabelleÂ 10.6: Vorhergesagter Hauspreis laut m1 fÃ¼r ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n91169.55\n(71537.64, 4.26e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, s. AbbildungÂ 10.5.\n\nâ€œVolltreffer! Jetzt verdien ich 100 Tausend mehr! ğŸ¤‘ Ich bin der GrÃ¶ÃŸte!â€ ğŸ§‘\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: â€œ4e+05â€ ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n10.3.5 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berÃ¼cksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im â€œStrukturmodellâ€: Wenn also z.B. in unserem Modell ein wichtiger PrÃ¤diktor fehlt, so kann die Vorhersagen nicht prÃ¤zise sein. Fehler im Strukturmodell schlagen sich in breiten SchÃ¤tzintervallen (bedingt durch ein groÃŸes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berÃ¼cksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\n\nDie SchÃ¤tzbereiche sind in dem Fall deutlich kleiner, s. TabelleÂ 10.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\n\nTabelleÂ 10.7: Model-based Expectation\n\n\n\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3104.98\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\nUngewissheit fÃ¼r die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\n\n\n\n10.3.6 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. TabelleÂ 10.8 gibt den PunktschÃ¤tzer fÃ¼r die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\nTabelleÂ 10.8: Parameter (PunktschÃ¤tzer, keine SchÃ¤tzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36311.05\n\n\nbedrooms\n-14077.64\n\n\nlivingArea\n125.32\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? TabelleÂ 10.9 gibt Aufschluss fÃ¼r den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 QuadratfuÃŸ WohnflÃ¤che; TabelleÂ 10.10 gibt die SchÃ¤tzung (laut m2) fÃ¼r den Preis eines Hauses mit 2 Zimmern (und der gleichen WohnflÃ¤che). Die Vorhersage erhÃ¤lt man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130423.8\n\n\n\n\nTabelleÂ 10.9: Vorhersage von m2 fÃ¼r ein Haus mit 4 Zimmern und 1200 Einheiten WohnflÃ¤che\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelleÂ 10.10: Vorhersage von m2 fÃ¼r ein Haus mit 2 Zimmern und 1200 Einheiten WohnflÃ¤che\n\n\n\n  \n\n\n\n\n\n\nAndere, aber Ã¤hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt Ã¼ber die verschiedenen GrÃ¶ÃŸen von livingArea? Stellen Sie sich alle HÃ¤user mit 4 Zimmern vor (also mit verschiedenen WohnflÃ¤chen). Wir mÃ¶chten nur wissen, was so ein Haus â€œim Mittelâ€ kostet. Wir mÃ¶chten also die Mittelwerte pro bedroom schÃ¤tzen, gemittelt fÃ¼r jeden Wert von bedroom Ã¼ber livingArea. Die Ergebnisse stehen in TabelleÂ 10.11 und sind in AbbildungÂ 10.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelleÂ 10.11: Vorhersagen des Preises von HÃ¤usern mit verschiedener Zimmerzahl gemittelt Ã¼ber die verschiedenen Werte der WohnflÃ¤che; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\nâ€œDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!â€\n\nğŸ‘©\n\nâ€œVerringert!? Weniger Geld?! Oh nein!â€\n\nğŸ§‘\n\n10.3.7 Die Zimmerzahl ist negativ mit dem Preis korreliert\nâ€¦ wenn man die WohnflÃ¤che (Quadratmeter) kontrolliert, s. AbbildungÂ 10.7.\n\nâ€œNe-Ga-Tiv!â€\n\nğŸ‘©\n\n\n\n\n\nAbbildungÂ 10.7: Hauspreis stratifizieren\n\n\nQuellcode\n\n\n\n\n\n\nHinweis\n\n\n\nAussagen, gleich ob sie statistischer, wissenshaftlicher oder sonstiger Couleur sind, kÃ¶nnen immer nur dann richtig sein, wenn ihre Annahmen richtig sind. Behauptet etwa ein Modell, dass der Wert einer Immobilie steigt, wenn man mehr Zimmer hat, so ist das kein Naturgesetz, sondern eine Aussage, die nur richtig sein kann, wenn das zugrundeliegende Modell richtig ist. \\(\\square\\)\n\n\n\n10.3.8 Kontrollieren von Variablen\nğŸ’¡ Durch das Aufnehmen von PrÃ¤diktoren in die multiple Regression werden die PrÃ¤diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen PrÃ¤diktors mit \\(y\\), wenn man den (oder die) anderen PrÃ¤diktoren statistisch konstant hÃ¤lt.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom â€œNetto-Effektâ€ eines PrÃ¤diktors, oder davon, dass ein PrÃ¤diktor â€œbereinigtâ€ wurde vom (linearen) Einfluss der anderen PrÃ¤diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des PrÃ¤diktors \\(x_1\\) auf \\(y\\) anzeigen unabhÃ¤ngig vom Effekt der anderen PrÃ¤diktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines PrÃ¤diktors \\(x_1\\) wird fÃ¼r jede AusprÃ¤gung (Gruppe) des PrÃ¤diktors \\(x_2\\) berechnet.\n\n\n\n\n\n\nWichtig\n\n\n\nDas HinzufÃ¼gen von PrÃ¤diktoren kann die Gewichte der Ã¼brigen PrÃ¤diktoren Ã¤ndern. \\(\\square\\)\n\n\n\nAber welche und wie viele PrÃ¤diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nğŸ§‘\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nğŸ‘©\n\nWozu ist sie dann gut?!\n\nğŸ§‘\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur ErklÃ¤rung der Ursachen heranzuziehen: Die Regressionskoeffizienten kÃ¶nnen sich wild Ã¤ndern, wenn man PrÃ¤diktoren hinzufÃ¼gt oder weglÃ¤sst. Es kÃ¶nnen sich sogar die Vorzeichen der Regressionsgewichte Ã¤ndern; in dem Fall spricht man von einem Simpson-Paradox.\n\n\n\n10.3.9 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, weâ€™d like to know wheter an effect is â€œrealâ€ or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical â€œtestsâ€ on its way to acceptance.\n\nâ€“ McElreath (2020), S. 139\n\n10.3.10 Kausalmodell fÃ¼r Konfundierung, km1\n\nDas Kausalmodell km1 ist in AbbildungÂ 10.8 dargestellt; vgl. AbbildungÂ 10.7.\n\n\n\n\n\n\n\nAbbildungÂ 10.8: Kausalmodell km1 - Eine ErklÃ¤rung (von mehreren) fÃ¼r m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms. Eine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht. d_connected heiÃŸt, dass die betreffenden Variablen â€œverbundenâ€ sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flieÃŸt ğŸŒŠ. d_separated heiÃŸt, dass sie nicht d_connected sind.\n\n10.3.11 m2 kontrolliert die Konfundierungsvariable livingArea\n\n\nBeispiel 10.3 In AbbildungÂ 10.8 ist living area eine Konfundierungsvariable fÃ¼r den Zusammenhang von bedrooms und price. \\(\\square\\)\n\n\nDefinition 10.1 (Konfundierungsvariable) Eine Konfundierungsvariable (Konfundierer) ist eine Variable, die den Zusammenhang zwischen UV und AV verzerrt, wenn sie nicht kontrolliert wird (VanderWeele und Shpitser 2013). \\(\\square\\)\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloÃŸ?! Oh jeh!\n\nğŸ§‘\n\nWir mÃ¼ssen die Konfundierungsvariable kontrollieren.\n\nğŸ‘©\nAbbildungÂ 10.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildungÂ 10.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (â€œadjustierenâ€), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separated.\n\nDefinition 10.2 (Blockieren) Das Kontrollieren eines Konfundierers (wie living_area) â€œblocktâ€ den betreffenden Pfad, fÃ¼hrt also dazu, dass Ã¼ber diesen Pfad keine Assoziation (z.B. Korrelation) zwischwen UV (bedrooms) und AV (price) mehr vorhanden ist. UV und AV sind dann d_separated (â€œgetrenntâ€). \\(\\square\\)\n\n\n10.3.12 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, AbbildungÂ 10.10, links: Es wird (fÃ¤lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, AbbildungÂ 10.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildungÂ 10.10: Konfundierung von y und x!\n\n\nAbbildungÂ 10.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. AuÃŸerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als PrÃ¤diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\nWichtig\n\n\n\nKontrollieren Sie Konfundierer. \\(\\square\\)\n\n\n\n10.3.13 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 dÃ¼rfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in AbbildungÂ 10.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n10.3.14 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide PrÃ¤diktoren jeweils einen eigenen Beitrag zur ErklÃ¤rung der AV haben.\nDaher kÃ¶nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei KausaleinflÃ¼sse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) Ã¼ber den Mediator (b) zur AV (p) auch Mediation, s. AbbildungÂ 10.11.\n\n\n\n\n\n\n\nAbbildungÂ 10.11: Der Effekt von livingArea wird Ã¼ber den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n10.3.15 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. AbbildungÂ 10.12.\n\n\n\n\n\n\n\nAbbildungÂ 10.12: Dons Kausalmodell\n\n\n\n\n\nâ€œIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das grÃ¶ÃŸte! Alle anderen Kausalmodelle sind ein Disaster!â€\n\nğŸ§‘\n\n\nâ€œDon, nach deinem Kausalmodell mÃ¼ssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.â€\n\nğŸ§‘\nRechne doch selber die Korrelation aus, Don:\n\nâ€œÃ„h, wie ging das nochmal?â€\n\nğŸ§‘\nSo kÃ¶nntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\nâ€œBitte, gerne hab ich dir geholfen, Don.â€\n\nğŸ‘©\n\n10.3.16 UnabhÃ¤ngigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 10.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhÃ¤ngig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zusÃ¤tzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete UnabhÃ¤ngigkeit findet sich nicht in den Daten wieder, s. TabelleÂ 10.8. Also: â›ˆï¸ Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. AbbildungÂ 10.11.\nDas Kausalmodell km2 postuliert keine UnabhÃ¤ngigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betrÃ¤gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so Ã¤hnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. ğŸ¥±\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 10.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhÃ¤ngig von livingArea (a)\nâ›ˆï¸ km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "href": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "title": "10Â  Konfundierung",
    "section": "\n10.4 DAGs: Directed Acyclic Graphs",
    "text": "10.4 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B. AbbildungÂ 10.12.\n\nDefinition 10.3 (DAG) DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen. Ein Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden. DAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung). DAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurÃ¼ckfÃ¼hren. \\(\\square\\)\n\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten Ã¼ber die Kanten, unabhÃ¤ngig von der Pfeilrichtung.\nDer DAG von km1 ist in AbbildungÂ 10.8 zu sehen.\n\n10.4.1 Leider passen potenziell viele DAGs zu einer Datenlage\nb: bedrooms, p: price, a area (living area)\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach wÃ¤re, die Kausalstruktur der PhÃ¤nomene zu entdecken, wÃ¤ren sie lÃ¤ngst erkannt, und alle Probleme der Menschheit gelÃ¶st.\nIn AbbildungÂ 10.13 sind mÃ¶gliche Kausalmodelle fÃ¼r Dons Studie dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 10.13: Kausalmodelle, die potenziell geeignet sind fÃ¼r Dons Fragestellung\n\n\n\n\nAlle diese DAgs in AbbildungÂ 10.8 haben die gleichen Implikationen hinsichtlich der (Un-)AbhÃ¤ngigkeiten zwischen der Variablen. Wir kÃ¶nnen also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, brÃ¤uchten wir z.B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n10.4.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als â€œKausationâ€ bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiÃŸ man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\nViele Menschen denken - fÃ¤lschlich - dass Korrelation Kausation bedeuten muss, s. AbbildungÂ 10.14.\n\n\n\n\n\n\n\nAbbildungÂ 10.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und ErklÃ¤rung\nDer â€œSchoki-DAGâ€ in AbbildungÂ 10.15 zeigt den DAG fÃ¼r das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\n\n\n\nAbbildungÂ 10.15: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#fazit",
    "href": "1150-konfundierung.html#fazit",
    "title": "10Â  Konfundierung",
    "section": "\n10.5 Fazit",
    "text": "10.5 Fazit\n\n10.5.1 Zusammenfassung\nSind zwei Variablen korreliert (abhÃ¤ngig, assoziiert), so kann es dafÃ¼r zwei GrÃ¼nde geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (â€œScheinkorrelationâ€)\n\nEine mÃ¶gliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als PrÃ¤diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so lÃ¶st sich der Scheinzusammenhang nach dem Adjustieren auf.\nLÃ¶st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der ZusammenhÃ¤nge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine kÃ¶nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nÃ¶tig, um DAGs auszuschlieÃŸen.\n\n10.5.2 Ausstieg\n\nBeispiel 10.4 (Schoki macht Nobelpreis!?) Eine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen der HÃ¶he des Schokoladenkonsums eines Landes und der Anzahl der Nobelpreise eines Landes (Messerli 2012), s. AbbildungÂ 10.16.\n\n\n\n\n\n\n\nAbbildungÂ 10.16: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle Ã¼berprÃ¼fen, so wie wir das hier tun.\n\n\n\n\n10.5.3 Vertiefung\nEs gibt viel Literatur zu dem Thema Kausalinferenz. Ein Artikel, der einen vertieften Einblick in das Thema Konfundierung liefert z.B. Tennant u.Â a. (2020) oder Suttorp u.Â a. (2015). Allerdings sollte man neben Konfundierung noch die drei anderen â€œAtomeâ€ der Kausalinferenz - Kollision, Mediation (und Nachfahre) - kennen, um gÃ¤ngige Fragen der Kausalinferenz bearbeiten zu kÃ¶nnen.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#aufgaben",
    "href": "1150-konfundierung.html#aufgaben",
    "title": "10Â  Konfundierung",
    "section": "\n10.6 Aufgaben",
    "text": "10.6 Aufgaben\n\nSammlung â€œkausalâ€",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#section",
    "href": "1150-konfundierung.html#section",
    "title": "10Â  Konfundierung",
    "section": "\n10.7 â€”",
    "text": "10.7 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. â€Chocolate Consumption, Cognitive Function, and Nobel Laureatesâ€œ. New England Journal of Medicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nSuttorp, Marit M., Bob Siegerink, Kitty J. Jager, Carmine Zoccali, und Friedo W. Dekker. 2015. â€Graphical Presentation of Confounding in Directed Acyclic Graphsâ€œ. Nephrology Dialysis Transplantation 30 (9): 1418â€“23. https://doi.org/10.1093/ndt/gfu325.\n\n\nTennant, Peter W G, Eleanor J Murray, Kellyn F Arnold, Laurie Berrie, Matthew P Fox, Sarah C Gadd, Wendy J Harrison, u.Â a. 2020. â€Use of Directed Acyclic Graphs (DAGs) to Identify Confounders in Applied Health Research: Review and Recommendationsâ€œ. International Journal of Epidemiology 50 (2): 620â€“32. https://doi.org/10.1093/ije/dyaa213.\n\n\nVanderWeele, Tyler J., und Ilya Shpitser. 2013. â€On the Definition of a Confounderâ€œ. Annals of statistics 41 (1): 196â€“220. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#lernsteuerung",
    "href": "1180-kausalatome.html#lernsteuerung",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n11.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 10.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie kÃ¶nnen ihn entweder Ã¼ber die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber Ã¼ber das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kÃ¼rzerer Name, das ist leichter zu tippen\n\n\n11.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\nerklÃ¤ren, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\ndie â€œAtomeâ€ der KausalitÃ¤t eines DAGs benennen\nâ€œkausale HintertÃ¼renâ€ schlieÃŸen\n\n11.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ã„hnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#kollision",
    "href": "1180-kausalatome.html#kollision",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.2 Kollision",
    "text": "11.2 Kollision\nğŸ“º Kollision\n\n11.2.1 Kein Zusammenhang von Intelligenz und SchÃ¶nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und SchÃ¶nheit (looks), wie AbbildungÂ 11.1 illustriert. FÃ¼r geringe Intelligenzwerte gibt es eine breites Spektrum von SchÃ¶nheitswerten und fÃ¼r hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildungÂ 11.1: Kein Zusammenhang von Intelligenz und SchÃ¶nheit in den Daten\n\n\n\n\n\n11.2.2 Aber Ihre Dates sind entweder schlau oder schÃ¶n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schÃ¶n sind oder schlau - aber seltens beides gleichzeitig (schade), s. AbbildungÂ 11.2.\n\n\n\n\n\n\n\nAbbildungÂ 11.2: Ihre Datingpartner sind komischerweise entweder schlau oder schÃ¶n (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?\n\n11.2.3 DAG zur Rettung\nğŸ¦¹ ğŸ¦¸\nDer DAG in AbbildungÂ 11.3 bietet eine rettende ErklÃ¤rung.\n\n\n\n\n\n\n\nAbbildungÂ 11.3: Date als gemeinsame Wirkung von SchÃ¶nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen SchÃ¶nheit und Intelligenz.\n\n\n\n\nEine Ã¤hnliche Visualisierung des gleichen Sachverhalts zeigt AbbildungÂ 11.4.\n\n\n\n\n\n\n\nAbbildungÂ 11.4: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n11.2.4 Was ist eine Kollision?\n\nDefinition 11.1 (Kollision) Als Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) [Pearl, Glymour, und Jewell (2016); p.Â 40]0 \\(\\square\\)\n\n. Kontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. AbbildungÂ 11.3, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche PrÃ¤diktoren einer Regression hinzufÃ¼gen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nğŸ™…â€â™€ï¸ Kontrollieren Sie keine Kollisionsvariablen. \\(\\square\\)\n\n\n\n11.2.5 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchÃ¶ne Menschen ğŸª\nReiche Menschen ğŸ¤‘\n\nSehen wir davon aus, dass SchÃ¶nheit und Reichtum unabhÃ¤ngig voneinander sind.\n\nÃœbungsaufgabe 11.1 Wenn ich Ihnen sage, dass Don nicht schÃ¶n ist, aber in der Glitzer hÃ¤ufig auftaucht, was lernen wir dann Ã¼ber seine finanzielle Situation?1 \\(\\square\\)\n\n\nâ€œIch bin schÃ¶n, unglaublich schÃ¶n, und groÃŸ, groÃŸartig, tolle Gene!!!â€ ğŸ§‘\n\n\n11.2.6 Noch ein einfaches Beispiel zur Kollision\n\nâ€œSo langsam check ichâ€™s!â€ ğŸ§‘2\n\nSei Z = X + Y, wobei X und Y unabhÃ¤ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts Ã¼ber Y, da die beiden Variablen unabhÃ¤ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhÃ¤ngig, gegeben Z: \\(X \\not\\indep Y \\,|\\, Z\\).3\n\n11.2.7 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildungÂ 11.3 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als PrÃ¤diktor in eine Regression zusÃ¤tzlich zu looks mit talent als PrÃ¤dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (â€œFlussâ€) von Looks Ã¼ber date nach Talent ist blockiert.\nKontrolliert man date, so Ã¶ffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr â€œblockiertâ€, die Korrelation kann â€œflieÃŸenâ€ - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n11.2.8 IQ, Fleiss und Eignung fÃ¼rs Studium\nSagen wir, Ã¼ber die Eignung fÃ¼r ein Studium wÃ¼rden nur (die individuellen AusprÃ¤gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in AbbildungÂ 11.5.\n\n\n\n\n\n\n\nAbbildungÂ 11.5: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fÃ¼rs Studium) sei definiert als die Summe von iq und fleiss, plus etwas GlÃ¼ck:\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\nLaut unserem Modell setzt sich Eignung zur HÃ¤lfte aus Intelligenz und zur HÃ¤lfte aus Fleiss zusammen, plus etwas GlÃ¼ck.\n\n11.2.9 Schlagzeile â€œSchlauheit macht Studentis faul!â€\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und FleiÃŸ (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das â€œEignungsmodellâ€, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. TabelleÂ 11.1.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\nTabelleÂ 11.1: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildungÂ 11.6 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildungÂ 11.6: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhÃ¤ngig von FleiÃŸ in unseren Daten, sondern abhÃ¤ngig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde Ã¼ber ZusammenhÃ¤nge auf und interpretieren die ZusammenhÃ¤nge â€“ oft vorschnell â€“ als kausal.4\n\n11.2.10 Kollisionsverzerrung nur bei Stratifizierung\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. AbbildungÂ 11.7.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.7: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nÃ¼tzen.\nNur Kenntnis des DAGs verrÃ¤t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten PrÃ¤diktor auf, so â€œkontrolliertâ€ man diese Variable. Das Regressiongewicht des ersten PrÃ¤diktors wird â€œbereinigtâ€ um den Einfluss des zweiten PrÃ¤diktors; insofern ist der zweite PrÃ¤diktor dann â€œkontrolliertâ€.\n\n\n\n11.2.11 Einfluss von GroÃŸeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und GroÃŸeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von GroÃŸeltern auf ihre Enkel, s. AbbildungÂ 11.8, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildungÂ 11.8: Der kausale Effekt von GroÃŸeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable Ã¼bersehen haben? (S. nÃ¤chster Abschnitt). ğŸ‘»\n\n11.2.12 Der Gespenster-DAG\nğŸ‘»\nEs gibt â€œunheilbareâ€ DAGs, nennen wir sie â€œGespenster-DAGsâ€, in denen es nicht mÃ¶glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. AbbildungÂ 11.9. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: â€œDeine Theorie ist nicht gut, zurÃ¼ck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.â€\n\n\n\n\n\n\n\nAbbildungÂ 11.9: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollstÃ¤ndig) mÃ¶glich.\n\n\n\n\n\nU kÃ¶nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft.\nDie GroÃŸeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\nE ist sowohl fÃ¼r G als auch fÃ¼r U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\n\nDie Sache ist in diesem Fall chancenlos. Wir mÃ¼ssen diesen DAG verloren geben, McElreath (2020), S. 180.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-hintertÃ¼r-schlieÃŸen",
    "href": "1180-kausalatome.html#die-hintertÃ¼r-schlieÃŸen",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.3 Die HintertÃ¼r schlieÃŸen",
    "text": "11.3 Die HintertÃ¼r schlieÃŸen\n\nDefinition 11.2 (HintertÃ¼r) Eine â€œHintertÃ¼râ€ ist ein nicht-kausaler Pfad zwischen einer UV und einer AV.\nEin HintertÃ¼rpfad entsteht, wenn es eine alternative Route Ã¼ber eine oder mehrere Variable gibt, dieUV mit der AV verbindet. Dieser Pfad verzerrt die SchÃ¤tzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. \\(\\square\\)\n\n\n11.3.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groÃŸ ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in AbbildungÂ 11.10 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.10: Der Preis wird sowohl von der Zimmerzahl als auch der WohnflÃ¤che beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund fÃ¼r die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\rightarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. GÃ¤be es nur nur den zweiten Pfad und wir wÃ¼rden b Ã¤ndern, so wÃ¼rde sich p nicht Ã¤ndern.\n\n11.3.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildungÂ 11.11 zeigt eine erfreuliche Situation: Die â€œHintertÃ¼râ€ zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die HintertÃ¼r geschlossen - fÃ¼hren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildungÂ 11.11: Unverzerrte SchÃ¤tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere PrÃ¤diktor im Modell enthalten ist. Da die beiden PrÃ¤diktoren unkorreliert sind, hat die Aufnahme des einen PrÃ¤diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie â€œHintertÃ¼râ€ der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berÃ¼hmte LÃ¶sung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment. Wenn wir den HÃ¤usern zufÃ¤llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen kÃ¶nnten (unabhÃ¤ngig von ihrer Quadratmeterzahl, a), wÃ¼rde sich der Graph so Ã¤ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\rightarrow a \\rightarrow p\\) geschlossen (â€œblockiertâ€).\n\n\n\n\n\n\nWichtig\n\n\n\nDie StÃ¤rke (gut gemachter) Experimente ist, dass sie kausale HintertÃ¼ren schlieÃŸen. \\(\\square\\)\n\n\n\n11.3.3 HintertÃ¼r schlieÃŸen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die HintertÃ¼r schlieÃŸen (backdoor criterion). Wir wollen die HintertÃ¼re schlieÃŸen, da wir sonst nicht den wahren, kausalen Effekt bestimmen kÃ¶nnen.\nZum GlÃ¼ck gibt es neben Experimenten noch andere Wege, die HintertÃ¼r zu schlieÃŸen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie Konfundierer, um kausale HintertÃ¼ren zu schlieÃŸen. \\(\\square\\)\n\n\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis Ã¼ber b kein zusÃ¤tzliches Wissen Ã¼ber p. Wissen Sie hingegen nichts Ã¼ber a, lernen Sie bei Kenntnis von b auch etwas Ã¼ber p. Konditionieren ist wie â€œgegeben, dass Sie a schon kennenâ€¦â€.\n\\(b \\indep p \\,|\\,a\\)",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "href": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.4 Die vier Atome der Kausalanalyse",
    "text": "11.4 Die vier Atome der Kausalanalyse\nAbbildungÂ 11.12 stellt die vier â€œAtomeâ€ der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so kÃ¶nnen Sie jedes beliebige Kausalsystem (DAG) entschlÃ¼sseln.\n\n\n\n\n\n\n\nAbbildungÂ 11.12: Die vier Atome der Kausalinferenz\n\n\n\n\n\n11.4.1 Mediation\n\nDefinition 11.3 (Mediator) Einen Pfad mit drei Knoten (Variablen), die Ã¼ber insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man Mediation. Der Mediator ist die Variable zwischen UV und AV [Pearl, Glymour, und Jewell (2016); p.Â 38]. \\(\\square\\)\n\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. AbbildungÂ 11.13. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y â€œvermitteltâ€ oder Ã¼bertrÃ¤gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildungÂ 11.13: Das Kausalmodell der Mediation.\n\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation â€œflieÃŸtâ€ den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlieÃŸt) die Kette (genau wie bei der Gabel).\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie den Mediator nicht. Der Pfad Ã¼ber den Mediator ist ein â€œechterâ€ Kausalpfad, keine Scheinkorrelation. \\(\\square\\)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. \\(\\square\\)\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. AbbildungÂ 11.14. In AbbildungÂ 11.14 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\). Die Summe der Effekte beider Pfade nennt man den totalen (kausalen) Effekt. Den Effekt Ã¼ber den Mediatorpfad nennt man den indirekten (kausalen) Effekt und den Pfad \\(x\\rightarrow y\\) nennt man den direkten (kaudalen) Effekt.\n\n\n\n\n\n\n\nAbbildungÂ 11.14: Partielle Mediation\n\n\n\n\n\n11.4.2 Der Nachfahre\n\nDefinition 11.4 (Nachfahre) Ein Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. AbbildungÂ 11.15. \\(\\square\\)\n\nKontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet Ã¼ber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise Ã¶ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildungÂ 11.15: Ein Nachfahre verhÃ¤lt sich Ã¤hnlich wie sein Vorfahreâ€¦\n\n\n\n\n\n11.4.3 Kochrezept zur Analyse von DAGs ğŸ‘¨â€ğŸ³\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: ğŸ“„\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geÃ¶ffnet ist.\nBeurteilen Sie fÃ¼r jeden Pfad, ob er ein HintertÃ¼rpfad ist (HintertÃ¼rpfade haben einen Pfeil, der zur UV fÃ¼hrt).\nWenn es geÃ¶ffnete Hinterpfade gibt, prÃ¼fen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlieÃŸen (falls mÃ¶glich).",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich-bsp1",
    "href": "1180-kausalatome.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich-bsp1",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.5 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp1\n",
    "text": "11.5 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp1\n\nğŸ“º HintertÃ¼r schlieÃŸen\nUV: \\(X\\), AV: \\(Y\\), drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\nTipp\n\n\n\nSchlieÃŸen Sie immer offene HintertÃ¼ren, um Verzerrungen der Kausaleffekte zu verhinden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.16: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei HintertÃ¼rpfade in AbbildungÂ 11.16:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlieÃŸt die offene HintertÃ¼r.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n11.5.1 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp2\n\nS. DAG in AbbildungÂ 11.17: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildungÂ 11.17: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen HintertÃ¼ren zu schlieÃŸen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), â€šS. 188.\n\n11.5.2 Implizierte bedingte UnabhÃ¤ngigkeiten von bsp2\n\nEin Graph ohne Us ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme. Auch wenn die Daten nicht sagen kÃ¶nnen, welcher DAG der richtige ist, kÃ¶nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten UnabhÃ¤ngigkeiten geben uns MÃ¶glichkeiten, zu prÃ¼fen, ob wir einen DAG verwerfen (ausschlieÃŸen) kÃ¶nnen. Bedingten UnabhÃ¤ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhÃ¤ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte UnabhÃ¤ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#fazit",
    "href": "1180-kausalatome.html#fazit",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.6 Fazit",
    "text": "11.6 Fazit\n\n11.6.1 Ausstieg\nğŸ“º MusterlÃ¶sung fÃ¼r eine DAG-PrÃ¼fungsaufgabe\nğŸ“º MusterlÃ¶sung fÃ¼r schwierige DAG-PrÃ¼fungsaufgaben\n\nBeispiel 11.1 (PMI zum heutigen Stoff) Der KreativitÃ¤tsforscher Edward de Bono hat verschiedene â€œDenkmethodenâ€ vorgestellt, die helfen sollen, Probleme besser zu lÃ¶sen. Eine Methode ist die â€œPMI-Methodeâ€. PMI steht fÃ¼r Plus, Minus, Interessant. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anfÃ¼hren. Bei Interessant verzichtet man aber explizit auf eine Bewertung (im Sinne von â€œgutâ€ oder â€œschlechtâ€) und fokussiert sich auf Interessantes, Ãœberraschendes, Bemerkenswertes (vgl. De Bono (1974)).\nFÃ¼hren Sie die PMI-Methode zum heutigen Stoff durch!\n\nPlus: Was fanden Sie am heutigen Stoff gut, sinnvoll, nÃ¼tzlich?\nMinus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, nÃ¼tzlich?\nInteressant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! \\(\\square\\)\n\n\n11.6.2 Zusammenfassung\nğŸ“º Kausalmodelle Ã¼berprÃ¼fen\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren kÃ¶nnen, hÃ¤ngt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen kÃ¶nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. â€œDer Unterschied zwischen beiden Gruppen betrÃ¤gt etwa â€¦â€. Allerdings ist eine kausale Interpretation nicht zulÃ¤ssig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht mÃ¶glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dÃ¼rfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten Ã¤ndern sich (oft), wenn man PrÃ¤diktoren zum Modell hinzufÃ¼gt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, mÃ¶glichst viele PrÃ¤diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der â€œkausalen Atomeâ€ ist Voraussetzung zur Ableitung von KausalschlÃ¼sse in Beobachtungsstudien.\n\n11.6.3 Vertiefung\nAn weiterfÃ¼hrender Literatur sei z.B. Cummiskey u.Â a. (2020), LÃ¼bke u.Â a. (2020), Pearl, Glymour, und Jewell (2016) und Dablander (2020) empfohlen. Es gibt viele Literatur zu dem Thema; relevante Suchterme sind z.B. â€œDAGâ€, â€œcausalâ€ oder â€œcausal inferenceâ€.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#aufgaben",
    "href": "1180-kausalatome.html#aufgaben",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.7 Aufgaben",
    "text": "11.7 Aufgaben\n\nSammlung â€œkausalâ€",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#section",
    "href": "1180-kausalatome.html#section",
    "title": "11Â  Die Atome des KausalitÃ¤t",
    "section": "\n11.8 â€”",
    "text": "11.8 â€”\n\n\n\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, und Krista Watts. 2020. â€Causal Inference in Introductory Statistics Coursesâ€œ. Journal of Statistics Education 0 (Januar): 1â€“16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. â€An Introduction to Causal Inferenceâ€œ. Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische Denken. Rowohlt Taschenbuch Verlag.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLÃ¼bke, Karsten, Matthias Gehrke, JÃ¶rg Horst, und Gero Szepannek. 2020. â€Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Dataâ€œ. Journal of Statistics Education, April, 1â€“17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "12Â  Abschluss",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische â€œLieblingsfehlerâ€ benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik Ã¼bersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n12.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n12.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "12Â  Abschluss",
    "section": "\n12.2 Lieblinglingsfehler",
    "text": "12.2 Lieblinglingsfehler\nLieblingsfehler im Ãœberblick ğŸ¤·:\n\nPost-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrÃ¤diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#post-prÃ¤d-verteilung-ppv-und-post-verteilung-verwechseln",
    "href": "1200-abschluss.html#post-prÃ¤d-verteilung-ppv-und-post-verteilung-verwechseln",
    "title": "12Â  Abschluss",
    "section": "\n12.3 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·",
    "text": "12.3 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. TabelleÂ 12.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelleÂ 12.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. HÃ¤ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und PunktschÃ¤tzer auszulesen.\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "href": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "title": "12Â  Abschluss",
    "section": "\n12.4 Quantile und Verteilungsfuntion verwechseln ğŸ¤·",
    "text": "12.4 Quantile und Verteilungsfuntion verwechseln ğŸ¤·\n\n12.4.1 Quantil fÃ¼r \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. AbbildungÂ 12.1.\n\n\n\n\n\n\n\nAbbildungÂ 12.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betrÃ¤gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist grÃ¶ÃŸer oder gleich dem \\(p\\)-Quantil.\n\n12.4.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. AbbildungÂ 12.2.\n\n\n\n\n\n\n\nAbbildungÂ 12.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betrÃ¤gt hier 50%, dass \\(x\\) nicht grÃ¶ÃŸer ist als 0.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "href": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "title": "12Â  Abschluss",
    "section": "\n12.5 Interaktion falsch interpretieren ğŸ¤·",
    "text": "12.5 Interaktion falsch interpretieren ğŸ¤·\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kÃ¼rzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. TabelleÂ 12.2.\n\nparameters(m2)\n\n\n\n\nTabelleÂ 12.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.58\n(19.05, 30.23)\n100%\n0.999\n2272.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.58%\n1.000\n2257.00\nNormal (0.00 +- 0.22)\n\n\nvs\n14.03\n(4.82, 22.98)\n99.90%\n1.001\n1900.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.03)\n99.65%\n1.001\n2111.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelleÂ 12.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\n\n\n\nAbbildungÂ 12.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch ğŸ˜ˆ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11.\nRichtig ğŸ‘¼ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11 â€“ wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte PrÃ¤diktoren wÃ¤ren hier eine sinnvolle LÃ¶sung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "12Â  Abschluss",
    "section": "\n12.6 Kochrezepte ğŸ²",
    "text": "12.6 Kochrezepte ğŸ²\n\n12.6.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen Ã¼ber ein PhÃ¤nomen, \\(y\\), Kausalfrage finden 2. Literatur wÃ¤lzen, um mÃ¶gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese prÃ¤zisieren 4. Modell prÃ¤zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prÃ¼fen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n12.6.2 Parameter schÃ¤tzen vs.Â Hypothesen prÃ¼fen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schÃ¤tzen. Beispiel HypothesenprÃ¼fung: â€œFrauen parken im Durchschnitt schneller ein als MÃ¤nnerâ€. Beispiel ParameterschÃ¤tzung: â€œWie groÃŸ ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und MÃ¤nnern?â€\nJe ausgereifter ein Forschungsfeld, desto kÃ¼hnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nÃ¤chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nÃ¤chste Sonnenfinsternis wird in den nÃ¤chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen fÃ¼r den Klausurerfolg. KÃ¼hne Hypothesen sind wÃ¼nschenswert ğŸ¦¹\n\n12.6.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist hÃ¶her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist grÃ¶ÃŸer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "12Â  Abschluss",
    "section": "\n12.7 Kerngedanken Bayes",
    "text": "12.7 Kerngedanken Bayes\nğŸ“º Bayes in fÃ¼nf Minuten\nğŸ“º Bayes in zehn Minuten\n\n12.7.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. AbbildungÂ 12.4.\n\n\n\n\n\n\n\nAbbildungÂ 12.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist mÃ¶glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind mÃ¶glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings Ã¼bermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n12.7.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "href": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "title": "12Â  Abschluss",
    "section": "\n12.8 Beispiele fÃ¼r PrÃ¼fungsaufgaben",
    "text": "12.8 Beispiele fÃ¼r PrÃ¼fungsaufgaben\n\n12.8.1 Geben Sie den korrekten Begriff an!\nğŸŒ¬ğŸš™ğŸ™‹ï¸ğŸ‘¨â¬…ï¸Hans ğŸ‘§â¬…ï¸Anna ğŸ‘©â¬…ï¸Lise\nPuh, wie erstelle ich fÃ¼r alle Studis ein anderes RÃ¤tsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-PrÃ¼fung bekommen alle Studentis eine eigene, jeweils andere PrÃ¼fung. Teamarbeit bleibt natÃ¼rlich trotzdem untersagt.\n\n\n\n12.8.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. AbbildungÂ 12.5.\n\n\n\n\n\n\n\nAbbildungÂ 12.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\nâ“Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\nâ— Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n12.8.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. AbbildungÂ 12.6.\n\n\n\n\n\n\n\nAbbildungÂ 12.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n12.8.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildungÂ 12.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildungÂ 12.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set fÃ¼r den totalen Kausaleffekt: {AIS, ALN}\n\n12.8.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrÃ¼fungsfragen zu Modellen kÃ¶nnten z.B. sein:\n\nGeben Sie den PunktschÃ¤tzer (Median) fÃ¼r den PrÃ¤diktor X im Modell Y an!\nGeben Sie ein 89%-HDI fÃ¼r den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris â€¦\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI fÃ¼r den PrÃ¤diktor X im Modell Y?\nWas verÃ¤ndert sich an den Parametern, wenn Sie die PrÃ¤diktoren zentrieren/z-standardisieren?\nâ€¦",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "12Â  Abschluss",
    "section": "\n12.9 Aufgabensammlungen",
    "text": "12.9 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere â€œPrÃ¼fungsnÃ¤heâ€ kÃ¶nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "title": "12Â  Abschluss",
    "section": "\n12.10 Viel Erfolg bei der PrÃ¼fung!",
    "text": "12.10 Viel Erfolg bei der PrÃ¼fung!\nğŸ¥³ğŸ†ğŸ€ğŸ€ğŸ€",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "12Â  Abschluss",
    "section": "\n12.11 â€”",
    "text": "12.11 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. â€The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphsâ€œ. European Psychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. â€œMisconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.â€ Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas\nClark, and Krista Watts. 2020. â€œCausal Inference in Introductory\nStatistics Courses.â€ Journal of Statistics Education 0\n(January): 1â€“16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. â€œAn Introduction to Causal\nInference.â€ Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische\nDenken. Rowohlt Taschenbuch Verlag.\n\n\nForum, World Economic. 2020. â€œThe Future of\nJobs Report 2020.â€ CH-1223 Cologny/Geneva\nSwitzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nHenze, Norbert. 2019. Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der\nMaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of\nScience. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nKampen, D. van. 2014. â€œThe SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.â€ European\nPsychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLÃ¼bke, Karsten, Matthias Gehrke, JÃ¶rg Horst, and Gero Szepannek. 2020.\nâ€œWhy We Should Teach Causal Inference: Examples in\nLinear Regression with Simulated Data.â€ Journal of Statistics\nEducation, April, 1â€“17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel LÃ¼decke. 2019. â€œIndices of Effect Existence\nand Significance in the Bayesian\nFramework.â€ Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. â€œChocolate Consumption,\nCognitive Function, and Nobel\nLaureates.â€ New England Journal of Medicine 367\n(16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nMittag, Hans-Joachim, and Katharina SchÃ¼ller. 2020. Statistik: Eine\nEinfÃ¼hrung mit interaktiven Elementen. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nRohrer, Julia M. 2018. â€œThinking Clearly About\nCorrelations and Causation: Graphical Causal\nModels for Observational Data.â€ Advances\nin Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nSuttorp, Marit M., Bob Siegerink, Kitty J. Jager, Carmine Zoccali, and\nFriedo W. Dekker. 2015. â€œGraphical Presentation of Confounding in\nDirected Acyclic Graphs.â€ Nephrology Dialysis\nTransplantation 30 (9): 1418â€“23. https://doi.org/10.1093/ndt/gfu325.\n\n\nTennant, Peter W G, Eleanor J Murray, Kellyn F Arnold, Laurie Berrie,\nMatthew P Fox, Sarah C Gadd, Wendy J Harrison, et al. 2020. â€œUse\nof Directed Acyclic Graphs (DAGs) to Identify Confounders\nin Applied Health Research: Review and Recommendations.â€\nInternational Journal of Epidemiology 50 (2): 620â€“32. https://doi.org/10.1093/ije/dyaa213.\n\n\nVanderWeele, Tyler J., and Ilya Shpitser. 2013. â€œOn the Definition\nof a Confounder.â€ Annals of Statistics 41 (1): 196â€“220.\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. â€œThe\nASA Statement on p-Values:\nContext, Process, and Purpose.â€ The American\nStatistician 70 (2): 129â€“33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 EinfÃ¼hrung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage fÃ¼r Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und MÃ¤nner vor eine Einpark-Aufgabe gestellt (natÃ¼rlich alles schÃ¶n standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen kÃ¶nnen schneller einparken als MÃ¤nner, im Durchschnitt. Das hÃ¤tten wir also geklÃ¤rt. Aber haben wir das ganz sicher geklÃ¤rt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich weiÃŸ, das ist jetzt ein harter Schlag fÃ¼r Sieâ€¦ Aber die gute Nachricht ist: Wir kÃ¶nnen angeben, wie (un)sicher wir bei mit einer Aussage (â€œFrauen parken schnellerâ€¦â€) sind. Zum Beispiel kÃ¶nnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie nÃ¤chste Woche ei Fahri fÃ¼r Ihren neuen Rolls Royce anheuern, mÃ¼ssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, mÃ¼ssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen â€œlaut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauenâ€. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es Ã¼blich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den â€œTop 20 job roles in increasing and decreasing demand across industriesâ€ (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 ModulÃ¼berblick\nAbbildungÂ 1.1 gibt einen Ãœberblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n  subgraph KausalitÃ¤t\n    Kausalstart\n  end \n  Wskt --&gt; Bayes --&gt; Regression --&gt; KausalitÃ¤t\n\n\n\n\nAbbildungÂ 1.1: Modulverlauf im Ãœberblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelleÂ 1.1 gibt einen Ãœberblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist nÃ¼tzlich fÃ¼r Sie, die Tabelle TabelleÂ 1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als nÃ¤chstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelleÂ 1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nInferenz\n2.-8. Okt.\nNA\n\n\n2\nWahrscheinlichkeit\n9.-15. Okt.\nNA\n\n\n3\nVerteilungen\n16.-22. Okt.\nNA\n\n\n4\nGlobusversuch\n23.-29. Okt.\nNA\n\n\n5\nAufhol-Woche\n30.-5. Nov.\nNA\n\n\n6\nDie Post befragen\n5.-12. Nov.\nNA\n\n\n7\nGauss-Modelle\n13.-19. Nov.\nNA\n\n\nNA\nNA\n20.-26. Nov.\nBlockwoche: Kein regulÃ¤rer Unterricht\n\n\n8\nLineare Modelle\n27.-3. Dez.\nNA\n\n\n9\nMetrische AV\n4.-10. Dez.\nNA\n\n\n10\nKonfundierung\n11.-17. Dez\nNA\n\n\n11\nKausalatome\n18.-24. Dez.\nNA\n\n\nNA\nNA\nNA\nJahreswechsel: Kein Unterricht\n\n\n12\nAbschluss\n8.-14. Jan. 24\nNA\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nFÃ¼r dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.B. im Online-Buch â€œStatistik1â€ vermittelt. Alle Inhalte daraus werden in diesem Kurs benÃ¶tigt.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.2 Hinweise",
    "text": "1.2 Hinweise\n\nğŸ“º Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#prÃ¼fung",
    "href": "index.html#prÃ¼fung",
    "title": "Start:Bayes!",
    "section": "\n1.3 PrÃ¼fung",
    "text": "1.3 PrÃ¼fung\nDas PrÃ¼fungsformat ist: Open-Book-PrÃ¼fung.\n\nAllgemeine PrÃ¼fungshinweise\nPrÃ¼fungsformat: Open-Book-PrÃ¼fung\nHinweise zu quantitativen PrÃ¼fungen\nPrÃ¼fungsvorbereitung\n\nIn KapitelÂ 12 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#faq",
    "href": "index.html#faq",
    "title": "Start:Bayes!",
    "section": "\n1.4 FAQ",
    "text": "1.4 FAQ\n\nFRAGE: Wo finde ich eine Probeklausur? â€“ ANTWORT: Dieser Tag stellt Fragen einer ProbeprÃ¼fung zusammen.\nFRAGE: Wie bereite ich mich gut auf die PrÃ¼fung vor? â€“ ANTWORT: Hier finden Sie Tipps zur PrÃ¼fungsvorbereitung.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.5 Zitation",
    "text": "1.5 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\n@book{sauer_statistik1_2022,\n    title = {Statistik1},\n    rights = {All rights reserved},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2023},\n}\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Start:Bayes!",
    "section": "\n1.6 Technische Details",
    "text": "1.6 Technische Details\nDieses Dokument wurde erzeugt am/um 2023-12-08 11:49:08.\n\n## â”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Europe/Berlin\n##  date     2023-11-29\n##  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n## \n## â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  ! package     * version date (UTC) lib source\n##  P cli           3.6.1   2023-03-23 [?] CRAN (R 4.2.0)\n##  P codetools     0.2-18  2020-11-04 [?] CRAN (R 4.2.1)\n##  P digest        0.6.33  2023-07-07 [?] CRAN (R 4.2.0)\n##  P dplyr         1.1.3   2023-09-03 [?] CRAN (R 4.2.0)\n##  P evaluate      0.21    2023-05-05 [?] CRAN (R 4.2.0)\n##  P fansi         1.0.5   2023-10-08 [?] CRAN (R 4.2.0)\n##  P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.2.0)\n##  P generics      0.1.3   2022-07-05 [?] CRAN (R 4.2.0)\n##  P glue          1.6.2   2022-02-24 [?] CRAN (R 4.2.0)\n##  P gt            0.10.0  2023-10-07 [?] CRAN (R 4.2.0)\n##  P htmltools     0.5.6.1 2023-10-06 [?] CRAN (R 4.2.0)\n##  P htmlwidgets   1.6.2   2023-03-17 [?] CRAN (R 4.2.0)\n##  P jsonlite      1.8.7   2023-06-29 [?] CRAN (R 4.2.0)\n##  P knitr         1.45    2023-10-30 [?] CRAN (R 4.2.1)\n##  P lifecycle     1.0.3   2022-10-07 [?] CRAN (R 4.2.0)\n##  P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.2.0)\n##  P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.2.0)\n##  P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.2.0)\n##  P R6            2.5.1   2021-08-19 [?] CRAN (R 4.2.0)\n##    renv          1.0.2   2023-08-15 [1] CRAN (R 4.2.0)\n##  P rlang         1.1.1   2023-04-28 [?] CRAN (R 4.2.0)\n##  P rmarkdown     2.25    2023-09-18 [?] CRAN (R 4.2.0)\n##  P rstudioapi    0.15.0  2023-07-07 [?] CRAN (R 4.2.0)\n##  P sass          0.4.7   2023-07-15 [?] CRAN (R 4.2.0)\n##  P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.2.0)\n##  P tibble        3.2.1   2023-03-20 [?] CRAN (R 4.2.0)\n##  P tidyselect    1.2.0   2022-10-10 [?] CRAN (R 4.2.0)\n##  P utf8          1.2.3   2023-01-31 [?] CRAN (R 4.2.0)\n##  P vctrs         0.6.4   2023-10-12 [?] CRAN (R 4.2.0)\n##  P withr         2.5.2   2023-10-30 [?] CRAN (R 4.2.1)\n##  P xfun          0.40    2023-08-09 [?] CRAN (R 4.2.0)\n##  P xml2          1.3.4   2023-04-27 [?] CRAN (R 4.2.0)\n##  P yaml          2.3.7   2023-01-23 [?] CRAN (R 4.2.0)\n## \n##  [1] /Users/sebastiansaueruser/github-repos/start-bayes/renv/library/R-4.2/x86_64-apple-darwin17.0\n##  [2] /Users/sebastiansaueruser/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.2/x86_64-apple-darwin17.0/fb4b0a46\n## \n##  P â”€â”€ Loaded and on-disk path mismatch.\n## \n## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nForum, World Economic. 2020. â€The Future of Jobs Report 2020â€œ. CH-1223 Cologny/Geneva Switzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "href": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.2 Arten von Forschungsfragen",
    "text": "9.2 Arten von Forschungsfragen\n\n9.2.1 Nach dem Erkenntnisziel\nğŸ“„ Deskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\nğŸ”® PrÃ¤diktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der GrÃ¶ÃŸe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts fÃ¼r die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhÃ¤lt?\n\nğŸ”— PrÃ¤skriptiv (erklÃ¤rend, kausal)\n\nIst GrÃ¶ÃŸe eine Ursache von Gewicht (bei deutschen MÃ¤nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklÃ¤rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehÃ¶rt.\n\n\n\n9.2.2 Nach dem Skalenniveau\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus.\nFÃ¼r die UV(s) sind nominale und metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.\n\n9.2.3 Varianten von Forschungsfragen\nIm Folgenden sind beispielhafte, hÃ¤ufig verwendete Arten von Forschungsfragen aufgefÃ¼hrt. FÃ¼r jede Variante ist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenmniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abhÃ¤ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabhÃ¤ngige Variable (querschnittlich)\n\nb: binÃ¤re Variable\n\nx: metrische unabhÃ¤ngige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#eine-binÃ¤re-uv",
    "href": "1000-metrische-AV.html#eine-binÃ¤re-uv",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.3 Eine binÃ¤re UV",
    "text": "9.3 Eine binÃ¤re UV\n\n9.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im Ã¶ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwÃ¤ndigen Studie die Intelligenz vieler Kinder gemessen. ZusÃ¤tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, â€œRisikofaktorenâ€ fÃ¼r geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in AbhÃ¤ngigkeit davon, ob ihre jeweilige Mutter Ã¼ber einen Schlusabschluss (mom_hs, \\(x=1\\)) verfÃ¼gt (bzw. nicht, \\(x=0\\))? (ceteris paribus)4.\n\nFormaler ausgedrÃ¼ckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (GleichungÂ 9.1):\n\\[\\mu_{x=1|\\alpha, \\beta, \\sigma} \\ne \\mu_{x=0|\\alpha, \\beta, \\sigma} \\tag{9.1}\\]\nDie Modellformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in AbbildungÂ 9.1 dargestellt. Y hat, laut unserem Modell, drei Ursachen:\n\nb\nx\nu, das steht fÃ¼r â€œunbekanntâ€5\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.1: DAG fÃ¼r kid_iq ~ mom_hs\n\n\n\n\n\n9.3.2 IQ von Kindern, binÃ¤rer PrÃ¤diktor\n\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. TabelleÂ 9.1.\n\n\n\nTabelleÂ 9.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nIn AbbildungÂ 9.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\nestimate_expectation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildungÂ 9.2: Kinder, deren MÃ¼tter Ã¼ber einen Schulabschluss verfÃ¼gen, haben im Mittel einen hÃ¶heren Intelligenztestwert, laut dem vorliegenden Modell\n\n\n\n\n\n9.3.3 Interpretation von m10.1\n\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss (mom_hs = 0) verfÃ¼gen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit MÃ¼tter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit MÃ¼tter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die SchÃ¤tzung (Vorhersage) ist bzw. wie stark PrÃ¤diktor (UV) und Kriterium (AV) zusammenhÃ¤ngen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tatsÃ¤chlichen IQ-Wert des Kindes (\\(\\y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n9.3.4 m10.1 als Mittelwertsdifferenz\n\nUV: binÃ¤r (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\n\nğŸ‘¨â€ğŸ« Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heiÃŸen kid_score_avg. An die Arbeit!\n\n\nğŸ¤– Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nkidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von MÃ¼ttern mit Abschluss.\n\n\n\n\n9.3.5 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation - Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das prÃ¼ft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen z.B. die Posteriori-Verteilung (z.B. mit 95%PI).\n\n9.3.6 Antwort auf die Forschungsfrage, m10.1\n\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nm10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schÃ¶nere Namen\n\n\n\nHier sind die ersten paar Zeilen, s. TabelleÂ 9.2.\n\n\n\nTabelleÂ 9.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n75.9\n11.5\n19.3\n\n\n78.6\n10.8\n21.2\n\n\n79.0\n10.2\n18.7\n\n\n79.1\n9.5\n19.8\n\n\n80.3\n8.5\n19.8\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir ein 95%-PI von Hand:7\n\npi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlieÃŸend die Posteriori-Verteilung, s. AbbildungÂ 9.3.\n\nplot(eti(m10.1))\n\n\n\n\n\n\nAbbildungÂ 9.3: Das 95% ETI zum (statistischen) Effekt des mÃ¼tterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem â€œEffektâ€ zu sprechen, lÃ¤sst in den meisten KÃ¶pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang.\n\n\n\n\n\n\n\n\n\n\n9.3.7 Toleranzbereich\nBerechnet man ein Regressionsmodell mit stan_glm (ğŸ¤–ğŸ˜), dann zieht man dabei Zufallszahlen ğŸ². Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zufÃ¤llig. Das erklÃ¤rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen kÃ¶nnen.\nUm zu prÃ¼fen, ob Ihre Ergebnisse â€œÃ¤hnlich genugâ€ oder â€œinnerhalb eines Toleranzbereichsâ€ sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nHinweis\n\n\n\nGrÃ¶ÃŸe des Toleranzbereichs Die GrÃ¶ÃŸe des relativen Toleranzbereichs ist auf 5% festgelegt. Das heiÃŸt, ein Unterschied von 5% zwischen einem Referenzwert (dem â€œwahrenâ€ Wert) und Ihrem Wert ist okay, also im Toleranzbereich. AuÃŸerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der grÃ¶ÃŸere der beiden Werte gilt. \\(\\square\\)\n\n\nZuerst mÃ¼ssen Sie das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN), das geht z.B. so:\n\nlibrary(remotes)  # dieses Paket kÃ¶nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\n\nDann starten Sie es wie gewohnt:\n\nlibrary(prada)\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der â€œrichtigeâ€ oder â€œwahreâ€ Wert (oder schlicht der Wert einer MusterlÃ¶sung) fÃ¼r \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. âœ…",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "1000-metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.4 Eine metrische plus eine nominale UV",
    "text": "9.4 Eine metrische plus eine nominale UV\n\n9.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b.\nDer Kausalgraph8 zur Modellformel sieht aus in AbbildungÂ 9.4 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) EinflÃ¼sse, b und u, wobei u fÃ¼r â€œunbekanntâ€ steht, also fÃ¼r alle sonstigen EinflÃ¼sse.9\n\n\n\n\n\n\n\nAbbildungÂ 9.4: DAG fÃ¼r y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle TabelleÂ 9.3 dargestellt.\n\ndata(\"kidiq\")  # Paket rstanarm, alternativ Ã¼ber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\nTabelleÂ 9.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n9.4.2 1 metrischer PrÃ¤diktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. TabelleÂ 9.4.\n\nm10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\nTabelleÂ 9.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. AbbildungÂ 9.5.\n\nkidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildungÂ 9.5: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. AbbildungÂ 9.6.\n\nplot(estimate_expectation(m10.2))\n\n\n\n\n\n\nAbbildungÂ 9.6: Die geschÃ¤tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder fÃ¼r verschiedene IQ-Werte der MÃ¼tter. Vergleicht man Teilpopulationen von MÃ¼ttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n9.4.3 Beide PrÃ¤diktoren, m10.3\n\nBerechnen wir als nÃ¤chstes ein Modell mit beiden PrÃ¤diktoren: kid_score ~ mom_hs + mom_iq, s. TabelleÂ 9.5.\n\nm10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\nTabelleÂ 9.5: Parameter des Modells m10.3 (ohne sigma)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. PunktschÃ¤tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nMÃ¶chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\nAber natÃ¼rlich ist es mÃ¶glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. AbbildungÂ 9.7.\n\nkidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\nplot(estimate_expectation(m10.3a))\n\n\n\n\n\n\nAbbildungÂ 9.7: Der Effekt von sowohl mÃ¼tterlicher Intelligenz als auch mÃ¼tterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schÃ¤tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum mÃ¼tterlichen Schulabschluss: Vergleicht man Kinder von MÃ¼ttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur mÃ¼tterlichen IQ: Vergleicht man Kinder von MÃ¼ttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#interaktion",
    "href": "1000-metrische-AV.html#interaktion",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.5 Interaktion",
    "text": "9.5 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 folgendes Modell: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. AbbildungÂ 9.8 und TabelleÂ 9.6.\n\nm10.4 &lt;- \n  stan_glm(kid_score ~  mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\nTabelleÂ 9.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.10\n(-37.00, 17.79)\n77.10%\n1.000\n1416.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n49.01\n(20.09, 79.88)\n99.85%\n1.000\n1438.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq\n0.95\n(0.65, 1.24)\n100%\n1.000\n1362.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq\n-0.46\n(-0.78, -0.15)\n99.75%\n1.000\n1388.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_expectation(m10.4) |&gt; plot() kann man es sich visualisieren, s. AbbildungÂ 9.8.\n\n\n\n\n\n\n\nAbbildungÂ 9.8: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt fÃ¼r diese Daten kaum zu interpretieren ist.\n\n\n\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 9.9 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 9.9: DAG fÃ¼r y ~ x + b + x:b\n\n\n\n\n\n9.5.1 Interpretation von m10.4\n\nAchsenabschnitt: IQ-SchÃ¤tzwerte fÃ¼r Kinder mit MÃ¼tter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit MÃ¼ttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten fÃ¼r mom_iq zwischen MÃ¼tter mit bzw. ohne Schulabschluss.\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\n\n9.5.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "href": "1000-metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.6 Zentrieren von PrÃ¤diktoren",
    "text": "9.6 Zentrieren von PrÃ¤diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq.\nMan kÃ¶nnte auch mom_hs zentrieren, aber fÃ¼r eine einfache Interpretation ist es meist nÃ¼tzlich, nur metrische PrÃ¤diktoren zu zentrieren.\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.31\n\n\nmom_hs\n2.91\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n9.6.1 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den geschÃ¤tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten fÃ¼r mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nm10.5 ist in AbbildungÂ 9.10 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 9.10: m10.5: Interaktionsmodell mit zentriertem PrÃ¤diktor fÃ¼r mÃ¼tterlicher Intelligenz. Wie man sieht, ist der Achsenabschnitt deutlich besser zu interpretieren als in m10.4, s. ?fig-m10.4.\n\n\n\n\n\n9.6.2 Zentrieren Ã¤ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.34184\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.3592\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren Ã¤ndert auch nicht die Regressionskoeffizienten, da die Streuungen der PrÃ¤diktoren nicht verÃ¤ndert wurden.\n\n9.6.3 Perzentilintervalle aus der Posterori-Verteilung\nTabelleÂ 9.7 zeigt die PunktschÃ¤tzer der Parameter fÃ¼r m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie dafÃ¼r parameters(m10.5), s. TabelleÂ 9.7.\n\n\n\nTabelleÂ 9.7: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(80.99, 89.72)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.69)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.67, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. TabelleÂ 9.8.\n\nparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelleÂ 9.8: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(81.26, 89.88)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.70)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.79, -0.17)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n9.6.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei MÃ¼ttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mÃ¼tterlichen Intelligenz; pro Punkt Unterschied in mÃ¼ttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). AuÃŸerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei MÃ¼tter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. ZusammenhÃ¤nge beschrieben. FÃ¼r kausale Aussagen ist mehr nÃ¶tig, als einen statistischen Zusammenhang festzustellen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "1000-metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.7 Eine nominale UV mit mehreren Stufen",
    "text": "9.7 Eine nominale UV mit mehreren Stufen\n\n9.7.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in; Ihre Kompetenz als Wirtschaftspsychologi war heiÃŸ begehrt. Von Statistik wollte niemand etwas wissenâ€¦ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt fÃ¼hrte Sie in die Antarktisâ€¦ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um GrÃ¶ÃŸenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren KÃ¶rpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 9.11 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 9.11: DAG fÃ¼r y ~ g\n\n\n\n\n\n9.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ğŸ¤” Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere KÃ¶rpergewichte in AbhÃ¤ngigkeit von der Pinguinart?\n\nAlternativ kÃ¶nnen wir die Hypothese prÃ¼fen, ob die Mittelwerte â€œpraktischâ€ gleich sind, also sich â€œkaumâ€ unterscheiden. Der Grenzwert fÃ¼r â€œpraktisch gleichâ€ bzw. â€œkaum unterschiedlichâ€ ist subjektiv. Dazu in KapitelÂ 9.10 mehr.\n\n9.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, TabelleÂ 9.9.\n\npenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\nTabelleÂ 9.9: Die Verteilung des KÃ¶rpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas fÃ¤llt Ihnen auf?\n\n9.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. AbbildungÂ 9.12?\n\n\n\n\n\n\n\nAbbildungÂ 9.12: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.7.5 Mittlere Gewichtsunterschiede in der Population\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und TabelleÂ 9.10.\n\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\nTabelleÂ 9.10: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3699.92\n(3624.56, 3776.46)\n100%\n1.001\n4194.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.24\n(-100.80, 159.99)\n69.92%\n1.000\n4266.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.94\n(1265.80, 1486.83)\n100%\n1.001\n4187.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n9.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, AusprÃ¤gungen; hier: Spezies), aber es werden in TabelleÂ 9.10 nur zwei Stufen angezeigt (also eine weniger) zusÃ¤tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrÃ¼ckt (Intercept). Die Koeffizienten fÃ¼r species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in AbbildungÂ 9.13 verdeutlicht.\n\nplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 9.13: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (d.Â Details hier).\n\n9.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich hÃ¶her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich Ã¤hnlich.\nWie in AbbildungÂ 9.13 ersichtlich, Ã¼berlappt sich der SchÃ¤tzbereich fÃ¼r den Parameter von Gentoo nicht mit der Null; hingegen Ã¼berlappt sich der SchÃ¤tzbereich des Parameters fÃ¼r Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hÃ¤tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prÃ¼fen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primÃ¤r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#priori-werte",
    "href": "1000-metrische-AV.html#priori-werte",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.8 Priori-Werte",
    "text": "9.8 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. FÃ¼r Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfÃ¼r Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: prior_summary(modell):\n\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWo man man Ã¼ber mehr inhaltliches Wissen verfÃ¼gt, so wird man die Prioris anpassen wollen, z.B.:\n\nm10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3703.90575         26.67909       1360.23645\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nm10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.98554         30.95782       1375.37494\n\nDen Parameter fÃ¼r die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\nsigma(m10.6b)\n## [1] 462.6415\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die GrÃ¶ÃŸe der Konfidenzintervalle.\nÃœbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren12.\n\n9.8.1 Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge Ã¤ndern.\n\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nlibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\nBeachten Sie, dass dazu das Paket forcats verfÃ¼gbar sein muss.\nJetzt haben wir die Referenzkategorie geÃ¤ndert:\n\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\nDer Wechsel der Referenzkategorie Ã¤ndert nichts Wesentliches am Modell, s. TabelleÂ 9.11.\n\nm10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\nTabelleÂ 9.11: m10.6a mit geÃ¤nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 5001.08, 5160.63]\n\n\nspeciesAdelie\n[-1477.80, -1264.23]\n\n\nspeciesChinstrap\n[-1475.95, -1204.52]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "href": "1000-metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.9 ModellgÃ¼te mit R-Quadrat bestimmen",
    "text": "9.9 ModellgÃ¼te mit R-Quadrat bestimmen\n\n9.9.1 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt. - HÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt. \\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert. Solch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor. Daher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\n\n\n\nr2(m10.6)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.668 (95% CI [0.618, 0.712])\n\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. AbbildungÂ 9.14.\n\nm10.6_r2 &lt;-\nm10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 9.14: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n9.9.2 Definition vom â€œklassischenâ€ \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die â€œtypischeâ€ Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nÃ¼tzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklÃ¤rten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck Ã¤quivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen AusdrÃ¼cke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlÃ¤ssigen Ungewissheit; sie sind Ã¼bergewiss aus Bayes-Sicht.\n\n9.9.3 Bayesâ€™ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der ModellgÃ¼te miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkÃ¤rte Varianz}}{\\text{ErklÃ¤rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. FÃ¼r jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklÃ¤rten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u.Â a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#sec-rope",
    "href": "1000-metrische-AV.html#sec-rope",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.10 Nullhypothesen sind praktisch immer falsch",
    "text": "9.10 Nullhypothesen sind praktisch immer falsch\nğŸ“º Teil 2\nNullhypothesen sind fast immer falsch, s. AbbildungÂ 9.15.\n\n\n\n\n\n\n\nAbbildungÂ 9.15: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, und Vehtari (2021)\n\n9.10.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist13\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n9.10.2 â€œPraktischâ€ kein Unterschied: Das Rope-Konzept\nğŸ“º ROPE-Video\nSagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar. Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt. Unter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroÃŸteil liegt innerhalb von Rope â¡ï¸ Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nGroÃŸteil liegt auÃŸerhalb von Rope â¡ï¸ Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nAnsonsten â¡ï¸ keine Entscheidung\n\n9.10.3 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildungÂ 9.16: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\n\nAbbildungÂ 9.16 illustriert die Entscheidungsregel zum ROPE fÃ¼r mehrere Situatioenen (Kruschke 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett auÃŸerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung mÃ¶glich; die Datenlage ist unklar.\n\n9.10.4 Rope berechnen\nDen Rope berechnet man mit rope(model).\n\nrope(m10.6)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir kÃ¶nnen daher fÃ¼r diese Gruppe das ROPE nicht verwerfen.\nAber: Gentoo liegt zu 0% im Rope. FÃ¼r Gentoo kÃ¶nnen wir das Rope verwerfen.\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n9.10.5 Visualisierung unserer Rope-Werte, m10.6\n\nEin GroÃŸteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut.\n\n\nplot(rope(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung fÃ¼r Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir kÃ¶nnen das Rope fÃ¼r Chinstrap nicht verwerfen, aber auch nicht bestÃ¤tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom â€œblauen Flussâ€ des Rope: Gentoo liegt auÃŸerhalb des Rope. Es gibt einen â€œsubstanziellenâ€ Unterschied, grÃ¶ÃŸer als das ROPE. Wir verwerfen die â€œPraktisch-Null-Hypotheseâ€ in diesem Fall.\n\n9.10.6 Finetuning des Rope\nWir kÃ¶nnen festlegen, was wir unter â€œpraktischer Ã„quivalenzâ€ verstehen, also die Grenzen des Ropes verÃ¤ndern. Sagen wir, 100 Gramm sind unsere Grenze fÃ¼r einen vernachlÃ¤ssigbaren Effekt, s. AbbildungÂ 9.17.\n\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 9.17: ROPE mit selber eingestellter Grenze von Â±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht fÃ¼r ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.\n\n9.10.7 Beantwortung der Forschungsfrage\nFÃ¼r die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. FÃ¼r Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#mehrere-metrische-uv",
    "href": "1000-metrische-AV.html#mehrere-metrische-uv",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.11 Mehrere metrische UV",
    "text": "9.11 Mehrere metrische UV\n\n9.11.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhÃ¤ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa â€œIQ der Mutter ist die Ursache zum IQ des Kindesâ€) wird impliziert.\nEs geht rein darum, ZusammenhÃ¤nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. FÃ¼r solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nÃ¶tig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n9.11.2 Was heiÃŸt, X hÃ¤ngt mit Y zusammen?\n\nDer Begriff â€œZusammenhangâ€ ist nicht exakt.\nHÃ¤ufig wird er (fÃ¼r metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groÃŸ der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem â€œEffekt von X auf Yâ€ Ã¼bersetzt. Vorsicht: â€œEffektâ€ klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende BegrÃ¼ndung fÃ¼r einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der StÃ¤rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehÃ¶rigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n9.11.3 Korrelationen zur Forschungsfrage\n\nkidiq %&gt;% \n  correlation()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\nTabelleÂ 9.12 zeigt die Korrelationsmatrix als Korrelationsmatrix:\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\nTabelleÂ 9.12: Die Korrelationen zwischen den Variablen der Tabelle kidiq\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.21***\n0.28***\n\n\n\nmom_iq\n0.09\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nNÃ¼tzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, AbbildungÂ 9.18.\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 9.18: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n9.11.4 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro PrÃ¤diktor, also eine fÃ¼r mom_iq und eine fÃ¼r mom_age.\n\nm10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\nHier die Ergebnisse fÃ¼r mom_iq:\n\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.8084927   0.6101706\n\nHier die Ergebnisse fÃ¼r mom_age:\n\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.1650562   0.6875296\n\n\n9.11.5 Visualisierung der univariaten Regressionen\nIn AbbildungÂ 9.19 ist die univariate Regression mit jeweils einem der beiden PrÃ¤diktoren dargestellt.\nm10.7: Die Steigung betrÃ¤gt 0.6. m10.8: Die Steigung betrÃ¤gt 0.7.\n\n\n\n\n\n\n\nAbbildungÂ 9.19: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n9.11.6 Multiples Modell (beide PrÃ¤diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein PrÃ¤diktor im Modell aufgenommen ist.\n\nm10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils â€œbereinigtâ€ vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines PrÃ¤diktors mit der AV, wobei man gleichzeitig den anderen PrÃ¤diktor konstant hÃ¤lt.\n\n\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n\n\n9.11.7 3D-Visualisierung eines Modells mit zwei PrÃ¤diktoren 1\nIn AbbildungÂ 9.20 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildungÂ 9.20: 3D-Visualisierung von m10.9 (zwei PrÃ¤diktoren)\n\n\n\n\n9.11.8 Visualisierung mit Farbe statt 3. Dimension\n3D-Visualisierungen haben Vorteile, aber auch Nachteile; AbbildungÂ 9.21 zeigt eine alternative Visualisierung, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildungÂ 9.21: Modell m10.9; die FarbverlÃ¤ufe zeigen der Wert der abhÃ¤ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der FarbÃ¤nderung) die VerÃ¤nderung fÃ¼r die AV (kid_score). Auf der Achse fÃ¼r mom_age sieht man, dass sich die AV kaum Ã¤ndert, wenn sich mom_age Ã¤ndert.\n\n9.11.9 Visualisierung in 10 Dimensionen\nAbbildungÂ 9.22 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildungÂ 9.22: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere SchwÃ¤chen, eine groÃŸe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n9.11.10 Relevanz der PrÃ¤diktoren\nWoher weiÃŸ man, welcher PrÃ¤diktor am stÃ¤rksten mit der AV zusammenhÃ¤ngt? Man kÃ¶nnte auch sagen: Welcher PrÃ¤diktor (welche UV) am â€œwichtigstenâ€ ist oder den â€œstÃ¤rksten Einflussâ€ auf die AV ausÃ¼bt? Bei solchen kausal konnotierten AusdrÃ¼cken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann fÃ¼r sich nur Muster in den Daten, also ZusammenhÃ¤nge bzw. Unterschiede, entdecken, s. AbbildungÂ 9.23.\n\n\n\n\n\nAbbildungÂ 9.23: Made at imgflip.com\n\n\nWelcher PrÃ¤diktor ist nun â€œwichtigerâ€ oder â€œstÃ¤rkerâ€ in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)?\n\n\nmom_iq hat den grÃ¶ÃŸeren Koeffizienten.\n\nmom_age hat weniger Streuung.\n\nUm die Relevanz der PrÃ¤diktoren vergleichen zu kÃ¶nnen, mÃ¼sste man vielleicht die VerÃ¤nderung von kid_score betrachten, wenn man von kleinsten zum grÃ¶ÃŸten PrÃ¤diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die VerÃ¤nderung in der AV zu betrachten, wenn man den PrÃ¤diktor von â€œunterdurchschnittlichâ€ auf â€œÃ¼berdurchschnittlichâ€ Ã¤ndert. Das kann man mit z-Standardisierung erreichen.\n\n9.11.11 z-Standardisierung\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie Ã¼ber einen Mittelwert von 0 und eine SD von 1 verfÃ¼gt:\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\ndata(\"kidiq\")\nkidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;% \n  select(mom_iq, mom_iq_z) %&gt;% \n  head()\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten14. Die Standardisierung ist Ã¤hnlich zur Vergabe von ProzentrÃ¤ngen: â€œDieser Messwert gehÃ¶rt zu den Top-3-Prozentâ€. Diese Aussage ist bedeutsam fÃ¼r Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen fÃ¼r verschiedene Verteilungen mÃ¶glich.\n\n9.11.12 Statistiken zu den z-transformierten Variablen\nTabelleÂ 9.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer AusprÃ¤gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener PrÃ¤diktoren sind einfacher in ihrer GrÃ¶ÃŸe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und Ã¤hnlich groÃŸe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (â€œSkalierungâ€) mit standardize (aus easystats) durchfÃ¼hren, s. TabelleÂ 9.13.\n\nkidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\nTabelleÂ 9.13: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n65\n1\n121.12\n27\n-1.07\n0.52\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n0.55\n0.52\n-0.71\n0.82\n\n\n85\n1\n115.44\n27\n-0.09\n0.52\n1.03\n1.56\n\n\n83\n1\n99.45\n25\n-0.19\n0.52\n-0.04\n0.82\n\n\n115\n1\n92.75\n27\n1.38\n0.52\n-0.48\n1.56\n\n\n98\n0\n107.90\n18\n0.55\n-1.91\n0.53\n-1.77\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafÃ¼r, dass die ursprÃ¼nglichen Variablen beim z-Standardisieren nicht Ã¼berschrieben werden, sondern angehÃ¤ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nkidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. TabelleÂ 9.14. Dazu verwendet man den Befehl scale().\n\nkidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\nTabelleÂ 9.14: Z-Standardisierung ohne Extrapaketâ€",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#modell-m10.10",
    "href": "1000-metrische-AV.html#modell-m10.10",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.12 Modell m10.10\n",
    "text": "9.12 Modell m10.10\n\n\n9.12.1 AV z-transformieren\nIm Modell m10.10 sind die PrÃ¤diktoren z-transformiert (standardisiert) und die AV ebenfalls. Das Standardisieren der AV, kid_score ist zwar nicht nÃ¶tig, um den Effekt der PrÃ¤diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darÃ¼ber, um wie viele SD-Einheiten sich die AV verÃ¤ndert, wenn sich ein PrÃ¤diktor um eine SD-Einheit verÃ¤ndert. Das kann auch eine interessante(re) Aussage sein.\n\nm10.10 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.10)\n## (Intercept)    mom_iq_z   mom_age_z \n## 0.001554359 0.443843346 0.050380199\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient fÃ¼r mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_iq um eine SD-Einheit Ã¤ndert.\nDer Koeffizient fÃ¼r mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_age um eine SD-Einheit Ã¤ndert.\n\nJetzt sind die PrÃ¤diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n9.12.2 95%-PI\nMit parameters kÃ¶nnen wir uns ein PI fÃ¼r m10.10 ausgeben lassen, s. AbbildungÂ 9.24; im Standard wird ein 95%-ETI berichtet15.\n\nparameters(m10.10) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n1.55e-03\n(-0.08, 0.08)\n51.12%\n0.999\n4683.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n5372.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.33%\n0.999\n4779.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nplot(eti(m10.10)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 9.24: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI fÃ¼r m10.10\n\n\n\n\n\n9.12.3 Was ist ein kleiner, was ein groÃŸer Effekt?\nCohen (1988) definiert EffektstÃ¤rken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\). FÃ¼r kleine, mittlere und groÃŸe Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\n\nmittel: \\(d \\approx 0.5\\)\n\ngroÃŸ: \\(d \\approx 0.8\\)\n\n\nAuf dieser Basis schlÃ¤gt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor. FÃ¤llt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als â€œpraktisch nullâ€. Richtlinien fÃ¼r EffektstÃ¤rken sind nur NotlÃ¶sungen, die durch Sachverstand ersetzt werden sollen, wo immer mÃ¶glich. Man kann EffektstÃ¤rken ineinander Ã¼berfÃ¼hren, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n9.12.4 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat. Ein vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n9.12.5 ModellgÃ¼te\n\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.204 (95% CI [0.142, 0.268])\n\nIst dieser Wert von \\(R2\\) â€œgutâ€? Diese Frage ist Ã¤hnlich zur Frage â€œIst das viel Geld?â€; man kann die Frage nur im Kontext beantworten.\nEine einfache LÃ¶sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklÃ¤rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufÃ¤llig hohen Werten der ModellgÃ¼te im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine â€œobjektiveâ€ Antwort auf die Frage â€œwie viel ist viel?â€ haben wollen, ziehen wir Herrn Cohen zu Rate:\n\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\nDanke, Herr Cohen!\n\n9.12.6 Priori-Verteilung fÃ¼r m10.10 und Modelldefinition\nStan hat fÃ¼r uns folgende Prioris ausgesucht:\n\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWie gesagt, Stan nimmt dafÃ¼r einfach die empirischen Mittelwerte und Streuungen her16.\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. GleichungÂ 9.2.\n\\[\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{9.2}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.10. Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzufÃ¼hren.\n\n9.12.7 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar fÃ¼r einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkÃ¤rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich u.Â a. 2020) zurÃ¼ck (s. Anhang fÃ¼r Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem â€œstatistischen Effektâ€ gesprochen, um klar zu machen, dass es sich lediglich um assoziative ZusammenhÃ¤nge, und nicht um kausale ZusammenhÃ¤nge, handelt. Kausale ZusammenhÃ¤nge dÃ¼rfen wir nur verkÃ¼nden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafÃ¼r finden oder c) wir ein Experiment fachgerecht durchgefÃ¼hrt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.13 Vertiefung",
    "text": "9.13 Vertiefung\nğŸï¸VERTIEFUNG, nicht prÃ¼fungsrelevantğŸï¸\n\n9.13.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\\[b = r \\frac{sd_x}{sd_y}\\]\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die PunktschÃ¤tzer fÃ¼r die Regressionskoeffizienten:\n\nm10.11 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.11)\n##  (Intercept)     mom_iq_z \n## 0.0002786206 0.4483327620\n\nVergleichen Sie diese Werte mit der Korrelation, s. TabelleÂ 9.15.17\n\nkidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelleÂ 9.15: Correlation Matrix (pearson-method)\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n9.13.2 PrÃ¼fen der LinearitÃ¤tsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen PrÃ¤diktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression hÃ¤ufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schÃ¤tzen (Gelman, Hill, und Vehtari 2021).\nIst die LinearitÃ¤tsannahme erfÃ¼llt, so sollte der Residualplot nur zufÃ¤llige Streuung um \\(y=0\\) herum zeigen, s. AbbildungÂ 9.25.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsÃ¤chlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\nkidiq %&gt;% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildungÂ 9.25: Die Verteilung der Fehler scheint keinem starken Trend (in AbhÃ¤ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine grÃ¶ÃŸeren AuffÃ¤lligkeiten.\n\n9.13.3 ModellprÃ¼fung mit der PPV\n\npp_check(m10.10)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht hÃ¤ufig.\n\n9.13.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildungÂ 9.26: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildungÂ 9.26 zeigt in der oberen Reihe die Regression eines PrÃ¤diktors auf den anderen PrÃ¤diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n9.13.5 Bayesianisch gleich Frequentistisch?\nÃœbrigens liefern stan_glm() und lm oft Ã¤hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch Ã¤hnlich sein kÃ¶nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.14 Fazit",
    "text": "9.14 Fazit\n\n9.14.1 Austieg: Bayes in fÃ¼nf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\nğŸ“º MusterlÃ¶sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\nğŸ“º MusterlÃ¶sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n9.14.2 Ausblick: BinÃ¤re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\ndata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m13: am ~ mpg_z:\n\nm13 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nmtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nneg_am &lt;- predict(m13, newdata = tibble(mpg_z = -1.3))\n\nFÃ¼r kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte fÃ¼r am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. MÃ¼ssen wir mal bei Gelegenheit besser machen.\n\n9.14.3 WeiterfÃ¼hrende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman, Hill, und Vehtari (2021), Kap. 10, insbesondere 10.3.\n\n9.14.4 Genug fÃ¼r heute\nWir waren fleiÃŸig â€¦\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.\n\n\nGenug fÃ¼r heute. ğŸ‘\n\n9.14.5 Vertiefung\nGelman, Hill, und Vehtari (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit fÃ¼hrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig Ã¼berschaubarem mathematischen Aufwand.\nFÃ¼r das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.15 Aufgaben",
    "text": "9.15 Aufgaben\n\nAnova-skalenniveau\nNullhyp-Beispiel\nttest-skalenniveau\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nstan_glm_parameterzahl\nstan_glm_prioriwerte\nzwert-berechnen\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope-regr\nrope1\nrope2\nrope3\nrope4",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n9Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n9.16 â€”",
    "text": "9.16 â€”\n\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. â€R-Squared for Bayesian Regression Modelsâ€œ. The American Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, und Sam Brilleman. 2020. â€Rstanarm: Bayesian Applied Regression Modeling via Stan.â€œ https://mc-stan.org/rstanarm.\n\n\nKruschke, John K. 2018. â€Rejecting or Accepting Parameter Values in Bayesian Estimationâ€œ. Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Forschungsfragen mit metrischer AV</span>"
    ]
  }
]