[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 EinfÃ¼hrung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage fÃ¼r Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und MÃ¤nner vor eine Einpark-Aufgabe gestellt (natÃ¼rlich alles schÃ¶n standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen kÃ¶nnen schneller einparken als MÃ¤nner, im Durchschnitt. Das hÃ¤tten wir also geklÃ¤rt. Aber haben wir das ganz sicher geklÃ¤rt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich weiÃŸ, das ist jetzt ein harter Schlag fÃ¼r Sieâ€¦ Aber die gute Nachricht ist: Wir kÃ¶nnen angeben, wie (un)sicher wir bei mit einer Aussage (â€œFrauen parken schnellerâ€¦â€) sind. Zum Beispiel kÃ¶nnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie nÃ¤chste Woche ei Fahri fÃ¼r Ihren neuen Rolls Royce anheuern, mÃ¼ssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, mÃ¼ssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen â€œlaut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauenâ€. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es Ã¼blich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den â€œTop 20 job roles in increasing and decreasing demand across industriesâ€ (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 ModulÃ¼berblick\nAbbildungÂ 1.1 gibt einen Ãœberblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n  subgraph KausalitÃ¤t\n    Kausalstart\n  end \n  Wskt --&gt; Bayes --&gt; Regression --&gt; KausalitÃ¤t\n\n\n\n\nAbbildungÂ 1.1: Modulverlauf im Ãœberblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelleÂ 1.1 gibt einen Ãœberblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist nÃ¼tzlich fÃ¼r Sie, die Tabelle TabelleÂ 1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als nÃ¤chstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelleÂ 1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nInferenz\n2.-8. Okt.\nNA\n\n\n2\nWahrscheinlichkeit\n9.-15. Okt.\nNA\n\n\n3\nVerteilungen\n16.-22. Okt.\nNA\n\n\n4\nGlobusversuch\n23.-29. Okt.\nNA\n\n\n5\nAufhol-Woche\n30.-5. Nov.\nNA\n\n\n6\nDie Post befragen\n5.-12. Nov.\nNA\n\n\n7\nGauss-Modelle\n13.-19. Nov.\nNA\n\n\nNA\nNA\n20.-26. Nov.\nBlockwoche: Kein regulÃ¤rer Unterricht\n\n\n8\nLineare Modelle\n27.-3. Dez.\nNA\n\n\n9\nMetrische AV\n4.-10. Dez.\nNA\n\n\n10\nKonfundierung\n11.-17. Dez\nNA\n\n\n11\nKausalatome\n18.-24. Dez.\nNA\n\n\nNA\nNA\nNA\nJahreswechsel: Kein Unterricht\n\n\n12\nAbschluss\n8.-14. Jan. 24\nNA\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nFÃ¼r dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z.B. im Online-Buch â€œStatistik1â€ vermittelt. Alle Inhalte daraus werden in diesem Kurs benÃ¶tigt.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.2 Hinweise",
    "text": "1.2 Hinweise\n\nğŸ“º Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#tutorium",
    "href": "index.html#tutorium",
    "title": "Start:Bayes!",
    "section": "\n1.3 Tutorium",
    "text": "1.3 Tutorium\nFÃ¼r dieses Modul wird ggf. ein Tutorium angeboten.\nDer Besuch des Tutoriums ist zu empfehlen. Arbeiten Sie auch das Materials auf der Webseite des Tutoriums durch.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#prÃ¼fung",
    "href": "index.html#prÃ¼fung",
    "title": "Start:Bayes!",
    "section": "\n1.4 PrÃ¼fung",
    "text": "1.4 PrÃ¼fung\nDas PrÃ¼fungsformat ist: Open-Book-PrÃ¼fung.\n\nAllgemeine PrÃ¼fungshinweise\nPrÃ¼fungsformat: Open-Book-PrÃ¼fung\nHinweise zu quantitativen PrÃ¼fungen\nPrÃ¼fungsvorbereitung\n\nIn KapitelÂ 13 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#faq",
    "href": "index.html#faq",
    "title": "Start:Bayes!",
    "section": "\n1.5 FAQ",
    "text": "1.5 FAQ\n\nFRAGE: Wo finde ich eine Probeklausur? â€“ ANTWORT: Dieser Tag stellt Fragen einer ProbeprÃ¼fung zusammen.\nFRAGE: Wie bereite ich mich gut auf die PrÃ¼fung vor? â€“ ANTWORT: Hier finden Sie Tipps zur PrÃ¼fungsvorbereitung.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.6 Zitation",
    "text": "1.6 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\n@book{sauer_statistik1_2022,\n    title = {Statistik1},\n    rights = {All rights reserved},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2023},\n}",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Start:Bayes!",
    "section": "\n1.7 Zum Autor",
    "text": "1.7 Zum Autor\nNÃ¤here Hinweise zum Autor, Sebastian Sauer, finden Sie hier.\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Start:Bayes!",
    "section": "\n1.8 Technische Details",
    "text": "1.8 Technische Details\nDieses Dokument wurde erzeugt am/um 2023-12-20 10:26:57.\n\n## â”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Europe/Berlin\n##  date     2023-11-29\n##  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n## \n## â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  ! package     * version date (UTC) lib source\n##  P cli           3.6.1   2023-03-23 [?] CRAN (R 4.2.0)\n##  P codetools     0.2-18  2020-11-04 [?] CRAN (R 4.2.1)\n##  P digest        0.6.33  2023-07-07 [?] CRAN (R 4.2.0)\n##  P dplyr         1.1.3   2023-09-03 [?] CRAN (R 4.2.0)\n##  P evaluate      0.21    2023-05-05 [?] CRAN (R 4.2.0)\n##  P fansi         1.0.5   2023-10-08 [?] CRAN (R 4.2.0)\n##  P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.2.0)\n##  P generics      0.1.3   2022-07-05 [?] CRAN (R 4.2.0)\n##  P glue          1.6.2   2022-02-24 [?] CRAN (R 4.2.0)\n##  P gt            0.10.0  2023-10-07 [?] CRAN (R 4.2.0)\n##  P htmltools     0.5.6.1 2023-10-06 [?] CRAN (R 4.2.0)\n##  P htmlwidgets   1.6.2   2023-03-17 [?] CRAN (R 4.2.0)\n##  P jsonlite      1.8.7   2023-06-29 [?] CRAN (R 4.2.0)\n##  P knitr         1.45    2023-10-30 [?] CRAN (R 4.2.1)\n##  P lifecycle     1.0.3   2022-10-07 [?] CRAN (R 4.2.0)\n##  P magrittr      2.0.3   2022-03-30 [?] CRAN (R 4.2.0)\n##  P pillar        1.9.0   2023-03-22 [?] CRAN (R 4.2.0)\n##  P pkgconfig     2.0.3   2019-09-22 [?] CRAN (R 4.2.0)\n##  P R6            2.5.1   2021-08-19 [?] CRAN (R 4.2.0)\n##    renv          1.0.2   2023-08-15 [1] CRAN (R 4.2.0)\n##  P rlang         1.1.1   2023-04-28 [?] CRAN (R 4.2.0)\n##  P rmarkdown     2.25    2023-09-18 [?] CRAN (R 4.2.0)\n##  P rstudioapi    0.15.0  2023-07-07 [?] CRAN (R 4.2.0)\n##  P sass          0.4.7   2023-07-15 [?] CRAN (R 4.2.0)\n##  P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.2.0)\n##  P tibble        3.2.1   2023-03-20 [?] CRAN (R 4.2.0)\n##  P tidyselect    1.2.0   2022-10-10 [?] CRAN (R 4.2.0)\n##  P utf8          1.2.3   2023-01-31 [?] CRAN (R 4.2.0)\n##  P vctrs         0.6.4   2023-10-12 [?] CRAN (R 4.2.0)\n##  P withr         2.5.2   2023-10-30 [?] CRAN (R 4.2.1)\n##  P xfun          0.40    2023-08-09 [?] CRAN (R 4.2.0)\n##  P xml2          1.3.4   2023-04-27 [?] CRAN (R 4.2.0)\n##  P yaml          2.3.7   2023-01-23 [?] CRAN (R 4.2.0)\n## \n##  [1] /Users/sebastiansaueruser/github-repos/start-bayes/renv/library/R-4.2/x86_64-apple-darwin17.0\n##  [2] /Users/sebastiansaueruser/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.2/x86_64-apple-darwin17.0/fb4b0a46\n## \n##  P â”€â”€ Loaded and on-disk path mismatch.\n## \n## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nForum, World Economic. 2020. â€The Future of Jobs Report 2020â€œ. CH-1223 Cologny/Geneva Switzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>EinfÃ¼hrung</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#lernsteuerung",
    "href": "0200-Inferenz.html#lernsteuerung",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n2.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Definition von Inferenzstatistik sowie Beispiele fÃ¼r inferenzstatistische Fragestellungen nennen\nzentrale Begriffe der Inferenzstatistik nennen und in GrundzÃ¼gen erklÃ¤ren\nden Nutzen von Inferenzstatistik nennen\nerlÃ¤utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nanhand von Beispielen erklÃ¤ren, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs.Â Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklÃ¤ren\n\n2.1.3 Begleitliteratur\nBei Gelman, Hill, und Vehtari (2021), Kap. 1 findet sich eine Darstellung Ã¤hnlich zu der in diesem Kapitel.\n\n2.1.4 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. â€œRahmenâ€\n\nStatistik 1, dort alle Inhalte zum Thema â€œModellierenâ€ und â€œRegressionâ€\n\n2.1.5 Begleitvideos\n\nVideo zur Inferenz, Teil 1\nVideo zur Inferenz, Teil 2\n\n2.1.6 Wozu ist Statistik Ã¼berhaupt da?\nğŸ“º Ja, wozu ist Statistik eigentlich da?\nJa, diese Frage haben Sie sich auch schon mal gestellt? Abb. AbbildungÂ 2.1 gibt einen Ãœberblick Ã¼ber die Ziele der Statistik.1 Nach dieser Einteilung lassen sich drei Arten von Zielen unterscheiden: Beschreiben, Vorhersagen und ErklÃ¤ren.\n\nBeispiel 2.1 (Beispiele fÃ¼r die Zielarten statistischer Analysen) Â \n\nBeschreiben: â€œWie groÃŸ ist der Gender-Paygap in der Branche X im Zeitraum Y?â€\nVorhersagen: Wenn eine Person, Mr.Â X, 100 Stunden auf die Statistikklausur lernen, welche Note kann diese Person dann erwarten?\nErklÃ¤ren: Wie viel bringt (mir) das Lernen auf die Statistikklausur?\\(\\square\\)\n\n\n\nFÃ¼r die Wissenschaft ist ErklÃ¤ren das wichtigste Ziel. Bei wenig beackerten Wissenschaftsfeldern ist das Beschreiben ein sinnvoller erster Schritt, der allerdings nicht Stolperfallen ist, wie in KapitelÂ 11 erlÃ¤utert. Vorhersagen ist mehr fÃ¼r die Praxis als fÃ¼r die Wissenschaft relevant.2\n\n\n\n\n\nflowchart TD \n  A{Goals} --&gt; B(describe)\n  A --&gt; C(predict)\n  A --&gt; D(explain)\n  B --&gt; E(distribution)\n  B --&gt; F(assocation)\n  B --&gt; G(extrapolation)\n  C --&gt; H(point estimate)\n  C --&gt; I(interval)\n  D --&gt; J(causal inference)\n  D --&gt; K(population)\n  D --&gt; L(latent construct)\n\n\n\n\n\nAbbildungÂ 2.1: Eine Einteilung der Ziele von statistischen Analysen",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#was-ist-inferenz",
    "href": "0200-Inferenz.html#was-ist-inferenz",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.2 Was ist Inferenz?",
    "text": "2.2 Was ist Inferenz?\n\n\n\n\n\nğŸ“º Was ist Inferenz?\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlieÃŸen, bzw. vom Konkreten auf das Abstrakte.3\nTypischerweise untersuchen im Rahmen einer statistischen Analyse eine Stichprobe, wie z.B. Ihr Freundeskreis, der leichtsinnig genug war, auf Ihre WhatsApp-Nachricht â€œTolle Studie zu dem Geheimnis des GlÃ¼cks!!!â€ zu klicken. Ihr Freundeskreis ist ein Teil der Menschen (z.B. aus Deutschland), also eine Stichprobe. Schauen wir uns den Unterschied zwischen Stichprobe und Population nÃ¤her an.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#stichprobe-vs.-population",
    "href": "0200-Inferenz.html#stichprobe-vs.-population",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.3 Stichprobe vs.Â Population",
    "text": "2.3 Stichprobe vs.Â Population\nNehmen wir an, wir mÃ¶chten herausfinden, wie groÃŸ der Anteil der R-Fans in der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A4.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit (synonym: Population) vorliegen haben.\nWir mÃ¼ssen also den Anteil der R-Fans in der Population auf Basis des Anteils in der Stichprobe schlieÃŸen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. AbbildungÂ 2.2 (a) und AbbildungÂ 2.2 (b).\n\n\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\n\n\nAbbildungÂ 2.2: Population vs.Â Sample. Autor: Karsten LÃ¼bke. OEM\n\n\n\n\n\nHÃ¤ufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!5. Man schreibt gerne: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei reprÃ¤sentativ fÃ¼r die Grundgesamtheit aller Studierender. Messerscharf schlieÃŸen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n\n\n\n\n\nHinweis\n\n\n\nWir verwenden lateinische Buchstaben (p), um Kennzahlen einer Stichprobe zu benennen, und griechische (\\(\\pi\\)) fÃ¼r Populationen.\\(\\square\\)\n\n\n\n2.3.1 Deskriptiv- vs.Â Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtungen, kÃ¶nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. AbbildungÂ 2.3.\nVereinfacht gesprochen fasst die Deskriptivstatistik Daten (einer Stichprobe) zu einer einzelnen Kennzahl zusammen.\n\nBeispiel 2.2 In einem HÃ¶rsaal sitzen 100 Studis. Alle schreiben Ihre KÃ¶rpergrÃ¶ÃŸe auf einen Zettel. Die Dozentin sammelt die Zettel ein und rechnet dann den Mittelwert der KÃ¶rpergrÃ¶ÃŸe der anwesenden Studentis aus. VoilÃ : Deskriptive Statistik!\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 2.3: Deskriptiv- vs.Â Inferenzstatistik\n\n\n\nÃœbungsaufgabe 2.1 ğŸ‹ SchlieÃŸen Sie die Augen und zeichnen Sie obiges Diagramm, AbbildungÂ 2.3!\\(\\square\\)\n\n\nDefinition 2.1 (Deskriptivstatistik) Deskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\n\n\n2.3.2 Inferenzstatistik\nInferenzstatistik schlieÃŸt von Statistiken auf Parameter (ein Parameter meint hier eine Kennzahl von einer Grundgesamtheit, z.B. die Streuung).\nInferenz bedeutet SchlieÃŸen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine SchlÃ¼sse zu ziehen.\n\nÃœbungsaufgabe 2.2 ğŸ‹ï¸ï¸ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Ãœben Sie jetzt schon mal.\\(\\square\\)\n\n\n2.3.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFÃ¼r jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, um den zugehÃ¶rigen Kennwert (Parameter) der Population zu bestimmen, s. Tabelle TabelleÂ 2.1. Da man die Parameter der Population so gut wie nie sicher kennt (schlieÃŸlich hat man meist nur AuszÃ¼ge, Teile der Population, also Stichproben), muss man sich mit SchÃ¤tzwerten begnÃ¼gen. SchÃ¤tzwerte macht man kenntlich mit einem â€œDach-Zeichenâ€ Ã¼ber dem Parameter, also z.b. \\(\\hat{\\mu}\\), lies: â€œmÃ¼-Dachâ€.\n\n\n\nTabelleÂ 2.1: Bezeichnungen fÃ¼r Kennwerte\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchÃ¤tzwert\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\n\\(\\mu\\) (mÃ¼)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\n\\(\\sigma\\) (sigma)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\n\\(\\pi\\) (pi)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\n\\(\\rho\\) (rho)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\n\\(\\beta\\) (beta)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n\nFÃ¼r Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; fÃ¼r Parameter (Population) verwendet man griechische Buchstaben.\n\nÃœbungsaufgabe 2.3 ğŸ‹ï¸ Geben Sie die griechischen Buchstaben fÃ¼r typische Statistiken an. Ohne auf die Tabelle zu schauen.ğŸ˜œ\\(\\square\\)!\n\n\n2.3.4 SchÃ¤tzen von Parametern einer Grundgesamtheit\nMeist begnÃ¼gt man sich beim Analysieren von Daten nicht mit Aussagen fÃ¼r eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit SchÃ¤tzungen begnÃ¼gen.\nSchÃ¤tzwerte werden mit einem â€œDachâ€ Ã¼ber dem Kennwert gekennzeichnet, s. letzte Spalte in TabelleÂ 2.1.\nIn der angewandten Forschung interessieren hÃ¤ufig Fragen wie: â€œWelche Entscheidung ist (wahrscheinlich) besser?â€. Da bekanntlich (fast) keine Aussagen sicher sind, spielt Wahrscheinlichkeit eine wichtige Rolle in den Forschungsfragen bzw. in deren Antworten.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinlichkeit wird oft mit Pr oder p abgekÃ¼rzt, fÃ¼r engl. probability.\\(\\square\\)\n\n\n\nBeispiel 2.3 Sie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs.Â V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\). Die Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} &gt; \\bar{X}_{V2}\\). Sind diese Unterschiede â€œzufÃ¤lligâ€ oder â€œsubstanziellâ€? Gilt also \\(\\mu_{V1} &gt; \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)? Wie groÃŸ ist die Wahrscheinlichkeit\\(Pr(\\mu_{V1} &gt; \\mu_{V2})\\)?\n\n\nÃœbungsaufgabe 2.4 ğŸ‹ï¸ VERTIEFUNG Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!\\(\\square\\)",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#modellieren",
    "href": "0200-Inferenz.html#modellieren",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.4 Modellieren",
    "text": "2.4 Modellieren\n\n2.4.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft - wie auch oft in der Technik, Wirtschaft oder im Alltag - betrachtet man einen Teil der Welt nÃ¤her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berÃ¼cksichtigen ist nicht mÃ¶glich. Wir mÃ¼ssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nÃ¶tig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die fÃ¼r unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\nDefinition 2.2 (Modell) Ein Modell ist ein vereinfachtes Abbild der Wirklichkeit.\\(\\square\\)\n\nDer Nutzen eines Modells ist, einen (Ã¼bermÃ¤ÃŸig) komplexen Sachverhalt zu vereinfachen oder Ã¼berhaupt erst handhabbar zu machen. Man versucht zu vereinfachen, ohne Wesentliches wegzulassen. Der Speck muss weg, sozusagen. Das Wesentliche bleibt.\nAuf die Statistik bezogen heiÃŸt das, dass man einen Datensatz dabei so zusammenfasst, damit man das Wesentliche erkennt. Was ist das â€œWesentlicheâ€? Oft interessiert man sich fÃ¼r die Ursachen eines PhÃ¤nomens. Etwa: â€œWie kommt es bloÃŸ, dass ich ohne zu lernen die Klausur so gut bestanden habe?â€6 Noch allgemeiner ist man dabei hÃ¤ufig am Zusammenhang von X und Y interessiert, s. AbbildungÂ 2.4, die ein Sinnbild von statistischen Modellen widergibt.\n\n\n\n\n\n\nflowchart LR\nX --&gt; Y\n\n\nX1 --&gt; Y2\nX2 --&gt; Y2\n\n\n\n\n\n\n\nAbbildungÂ 2.4: oben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\nMan kann AbbildungÂ 2.4 als ein Sinnbild einer (mathematischen) Funktion lesen.\n\nDefinition 2.3 Eine Funktion \\(f\\) setzt zwei GrÃ¶ÃŸen in Beziehung.\\(\\square\\)\n\nIn Mathe-Sprech:\n\\(f: X \\rightarrow Y\\)\noder:\n\\(y = f(x)\\), lies: â€œY ist eine Funktion von Xâ€.\nEs hÃ¶rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n2.4.2 Vertiefung\nLesen Sie die EinfÃ¼hrung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nHinweis\n\n\n\nNutzen Sie die Ãœbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#regression",
    "href": "0200-Inferenz.html#regression",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.5 Regression",
    "text": "2.5 Regression\nEinflussreiche Leute schwÃ¶ren auf die Regressionsanalyse (AbbildungÂ 2.5).\n\n\n\n\n\nAbbildungÂ 2.5: One regression\n\n\nNutzen Sie die folgende App, um die Regressionskoeffizienten, Steigung (slope) und Achsenabschnitt (Intercept), zu optimieren. Dabei meint â€œoptimierenâ€, die Abweichungen (Residuen, Residualfehler; die roten Balken in der App) zu minimieren.\n\nHier finden Sie eine Ã¤hnliche App, die Ihnen gestattet, selber Hand an eine Regressionsgerade zu legen.\n\nÃœbungsaufgabe 2.5 (VERTIEFUNG Regression mit Animationen erklÃ¤rt) Lesen Sie diesen Post, der Ihnen mit Hilfe von Bildern und Animationen (okay, und etwas) Text die Grundlagen der Regressionsanalyse erklÃ¤rt.\\(\\square\\)\n\n\n2.5.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmesser der Statistik: FÃ¼r vieles gut einsetzbar. Anstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schÃ¶ner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden. Dann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nHinweis\n\n\n\nRegression + Inferenz = ğŸ’–\n\n\nAlternativ zur Regression kÃ¶nnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni MÃ¼nster als Ausschnitt (!) aufgefÃ¼hrt. Auf dieser Basis kann man meditieren, welches statistischen Verfahren man fÃ¼r eine bestimmte Fragestellung verwenden sollte, s. Abb. AbbildungÂ 2.6. Muss man aber nicht.\n\n\n\n\n\nAbbildungÂ 2.6: WÃ¤hle deine Statistik mit Bedacht. Oder wÃ¤hle die Regressionsanalyse.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEs ist meist einfacher und nÃ¼tzlicher, die Regression zu verwenden, anstelle der Vielzahl von anderen Verfahren (die zumeist SpezialfÃ¤lle der Regression sind). In diesem Kurs werden wir fÃ¼r alle Fragestellungen die Regression verwenden.7\\(\\square\\)\n\n\n\n\n2.5.2 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; s. AbbildungÂ 2.7. Links sieht man eine einfache Regression mit hp als PrÃ¤diktor (X, unabhÃ¤ngige Variable) und mpg als abhÃ¤ngige Variable (Y). Das rechte Teildiagramm zeigt eine multiple Regression mit den PrÃ¤diktoren hp und am.8\nIm einfachsten Fall sind die vom Modell vorhergesagten (geschÃ¤tzten) Werte, \\(\\hat{y}\\), durch eine einfache Gerade beschrieben, s. AbbildungÂ 2.7, links. Eine Gerade lÃ¤sst sich durch folgende Formel beschreiben: \\(\\hat{y} = \\beta_0 + \\beta_1\\). Dabei ist \\(\\beta_0\\) der Achsenabschnitt (eng. intercept) und \\(\\beta_1\\) die Steigung der Regressiongeraden.\n\nIn allgemeiner Form schreibt man die Regressionsgleichung so, s. GleichungÂ 2.1\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon \\tag{2.1}\\]\nMan nennt alle \\(\\beta_0, \\beta_1, \\beta_2, ...\\) die Koeffizienten, Regressionsgewichte oder Parameter des Modells (Gelman, Hill, und Vehtari 2021).\n\nAnhand von GleichungÂ 2.1 erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden (\\(X_1, X_2, ...\\)) berechnet.\n\n\n\n\n\n\n\n\n\n(a) Einfache Regression (ein PrÃ¤diktor: hp)\n\n\n\n\n\n\n\n\n\n(b) Multiple Regression (zwei PrÃ¤diktoren: hp und am)\n\n\n\n\n\n\nAbbildungÂ 2.7: Die Regressionsgerade in voller Pracht",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#unsicherheit",
    "href": "0200-Inferenz.html#unsicherheit",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.6 Unsicherheit",
    "text": "2.6 Unsicherheit\n\n2.6.1 Inferenz beinhaltet Ungewissheit\nInferenzstatistische SchlÃ¼sse sind mit Unsicherheit behaftet: SchlieÃŸlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), mÃ¶chte aber vom Teil auf das Ganze schlieÃŸen.\n\n\n\n\n\n\nWichtig\n\n\n\nNichts Genaues weiÃŸ man nicht: SchlieÃŸt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen Ã¼ber die Genauigkeit des SchlieÃŸens betrifft.\n\n\nSchlieÃŸt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit; es ist ungewiss. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. SchlieÃŸlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen fÃ¼r die Stichprobe (Messfehler einmal ausgeblendet). Zur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer mÃ¶glich). Die Wahrscheinlichkeitstheorie bzw. -rechnung wird daher auch als die Mathematik des Zufalls bezeichnet.\n\nDefinition 2.4 (ZufÃ¤lliges Ereignis) Unter einem zufÃ¤lligen (engl. random) Ereignis verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nÃ¤chsten WÃ¼rfelwurfs. ZufÃ¤llig bedeutet nicht (zwangslÃ¤ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines WÃ¼rfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\nÃœbungsaufgabe 2.6 ğŸ‹ Welche physikalischen Randbedingungen wirken wohl auf einen MÃ¼nzwurf ein?\\(\\square\\)\n\n\nBeispiel 2.4 (Beispiele zur Quantifizierung von Ungewissheit) Aussagen mit Unsicherheit kÃ¶nnen unterschiedlich prÃ¤zise formuliert sein.\n\nMorgen regnetâ€™s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert von \\(Y\\) fÃ¼r Methode \\(A\\) hÃ¶her als fÃ¼r Methode \\(B\\).\nDie Maschine fÃ¤llt demnÃ¤chst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nÃ¤chsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n\n\nÃœbungsaufgabe 2.7 ğŸ‹ Geben Sie weitere Beispiele an!\n\n\n2.6.2 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. AbbildungÂ 2.8.\n\nWie (un)gewiss ist man sich Ã¼ber die Regressionsgewichte?\nWie (un)gewiss ist man sich Ã¼ber die Genauigkeit der Vorhersage (des Modells)?\n\n\n\n\n\n\nflowchart LR\nX1 --&gt;|Werte von Steigung und Achsenabschnitt?|B\nX2 -. Genauigkeit des Modells .-&gt; B\n\n\n\n\n\nAbbildungÂ 2.8: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n2.6.2.1 Ungewissheit der Modellkoeffizienten\nWie man in AbbildungÂ 2.9 sieht, kÃ¶nnen sich die Koeffizienten (Achsenabschnitt und Steigung) unterscheiden. Woran liegt das?\n\nBeispiel 2.5 (Stichproben der New Yorker FlÃ¼ge) Nehmen wir an, wir ziehen ein paar Zufallstichproben aus der Menge (Population) aller FlÃ¼ge, die in New York im Jahre 2013 gestartet sind. In jeder Stichprobe berechnen wir eine Regression zwischen Flugzeit und VerspÃ¤tung des Flugs am Ankunftsort. Sicherlich werden sich die Stichproben in ihren Kennwerten, z.B. in den Koeffizienten der genannten Regression, unterscheiden.\\(\\square\\)\n\n\nlibrary(nycflights13)\ndata(flights)\n\nstipro1 &lt;- sample_n(flights, size = 100)\nstipro2 &lt;- sample_n(flights, size = 100)\nstipro3 &lt;- sample_n(flights, size = 100)\n\n\n\n\n\n\n\n\n\n\n(a) Stichprobe 1\n\n\n\n\n\n\n\n\n\n(b) Stichprobe 2\n\n\n\n\n\n\n\n\n\n(c) Stichprobe 3\n\n\n\n\n\n\nAbbildungÂ 2.9: Regressionsanalysen mit verschiedenen Koeffizienten aufgrund der ZufÃ¤lligkeit des Stichprobenziehens\n\n\nDer Grund fÃ¼r die Schwankungen der Modellparameter zwischen den Stichproben ist die ZufÃ¤lligkeit des Stichprobenziehens. Je nachdem, wie es der Zufall (oder sonst wer) will, landen bestimmte FÃ¤lle (FlÃ¼ge in unserem Beispiel) in unserer Stichprobe. Zumeist unterscheiden sich die Stichproben; theoretisch kÃ¶nnten sie aber auch rein zufÃ¤llig gleich sein.\n\n\n\n\n\n\nWichtig\n\n\n\nStichproben-Kennwerte schwanken um den tatsÃ¤chlichen Wert in der Population herum.\\(\\square\\)\n\n\nUm diese Ungewissheit, die sich in den Schwankungen der Stichproben-Regressionskoeffizienten ausdrÃ¼ckt, anzuzeigen, ist ein â€œgrauer Schleierâ€ um die Regressionsgeraden in AbbildungÂ 2.9 gekennzeichnet. Dieser grauer Schleier gibt also eine Spannbreite anderer, plausibler Ergebnisse an, die sich in einer anderen Stichprobe auch manifestieren kÃ¶nnten.\n\n2.6.2.2 Ungewissheit der ModellgÃ¼te\nAngenommen, wir sind uns sicher Ã¼ber die Werte der Modellparameter, also Ã¼ber die Lage der Regressionsgeraden, anschaulich gesprochen. Dann bliebe immer noch Ungewissheit zur ModellgÃ¼te. Ein bestimmtes Modell kann genau oder ungenaue Vorhersagen abgeben; das ist die zweite Art der Ungewissheit.\nDiese Art der Ungewissheit ist nicht von Interesse, wenn man nur an Modellkoeffizienten interessiert ist. Sie ist dann interessant, wenn man fÃ¼r einzelne FÃ¤lle eine Vorherage macht und sich fragt, wie zuverlÃ¤ssig diese Vorhersage ist.\n\n\n\n\n\n\n\n\n\n(a) geringer Vorhersagefehler (hohe VorhersagegÃ¼te)\n\n\n\n\n\n\n\n\n\n(b) hoher Vorhersagefehler\n\n\n\n\n\n\n\n\n\n(c) auch hoher Vorhsagefehler\n\n\n\n\n\n\nAbbildungÂ 2.10: Regressionsanalyse mit gleicher Regressionsgerade, aber unterschiedlicher VorhersagegÃ¼te\n\n\n\n2.6.3 Ich weiÃŸ, was ich nicht weiÃŸ: Ungewissheit angeben\nStreng genommen ist eine Inferenz ohne Angabe der Ungewissheit (Genauigkeit der SchÃ¤tzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schÃ¤tzt, lÃ¤sst aber offen wie sicher (prÃ¤zise) die SchÃ¤tzung (der Modellparameter) ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die SchÃ¤tzung schlieÃŸt sogar 41% oder 43% aus.\n\n\n\n\n\n\nWichtig\n\n\n\nSchlieÃŸt man auf eine Population, schÃ¤tzt also die Modellparameter, so sollte stets die (Un-)Genauigkeit der SchÃ¤tzung, also die Ungewissheit des Modells, angegeben sein.\\(\\square\\)\n\n\nIm Rahmen der Regressionsanalyse schlÃ¤gt sich die Ungewissheit an zwei Stellen nieder:\n\nzur Lage der Regressionsgeraden, \\(\\beta_0\\), \\(\\beta_1\\)\n\nzur ModellgÃ¼te bzw. zum Vorhersagefehler, \\(\\sigma\\) 9\n\n\n2.6.4 Visualisierung von Ungewissheit\n\nDefinition 2.5 (PunktschÃ¤tzer) Gibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem PunktschÃ¤tzer.\nPunktschÃ¤tzer beinhalten keine Angabe der SchÃ¤tz(un)genauigkeit, s. Abb. AbbildungÂ 2.11, links. Rot markiert: Die PunktschÃ¤tzung von mpg fÃ¼r hp=200.\n\n\nIn Abb. AbbildungÂ 2.11, links, ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns bzgl. der Lage der Regressionskoeffizienten? Vgl. DefinitionÂ 2.5.\nAuch wenn wir uns sicher wÃ¤ren im Hinblick auf die Regressionsgewichte in Abb. AbbildungÂ 2.11, links, bliebe Ungewissheit bei der Vorhersage des Bereichs plausibler Werte fÃ¼r individuelle Vorhersagen, s. AbbildungÂ 2.11, rechts. Unsere SchÃ¤tzungen wÃ¤ren auch dann nicht sicher, nicht fehlerfrei, wenn wir den genauen Verlauf der Regressiongerade sicher wÃ¼ssten. Das liegt daran, da das Modell nicht alle EinflÃ¼sse auf Y berÃ¼cksichtigt, sondern nur einen einzigen, hier als X bezeichnet. Das Modell hat also keine perfekte Information, es ist ungewiss Ã¼ber alle mÃ¶glichen Einflussfaktoren auf Y. WÃ¼sste unser Modell alle Einflussfaktoren genau, so wÃ¤re unser Vorhersageintervall sehr schmal (bzw. hÃ¤tte null Breite).\nIn Abb. AbbildungÂ 2.11, rechts, ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die Ungewissheit zur Vorhersage der Y-Werte individueller Beobachtungen dargestellt. In diesem Fall spricht man von einem â€œVorhersageintervallâ€, da man nicht nur von â€œtypischen FÃ¤llenâ€ auf der Regressiongeraden spricht, sondern fÃ¼r echte FÃ¤lle Vorhersagen (SchÃ¤tzungen) tÃ¤tigt, wo auch die Ungewissheit der ModellgÃ¼te relevant ist.\n\n\n\n\n\n\n\n\n\n\n(a) Eine PunktschÃ¤tzung der Regressionsgeraden und die zugehÃ¶rige Ungewissheit der Koeffizienten\n\n\n\n\n\n\n\n\n\n(b) Das Vorhersageintevall zur Regressionsgeraden zeigt die Ungewissheit fÃ¼r die jeweiligen Beobachtungen\n\n\n\n\n\n\nAbbildungÂ 2.11: Die zwei Arten der Ungewissheit visualisiert\n\n\nAbbildungÂ 2.11 zeigt auch, dass fÃ¼r eine Beobachtung mit hp=200 der PunktschÃ¤tzer der geschÃ¤tzte Wert von mpg bei ca 16.5 liegt. Das ist sozusagen unser Best Guess. Weiterhin ist (in grÃ¼n) das Vorhersageintervall fÃ¼r hp=200 angezeigt. FÃ¼r Beobachtungen mit hp=200 liegt der Bereich plausibler mpg-Werte in dem (grÃ¼n) markierten Bereich (ca. 8 bis 25).\n\nDefinition 2.6 (Vorhersageintervall) Ein Vorhersageintervall zeigt den Bereich plausibler Werte (laut unserer Analyse) fÃ¼r eine Beobachtung mit bestimmten PrÃ¤diktor-Werten.\\(\\square\\)\n\nWie man sieht, wird die Ungewissheit grÃ¶ÃŸer, wenn man beide Arten der Ungewissheit berÃ¼cksichtigt. Das Vorhersage-Intervall berÃ¼cksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\nÃœbungsaufgabe 2.8 ğŸ‹ Geben Sie ein vergleichbares Beispiel an!\n\n\n2.6.5 Konfidenzintervall\nWir sehen in AbbildungÂ 2.11, dass ein â€œUngewissheitskorridorâ€ angegeben wird fÃ¼r die Lage der Regressionsgerade (linkes Teildiagramm) bzw. fÃ¼r den Bereich plausibler Vorhersagen im konkreten Fall einer Beobachtung mit bestimmten X-Wert. Entsprechend wird nicht ein PunktschÃ¤tzer, sondern ein SchÃ¤tzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich.10\n\nDefinition 2.7 (Konfidenzintervall) Ein Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff fÃ¼r SchÃ¤tzbereiche. Die Grenzen eines Konfindenzintervall markieren einen Bereich plausibler Werte fÃ¼r einen Parameter.\n\nEs gibt verschiedene Arten, Konfidenzintervalle zu berechnen; wir sprechen in spÃ¤teren Kapiteln dazu ausfÃ¼hrlicher. Ein Konfidenzintervall wird hÃ¤ufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse - auf der dieser Kurs aufbaut - ist ein Konfidenzintervall einfach zu interpretieren. Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall fÃ¼r den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt. Dieser Befund lÃ¤sst sich so interpretieren: â€œLaut Modell liegt der gesuchte Anteil der R-Fans mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.â€\n\nBeispiel 2.6 Geben Sie Beispiele fÃ¼r Konfidenzintervalle an.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "0200-Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.7 Klassische vs.Â Bayes-Inferenz",
    "text": "2.7 Klassische vs.Â Bayes-Inferenz\n\n\n\n2.7.1 Klassische Inferenz: Frequentismus\n\nDie BerÃ¼cksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurÃ¼ckgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein, keine Vorannahmen.\nWahrscheinlichkeit wird Ã¼ber relative HÃ¤ufigkeiten definiert.\nEs ist nicht mÃ¶glich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie hÃ¤ufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr hÃ¤ufig wiederholt ist.\nEin GroÃŸteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.7.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) flieÃŸt explizit in die Analyse ein (zusammen mit den Daten).\n\nWenn das Vorwissen gut ist, wird die Vorhersage durch das Vorwissen genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen fÃ¼r Hypothesen mÃ¶glich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (fÃ¼r gÃ¤ngige Computer) komfortabel geworden.\n\n\n\n\n2.7.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.7.3.1 Frequentismus\nDie zentrale Statistik des Frequentismus heiÃŸt der p-Wert\nDer p-Wert ist so definiert, vgl. Wasserstein und Lazar (2016):\n\nWie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufÃ¤llig verschieden und auf Basis unseres Modells)?\n\nFindet man \\(p&lt;.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von â€œ(statistischer) Signifikanzâ€ und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann. Faktisch entscheidet man sich, die Forschungshypothese weiterhin als â€œvorlÃ¤ufig gÃ¼ltigâ€ oder zumindest als â€œnicht widerlegtâ€ zu betrachten.\n\nÃœbungsaufgabe 2.9 ğŸ‹ Recherchieren Sie eine Definition des p-Werts und lesen Sie sie einem Freund. Beobachten sie die Reaktionen auf ihre ErklÃ¤rung.\\(\\square\\)\n\nDer p-Wert wird oft falsch verstanden (Badenes-Ribera u.Â a. 2016). Aber er ist auch nicht leicht zu verstehen, meint Meister Yoda, s. AbbildungÂ 2.12. Hier sind einige FALSCHE Interpretationen zum p-Wert laut der Autoren:\n\nğŸ™…â€â™€ Der p-Wert wÃ¼rde die Wahrscheinlichkeit der Nullhypothese oder der Forschungshypothese angeben. ğŸ™Š\nğŸ™…â€â™€ Der p-Wert wÃ¼rde ein inhaltlich bedeutsames, praktisch signifikantes Ergebnis anzeigen.\n\n\n\n\n\n\nAbbildungÂ 2.12: Der p-Wert ist wenig intuitiv, meint Meister Yoda\n\n\nDie Definition der Konfidenzintervalls in Frquentistischer Lesart lautet:\n\nDer Konfidenzbereich, z.B. von 95%, reprÃ¤sentiert den Anteil der Konfidenzintervalle bei sehr vielen (oder undentlich vielen) Wiederholungen des Experiments, die den echten Parameterwert enthalten.\n\n\n2.7.3.2 Bayes-Statistik\nDie zentrale Statistik der Bayes-Statistik ist die Posteriori-Verteilung.\nDie Posteriori-Verteilung beantwortet uns die Frage: â€œWie wahrscheinlich ist die Forschungshypothese (oder Varianten von ihr), jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?â€\nIn diesem Post wird fÃ¼r Bayes geworben und (einseitig) Stellung pro Bayes bezogen.\n\n2.7.4 Frequentist und Bayesianer\nIm Cartoon 1132 von xkcd wird sich Ã¼ber das Nicht-BerÃ¼cksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. AbbildungÂ 2.13.\n\n\n\n\n\nAbbildungÂ 2.13: Frequentist wettet mit Bayesianer\n\n\nQuelle\n\nfrom Imgflip Meme Generator\n\n\n2.7.5 Beispiel zum Nutzen von Apriori-Wissen 1\nEin Betrunkener behauptet, er kÃ¶nne hellsehen. Er wirft eine MÃ¼nze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird. Die Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die MÃ¼nze fair ist, dass Ergebnis also â€œzufÃ¤lligâ€ ist, also \\(p &lt; .05\\) und damit ist das Ergebnis â€œstatistisch signifikantâ€.\nUnser Vorwissen lÃ¤sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der ZufÃ¤lligkeit des Ergebnisses wohl nicht verwerfen.\n\n2.7.6 Beispiel zum Nutzen von Apriori-Wissen 2\nEine Studie (Gelman, Hill, und Vehtari 2021) fand einen â€œgroÃŸen Effektâ€ auf das Einkommen von Babies, die eine Stunde pro Woche wÃ¤hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\). Nach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% hÃ¶her (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lÃ¤sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lÃ¤sst. Wir wÃ¼rden den Effekt lieber in einem konservativeren Intervall schÃ¤tzen (enger um Null).",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#fazit",
    "href": "0200-Inferenz.html#fazit",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.8 Fazit",
    "text": "2.8 Fazit\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#aufgaben",
    "href": "0200-Inferenz.html#aufgaben",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.9 Aufgaben",
    "text": "2.9 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2a\ninferenz-fuer-alle\nadjustieren1a\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\nWarum-Bayes",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0200-Inferenz.html#section",
    "href": "0200-Inferenz.html#section",
    "title": "\n2Â  Inferenz\n",
    "section": "\n2.10 â€”",
    "text": "2.10 â€”\n\n\n\n\n\nBadenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo Bonilla-Campos, und Claudio Longobardi. 2016. â€Misconceptions of the P-Value among Chilean and Italian Academic Psychologistsâ€œ. Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nWasserstein, Ronald L., und Nicole A. Lazar. 2016. â€The ASA Statement on P-Values: Context, Process, and Purposeâ€œ. The American Statistician 70 (2): 129â€“33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Inferenz</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#lernsteuerung",
    "href": "0300-Wskt.html#lernsteuerung",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.1 Lernsteuerung",
    "text": "3.1 Lernsteuerung\n\n3.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n3.1.2 Ãœberblick\nDieses Kapitel hat die Wahrscheinlichkeitstheorie (synonym: Wahrscheinlichkeitsrechnung) bzw. das Konzept der Wahrscheinlichkeit zum Thema.1 Es geht sozusagen um die Mathematik des Zufalls.\n\n3.1.3 Wozu brauche ich dieses Kapitel?\nIm wirklichen Leben sind Aussagen (Behauptungen) so gut wie nie sicher.\n\nâ€œWeil sie so schlau ist, ist sie erfolgreich.â€\nâ€œIn Elektroautos liegt die Zukunft.â€\nâ€œDas klappt sicher, meine Meinung.â€\nâ€œDer nÃ¤chste PrÃ¤sident wird XYZ.â€\n\nAussagen sind nur mehr oder weniger (graduell) sicher. Wir kÃ¶nnen die Regeln der Wahrscheinlichkeitslogik verwenden, um den Grad der Sicherheit (von ganz unsicher bis ganz sicher) zu prÃ¤zisieren. Daher sagt man auch, Wahrscheinlichkeit sei die Logik der Wissenschaft (Jaynes 2014).\n\n3.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erlÃ¤uternd definieren\ndie drei Arten der direkten Ermittlung von Wahrscheinlichkeit erlÃ¤utern\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n3.1.5 Begleitliteratur\nLesen Sie zur Begleitung dieses Kapitels Bourier (2018), Kap. 2-4.\n\n3.1.6 Eigenstudium\n\n\n\n\n\n\nWichtig\n\n\n\nDieses Kapitel ist selbstÃ¤ndig im Eigenstudium vorzubereiten vor dem Unterricht. Lesen Sie dazu die angegebene Literatur. Im Unterricht werden Fragen beantwortet und Aufgaben gemeinsam bearbeitet. Der Stoff wird aber nicht vorgestellt, sondern ist im Selbststudium vorab vorzubereiten.\\(\\square\\)\n\n\n\n3.1.7 PrÃ¼fungsrelevanter Stoff\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2018), Kap. 2-4. Weitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verfÃ¼gbar sein. PrÃ¼fen Sie, ob Ihr Dozent Ihnen weitere Hilfen im geschÃ¼tzten Bereich (Moodle) eingestellt hat.\\(\\square\\)\n\n\n\n3.1.8 Zentrale Begriffe\n\n3.1.8.1 Grundbegriffe\n\nZufallsvorgang (Zufallsexperiment)\nElementarereignis\nEreignisraum\nZufallsereignis (zufÃ¤lliges Ereignis)\nSicheres Ereignis\nUnmÃ¶gliches Ereignis\n\n3.1.8.2 Wahrscheinlichkeitsbegriffe\n\nKlassische Wahrscheinlichkeit (LaPlaceâ€™sche Wahrscheinlichkeit)\nStatistische (empirische) Wahrscheinlichkeitsermittlung\nSubjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n3.1.8.3 Wahrscheinlichkeitsrelationen\n\nVereinigung von Ereignissen\nSchnitt(menge) von Ereignissen\nKomplementÃ¤rereignis\nVollstÃ¤ndiges Ereignissystem\nAnforderungen an eine Definition von Wahrscheinlichkeit\n\n3.1.8.4 Wahrscheinlichkeitsrechnung\n\nAllgemeiner Additionsssatz\nDisjunkte Ereignisse\nAdditionssatz fÃ¼r disjunkte Ereignisse\nBedingte Wahrscheinlichkeit\n(Stochastische) UnabhÃ¤ngigkeit\nBaumdiagramm fÃ¼r gemeinsame Wahrscheinlichkeit\nAllgemeiner Multiplikationssatz\nMultiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse\nTotale Wahrscheinlichkeit\nSatz von Bayes\n\n3.1.8.5 Kolmogorovs Wahrscheinlichkeitsdefinition\nWir richten eine Reihe von Forderungen an eine Definition von bzw. an das Rechnen mit Wahrscheinlichkeiten, die direkt plausibel erscheinen:2\n\n\nNichtnegativitÃ¤t: Die Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein.\n\nNormierung: Das sichere Ereignis hat die Wahrscheinlichkeit 1 bzw. 100%: \\(Pr(\\Omega)=1\\); das unmÃ¶gliche Ereignis hat die Wahrscheinlichkeit 0: \\(Pr(\\emptyset)=0\\).\n\nAdditivitÃ¤t. Sind \\(A\\) und \\(B\\) disjunkt, dann ist die Wahrscheinlichkeit von \\(A\\cup B\\) die Summe der beiden Einzelwahrscheinlichkeiten von \\(A\\) und \\(B\\).\n\n3.1.9 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#grundbegriffe-1",
    "href": "0300-Wskt.html#grundbegriffe-1",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.2 Grundbegriffe",
    "text": "3.2 Grundbegriffe\n\nBeispiel 3.1 Klassisches Beispiel fÃ¼r einen Zufallsvorgang ist das (einmalige oder mehrmalige) Werfen einer MÃ¼nze.\\(\\square\\)\nWerfen Sie eine MÃ¼nze! Diese hier zum Beispiel:\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10 Mal.\nDas reicht Ihnen nicht? Okay, wiederholen Sie den Versuch 100, nein 1000, nein: \\(10^6\\) Mal.\nNotieren Sie als Ergebnis, wie oft die Seite mit der Zahl oben liegen kommt (â€œTrefferâ€).\\(\\square\\)\n\nOder probieren Sie die App der Brown University, wenn Sie keine SehnenscheidenentzÃ¼ndung bekommen wollen.\n\nDefinition 3.1 (Zufallsvorgang) Ein Zufallsvorgang oder Zufallsexperiment ist eine einigermaÃŸen klar beschriebene TÃ¤tigkeit, deren Ergebnis nicht bekannt ist. Allerdings ist die Menge mÃ¶glicher Ergebnisse sicher und die Wahrscheinlichkeit fÃ¼r die Ergebnisse kann quantifiziert werden.\\(\\square\\)\n\n\nÃœbungsaufgabe 3.1 Nennen Sie Beispiele fÃ¼r ZufallsvorgÃ¤nge!3\n\n\n\n\n\n\n\nVorsicht\n\n\n\nZufall heiÃŸt nicht, dass ein Vorgang keine Ursachen hÃ¤tte. So gehorcht der Fall einer MÃ¼nze komplett den Gesetzen der Gravitation. WÃ¼rden wir diese Gesetze und die Ausgangsbedingungen (Luftdruck, FallhÃ¶he, OberflÃ¤chenbeschaffenheit, Gewichtsverteilungen, â€¦) exakt kennen, kÃ¶nnten wir theoretisch sehr genaue Vorhersagen machen. Der â€œZufallâ€ wÃ¼rde aus dem MÃ¼nzwurf verschwinden. Man sollte â€œZufallâ€ also besser verstehen als â€œunbekanntâ€.\\(\\square\\)\n\n\n\nÃœbungsaufgabe 3.2 Mit dieser App kÃ¶nnen Sie WÃ¼rfelwÃ¼rfe simulieren und die AusgÃ¤nge dieses Zufallsexperiments beobachten.\\(\\square\\)\n\n\nDefinition 3.2 (Ereignisraum) Die mÃ¶glichen Ergebnisse eines Zufallvorgangs fasst man als Menge mit dem Namen Ereignisraum[leider gibt es eine FÃ¼lle synonymer Namen: Ereignisraum, Elementarereignisraum, Ergebnisraum oder Grundraum] zusammen. Man verwendet den griechischen Buchstaben \\(\\Omega\\) fÃ¼r diese Menge. Die Elemente \\(\\omega\\) (kleines Omega) von \\(\\Omega\\) nennt man Ergebnisse.\\(\\square\\)\n\n\nBeispiel 3.2 Beobachtet man beim WÃ¼rfelwurf (s. AbbildungÂ 3.4) die oben liegende Augenzahl, so ist\n\\[\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{âš€, âš, âš‚, âšƒ, âš„, âš…\\}\\]\nein natÃ¼rlicher Grundraum (Henze 2019).\\(\\square\\)\n\n\n\n\n\nEin (sechsseitiger) WÃ¼rfel\n\nBildquelle: CC BY-SA 3.0\n\n\n\n\n\n\nAbbildungÂ 3.1: Ein (sechsseitiger) WÃ¼rfel, Bildquelle: Peter Steinberg, Wikipedia, CC-BY-\n\n\n\n\n\nDefinition 3.3 (Ereignis) Jede Teilmenge4 von \\(\\Omega\\) heiÃŸt Ereignis; \\(A \\subseteq B\\) .\\(\\square\\)\n\n\nBeispiel 3.3 Beim Mensch-Ã¤rger-dich-nicht Spielen habe ich eine 6 geworfen.5 Das Nennen wir das Ereignis \\(A\\): â€œAugenzahl 6 liegt obenâ€.\\(\\square\\)\n\\(A= \\{6\\}\\)\n\n\nBeispiel 3.4 Sie werfen eine MÃ¼nze (Sie haben keinen Grund, an ihrer Fairness zu zweifeln). â€œSoll ich jetzt lernen fÃ¼r die Klausur (Kopf) oder lieber zur Party gehen (Zahl)?â€\nAbbildungÂ 3.2 zeigt die mÃ¶glichen AusgÃ¤nge (T wie Treffer (Party) und N (Niete, Lernen)) dieses Zufallexperiments.\n\n\n\n\n\nflowchart LR\n M[Sie werfen die MÃ¼nze] --&gt; T\n M --&gt; N\n\n\n\n\nAbbildungÂ 3.2: Sie werfen eine MÃ¼nze. Party oder Lernen???\n\n\n\n\nZahl! Treffer! GlÃ¼ck gehabt!6\\(\\square\\)\n\n\nDefinition 3.4 (UnmÃ¶gliches und sicheres Ereignis) Die leere Menge \\(\\varnothing\\) heiÃŸt das umÃ¶gliche, der Grundraum \\(\\Omega\\) heiÃŸt das sichere Ereignis. \\(\\square\\)\n\n\nBeispiel 3.5 (UnmÃ¶gliches Ereignis) Alois behauptet, er habe mit seinem WÃ¼rfel eine 7 geworfen. Schorsch ergÃ¤nt, sein WÃ¼rfel liege auf einer Ecke, so dass keine Augenzahl oben liegt. Draco hat seinen WÃ¼rfel runtergeschluckt.\\(\\square\\)\n\n\nBeispiel 3.6 Nach dem der WÃ¼rfel geworfen wurde, liegt eine Augenzahl zwischen 1 und 6 oben.\\(\\square\\)\n\n\nDefinition 3.5 (Elementarereignis) Jede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) heiÃŸt Elementarereignis (hÃ¤ufig mit \\(A\\) bezeichnet).\\(\\square\\)\n\n\nBeispiel 3.7 (Elementarereignis) Â \n\nSie spielen Mensch-Ã¤rger-dich-nicht. Und brauchen dringend eine 6. Sie wÃ¼rfeln. Das Ereignis \\(A = \\{1\\}\\) tritt ein.7\nSie schreiben eine Statistik-Klausur. Irgendwie haben Sie das GefÃ¼hl, das Ergebnis ist eine Zufallsexperimentâ€¦ Jedenfalls kÃ¶nnen nach Adam Riese zwei Dinge passieren: \\(\\Omega= \\{\\text{bestehen, nicht bestehen}\\}\\). Das erste der beiden Elementarereignisse tritt ein. Yeah!\nSie fÃ¼hren eine Studie durch zur Wirksamkeit einer Lern-App. Es ist nicht klar, ob die App wirklich was bringt fÃ¼r den Lernerfolg. Vereinfacht gesprochen ist der Grundraum dieses Experiments: \\(\\Omega = \\{\\text{schadet, bringt nichts, nÃ¼tzt}\\}\\). Die Daten sprechen fÃ¼r das Ereignis \\(A = \\{\\text{bringt nichts}\\}\\).\n\n\n\nDefinition 3.6 (VollstÃ¤ndiges Ereignissystem) Wird der Grundraum \\(\\Omega\\) vollstÃ¤ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollstÃ¤ndiges Ereignissystem, s. AbbildungÂ 3.3.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 3.3: Zerlegung des Grundraums in ein vollstÃ¤ndiges Ereignissystem\n\n\n\nBeispiel 3.8 Sei \\(\\Omega\\) der typische Ereignisraum des WÃ¼rfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) â€œgerade Zahlenâ€, und \\(B\\) â€œungerade Zahlenâ€. Damit haben wir ein vollstÃ¤ndiges Ereignissystem erstellt.\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\}  \\qquad  \\hfill \\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6 }\n\n\\end{align}\\]\n\n\nBeispiel 3.9 Sei \\(\\Omega\\) der typische Ereignisraum des WÃ¼rfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) â€œ1,2,3â€, und \\(B\\) â€œ4,5,6â€. Damit haben wir ein vollstÃ¤ndiges Ereignissystem erstellt.\n\\[\\begin{align}\nA = \\{1,2,3\\} \\qquad \\qquad \\hfill  \\boxed{\\boxed{ \\color{black}{1\\; 2\\; 3}}\\; \\color{gray}{4\\; 5\\; 6}} \\\\\nB = \\{4,5, 6\\} \\qquad \\qquad  \\hfill \\boxed{\\color{gray}{1 \\; 2 \\; 3}\\; \\boxed{\\color{black}{4\\; 5 \\; 6}}} \\\\\n\n\\newline\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\} \\qquad \\qquad \\hfill  \\boxed{1\\; 2\\; 3\\; 4\\; 5\\;6}\n\\end{align}\\]\n\n\nDefinition 3.7 (MÃ¤chtigkeit) Die Anzahl der Elementarereignisse eines Ereignismraums nennt man die MÃ¤chtigkeit (des Ereignisraums).8\\(\\square\\)\n\nDie MÃ¤chtigkeit von \\(\\Omega\\) bezeichnet man mit dem Symbol \\(|\\Omega|\\).\n\nBeispiel 3.10 Beim Wurf eines WÃ¼rfels mit \\(\\Omega=\\{1,2,3,4,5,6\\}\\) gibt es 6 Elementarereignisse. Die MÃ¤chtigkeit ist also 6: \\(|\\Omega|=6\\).\\(\\square\\)",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#direkte-ermittlung-von-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#direkte-ermittlung-von-wahrscheinlichkeiten",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.3 Direkte Ermittlung von Wahrscheinlichkeiten",
    "text": "3.3 Direkte Ermittlung von Wahrscheinlichkeiten\n\n3.3.1 Epistemologische Wahrscheinlichkeit\nVor uns liegt ein WÃ¼rfel. Schlicht, ruhig, unbesonders. Wir haben keinen Grund anzunehmen, dass eine seiner \\(n=6\\) Seiten bevorzugt nach oben zu liegen kommt. Jedes der sechs Elementarereignisse ist uns gleich plausibel; der WÃ¼rfel erscheint uns fair. In Ermangelung weiteres Wissens zu unserem WÃ¼rfel gehen wir schlicht davon aus, dass jedes der \\(n\\) Elementarereignis gleich wahrscheinlich ist. Es gibt keinerlei Notwendigkeit, den WÃ¼rfel in die Hand zu nehmen, um zu einer Wahrscheinlichkeitsaussage auf diesem Weg zu kommen. NatÃ¼rlich kÃ¶nnten wir unsere Auffassung eines fairen WÃ¼rfels testen, aber auch ohne das Testen kÃ¶nnen wir eine stringente Aussage (basierend auf unserer Annahme der Indifferenz der \\(n\\) Elementarereignisse) zur Wahrscheinlichkeit eines bestimmten (Elementar-)Ereignisses \\(A\\) kommen (Briggs 2016), s. GleichungÂ 3.1.\n\\[Pr(A) = 1/n= \\frac{1}{|\\Omega|} \\tag{3.1}\\]\n\nBeispiel 3.11 Sei \\(A\\) = â€œDer WÃ¼rfel wird beim nÃ¤chsten Wurf eine 6 zeigen.â€ Die Wahrscheinlichkeit fÃ¼r \\(A\\) ist \\(1/6. \\square\\)\n\n\nDefinition 3.8 Ein Zufallsexperiment, bei dem alle Elementarereignisse die selbe Wahrscheinlichkeit haben, nennt man man ein Laplace-Experiment.\\(\\square\\)\n\nIn Erweiterung von GleichungÂ 3.1 kÃ¶nnen wir schreiben:\n\\[Pr(A)=\\frac{\\text{Anzahl Treffer}}{\\text{Anzahl mÃ¶glicher Ergebnisse}}\\]\n\n3.3.2 Frequentistische Wahrscheinlichkeit\nIn Ermangelung einer Theorie zum Verhalten eines (uns) unbekannten Zufallsvorgangs und unter der Vermutung, dass die Elementarereignisse nicht gleichwahrscheinlich sind, bleibt uns ein einfacher (aber aufwÃ¤ndiger) Ausweg: Ausprobieren.\nAngenommen, ein Statistik-Dozent, bekannt fÃ¼r seine Vorliebe zum GlÃ¼cksspiel und scheinbar endlosen GlÃ¼cksstrÃ¤hnen, er wirft andauernd eine 6, hat seinen LieblingswÃ¼rfel versehentlich liegen gelassen. Das ist die Gelegenheit! Sie greifen sich den WÃ¼rfel, und â€¦ Ja, was jetzt? Nach kurzer Ãœberlegung kommen Sie zum Entschluss, den WÃ¼rfel einen â€œPraxistestâ€ zu unterziehen: Sie werfen ihn 1000 Mal (Puh!) und zÃ¤hlen den Anteil der 6. Falls der WÃ¼rfel fair ist, mÃ¼sste gelten \\(Pr(A=6)=1/6\\approx .17\\). Schauen wir mal!\nUnd hier der Anteil von 6 im Verlauf unserer WÃ¼rfe, s. AbbildungÂ 3.4.\n\n\n\n\n\n\n\nAbbildungÂ 3.4: Das Gesetz der groÃŸen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten WÃ¼rfelwurf\n\n\n\n\nHm, leider ist auf den ersten Blick kein Anzeichen fÃ¼r Schummeln bzw. einen gezinkten WÃ¼rfel zu finden (zumindest nicht zu Gunsten des Zwielichten Dozenten).\n\n3.3.3 Subjektive Wahrscheinlichkeit\nUm subjektiv zu einer Wahrscheinlichkeit zu kommen, sagt man einfach seine Meinung. Das hÃ¶rt sich natÃ¼rlich total plump an. Und tatsÃ¤chlich besteht die Gefahr, dass die so ermittelten Wahrscheinlichkeiten aus der Luft gegriffen, also haltlos, sind.\nAllerdings kann diese Art von Wahrscheinlichkeitsermittlung auch sehr wertvoll sein. In komplizierten Situation im echten Leben kommt man oft in die Situation, dass weder die epistemologische noch die frequentistische Variante verwendet werden kann. Dann muss man auf SchÃ¤tzungen, Vorwissen, Erfahrung, theoretischen Ãœberlengungen etc. zurÃ¼ckgreifen.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#indirekte-ermittlung-von-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#indirekte-ermittlung-von-wahrscheinlichkeiten",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.4 Indirekte Ermittlung von Wahrscheinlichkeiten",
    "text": "3.4 Indirekte Ermittlung von Wahrscheinlichkeiten\nDie indirekte Ermittlung von Wahrscheinlichkeiten meint das Ableiten von Wahrscheinlichkeitsaussagen, wenn man schon etwas Ã¼ber die Wahrscheinlichkeiten des Grundraums weiÃŸ. Dazu greift man auf Rechenregeln der Stochastik zurÃ¼ck. Das hÃ¶rt sich vielleicht wild an, ist aber oft ganz einfach.\n\nBeispiel 3.12 (Gezinkter WÃ¼rfel) Ein gezinkter WÃ¼rfel hat eine erhÃ¶hte Wahrscheinlichkeit fÃ¼r das Ereignis \\(A=\\)â€œ6 liegt obenâ€, und zwar gelte \\(Pr(A)=1/3\\). Was ist die Wahrscheinlichkeit, keine 6 zu wÃ¼rfeln?\\(\\square\\)9\n\nFÃ¼r das Rechnen mit Wahrscheinlichkeiten ist es hilfreich, ein paar Werkzeuge zu kennen, die wir uns im Folgenden anschauen.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#relationen-von-ereignissen",
    "href": "0300-Wskt.html#relationen-von-ereignissen",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.5 Relationen von Ereignissen",
    "text": "3.5 Relationen von Ereignissen\n\n3.5.1 Ãœberblick\nWir gehen von Grundraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge: \\(A \\subset B\\).\nDa wir Ereignisse als Mengen auffassen, verwenden wir im Folgenden die beiden Begriffe synonym.\nDabei nutzen wir u.a. Venn-Diagramme. Venn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren. Die folgenden Venn-Diagramme stammen von Wikipedia (En).\n\n\n\n\n\n\nWozu sind die Venn-Diagramme gut? Warum soll ich die lernen?\n\n\n\nVenn-Diagramme zeigen Kreise und ihre Ã¼berlappenden Teile; daraus lassen sich RÃ¼ckschlÃ¼sse auf Rechenregeln fÃ¼r Wahrscheinlichkeiten ableiten. Viele Menschen tun sich leichter, Rechenregeln visuell aufzufassen als mit Formeln und Zahlen alleine. Aber entscheiden Sie selbst!\\(\\square\\)\n\n\nDie folgende App versinnbildlicht das Rechnen mit Relationen von Ereignissen anhand von Venn-Diagrammen.\n\n\n3.5.2 Vereinigung von Ereignissen\n\nDefinition 3.9 (Vereinigung von Ereignissen) Vereinigt man zwei Ereignisse \\(A\\) und \\(B\\), dann besteht das neue Ereignis \\(C\\) genau aus den Elementarereignissen der vereinigten Ereignisse. Man schreibt \\(C = A \\cup B\\), lies: â€œC ist A vereinigt mit Bâ€.\\(\\square\\)\n\nAbbildungÂ 3.5 zeigt ein Venn-Diagramm zur Verdeutlichung der Vereinigung von Ereignissen.\n\n\n\n\n\nAbbildungÂ 3.5: \\(A \\cup B\\)\n\n\n\nBeispiel 3.13 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem nÃ¤chsten Wurf mindestens eines der beiden Ereignisse \\(A\\) oder \\(B\\) eintreten.\n\\[\\begin{aligned}\nA = \\{1,2\\} \\qquad \\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}} \\\\\nB = \\{2,3\\} \\qquad  \\boxed{1\\; \\boxed{2\\; 3}\\; \\color{gray}{ 4\\; 5\\; 6}} \\\\\n\\newline\n\\hline \\\\\nA \\cup B = \\{1,2,3\\} \\qquad \\boxed{\\boxed{1\\; 2\\; 3}\\; \\color{gray}{4\\; 5\\; 6}}\n\\end{aligned}\\]\n\nZur besseren Verbildlichung betrachten Sie mal diese Animation zur Vereinigung von Mengen; Quelle.\nIn R heiÃŸt die Vereinigung von Mengen union(). Praktisch zum Ausprobieren:\n\nA &lt;- c(1, 2)\nB &lt;- c(2, 3)\n\nunion(A, B)\n## [1] 1 2 3\n\n\n3.5.3 (Durch-)Schnitt von Ereignissen\n\nDefinition 3.10 (Schnittmenge von Ereignissen) Die Schnittmenge zweier Ereignisse \\(A\\) und \\(B\\) umfasst genau die Elementarereignisse, die Teil beider Ereignisse sind. Man schreibt: \\(A \\cap B.\\)10 Lies: â€œA geschnitten Bâ€. \\(\\square\\)\n\nAbbildungÂ 3.6 zeigt ein Sinnbild zur Schnittmenge zweier Ereignisse.\n\n\n\n\n\nAbbildungÂ 3.6: \\(A \\cap B\\)\n\n\n\nBeispiel 3.14 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem nÃ¤chsten Wurf sowohl das Ereignis \\(A\\) = â€œgerade Augenzahlâ€ als auch \\(B\\) = â€œAugenzahl grÃ¶ÃŸer 4â€.\n\\[\\begin{align}\n& A = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n& B = \\{5,6\\} \\qquad \\qquad \\hfill  \\boxed{ \\color{gray}{1\\; 2\\; 3\\; 4\\;} \\boxed{\\color{black}{5\\; 6}}} \\\\\n\\newline\n\\hline \\\\\n& A \\cap B = \\{6\\} \\qquad \\qquad \\hfill  \\boxed{\\color{gray}{1\\; 2\\; 3\\; 4\\; 5\\;} \\color{black}{6}}\n\\end{align}\\]\n\n\nA &lt;- c(2, 4, 6)\nB &lt;- c(5, 6)\nintersect(A, B)\n## [1] 6\n\n\n\n\n\n\n\nEselsbrÃ¼cke zur Vereinigungs- und Schnittmenge\n\n\n\nDas Zeichen fÃ¼r eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen fÃ¼r einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine EselbrÃ¼cke gelesen, s. AbbildungÂ 3.7.\n\n\n\n\n\nAbbildungÂ 3.7: EselsbrÃ¼cke fÃ¼r Vereinigungs- und Schnittmenge\n\n\n\n\n\n3.5.4 KomplementÃ¤rereignis\n\nDefinition 3.11 (KomplementÃ¤rereignis) Ein Ereignis \\(A\\) ist genau dann ein KomplementÃ¤rereignis zu \\(B\\), wenn es genau die Elementarereignisse von \\(\\Omega\\) umfasst, die nicht Elementarereignis des anderen Ereignisses sind, s. AbbildungÂ 3.8.\\(\\square\\)\n\nMan schreibt fÃ¼r das KomplementÃ¤rereignis von \\(A\\) oft \\(\\bar{A}\\) oder \\(\\neg A\\)11; lies â€œNicht-Aâ€ oder â€œA-querâ€.\n\nBeispiel 3.15 Beim normalen WÃ¼rfelwurf sei \\(A\\) das Ereignis â€œgerade Augenzahlâ€; das KomplementÃ¤rereignis ist dann \\(\\neg A\\) â€œungerade Augenzahlâ€.\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n\\hline \\\\\n\\neg A = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\end{align}\\]\n\n\n\n\n\n\nAbbildungÂ 3.8: \\(\\bar{A}\\)\n\n\n\n3.5.5 Logische Differenz\n\nDefinition 3.12 (Logische Differenz) Die logische Differenz der Ereignisse \\(A\\) und \\(B\\) ist das Ereignis, das genau aus den Elementarereignissen besteht von \\(A\\) besteht, die nicht zugleich Elementarereignis von \\(B\\) sind, s. AbbildungÂ 3.9.\\(\\square\\)\n\nDie logische Differenz von \\(A\\) zu \\(B\\) schreibt man hÃ¤ufig so: \\(A \\setminus B\\); lies â€œA minus Bâ€.\n\n\n\n\n\nAbbildungÂ 3.9: \\(A \\setminus B\\)\n\n\n\nBeispiel 3.16 Sei \\(A\\) die Menge â€œgroÃŸe Zahlenâ€ mit \\(A = \\{4,5,6 \\}\\). Sei \\(B\\) die Menge â€œgerade Zahlenâ€. Wir suchen die logische Differenz, \\(A \\setminus B\\).\n\\[\\begin{align}\nA = \\{4,5, 6\\} \\qquad \\hfill \\boxed{4\\; 5\\; 6} \\\\\nB = \\{2,4,6\\} \\qquad  \\hfill \\boxed{2\\; 4\\; 6} \\\\\n\\hline \\\\\nA \\setminus B \\qquad \\hfill \\boxed{5}\n\\end{align}\\]\n\nIn R gibt es die Funktion setdiff(), die eine Mengendifferenz ausgibt.\n\nA &lt;- c(4, 5, 6)\nB &lt;- c(2, 4, 6)\n\nsetdiff(A, B)\n## [1] 5\n\nğŸ¤¯ Von der Menge \\(A\\) die Menge \\(B\\) abzuziehen, ist etwas anderes, als von \\(B\\) die Menge \\(A\\) abzuziehen:\n\nsetdiff(B, A)\n## [1] 2\n\n\n\n\n\n\n\nVorsicht\n\n\n\n\\(A \\setminus B \\ne B \\setminus A\\).\n\n\n\n3.5.6 Disjunkte Ereignisse\nSeien \\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\).\n\\(A\\) und \\(B\\) sind disjunkt12: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. AbbildungÂ 3.10\n\n\n\n\n\nAbbildungÂ 3.10: Zwei disjunkte Ereignisse, dargestellt noch Ã¼berlappungsfreie Kreise\n\n\nQuelle: rither.de\n\nBeispiel 3.17 Â \n\nDas Ereignis \\(A\\) â€œGerade Augenzahl beim WÃ¼rfelwurfâ€, \\(A={2,4,6}\\) und das Ereignis \\(B\\) â€œUngerade Augenzahl beim WÃ¼rfelwurfâ€, \\(B={1,3,5}\\) sind disjunkt.\nDie Ereignisse â€œnormaler Wochentagâ€ und â€œWochenendeâ€ sind disjunkt.\\(\\square\\)\n\n\n\n3.5.7 Vertiefung\nAnimation zu Mengenoperationen",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#rechnen-mit-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#rechnen-mit-wahrscheinlichkeiten",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.6 Rechnen mit Wahrscheinlichkeiten",
    "text": "3.6 Rechnen mit Wahrscheinlichkeiten\n\n3.6.1 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse eintritt.\n\n3.6.1.1 Disjunkte Ereignisse\nGegeben sei \\(\\Omega = {1,2,3,4,5,6}\\). Als Sinnbild: \\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\).\nGesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\).\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\n\\(P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\nBeispiel 3.18 Was ist die Wahrscheinlichkeit, an einem Samstag oder Sonntag geboren zu sein? Unter der (etwas vereinfachten) Annahme, dass alle Jahre zu gleichen Teilen aus allen Wochentagen bestehen, ist die Antwort \\(Pr(A)=1/7 + 1/7 = 2/7\\).\\(\\square\\)\n\n\n3.6.1.2 Allgemein (disjunkt oder nicht disjunkt)\nBei der Addition der Wahrscheinlichkeiten fÃ¼r \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) doppelt erfasst.13 Er muss daher noch abgezogen werden.\n\nDefinition 3.13 (Allgemeiner Additionssatz) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse \\(A\\) und \\(B\\) eintritt, ist gleich der Summe ihrer Wahrscheinlichkeiten minus ihrer gemeinsamen Wahrscheinlichkeit, s. GleichungÂ 3.2.\n\\[P(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\square \\tag{3.2}\\]\n\n\n\n\n\n\n\n\nBeispiel 3.19 (Lernen und Klausur bestehen) In einem angewandten Psychologie-Studiengang sind die Studis verdonnert, zwei Statistik-Module (\\(S1, S2\\)) zu belegen. Die meisten bestehen (\\(B\\)), einige leider nicht (\\(N\\)), s. tbl-klausur2.\nEreignis \\(A\\) ist â€œKlausur Statistik 1â€ mit den Ergebnissen â€œbestandenâ€ und â€œnicht bestandenâ€. Ereignis \\(B\\) ist analog fÃ¼r â€œKlausur Statistik 2â€.\nWir suchen die Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen: \\(Pr(S_1B \\cup S_2B)\\). Nennen wir das Ereignise \\(A\\).\n\n\n\nTabelleÂ 3.1: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n.\nS1_B\nS1_NB\nSumme\n\n\n\nS2_B\n85\n9\n94\n\n\nS2_NB\n5\n1\n6\n\n\nSumme\n90\n10\n100\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(A) &= Pr(S_1B \\cup S_2B) \\\\\n&= Pr(S1_B) + Pr(S_2B) - Pr(S_1B \\cap S_2B)  \\\\\n&= (90 + 94 - 85) / 100 = 99 / 100\\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen liegt bei 99%. Umgekehrt liegt die Wahrscheinlichkeit, keine der beiden Klausuren zu bestehen, liegt bei \\(Pr(\\neg A) = 1- Pr(A) = 0.01 = 1\\%\\); ein Sachverhalt, der sich auch mit einem kurzen Blick in die Datentabelle erkennen lÃ¤sst.\\(\\square\\)\n\n\n3.6.2 Bedingte Wahrscheinlichkeit\n\nDefinition 3.14 (Bedingte Wahrscheinlichkeit) Die Bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit, dass \\(A\\) eintritt, gegeben dass \\(B\\) schon eingetreten ist. \\(\\square\\)\n\nMan schreibt: \\(Pr(A|B).\\) Lies: â€œA gegeben Bâ€ oder â€œA wenn Bâ€.\n\nÃœbungsaufgabe 3.3 Schauen Sie sich mal diese Wahnsinnsanimation von Victor Powell an zu bedingten Wahrscheinlichkeiten. Hammer!\n\nAbbildungÂ 3.11 illustriert gemeinsame Wahrscheinlichkeit, \\(P(A \\cap B)\\), und bedingte Wahrscheinlichkeit, \\(P(A|B)\\).\n\n\n\n\n\n\n\n\n\n(a) Wahrscheinlichkeit fÃ¼r Ereignis B: 50%\n\n\n\n\n\n\n\n\n\n(b) Wahrscheinlichkeit fÃ¼r Ereignis A: 50%\n\n\n\n\n\n\n\n\n\n(c) Wahrscheinlichkeit fÃ¼r Ereignis B gegeben A: 50%\n\n\n\n\n\n\nAbbildungÂ 3.11: Illustration von gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\nBeispiel 3.20 (Bedingte Wahrscheinlichkeit) Sei \\(A\\) â€œSchÃ¶nes Wetterâ€ und \\(B\\) â€œKlausur steht anâ€. Dann meint \\(Pr(A|B)\\) die Wahrscheinlichkeit, dass das Wetter schÃ¶n ist, wenn gerade eine Klausur ansteht.\\(square\\)\n\n\nBeispiel 3.21 (Von PÃ¤psten und MÃ¤nnern) Man(n) beachte, dass die Wahrscheinlichkeit, Papst \\(P\\) zu sein, wenn man Mann \\(M\\) ist etwas anderes ist, als die Wahrscheinlichkeit, Mann zu sein, wenn man Papst ist: \\(Pr(P|M) \\ne Pr(M|P)\\). Das hÃ¶rt sich erst verwirrend an, aber wenn man darÃ¼ber nachdenkt, wird es sehr plausibel.\\(\\square\\)\n\n\nBeispiel 3.22 (Kalt und Regen) Die Wahrscheinlichkeit, dass es kalt ist, wenn es regnet, ist gleich der Wahrscheinlichkeit, dass es gleichzeitig kalt ist und regnet geteilt durch die Wahrscheinlichkeit, dass es regnet.\\(\\square\\)\n\n\nBeispiel 3.23 Gustav GroÃŸ-GÃ¼tz verkauft eine Tinktur14, die schlau machen soll, â€œGÃ¼tzis Gehirn GrÃ¼tzeâ€.15 Gustav trinkt die GrÃ¼tze und sagt schlaue Dinge. Was schlieÃŸen wir daraus? Sei \\(H\\) (wie Hypothese) â€œGÃ¼tzis GrÃ¼tze macht schlauâ€; sei \\(D\\) (wie Daten) die Beobachtung, dass Gustav schlaue Dinge gesagt hat. Ohne exakte Zahlen zu suchen, wie hoch ist wohl \\(Pr(D|H)\\)? In Worten: â€œWie wahrscheinlich ist es, schlaue Dinge gesagt zu haben, wenn die GrÃ¼tze wirklich schlau macht?â€. Vermutlich ist diese Wahrscheinlichkeit sehr hoch. Aber wie hoch ist wohl \\(Pr(H|D)\\)? In Worten: â€œWie wahrscheinlich ist es, dass die GrÃ¼tze wirklich schlau macht, gegeben, dass wir gesehen hat, dass jemand etwas schlaues gesagt hat, nachdem er besagte GrÃ¼tze getrunken hat?â€ Skeptische Geister werden der Meinung sein, \\(Pr(H|D)\\) ist gering. Das Beispiel zeigt u.a. \\(Pr(H|D) \\ne Pr(D|H).\\square\\)\n\nDas Berechnen einer bedingten Wahrscheinlichkeit, \\(Pr(A|B)\\), ist vergleichbar zum Filtern einer Tabelle:\n\n\n\n\nid\nA\nB\n\n\n\n1\n0\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n1\n1\n\n\nSUMME\n2\n2\n\n\n\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(P(A) = 2/4; P(B) = 2/4; P(A \\cap B) = 1/4; P(A|B) = 1/2\\)\n\n3.6.2.1 Rechenregel\nDie Wahrscheinlichkeit fÃ¼r \\(A\\), wenn \\(B\\) schon eingetreten ist, berechnet sich so, s. GleichungÂ 3.3.\n\\[Pr(A|B) = \\frac{Pr(A \\cap B)}{Pr(B)} \\tag{3.3}\\]\n\nBeispiel 3.24 (Lernen und Klausur bestehen) Sie bereiten sich gerade auf die Klausur bei Prof.Â SÃ¼ÃŸ vor. Das heiÃŸt: Sie Ã¼berlegen, ob Sie sich auf die Klausur vorbereiten sollten. Vielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr groÃŸ? Aber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen kÃ¶nnen, s. TabelleÂ 3.2. In der Tabelle sind die Daten von 100 Studis ausgewiesen. Ein Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die â€œLerner. Ein anderer Teil hat nicht gelernt, \\(NL\\) bzw. \\(\\neg L\\). Ein Teil hat bestanden, \\(B\\), ein Teil nicht \\(NB\\) oder \\(\\neg B\\).\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: \\(Pr(B |\\neg L)\\).\n\n\n\nTabelleÂ 3.2: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n\n\n\n.\nL\nNL\nSumme\n\n\n\nB\n80\n1\n81\n\n\nNB\n5\n14\n19\n\n\nSumme\n85\n15\n100\n\n\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(B |\\neg L) &= \\frac{Pr(B \\cap \\neg L)}{Pr(\\neg L)} \\\\\n&=\\frac{1/100}{15/100} = 1/15 \\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat, liegt bei 1 von 15, also ca. 7%.\\(\\square\\)\n\n\n3.6.3 Stochastische (Un-)AbhÃ¤ngigkeit\nStochastische UnabhÃ¤ngigkeit ist ein Spezialfall von AbhÃ¤ngigkeit: Es gibt sehr viele AusprÃ¤gungen fÃ¼r AbhÃ¤ngigkeit, aber nur eine fÃ¼r UnabhÃ¤ngigkeit. KÃ¶nnen wir UnabhÃ¤ngigkeit nachweisen, haben wir also eine starke Aussage getÃ¤tigt.\n\nDefinition 3.15 (Stochastische UnabhÃ¤ngigkeit) Zwei Ereignisse sind (stochastisch) unabhÃ¤ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abhÃ¤ngt, ob \\(B\\) der Fall ist, s. GleichungÂ 3.4. Dann gilt:16\n\n\\[P(A|B) = P(A) = P(A|\\neg B). \\square \\tag{3.4}\\]\nDie UnabhÃ¤ngigkeit von \\(A\\) und \\(B\\) wird manchmal so in Kurzschreibweise ausgedrÃ¼ckt: \\(\\perp \\!\\!\\! \\perp(A, B) \\square\\).\n\n\nBeispiel 3.25 (Augenfarbe und Statistikliebe) Ich vermute, dass die Ereignisse \\(A\\), â€œAugenfarbe ist blauâ€, und \\(B\\), â€œIch liebe Statistikâ€, voneinander unabhÃ¤ngig sind.\\(\\square\\)17\n\n\nBeispiel 3.26 (Ãœberleben auf der Titanic) AbhÃ¤ngig, s. AbbildungÂ 3.12, links: Ãœberleben auf der Titanic ist offenbar abhÃ¤ngig von der Passagierklasse. Auf der anderen Seite: Das Ereignis Ãœberleben auf der Titanic ist unabhÃ¤ngig vom Ereignis Alter ist eine Primzahl, s. AbbildungÂ 3.12, rechts.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Ãœberleben und Passagierklasse sind abhÃ¤ngig\n\n\n\n\n\n\n\n\n\n(b) Ãœberleben und â€˜Geburstag ist eine Primzahlâ€™ sind nicht abhÃ¤ngig\n\n\n\n\n\n\nAbbildungÂ 3.12: AbhÃ¤ngigkeit und UnabhÃ¤ngigkeit zweier Ereignisse\n\n\nZur Ab- bzw. Un-AbhÃ¤ngigkeit zweier Variablen, an Beispielen illustriert.\n\nBeispiel 3.27 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land18 (\\(B\\)) voneinander abhÃ¤ngig (AbbildungÂ 3.13)?\n\n\n\n\n\n\n\n\n\n(a) Impfquote und Land sind voneinander abhÃ¤ngig\n\n\n\n\n\n\n\n\n\n(b) Anteil Corona-Tote und Land sind voneinander abhÃ¤ngig\n\n\n\n\n\n\nAbbildungÂ 3.13: Impfquote und Sterblichkeit sind voneinander abhÃ¤ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\nJa, die beiden Ereignisse sind abhÃ¤gig, da in beiden Diagrammen gilt: \\(P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\\(\\square\\)19\n\n\n3.6.4 Multiplikationssatz\nGegeben seien die Ereignisse \\(A\\) und \\(B\\). Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass beide Ereignisse \\(A\\) und \\(B\\) eintreten.\n\n3.6.4.1 UnabhÃ¤ngige Ereignisse\n\nBeispiel 3.28 Wir fÃ¼hren das Zufallsexperiment â€œWurf einer fairen MÃ¼nzeâ€ zwei Mal aus (AbbildungÂ 3.14). Wie groÃŸ ist die Wahrscheinlichkeit, 2 Mal Kopf zu werfen? Dabei vereinbaren wir, dass â€œKopfâ€ als â€œTrefferâ€ zÃ¤hlt (und â€œZahlâ€ als â€œNieteâ€).\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 3.14: Wir werfen zwei faire MÃ¼nzen\n\n\nAbbildungÂ 3.14 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom â€œStartâ€ (schwarzer Kreis) fÃ¼hren zwei mÃ¶gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch BlÃ¤tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen MÃ¼nzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der BlÃ¤tter. In diesen Diagramm gibt es vier Pfade (und BlÃ¤tter).\nDen Wurf der ersten MÃ¼nze nennen wir in gewohnter Manier \\(A\\); den Wurf der zweiten MÃ¼nze \\(B\\).\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in TabelleÂ 3.3.\n\n\n\nTabelleÂ 3.3: Wahrscheinlichkeiten der Ereignisse im zweimaligen MÃ¼nzwurf\n\n\n\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\n\n\nSei \\(K_1\\) das Ereignis, mit der 1. MÃ¼nze Kopf zu werfen; sei \\(K_2\\) das Ereignis, mit der 2. MÃ¼nze Kopf zu werfen-\nWir suchen \\(Pr(K_1 \\cap K_2)\\). Aufgrund der stochastischen UnabhÃ¤ngigkeit der beiden Ereignisse gilt: \\(Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)\\).\n\nPr_K1K2 &lt;- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n\n\nDefinition 3.16 (Multiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse) Die Wahrscheinlichkeit, dass zwei unabhÃ¤ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. GleichungÂ 3.5.\n\\[Pr(A \\cap B) = Pr(AB) = Pr(A) \\cdot Pr(B) = Pr(B\\cap A) = Pr(B) \\cdot Pr(A)\\square \\tag{3.5}\\]\n\nMit dieser App kÃ¶nnen Sie das Baumdiagramm fÃ¼r den zweifachen MÃ¼nzwurf nÃ¤her erkunden.\nWir fÃ¼hren das Zufallsexperiment â€œWurf einer fairen MÃ¼nzeâ€ drei Mal aus (AbbildungÂ 3.15). Dabei vereinbaren wir wieder, dass â€œKopfâ€ (K) als â€œTrefferâ€ gilt und â€œZahlâ€ (Z) als â€œNieteâ€.\n\n\n\n\n\nAbbildungÂ 3.15: Wir werfen drei faire MÃ¼nzen\n\n\nBeim Wurf von â€œfairenâ€ MÃ¼nzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere EinschÃ¤tzung des Ergebnis des 2. Wurfes nicht verÃ¤ndert etc. Anders gesagt: Wir gehen von (stochastischer) UnabhÃ¤ngigkeit aus.\nFÃ¼r z.B. das Ereignis \\(A=\\{ZZZ\\}\\) gilt: \\(Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3\\). Da jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jeweils gleich.\nAllgemeiner gilt: FÃ¼r ein Zufallsexpriment, das aus \\(k\\) Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit \\(Pr(X)=p\\) ist, so ist die Wahrscheinlichkeit fÃ¼r einen Endkonten \\(Pr(X^k)=p^k\\).\n\n\n\nTabelleÂ 3.4: AusgewÃ¤hlte Wahrscheinlichkeiten von Ereignissen im dreifachen MÃ¼nzwurf\n\n\n\n  \n\n\n\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. TabelleÂ 3.4.\nAbbildungÂ 3.11 versinnbildlicht nicht nur die Bedingtheit zweier Ereignisse, sondern auch die (Un-)AbhÃ¤ngigkeit zweier Ereignisse, \\(A\\) und \\(B\\). In diesem Fall ist die Wahrscheinlichkeit von \\(A\\) gleich \\(B\\): \\(Pr(A)=Pr(B)=.5\\). Man sieht, dass die Wahrscheinlichkeit von \\(A\\) bzw. von \\(B\\) jeweils die HÃ¤lfte der FlÃ¤che (der GesamtflÃ¤che, d.h von \\(Pr(\\Omega)=1\\)) ausmacht. Die Schnittmenge der FlÃ¤che von \\(A\\) und \\(B\\) entspricht einem Viertel der FlÃ¤che: \\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.\\) In diesem Fall sind \\(A\\) und \\(B\\) unabhÃ¤ngig.\n\n\n\n\n\n\n\n\n\n(a) \\(A\\)\n\n\n\n\n\n\n\n\n\n(b) \\(B\\)\n\n\n\n\n\n\n\n\n\n(c) \\(A \\cap B\\), \\(B|A\\)\n\n\n\n\n\n\nAbbildungÂ 3.16: UnabhÃ¤ngige Ereignisse visualisiert\n\n\nAbbildungÂ 3.16 zeigt weiterhin, dass gilt: \\(P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\).\n\nBeispiel 3.29 (Kalt und Regen) Von McElreath (2020) stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit:\nWas ist die Wahrscheinlichkeit fÃ¼r kalt â„ und Regen â›ˆï¸?\nDie Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von Regen â›ˆ, wennâ€™s kalt â„ ist mal die Wahrscheinlichkeit von KÃ¤lte â„.\nEbenfalls gilt:\nDie Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von KÃ¤lte â„, wennâ€™s regnet â›ˆï¸ mal die Wahrscheinlichkeit von Regen â›ˆï¸.\nDas Gesagte als Emoji-Gleichung:\n\\(P(â„ï¸ \\text{ und } â›ˆï¸) = P(â›ˆï¸ |â„ï¸ ) \\cdot P(â„ï¸) = P(â„ï¸ |â›ˆï¸ ) \\cdot P(â›ˆï¸) = P(â›ˆ \\text{ und } â„ï¸)\\) Man kann also die â€œGleichung drehenâ€.20\\(\\square\\)\n\n\nDefinition 3.17 (Kettenregel) Allgemein gesagt, spricht man von der Kettenregel der Wahrscheinlichkeitsrechnung, s. GleichungÂ 3.6.\n\\[P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\square \\tag{3.6}\\]\nIn Worten: Die Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) ist gleich der Wahrscheinlichkeit von \\(A\\) mal der Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\).\n\n\n3.6.4.2 AbhÃ¤ngige Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung abhÃ¤ngiger Ereignisse an, s. AbbildungÂ 3.17. FÃ¼r unabhÃ¤ngige Ereignisse Ã¼brigens auch.\n\nBeispiel 3.30 In einer Urne befinden sich fÃ¼nf Kugeln, von denen vier rot sind und eine blau ist.\nwie groÃŸ ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne ZurÃ¼cklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier 2018), S. 47.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. AbbildungÂ 3.17.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|4/5|B[1. Zug: R]\n  A --&gt;|1/5|C[1. Zug: B]\n  B --&gt;|3/4|D[2. Zug: R]\n  B --&gt;|1/4|E[2. Zug: B]\n  D --- H[Fazit: RR:  12/20]\n  E --- I[Fazit: RB: 4/20]\n  C --&gt;|4/4|F[2. Zug: R]\n  C --&gt;|0/4|G[2. Zug: B]\n  F --- J[Fazit: BR: 4/20]\n  G --- K[Fazit: BB: 0/20]\n\n\n\n\nAbbildungÂ 3.17: Baumdiagramm fÃ¼r ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abhÃ¤ngig ist vom 1. Zug.\n\n\n\n\nEs gilt also: \\(P(A\\cap B) = P(A) \\cdot P(B|A) \\square\\).\n\n\nBeispiel 3.31 (Bertie Botts Bohnen jeder Geschmacksrichtung) Â \n\nSei bloÃŸ vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gewÃ¶hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.â€œ\n\nâ€” Ron Weasley zu Harry Potter21\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=3\\) furchtbar scheuÃŸliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erklÃ¤rt, \\(k=3\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt heiÃŸt es tapfer sein. Ziehen und runter damit!\nWie groÃŸ ist die Wahrscheinlichkeit, genau eine scheuÃŸliche Bohne zu erwischen?\nEs gibt drei Pfade fÃ¼r 1 Treffer bei 3 Wiederholungen:\n\nPfad1 &lt;- 3/20 * 17/19 * 16/18\nPfad2 &lt;- 17/20 * 3/19 * 16/18\nPfad3 &lt;- 17/20 * 16/19 * 3/18\n\nGesamt_Pr &lt;- Pfad1 + Pfad2 + Pfad3\nGesamt_Pr\n## [1] 0.3578947\n\nNutzen Sie diese App, um das auszuprobieren. Sie mÃ¼ssen in der App noch die Zahl der Bohnen (\\(n\\)) und die Zahl der scheuÃŸlichen Bohnen (\\(x\\)) einstellen.\\(\\square\\)\n\n\n3.6.5 Baumdiagramm sucht Problem\nÃœberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit folgender Baumdiagramm-App gelÃ¶st werden kann.\\(\\square\\)\n\n\n3.6.6 Totale Wahrscheinlichkeit\nAbbildungÂ 3.18 zeigt das Baumdiagramm fÃ¼r die Aufgabe Bourier (2018), S. 56.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[A1]\n  A --&gt;|0.1|C[A2]\n  A --&gt;|0.3|D[A3]\n  B --&gt;|0.05|E[B]\n  B -.-&gt;|0.95|F[Nicht-B]\n  C --&gt;|0.02|G[B]\n  C -.-&gt;|0.98|H[Nicht-B]\n  D --&gt;|0.04|I[B]\n  D -.-&gt;|0.96|J[Nicht-B]\n\n\n\n\nAbbildungÂ 3.18: Totale Wahrscheinlichkeit\n\n\n\n\nGesucht ist die Wahrscheinlichkeit \\(P(B)\\); \\(A\\) ist ein vollstÃ¤ndiges Ereignissystem.\nDazu addieren wir die Wahrscheinlichkeiten der relevanten Ã„ste. Jeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse \\(A_i\\) und \\(B\\) dar.\n\nW_Ast1 &lt;- 0.6 * 0.05  # Wahrscheinlichkeit fÃ¼r Ast 1\nW_Ast2 &lt;- 0.1 * 0.02  # ... Ast 2\nW_Ast3 &lt;- 0.3 * 0.04  # ... Ast 3\nW_total &lt;- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n\nDie totale Wahrscheinlichkeit betrÃ¤gt in diesem Beispiel also \\(P(B) = 4.4\\%\\).22\n\nDefinition 3.18 (Totale Wahrscheinlichkeit) Bilden die Ereignisse \\(A_1, A_2, ..., A_n\\) ein vollstÃ¤ndiges Ereignissystem und ist \\(B\\) ein beliebiges Ereignis dann gilt \\(Pr(B) = \\sum_{i=1}^n Pr(A_i) \\cdot Pr(B|A_i).\\square\\)\n\n\nIn AbbildungÂ 3.18 gilt \\(Pr(B) = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot 0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square\\)\n\n\nÃœbungsaufgabe 3.4 (Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2) Es ist die gleich Aufgabe wie BeispielÂ 3.31, aber jetzt lautet die Frage: Wie groÃŸ ist die Wahrscheinlichkeit, mindestens eine scheuÃŸliche Bohne zu erwischen?23\n\\(\\square\\)\n\n\n3.6.7 Baumsammlung\nBaumdiagramme sind ein hilfreiches Werkzeug fÃ¼r wiederholte Zufallsexperimente. Daher ist hier eine â€œBaumsammlungâ€24 zusammengestellt, s. fig-baumsammlung.\n\nSie werfen 1 MÃ¼nze, AbbildungÂ 3.2.\nSie werfen 2 MÃ¼nzen, AbbildungÂ 3.14.\nSie werfen 3 MÃ¼nzen, AbbildungÂ 3.15.\nSie werfen 4 MÃ¼nzen, AbbildungÂ 4.1.\nSie werfen 9 MÃ¼nzen, ğŸ¤¯ AbbildungÂ 5.7.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#bayes-theorem",
    "href": "0300-Wskt.html#bayes-theorem",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.7 Bayesâ€™ Theorem",
    "text": "3.7 Bayesâ€™ Theorem\n\n3.7.1 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes hÃ¤ufig, wenn man Daten zu einer Wirkung \\(W\\) hat, und auf die Ursache \\(U\\) zurÃ¼ckschlieÃŸen mÃ¶chte, sinngemÃ¤ÃŸ:\n\\[W \\quad \\underrightarrow{Bayes} \\quad U\\]\nDann kann man GleichungÂ 3.9 so schreiben, s. GleichungÂ 3.7:\n\\[P(U|W) = \\frac{ P(U) \\cdot P(W|U) }{P(W)} \\tag{3.7}\\]\nEine Ã¤hnliche Situation, die in der Praxis hÃ¤ufig ist, dass man Daten \\(D\\) hat und auf die Wahrscheinlichkeit einer Hypothese \\(H\\) schlieÃŸen mÃ¶chte, s. GleichungÂ 3.8.\n\\[D \\quad \\underrightarrow{Bayes} \\quad H\\]\n\\[P(H|D) = \\frac{ P(H) \\cdot P(D|H) }{P(D)} \\tag{3.8}\\]\nGleichungÂ 3.8 fragt nach \\(P(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (GleichungÂ 3.8):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der PlausibilitÃ¤t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus StandardisierungsgrÃ¼nden dividiert man noch die totale Wahrscheinlichkeit der Daten Ã¼ber alle Hypothesen.\n\n\n3.7.2 Bayes als Baum\nGesucht sei \\(P(A_1|B)\\).\nFÃ¼r Bayesâ€™ Formel25 setzt man die Wahrscheinlichkeit des gÃ¼nstigen Ast zur Wahrscheinlichkeit aller relevanten Ã„ste, \\(P(B)\\).\n\nBeispiel 3.32 (Maschine produziert Ausschuss) Die drei Maschinen \\(M_1, M_2, M_3\\) produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. AbbildungÂ 3.19. Aufgabe: Wie groÃŸ ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde?\\(\\square\\)\n\nDer gÃ¼nstige (gesuchte) Ast ist hier schwarz gedruckt, die Ã¼brigen Ã„ste gestrichelt, s. AbbildungÂ 3.19. \\(A_i\\) zeigt das Ereignis, dass der Artikel von Maschine \\(i\\) produziert wurde. \\(B\\) ist das Ereignis â€œArtikel ist Ausschussâ€.\n\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[A1]\n  A -.-&gt;|0.1|C[A2]\n  A -.-&gt;|0.3|D[A3]\n  B ---&gt;|0.05|E[B]\n  B -.-&gt;|0.95|F[Nicht-B]\n  C -.-&gt;|0.02|G[B]\n  C -.-&gt;|0.98|H[Nicht-B]\n  D -.-&gt;|0.04|I[B]\n  D -.-&gt;|0.96|J[Nicht-B]\n\n\n\n\nAbbildungÂ 3.19: GÃ¼nstige Pfade\n\n\n\n\n\\[P(A|B) = \\frac{P(A1 \\cap B)}{P(B)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(P(A|B)\\) betrÃ¤gt also ca. 68%.\nZur Erinnerung: \\(P(B)\\) ist die totale Wahrscheinlichkeit.\n\n3.7.3 Bayes als bedingte Wahrscheinlichkeit\nBayesâ€™ Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:\n\\(P(A|B) = \\frac{\\overbrace{ P(A\\cap B)}^\\text{umformen}}{P(B)}\\)\n\\(P(A| B)\\) kann man umformen, s. GleichungÂ 3.9:\n\\[P(A|B) =\\frac{P(A\\cap B)}{P(B)} = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\tag{3.9}\\]\nMan kann sich Bayesâ€™ Theorem auch wie folgt herleiten:\n\\(P(A\\cap B) = P(B \\cap A) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\nDann lÃ¶sen wir nach P\\((A|B)\\) auf:\n\\(P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(B)}\\)\n\n3.7.4 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayesâ€™ Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel wÃ¤re: â€œWas ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?â€.\nDas sieht dann so aus, GleichungÂ 3.10:\n\\[\n\\begin{aligned}\nP(R \\cap B |K) &= \\frac{ P(R \\cap B) \\cdot P(K|R \\cap B) }{P(D)} \\\\\n&= \\frac{ P(R ) \\cdot P(B) \\cdot P(K|R \\cap B) }{P(D)}\n\\end{aligned}\n\\tag{3.10}\\]\nHier haben wir \\(P(R \\cap B)\\) aufgelÃ¶st in \\(P(R) \\cdot P(B)\\), das ist nur zulÃ¤ssig, wenn \\(R\\) und \\(B\\) unabhÃ¤ngig sind.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#vertiefung-1",
    "href": "0300-Wskt.html#vertiefung-1",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.8 Vertiefung",
    "text": "3.8 Vertiefung\nBei Henze (2019) findet sich eine anspruchsvollere EinfÃ¼hrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes der Kapitel 2 und 3 von Henze (2019).\nMit dieser App, die ein zweistufiges Baumdiagramm zeigt, kÃ¶nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\nDiese App lÃ¤sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise.\nMittag und SchÃ¼ller (2020) stellen in Kap. 11 die Grundlagen der Wahrscheinlichkeitstheorie vor. Ã„hnliche Darstellungen finden sich in einer groÃŸen Zahl an LehrbÃ¼chern.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#aufgaben",
    "href": "0300-Wskt.html#aufgaben",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.9 Aufgaben",
    "text": "3.9 Aufgaben\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\n\nAdditionssatz1\nNerd-gelockert\nUrne1\nUrne2\nk-coins-k-hits\nsicherheit\nsicherheit2\nKlausuren-bestehen\nGem-Wskt1\nGem-Wskt2\nGem-Wskt3\nwuerfel05\nwuerfel06\nBed-Wskt1\nBed-Wskt2\nBed-Wskt3\nmtcars-abhaengig\nmtcars-abhaengig-var2\nmtcars-abhaengig_var3a\nvoll-normal\ncorona-blutgruppe\ntotale-Wskt1\nKrebs1\nBayes-Theorem1",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0300-Wskt.html#section",
    "href": "0300-Wskt.html#section",
    "title": "\n3Â  Wahrscheinlichkeit\n",
    "section": "\n3.10 â€”",
    "text": "3.10 â€”\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of Modeling, Probability & Statistics. Springer.\n\n\nHenze, Norbert. 2019. Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der MaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of Science. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMittag, Hans-Joachim, und Katharina SchÃ¼ller. 2020. Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Wahrscheinlichkeit</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#lernsteuerung",
    "href": "0400-Verteilungen.html#lernsteuerung",
    "title": "\n4Â  Verteilungen\n",
    "section": "\n4.1 Lernsteuerung",
    "text": "4.1 Lernsteuerung\n\n4.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n4.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nden Begriff der Zufallsvariablen erlÃ¤utern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erlÃ¤utern\nden Begriff einer Gleichverteilung erlÃ¤utern\ndie Parameter einer Normalverteilung nennen und erlÃ¤utern\nzentrale Konzepte in R umsetzen\n\n4.1.3 Begleitliteratur\nDer Stoff dieses Kapitels deckt sich (weitgehend) mit Bourier (2018), Kap. 6.1 und 6.3 sowie 7.1 und und 7.2.\n\n4.1.4 Vorbereitung im Eigenstudium\nLesen Sie selbstÃ¤ndig, zusÃ¤tzlich zum Stoff dieses Kapitels noch Bourier (2018); dort folgende Abschnitte:\n\nKap. 6.1 (Zum Begriff Zufallsvariable)\nKap. 6.3 (Stetige Zufallsvariablen)\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung)\nKap. 7.2.3 (Normalverteilung)\n\nLÃ¶sen Sie auch die Ãœbungsaufgaben dazu.\nWeitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n4.1.5 PrÃ¼fungsrelevanter Stoff\nBeachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff prÃ¼fungsrelevant ist.\n\n4.1.6 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\n\n\n4.1.7 Zentrale Begriffe\n\n4.1.7.1 Eigenschaften von Zufallsvariablen\n\nZufallsvariable (random variable)\nDiskret vs.Â stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n4.1.7.2 Verteilungen\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n4.1.8 Begleitvideos\n\nVideo 1 zum Thema Verteilungen\nVideo 2 zum Thema Verteilungen",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#zufallsvariable",
    "href": "0400-Verteilungen.html#zufallsvariable",
    "title": "\n4Â  Verteilungen\n",
    "section": "\n4.2 Zufallsvariable",
    "text": "4.2 Zufallsvariable\n\nBeispiel 4.1 Schorsch sucht eine Betreuerin fÃ¼r seine Abschlussarbeit. An die ideale Betreuerin setzt er 4 Kriterien an: a) klare, schriftliche fixierte Rahmenbedingungen, b) viel Erfahrung, c) guten Ruf und d) interessante Forschungsinteressen. Je mehr dieser 4 Kriterien erfÃ¼llt sind, desto besser. Schorsch geht davon aus, dass die 4 Kriterien voneinander unabhÃ¤ngig sind (ob eines erfÃ¼llt ist oder nicht, Ã¤ndert nichts an der Wahrscheinlichkeit eines anderen Kriteriums). Schorsch interessiert sich also fÃ¼r die Anzahl der erfÃ¼llten Kriterien, also eine Zahl von 0 bis 4. Er schÃ¤tzt die Wahrscheinlichkeit fÃ¼r einen â€œTrefferâ€ in jedem seiner 4 Kriterien auf 50%. Viel GlÃ¼ck, Schorsch! Sein Zufallsexperiment hat 16 AusgÃ¤nge, s. AbbildungÂ 4.1 und TabelleÂ 4.1. Ganz schÃ¶n komplex. Eigentlich wÃ¼rden ihm ja eine Darstellung mit 5 Ergebnissen, also der â€œGutachter-Scoreâ€ von 0 bis 4 ja reichen. Wie kÃ¶nnen wir es Ã¼bersichtlicher fÃ¼r Schorsch?\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 4.1: Ein Baumdiagramm mit 16 AusgÃ¤ngen, analog zur 4 MÃ¼nzwÃ¼rfen. Jede MÃ¼nze ist in einer anderen Farbe dargestellt. Der Knoten â€˜1â€™ ist der Start, da ist noch keine MÃ¼nze geworfen.\n\n\n\n\n\n\n\nTabelleÂ 4.1: Schorschs Zufallsexperiment, Auszug der Elementarereignisse\n\n\n\n\ni\nElementarereignis\nPr(EE)\nTrefferzahl\nPr(Trefferzahl)\n\n\n\n1\nNNNN\n1/16\n0\n1/16\n\n\n2\nNNNT\n1/16\n1\n1/4\n\n\n3\nNNTN\n1/16\n1\n1/4\n\n\n4\nNTNN\n1/16\n1\n1/4\n\n\n5\nTNNN\n1/16\n1\n1/4\n\n\n6\nNNTT\n1/16\n2\nâ€¦\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\n\n\n\n\n\nSchorsch braucht also eine Ã¼bersichtlichere Darstellung; die Zahl der Treffer und ihre Wahrscheinlichkeit wÃ¼rde ihm ganz reichen. In vielen Situationen ist man an der Anzahl der Treffer interessiert. Die Wahrscheinlichkeit fÃ¼r eine bestimmte Trefferanzahl bekommt man einfach durch Addieren der Wahrscheinlichkeiten der zugehÃ¶rigen Elementarereignisse, s. TabelleÂ 4.1. Hier kommt die Zufallsvariable ins Spiel. Wir nutzen sie, um die Anzahl der Treffer in einem Zufallsexperiment zu zÃ¤hlen.\n\nDefinition 4.1 (Zufallsvariable) Die Zuordnung der Elementarereignisse eines Zufallsexperiments zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable.\\(\\square\\)\n\nDie den Elementarereignissen zugewiesenen Zahlen nennt man Realisationen oder AusprÃ¤gungen der Zufallsvariablen.\n\nBeispiel 4.2 (Lotto) Ein Lottospiel hat ca. 14 Millionen Elementarereignisse. Die Zufallsvariable â€œAnzahl der Trefferâ€ hat nur 7 Realisationen: 0,1,â€¦,6.\\(\\square\\)\n\nEs hat sich eingebÃ¼rgert, Zufallszahlen mit \\(X\\) zu bezeichnen (oder anderen Buchstaben weit hinten aus dem Alphabet).\nMan schreibt kurz: \\(X: \\Omega \\rightarrow \\mathbb{R}\\). Um die Vorschrift der Zuordnung genauer zu bestimmen, kann man folgende Kurzschreibweise nutzen:\n\\({\\displaystyle X(\\omega )={\\begin{cases}1,&{\\text{wenn }}\\omega ={\\text{Kopf}},\\\\[6pt]0,&{\\text{wenn }}\\omega ={\\text{Zahl}}.\\end{cases}}}\\)\nAbbildungÂ 4.2 stellt diese Abbildung dar.\n\n\n\n\n\nflowchart LR\n  subgraph A[Ereignisse&lt;br&gt; im Ereignisraum]\n    Kopf\n    Zahl\n  end\n  subgraph B[Realisationen der &lt;br&gt;Zufallsvariable]\n    null[0]\n    eins[1]\n  end\n  subgraph C[Wahrscheinlichkeit]\n    half[50%]\n  end\n  \n  Kopf --&gt; null\n  Zahl --&gt; eins\n  null --&gt; half\n  eins --&gt; half\n\n\n\n\nAbbildungÂ 4.2: Eine Zufallsvariable ist eine Abbildung vom Ereignisraum zu den Realisationen der Zufallsvariable. AuÃŸerdem sieht man, wie Zufallsvariablen genutzt werden, um Wahrsscheinlichkeiten zu bestimmen.\n\n\n\n\nZufallsverteilungen kann im zwei Artein einteilen:\n\ndiskrete Zufallsvariablen\nstetige Zufallsvariablen\n\n\n4.2.1 Diskrete Zufallsvariable\n\n4.2.1.1 Grundlagen\nEine diskrete Zufallsvariable ist dadurch gekennzeichnet, dass nur bestimmte Realisationen mÃ¶glich sind, zumeist natÃ¼rliche Zahlen, wie 0, 1, 2,â€¦, . AbbildungÂ 4.3 versinnbildlicht die Zufallsvariable des â€œGutachter-Scoresâ€, s. BeispielÂ 4.1.\n\n\n\n\n\n\n\nAbbildungÂ 4.3: Sinnbild einer diskreten Zufallsvariablen X fÃ¼r Schorschs Suche nach einer Betreuerin seiner Abschlussarbeit. X gibt den Score der Gutachterin wider.\n\n\n\n\n\nBeispiel 4.3 (Diskrete Zufallsvariablen) Â \n\nAnzahl der Bewerbungen bis zum ersten Job-Interview\nAnzahl AnlÃ¤ufe bis zum Bestehen der Statistik-Klausur\nAnzahl der Absolventen an der HS Ansbach pro Jahr\nAnzahl Treffer beim Kauf von Losen\nAnzahl BetriebsunfÃ¤lle\nAnzahl der Produkte in der Produktpalette\\(\\square\\)\n\n\n\n\nBeispiel 4.4 Der zweifache WÃ¼rfelwurf ist ein typisches Lehrbuchbeispiel fÃ¼r eine diskrete Zufallsvariable.1 Hier ist \\(S\\)2 die Augensumme des zweifachen WÃ¼rfelwurfs und \\(S\\) ist eine Zahl zwischen 2 und 12. FÃ¼r jede Realisation \\(X=x\\) kann die Wahrscheinlichkeit berechnen, AbbildungÂ 4.4 versinnbildlicht die Wahrscheinlichkeit fÃ¼r jede Realisation von \\(X\\).\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 4.4: Augensumme des zweifachen WÃ¼rfelwurfs; fÃ¼r jede Realisation von S ist die zugehÃ¶rige Wahrscheinlichkeit dargestellt. Bildquelle: Tim Stellmach, Wikipedia, PD\n\n\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariablen eine Wahrscheinlichkeit zuzuordnen.\n\nDefinition 4.2 (Diskrete Wahrscheinlichkeitsverteilung) Eine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) AusprÃ¤gungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu.\\(\\square\\)\n\n\nBeispiel 4.5 (Wahrscheinlichkeit des Geschlechts bei der Geburt) So hat die Variable Geschlecht eines Babies die beiden AusprÃ¤gungen MÃ¤dchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\), laut einer Studie (Gelman, Hill, und Vehtari 2021).\\(\\square\\)\n\nZwischen der deskriptiven Statistik und der Wahrscheinlichkeitstheorie bestehen enge Parallelen, TabelleÂ 4.2 stellt einige zentrale Konzepte gegenÃ¼ber.\n\n\n\nTabelleÂ 4.2: GegenÃ¼berstellung von Wahrscheinlichkeitstheorie und deskriptiver Statistik\n\n\n\n\n\n\nWahrscheinlichkeitstheorie\nDesktiptive.Statistik\n\n\n\nZufallsvariable\nMerkmal\n\n\nWahrscheinlichkeit\nrelative HÃ¤ufigkeit, Anteil\n\n\nWahrscheinlichkeitsfunktion\neinfache relative HÃ¤ufigkeitsverteilung\n\n\nVerteilungsfunktion\nkumulierte relative HÃ¤ufigkeitsverteilung\n\n\nErwartungswert\nMittelwert\n\n\nVarianz\nVarianz\n\n\n\n\n\n\n\n\n\nEine Verteilung zeigt, welche AusprÃ¤gungen eine Variable aufweist und wie hÃ¤ufig bzw. wahrscheinlich diese sind. Einfach gesprochen veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet HÃ¤ufigkeitsverteilungen (s. Abb. AbbildungÂ 4.6) von Wahrscheinlichkeitsverteilungen (Abb. AbbildungÂ 4.5).\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.5: Wahrscheinlichkeitsverteilung der Zufallsvariable â€œAugenzahl im zweifachen WÃ¼rfelwurfâ€\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.6: (relative und absolute) HÃ¤ufigkeiten des zweifachen WÃ¼rfelwurfs, 1000 Mal wiederholt\n\n\n\n\n\n\n\nBeispiel 4.6 (Wahrscheinlichkeitsfunktion eines WÃ¼rfels) AbbildungÂ 4.7 zeigt die Wahrscheinlichkeitsfunktion eines einfachen WÃ¼rfelwurfs.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 4.7: Wahrscheinlichkeitsfunktion eines einfachen WÃ¼rfelwurfs, Bildrechte: Olex Alexandrov, Wikipedia, PD\n\n\n\n\nDie HÃ¤ufigkeitsverteilung eines diskreten Merkmals \\(X\\) mit \\(k\\) AusprÃ¤gungen zeigt (vgl. TabelleÂ 4.3), wie hÃ¤ufig die einzelnen AusprÃ¤gungen sind. So hat die Variable Zylinder (in einem Datensatz) etwa die AusprÃ¤gungen 4,6 und 8.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.8: HÃ¤ufigkeitsverteilung von cyl und hp (diskretisiert in 10 KÃ¶rbe oder Gruppen)\n\n\n\n\n\n\n\n\nTabelleÂ 4.3: Eine diskrete HÃ¤ufigkeitsverteilung, dargestellt in einer HÃ¤ufigkeitstabelle\n\n\n\n  \n\n\n\n\n\n\n\n\nAbb. AbbildungÂ 4.8, links, visualisiert die HÃ¤ufigkeitsverteilung von cyl. Ein stetiges Merkmal, wie hp (PS-Zahl), lÃ¤sst sich durch Klassenbildung in ein diskretes umwandeln (diskretisieren), s. Abb. AbbildungÂ 4.8, rechts.\n\n4.2.1.2 Wahrscheinlichkeitsfunktion\n\nDefinition 4.3 (Wahrscheinlichkeitsfunktion) Die Funktion \\(f\\), die den mÃ¶glichen Realisationen \\(x_i\\) der diskreten Zufallsvariablen \\(X\\) die Eintrittswahrscheinlichkeiten zuordnet, heiÃŸt Wahrscheinlichkeitsfunktion.\\(\\square\\)\n\n\nBeispiel 4.7 Die Wahrscheinlichkeitsfunktion fÃ¼r \\(X\\) â€œAugensumme im zweifachen WÃ¼rfelwurfâ€ ist in AbbildungÂ 4.5 visualisiert.\\(\\square\\)\n\n\nBeispiel 4.8 Die Wahrscheinlichkeitsfunktion fÃ¼r \\(X\\) â€œTreffer im einfachen MÃ¼nzwurf, mit Zahl ist Trefferâ€ ist \\(Pr(X=1)=1/2.\\), vgl. AbbildungÂ 4.2.\\(\\square\\)\n\nğŸ’¡ Einfach gesprochen gibt die Wahrscheinlichkeitsfunktion die Wahrscheinlichkeit einer bestimmten Realisation einer Zufallsvariable an.\n\n4.2.1.3 Verteilungsfunktion\n\nDefinition 4.4 (Verteilungsfunktion) Die Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist.\\(\\square\\)\n\nDie Berechnung von \\(F(x)\\) erfolgt, indem die Wahrscheinlichkeiten aller mÃ¶glichen Realisationen \\(x_i\\), die kleiner oder gleich dem vorgegebenen Realisationswert \\(x\\) sind, addiert werden:\n\\(F(x) = \\sum_{x_ \\le x} Pr(X=x_i).\\)\nDie Verteilungsfunktion ist das Pendant zur kumulierten HÃ¤ufigkeitsverteilung, vgl. AbbildungÂ 4.9 und AbbildungÂ 4.10: Was die kumulierte HÃ¤ufigkeitsverteilung fÃ¼r HÃ¤ufigkeiten ist, ist die Verteilungsfunktion fÃ¼r Wahrscheinlichkeiten.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.9: Verteilungsfunktion \\(F(X \\le x_i)\\) fÃ¼r die Zufallsvariable â€œAugenzahl im zweifachen WÃ¼rfelwurfâ€\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.10: Empirische Verteilungsfunktion (kumulierte HÃ¤ufigkeitsverteilung) \\(F(X \\le x_i)\\) von 1000 zweifachen MÃ¼nzwÃ¼rfen\n\n\n\n\n\n\n\n4.2.2 Stetige Zufallsvariablen\nğŸ“º Verteilungen metrischer Zufallsvariablen\nAbbildungÂ 4.11 versinnbildlicht die stetige Zufallsvariable â€œKÃ¶rpergrÃ¶ÃŸeâ€, die (theoretisch, in AnnÃ¤herung) jeden beliebigen Wert zwischen 0 und (vielleicht) 3m annehmen kann.\n\n\n\n\n\n\n\nAbbildungÂ 4.11: Sinnbild fÃ¼r eine stetige Zufallsvariable X â€œKÃ¶rpergrÃ¶ÃŸeâ€\n\n\n\n\n\nDefinition 4.5 (Stetige Zufallsvariable) Eine stetige Zufallsvariable gleicht einer diskreten, nur dass alle Werte im Intervall erlaubt sind.\\(\\square\\)\n\n\nBeispiel 4.9 Â \n\nSpritverbrauch\nKÃ¶rpergewicht von Professoren\nSchnabellÃ¤ngen von Pinguinen\nGeschwindigkeit beim Geblitztwerden\\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 4.1 (Warten auf den Bus, 42 Sekunden) Sie stehen an der Bushaltestellen und warten auf den Bus. Langweilig. Da kommt Ihnen ein Gedanken in den Sinn: Wie hoch ist wohl die Wahrscheinlichkeit, dass Sie exakt 42 Sekunden auf den Bus warten mÃ¼ssen, s. AbbildungÂ 4.13? Weiterhin Ã¼berlegen Sie, dass davon auszugehen ist, dass jede Wartezeit zwischen 0 und 10 Minuten gleich wahrscheinlich ist. SpÃ¤testens nach 10 Minuten kommt der Bus, so ist die Taktung (extrem zuverlÃ¤ssig). Exakt heiÃŸt exakt, also nicht 42.1s, nicht 42.01s, nicht 42.001s, etc. bis zur x-ten Dezimale.\\(\\square\\)\n\nNicht so einfach (?). Hingegen ist die Frage, wie hoch die Wahrscheinlichkeit ist, zwischen 0 und 5 Minuten auf den Bus zu warten (\\(0&lt;x&lt;5\\)), einfach: Sie betrÃ¤gt 50%, wie man in AbbildungÂ 4.12 gut sehen kann.\n\n\n\n\n\n\n\nAbbildungÂ 4.12: Wie groÃŸ ist die Wahrscheinlichkeit, zwischen 0 und 5 Minuten auf den Bus zu warten? 50 Prozent!\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.13: Wie groÃŸ ist die Wahrscheinlichkeit, genau 42 Sekunden auf den Bus zu warten? Hm.\n\n\n\n\n\n\nVergleicht man AbbildungÂ 4.13 und AbbildungÂ 4.12 kommt man (vielleicht) zu dem Schluss, dass die Wahrscheinlichkeit exakt 42s auf den Bus zu warten, praktisch Null ist. Der Grund ist, dass die FlÃ¤che des Intervalls gegen Null geht, wenn das Intervall immer schmÃ¤ler wird. Aus diesem Grund kann man bei stetigen Zufallszahlen nicht von einer Wahrscheinlichkeit eines bestimmten Punktes \\(X=x\\) sprechen. FÃ¼r einen bestimmten Punkt \\(X=x\\) kann man aber die Dichte der Wahrscheinlichkeit angeben.\nWas gleich ist in beiden Situationen (\\(Pr(X=.42)\\) und \\(Pr(0&lt;x&lt;0.5)\\)) ist die Wahrscheinlichkeitsdichte, \\(f\\). In AbbildungÂ 4.13 und AbbildungÂ 4.12 ist die Wahrscheinlichkeitsdichte gleich, \\(f=1/10=0.1\\).\n\nDefinition 4.6 (Wahrscheinlichkeitsdichte) Die Wahrscheinlichkeitsdichte \\(f(x)\\) gibt an, wie viel Wahrscheinlichkeitsmasse pro Einheit von \\(X\\) an an der Stelle \\(x\\) ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsdichte zeigt an, an welchen Stellen \\(x\\) die Wahrscheinlichkeit besonders â€œgeballtâ€ oder â€œdichtâ€ sind, s. AbbildungÂ 4.14.\n\n\n\n\n\nAbbildungÂ 4.14: Die Wahrscheinlichkeit, dass eine Zufallsvariable einen Wert zwischen und annimmt, entspricht dem Inhalt der FlÃ¤che unter dem Graph der Wahrscheinlichkeitsdichtefunktion. Bildrechte: 4C, Wikipedia, CC-BY-SA .\n\n\n\n4.2.2.1 Verteilungsfunktion\n\n\n\nDefinition 4.7 Die Verteilungsfunktion einer stetigen Zufallsvariablen gibt wie im diskreten Fall an, wie groÃŸ die Wahrscheinlichkeit fÃ¼r eine Realisation kleiner oder gleich einem vorgegebenen Realisationswert \\(x\\) ist.\\(\\square\\)\nDie Verteilungsfunktion \\(F(x)\\) ist analog zur kumulierten HÃ¤ufigkeitsverteilung zu verstehen, vgl. AbbildungÂ 4.15.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.15: Verteilungsfunktion F fÃ¼r X=â€œWartezeit auf den Busâ€\n\n\n\n\n\n\n\nDefinition 4.8 (Stetige Wahrscheinlichkeitsverteilung) Bei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen AusprÃ¤gungen aus; die Wahrscheinlichkeit einer bestimmten AusprÃ¤gung ist (praktisch) Null: \\(Pr(X=x_j)=0, \\quad j=1,...,+\\infty \\square\\).\n\n\nBeispiel 4.10 (Wahrscheinlichkeitsverteilung fÃ¼r die KÃ¶rpergrÃ¶ÃŸe) So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666â€¦ cm groÃŸ ist, (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\).\\(\\square\\)\n\nFÃ¼r praktische Fragen berechnet man zumeist die Wahrscheinlichkeit von Intervallen, s. AbbildungÂ 4.14.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#wichtige-verteilngen",
    "href": "0400-Verteilungen.html#wichtige-verteilngen",
    "title": "\n4Â  Verteilungen\n",
    "section": "\n4.3 Wichtige Verteilngen",
    "text": "4.3 Wichtige Verteilngen\nğŸ“º Einstieg in Verteilungen\n\n4.3.1 Gleichverteilung\n\n4.3.1.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jeder Wert im Ergebnisraum der zugehÃ¶rigen Zufallsvariable gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine Realisation einer Zufallsvariablen fÃ¼r plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. AbbildungÂ 4.16 zeigt ein Beispiel fÃ¼r eine (stetige) Gleichverteilung.\n\n\n\n\n\n\n\n\n\n(a) Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2\n\n\n\n\n\n\n\n\n\n(b) Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3\n\n\n\n\n\n\nAbbildungÂ 4.16: Stetige Gleichverteilung; man beachte jeweils die Y-Achse\n\n\nAbbildungÂ 4.16, links: Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 50%, da der Bereich \\([-0.5, +0.5]\\) die HÃ¤lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte gleich. AbbildungÂ 4.16, rechts: Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von ca. 33%, da der Bereich \\([-0.5, +0.5]\\) ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte gleich. Definierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.\n\n4.3.1.2 Simulation\nMÃ¶chte man die Verteilungsfunktion einer stetigen Zufallsvariablen berechnen, kann die Mathe ganz schÃ¶n kompliziert werden, schlieÃŸlich muss man Integrale lÃ¶sen. Aber es gibt einen Trick, wie man die Sache stark vereinfachen kann: man simuliert die Verteilung. Was bedeutet das?\nAngenommen, die Wartezeit auf einen Bus ist gleichverteilt (engl. uniform distribution); der Bus kommt regelmÃ¤ÃŸig und pÃ¼nktlich alle 10 Minuten. Die minimale Wartezeit betrÃ¤gt also 0 Minuten und die maximale 10 Minuten. Nennen wir die zugehÃ¶rige Zufallsvariable \\(X\\), das ist schÃ¶n kurz zu schreiben.\nEine gleichverteilte Zufallsvariable \\(X\\) mit Min \\(m_0\\) und Maximum \\(m_1\\) schreibt man auch wie folgt in Kurzschreibweise:\n\\[X \\sim Unif(m_0,m_1).\\]\nJa, das sieht fancy aus, ist aber dafÃ¼r schÃ¶n kurz, aber wo ist der versprochene Trick zum Vereinfachen? Kommt gleich, Moment.\nEine Frage kÃ¶nnte nun lauten, wie groÃŸ ist die Wahrscheinlichkeit, dass man zwischen 3 und 5 Minuten auf den Bus warten muss? Achtung: Hier ist der Trick. NÃ¤mlich, dass wir Integralrechnung gegen stumpfes ZÃ¤hlen eintauschen.\nComputer (und damit R) haben eingebaute Funktionen, die eine beliebige Zufallszahl ziehen kÃ¶nnen, zum Beispiel gleichverteilte. Auf Errisch heiÃŸt das Zauberwort runif():\n\nrunif(n = 1, min = 0, max = 10)\n\n\n## [1] 9.14806\n\nAuf Deutsch heiÃŸt das:\n\nğŸ‘¨â€ğŸ« â€œHey R, ich hÃ¤tte gerne eine (daher n = 1) Zufallszahl (r wie random), die gleichverteilt ist (uniform) mit min = 0 und max = 10.\n\n\nğŸ¤– Jawohl, oh herrliches Leberwesen\n\n(Zu) anschaulich gesprochen: R hat den Bus kommen lassen und es hat gut 9.1 Minuten gedauert, bis er da war. Achtung, jetzt kommtâ€™s: Jetzt lassen wir R mal \\(10^5\\) (1e5 auf Computersprech) Busse vorfahren. R soll jedes Mal notieren, wie lange man auf den Bus warten musste.3\n\nx_simu &lt;- runif(n = 1e5, min = 0, max = 10)\n\nSchauen wir uns die Verteilung an, s. AbbildungÂ 4.17.4\n\nlibrary(ggpubr)\ngghistogram(x_simu_df, x = \"x_simu\", fill = \"grey20\")\n\n\n\n\n\n\n\n\nAbbildungÂ 4.17: Simulation einer gleichverteiluten Zufallsvariablen\n\n\n\n\nOkay, unsere Verteilung sieht nicht exakt gleichverteilt, aber einigermaÃŸen. Gut genug fÃ¼r unsere Zwecke!\nSo, und jetzt kommt das Ernten. Wir kÃ¶nnen jetzt nÃ¤mlich einfach zÃ¤hlen (count()), um die Antwort auf unsere Frage (der Wartezeit 3-5 Min.) zu erhalten, s. TabelleÂ 4.4.\n\n\n\nx_simu_df %&gt;% \n  count(Schnittmenge = x &gt; 3 & x &lt; 5)\n\n\n\n\n\nTabelleÂ 4.4: HÃ¤ufigkiten auslesen anstelle von Integralen berechnen\n\n\n\n  \n\n\n\n\n\n\n\n\nDas Zeichen & ist das logische UND, also die Schnittmenge der zwei Mengen \\(A := \\{x|x&gt;3\\}\\) und \\(B := \\{x|x&lt;5\\}\\), also \\(A \\cap B\\).\nWie man sieht, fallen ca. 20% der Stichproben in den entsprechenden Bereich.\nDa viele Probleme, wenn sie komplexer werden, kaum noch â€œanalytischâ€ (d.h. wie Ausrechnen von Integralen) lÃ¶sbar sind, greift man in der modernen (Analyse-)Welt oft lieber auf Simulationsverfahren zurÃ¼ck - Dank sei den schnellen Rechnern. FÃ¼r uns Menschen ist damit die Aufgabe des Integrierens auf schnÃ¶des ZÃ¤hlen zurÃ¼ckgefÃ¼hrt.\n\n4.3.2 Binomialverteilung\n\n4.3.2.1 Grundlagen\n\nDefinition 4.9 (Binomialverteilung) Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines \\(n\\)-fach wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei5 Ergebnissen bzw. Elementarereignissen also. Dabei interessiert die Anzahl der \\(x\\) Treffer. Typisches Beispiel ist ein (wiederholter) MÃ¼nzwurf. Bei jeder Wiederholung des Zufallexperiments bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die MÃ¼nze verÃ¤ndert sich nicht durch die WÃ¼rfe (Ziehen mit ZurÃ¼cklegen, ZmZ). AuÃŸerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc.\\(\\square\\)\n\nFÃ¼r eine binomialverteilte Zufallsvariable \\(X\\) schreibt man kurz (s. GleichungÂ 4.1):\n\\[X \\sim \\text{Bin}(n, x) \\tag{4.1}\\]\n\n4.3.2.2 Veranschaulichung\nStellen wir uns eine Kistchen6 mit 5 Losen vor, darunter 2 Treffer (Gewinn) und 3 Nieten, s. Abb. AbbildungÂ 4.18. Der Versuch lÃ¤uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zurÃ¼ck und ziehen erneut.\n\n\n\n\n\n\n\nAbbildungÂ 4.18: Ein KÃ¤stchen mit 5 Losen, darunter 2 Treffer und 3 Nieten.\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nUm die Wahrscheinlichkeitsverteilung einer binomialverteilte Zufallsvariable ausrechnen zu kÃ¶nnen, muss man zwei Dinge wissen: Erstens die Anzahl der ZÃ¼ge, \\(n\\) (StichprobengrÃ¶ÃŸe) und zweitens die Trefferwahrscheinlichkeit, \\(p\\).\n\n\n\nÃœbungsaufgabe 4.2 (Vier Lose, zwei Treffer) Wie groÃŸ ist die Wahrscheinlichkeit von \\(A^{\\prime}\\), d.h. bei \\(n=4\\) ZÃ¼gen \\(x=2\\) Treffer zu erzielen (und \\(n-x=2\\) Nieten), gegeben dass die Trefferwahrscheinlichkeit bei \\(p=2/4\\) liegt? Wir ziehen dabei ohne ZurÃ¼cklegen (ZoZ). AuÃŸerdem sind die Lose nicht zu unterscheiden (abgesehen davon, ob es Treffer oder Nieten sind).\\(\\square\\)\n\nWir kÃ¶nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz, GleichungÂ 3.5), vgl. AbbildungÂ 3.15. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit, \\(W\\) (Additionssatz). Das ist einfach, dauert aber. In diesem Fall ist die Wahrscheinlichkeit eines (gÃ¼nstigen) Pfades, \\(A\\):\n\\(Pr(A) = Pr(T)^2 \\cdot Pr(N)^2 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right) ^2\\).\n\np_a = (2/5)^2 * (3/5)^2\np_a\n## [1] 0.0576\n\nEtwas mÃ¼hevolles ZÃ¤hlen der Pfade wÃ¼rde uns zeigen, dass es \\(k=6\\) Pfade gibt, die alle die gleiche Wahrscheinlichkeit, \\(Pr(A)\\), aufweisen. Damit betrÃ¤gt die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 4 ZÃ¼gen):\n\\(Pr(A^{\\prime}) = 6 \\cdot Pr(A)\\).\n\np_a_strich = 6 * p_a\np_a_strich\n## [1] 0.3456\n\nMithilfe der Formel der Binomialverteilung lÃ¤sst sich das Ergebnis, die Wahrscheinlichkeit von \\(A^{\\prime}\\) schneller ausrechnen. Einfach gesprochen sieht sie so aus:\n\\[Pr(A^{\\prime}) = k \\cdot Pr(A)\\] Dabei steht \\(k\\) fÃ¼r die Anzahl der gÃ¼nstigen Pfade und \\(Pr(A)\\) fÃ¼r die Wahrscheinlichkeit eines gÃ¼nstigen Pfades (d.h. 2 Treffer und 2 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\nDie Anzahl der Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt, s. GleichungÂ 4.2.7\n\nDefinition 4.10 (Binomialkoeffizient) Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von \\(n\\) verschiedenen Objekten \\(k\\) Objekte ziehen kann (ohne ZurÃ¼cklegen und ohne Beachtung der Reihenfolge).\n\\[k = \\tbinom{n}{k}= \\frac{n!}{k!(n-k)!}  \\tag{4.2}\\]\nLies: â€œWÃ¤hle aus \\(n\\) mÃ¶glichen Ereignissen (Pfade im Baum) \\(k\\) gÃ¼nstige Ereignisse (gÃ¼nstige Pfade) oder kÃ¼rzerâ€k aus nâ€.\n\n\nBeispiel 4.11 (Lotto) Wie viele Zahlenkombinationen gibt es im Lotto fÃ¼r 6 Richtige? Der Binomialkoeffizient verrÃ¤t es uns: \\(\\tbinom{49}{6}= 13\\,983\\,816\\square\\)\n\nAuf Errisch geht das so:\n\n\n\nğŸ‘¨â€ğŸ« Hey R, Wie viele MÃ¶glichkeiten gibt es, aus \\(n=4\\) Pfaden \\(k=2\\) auszuwÃ¤hlen?\n\n\n\nğŸ¤– Ã„h, Moment, oh herzliches Leberwesen\n\n\nchoose(4,2)\n## [1] 6\n\n\n\nHier ist ein Ãœberblick der mÃ¶glichen 6 gÃ¼nstigen Ereigniise des Experiments (2 Treffer bei 4 Versuchen): 1. TTNN, 2. TNTN, 3. TNNT, 4. NTTN ,5. NTNT, 6. NNTT.\n\nBeispiel 4.12 (BefÃ¶rderung) Aus einem Team mit 25 Personen sollen 11 Personen befÃ¶rdert werden. Wie viele mÃ¶gliche Kombinationen (von befÃ¶rderten Personen) kÃ¶nnen gebildet werden?\n\\(\\tbinom{25}{11} = \\frac{25!}{11!\\cdot(25-11)!} = 4\\,457\\,400\\)\nIn Errisch:\n\nchoose(n = 25, k = 11)\n## [1] 4457400\n\nEs gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht berÃ¼cksichtigt.\\(\\square\\)\n\n\n4.3.2.3 Formel der Binomialverteilung\nGleichungÂ 4.3 zeigt die mathematische Definition der Binomialverteilung. Dabei liegt immer ein Zufallsversuch mit \\(n\\) DurchgÃ¤ngen und \\(k\\) Treffern zugrunde. Jeder Durchgang hat die Trefferwahrscheinlichkeit \\(p\\) und jeder Durchgang ist unabhÃ¤ngig von allen anderen.\n\\[Pr(X=k|p,n) = \\frac{n}{k!(n-k)!}p^k(1-p)^{n-k} \\tag{4.3}\\]\nGleichungÂ 4.3 kann wie folgt auf Deutsch Ã¼bersetzen:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œW,Lâ€ gegeben p berechnet als Produkt von zwei Termen. Erstens der Quotient von der FakultÃ¤t von W plus L im ZÃ¤hler und im Nenner das Produkt von erstens der FakultÃ¤t von W mit zweitens der FakultÃ¤t von L. Der zweite Term ist das Produkt von p hoch W mal der komplementÃ¤ren Wahrscheinlichkeit von p hoch L.\n\nOder noch kÃ¼rzer:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œW,Lâ€ gegeben p berechnet als Produkt von zwei Termen. Erstens der Anzahl der gÃ¼nstigen Pfade, k und zweitens der Wahrscheinlichkeit fÃ¼r einen gÃ¼nstigen Pfad, P(A).\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange Ãœbersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und fÃ¼r uns ausrechnen. Los, R, mach mal.\n\n4.3.2.4 Rechnen mit R\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen.\nDie Wahrscheinlichkeit, bei 4 ZÃ¼gen 2 Treffer zu erzielen mit \\(p=2/5\\) unter der Annahme einer Binomialverteilung lÃ¤sst sich so mit R berechnen:\n\ndbinom(x = 2, size = 4, prob = 2/5)\n## [1] 0.3456\n\n\nBeispiel 4.13 (Pumpstation-Beispiel zur Binomialverteilung) In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% fÃ¤llt ein Motor aus und ist fÃ¼r den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie groÃŸ ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb fÃ¤llt?\n\\(Pr(X=k)\\) (oder kurz: \\(Pr(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an fÃ¼r das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(Pr(X=5)\\) ausrechnen.\n\ndbinom(x = 5, size = 7, prob = .95)\n## [1] 0.0406235\n\nEs gilt also \\(Pr(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist relativ gering8. Die Wahrscheinlichkeit, dass \\(k=0 \\ldots 7\\) Motoren laufen, ist in AbbildungÂ 4.19 dargestellt.\ndbinom() steht fÃ¼r die Wahrscheinlichkeitsdichte (im diskreten Fall, wie hier, Wahrscheinlichkeitsfunktion genannt) und binom fÃ¼r die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die StichprobengrÃ¶ÃŸe an (hier 7 Motoren).\nDamit gilt:\n\\(Pr(X\\ge 5) = Pr(X=5) + Pr(X=6) + Pr(X=7)\\)\nBerechnen wir zunÃ¤chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen:\n\np_5 &lt;- dbinom(x = 5, size = 7, prob = .95)\np_6 &lt;- dbinom(x = 6, size = 7, prob = .95)\np_7 &lt;- dbinom(x = 7, size = 7, prob = .95)\n\np_5\n## [1] 0.0406235\np_6\n## [1] 0.2572822\np_7\n## [1] 0.6983373\n\nDie gesuchte Wahrscheinlichkeit, p_mind_5, ist die Summe der drei Einzelwahrscheinlichkeiten:\n\np_mind_5 &lt;- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 0.996243\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betrÃ¤gt also 0.9962.\nDas Komplement zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also hÃ¶chstens 4 und es daher zu einem Ausfall kommt.\nNatÃ¼rlich gilt \\(Pr(\\bar{X}) = 1- Pr(X)\\).\n\np_weniger_als_4 &lt;- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.003757043\n\n\n\n\n\n\n\n\n\n\n(a) In â€˜normalerâ€™ Wahrscheinlichkeit, 0&lt;p&lt;1\n\n\n\n\n\n\n\n\n\n(b) In Log-Einheiten (Basis 2), â€˜Halbierungenâ€™\n\n\n\n\n\n\nAbbildungÂ 4.19: Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen\n\n\nAlternativ kann man mit der Verteilungsfunktion rechnen: \\(Pr(X \\le 4)\\).\nIn R kann man die Funktion pbinom() nutzen (p fÃ¼r (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen:\n\npbinom(q = 4, size = 7, prob = .95)\n## [1] 0.003757043\n\nq = 4 steht fÃ¼r \\(X \\le 4\\), also fÃ¼r hÃ¶chstens 4 Treffer (arbeitende Motoren); size = 7 meint die StichprobengrÃ¶ÃŸe, hier 7 Motoren.\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Funktion, die die Wahrscheinlichkeit dafÃ¼r angibt, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich (hÃ¶chstens) einem Wert \\(X=x\\) ist, heiÃŸt Verteilungsfunktion.\n\\(F(X=x) = Pr(X \\le x)\\)\n\n\n\n\n\n\n\n\nLogarithmus\n\n\n\nDer Logarithmus zur Basis 29 gibt die â€œVerdopplungenâ€ bzw. â€œHalbierungenâ€ der Wahrscheinlichkeit an, wobei \\(ld(1/2) = -1.\\square\\)\n\n\n\nBeispiel 4.14 \\(ld(1/2) = -1:\\)\n\nlog(.5, base = 2)\n## [1] -1\n\n1/2 ist genau â€œminus 1 Verdopplungâ€ von 1 entfernt, d.h. eine Halbierung.\n\\(ld(1/4) = -2:\\)\n\nlog(1/4, base = 2)\n## [1] -2\n\n1/2 ist genau â€œminus 2 Verdopplungenâ€ von 1 entfernt, d.h. zwei Halbierungen.\n\\(ld(1/8) = -3:\\)\n\nlog(1/8, base = 2)\n## [1] -3\n\n1/8 (0.125) ist 3 Halbierungen von 1 entfernt.\\(\\square\\)\n\n\nBeispiel 4.15 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?10\n\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.01478577\n\nUm hÃ¶chstens 15 Treffer zu erzielen, mÃ¼ssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern addieren.\nPraktischerweise gibt es einen R-Befehl, der das fÃ¼r uns Ã¼bernimmt:\n\npbinom(q = 15, size = 20, prob = .5)\n## [1] 0.994091\n\nDie Wahrscheinlichkeit 0, 1, 2, â€¦ oder 15 Treffer zu erzielen, liegt also bei gut 99%.\n\n\nBeispiel 4.16 (3 MÃ¼nzwÃ¼rfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\ndbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.125\n\nDie LÃ¶sung lautet also \\(p=1/8 = .125.\\qquad \\square\\)\n\n\n\n\n\n\n\n\n\nn=3, p=1/2\n\n\n\nn=9, p=.7\n\n\n\n\nVerschiedene Binomialverteilungen\n\n\n\n\nÃœbungsaufgabe 4.3 ğŸ‹ï¸ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear?\n\n\n4.3.2.5 Simulieren wir eine Binomialverteilung\nDie Binomialverteilung lÃ¤sst sich gut als â€œMÃ¼nzwurf-Verteilungâ€ auffassen.\nWerfen wir eine MÃ¼nze und sehen wir, was passiert.\n\nsample(x = c(0, 1), size = 1)\n## [1] 1\n\nMit sample() ziehen wir eine Stichprobe aus dem Ereignisraum x, hier 0 und 1. Dabei vereinbaren wir (willkÃ¼rlich), dass 0 fÃ¼r â€œKopfâ€ steht und 1 fÃ¼r â€œZahlâ€. size = 1 bedeutet, wir werfen die MÃ¼nze ein Mal (d.h. StichprobengrÃ¶ÃŸe size ist 1).\nOkay, noch an Bord? Dann werfen wir die MÃ¼nze 10 Mal:\n\nsample(x = c(0, 1), size = 10, replace = TRUE)\n##  [1] 0 1 1 1 1 0 0 1 0 1\n\nreplace = TRUE heiÃŸt, wir legen die MÃ¼nze wieder zurÃ¼ck auf den Tisch, wenn wir sie geworfen haben. Oder anders ausgedrÃ¼ckt: Ziehen mit ZurÃ¼cklegen.\nR, mach dich bereit, wirf die MÃ¼nze 1000 (\\(n=10^3\\) oder 1e3) Mal11:\n\nn &lt;- 1e3\n\nmuenze_oft &lt;- \n  sample(x = c(0, 1), size = n, replace = TRUE) \n\n\nmuenze_oft %&gt;% \n  sum()\n## [1] 539\n\nMit sum() nach dem Pfeifensymbol %&gt;% haben wir aus dem Vektor muenze_oft, der aus der ersten Zeile resultiert, die Summe ausgerechnet.\nJetzt wissen wir, wie oft die MÃ¼nze â€œZahlâ€ gezeigt hat, nÃ¤mlich 539 Mal.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie einen Zufallsversuch wiederholen, muss nicht jedes Mal das gleiche Ergebnis resultieren. Entsprechend wird bei wiederholten AusfÃ¼hrung der Funktion sample() nicht immer das gleiche Ergebnis resultieren. Wundern Sie sich also nicht, wenn bei Ihrem Computer eine Ã¤hnliche, aber nicht gleiche, Zahl herauskommt.\n\n\nVisualisieren wir mal unsere MÃ¼nzwÃ¼rfe. Dazu erstellen wir zuerst eine geeignete Tabelle, TabelleÂ 4.5.\n\nmuenz_tab &lt;-\n  tibble(\n    id = 1:n,\n    x = muenze_oft,\n    x_cumsum = cumsum(x) / id  # gibt Anteil von \"Zahl\" wieder\n  )\n\n\n\n\nTabelleÂ 4.5: Die kumulierte Summe beim MÃ¼nzwurf (nur die ersten paar Zeilen)\n\n\n\n  \n\n\n\n\n\n\nUnd hier der Anteil von â€œZahlâ€ im Verlauf unserer MÃ¼nzwÃ¼rfe, s. AbbildungÂ 4.20.12\n\n\n\n\n\n\n\nAbbildungÂ 4.20: Das Gesetz der groÃŸen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten MÃ¼nzwurf\n\n\n\n\nGrob gesagt scheint sich ein MÃ¼nzwurf nach, naja, vielleicht 500 WÃ¼rfen â€œeinigermaÃŸenâ€ zu stabilisieren.13\n\n\n\n\n\n\nDas Gesetz der groÃŸen Zahl\n\n\n\nZieht man (zufÃ¤llig) immer mehr Werte aus einer Verteilung (mit endlichem Mittelwert), nÃ¤hert sich der Mittelwert der Stichprobe immer mehr mit dem Mittelwert (oft als Erwartungswert bezeichnet) der Verteilung an.\n\n\n\n\n4.3.3 Normalverteilung\n\nDefinition 4.11 (Normalverteilung) Normalverteilungen haben eine charakteristische Glockenform; sie sind symmetrisch14. Normalverteilungen kÃ¶nnen sich unterscheiden in ihrem Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden GrÃ¶ÃŸen (â€œParameterâ€) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. AbbildungÂ 4.21. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\\(\\square\\)\n\nEine normalverteilte Zufallsvariable \\(X\\) mit einem bestimmten Mittelwert und einer bestimmten Streuung schreibt man kurz so:\n\\[X \\sim \\mathcal{N}(\\mu, \\sigma)\\]\n\nDefinition 4.12 (Parameter) Ein Parameter (einer Verteilung) legt die â€œVariantenâ€ einer Verteilung fest. Durch die Wahl der Parameterwerte nimmt eine Verteilung eine genaue Form an.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 4.21: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\n\nBeispiel: Wie groÃŸ sind Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%, vgl. TabelleÂ 4.6.\n\n\n\nTabelleÂ 4.6: Quantile der KÃ¶rpergrÃ¶ÃŸen von Studentis\n\n\n\n\n\n\nq25\nq50\nq75\n\n\n160.02\n167.64\n175.26\n\n\n\n\n\n\n\n\nAbbildungÂ 4.22 zeigt eine Visualisierung der Quantile.\n\n\n\n\n\n\n\nAbbildungÂ 4.22: Quantile verschieden visualisiert\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas 25%-Quantil nennt man 1. Quartil, das 50%-Quantil auch 2. Quartil, das 75%-Quantil das 3. Quartil, und das 100%-Quantil (Maximalwert) das 4. Quartil.\n\n\n\n4.3.3.1 Normal auf dem FuÃŸballfeld\nSie und 100 Ihrer besten Freunde stehen auf der Mittellinie eines FuÃŸballfelds. Auf Kommando werfen alle jeweils eine MÃ¼nze; bei Kopf geht man einen Schritt nach links, bei Zahl nach rechts. Das wird 16 Mal wiederholt. Wie wird die Verteilung der Positionen wohl aussehen?\n\n\n\n\n\n\n\n\n(McElreath 2020)\n\n4.3.3.2 Normal durch Addieren\nDie Summe vieler (gleich starker) Zufallswerte (aus der gleichen Verteilung) erzeugt eine Normalverteilung; egal aus welcher Verteilung die Zufallswerte kommen (Zentraler Grenzwertsatz), vgl. AbbildungÂ 4.23.\n\n\n\n\n\n\n\nAbbildungÂ 4.23: Entstehen einer Normalverteilung durch Addition vieler unabhgÃ¤ngiger Ereignisse\n\n\n\n\nVerwechseln Sie die Normalverteilung nicht mit der Paranormalverteilung, s. AbbildungÂ 4.24.\n\n\n\n\n\nAbbildungÂ 4.24: Die Paranormalverteilung\n\n\n\n4.3.3.3 Normalverteilung vs.Â randlastige Verteilungen\nBei randlastigen Verteilungen (â€œfat tailsâ€) kommen Extremereignisse viel hÃ¤ufiger vor als bei Normalverteilungen. Deshalb ist es wichtig sein, zu wissen, ob eine Normalverteilung oder eine randlastige Verteilung vorliegt. Viele statistische Methoden sind nicht zuverlÃ¤ssig bei (stark) randlastigen Methoden. AbbildungÂ 4.25 grenzt eine Normalverteilung von einer â€œFat-Tail-Verteilungâ€ ab.\n\n\n\n\n\n\n\nAbbildungÂ 4.25: Normalverteilung vs.Â randlastige Verteilungen\n\n\n\n\n\nBeispiel 4.17 (Beispiele fÃ¼r Normal- und randlastige Verteilungen) Â \n\n\nNormal verteilt:\n\nGrÃ¶ÃŸe\nMÃ¼nzwÃ¼rfe\nGewicht\nIQ\nBlutdruck\nAusschuss einer Maschine\n\n\nRandlastig verteilt:\n\nVermÃ¶gen\nVerkaufte BÃ¼cher (Anzahl)\nRuhm (z.B. Anzahl Follower auf Instagram)\nAktienkurse (Kurswert)\nErdbeben (StÃ¤rke)\nAnzahl von Todesopfern in Pandemien\nAnzahl von Todesopfern in Kriege\nErfolg auf Tinder (Anzahl erfolgreicher Matches)\nMeteroritengrÃ¶ÃŸe (Volumen)\nStadtgrÃ¶ÃŸen (Einwohnerzahl)\n\n\n\n\n\n4.3.3.4 Formel der Normalverteilung\nVereinfacht ausgedrÃ¼ckt lÃ¤sst die Normalverteilung \\(\\mathcal{N}\\) durch Exponenzieren einer Quadratfunktion beschreiben:\n\\[\\mathcal{N} \\propto e^{-x^2}\\]\nmit \\(e=2.71...\\), der Eulerschen Zahl.15\nWie man sieht (AbbildungÂ 4.26) ergibt sich eine Normalverteilung.\n\nd &lt;-\n  tibble(\n    x = seq(-3, 3, \n            length.out = 100),\n    y = exp(-x^2)\n  )\n\nggline(d, x = \"x\",y = \"y\")  # aus {ggpubr}\n\n\n\n\n\n\n\n\nAbbildungÂ 4.26: Wir basteln uns eine Normalverteilung\n\n\n\n\nEine Normalverteilung mit \\(\\mu=0\\) und \\(\\sigma=1\\) nennt man auch Standardnormalverteilung und man schreibt:\n\\[IQ \\sim \\mathcal{N}(0,1)\\]\nDie Normalverteilung wird auch Gauss-Verteilung oder Glockenkurve genannt.\n\n4.3.3.5 Simulation einer Normalverteilung\nR hat eine Funktion eingebaut zur Erzeugung von Zufallszahlen (Zufallszahlengenerator), z.B. normalverteilte. Man Ã¼bergibt dieser Funktion den gewÃ¼nschten Mittelwert und die gewÃ¼nschte Streuung und die Funktion zieht dann zufÃ¤llig Werte aus dieser Verteilung.\nDiesen Zufallszahlengenerator kann man mit einem Duschkopf vergleichen, s. AbbildungÂ 4.27. An diesem Duschkopf kann man einen Schwenker einstellen, der den Duschkopf ausrichtet, also steuert, ob die Wassertropfen weit in die eine oder die andere Richtugn fallen. Zweitens hat unser Duschkopf noch einen Streuregler, der den Wasserstrahl entweder eng bÃ¼ndelt16 oder weit auseinanderfÃ¤chert. Im ersten Fall fÃ¤llt der Wasserstrahl eng und schmal aus. Im zweiten Fall fÃ¤llt der Wasserstrahl breit aus.\n\n\n\n\n\nAbbildungÂ 4.27: Zufallszahlengenerator als Duschkopf\n\n\nQuelle: John Kruschke.\nEine Zufallszahl (random number), die normalverteilt ist, mit \\(\\mu=0\\) und \\(\\sigma=1\\) kann man in R so erzeugen:\n\nrnorm(n = 1, mean = 0, sd = 1)\n## [1] 0.2664096\n\nEin Fallbeispiel: Der Inhalt einer TÃ¼te mit Zucker, \\(X\\), sei normalverteilt mit \\(\\mu = 10002\\) g und \\(\\sigma=1.5\\) g. Aus vertragsrechtlichen GrÃ¼nden darf das FÃ¼llgewicht von 1000g nicht unterschritten werden, sonst drohen Konventionalstrafen.\nWie groÃŸ ist die Wahrscheinlichkeit, dass 1000g unterschritten werden?\nSimulieren wir uns 1e4 ZuckertÃ¼ten!\n\nn &lt;- 1e4\nd &lt;- \n  tibble(\n    id = 1:n,\n    x = rnorm(n = n, mean = 1002, sd = 1.5)\n  )\n\nhead(d)\n\n\n  \n\n\n\nZÃ¤hlen wir, viele der ZuckertÃ¼ten ein Gewicht von weniger als 1000g aufweisen:\n\nd %&gt;% \n  count(x &lt; 1000)\n\n\n  \n\n\n\nEin ziemlich17 kleiner Anteil. Rechnen wir uns noch die Anteile (proportion) aus:\n\nd %&gt;% \n  count(x &lt; 1000) %&gt;% \n  mutate(prop = n/1e4)\n\n\n  \n\n\n\n\n4.3.3.6 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. AbbildungÂ 4.28:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\nÃœbungsaufgabe 4.4 (Wie schlau muss man (nicht) sein?) Â \n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu gehÃ¶ren?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, â€¦ der Leute nicht Ã¼berschritten?\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 4.28: Visualisierung der theoretischen IQ-Verteilung\n\n\nQuelle:: John Kruschke.\n\n\nZiehen wir zufÃ¤llig \\(1e4\\) Stichproben aus \\(\\mathcal{N}(100,15)\\) und berechnen die Quantile, s. TabelleÂ 4.7.\n\nd &lt;-\n  tibble(\n  iq = rnorm(n = 1e4, \n             mean = 100, \n             sd = 15))\n\nprobs &lt;- c(0.75,.5,.25,.05,.01)\n\nd_summary &lt;- d %&gt;% \n  summarise(p = probs,\n            q = quantile(iq, probs))\n\n\n\n\n\nTabelleÂ 4.7: Quantile der IQ-Verteilung\n\n\n\n\n\n\np\nq\n\n\n\n0.75\n110\n\n\n0.50\n100\n\n\n0.25\n90\n\n\n0.05\n75\n\n\n0.01\n65\n\n\n\n\n\n\n\n\n\n\n\nDas Quantil \\(q\\) zur kumulierten Wahrscheinlichkeit \\(p=75\\) ist 110, etc.\nUmgekehrt kÃ¶nnen wir uns auch fragen: Gegeben einer Realisation der Zufallsvariablen (z.B. IQ), was ist die zugehÃ¶rige Wahrscheinlichkeit (Wert der Verteilungsfunktion?)\n\nÃœbungsaufgabe 4.5 (Wie schlau muss man (nicht) sein, Teil 2) Â \n\nWelcher Anteil der FlÃ¤che unter der Kurve \\(p\\) gehÃ¶rt zu den IQ-Werten 75, 100, 115, 130?\nAnders gesagt: Welcher Anteil der Wahrscheinlichkeitsmasse der Verteilung liegt unter IQ=75, IQ=100, etc.?\\(\\square\\)\n\n\n\nZiehen wir Stichproben aus \\(\\mathcal{N}(100,15)\\). Was ist die Wahrscheinlichkeit fÃ¼r eine iq &lt; 100?\n\nd &lt;-\n  tibble(\n    iq = rnorm(1e4, \n               mean = 100, \n               sd = 15)) %&gt;% \n  mutate(iq = round(iq))\n\nqs &lt;- c(75,100,115,130)\n\nd %&gt;% \n  count(p_100 = iq &lt; 100) %&gt;% \n  mutate(prop = n / sum(n)) \n\nTabelleÂ 4.8 zeigt uns die Antwort.\n\n\n\n\n\n\nHinweis\n\n\n\nWir schÃ¤tzen die wahre, â€œtheoretischeâ€ Wahrscheinlichkeit durch einfaches Ausprobieren: Wir fÃ¼hren das Zufallsexperiment einfach hÃ¤ufig durch. Dann zÃ¤hlen wir den Anteil der Treffer. Nennt man auch â€œSimulierenâ€; klingt cooler als â€œAusprobierenâ€.ğŸ¤“\\(\\square\\)\n\n\n\n\n\nTabelleÂ 4.8: Wahrscheinlichkeit fÃ¼r iq &lt; 100\n\n\n\n\n\n\np_100\nn\nprop\n\n\n\nFALSE\n5143\n0.51\n\n\nTRUE\n4857\n0.49\n\n\n\n\n\n\n\n\n\nAnstelle von iq &lt; 100 kann man iq &lt; 115 einsetzen, etc.\nDie Verteilungsfunktion (der Anteil der Wahrscheinlichkeitsmasse), p, fÃ¼r IQ-Werte nicht grÃ¶ÃŸer als 100, \\(IQ\\le100\\), ist 50%, etc.\n\n4.3.3.7 Quantile der Normalverteilung\nğŸ’¡ Zur Erinnerung: Quantile teilen eine Verteilung so ein, dass ein Anteil \\(p\\) kleiner oder gleich und der andere Teil \\(1-p\\) grÃ¶ÃŸer dem Quantil \\(q\\) ist.\n\nBeispiel 4.18 â€œ50%-Quantil = 100â€ meint, dass 50% der Elemente der Verteilung einen Wert kleiner oder gleich als 100 haben. Man schreibt auch: q(.5) = 100.\n\nğŸ’¡ Zur Erinnerung: Die Verteilungsfunktion F (fÃ¼r einen Wert \\(x\\) der Zufallsvariable \\(X\\)) gibt die Wahrscheinlichkeit an, dass \\(X\\) einen Wert hÃ¶chstens so groÃŸ wie \\(x\\) annimmt. Sie zeigt also die kumulierte Wahrscheinlichkeit \\([-\\infty, q)\\).\n\nBeispiel 4.19 â€œF(100) = 50%â€ meint: Die Wahrscheinlichkeit fÃ¼r eine AusprÃ¤gung von hÃ¶chstens als 100 betrÃ¤gt 50%.\\(\\square\\)\n\nSchauen wir uns die Quantile der Normalverteilung einmal nÃ¤her an. Wir gehen von einer Normalverteilung aus, wie sie zur Beschreibung von Intelligenz (IQ) verwendet wird, s. AbbildungÂ 4.29.\n\n\n\n\n\n\n\nAbbildungÂ 4.29: Quantile der Normalverteiltung\n\n\n\n\n\\[IQ \\sim \\mathcal{N}(100, 15)\\] Mit R kann man sich die beiden GrÃ¶ÃŸen komfortabel berechnen lassen:\n\nqnorm(.50, mean = 100, sd = 15)  # 50%-Quantil\npnorm(100, mean = 100, sd = 15)  # Verteilungsfunktion fÃ¼r IQ=100\n\nBetrachten wir einige wichtigen Quantile, s. AbbildungÂ 4.30.\n\n\n\n\n\n\n\nAbbildungÂ 4.30: Verschiedene Quantil der Normalverteilung\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.31: Die Quantile fÃ¼r 10%, 20%, â€¦ 100% visualisiert\n\n\n\n4.3.3.8 Standardnormalverteilung\n\n\n\n\n\n\n\n\n\nAbbildungÂ 4.32: Normalverteilung mit Mittelwert 0 und SD 1, auch Standard-Normalverteilung genannt\n\n\n\n\n\nBei \\(X=0\\) einer Standard-Normalverteilung (s. AbbildungÂ 4.32) gilt:\n\nhat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 40% (Wahrscheinlichkeitsdichte)\nsind 50% der Wahrscheinlichkeitsmasse (FlÃ¤che unter der Kurve) kleiner als dieser Wert (Verteilungsfunktion).\n\nIn Summe liegen 100% der Wahrscheinlichkeitsmasse unter der Kurve.\n\n\n\n4.3.3.9 Normalverteilung als konservative Wahl\nDem Mathematiker Carl Friedrich Gauss (s. AbbildungÂ 4.33) wird die Ehre zuerkannt, die Normalverteilung eingefÃ¼hrt zu haben.\n\n\n\n\n\n\n\nAbbildungÂ 4.33: Zehn-Mark-Geldschein mit Gauss und Normalverteilung\n\n\n\n\nQuelle: Uni Greifswald, Public domain, via Wikimedia Commons\n\n\n\n\n\n\nHinweis\n\n\n\nOntologische BegrÃ¼ndung\n\nWirken viele, gleichstarke EinflÃ¼sse additiv zusammen, entsteht eine Normalverteilung (McElreath 2020), Kap. 4.1.4.\n\nEpistemologische BegrÃ¼ndung\n\nWenn wir nur wissen, dass eine Variable Ã¼ber einen endlichen Mittelwert und eine endliche Varianz verfÃ¼gt und wir keine weiteren Annahmen treffen bzw. Ã¼ber kein weiteres Vorwissen verfÃ¼gen, dann ist die Normalverteilung die plausibelste Verteilung (maximale Entropie) (McElreath 2020), Kap. 7 und 10.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#vertiefung",
    "href": "0400-Verteilungen.html#vertiefung",
    "title": "\n4Â  Verteilungen\n",
    "section": "\n4.4 Vertiefung",
    "text": "4.4 Vertiefung\nBourier (2018), Kap. 6.2 und 7.1 erlÃ¤utert einige (grundlegende) theoretische HintergrÃ¼nde zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar ist dabei die Binomialverteilung.\nMittag und SchÃ¼ller (2020) stellen in Kap. 12 und 13 Zufallsvariablen vor; zum Teil geht die Darstellung dort Ã¼ber die Lernziele bzw. Inhalte dieses Kurses hinaus.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#aufgaben",
    "href": "0400-Verteilungen.html#aufgaben",
    "title": "\n4Â  Verteilungen\n",
    "section": "\n4.5 Aufgaben",
    "text": "4.5 Aufgaben\nZusÃ¤tzlich zu den Aufgaben in der genannten Literatur sind folgende Aufgaben zu empfehlen.\n\nQuiz (Aufgabensammlung) zu Verteilungen\nBsp-Binomial\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08  \nBus1\nalphafehler-inflation2\nalphafehler-inflation3\nalphafehler-inflation4",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0400-Verteilungen.html#section",
    "href": "0400-Verteilungen.html#section",
    "title": "\n4Â  Verteilungen\n",
    "section": "\n4.6 â€”",
    "text": "4.6 â€”\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMittag, Hans-Joachim, und Katharina SchÃ¼ller. 2020. Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4.",
    "crumbs": [
      "Wahrscheinlichkeit",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#lernsteuerung",
    "href": "0500-Globusversuch.html#lernsteuerung",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n5.1.2 Ãœberblick\nIn diesem Kapitel Ã¼bersetzen wir eine Problemstellung (Forschungsfrage) in ein (mathematisches) Modell, das uns dann mit Hilfe der Bayes-Formel Antworten auf die Problemstellung gibt.\n\n5.1.3 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nUnterschiede zwischen Modellen und der RealitÃ¤t erlÃ¤utern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (fÃ¼r binomial verteilte Zufallsvariablen)\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\nPost-Wahrscheinlichkeiten anhand der Gittermethode berechnen\n\n5.1.4 Begleitliteratur\nDer Stoff dieses Kapitels deckt einen Teil aus McElreath (2020), Kap. 2, ab. McElreath (2020) stellt das Globusmodell mit mehr ErlÃ¤uterung und etwas mehr theoretischem Hintergrund vor, als es in diesem Kapitel der Fall ist.\n\n5.1.5 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. â€œDaten Einlesenâ€\n\n5.1.6 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(ggpubr)  # komfortable Visualisierung",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#von-welten-und-golems",
    "href": "0500-Globusversuch.html#von-welten-und-golems",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.2 Von Welten und Golems",
    "text": "5.2 Von Welten und Golems\n\n5.2.1 Kleine Welt, groÃŸe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb AbbildungÂ 5.1.\n\n\n\n\n\nAbbildungÂ 5.1: Behaims Globus: Kein Amerika\n\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der groÃŸen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die groÃŸe Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.\n\nğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht! \\(\\square\\)\n\n\n5.2.2 Der Golem von Prag\n\n\n\n\n\nAbbildungÂ 5.2: Der Golem von Prag\n\n\nQuelle\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt, s. AbbildungÂ 5.2. Die Geschichte besagt, dass ein Rabbi mit ZauberkrÃ¤ften den Golem aus Lehm erschuf, um die jÃ¼dische BevÃ¶lkerung der Stadt zu schÃ¤tzen. Bei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen. Bei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.\n\n5.2.3 Wissenschaftliche Modelle sind wie Golems\n\n\nâ€œYeah, ich bin ein Golem!â€ - Bildquelle: Klara Schaumann\n\n\n\nGolem\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch â€œWahrheitâ€\nMÃ¤chtig\ndumm\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nMÃ¤rchen\n\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mÃ¤chtig\nsimpler als die RealitÃ¤t\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nNicht einmal falsch\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildungÂ 2.4 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen (TabelleÂ 5.1), wie z.B. Behaims Globus, mit der GroÃŸen Welt, die Kolumbus und wir befahren.\n\n\nTabelleÂ 5.1: Kleine Welt vs.Â groÃŸe Welt\n\n\n\n\n\n\n\nKleine Welt\nGroÃŸe Welt\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit\nentspricht nicht (zwangslÃ¤ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n5.2.4 Die Bayes-Formel und Lernen\nğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!\\(\\square\\)",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.3 Ein erster Versuch: Wir werfen den Globus\n\n5.3.1 Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?\n\nBeispiel 5.1 (Wasseranteil auf der ErdoberflÃ¤che) Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (AbbildungÂ 5.3)? Um mÃ¶glichst wenig schreiben zu mÃ¼ssen, schreiben wir fÃ¼r â€œangenommener Wasseranteil auf der ErdoberflÃ¤cheâ€ kurz \\(p\\) (wie proportion, Anteil). \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 5.3: Die Erde. SchÃ¶n! Und mit viel Wasser, ca. 70% der ErdoberflÃ¤che sind mit Wasser bedeckt.\n\n\nQuelle CC 4.0 BY-NC\nAnalog kÃ¶nnen wir uns vorstellen, 11 Wissenschaftlis haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus â€¦ die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.2\nSo sah mein3 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\nAlso \\(W=6\\) und \\(L=3\\).\n\nÃœbungsaufgabe 5.1 ğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!\\(\\square\\)\n\n\n5.3.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten fÃ¼hrt, nennt man den datengenierenden Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der ErdoberflÃ¤che ist \\(\\pi\\) (und \\(1-\\pi\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballs hat die Wahrscheinlichkeit \\(\\pi\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie WÃ¼rfe des Globusballs sind unabhÃ¤ngig voneinander.\nWir haben kein Vorwissen Ã¼ber \\(\\pi\\); jeder Wert ist uns gleich wahrscheinlich.\n\n\nÃœbungsaufgabe 5.2 ğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?\\(\\square\\)\n\n\n5.3.3 Ein paar Fachbegriffe\n\nDefinition 5.1 (Priori-Verteilung) FÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: Priori-Verteilung.\\(\\square\\)\n\n\nDefinition 5.2 (Likelihood) FÃ¼r jede Hypothese (d.h. jeden Parameterwert \\(\\pi\\)) mÃ¶chten wir wissen, wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Kurz: Wir suchen die Likelihood. Anders gesagt: Die Likelihood sagt uns, wie gut die Daten zu einer bestimmten Hypothese passen.\\(\\square\\)\n\n\nDefinition 5.3 (Posteriori-Verteilung) Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung4 bekommen.\\(\\square\\)\n\n\n5.3.4 Bayes-Updates\nDer Golem denkt eigentlich ganz vernÃ¼nftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugehÃ¶rige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung. In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als nÃ¤chstes beschaut sich der Golem die Daten und Ã¼berlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 10% betrÃ¤gt. Die zugehÃ¶rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die5 Likelihood. Als letztes bildet sich der Golem eine abschlieÃŸende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder â€œgeupdatetâ€, s. AbbildungÂ 5.4.\n\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]--&gt;B[Likelihood]--&gt;C[Post-Vert.]--&gt;A\n\n\n\n\nAbbildungÂ 5.4: Updating mit Bayes\n\n\n\n\n\nÃœbungsaufgabe 5.3 (Wie gut passen die Daten zur Hypothese, dass die Erde komplett trocken ist?) Wir haben in unseren Versuch \\(W=6\\) und \\(L=3\\) erzielt. Diese Daten passen Ã¼berhaupt nicht zur Hypothese, dass die ErdoberflÃ¤che komplett trocken ist. Die Likelihood, \\(L\\) fÃ¼r \\(\\pi=0\\) ist also Null. Analog ist die Likelihood fÃ¼r \\(\\pi=1\\) auch Null.\\(\\square\\)\n\n\n5.3.5 Wie wahrscheinlich ist ein Wasseranteil von 90%?\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer (bei 9 WÃ¼rfen) zu erhalten, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 90%) annimmt? Diese Wahrscheinlichkeit nennt man die Likelihood, \\(L\\) oder \\(L\\).\n\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert6. Der Wasseranteil der Erde bleibt wÃ¤hrend des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser \\(\\pi\\) betrÃ¤gt, so bezeichnen: \\((Pr(W,L | \\pi))\\). Diese Wahrscheinlichkeit, \\((Pr(W,L | \\pi))\\), kann man mit der Binomialverteilung berechnen.\nMÃ¶chte man die Wahrscheinlichkeit ansprechen fÃ¼r das Ereignis â€œ5 mal Wasser und 2 mal Land, wenn wir von einem Wasseranteil von 70% ausgehenâ€, so wÃ¼rden wir kurz schreiben: \\(Pr(W=5, L=2 | \\pi=.7)\\). Oder noch kÃ¼rzer: \\(Pr(W=5 | \\pi=.7)\\), denn bei 7 WÃ¼rfen, von denen 5 \\(W\\) gezeigt haben, ist die Anzahl von \\(L\\) festgelegt.\nDie Binomialverteilung zeigt die Verteilung der HÃ¤ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten): â€œMÃ¼nzwurfverteilungâ€, s. Kap. KapitelÂ 4.3.2.\n\n5.3.6 Binomialverteilung mit R\nPraktischerweise ist die Binomialverteilung in R eingebaut, wie wir gleich sehen werden.\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(N=W+L=3\\) WÃ¼rfen zu bekommen, wenn wir von \\(\\pi=1/2\\) ausgehen?7.\n\ndbinom(x = 2, size = 3, prob = 1/2)\n## [1] 0.375\n\nVon den 8 Endkonten bzw. Pfaden sind 3 gÃ¼nstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 WÃ¼rfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-&gt; B[B - 0]\n  A -. 1/2 .-&gt; C[C - 1]\n  B -. 1/2 .-&gt; D[D - 0]\n  B -. 1/2 .-&gt; E[E - 1]\n  C -. 1/2 .-&gt; F[F - 0]\n  C -. 1/2 .-&gt; G[G - 1]\n  D -. 1/2 .-&gt; H[H - 0]\n  D -. 1/2 .-&gt; J[I - 1]\n  E -. 1/2 .-&gt; K[K - 0]\n  E -. 1/2 .-&gt; L[L - 1]\n  F -. 1/2 .-&gt; M[M - 0]\n  F -. 1/2 .-&gt; N[N - 1]\n  G -. 1/2 .-&gt; O[O - 0]\n  G -. 1/2 .-&gt; P[P - 1]\n\n\n\n\nAbbildungÂ 5.5: Wir werfen den Globus (oder eine MÃ¼nze) 3 Mal\n\n\n\n\nAbb. AbbildungÂ 5.5 stellt einen einfachen Baum fÃ¼r 3 GlobuswÃ¼rfe mit je zwei mÃ¶glichen Ereignissen (W vs.Â L) dar. In der ersten (obersten) Zeile (Knoten A; â€œStartâ€) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) mÃ¶gliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nFÃ¼r mehr WÃ¼rfe wÃ¼rde das Diagramm irgendwann unÃ¼bersichtlich werden.\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\ndbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.1640625\n\nAbbildungÂ 5.6 zeigt die Binomialverteilung \\(X \\sim Bin(9, 1/2)\\).\n\n\n\n\n\n\n\nAbbildungÂ 5.6: Ein Beispiel fÃ¼r eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\n\n\n\nAbb AbbildungÂ 5.7 ist ein vergeblicher Versuch, so einen groÃŸen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum VerstÃ¤ndnis, kommen aber bei grÃ¶ÃŸeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.7: Wir werfen den Globus (oder eine MÃ¼nze) 9 Mal, es resultieren 512 Endknoten. Nicht gerade Ã¼bersichtlich.\n\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 5.2 (Globus mit 9 Treffern bei 9 WÃ¼rfen) Was ist die Wahrscheinlichkeit fÃ¼r \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\ndbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.001953125\n\nDas ist 1 gÃ¼nstiger Pfad von 512 Pfaden.\n\ndbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zurÃ¼ck, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\n\n5.3.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen, s. GleichungÂ 5.1.\n\\[W \\sim \\text{Bin}(N,\\pi) \\tag{5.1}\\]\nLies: â€œW ist binomial verteilt mit den Parametern \\(N\\) und \\(\\pi\\)â€. \\(N\\) gibt die Anzahl der GlobuswÃ¼rfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (â€œuniformâ€):\n\\[\\pi \\sim \\text{Unif}(0,1).\\]\nLies: â€œ\\(\\pi\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1â€.\nMan kÃ¶nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (aprior) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#das-globus-modell-als-bayes-theorem",
    "href": "0500-Globusversuch.html#das-globus-modell-als-bayes-theorem",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.4 Das Globus-Modell als Bayesâ€™ Theorem",
    "text": "5.4 Das Globus-Modell als Bayesâ€™ Theorem\nğŸ“º Globusversuch\n\n5.4.1 Von gemeinsamer zur bedingen Wahrscheinlichkeit\nErinnerung wir uns (BeispielÂ 3.22): Die Wahrscheinlichkeit fÃ¼r Regen und kalt ist gleich der Wahrscheinlichkeit von Regen, gegeben kalt mal der Wahrscheinlichkeit von kalt; das ist die Kettenregel (DefinitionÂ 3.17).\nEntsprechend gilt:\nDie gemeinsame Wahrscheinlichkeit fÃ¼r die beiden Ereignisse \\(W\\) (z.B. 6 Mal Wasser zu erhalten bei 9 Versuchen) und \\(A\\) (z.B. dass der Wasseranteil der ErdoberflÃ¤che 70% betrÃ¤gt) lÃ¤sst sich ebenso mit der Kettenregel der Wahrscheinlichkeitsrechnung bestimmen:\n\n\\[Pr(W,A) = Pr(W|A) \\cdot Pr(A)\\]\nLaut der Kettenregel ist â€œDrehenâ€ erlaubt:\n\\[Pr(A,W) = Pr(A|W) \\cdot Pr(W)\\]\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W|p) \\cdot Pr(A) = Pr(A|W) \\cdot (W)\\]\nUnd dann lÃ¶sen wir auf nach der Posteriori-Wahrscheinlichkeit8, \\(Pr(A|W)\\), voilÃ ! Wir haben Bayesâ€™ Theorem genutzt, um die gesuchte GrÃ¶ÃŸe, \\(Pr(A|W)\\), zu bestimmen, s. GleichungÂ 5.2.\n\\[Pr(A|W) = \\frac{Pr(W|A) \\times Pr(A)}{Pr(W)} \\tag{5.2}\\]\n\\(Pr(W)\\) nennt die Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods Ã¼ber alle Werte von \\(W\\), vgl. DefinitionÂ 3.18:\n\\(Pr(W) = Pr(W|A) \\times Pr(A) + Pr(\\neg W| \\neg A) \\times Pr(\\neg A)\\)\nDie Aufgabe der Evidenz ist nur dafÃ¼r zu sorgen, dass der Bruch insgesamt nur Werte zwischen 0 und 1 annehmen kann.\n\n5.4.2 Bayesâ€™ Theorem als Formel\nGesucht ist die Wahrscheinlichkeit einer Hypothese gegeben einer bestimmten Datenlage, \\(Pr(H|D)\\):\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)} = \\frac{\\text{Likelihood}  \\cdot \\text{Priori}}{\\text{Evidenz}}\\]\nSchauen wir uns die Bestandteile von Bayesâ€™ Theorem noch etwas nÃ¤her an:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayesâ€™ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) fÃ¼ttert.\nBayesâ€™ Theorem wird verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n5.4.3 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Post-Wahrscheinlichkeit \\(Pr_{\\text{unPost}}\\) ist einfach das Produkt von Likelihood und Priori, s. GleichungÂ 5.3.\n\\[Pr_{\\text{unPost}} = L \\times \\text{Priori} \\tag{5.3}\\]\nDas Standardisieren dient wie gesagt nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung GleichungÂ 5.4.\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}} \\tag{5.4}\\]\nAbb. AbbildungÂ 5.8 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\n\n\n\nAbbildungÂ 5.8: Prior mal Likelihood = Post\n\n\n\n5.4.4 Wissen updaten: Wir fÃ¼ttern Daten in das Modell\nGolems kÃ¶nnen lernen?! AbbildungÂ 5.9 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. WÃ¼rfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich fÃ¼r den Golem (das Modell). Je nach Ergebnis des Wurfes verÃ¤ndert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung verÃ¤ndert sich in AbhÃ¤ngigkeit von den Daten.\n\n\n\n\n\nAbbildungÂ 5.9: Unser Golem lernt\n\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "href": "0500-Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.5 Bayes berechnen mit mit dem Bayes-Gitter",
    "text": "5.5 Bayes berechnen mit mit dem Bayes-Gitter\nWir erstellen uns eine kleine Tabelle, die man â€œBayes-Gitterâ€ nennen kÃ¶nnte. Dazu gehen wir so vor:\n\n5.5.1 Idee\n\nTeile den Wertebereich des Parameter in ein â€œGitterâ€ auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\).\nWÃ¤hle den Priori-Wert des Parameters fÃ¼r jeden Gitterwert, z.B. 1/10 bei einer Gleichverteilung von 0 bis 1.\nBerechne den Likelihood fÃ¼r jeden Parameterwert.\nBerechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Parameterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nFÃ¼r jeden Parameterwert berechnen wir eine (Post-)Wahrscheinlichkeit.9 HÃ¤ufig entspricht eine Hypothese einem Parameterwert, etwa wenn man sagt: â€œIch glaube, die MÃ¼nze ist fairâ€, was auf einem Parameterwert von 50% herauslÃ¤uft. Dazu geben wir an, fÃ¼r wie wahrscheinlich wie apriori10 - also bevor wir irgendwelche Daten erheben - jeden einzelnen Gitterwert halten. Wir machen es uns hier einfach und halten jeden Gitterwert fÃ¼r gleich wahrscheinlich. TatsÃ¤chlich ist der konkrete Wert hier egal, entscheidend ist das VerhÃ¤ltnis der Apriori-Werte zueinander: Geben wir einigen Gitterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere fÃ¼r (apriori) doppelt so plausibel wie Letztere. Der Likelihood wird in diesem Fall mit der Binomialverteilung berechnet. Der Likelihood gibt an, wie wahrscheinlich ein Gitterwert ist gegeben einem bestimmten apriori gewÃ¤hlten Parameterwert. Die â€œEnd-Wahrscheinlichkeitâ€, die unstandardisierte Post-Wahrscheinlichkeit, die â€œhinten rauskommtâ€ ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet11. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen mÃ¶chten, teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die AnsprÃ¼che an eine Wahrscheinlichkeitsverteilung erfÃ¼llt (vgl. KapitelÂ 3.1.8.5).\n\n5.5.2 Bayes-Gitter in R berechnen\nLegen wir uns eine Tabelle mit Gitterwerten an, um deren Posteriori-Wahrscheinlichkeit zu berechnen.\nEin paar Vorarbeiten. Zuerst wÃ¤hlen wir unsere Parameterwerte; sagen wir 0, 0.1, 0.2, â€¦ , 1:\n\np_Gitter &lt;- seq(from = 0, to = 1, by = 0.1)\np_Gitter\n##  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 WÃ¼rfen) gegeben jeweils eines Gitterwerts:\n\nLikelihood &lt;- dbinom(6, size = 9, prob = p_Gitter)\nLikelihood\n##  [1] 0.000000000 0.000061236 0.002752512 0.021003948 0.074317824 0.164062500\n##  [7] 0.250822656 0.266827932 0.176160768 0.044641044 0.000000000\n\nDann packen wir das alles in eine Tabelle, s. TabelleÂ 5.2.\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (das \"Gitter\"): \n    p_Gitter = p_Gitter,\n    # bestimme den Priori-Wert:       \n    Priori  = .1) %&gt;%  \n    mutate(\n      # berechne Likelihood fÃ¼r jeden Gitterwert:\n      Likelihood = Likelihood,\n      # berechne unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:\n      Evidenz = sum(unstd_Post),\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / Evidenz)  \n\nDas â€œBayes-Gitterâ€ (TabelleÂ 5.2) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\nTabelleÂ 5.2: Die Bayes-Box fÃ¼r den Globusversuch\n\n\n\n\nid\np_Gitter\nPriori\nLikelihood\nunstd_Post\nEvidenz\nPost\n\n\n\n1\n0.0\n0.1\n0.00\n0.00\n0.1\n0.00\n\n\n2\n0.1\n0.1\n0.00\n0.00\n0.1\n0.00\n\n\n3\n0.2\n0.1\n0.00\n0.00\n0.1\n0.00\n\n\n4\n0.3\n0.1\n0.02\n0.00\n0.1\n0.02\n\n\n5\n0.4\n0.1\n0.07\n0.01\n0.1\n0.07\n\n\n6\n0.5\n0.1\n0.16\n0.02\n0.1\n0.16\n\n\n7\n0.6\n0.1\n0.25\n0.03\n0.1\n0.25\n\n\n8\n0.7\n0.1\n0.27\n0.03\n0.1\n0.27\n\n\n9\n0.8\n0.1\n0.18\n0.02\n0.1\n0.18\n\n\n10\n0.9\n0.1\n0.04\n0.00\n0.1\n0.04\n\n\n11\n1.0\n0.1\n0.00\n0.00\n0.1\n0.00\n\n\n\n\n\n\n\n\nFÃ¼r jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood:\n\\(\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood}\\)\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Gitterbox (also fÃ¼r jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn der Priori-Wert fÃ¼r jeden Gitterwert gleich ist, dann ist der Likelihood gleich der unstandardisierten Post-Wahrscheinlichkeit.\\(\\square\\)\n\n\n\nğŸ‹ï¸ Was wohl mit Post passiert, wenn wir Priori Ã¤ndern?\\(\\square\\)\n\nAbbildungÂ 6.1 zeigt eine Visualisierung der Post-Verteilung mit Hilfe der Funktion ggline() aus dem Paket ggpubr.\n\n\n\nlibrary(ggpubr)\n\nggline(d,\n       x = \"p_Gitter\",\n       y = \"Post\")\n\n\n\n\n\n\nDie Post-Verteilung visualisiert\n\n\n\n\n\n\n5.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: â€œPost-Verteilungâ€), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten, jetzt, nachdem wir die Daten des Versuchs kennen.\nAbbildungÂ 5.10 zeigt die Post-Wahrscheinlichkeit fÃ¼r 5, 10 und 20 Parameterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben.\n\n\n\n\n\nAbbildungÂ 5.10: Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen UmstÃ¤nden gilt:\n\nMehr Gitterwerte glÃ¤tten die AnnÃ¤herung.\nJe grÃ¶ÃŸer die Stichprobe (\\(N\\)), desto zuverlÃ¤ssiger wird unsere Berechnung.\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer TrÃ¤ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung kÃ¶nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nÃ¤chsten Kapitels.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#abschluss",
    "href": "0500-Globusversuch.html#abschluss",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.6 Abschluss",
    "text": "5.6 Abschluss\n\n5.6.1 Zusammenfassung\nğŸ“º Ãœbung zum Globusversucht\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.\n\nğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r \\(W\\) tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)?\n\n5.6.2 Der Globusversuch als Modell fÃ¼r zweiwertige Zufallsversuche\nDer Globusversuch ist kein prototypisches Beispiel fÃ¼r Statistik in der Praxis, zumindest nicht auf dem ersten Blick. Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist. Bei nÃ¤herer Betrachtung ist der Globusversuch prototypisch fÃ¼r ganz viele Fragestellungen:\n\nVon einem neuen Produkt von von \\(n\\) Exemplaren \\(k\\) verkauft. Auf welchen Wert \\(p\\) kann die Akzeptanzrate dieses Produkts geschÃ¤tzt werden?\nEin Chat-Bot hat von \\(n\\) Fragen \\(k\\) richtig beantwortet. Wie hoch kann die VerstÃ¤ndnisrate \\(p\\) dieses Programms geschÃ¤tzt werden?\nEine neue Krebstherapie hat von \\(n\\) â€œaustherapiertenâ€ Patientis \\(k\\) geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie geschÃ¤tzt werden?\n\nKurz: Der Globusversuch ist ein Muster fÃ¼r zweiwertige Zufallsversuche. Und solche sind hÃ¤ufig im Leben, im Business und in der Wissenschaft.\n\n5.6.3 Halbzeit-Quiz\nTesten Sie Ihr Wissen mit diesem Halbzeit-Quiz. Viel Erfolg! ğŸ€ğŸ€ğŸ€",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#vertiefung",
    "href": "0500-Globusversuch.html#vertiefung",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.7 Vertiefung",
    "text": "5.7 Vertiefung\nDas â€œBayes-Paradox-Videoâ€ von 3b1b prÃ¤sentiert eine gut verstÃ¤ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber Ã¤hnlichen Darstellung wie in diesem Kapitel.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#aufgaben",
    "href": "0500-Globusversuch.html#aufgaben",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\nAlle Aufgaben mit dem Tag rethink-chap2.\n\nLose-Nieten-Binomial-Grid\nRethink2E4\nRethink2m1\nRethink2m2\nRethink2m3\nRethink2m4\nRethink2m5\nRethink2m6\nRethink2m7\nkekse01\nkekse02\neuro-bayes\nbayes2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0500-Globusversuch.html#section",
    "href": "0500-Globusversuch.html#section",
    "title": "\n5Â  Globusversuch\n",
    "section": "\n5.9 â€”",
    "text": "5.9 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Globusversuch</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "6Â  Die Post befragen",
    "section": "6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n6.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n6.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 3.1 und 3.2.\n\n\n6.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œDaten umformenâ€\nStatistik1, Kap. â€œDaten zusammenfassenâ€\n\n\n\n6.1.5 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # optional\n\n\n\n6.1.6 Begleitvideos\n\nPlaylist QM2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6Â  Die Post befragen",
    "section": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.2.1 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (â€œBayes-Boxâ€) die Postverteilung fÃ¼r den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen, bei Apriori-Indifferenz gegenÃ¼ber den Parameterwerten. Und sagen wir \\(k=11\\) Gitterwerten1, also mit 10 Wasseranteilswerten zwischen 0 und 1.\n\nÃœbungsaufgabe 6.1 (Welcher Paramterwert hat die hÃ¶chste Posteriori-Wahrscheinlichkeit?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\nAufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die hÃ¶chste Wahrscheinlichkeit (d.h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. ListingÂ 6.1. \\(\\square\\)\n\n\n\n\n\n\n\n\nListingÂ 6.1: Bayes-Box mit 6 Wasser bei 9 Versuchen\n\n\nn &lt;- 11\nn_success &lt;- 6          \nn_trials  &lt;- 9\np_grid &lt;- seq(from = 0, to = 1, length.out = n)         # &lt;1&gt;\nL &lt;- dbinom(n_success, size = n_trials, prob = p_grid)  # &lt;2&gt;\n\nd &lt;-                                                    # &lt;3&gt;\n  tibble(p_grid = p_grid,prior  = 1) %&gt;% \n  mutate(likelihood = L) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n\n\nSequenz von 0 bis 1 mit der LÃ¤nge n=11 Schritte, das gibt uns die Parameterwerte\nLikelihood mit 6 Treffern bei 9 WÃ¼rfen und das Ganze jeweils fÃ¼r alle 11 Parameterwerte\nDann packen wir alles in eine Tabelle.\n\n\n\nAbb. AbbildungÂ 6.1 zeigt die resultierende Bayes-Box; vor allem ist die Post-Verteilung wichtig.\n\nlibrary(ggpubr)\nggline(d, x = \"p_grid\", y = \"post\") \n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.1: Die Postverteilung fÃ¼r W=6, N=9, k=10\n\n\n\n\n\nVoilÃ , die Post-Verteilung als Tabelle, auch â€œBayes-Boxâ€ (oder Bayes-Gitter) genannt: s. TabelleÂ 6.1.\n\n\n\n\nTabelleÂ 6.1: Postverteilung mit der Gittermethode berechnet\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.02\n0.02\n0.02\n\n\n0.4\n1\n0.07\n0.07\n0.07\n\n\n0.5\n1\n0.16\n0.16\n0.16\n\n\n0.6\n1\n0.25\n0.25\n0.25\n\n\n0.7\n1\n0.27\n0.27\n0.27\n\n\n0.8\n1\n0.18\n0.18\n0.18\n\n\n0.9\n1\n0.04\n0.04\n0.04\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.2 Bayes-Box automatisiert\nÃœbrigens kann man die Berechnung der Bayes-Box auch automatisieren, s. TabelleÂ 6.2 und ListingÂ 6.2, z.B. so:2\nEntweder so:\n\nsource(\"https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R\") \nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\nMit source importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code fÃ¼r die Funktion bayesbox.\nOder Sie starten das R-Paket, wo die Funktion wohnt:\n\n\n\n\nListingÂ 6.2: Funktion bayesbox, auch im Paket prada erhÃ¤ltlich\n\n\nlibrary(prada)  # &lt;1&gt;\nbayesbox(hyps = p_grid, priors = 1, liks = L)  # &lt;3&gt;\n\n\n\n\n\n\nTabelleÂ 6.2: Eine Bayes-Box â€˜automatisiertâ€™ erstellt, mit Hilfe der Funktion bayesbox\n\n\n\n\n  \n\n\n\n\n\n\n\nDas Paket prada steht nicht im Standard-R-App-Store (â€œCRANâ€), sondern auf Github. Sie kÃ¶nnnen es so installieren: devtools::install_github(\"sebastiansauer/prada\").\nDie Funktion verhÃ¤lt sich wie eine gewÃ¶hnliche Bayes-Box: Bei hyps schreibt man die Hypothesen (bzw. Parameterwerte) auf. Bei priors die Priori-Werte und bei liks die Likelihoods der jeweiligen Hypothesn.\n\n\n\n\n\n\n\n\n\n\n\n\nViele nÃ¼tzliche Fragen (und Antworten) leiten sich ab aus Abb. AbbildungÂ 6.1.\n\nBeispiel 6.1 (Beispiele fÃ¼r Fragen an die Post-Verteilung) Â \n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\netc. \\(\\square\\)\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.2.3 Bayes-Box fÃ¼r komplexe Modelle\nBisher, fÃ¼r einfache Fragestellungen hat unsere Bayes-Box, das heiÃŸt die Gittermethode bestens funktioniert: einfach, robust, formschÃ¶n3. Allerdings: Funktioniert sie auch bei komplexeren Modellen? SchlieÃŸlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 PrÃ¤diktor, dann haben wir folgende drei GrÃ¶ÃŸen4 zu schÃ¤tzen: \\(\\beta_0, \\beta_1, \\sigma\\). HÃ¶rt sich gar nicht so viel an. Aber Moment, wir mÃ¼ssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach mÃ¼ssen wir alle AusprÃ¤gungen (â€œGitterwerteâ€) der Variablen multiplizieren. Puh, das wird eine groÃŸe Zahl. Wenn wir fÃ¼r die drei GrÃ¶ÃŸen jeweils 10 AusprÃ¤gungen annehmen, was wenig ist, kÃ¤men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 AusprÃ¤gungen wÃ¤ren es schon \\(100^3=10^6\\) Kombinationen. Das wÃ¤re doch eine recht lange Tabelle.5\nBei einer multiplen Regression mit sagen wir 10 PrÃ¤diktoren mit jeweils 100 AusprÃ¤gungen rechnet das arme R bis zum jÃ¼ngsten Tag: \\(10^{100}\\).\n\nğŸ¤– Bitte tue mir das nicht an!\n\n\nğŸ‘¨â€ğŸ« Schon gut, das kÃ¶nnen wir R nicht zumuten. Wir brauchen eine andere LÃ¶sung!\n\n\n\n6.2.4 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Mathematik wird zu umfangreich bzw. zu komplex. GlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht. Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten. Praktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der das fÃ¼r uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck. Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung mit HÃ¤ufigkeiten (d.h. in Stichprobenform) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Bayes-Box-Methode6 ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu unpraktisch. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein7\n\n\n6.2.5 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck. Bevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform. Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. ListingÂ 6.3.\n\n\n\nListingÂ 6.3: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\n\n\nsamples &lt;-\n  d %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit ZurÃ¼cklegen\n  select(p_grid)\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird. Wir begnÃ¼gen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht. Das Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 6.3 dargestellt.\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\n\n\nTabelleÂ 6.3 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.\n\n\n\n\nTabelleÂ 6.3: Stichproben-Post-Verteilung\n\n\n\n\n\n\n\n\n\np_grid\n\n\n\n\n0.500\n\n\n0.900\n\n\n0.600\n\n\n0.700\n\n\n0.500\n\n\n\n\n\n\n\n\n\n\n\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.5 0.9 0.6 0.7 0.5 0.7 0.9 0.6 0.5 0.8 0.4 0.6 0.7 0.4 0.8 0.6 0.6 0.5\n##  [19] 0.6 0.6 0.8 0.7 0.5 0.6 0.5 0.9 0.4 0.7 0.8 0.7 0.5 0.7 0.8 0.6 0.6 0.7\n##  [37] 0.7 0.7 0.7 0.8 0.6 0.6 0.7 0.7 0.8 0.5 0.6 0.4 0.6 0.8 0.7 0.7 0.8 0.7\n##  [55] 0.6 0.7 0.4 0.7 0.6 0.7 0.8 0.8 0.7 0.8 0.6 0.5 0.6 0.7 0.6 0.6 0.5 0.7\n##  [73] 0.4 0.8 0.6 0.6 0.6 0.7 0.7 0.8 0.7 0.4 0.6 0.6 0.7 0.4 0.5 0.7 0.8 0.5\n##  [91] 0.6 0.5 0.6 0.5 0.7 0.8 0.7 0.9 0.7 0.8\n\n\n\nSo sieht unsere â€œStichproben-Bayesboxâ€ als Balkendiagramm aus, s. AbbildungÂ 6.2.\n\nSyntaxOutput\n\n\n\nsamples |&gt; \n  count(p_grid) |&gt; \n  ggbarplot(x = \"p_grid\", y = \"n\") \n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n\n\nAus AbbildungÂ 6.2 kÃ¶nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% fÃ¼r am wahrscheinlichsten hÃ¤lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlieÃŸen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie AbbildungÂ 6.2 mit AbbildungÂ 5.10: beide sind sehr Ã¤hnlich! Das Stichprobenziehen (AbbildungÂ 6.2) nÃ¤hert sich recht gut an die exakte Berechnung an (AbbildungÂ 5.10).\n\n\n6.2.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) Gitterwerte (AusprÃ¤gungen) nach oben.\n\n1k &lt;- 100\n2n_success &lt;- 6\n3n_trials  &lt;- 9\n\nd_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n4                      length.out = k),\n5         prior  = 1) %&gt;%\n6  mutate(likelihood = dbinom(n_success,\n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n7  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n1\n\n\\(k=100\\) Gitterwerte\n\n2\n\n6 Treffer (Wasser)\n\n3\n\n9 Versuche\n\n4\n\nBayes-Box anlegen mit 100 Zeilen, d.h. 100 Parameterwerten\n\n5\n\nApriori indifferent: Alle Hypothesen haben die gleiche Apriori-PlausibilitÃ¤t\n\n6\n\nDie Likelihood ist binomialverteilt.\n\n7\n\nPost-Verteilung berechnen wie gewohnt.\n\n\n\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\nsamples_k100 &lt;-\n  d_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\nAbbildungÂ 6.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen FÃ¤llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der â€œtypischeâ€ Wert des Modells zu sein. AuÃŸerdem erkennt man, dass das Modell durchaus einige Streuung in der SchÃ¤tzung des Wasseranteils bereithÃ¤lt. Das Modell ist sich nicht sehr sicher, kÃ¶nnte man sagen.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.3: Post-Verteilung mit 100 Gitterwerten, exakt vs.Â auf Basis von Stichproben\n\n\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt die Post-Verteilung noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. AbbildungÂ 6.4.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schÃ¶n â€˜glattâ€™. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "6Â  Die Post befragen",
    "section": "6.3 Die Post-Verteilung befragen",
    "text": "6.3 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\nğŸ“º Die Post-Verteilung auslesen\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in AbbildungÂ 6.5 schematisch illustriert.\n\n\n\n\n\n\nAbbildungÂ 6.5: Fragen nach p vs.Â Fragen nach q\n\n\n\nIm linken Teildiagramm von AbbildungÂ 6.5 fragen wir: â€œWie wahrscheinlich ist ein Wasseranteil von hÃ¶chstens 80%?â€. Im rechten Teildiagramm fragen wir: â€œWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht Ã¼berschritten?â€.\n\n6.3.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt? Um diese Frage zu beantworten, zÃ¤hlen wir einfach, wie viele Stichproben die Bedingung erfÃ¼llen, und summieren die Wahrscheinlichkeiten dieser Stichproben. Wir zÃ¤hlen (count) also die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.\n\nBeispiel 6.2 (Was macht die Funktion count?) Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem PrÃ¼fkriterium, Wasseranteil hÃ¶chstens 50%. Dann zÃ¤hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurÃ¼ck. \\(\\square\\)\n\n\n\nWir zÃ¤hlen wie oft der Wasseranteil weniger als 50% betrÃ¤gt:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\n\n  \n\n\n\n\nMan kÃ¶nnte also alternativ auch schreiben:\n\nd %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n  \n\n\n\n\n\n\nBeispiel 6.3 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\nWir zÃ¤hlen die Stichproben, die diesen Kriterien entsprechen:\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n  \n\n\n\n\nğŸ¤– Ich wÃ¼rde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.\n\n\nğŸ‘¨â€ğŸ« Das wollte ich auch gerade sagenâ€¦\n\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n  \n\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden:\n\nsamples %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n  \n\n\n\nFertig ğŸ˜„ \\(\\square\\)\n\n\nBeispiel 6.4 (Wasseranteil zwischen 90& und 100%?) Noch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nSyntaxOutput\n\n\n\nsamples %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\n  \n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.2 (Wasseranteil hÃ¶chstens 50%?) Â \n\nğŸ‘©â€ğŸ”¬ Mit welcher Wahrscheinlichkeit ist der Planet hÃ¶chstens zur HÃ¤lfte mit Wasser bedeckt?\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples %&gt;% count(p_grid &lt;= .5)\n\n\n  \n\n\n\n\n\n\n\nWir kÃ¶nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem â€œGipfelâ€ des Berges, s. AbbildungÂ 6.4.\nFÃ¼r unsere Stichproben-Postverteilung, samples, s. AbbildungÂ 6.2, lÃ¤sst sich der Modus so berechnen:\n\nmap_estimate(samples$p_grid)  \n## MAP Estimate: 0.70\n\nDabei steht map fÃ¼r Maximum Aposteriori, also das Maximum der Post-Verteilung.\n\nÃœbungsaufgabe 6.3 Bei der Gelegenheit kÃ¶nnten wir folgende, Ã¤hnliche Fragen stellen:\n\nWas ist der mittlere SchÃ¤tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane SchÃ¤tzwert (Median)?\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n  \n\n\n\n\n\n\n\n\n\n6.3.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall8.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir mÃ¶chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist9.\n\nsamples %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n  \n\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren, s. AbbildungÂ 6.4.\n\n\n\n\n\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\nsamples %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n  \n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n\n6.3.3 Zur Erinnerung: Quantile\nBeispiel: Wie groÃŸ sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%, in Inches10:\n\n# speed_gender_height &lt;- read.csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n1data(\"speed_gender_height\", package = \"openintro\")\n\nheight_summary &lt;- \n  speed_gender_height %&gt;% \n2  mutate(height_cm = height*2.54) %&gt;%\n  select(height_inch = height, height_cm) %&gt;% \n3  drop_na() %&gt;%\n4  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %&gt;%\n5  group_by(Einheit) %&gt;%\n6  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n1\n\nDaten importieren\n\n2\n\nInch in Zentimeter umrechnen\n\n3\n\nZeilen mit fehlenden Werten lÃ¶schen\n\n4\n\nIn die Langform pivotieren\n\n5\n\nGruppieren nach Einheit (Inch, Zentimeter)\n\n6\n\nQuantile berechnen (Q1, Q2, Q3)\n\n\n\n\n\n  \n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildungÂ 6.6 visualisiert die Quantile und die HÃ¤ufigkeitsverteilung.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.6: GrÃ¶ÃŸenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n\n\nÃœbungsaufgabe 6.4 (Welcher Parameterwert ist der wahrscheinlich grÃ¶ÃŸte?) Ãœbersetzen wir â€œwahrscheinlichâ€ grÃ¶ÃŸte in â€œmit einer Wahrscheinlichkeit von 99% gibt es keinen grÃ¶ÃŸerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(quant99 = quantile(p_grid, p = .99))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der hÃ¶chste zu erwartende Wasseranteil 0.9.\n\n\n\n\n\nÃœbungsaufgabe 6.5 (Welcher Parameterwert ist der wahrscheinlich kleinste?) Ãœbersetzen wir â€œwahrscheinlichâ€ kleinste in â€œmit einer Wahrscheinlichkeit von 99% gibt es keinen kleinerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .01))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 â€“ immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\nÃœbungsaufgabe 6.6 (Welcher Parameterwert ist der â€œvermutlichâ€ kleinste?) In der â€œwirklichenâ€ Welt sind Aussagen nicht immer prÃ¤zise. Sagen wir, die Chefin der WeltraumbehÃ¶rde hat in einem Presse-Statement von der â€œvermutlichen Untergrenzeâ€ hinsichtlich des Wasseranteils gesprochen.\nÃœbersetzen wir â€œvermutlichâ€ kleinste in â€œmit einer Wahrscheinlichkeit von 90% gibt es keinen kleinerenâ€.\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .1))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 â€“ immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\n\n6.3.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht Ã¼berschritten wird. Das kÃ¶nnen wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% (von 10000) ab (entferne sie).\nSchaue, was der grÃ¶ÃŸte verbleibende Wert ist.\n\n\nsamples %&gt;% \n  arrange(p_grid) %&gt;%   # sortiere\n  slice_head(n = 9000) %&gt;%  # nur die ersten 90%\n  summarise(p90 = max(p_grid))\n\n\n  \n\n\n\nDas (annÃ¤hernd) gleiche Ergebnis liefert quantile():\n\nsamples %&gt;% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n  \n\n\n\n\n\n6.3.5 Visualisierung der Intervalle\n\nDefinition 6.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die â€œabzuschneidendeâ€ Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. AbbildungÂ 6.7, rechtes Teildiagramm.11 \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\n\n\n(b) Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\nAbbildungÂ 6.7: Perzintilintervalle\n\n\n\nDas 10%, 20%, â€¦ 100%-Quantil12 (auf Basis von samples_k100) sind in AbbildungÂ 6.8 illustriert.\n\n\n\n\n\n\nAbbildungÂ 6.8: Quantile in 10%-Schritenn durch die Verteilung von samples_k100",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "href": "0600-Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "title": "6Â  Die Post befragen",
    "section": "6.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich",
    "text": "6.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nNoch einmal zum Globusversuch: Gehen wir von 3 WÃ¼rfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe), s. ListingÂ 6.4:\n\n\n\n\nListingÂ 6.4: Schiefe Post-Verteilung in einer Bayes-Box\n\n\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\n\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\n\n\n\n\n1.00\n1\n1.00\n1.00\n\n\n0.87\n1\n0.66\n0.66\n\n\n0.61\n1\n0.23\n0.23\n\n\n0.66\n1\n0.29\n0.29\n\n\n0.87\n1\n0.66\n0.66\n\n\n0.76\n1\n0.44\n0.44\n\n\n\n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\n\n6.4.1 Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall, s. Abb. AbbildungÂ 6.9.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.9: Schiefe Intervalle\n\n\n\n\n\nEin Perzentilintervall (ETI, PI) kann, wenn es dumm lÃ¤uft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zurÃ¼ckweisen. Das ist nicht so toll.\nEin Highest-Density-Intervall (HDI13) ist schmÃ¤ler als der Perzintilintervall und enthÃ¤lt immer den wahrscheinlichsten Parameterwert.\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)  # Paket `easystats`\n\n\n\n\n\n  \n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.4.2 Intervalle hÃ¶chster Dichte\n\nDefinition 6.2 Intervalle hÃ¶chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schmÃ¤lste Intervall, das den gesuchten Parameter enthÃ¤lt (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten RÃ¤nder nicht mehr gleich groÃŸ, im Sinne von enthalten nicht (zwangslÃ¤ufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen RÃ¤ndern hingegen gleich groÃŸ.\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt), s. Abb. AbbildungÂ 6.10.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.10: Visualisierung der PunktschÃ¤tzer bei einer schiefen Post-Verteilung\n\n\n\n\n\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen, s. TabelleÂ 6.4.\n\nsamples %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\nTabelleÂ 6.4: 50%-HDI fÃ¼r unser Globusmodell\n\n\n\n\n  \n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI).",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "6Â  Die Post befragen",
    "section": "6.5 Fazit",
    "text": "6.5 Fazit\n\n6.5.1 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich\nPerzentilintervalle sind verbreiteter\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n6.5.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datensatz samples, s. ListingÂ 6.3. Sagen wir, wir haben 6 Treffer bei 9 WÃ¼rfen erzielt.\nLageparameter: Welchen mittleren Wasseranteil kann man erwarten?\n\nsamples %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n  \n\n\n\nStreuungsparameter: Wie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?\n\nsamples %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler\n\n\n  \n\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel fÃ¼r einen Parameter, einer unbekannten GrÃ¶ÃŸes eines Modells.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "6Â  Die Post befragen",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nfattails1\nfattails2\nReThink3e1-7\nWeinhaendler\nRethink3m1\nRethink3m2\nKaefer2\ngroesse2\ngroesse1\nAnteil-Apple\nKung-height\nzwielichter-dozent-bayes",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "6Â  Die Post befragen",
    "section": "6.7 â€”",
    "text": "6.7 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "7Â  Gauss-Modelle",
    "section": "7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n7.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nein GauÃŸmodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n7.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.1 bis 4.3.\n\n\n7.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œModellgÃ¼teâ€\nStatistik1, Kap. â€œPunktmodelle 2â€\n\n\n\n7.1.5 BenÃ¶tigte R-Pakete\nFÃ¼r rstanarm wird ggf. weitere Software benÃ¶tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, mÃ¼ssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio mÃ¼ssen Sie die (benÃ¶tigten!) Pakete starten.\n\n\n\nlibrary(tidyverse)  # Datenjudo\nlibrary(rstanarm)  # Bayes-Modelle berechnen\nlibrary(easystats)  # Statistik-Komfort\nlibrary(DataExplorer)  # Daten verbildlichen\nlibrary(ggpubr)  # Daten verbildlichen\n\n\n\n\n\n\n\nWichtig\n\n\n\nAb diesem Kapitel benÃ¶tigen Sie das R-Paket rstanarm. \\(\\square\\)\n\n\n\n\n7.1.6 BenÃ¶tigte Daten\nWir benÃ¶tigen den Datensatz !Kung. Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\n\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd &lt;- read.csv(Kung_path) \n\nhead(d)\n\n\n  \n\n\n\nDatenquelle\n Download \n\n\n7.1.7 Einstieg\n\nBeispiel 7.1 (Was war noch mal eine Normalverteilung?) In diesem Kapitel benÃ¶tigen Sie ein gutes VerstÃ¤ndnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! \\(\\square\\)\n\n\nBeispiel 7.2 (Was war noch mal eine Posterior-Verteilung?) In diesem Kapitel befragen wir die Post-Verteilung fÃ¼r ein normalverteilte Zufallsvariable, nÃ¤mlich die KÃ¶rpergrÃ¶ÃŸe der !Kung San. Was war noch mal eine Post-Verteilung und wozu ist sie gut? \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-groÃŸ-sind-die-kung-san",
    "href": "0800-gauss.html#wie-groÃŸ-sind-die-kung-san",
    "title": "7Â  Gauss-Modelle",
    "section": "7.2 Wie groÃŸ sind die !Kung San?",
    "text": "7.2 Wie groÃŸ sind die !Kung San?\nDieser Abschnitt basiert slee auf McElreath (2020), Kap. 4.3.\n\n7.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. AbbildungÂ 7.1.\n\nThe ÇƒKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names ÇƒKung (ÇƒXun) and Ju are variant words for â€˜peopleâ€™, preferred by different ÇƒKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of ÇƒKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\n\n\n\n\n\n\n\n\n\n\n\n(a) Kung People\n\n\n\n\n\n\n\n\n\n\n\n(b) Verbreitung der Kung-Sprachen\n\n\n\n\n\n\n\nAbbildungÂ 7.1: Die !Kung im sÃ¼dlichen Afrika\n\n\n\nQuelle\nQuelle: By Andrewwik.0 - Own work, CC BY-SA 4.0,]\nWir interessieren uns fÃ¼r die GrÃ¶ÃŸe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als d2.\n\nd2 &lt;- d %&gt;% \n  filter(age &gt;= 18)\n\nnrow(d2)\n## [1] 352\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tatsÃ¤chlich recht easy, s. TabelleÂ 7.1.\n\ndescribe_distribution(d2)\n\n\n\n\n\nTabelleÂ 7.1: Statistiken der metrischen Variablen im Kung-Datensatz\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\nâˆ’0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\nâˆ’0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\nâˆ’0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\nâˆ’2.00\n352.00\n0\n\n\n\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus {DataExplorer}), s. AbbildungÂ 7.2.\n\nplot_density(d2)\n\n\n\n\n\n\n\nAbbildungÂ 7.2: Verteilungen der Variablen im Kung-Datensatz. GrÃ¶ÃŸe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n\n\n\n7.2.2 Wir gehen apriori von normalverteilter GrÃ¶ÃŸe Der !Kung aus\nForschungsfrage: Wie groÃŸ sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also fÃ¼r den Mittelwert der KÃ¶rpergrÃ¶ÃŸe (erwachsener Kung beider Geschlechter), \\(\\mu\\).\n\n\n\nMensch\n\n\nQuelle1\nWir sind uns Ã¼ber diesen Mittelwert nicht sicher2, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178cm und Streuung von 20 cm:\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{7.1}\\]\nGleichungÂ 7.1 definiert ein Modell: Unsere Vorstellung der mittleren (â€œtypischenâ€) KÃ¶rpergrÃ¶ÃŸe der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.3 In einer echten Untersuchung sollte man immer einen inhaltlichen Grund fÃ¼r einen Priori-Wert haben. Oder man wÃ¤hlt â€œschwach informativeâ€ Prioris, wie das {rstanarm} tut: Damit lÃ¤sst man kaum Vorab-Information in das Modell einflieÃŸen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der KÃ¶rpergrÃ¶ÃŸen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. DarÃ¼ber hinaus ist eine Normalverteilung nicht unplausibel.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#die-exponentialverteilung",
    "href": "0800-gauss.html#die-exponentialverteilung",
    "title": "7Â  Gauss-Modelle",
    "section": "7.3 Die Exponentialverteilung",
    "text": "7.3 Die Exponentialverteilung\n\n7.3.1 Die Apfel-fÃ¤llt-nicht-weit-vom-Stamm-Verteilung\nDarf ich vorstellen â€¦\nBevor wir unser Kung-Modell spezifizieren kÃ¶nnen, sollten wir noch Ã¼berlegen, welches Vorab-Wissen wir zur Streuung um den Mittelwert herum haben. Da wir uns nicht 100% sicher zur gesuchten GrÃ¶ÃŸe sind, mÃ¼ssen wir angeben, wie groÃŸ die Streuung um den Mittelwert sein soll. Hier werden wir eingestehen, dass wir uns auch nicht 100% sicher sind, wie groÃŸ die Streuung exakt ist. Also geben wir eine Verteilung fÃ¼r die Streuung an.\nEtwas Wissen Ã¼ber diese Verteilung haben wir:\n\nEine Streuung muss positiv sein (es gibt keine negative Streuung).\nEine Gleichverteilung der Streuung ist vielleicht mÃ¶glich, aber nicht sehr plausibel.\nWenn wir der Meinung sind, der Mittelwert betrage â€œungefÃ¤hr 178cmâ€, so halten wir 180cm fÃ¼r plausibel, aber 18000 cm fÃ¼r unmÃ¶glich und schon 200 fÃ¼r sehr unplausibel. Also: Je grÃ¶ÃŸer die die Abweichung vom Mittelwert desto unplausibler.\n\nDiese Anforderungen4 spiegeln sich in AbbildungÂ 7.3 wider; es handelt sich um eine Exponentialveteilung. AuÃŸerdem zeigt die Abbildung verschiedene Quantile, wie das 95%-Quantil, das bei 3 liegt; 95% der Werte dieser Verteilung sind also nicht grÃ¶ÃŸer als 3.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.3: Die Exponentialverteilung mit einigen ihrer Quantilen\n\n\n\n\n\nFÃ¼r eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung.\n\nEine Exponentialverteilung ist nur fÃ¼r positive Werte, \\(x&gt;0\\), definiert.\nSteigt X um eine Einheit, so Ã¤ndert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (â€œlambdaâ€).\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (â€œGestrecktheitâ€) der Verteilung an.\nJe grÃ¶ÃŸer die Rate \\(\\lambda\\), desto kleiner die Streuung und der Mittelwert der Verteilung.\nJe grÃ¶ÃŸer \\(1/\\lambda\\), desto grÃ¶ÃŸer die Streuung und der Mittelwert der Verteilung.\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren PlÃ¤nen passt.\n\n\n7.3.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zurÃ¼ckzufÃ¼hren, s. AbbildungÂ 7.4.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.4: Beispiele von Expnentialverteilungen mit unterschiedlichem lambda\n\n\n\n\n\nWie wir in AbbildungÂ 7.4 sehen, kÃ¶nnte eine Exponentialverteilung mit \\(\\lambda=1/8\\) grob passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie â€œrichtigenâ€ Priori-Verteilung zu finden, bzw. die richtigen Parameter fÃ¼r die Priori-Verteilung zu wÃ¤hlen, ist nicht mÃ¶glichn, denn es gibt nicht die eine, richtige Priori-Verteilung. Eine â€œgut passendeâ€ Verteilung zu finden, ist hÃ¤ufig nicht leicht. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu wÃ¤hlen, die einen breiteren Raum an mÃ¶glichen Werten zulÃ¤sst. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie mehrere Meter KÃ¶rpergrÃ¶ÃŸe Streuung, erlauben.\n\n\nMan kann sich die Quantile der Exponentialverteilung mit qexp ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, fÃ¼r den man das Quantil haben mÃ¶chte. Mit rate wird \\(\\lambda\\) (lambda) bezeichnet.\nDieser Aufruf zum Beispiel:\n\nqexp(p = .5, rate = 1/8)\n## [1] 5.545177\n\nGibt uns die Verteilungsfunktion einer Exponentialverteilung mit Rate (\\(\\lambda\\)) von 1/8 zurÃ¼ck, ca. 5.5.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich so ausgeben lassen:\n\nqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2025425 29.5110356\n\nDiese Grenzen scheinen hinreichend weit, das wir noch von den Daten Ã¼berrascht werden kÃ¶nnen, aber schmal genug, um unsinnige Werte auszuschlieÃŸen. Ein guter Start! Weiter gehtâ€™s!",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "7Â  Gauss-Modelle",
    "section": "7.4 Unser Gauss-Modell der !Kung",
    "text": "7.4 Unser Gauss-Modell der !Kung\nğŸ“º Teil 1\n\n7.4.1 Modelldefinition\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior fÃ¼r den Parameter \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior fÃ¼r den Parameter \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn AbbildungÂ 7.5 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.5: Unser (erstes) Kung-Modell (m41)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDieses Modell hat zwei Parameter, \\(\\mu\\) und \\(\\sigma\\). \\(\\square\\)\n\n\n\n\n7.4.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie KÃ¶rpergrÃ¶ÃŸen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})\\]\n\n\n7.4.3 Prioris der Parameter\nDer Mittelwert der KÃ¶rpergrÃ¶ÃŸe sei normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)}\\]\nDie Streuung \\(\\sigma\\) der GrÃ¶ÃŸen sei exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)}\\]\n\n\n7.4.4 Fertig!\nJetzt haben wir unser Modell (m41) definiert!\nWeil es so schÃ¶n ist, schreiben/zeichnen wir es hier noch einmal auf, GleichungÂ 7.2, AbbildungÂ 7.6.\n\n\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) \\\\\n\\sigma &\\sim \\mathcal{E}(1/8)\n\\end{aligned}\n\\tag{7.2}\\]\n\n\n\n\n\n\n\nAbbildungÂ 7.6: Modellschema fÃ¼r das Modell m41\n\n\n\n\n\nZur Berechnung von m41 nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich krÃ¤ftig der Bursche, der soll die Arbeit fÃ¼r uns tun. Der Golem hÃ¶rt auf den Namen rstanarm5.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#zufÃ¤llige-motivationsseite",
    "href": "0800-gauss.html#zufÃ¤llige-motivationsseite",
    "title": "7Â  Gauss-Modelle",
    "section": "7.5 ZufÃ¤llige Motivationsseite",
    "text": "7.5 ZufÃ¤llige Motivationsseite",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "href": "0800-gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "title": "7Â  Gauss-Modelle",
    "section": "7.6 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41",
    "text": "7.6 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m416.\n\n1m41 &lt;- stan_glm(height ~ 1, data = d2, refresh = 0)\n2m41_post &lt;- as_tibble(m41)\n3names(m41_post) &lt;- c(\"mu\", \"sigma\")\n\n\n1\n\nBayes-Regressionsmodell berechnen\n\n2\n\nModellergebnis in Tabelle umwandeln\n\n3\n\nSchÃ¶nere Namen fÃ¼r die Spalten geben\n\n\n\n\nDas Argument refresh = 0 verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrÃ¼cke. stan_glm7 ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein â€œrichtigesâ€ Regressionsmodell. Man kÃ¶nnte sagen, wir haben eine AV (KÃ¶rpergrÃ¶ÃŸe), aber keine UV (keine PrÃ¤diktoren). GlÃ¼cklicherweise kÃ¶nnen wir auch solche â€œarmenâ€ Regressionsmodelle formulieren: av ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen mÃ¶chte, aber keine PrÃ¤diktoren hat (das soll die 1 symbolisieren). FÃ¼r das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung (defaults) der Prioris von rstanarm zurÃ¼ck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wÃ¤re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die gemeinsame Posteriori-Verteilung von m41, s. AbbildungÂ 7.7\n\nFliesendiagrammStreudiagrammHistogramm\n\n\nGemeinsame Post-Verteilung von Mittelwert und Streuung\n\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\n\n\nAbbildungÂ 7.7: Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m42\n\n\n\n\n\nDa das Modell zwei Parameter hat, kÃ¶nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen kÃ¶nnen die Parameter korreliert sein.\nAbbildungÂ 7.7 erlaubt uns, fÃ¼r jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\n\n\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m42, s. AbbildungÂ 7.8.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.8: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\n\n\n\nUnd hier kommt die Post-Verteilung nur des Mittelwerts.\nNatÃ¼rlich kÃ¶nnen wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. AbbildungÂ 7.9.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.9: Die Post-Verteilung von mu in m42; ein Balkendiagramm bietet sich an.\n\n\n\n\n\n\n\n\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung fÃ¼r \\(\\mu\\) und eine fÃ¼r \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, fÃ¼r die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte fÃ¼r \\(\\mu\\) und \\(\\sigma\\) klein: Die groÃŸe Stichprobe hat die Priori-Werte Ã¼berstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so kÃ¶nnen wir interessante Fragen stellen.\n\n\n7.6.1 Hallo, Posteriori-Verteilung\nâ€¦ wir hÃ¤tten da mal ein paar Fragen an Sie. ğŸ•µ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person grÃ¶ÃŸer als 1,55m?\nWelche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?\nWas ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?\n\nAntworten folgen etwas weiter unten.\nAbschlieÃŸend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), AbbildungÂ 7.10.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.10: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen fÃ¼r mu und fÃ¼r sigma\n\n\n\n\n\n\n\n7.6.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() kÃ¶nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - Ã¤hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurÃ¼ck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so:\n\nlibrary(rstanarm)  # Paket muss gestartet sein.\n\n# berechnet Post.-Vert.:\nstan_glm(\n  # modelldefinition:\n  AV ~ UV,\n  # Datensatz:\n  data = meine_daten\n)\n\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum GrÃ¶ÃŸenmittelwert\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der GrÃ¶ÃŸen\n\n\n7.6.3 Ausgabe von stan_glm()\nWir kÃ¶nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir kÃ¶nnen es aber auch komfortabler haben â€¦ Mit dem Befehl parameters kann man sich die geschÃ¤tzten Parameterwerte einfach ausgeben lassen.\n\nm41 &lt;- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.61\n(153.78, 155.45)\n100%\n1.000\n2629.00\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem schÃ¤tzt den GrÃ¶ÃŸenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.7752401 bis 155.4515294 schÃ¤tzt. Informativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu spÃ¤ter mehr.\n\n\n\n\n\n\nHinweis\n\n\n\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren ğŸ¤“ Wer NÃ¤heres wissen will, findet hier einen Anfang. AuÃŸerdem sei an McElreath (2020) und Gelman, Hill, und Vehtari (2021) verwiesen. \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "7Â  Gauss-Modelle",
    "section": "7.7 Wie tickt stan_glm()?",
    "text": "7.7 Wie tickt stan_glm()?\n\n\n\n\n\n\n Quelle\n\nHier ein paar Kerninfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan fÃ¼r uns bereit.\nstan_glm() ist fÃ¼r die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schÃ¤tzen, so hat man man â€¦ eine Regression ohne PrÃ¤diktor.\nEine Regression ohne PrÃ¤diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also fÃ¼r die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\n\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n7.7.1 SchÃ¤tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die GrÃ¶ÃŸen, fÃ¼r die wir eine Priori-Verteilung annehmen. AuÃŸerdem wÃ¤hlen wir einen einen Likelihood-Funktion, so dass wir die Likelihood berechnen kÃ¶nnen. Auf dieser Basis schÃ¤tzen wir dann die Post-Verteilung. Ich sage schÃ¤tzen, um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren SchÃ¤tzungen) einfach mit parameters(modellname) auslesen.\n\n\n7.7.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, kÃ¶nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_m41:\n\npost_m41 &lt;- as_tibble(m41)\nhead(post_m41)\n\n\n  \n\n\n\nIn einer Regression ohne PrÃ¤diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss Ã¼ber unsere SchÃ¤tzwerte zu \\(\\mu\\) (der KÃ¶rpergrÃ¶ÃŸe).\n\nÃœbungsaufgabe 7.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\n\nnames(post_m41) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_m41 %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlieÃŸen, dass die Kung im Schnitt grÃ¶ÃŸer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. \\(\\square\\)\n\n\n\n\n\nÃœbungsaufgabe 7.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nnames(post_m41) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_m41 %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n  \n\n\n\nOh, diese Hypothese kÃ¶nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlieÃŸen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschlieÃŸen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\n\n\nBeispiel 7.3 (Welche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell m41?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\npost_m41 %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n  \n\n\n\n\n\n\n\n\nÃœbungsaufgabe 7.3 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\npost_m41 %&gt;% \n  eti()\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\n\n\n\nÃœbungsaufgabe 7.4 (Mit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\n\nm41 %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.61\n(153.78, 155.45)\n100%\n1.000\n2629.00\nNormal (154.60 +- 19.36)\n\n\n\n\n\nSeeing is believing, s. AbbildungÂ 7.11.\n\nm41 %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\n\n\n\n\nAbbildungÂ 7.11: Parameter von m41, nur einer: der Intercept\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren KÃ¶rpergrÃ¶ÃŸe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\n\n\n\nÃœbungsaufgabe 7.5 (Was ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?) Â \n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\nparameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n\n\n\nğŸ‹ï¸ Ã„hnliche Fragen bleiben als Ãœbung fÃ¼r die Lesis. ğŸ¤“\n\n\n7.7.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt fÃ¼r uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\nprior_summary(m41)\n## Priors for model 'm41' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden dafÃ¼r die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage fÃ¼r die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht â€œpures Bayesâ€, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte wÃ¤ren auch denkbar.\n\n\n\n\n\n\nStandardwerte von stan_glm\n\n\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (fÃ¼r \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals â€œStreuungâ€, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen. \\(\\square\\)\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wÃ¤hlen, dass man nicht Ã¼bergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlieÃŸen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflieÃŸen zu lassen und eigene Entscheidungen zu begrÃ¼nden. HÃ¤ufig sind mehrere Entscheidungen mÃ¶glich. MÃ¶chte man lieber vorsichtig sein, weil man wenig Ã¼ber den Gegenstand weiÃŸ, dann kÃ¶nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die â€œschwachinformativâ€ ist, also nur wenig Priori-Information in das Modell einflieÃŸen lÃ¤sst.\n\n\n\n\n7.7.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund fÃ¼r Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu zÃ¤hlen hat. AuÃŸerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister prÃ¼fen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier DurchfÃ¼hrungen (auch â€œKettenâ€ engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist â€œdumm gelaufenâ€. An dieser Stelle schauen wir uns die Ketten nicht nÃ¤her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. MÃ¶chte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit.\n\nm41a &lt;- stan_glm(height ~ 1, \n                 data = d2, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m41a)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#modell-m42-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m42-unsere-priori-werte",
    "title": "7Â  Gauss-Modelle",
    "section": "7.8 Modell m42: unsere Priori-Werte",
    "text": "7.8 Modell m42: unsere Priori-Werte\nğŸ“º Teil 2\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflieÃŸen, in unserem zweiten Kung-Modell, m42.\n\n7.8.1 m42\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.8 Dieses Mal geben wir die Priori-Werte explizit an, TabelleÂ 7.2.\n\nm42 &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\n\n\n\n\nTabelleÂ 7.2: Parameter von m42 mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482.00\nNormal (178 +- 20)\n\n\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in TabelleÂ 7.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige FÃ¤higkeit im Studium. ğŸ¤“\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m41 und m42! Was fÃ¤llt Ihnen auf? Nichts? Gut! TatsÃ¤chlich liefern beide Modelle sehr Ã¤hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigermaÃŸen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gewÃ¤hlt waren.\n\n\n\n\n7.8.2 Posteriori-Verteilung und Parameter plotten\nLeider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zurÃ¼ck.\n\nğŸ‘¨â€ğŸ« BÃ¶ser Golem!\n\n\nğŸ¤– Beim nÃ¤chsten Mal strenge ich mich mehr an!\n\nDaher mÃ¼ssen wir die Ausgabe des Stan-Golemns erst in eine schÃ¶ne Tabelle umwandeln:\n\nm42_tibble &lt;-\n  as_tibble(m42)\n\nhead(m42_tibble)\n\n\n  \n\n\n\nAuÃŸerdem ist der Name der ersten Spalte eigentlich unzulÃ¤ssig, da Spaltennamen in R nicht mit Sonderzeichen anfangen dÃ¼rfen (sondern mit Buchstaben). Daher mÃ¼ssen wir den Namen mit â€œSamthandschuhenâ€ anpacken. Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln mÃ¼ssen, s. die folgende Syntax.\n\nMit {ggpubr}Mit {ggplot}\n\n\n\nm42_tibble |&gt; \n  gghistogram(x = \"`(Intercept)`\")  # Aus dem Paket \"ggpubr\"\n\n\n\n\n\n\n\n\n\n\n\nm42_tibble |&gt; \n  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\nAls Ausblick: Ein Vergleich mehrerer Priori-Werte wÃ¤re auch nÃ¼tzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewÃ¤hlten Priori-Werte zu Ã¼berzeugen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "7Â  Gauss-Modelle",
    "section": "7.9 Fazit",
    "text": "7.9 Fazit\n\n7.9.1 Zusammenfassung\nWir haben die Posteriori-Verteilung fÃ¼r ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne PrÃ¤diktoren, betrachtet. Die Zielvariable, KÃ¶rpergrÃ¶ÃŸe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. FÃ¼r \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung fÃ¼r \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n7.9.2 Botschaft von einem Statistiker\n\n\n\nğŸ§¡ Bleiben Sie dran!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#wahl-der-priori-werte",
    "href": "0800-gauss.html#wahl-der-priori-werte",
    "title": "7Â  Gauss-Modelle",
    "section": "7.10 Wahl der Priori-Werte",
    "text": "7.10 Wahl der Priori-Werte\nğŸï¸ Dieser Abschnitt ist eine VERTIEFUNG und nicht prÃ¼fungsrelevant. ğŸ\n\n7.10.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\nğŸ’­ Was denkt der Golem (m41) apriori von der GrÃ¶ÃŸe der !Kung?\nğŸ¦¾ Ziehen wir mal ein paar Stichproben auf Basis des Modells. VoilÃ :\n\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MWÂ±3SD\",\n       x = \"GrÃ¶ÃŸe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\n\n\n\nQuellcode\n\n\n7.10.2 Priori-Werte prÃ¼fen mit der Priori-PrÃ¤diktiv-Verteilung\n\nDie Priori-PrÃ¤diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo kÃ¶nnen wir prÃ¼fen, ob die Priori-Werte vernÃ¼nftig sind.\n\nDie Priori-PrÃ¤diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an GrÃ¶ÃŸenwerten zulassen:\n\np3\n\n\n\n\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\nanteil_groÃŸer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_groÃŸer_kung\n\n\n  \n\n\n\nğŸ¤” Sehr groÃŸe Buschleute? 17 Prozent sind grÃ¶ÃŸer als 2 Meter. Das ist diskutabel, muss aber nicht zwangslÃ¤ufig ein schlechter Prior sein.\n\n\n7.10.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n\n\n\n\n7.10.4 Extrem vage Priori-Verteilung fÃ¼r die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\n\n\n\n\nDie Streuung der GrÃ¶ÃŸen ist weit:\n\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\nğŸ¤” Das Modell geht apriori von ein paar Prozent Menschen mit negativer GrÃ¶ÃŸe aus. Ein Haufen Riesen ğŸ‘¹ werden auch erwartet.\nğŸ¤¯ Vage (flache, informationslose, â€œneutraleâ€, â€œobjektiveâ€) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "7Â  Gauss-Modelle",
    "section": "7.11 Aufgaben",
    "text": "7.11 Aufgaben\n\nstan_glm01\nReThink4e1\nReThink4e2\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung\nPriorwahl1\nRethink4e2",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "7Â  Gauss-Modelle",
    "section": "7.12 â€”",
    "text": "7.12 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Gauss-Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n\n8.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung fÃ¼r einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder StreuungsmaÃŸe und auch SchÃ¤tzintervalle - aus der Post-Verteilung herauslesen\nkÃ¼nftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n8.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4.\n\n\n8.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 1â€\n\n\n\n8.1.5 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)  # Bayes-Golem\nlibrary(ggpubr)  # Datenvisualisierung\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine Ãœbersicht aller Funktionen des Pakets.1\n\n\n8.1.6 BenÃ¶tigte Daten\nIn diesem Kapitel benÃ¶tigen wir den Datensatz zu den !Kung-Leuten, Howell1a, McElreath (2020). Sie kÃ¶nnen ihn hier herunterladen.\n Download \n\n1Kung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\n2d &lt;- read.csv(Kung_path)\n\n3d2 &lt;- d %&gt;% filter(age &gt; 18)\n\n\n1\n\nPfad zum Datensatz; Sie mÃ¼ssen online sein, um die Daten herunterzuladen.\n\n2\n\nDaten einlesen\n\n3\n\nAuf Erwachsene Personen begrenzen (d.h. Alter &gt; 18)\n\n\n\n\n\n\n8.1.7 Einstieg\n\nBeispiel 8.1 (Grundkonzepte der linearen Regression) Fassen Sie die Grundkonzepte der linearen Regression kurz zusammen! \\(\\square\\)\n\n\nBeispiel 8.2 (Was ist eine Post-Verteilung und wozu ist sie gut?) ErklÃ¤ren Sie kurz, was eine Post-Verteilung ist - insbesondere im Zusammenhang mit den Koeffizienten einer einfachen Regression - und wozu sie gut ist. \\(\\square\\)\n\n\n\n8.1.8 Ãœberblick\nDieses Kapitel stellt ein einfaches Regressionsmodell vor, wo die KÃ¶rpergrÃ¶ÃŸe auf das Gewicht zurÃ¼ckgefÃ¼hrt wird; also ein sehr eingÃ¤ngiges Modell.\nNeu ist dabei lediglich, dass die Parameter des Modells - \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) - jetzt Ã¼ber eine Post-Verteilung verfÃ¼gen. Die Post-Verteilung ist der Zusatznutzen der Bayes-Statistik. Die â€œnormaleâ€ Regression hat uns nur einzelne Werte fÃ¼r die Modellparameter geliefert (â€œPunktschÃ¤tzerâ€). Mit Bayes haben wir eine ganz Verteilung pro Parameter.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.2 Post-Verteilung der Regression",
    "text": "8.2 Post-Verteilung der Regression\n\n8.2.1 Einfache Regression\nDie (einfache) Regression prÃ¼ft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhÃ¤ngen. Je mehr sie zusammenhÃ¤ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). HÃ¤ngen \\(X\\) und \\(Y\\) zusammen, heiÃŸt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).2\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und GrÃ¶ÃŸe (Y), AbbildungÂ 8.1.\nd2 %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\nggscatter(d2,\n          x = \"weight\", y = \"height\",\n          add = \"reg.line\")\n\n\n\n\n\nMit ggplot2Mit ggpubr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 8.1: Der Zusammenhang zwischen Gewicht (X) und GrÃ¶ÃŸe (Y)\n\n\n\n\n\n8.2.2 Statistiken zum !Kung-Datensatz\nDie Daten kÃ¶nnen Sie hier herunterladen.\nTabelleÂ 8.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\nKung_path &lt;- \"data/Howell1a.csv\"  \nd &lt;- read_csv(Kung_path)  \n\nd2 &lt;- d %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(d2)\n\n\n\n\n\nTabelleÂ 8.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\n\n\nWie aus TabelleÂ 8.1 abzulesen ist, betrÃ¤gt das mittlere KÃ¶rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n\n8.2.3 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\nlibrary(DataExplorer)\n\n\n8.2.3.1 Gibt es fehlende Werte?\nNein, s. Abb. AbbildungÂ 8.2.\n\nd2 %&gt;% plot_missing()\n\n\n\n\n\n\n\nAbbildungÂ 8.2: Fehlende Werte - fehlen.\n\n\n\n\n\n\n\n8.2.3.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. AbbildungÂ 8.3.\n\nd2 %&gt;% plot_histogram()\n\n\n\n\n\n\n\nAbbildungÂ 8.3: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n\n8.2.3.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. AbbildungÂ 8.4.\n\nd2 %&gt;% plot_bar()\n\n\n\n\n\n\n\nAbbildungÂ 8.4: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n\n8.2.3.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in AbbildungÂ 8.5 dargestellt.\n\nd2 %&gt;% plot_correlation()\n\n\n\n\n\n\n\nAbbildungÂ 8.5: Korrelationsmatrix\n\n\n\n\n\n\nÃœbungsaufgabe 8.1 (EDA-Bericht) Probieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(d2). \\(\\square\\)\n\n\n\n\n8.2.4 PrÃ¤diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (PrÃ¤diktor â€œzentrierenâ€, engl. to center). Wenn man den PrÃ¤diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\beta_0\\), einfacher zu verstehen. In einem Modell mit zentriertem PrÃ¤diktor (weight) gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit durchschnittlichem Gewicht an. WÃ¼rde man weight nicht zentrieren, gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist. Vgl. Gelman, Hill, und Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen (mit Hilfe von center aus {easystats}):\n\nd3 &lt;- \n  d2 %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\nOder so, von Hand:\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\nweight_c\n\n\n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\nâˆ’9\n\n\n137\n32\n65\n0\nâˆ’13\n\n\n\n\n\n\n\nWie man sieht, ist die Verteilung â€œzur Seite geschobenâ€: Der Mittelwert liegt jetzt eben bei 0, s. AbbildungÂ 8.6.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.6: Das Zentrieren Ã¤ndert die Verteilungsform nicht, sondern â€œschiebtâ€ die Verteilung nur zur Seite\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem PrÃ¤diktor ist, nicht d2.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "href": "0900-lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.3 Modell m43: zentrierter PrÃ¤diktor",
    "text": "8.3 Modell m43: zentrierter PrÃ¤diktor\nğŸ“º PrÃ¤diktoren zentrieren\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wÃ¤re wohl die KÃ¶rpergrÃ¶ÃŸe? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa wÃ¤re es schÃ¶n, wenn wir die Daten so umformen kÃ¶nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum GlÃ¼ck geht das leicht: Wir zentrieren den PrÃ¤diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n8.3.1 Modelldefinition von m43\nFÃ¼r jede AusprÃ¤gung des PrÃ¤diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung fÃ¼r die abhÃ¤ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) fÃ¼r jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte fÃ¼r die Steigung \\(\\beta_1\\) und den Achsenabschnitt \\(\\beta_0\\) der Regressionsgeraden. AuÃŸerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der GrÃ¶ÃŸe (height) angibt; dieser Wert wird als exonentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\). GleichungÂ 8.1 stellt die Modelldefinition dar.\n\\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*} \\tag{8.1}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnit (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\beta_0\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ğŸ¤·\n\n\n\n\n8.3.2 Likelihood, m43\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m43 ist Ã¤hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines â€œIndex-iâ€ am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern fÃ¼r jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\nâ€œDie Wahrscheinlichkeit, eine bestimmte GrÃ¶ÃŸe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))â€.\n\n\n\n8.3.3 Regressionsformel, m43\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschÃ¤tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\beta_0\\) und \\(\\beta_1\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der PrÃ¤diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\nâ€œDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\beta_0\\) und \\(\\beta_1\\) mal \\(\\text{weight}_i\\)â€.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta_1\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\beta_0\\) gibt an, wie groÃŸ \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n8.3.4 Priori-Werte des Modells m43\n\\[\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen. \\(\\beta_0\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine â€œRegression ohne PrÃ¤diktorenâ€ berechnet haben. \\(\\sigma\\) ist uns schon als Parameter bekannt und behÃ¤lt seine Bedeutung aus dem letzten Kapitel. Da height nicht zentriert ist, der Mittelwert von \\(\\beta_0\\) bei 178 und nicht 0. \\(\\beta_1\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und GrÃ¶ÃŸe positiv (gleichsinnig) ist. Die Anzahl der Prioris entspricht der Anzahl der Parameter des Modells.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.4 Die Post-Verteilung befragen",
    "text": "8.4 Die Post-Verteilung befragen\nğŸ“º Post-Verteilung auslesen 1\nğŸ“º Post-Verteilung auslesen 2\n\n8.4.1 m43a\nSagen wir, auf Basis gut geprÃ¼fter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. GleichungÂ 8.2.\nPrioris:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{8.2}\\]\nWir nennen das Modell m43a3, s. ListingÂ 8.1.\n\n\n\nListingÂ 8.1: Modelldefinition von m43a in R\n\n\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest fÃ¼r Reproduzierbarkeit\n    data = d3)\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die NachprÃ¼fbarkeit der Ergebnisse (â€œReproduzierbarkeitâ€) sichergestellt4. Welche Wert fÃ¼r seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung schÃ¤tzen.\n\n\n\n\n8.4.2 Mittelwerte von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\n\nid\n(Intercept)\nweight_c\nsigma\n\n\n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters, s. TabelleÂ 8.2.\n\n\n\nTabelleÂ 8.2: Parameter von m43a\n\n\nparameters(m43a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 8.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also grÃ¶ÃŸer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) Ã„hnliches wie der p-Wert in der Frequentistischen Statistik (Makowski u.Â a. 2019).\n\nAm besten das Diagramm dazu anschauen, s AbbildungÂ 8.7.\n\nplot(p_direction(m43a))\n\n\n\n\n\n\n\nAbbildungÂ 8.7: Diagramm zur Probability of Direction, Modell m43a\n\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) grÃ¶ÃŸer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschÃ¤ftigen in diesem Kurs.\n\n\n8.4.3 Visualisieren der â€œmittlerenâ€ Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). Ãœberzeugen wir uns mit einem Blick in die Post-Verteilung von m43a:\n\nm43a %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n  \n\n\n\nWir kÃ¶nnen z.B. ein LagemaÃŸ wie den Median hernehmen, um die â€œmittlereâ€ Regressionsgerade zu betrachten.\n\nMit ggplotMit easystats\n\n\n\nd3 %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n\n\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. AbbildungÂ 8.8. Mit â€œexpectationâ€ sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\nm43_expect &lt;- estimate_expectation(m43a)   # aus {easystats}\nplot(m43_expect)\n\n\n\n\n\n\n\nAbbildungÂ 8.8: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n\n\n\n\n\n\n\n\n\n\n8.4.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\beta_0, \\beta_1, \\sigma\\).5 Hier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen kÃ¶nnen.\n\n8.4.4.1 LagemaÃŸe zu den Parametern\n\nWas ist die mittlere GrÃ¶ÃŸe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der SchÃ¤tzwert fÃ¼r den Zusammenhang von Gewicht und GrÃ¶ÃŸe? (\\(\\beta_1\\))\nWas ist der SchÃ¤tzwert fÃ¼r Ungewissheit in der SchÃ¤tzung der GrÃ¶ÃŸe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert fÃ¼r z.B: \\(\\beta_1\\)?\n\nEine nÃ¼tzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell), s. TabelleÂ 8.2.\n\n\n\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m43a, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\nm43a_post &lt;- \n  m43a %&gt;% \n  as_tibble()\n\nm43a_post %&gt;% \n  head()\n\n\n  \n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post. Jetzt haben wir wieder eine schÃ¶ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen kÃ¶nnen. Eine Visualisierung zeigt gut sowohl Lage- als auch StreuungsmaÃŸe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot oder ggpubr, s. AbbildungÂ 8.9.\n\nm43a_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\nAbbildungÂ 8.9: Postverteilung fÃ¼r den Parameter Gewicht (zentriert)\n\n\n\n\n\nAbbildungÂ 8.9 zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den hÃ¤ufigsten, d.h. hier also den wahrscheinlichsten, Wert an. Der Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\nm43a_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. AbbildungÂ 8.10.\n\nm43a_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\nAbbildungÂ 8.10: Die Post-Verteilung fÃ¼r den Parameter sigma, m43a\n\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s. AbbildungÂ 8.11.\n\nm43a_hdi &lt;- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\n\n\n\nAbbildungÂ 8.11: Die Parameter Gewicht (zentriert) und sigma des Modells m43a\n\n\n\n\n\nErgÃ¤nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n\n\n8.4.5 StreuungsmaÃŸe zu den Parametern\n\nWie unsicher sind wir uns in den SchÃ¤tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebrÃ¤uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen StabilitÃ¤t.\n\n\n\n\n8.4.6 Ungewissheit von \\(\\beta_0\\) und \\(\\beta_1\\) aus der Post-Verteilung visualisiert\n\n1010001000000\n\n\nDie ersten 10 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\n\n\n\n\n\n8.5 100\nDie ersten 100 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\n\n\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\n\n\n\n\n\nDie ersten 10000006 â€¦ okay, lassen wir es gut sein7.\n\n\n\nEinfacher ist die Visualisierung mit estimate_expectation, s. AbbildungÂ 8.12.\n\nestimate_expectation(m43a, seed = 42) %&gt;% plot()\n\n\n\n\n\n\n\nAbbildungÂ 8.12: SchÃ¤tzbereich fÃ¼r die bedingten mittleren KÃ¶rpergrÃ¶ÃŸe, also die Regressionsgerade mit Unsicherheitsintervall\n\n\n\n\n\n\n\n8.5.1 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten PrÃ¤diktor misst der Achsenabschnitt die mittlere GrÃ¶ÃŸe8.\n\n\n\nWelche mittlere GrÃ¶ÃŸe wird mit einer Wahrscheinlichkeit von 50%, 90% bzw. 95% Wahrscheinlichkeit nicht Ã¼berschritten?\nWelche mittlere GrÃ¶ÃŸe mit Wahrscheinlichkeit von 95% nicht unterschritten?\nVon wo bis wo reicht der innere 50%-SchÃ¤tzbereich der mittleren GrÃ¶ÃŸe?\n\nQuantile:\n\nm43a_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n  \n\n\n\n50%-PI:\n\nm43a %&gt;% \n  eti(ci = .5)\n\n\n  \n\n\n\n\n\n8.5.2 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe bei mind. 155 cm liegt?\n\nm43a_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe hÃ¶chstens 154.5 cm betrÃ¤gt?\n\nm43a_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n  \n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 Typischer Bayes-Nutzer in Aktion\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-1",
    "href": "0900-lineare-modelle.html#section-1",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.5 100",
    "text": "8.5 100\nDie ersten 100 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert",
    "text": "8.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert\n\n8.6.1 Bei jedem PrÃ¤diktorwert eine Post-Verteilung fÃ¼r \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns fÃ¼r jeden beliebigen Wert des PrÃ¤diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m42, s. AbbildungÂ 8.13.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.13: FÃ¼r jeden beliebigen PrÃ¤diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgewÃ¤hlten Gewichtswerten. B: FÃ¼r jeden beliebigen Gewichtswert bekommt man eine Post-Verteilung\n\n\n\n\n\n\n\n8.6.2 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der KÃ¶rpergrÃ¶ÃŸe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche KÃ¶rpergrÃ¶ÃŸe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns Ã¼ber diesen Mittelwert?\nEtwas formaler ausgedrÃ¼ckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten PrÃ¤diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\nmu_at_45 &lt;-\n  m43a_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\nUnd plotten diese, s. AbbildungÂ 8.14.\n\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\nAbbildungÂ 8.14: Post-Verteilung der GrÃ¶ÃŸe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\n\nAnalog kÃ¶nnen wir fragen, wie groÃŸ wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns Ã¼ber diesen Mittelwert sind.\n50 kg, das sind 5 Ã¼ber dem Mittelwert, in zentrierten Einheiten ausgedrÃ¼ckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle, s. TabelleÂ 8.3.\n\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\nTabelleÂ 8.3: Die Verteilung von mu bedingt auf ein Gewicht von 50kg.\n\n\n\n\n  \n\n\n\n\n\n\nDie Verteilung der mittleren GrÃ¶ÃŸe bei einem Gewicht von 50kg ist weiter â€œrechtsâ€ (Richtung hÃ¶here GrÃ¶ÃŸe) zentriert, s. AbbildungÂ 8.15.\n\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\nAbbildungÂ 8.15: Post-Verteilung der mittleren GrÃ¶ÃŸe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n\n8.6.3 LagemaÃŸe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der KÃ¶rpergrÃ¶ÃŸe.\nWas ist das 90% PI fÃ¼r \\(\\mu|w=50\\) ?\n\nmu_at_50 %&gt;% \n  eti(mu_at_50, ci = .9)\n\n\n  \n\n\n\nDie mittlere GrÃ¶ÃŸe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere GrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, wenn die Person 45kg wiegt?\n\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#prior-prÃ¤diktiv-verteilung",
    "href": "0900-lineare-modelle.html#prior-prÃ¤diktiv-verteilung",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.7 Prior-PrÃ¤diktiv-Verteilung",
    "text": "8.7 Prior-PrÃ¤diktiv-Verteilung\nğŸğŸï¸ VERTIEFUNG (nicht prÃ¼fungsrelevant ) ğŸğŸ\n\n8.7.1 Moment\nğŸ¤” Moment. Dieser Prior, \\(\\beta_1\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und GrÃ¶ÃŸe positiv oder negativ ist? Nein, sind wir nicht.\n\n\n8.7.2 Priori-PrÃ¤diktiv-Verteilung fÃ¼r m43\nWas denkt wir bzw. unser Golem apriori Ã¼ber den Zusammenhang von GrÃ¶ÃŸe und Gewicht? Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also fÃ¼r \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\).\n\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter fÃ¼r Prior-Pred-Verteilung\n             data = d3)\n\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n\n\na\nb\nsigma\n\n\n\n\n193.0\n24.7\n24.6\n\n\n192.1\n1.7\n3.1\n\n\n173.1\nâˆ’8.3\n0.5\n\n\n178.7\n12.3\n1.0\n\n\n174.3\n17.6\n9.2\n\n\n\n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n8.7.3 Prior-PrÃ¤diktiv-Simulation fÃ¼r m43 mit stan_glm()\n\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d3)\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n\n8.7.4 Visualisieren der Prior-PrÃ¤diktiv-Verteilung\n\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\nğŸ¤¯ Einige dieser Regressionsgeraden sind unsinnig!\n\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n\n8.7.5 Ein positiver Wert fÃ¼r \\(\\beta_1\\) ist plausibler\n\n8.7.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\n\n\n\n\nğŸ‘ \\(\\beta=-20\\) wÃ¤re mit diesem Prior gut mÃ¶glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n8.7.5.2 Oh yes\nWir brÃ¤uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x&gt;0):\n\n\n\n\n\n\n\n\n\nğŸ‘ Vermutlich besser: Ein GroÃŸteil der Wahrscheinlichkeitsmasse ist \\(X&gt;0\\). Allerdings gibtâ€™s keine GewÃ¤hr, dass unser Prior â€œrichtigâ€ ist.\n\n\n\n8.7.6 Priori-PrÃ¤diktiv-Simulation, 2. Versuch\n\nm43a_prior_pred &lt;-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter fÃ¼r Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d3)\n\n\nm43a_prior_pred_draws &lt;- \n  m43a_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  # Spaltennamen kÃ¼rzen: \n  rename(a = `(Intercept)`) %&gt;%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n\n\na\nb\ns\n\n\n\n\n187.0\n0.6\n10.9\n\n\n170.6\n7.2\n11.5\n\n\n182.1\n3.4\n22.5\n\n\n184.6\nâˆ’0.2\n5.5\n\n\n185.7\n1.2\n3.7\n\n\n\n\n\n\n\nDas Argument prior_PD = TRUE sorgt dafÃ¼r, dass keine Posteriori-Verteilung, sondern eine Prior-PrÃ¤diktiv-Verteilung berechnet wird.\n\n\n8.7.7 Visualisieren der Prior-PrÃ¤diktiv-Verteilung, m43a\nUnsere Priori-Werte scheinen einigermaÃŸen vernÃ¼nftige Vorhersagen zu tÃ¤tigen. Allerdings erwartet unser Golem einige Riesen.\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %&gt;% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n\n8.7.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p.Â 96.\n\n\n8.7.9 Hier ist unser Modell, m43a\n\\[\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\\]\n\n# Posteriori-Vert. berechnen:\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # Zufallszahlen festlegen\n    data = d3)\n\n\n\n8.7.10 Eine Zusammenfassung der Posteriori-Verteilung fÃ¼r m43a\n\nm43a %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nUnser Modell m43a schÃ¤tzt die typische KÃ¶rpergrÃ¶ÃŸe einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugehÃ¶rige 95%-CI keine 20 Zentimenter umfasst.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#die-ppv-befragen",
    "href": "0900-lineare-modelle.html#die-ppv-befragen",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.8 Die PPV befragen",
    "text": "8.8 Die PPV befragen\nğŸğŸï¸ VERTIEFUNG (nicht prÃ¼fungsrelevant ) ğŸğŸ\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) gibt uns die MÃ¶glichkeit, nach der Wahrscheinlichkeit tatsÃ¤chlicher KÃ¶rpergrÃ¶ÃŸen zu fragen - und nicht nur nach mittleren KÃ¶rpergrÃ¶ÃŸen anhand der Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren KÃ¶rpergrÃ¶ÃŸe, denn das ist was wir modellieren wollten. MÃ¶chten wir Aussagen zur Wahrscheinlichkeit tatsÃ¤chlicher GrÃ¶ÃŸen treffen, brauchen wir die PPV. Allgemeiner gesagt: Die PPV macht Vorhersagen auf Basis eines Modells. FÃ¼r jede Vorhersage gibt es eine Verteilung, die wir zu einem PunktschÃ¤tzer (z.B. Median) und einem SchÃ¤tzbereich (z.B. 89%-HDI) zusammenfassen kÃ¶nnen.\n\n\nAn dieser Stelle sollten wir uns vor Augen fÃ¼hren, dass die PPV mehr Ungewissheit beinhaltet, denn sie berÃ¼cksichtigt derer zweier Arten:\n\nUngewissheit bzgl. der Modellparameter (Steigung und Achsenabschnitt der Regressionsgeraden)\nUngewissheit der Vorhersagen (das Modell macht keine perfekten Vorhersagen)\n\nDie Post-Verteilung berÃ¼cksichtigt nur die Ungewissheit in den Modellparametern, macht also nur Aussagen zur Regressionsgeraden.\nDie PPV macht Aussagen fÃ¼r konkrete Beobachtungen. Der Unterschied ist in AbbildungÂ 8.16 dargestellt; die Funktionen stammen Ã¼brigens aus {easystats}.\nestimate_prediction(m43a) %&gt;% plot()\nestimate_relation(m43a) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) PPV mit viel Ungewissheit\n\n\n\n\n\n\n\n\n\n\n\n(b) Post-Verteilung mit wenig(er) Ungewissheit\n\n\n\n\n\n\n\nAbbildungÂ 8.16: PPV vs.Â Post-Verteilung\n\n\n\n\n8.8.1 Perzentil-Intervalle fÃ¼r bestimmte PrÃ¤diktor-Werte\n\nWie groÃŸ ist ein !Kung-Mann mit mittlerem Gewicht?\n\n\nset.seed(42)\nestimate_prediction(m43a, data = tibble(weight_c = 0), seed = 42)\n\n\n  \n\n\n\nUnser Modell, ma43a schÃ¤tzt ca. 145cm bis 165cm.\nWir kÃ¶nnen uns auch eine Sequenz an PrÃ¤diktorwerten, die uns interessieren, erstellen, s. weight_df:\n\nweight_df &lt;- tibble(weight_c = seq(-20,20, by = 5))\n\nFÃ¼r diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\nmus &lt;- \n  estimate_prediction(m43a, data = weight_df) \n\nhead(mus)\n\n\n  \n\n\n\nUm die Perzentilintervalle zu erstellen, wird von estimate_prediction() fÃ¼r jeden PrÃ¤diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil dafÃ¼r berechnet. Sie kÃ¶nnen die Voreinstellung Ã¤ndern mittels des Arguments ci; um ein 89%-PI zu berechnen, wÃ¼rde man z.B. schreiben ci = .89.\nUm Reproduzierbarkeit sicherzustellen, haben wir mit set.seed(42) die Zufallszahlen fixiert.\nHoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedrÃ¼ckt; die PPV gibt die Ungewissheit tatsÃ¤chlicher beobachtbarer KÃ¶rpergrÃ¶ÃŸen aus, nicht nur die Ungewissheit zum Mittelwert.\nBerechnen wir die PPV fÃ¼r die bestehenden Beobachtungen aus m43a:\n\nppv_m43a &lt;- estimate_prediction(\n  m43a,\n  data = weight_df)\n\nmus \n\n\n  \n\n\n\n\n\n8.8.2 Perzentilintervalle fÃ¼r verschiedenen PrÃ¤diktorwerte visualisiert\nAbbildungÂ 8.17 visualisiert die Ungewissheit von Vorhersagen laut der PPV. Die Ungewissheit in AbbildungÂ 8.17 ist die Antwort auf die Frage: â€œWie sicher sind wir uns, zur GrÃ¶ÃŸe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?â€ Eine Vorhersage bezeichnet man auch als â€œbedingte Verteilungâ€, da man den Wert einer Verteilung voraussagt, gegeben einer Bedingung, z.B. weight_c = 10.\n\n\n\n\n\n\n\n\nAbbildungÂ 8.17: Visualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV grÃ¶ÃŸer als die der Post-Verteilung.\n\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung, s. AbbildungÂ 8.18; je dicker die â€œKatzenaugenâ€, desto mehr Stichproben (samples) liegen vor an der Stelle, und umso genauer ist die SchÃ¤tzung.\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 8.18: Die PPV fÃ¼r bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\n\n\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu | w_i\\).\n\n\n8.8.3 Die PPV Ã¼ber alle Beobachtungen visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV fÃ¼r einen bestimmten PrÃ¤diktorwert, z.B. bei einer Person mittleren Gewichts. Wir kÃ¶nnen auch den Mittelwert Ã¼ber alle bedingten PPV anschauen, sozusagen die â€œMaster-PPVâ€ oder â€œunbedingte PPVâ€ oder schlicht PPV. Vergleichen wir die echten Werte fÃ¼r height, \\(y\\), mit den von der PPV simulierten Werten fÃ¼r height, \\(y_{rep}\\), s. AbbildungÂ 8.19.\n\ncheck_predictions(m43a)  # aus easystatss\n\n\n\n\n\n\n\nAbbildungÂ 8.19: Vergleich der Vorhersagen fÃ¼r y (leichte, blaue Linien) mit der beobachteten Verteilung von y\n\n\n\n\n\n?check_predictions zeigt Hilfe fÃ¼r diese Funktion. Die Funktion zeigt die Vorhersagen fÃ¼r die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n8.8.4 Fragen an die Master-PPV\n\nWie groÃŸ sind die !Kung im Schnitt?\nWelche GrÃ¶ÃŸe wird von 90% der Personen nicht Ã¼berschritten?\nWie groÃŸ sind die 10% kleinsten?\n\n\nppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\nhead(ppv_m43a)\n\n\n  \n\n\n\n\nppv_m43a &lt;-\n  ppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\nhead(ppv_m43a)\n\n\n  \n\n\n\n\nppv_m43a %&gt;% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n\n  \n\n\n\nWas ist der 50% Bereich der KÃ¶rpergrÃ¶ÃŸe?\n\nppv_m43a %&gt;% \n  eti(ci = .5)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#fazit",
    "href": "0900-lineare-modelle.html#fazit",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.9 Fazit",
    "text": "8.9 Fazit\n\n8.9.1 Ausstieg\n\nBeispiel 8.3 (Fassen Sie das Wesentliche zusammen!) Schreiben Sie 5-10 SÃ¤tze zum Wesentlichen Stoff dieses Kapitels und reichen Sie bei der von Lehrkraft vorgegebenen Stelle ein! \\(\\square\\)\n\n\n\n8.9.2 Vertiefung\nMcElreath (2020) bietet eine tiefere Darstellung von linearen Modellen auf Basis der Bayes-Statistik, insbesondere Kapitel 4 daraus vertieft die Themen dieses Kapitels. Kurz (2021) greift die R-Inhalte von McElreath (2020) auf und setzt sie mit anderen R-Methoden um; ein interessanter Blickwinkel, wenn man tiefer in die R-Umsetzung einsteigen mÃ¶chte. Gelman, Hill, und Vehtari (2021) bieten ebenfalls viele erhellende Einblicke in das Thema Regressionsanalyse, sowohl aus einem frequentistischen als auch aus einer Bayes-Perspektive.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.10 Aufgaben",
    "text": "8.10 Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nLikelihood2\nPost-befragen1\nPostvert-Regr-01\nregression1a\nRegression2\nBed-Post-Wskt1\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\npenguins-stan-01",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "0900-lineare-modelle.html#section-4",
    "href": "0900-lineare-modelle.html#section-4",
    "title": "8Â  Einfache lineare Modelle",
    "section": "8.11 â€”",
    "text": "8.11 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel LÃ¼decke. 2019. â€Indices of Effect Existence and Significance in the Bayesian Frameworkâ€œ. Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Einfache lineare Modelle</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\nden Unterschied zwischen dem SchÃ¤tzen von Modellparametern und dem Testen von Hypothesen erlÃ¤utern\nVor- und Nachteile des SchÃ¤tzens und Testens diskutieren\nDas ROPE-Konzept erlÃ¤utern und anwenden\nDie GÃ¼te von Regressionsmodellen einschÃ¤tzen und berechnen\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an (Kruschke 2018).\n\n9.1.4 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.5 BenÃ¶tigte Daten\nWir benÃ¶tigen in diesem Kapitel folgenden Datensatz: penguins.\nSie kÃ¶nnen den Datensatz penguins entweder via dem Pfad importieren:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n Download \nOder via dem zugehÃ¶rigen R-Paket:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nBeide MÃ¶glichkeit sind okay.\n\n9.1.6 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\nâ€œLernen fÃ¼r die Klausur bringt etwas!â€\nâ€œWie viel bringt Lernen fÃ¼r die Klausur?â€\n\n\nBeispiel 9.1 Diskutieren Sie die epistemologische Ausrichtung sowie mÃ¶gliches FÃ¼r und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#schÃ¤tzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#schÃ¤tzen-oder-testen",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.2 SchÃ¤tzen oder Testen?",
    "text": "9.2 SchÃ¤tzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen prÃ¼fend: â€œDie Daten widerlegen die Hypothese (nicht)â€\n\nParameter schÃ¤tzend: â€œDer Effekt von X auf Y liegt zwischen A und Bâ€.\n\n\n9.2.1 Hypothesen prÃ¼fen\nHypothesen prÃ¼fende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann natÃ¼rlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 9.2 (â€œLernen erhÃ¶ht den PrÃ¼fungserfolgâ€) Die Hypothese Lernen erhÃ¶ht den PrÃ¼fungserfolg kann durch eine Studie und eine entsprechende Analyse grundsÃ¤tzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts fÃ¼r den Klausurerfolg. 2) Die Daten unterstÃ¼tzen die Hypothese: Lernen erhÃ¶ht den PrÃ¼fungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den PrÃ¼fungserfolg mÃ¶glich. \\(\\square\\)\n\nDas PrÃ¼fen einer Hypothese kann zu drei Arten von Ergebnissen fÃ¼hren. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\nğŸŸ¢ Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die GlaubwÃ¼rdigkeit der Hypothese gelitten.\nğŸŸ¥ Die Daten unterstÃ¼tzen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an GlaubwÃ¼rdigkeit gewonnen.\nâ“ Die Datenlage ist unklar; zum Teil unterstÃ¼tzen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum SchlÃ¼sse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen prÃ¼fen ist binÃ¤r in dem Sinne, dass sie zu â€œSchwarz-WeiÃŸ-Ergebnissenâ€ fÃ¼hren (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine gÃ¤ngige Variante des Hypothesen testen1 ist das Testen der Hypothese â€œkein Effektâ€ (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n9.2.2 Beispiele fÃ¼r Nullhypothesen\n\nâ€œLernen bringt nichtsâ€\nâ€œFrauen und MÃ¤nner parken gleich schnell einâ€\nâ€œEs gibt keinen Zusammenhang von Babies und StÃ¶rchenâ€\nâ€œFrÃ¼her war es auch nicht besser (sondern gleich gut)â€\nâ€œBei Frauen ist der Anteil, derer, die Statistik mÃ¶gen gleich hoch wie bei MÃ¤nnernâ€ (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterstÃ¼tzen kann, da es die KomplexitÃ¤t reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht bestÃ¤tigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht bestÃ¤tigen (verifizieren) kann, hat groÃŸen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausgeÃ¼bt (Popper 2013). Schlagend ist das Beispiel zur Hypothese â€œAlle SchwÃ¤ne sind weiÃŸâ€. Auch eine groÃŸe Stichprobe an weiÃŸen SchwÃ¤nen kann die Wahrheit der Hypothese nicht beweisen. SchlieÃŸlich ist es mÃ¶glich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben.2 Umgekehrt reicht die (zuverlÃ¤ssige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im bestÃ¤tigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverlÃ¤ssiger, reprÃ¤sentativer Daten erscheint plausibel, dass Hypothesen sowohl bestÃ¤tigt als auch widerlegt werden kÃ¶nnen (Kruschke 2018; Morey und Rouder 2011). \\(\\square\\)\n\n\n\n9.2.3 Parameter schÃ¤tzen\nBeim Parameter schÃ¤tzen untersucht man, wie groÃŸ ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein â€œja/neinâ€, was beim Hypothesen testen der Fall ist.\nBeim Parameter schÃ¤tzen gibt es zwei Varianten:\n\nâš«ï¸ PunktschÃ¤tzung: Das SchÃ¤tzen eines einzelnen Parameterwerts, sozusagen ein â€œBest Guessâ€\nğŸ“ BereichsschÃ¤tzung: Das SchÃ¤tzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Parameter schÃ¤tzen auch wie einen Hypothesentest nutzen: Ist ein bestimmter Wert, etwa die Null, nicht im SchÃ¤tzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 9.3 (ParameterschÃ¤tzen als Nullhypothesentest) Â \n\nForschungsfrage: Sind mÃ¤nnliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nGleichungÂ 9.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0 \\tag{9.1}\\]\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nm1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\nDann zÃ¤hlen wir einfach den Anteil der Stichproben in der Post-Verteilung fÃ¼r die UV sexmale, die einen Wert grÃ¶ÃŸer Null aufweisen:\n\nm1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert grÃ¶ÃŸer Null fÃ¼r sexmale, dass also weibliche Tiere leichter bzw. mÃ¤nnliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der fÃ¼r das Gegenteil spricht (das weibliche Tiere schwerer wÃ¤ren). Damit resÃ¼mieren wir, dass unser Modell 100% Wahrscheinlichkeit fÃ¼r die Hypothese einrÃ¤umt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der ParameterschÃ¤tzung ist die Nuanciertheit des Ergebnisses, die der KomplexitÃ¤t echter Systeme besser Rechnung trÃ¤gt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.3 ROPE: Bereich von â€œpraktisch Nullâ€",
    "text": "9.3 ROPE: Bereich von â€œpraktisch Nullâ€\nğŸ“º Teil 2\nNullhypothesen sind fast immer falsch, s. AbbildungÂ 9.1.\n\n\n\n\n\n\n\nAbbildungÂ 9.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman, Hill, und Vehtari 2021)\n\n\n9.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist.3\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht. ğŸ¤·â€â™€ï¸\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n9.3.2 â€œPraktischâ€ kein Unterschied: Das Rope-Konzept\nğŸ“º ROPE-Video\n\nBeispiel 9.4 (Beispiele fÃ¼r ROPE) Sagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g â€œvernachlÃ¤ssigbar wenigâ€ ist.\nEine findige GeschÃ¤ftsfrau entscheidet fÃ¼r ihre Firma, dass ein Umssatzunterschied von 100k Euro â€œpraktisch irrelevantâ€ sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt. Unter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroÃŸteil liegt innerhalb von Rope â¡ï¸ Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nGroÃŸteil liegt auÃŸerhalb von Rope â¡ï¸ Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nAnsonsten â¡ï¸ keine Entscheidung\n\n9.3.3 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat. Ein vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die GrÃ¶ÃŸe des ROPE Â±5% der SD der AV. \\(\\square\\)\n\n\n\n9.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildungÂ 9.2: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\n\nAbbildungÂ 9.2 illustriert die Entscheidungsregel zum ROPE fÃ¼r mehrere Situatioenen (Kruschke 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett auÃŸerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung mÃ¶glich; die Datenlage ist unklar.\n\n9.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erklÃ¤rt (m10.6).\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nDen Rope berechnet man mit rope(model).\n\nrope(m10.6)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir kÃ¶nnen daher fÃ¼r diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschlieÃŸende Entscheidung Ã¼ber die Hypothese mÃ¶glich.\nAber: Gentoo liegt zu 0% im Rope. FÃ¼r Gentoo kÃ¶nnen wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n9.3.6 Visualisierung unserer Rope-Werte, m10.6\n\nEin GroÃŸteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut.\n\n\nplot(rope(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung fÃ¼r Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir kÃ¶nnen das Nullhypothese fÃ¼r Chinstrap nicht verwerfen, aber auch nicht bestÃ¤tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom â€œblauen Flussâ€ des Rope: Gentoo liegt auÃŸerhalb des Rope. Es gibt einen â€œsubstanziellenâ€ Unterschied, grÃ¶ÃŸer als das ROPE. Wir verwerfen die â€œPraktisch-Null-Hypotheseâ€ in diesem Fall.\n\n9.3.7 Finetuning des Rope\nWir kÃ¶nnen festlegen, was wir unter â€œpraktischer Ã„quivalenzâ€ verstehen, also die Grenzen des Ropes verÃ¤ndern. Sagen wir, 100 Gramm sind unsere Grenze fÃ¼r einen vernachlÃ¤ssigbaren Effekt, s. AbbildungÂ 9.3.\n\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 9.3: ROPE mit selber eingestellter Grenze von Â±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht fÃ¼r ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n9.3.8 Beantwortung der Forschungsfrage\nFÃ¼r die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. FÃ¼r Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellgÃ¼te",
    "href": "1050-Schaetzen-Testen.html#modellgÃ¼te",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.4 ModellgÃ¼te",
    "text": "9.4 ModellgÃ¼te\n\n\n\n\n\n\n\n\n\n\n\n9.4.1 Wozu ModellgÃ¼te?\nHat man ein Modell aufgestellt und geprÃ¼ft und Ergebnisse erhalten, mÃ¶chte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der ModellgÃ¼te. Diese Kennwerte zielen z.B. darauf ab, wie prÃ¤zise die Aussagen des Modells sind. Je prÃ¤ziser die Aussagen eines Modells, desto nÃ¼tzlicher ist es natÃ¼rlich. Bei einer ParameterschÃ¤tzung erhÃ¤lt man auch Informationen zur PrÃ¤zision der SchÃ¤tzung: Ist der SchÃ¤tzbereich schmal, so ist die SchÃ¤tzung prÃ¤zise (und vice versa). Allerdings kÃ¶nnte ein Modell aus mehreren ParameterschÃ¤tzungen bestehen, die unterschiedlich prÃ¤zise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur PrÃ¤zision, oder allgemeiner zur GÃ¼te des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebrÃ¤uchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n9.4.2 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt. - HÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt. \\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert. Solch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor. Daher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\n\n\n\n\n\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. AbbildungÂ 9.4.\n\nm10.6_r2 &lt;-\n  m10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 9.4: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n9.4.3 Definition vom â€œklassischenâ€ \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die â€œtypischeâ€ Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nÃ¼tzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklÃ¤rten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck Ã¤quivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen AusdrÃ¼cke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlÃ¤ssigen Ungewissheit; sie sind Ã¼bergewiss aus Bayes-Sicht.\n\n9.4.4 Bayesâ€™ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der ModellgÃ¼te miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkÃ¤rte Varianz}}{\\text{ErklÃ¤rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. FÃ¼r jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklÃ¤rten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u.Â a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.5 Fazit",
    "text": "9.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der VorzÃ¼ge der ParameterschÃ¤tzung. MÃ¶chte man aber, um sich bestimmter bestehender Forschung anzunÃ¤hern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n9Â  SchÃ¤tzen vs.Â Testen\n",
    "section": "\n9.6 Aufgaben",
    "text": "9.6 Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope-regr\nrope1\nrope2\nrope3\n\n\n\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. â€R-Squared for Bayesian Regression Modelsâ€œ. The American Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKruschke, John K. 2018. â€Rejecting or Accepting Parameter Values in Bayesian Estimationâ€œ. Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nMorey, Richard D., und Jeffrey N. Rouder. 2011. â€Bayes Factor Approaches for Testing Interval Null Hypothesesâ€œ. Psychological Methods 16 (4): 406â€“19. https://doi.org/10.1037/a0024377.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Herausgegeben von Herbert Keuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>SchÃ¤tzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n10.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme Ã¼bersetzen\ntypische Forschungsfragen auswerten\n\n10.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 4.4 sowie Gelman, Hill, und Vehtari (2021), Kap. 7 und 10.\n\n10.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 2â€\n\n10.1.5 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n10.1.6 BenÃ¶tigte Daten\nWir benÃ¶tigen in diesem Kapitel folgende DatensÃ¤tze: kidiq, penguins.\n\n10.1.6.1 kidiq\n\nDen Datensatz kidiq importieren Sie am einfachsten aus dem R-Paket rstanarm, das Sie schon installiert haben.\n\ndata(\"kidiq\", package = \"rstanarm\")\n\nAlternativ kÃ¶nnen Sie die Daten hier herunterladen.\n Download \n\n10.1.6.2 penguins\n\nSie kÃ¶nnen den Datensatz penguins entweder via dem Pfad importieren:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n Download \nOder via dem zugehÃ¶rigen R-Paket:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nBeide MÃ¶glichkeit sind okay.\n\n10.1.7 Einstieg\n\nBeispiel 10.1 (Was waren noch mal die Skalenniveaus?) Um Forschungsfragen zu klassifizieren, mÃ¼ssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.1 \\(\\square\\)\n\n\nBeispiel 10.2 (Was war noch einmal die Interaktion?) ErkÃ¤ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!2 \\(\\square\\)\n\n\n10.1.8 Ãœberblick\nWenn Sie die Skalenniveaus wissen, kÃ¶nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren. Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und Ã¤hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil, dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, â€¦) lernen mÃ¼ssen. AuÃŸerdem ist die Regressionsanalyse (fÃ¼r viele Situationen) die beste Heransgehensweise, da sie viele MÃ¶glichkeiten fÃ¼r Erweiterungen bietet. Entsperchend ist das Thema dieses Kapitels gÃ¤ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen. Wenn Sie die Grundkonzepte der Regression schon kennen, wird Ihnen vieles sehr bekannt vorkommen. NatÃ¼rlich wÃ¼rzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-KÃ¼che. Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "href": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.2 Arten von Forschungsfragen",
    "text": "10.2 Arten von Forschungsfragen\n\n10.2.1 Nach dem Erkenntnisziel\nğŸ“„ Deskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\nğŸ”® PrÃ¤diktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der GrÃ¶ÃŸe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts fÃ¼r die Klausur lernt?\nWie viel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhÃ¤lt?\n\nğŸ”— PrÃ¤skriptiv (erklÃ¤rend, kausal)\n\nIst GrÃ¶ÃŸe eine Ursache von Gewicht (bei deutschen MÃ¤nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklÃ¤rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehÃ¶rt.\n\n\n\n10.2.2 Nach dem Skalenniveau\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus.\nFÃ¼r die UV(s) sind nominale und metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.\n\n10.2.3 Varianten von Forschungsfragen\nIm Folgenden sind beispielhafte, hÃ¤ufig verwendete Arten von Forschungsfragen aufgefÃ¼hrt. FÃ¼r jede Variante ist ein Beispiel, die Modellformel, der Kausalgraph3, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet, um die Skalenmniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:\n\n\ny: metrische abhÃ¤ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabhÃ¤ngige Variable (querschnittlich)\n\nb: binÃ¤re Variable\n\nx: metrische unabhÃ¤ngige Variable\n\nu: ungemessene Variable",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-b",
    "href": "1000-metrische-AV.html#y-b",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.3 y ~ b\n",
    "text": "10.3 y ~ b\n\n\n10.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im Ã¶ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwÃ¤ndigen Studie die Intelligenz vieler Kinder gemessen. ZusÃ¤tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, â€œRisikofaktorenâ€ fÃ¼r geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in AbhÃ¤ngigkeit davon, ob ihre jeweilige Mutter Ã¼ber einen Schlusabschluss (mom_hs, \\(x=1\\)) verfÃ¼gt (bzw. nicht, \\(x=0\\))? (ceteris paribus)4.\n\nDie Modellformel zur Forschungsfrage lautet: y ~  b bzw. kid_iq ~ mom_hs.\nFormaler ausgedrÃ¼ckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (GleichungÂ 10.1):\n\\[\\mu_{x=1|\\alpha, \\beta, \\sigma} \\ne \\mu_{x=0|\\alpha, \\beta, \\sigma} \\tag{10.1}\\]\nDie Modellformel zur Forschungsfrage lautet: y ~ b bzw. kid_iq ~ mom_hs.\nDer Kausalgraph zur Modellformel sieht aus in AbbildungÂ 10.1 dargestellt. Y hat, laut unserem Modell, drei Ursachen:\n\nb\nx\nu, das steht fÃ¼r â€œunbekanntâ€5\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.1: DAG fÃ¼r kid_iq ~ mom_hs\n\n\n\n\n\n10.3.2 IQ von Kindern, binÃ¤rer PrÃ¤diktor\n\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. TabelleÂ 10.1.\n\n\n\nTabelleÂ 10.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nIn AbbildungÂ 10.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\nestimate_expectation(m10.1) %&gt;% plot()\n\n\n\n\n\n\n\n\nAbbildungÂ 10.2: Kinder, deren MÃ¼tter Ã¼ber einen Schulabschluss verfÃ¼gen, haben im Mittel einen hÃ¶heren Intelligenztestwert, laut dem vorliegenden Modell\n\n\n\n\n\n10.3.3 Interpretation von m10.1\n\nm10.1: kid_score = 78 + 12*mom_hs + error\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss (mom_hs = 0) verfÃ¼gen:\nkid_score = 78 + 0*12 + error\nDas Regressionsgewicht (slope, \\(\\beta_1\\), \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit MÃ¼tter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit MÃ¼tter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\nkid_score = 78 + 1*12 + error = 90 + error\nDer Wert von error zeigt, wie genau die SchÃ¤tzung (Vorhersage) ist bzw. wie stark PrÃ¤diktor (UV) und Kriterium (AV) zusammenhÃ¤ngen.\nerror entspricht dem Vorhersagefehler, also dem Unterschied vom tatsÃ¤chlichen IQ-Wert des Kindes (\\(y\\)) zum vom Modell vorhergesagten Wert (\\(\\hat{y}\\)).\n\n10.3.4 m10.1 als Mittelwertsdifferenz\n\nUV: binÃ¤r (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\n\nğŸ‘¨â€ğŸ« Hey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heiÃŸen kid_score_avg. An die Arbeit!\n\n\nğŸ¤– Loving it!\n\n\n\nR-Code\nAusgabe\n\n\n\n\nkidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.55\n\n\n1\n89.32\n\n\n\n\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von MÃ¼ttern mit Abschluss.\n\n\n\n\n10.3.5 t-Test\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation - Mittelwertsdifferenz zwischen zwei Gruppen - mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, das prÃ¼ft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).6 In der Bayes-Statistik betrachtet man dazu stattdessen z.B. die Posteriori-Verteilung (z.B. mit 95%PI).\n\n10.3.6 Antwort auf die Forschungsfrage, m10.1\n\nBetrachten wir die Ergebnisse von m10.1.\n\n\nR-Code\nAusgabe\n\n\n\n\nm10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schÃ¶nere Namen\n\n\n\nHier sind die ersten paar Zeilen, s. TabelleÂ 10.2.\n\n\n\nTabelleÂ 10.2: m10.1, Postverteilung, ersten paar Zeilen\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n\n\nAchsenabschnitt\nmomhs\nsigma\n\n\n\n\n75.9\n11.5\n19.3\n\n\n78.6\n10.8\n21.2\n\n\n79.0\n10.2\n18.7\n\n\n79.1\n9.5\n19.8\n\n\n80.3\n8.5\n19.8\n\n\n\n\n\n\n\n\n\n\n\n\nBerechnen wir ein 95%-PI von Hand:7\n\npi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlieÃŸend die Posteriori-Verteilung, s. AbbildungÂ 10.3.\n\nplot(eti(m10.1))\n\n\n\n\n\n\nAbbildungÂ 10.3: Das 95% ETI zum (statistischen) Effekt des mÃ¼tterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem â€œEffektâ€ zu sprechen, lÃ¤sst in den meisten KÃ¶pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang.\n\n\n\n\n\n\n\n\n\n\n10.3.7 Toleranzbereich\nBerechnet man ein Regressionsmodell mit stan_glm (ğŸ¤–ğŸ˜), dann zieht man dabei Zufallszahlen ğŸ². Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zufÃ¤llig. Das erklÃ¤rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels stan_glm von denen in diesem Buch abweichen kÃ¶nnen.\nUm zu prÃ¼fen, ob Ihre Ergebnisse â€œÃ¤hnlich genugâ€ oder â€œinnerhalb eines Toleranzbereichsâ€ sind, kann man die Funktion is_in_tolerance() aus dem R-Paket prada nutzen.\n\n\n\n\n\n\nHinweis\n\n\n\nGrÃ¶ÃŸe des Toleranzbereichs Die GrÃ¶ÃŸe des relativen Toleranzbereichs ist auf 5% festgelegt. Das heiÃŸt, ein Unterschied von 5% zwischen einem Referenzwert (dem â€œwahrenâ€ Wert) und Ihrem Wert ist okay, also im Toleranzbereich. AuÃŸerdem gibt es noch einen absoluten Toleranzbereich, der auf 5% der SD der AV festgelegt ist (bei Regressionsmodellen). Der grÃ¶ÃŸere der beiden Werte gilt. \\(\\square\\)\n\n\nZuerst mÃ¼ssen Sie das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN), das geht z.B. so:\n\nlibrary(remotes)  # dieses Paket kÃ¶nnen Sie mit `install.packages(\"remotes\") installieren\ninstall_github(\"sebastiansauer/prada\")\n\nDann starten Sie es wie gewohnt:\n\nlibrary(prada)\n\nDann testen Sie, ob Ihr Modellparameter, z.B. \\(\\beta_1\\) innerhalb eines Toleranzbereichs liegt.\nSagen wir der â€œrichtigeâ€ oder â€œwahreâ€ Wert (oder schlicht der Wert einer MusterlÃ¶sung) fÃ¼r \\(\\beta_0\\) ist 77. Unser Wert sei 77.56. Liegt dieser Wert noch innerhalb eines Toleranzbereichs?\n\nis_in_tolerance(asis = 77.56,  # Ihr Wert\n                tobe = 77,   # Referenzwert\n                tol_rel = .05,   # relative Toleranz\n                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz\n                )\n## [1] TRUE\n\nJa, unser Wert ist innerhalb des Toleranzbereichs. âœ…",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b",
    "href": "1000-metrische-AV.html#y-x-b",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.4 y ~ x + b\n",
    "text": "10.4 y ~ x + b\n\n\n10.4.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b bzw. kid_score ~ mom_iq + mom_hs.\nDer Kausalgraph8 zur Modellformel sieht aus in AbbildungÂ 10.4 dargestellt. Laut unserem Modell ist y also eine Funktion zweier (kausaler) EinflÃ¼sse, b und u, wobei u fÃ¼r â€œunbekanntâ€ steht, also fÃ¼r alle sonstigen EinflÃ¼sse.9\n\n\n\n\n\n\n\nAbbildungÂ 10.4: DAG fÃ¼r y ~ b\n\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle TabelleÂ 10.3 dargestellt.\n\ndata(\"kidiq\")  # Paket rstanarm, alternativ Ã¼ber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\nTabelleÂ 10.3: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\n\n\n\n10.4.2 1 metrischer PrÃ¤diktor\nBerechnen wir folgendes Modell: kid_score ~ mom_iq (m10.2), s. Tab. TabelleÂ 10.4.\n\nm10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\nTabelleÂ 10.4: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\n\nmit ggplot2\nMit easystats\n\n\n\nVisualisieren wir uns noch das Modell m10.2, s. AbbildungÂ 10.5.\n\nkidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\n\nAbbildungÂ 10.5: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets easystats, s. AbbildungÂ 10.6.\n\nplot(estimate_expectation(m10.2))\n\n\n\n\n\n\nAbbildungÂ 10.6: Die geschÃ¤tzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder fÃ¼r verschiedene IQ-Werte der MÃ¼tter. Vergleicht man Teilpopulationen von MÃ¼ttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n10.4.3 Beide PrÃ¤diktoren, m10.3\n\nBerechnen wir als nÃ¤chstes ein Modell mit beiden PrÃ¤diktoren: kid_score ~ mom_hs + mom_iq, s. TabelleÂ 10.5.\n\nm10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\nTabelleÂ 10.5: Parameter des Modells m10.3 (ohne sigma)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. PunktschÃ¤tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\nm10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error\nMÃ¶chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\nAber natÃ¼rlich ist es mÃ¶glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. AbbildungÂ 10.7.\n\nkidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\nplot(estimate_expectation(m10.3a))\n\n\n\n\n\n\nAbbildungÂ 10.7: Der Effekt von sowohl mÃ¼tterlicher Intelligenz als auch mÃ¼tterlichem Schulabschluss.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schÃ¤tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum mÃ¼tterlichen Schulabschluss: Vergleicht man Kinder von MÃ¼ttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur mÃ¼tterlichen IQ: Vergleicht man Kinder von MÃ¼ttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x-b-xb",
    "href": "1000-metrische-AV.html#y-x-b-xb",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.5 y ~ x + b + x:b\n",
    "text": "10.5 y ~ x + b + x:b\n\n\n10.5.1 Interaktion zur Modellformel hinzufÃ¼gen\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 das Modell mit folgender Modellformel: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. AbbildungÂ 10.8 und TabelleÂ 10.6.\n\nm10.4 &lt;- \n  stan_glm(kid_score ~  mom_iq + mom_hs + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\nTabelleÂ 10.6: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.10\n(-37.00, 17.79)\n77.10%\n1.000\n1416.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n49.01\n(20.09, 79.88)\n99.85%\n1.000\n1438.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq\n0.95\n(0.65, 1.24)\n100%\n1.000\n1362.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq\n-0.46\n(-0.78, -0.15)\n99.75%\n1.000\n1388.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\nMit estimate_expectation(m10.4) |&gt; plot() kann man es sich visualisieren, s. AbbildungÂ 10.8.\n\n\n\n\n\n\n\nAbbildungÂ 10.8: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt fÃ¼r diese Daten kaum zu interpretieren ist.\n\n\n\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 10.9 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 10.9: DAG fÃ¼r y ~ x + b + x:b\n\n\n\n\n\n10.5.2 Interpretation von m10.4\n\nAchsenabschnitt: IQ-SchÃ¤tzwerte fÃ¼r Kinder mit MÃ¼tter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren. - mom_hs: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh. mom_iq: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit MÃ¼ttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss. Interaktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten fÃ¼r mom_iq zwischen MÃ¼tter mit bzw. ohne Schulabschluss.\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\n\n10.5.3 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "href": "1000-metrische-AV.html#y-x_c-b-x_cb",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.6 y ~ x_c + b + x_c:b\n",
    "text": "10.6 y ~ x_c + b + x_c:b\n\n\n10.6.1 Zentrieren von PrÃ¤diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.10 Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq; die zentrierte Variable kennzeichnen wir durch den Suffix _c, also mom_iq_c.\nMan kÃ¶nnte auch mom_hs zentrieren, aber fÃ¼r eine einfache Interpretation ist es meist nÃ¼tzlich, nur metrische PrÃ¤diktoren zu zentrieren.\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.31\n\n\nmom_hs\n2.91\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n10.6.2 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den geschÃ¤tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten fÃ¼r mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nm10.5 ist in AbbildungÂ 10.10 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 10.10: m10.5: Interaktionsmodell mit zentriertem PrÃ¤diktor fÃ¼r mÃ¼tterlicher Intelligenz. Wie man sieht, ist der Achsenabschnitt deutlich besser zu interpretieren als in m10.4, s. AbbildungÂ 10.8.\n\n\n\n\n\n10.6.3 Zentrieren Ã¤ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.34184\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.3592\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren Ã¤ndert auch nicht die Regressionskoeffizienten, da die Streuungen der PrÃ¤diktoren nicht verÃ¤ndert wurden.\n\n10.6.4 Perzentilintervalle aus der Posterori-Verteilung\nTabelleÂ 10.7 zeigt die PunktschÃ¤tzer der Parameter fÃ¼r m10.5 sowie ihre Perzentilintervalle11. Nutzen Sie dafÃ¼r parameters(m10.5), s. TabelleÂ 10.7.\n\n\n\nTabelleÂ 10.7: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(80.99, 89.72)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.69)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.67, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. TabelleÂ 10.8.\n\nparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\nTabelleÂ 10.8: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(81.26, 89.88)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.70)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.79, -0.17)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n10.6.5 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei MÃ¼ttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mÃ¼tterlichen Intelligenz; pro Punkt Unterschied in mÃ¼ttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). AuÃŸerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei MÃ¼tter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. ZusammenhÃ¤nge beschrieben. FÃ¼r kausale Aussagen ist mehr nÃ¶tig, als einen statistischen Zusammenhang festzustellen.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-g",
    "href": "1000-metrische-AV.html#y-g",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.7 y ~ g\n",
    "text": "10.7 y ~ g\n\nHier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.\n\n10.7.1 Forschungsfrage\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in; Ihre Kompetenz als Wirtschaftspsychologi war heiÃŸ begehrt. Von Statistik wollte niemand etwas wissenâ€¦ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt fÃ¼hrte Sie in die Antarktisâ€¦ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um GrÃ¶ÃŸenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren KÃ¶rpergewichte der drei Pinguinarten?\n\nDie allgemeine Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 10.11 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 10.11: DAG fÃ¼r y ~ g\n\n\n\n\n\n10.7.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ğŸ¤” Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere KÃ¶rpergewichte in AbhÃ¤ngigkeit von der Pinguinart?\n\nAlternativ kÃ¶nnen wir die Hypothese prÃ¼fen, ob die Mittelwerte â€œpraktischâ€ gleich sind, also sich â€œkaumâ€ unterscheiden. Der Grenzwert fÃ¼r â€œpraktisch gleichâ€ bzw. â€œkaum unterschiedlichâ€ ist subjektiv. Dazu in KapitelÂ 9.3 mehr.\n\n10.7.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, TabelleÂ 10.9.\n\npenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\nTabelleÂ 10.9: Die Verteilung des KÃ¶rpergewichts pro Spezies der Pinguine\n\n\n\n  \n\n\n\n\n\n\nWas fÃ¤llt Ihnen auf?\n\n10.7.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. AbbildungÂ 10.12?\n\n\n\n\n\n\n\nAbbildungÂ 10.12: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.7.5 Gewicht pro Spezies, m10.6\n\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und TabelleÂ 10.10.\nDie Modellformel fÃ¼r m10.6 lautet also body_mass_g ~ species.\n\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\nTabelleÂ 10.10: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3699.92\n(3624.56, 3776.46)\n100%\n1.001\n4194.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n32.24\n(-100.80, 159.99)\n69.92%\n1.000\n4266.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.94\n(1265.80, 1486.83)\n100%\n1.001\n4187.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n\n10.7.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, AusprÃ¤gungen; hier: Spezies), aber es werden in TabelleÂ 10.10 nur zwei Stufen angezeigt (also eine weniger) zusÃ¤tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrÃ¼ckt (Intercept). Die Koeffizienten fÃ¼r species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in AbbildungÂ 10.13 verdeutlicht.\n\nplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 10.13: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (d.Â Details hier).\n\n10.7.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich hÃ¶her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich Ã¤hnlich.\nWie in AbbildungÂ 10.13 ersichtlich, Ã¼berlappt sich der SchÃ¤tzbereich fÃ¼r den Parameter von Gentoo nicht mit der Null; hingegen Ã¼berlappt sich der SchÃ¤tzbereich des Parameters fÃ¼r Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hÃ¤tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prÃ¼fen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primÃ¤r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen.\n\n10.7.8 Priori-Werte Ã¤ndern\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. FÃ¼r Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfÃ¼r Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: prior_summary(modell):\n\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWo man man Ã¼ber mehr inhaltliches Wissen verfÃ¼gt, so wird man die Prioris anpassen wollen, z.B.:\n\nm10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3703.90575         26.67909       1360.23645\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nm10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.98554         30.95782       1375.37494\n\nDen Parameter fÃ¼r die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\nsigma(m10.6b)\n## [1] 462.6415\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die GrÃ¶ÃŸe der Konfidenzintervalle.\nÃœbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren12.\n\n10.7.9 Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge Ã¤ndern.\n\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nlibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\nBeachten Sie, dass dazu das Paket forcats verfÃ¼gbar sein muss.\nJetzt haben wir die Referenzkategorie geÃ¤ndert:\n\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\nDer Wechsel der Referenzkategorie Ã¤ndert nichts Wesentliches am Modell, s. TabelleÂ 10.11.\n\nm10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\nTabelleÂ 10.11: m10.6a mit geÃ¤nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 5001.08, 5160.63]\n\n\nspeciesAdelie\n[-1477.80, -1264.23]\n\n\nspeciesChinstrap\n[-1475.95, -1204.52]",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y-x1-x2",
    "href": "1000-metrische-AV.html#y-x1-x2",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.8 y ~ x1 + x2\n",
    "text": "10.8 y ~ x1 + x2\n\n\n10.8.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhÃ¤ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa â€œIQ der Mutter ist die Ursache zum IQ des Kindesâ€) wird impliziert.\nEs geht rein darum, ZusammenhÃ¤nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. FÃ¼r solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nÃ¶tig.\n\n10.8.2 Was heiÃŸt, X hÃ¤ngt mit Y zusammen?\n\nDer Begriff â€œZusammenhangâ€ ist nicht exakt.\nHÃ¤ufig wird er (fÃ¼r metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groÃŸ der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem â€œEffekt von X auf Yâ€ Ã¼bersetzt. Vorsicht: â€œEffektâ€ klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende BegrÃ¼ndung fÃ¼r einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der StÃ¤rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehÃ¶rigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\nEs ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten, bevor man ein (Regressions-)Modell aufstellt.\n\nkidiq %&gt;% \n  correlation()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.166\n\n\nkid_score\nmom_iq_c\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_hs\nmom_iq_c\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\nmom_iq\nmom_iq_c\n1.00\n(1.00, 1.00)\n1.39e+09\n&lt; .001***\n\n\nmom_age\nmom_iq_c\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.166\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\nTabelleÂ 10.12 zeigt die Korrelationsmatrix als Korrelationsmatrix:\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\nTabelleÂ 10.12: Die Korrelationen zwischen den Variablen der Tabelle kidiq\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.21***\n0.28***\n\n\n\nmom_iq\n0.09\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\nNÃ¼tzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, AbbildungÂ 10.14.\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildungÂ 10.14: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n\n10.8.3 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro PrÃ¤diktor, also eine fÃ¼r mom_iq und eine fÃ¼r mom_age.\n\nm10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\nHier die Ergebnisse fÃ¼r mom_iq:\n\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.8084927   0.6101706\n\nHier die Ergebnisse fÃ¼r mom_age:\n\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.1650562   0.6875296\n\n\n10.8.4 Visualisierung der univariaten Regressionen\nIn AbbildungÂ 10.15 ist die univariate Regression mit jeweils einem der beiden PrÃ¤diktoren dargestellt.\nm10.7: Die Steigung betrÃ¤gt 0.6. m10.8: Die Steigung betrÃ¤gt 0.7.\n\n\n\n\n\n\n\nAbbildungÂ 10.15: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n10.8.5 Multiples Modell (beide PrÃ¤diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein PrÃ¤diktor im Modell aufgenommen ist.\n\nm10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils â€œbereinigtâ€ vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines PrÃ¤diktors mit der AV, wobei man gleichzeitig den anderen PrÃ¤diktor konstant hÃ¤lt.\n\n\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.6664277   0.6031031   0.3898825\n\n\n10.8.6 3D-Visualisierung eines Modells mit zwei PrÃ¤diktoren 1\nIn AbbildungÂ 10.16 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\n\n\nAbbildungÂ 10.16: 3D-Visualisierung von m10.9 (zwei PrÃ¤diktoren)\n\n\n\n\n10.8.7 Visualisierung mit Farbe statt 3. Dimension\n3D-Visualisierungen haben Vorteile, aber auch Nachteile; AbbildungÂ 10.17 zeigt eine alternative Visualisierung, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\n\n\nAbbildungÂ 10.17: Modell m10.9; die FarbverlÃ¤ufe zeigen der Wert der abhÃ¤ngigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der FarbÃ¤nderung) die VerÃ¤nderung fÃ¼r die AV (kid_score). Auf der Achse fÃ¼r mom_age sieht man, dass sich die AV kaum Ã¤ndert, wenn sich mom_age Ã¤ndert.\n\n10.8.8 Visualisierung in 10 Dimensionen\nAbbildungÂ 10.18 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\n\n\nAbbildungÂ 10.18: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere SchwÃ¤chen, eine groÃŸe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n10.8.9 Relevanz der PrÃ¤diktoren\nWoher weiÃŸ man, welcher PrÃ¤diktor am stÃ¤rksten mit der AV zusammenhÃ¤ngt? Man kÃ¶nnte auch sagen: Welcher PrÃ¤diktor (welche UV) am â€œwichtigstenâ€ ist oder den â€œstÃ¤rksten Einflussâ€ auf die AV ausÃ¼bt? Bei solchen kausal konnotierten AusdrÃ¼cken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann fÃ¼r sich nur Muster in den Daten, also ZusammenhÃ¤nge bzw. Unterschiede, entdecken, s. AbbildungÂ 10.19.\n\n\n\n\n\nAbbildungÂ 10.19: Made at imgflip.com\n\n\nWelcher PrÃ¤diktor ist nun â€œwichtigerâ€ oder â€œstÃ¤rkerâ€ in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)?\n\n\nmom_iq hat den grÃ¶ÃŸeren Koeffizienten.\n\nmom_age hat weniger Streuung.\n\nUm die Relevanz der PrÃ¤diktoren vergleichen zu kÃ¶nnen, mÃ¼sste man vielleicht die VerÃ¤nderung von kid_score betrachten, wenn man von kleinsten zum grÃ¶ÃŸten PrÃ¤diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die VerÃ¤nderung in der AV zu betrachten, wenn man den PrÃ¤diktor von â€œunterdurchschnittlichâ€ auf â€œÃ¼berdurchschnittlichâ€ Ã¤ndert. Das kann man mit z-Standardisierung erreichen.\n\n10.8.10 z-Standardisierung\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie Ã¼ber einen Mittelwert von 0 und eine SD von 1 verfÃ¼gt:\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\nkidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;% \n  select(mom_iq, mom_iq_z) %&gt;% \n  head()\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten13. Die Standardisierung ist Ã¤hnlich zur Vergabe von ProzentrÃ¤ngen: â€œDieser Messwert gehÃ¶rt zu den Top-3-Prozentâ€. Diese Aussage ist bedeutsam fÃ¼r Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen fÃ¼r verschiedene Verteilungen mÃ¶glich.\n\n10.8.11 Statistiken zu den z-transformierten Variablen\nTabelleÂ 10.3 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer AusprÃ¤gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener PrÃ¤diktoren sind einfacher in ihrer GrÃ¶ÃŸe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und Ã¤hnlich groÃŸe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (â€œSkalierungâ€) mit standardize (aus easystats) durchfÃ¼hren, s. TabelleÂ 10.13.\n\nkidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\nTabelleÂ 10.13: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n65\n1\n121.12\n27\n-1.07\n0.52\n1.41\n1.56\n\n\n98\n1\n89.36\n25\n0.55\n0.52\n-0.71\n0.82\n\n\n85\n1\n115.44\n27\n-0.09\n0.52\n1.03\n1.56\n\n\n83\n1\n99.45\n25\n-0.19\n0.52\n-0.04\n0.82\n\n\n115\n1\n92.75\n27\n1.38\n0.52\n-0.48\n1.56\n\n\n98\n0\n107.90\n18\n0.55\n-1.91\n0.53\n-1.77\n\n\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafÃ¼r, dass die ursprÃ¼nglichen Variablen beim z-Standardisieren nicht Ã¼berschrieben werden, sondern angehÃ¤ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nkidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. TabelleÂ 10.14. Dazu verwendet man den Befehl scale().\n\nkidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\nTabelleÂ 10.14: Z-Standardisierung ohne Extrapaketâ€",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#y_c-x1_c-x2_c",
    "href": "1000-metrische-AV.html#y_c-x1_c-x2_c",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.9 y_c ~ x1_c + x2_c\n",
    "text": "10.9 y_c ~ x1_c + x2_c\n\n\n10.9.1 AV z-transformieren\nIn diese Abschnitt berechnen wir ein Modell (Modell m10.10), in dem die PrÃ¤diktoren z-transformiert sind (standardisiert) und die AV ebenfalls. Das Standardisieren der AV, kid_score ist zwar nicht nÃ¶tig, um den Effekt der PrÃ¤diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darÃ¼ber, um wie viele SD-Einheiten sich die AV verÃ¤ndert, wenn sich ein PrÃ¤diktor um eine SD-Einheit verÃ¤ndert. Das kann auch eine interessante(re) Aussage sein.\n\nm10.10 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.10)\n## (Intercept)    mom_iq_z   mom_age_z \n## 0.001554359 0.443843346 0.050380199\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient fÃ¼r mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_iq um eine SD-Einheit Ã¤ndert.\nDer Koeffizient fÃ¼r mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_age um eine SD-Einheit Ã¤ndert.\n\nJetzt sind die PrÃ¤diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n10.9.2 95%-PI\nMit parameters kÃ¶nnen wir uns ein PI fÃ¼r m10.10 ausgeben lassen, s. AbbildungÂ 10.20; im Standard wird ein 95%-ETI berichtet14.\n\nparameters(m10.10) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n1.55e-03\n(-0.08, 0.08)\n51.12%\n0.999\n4683.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.000\n5372.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.33%\n0.999\n4779.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nplot(eti(m10.10)) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 10.20: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI fÃ¼r m10.10\n\n\n\n\n\n10.9.3 ModellgÃ¼te\n\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.204 (95% CI [0.142, 0.268])\n\nIst dieser Wert von \\(R2\\) â€œgutâ€? Diese Frage ist Ã¤hnlich zur Frage â€œIst das viel Geld?â€; man kann die Frage nur im Kontext beantworten.\nEine einfache LÃ¶sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklÃ¤rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufÃ¤llig hohen Werten der ModellgÃ¼te im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine â€œobjektiveâ€ Antwort auf die Frage â€œwie viel ist viel?â€ haben wollen, ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage â€œWieviel ist viel?â€ gegeben hat (Cohen 1992):\n\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\nDanke, Herr Cohen!\n\n10.9.4 Priori-Verteilung fÃ¼r m10.10 und Modelldefinition\nStan hat fÃ¼r uns folgende Prioris ausgesucht:\n\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nğŸ¤– Nix zu danken!\n\nWie gesagt, Stan nimmt dafÃ¼r einfach die empirischen Mittelwerte und Streuungen her15.\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. GleichungÂ 10.2.\n\\[\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{10.2}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.10. Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzufÃ¼hren.\n:::{#exm-anz-mod-m1010} ### Anzahl der Modellparameter Wie viele Modellparameter hat m10.10?16\n\n10.9.5 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar fÃ¼r einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkÃ¤rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich u.Â a. 2020) zurÃ¼ck (s. Anhang fÃ¼r Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem â€œstatistischen Effektâ€ gesprochen, um klar zu machen, dass es sich lediglich um assoziative ZusammenhÃ¤nge, und nicht um kausale ZusammenhÃ¤nge, handelt. Kausale ZusammenhÃ¤nge dÃ¼rfen wir nur verkÃ¼nden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafÃ¼r finden oder c) wir ein Experiment fachgerecht durchgefÃ¼hrt haben.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.10 Vertiefung",
    "text": "10.10 Vertiefung\nğŸï¸VERTIEFUNG, nicht prÃ¼fungsrelevantğŸï¸\n\n10.10.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch, s. GleichungÂ 10.3.\n\\[b = r \\frac{sd_x}{sd_y} \\tag{10.3}\\]\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die PunktschÃ¤tzer fÃ¼r die Regressionskoeffizienten:\n\nm10.11 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.11)\n##  (Intercept)     mom_iq_z \n## 0.0002786206 0.4483327620\n\nVergleichen Sie diese Werte mit der Korrelation, s. TabelleÂ 10.15.17\n\nkidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelleÂ 10.15: Correlation Matrix (pearson-method)\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n\n10.10.2 PrÃ¼fen der LinearitÃ¤tsannahme\nZentrale Annahme eines linearen Modells: Die AV ist eine lineare Funktion der einzelnen PrÃ¤diktoren, s. GleichungÂ 10.4.\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots  \\tag{10.4}\\]\nHingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression hÃ¤ufig normalverteilte Residuen an18, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schÃ¤tzen (Gelman, Hill, und Vehtari 2021).\nIst die LinearitÃ¤tsannahme erfÃ¼llt, so sollte der Residualplot nur zufÃ¤llige Streuung um \\(y=0\\) herum zeigen, s. AbbildungÂ 10.21.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsÃ¤chlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\nkidiq %&gt;% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\n\nAbbildungÂ 10.21: Die Verteilung der Fehler scheint keinem starken Trend (in AbhÃ¤ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine grÃ¶ÃŸeren AuffÃ¤lligkeiten.\n\n10.10.3 ModellprÃ¼fung mit der PPV\n\npp_check(m10.10)\n\n\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht hÃ¤ufig.\n\n10.10.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\n\n\n\nAbbildungÂ 10.22: Bereinigte Regressionskoeffizienten\n\n\n\n\nAbbildungÂ 10.22 zeigt in der oberen Reihe die Regression eines PrÃ¤diktors auf den anderen PrÃ¤diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n10.10.5 Bayesianisch gleich Frequentistisch?\nÃœbrigens liefern stan_glm() und lm oft Ã¤hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch Ã¤hnlich sein kÃ¶nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.11 Fazit",
    "text": "10.11 Fazit\n\n10.11.1 Austieg: Bayes in fÃ¼nf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem.\nğŸ“º MusterlÃ¶sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars\nğŸ“º MusterlÃ¶sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress\n\n10.11.2 Ausblick: BinÃ¤re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\ndata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m13: am ~ mpg_z:\n\nm13 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nmtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\n\nneg_am &lt;- predict(m13, newdata = tibble(mpg_z = -1.3))\n\nFÃ¼r kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte fÃ¼r am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. MÃ¼ssen wir mal bei Gelegenheit besser machen.\n\n10.11.3 Genug fÃ¼r heute\nWir waren fleiÃŸig â€¦\n\n\n\n\n\n\n\n\nQuelle\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg.\n\n\nGenug fÃ¼r heute. ğŸ‘\n\n10.11.4 WeiterfÃ¼hrende Literatur\nWeiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei Gelman, Hill, und Vehtari (2021), Kap. 10, insbesondere 10.3.\nGelman, Hill, und Vehtari (2021) bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit fÃ¼hrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig Ã¼berschaubarem mathematischen Aufwand.\nFÃ¼r das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\n\nAnova-skalenniveau\nNullhyp-Beispiel\nttest-skalenniveau\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nstan_glm_parameterzahl\nstan_glm_prioriwerte\nzwert-berechnen\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope4",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n10Â  Fallbeispiele\n",
    "section": "\n10.13 â€”",
    "text": "10.13 â€”\n\n\n\n\n\nCohen, J. 1992. â€A Power Primerâ€œ. Psychological Bulletin 112 (1): 155â€“59.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, und Sam Brilleman. 2020. â€Rstanarm: Bayesian Applied Regression Modeling via Stan.â€œ https://mc-stan.org/rstanarm.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Fallbeispiele</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#lernsteuerung",
    "href": "1150-konfundierung.html#lernsteuerung",
    "title": "11Â  Konfundierung",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n11.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie kÃ¶nnen ihn entweder Ã¼ber die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber Ã¼ber das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kÃ¼rzerer Name, das ist leichter zu tippen\n\n\n11.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, was eine Konfundierung ist\nDAGs lesen und zeichen\nKonfundierung in einem DAG erkennen\n\n11.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ã„hnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).\n\n11.1.6 Ãœberblick\nIn diesem Kapitel steigen wir ein in das Themengebiet Kausalanalyse (oder synonym Kausalinferenz). Wir beschÃ¤ftigen uns also mit der fÃ¼r die Wissenschaft (und den Rest des Universums) zentralen Frage, was die Ursache eines PhÃ¤nomens ist. In diesem ersten Kapitel zu dem Thema geht es um einen hÃ¤ufigen Fall von â€œScheinkorrelationâ€, also eines Zusammenhangs zwischen UV und AV, der aber gar kein echter kausaler ist, sondern nur Schein. Bei diesem Scheinzusammenhang handelt es sich um die Konfundierung. Im nÃ¤chsten Kapitel schauen wir uns die verbleibenden Grundbausteine der Kausalinferenz an.\n\n11.1.7 Einstieg\n\n11.1.8 Von StÃ¶rchen und Babies\nKennen Sie die Geschichte von StÃ¶rchen und Babies? Ich meine nicht die aus dem Biologieunterricht in der fÃ¼nften Klasse, sondern in einem statistischen Zusammenhang. Was war da noch mal die Moral von der Geschichte?1 \\(\\square\\)\n\n11.1.9 Erlaubt eine Regressionsanalyse KausalschlÃ¼sse?\nFindet man in einer Regressionsanalyse einen â€œEffektâ€, also ein Regressionsgewicht ungleich Null, heiÃŸt das dann, dass die UV die Ursache der AV ist?2 ErklÃ¤ren Sie diesen Sachverhalt genauer. \\(\\square\\)",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "href": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "title": "11Â  Konfundierung",
    "section": "\n11.2 Statistik, was soll ich tun?",
    "text": "11.2 Statistik, was soll ich tun?\n\n11.2.1 Studie A: Ã–strogen\n\n11.2.1.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 11.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelleÂ 11.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nFrauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n11.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 11.1 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder â€œSchichtenâ€ (â€œStrataâ€).\n\n\n\n11.2.2 Studie B: Blutdruck\n\n11.2.2.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 11.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelleÂ 11.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nhoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl, Glymour, und Jewell 2016)?\n\n11.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in AbbildungÂ 11.2 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 11.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n11.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 11.1 und AbbildungÂ 11.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n11.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ\nStatistik plus Theorie erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n11.2.5 Vertiefung3\n\n\n11.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ã„rzte tendieren zu Behandlung A bei groÃŸen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ã„rzte zu Behandlung B.\nSollte ein Patient, der nicht weiÃŸ, ob sein Nierenstein groÃŸ oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach SteingrÃ¶ÃŸe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wÃ¤hlt?\nDie GrÃ¶ÃŸe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (â€œKetteâ€) von GrÃ¶ÃŸe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. DarÃ¼ber hinaus gibt es noch einen Einfluss von GrÃ¶ÃŸe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in AbbildungÂ 11.3 dargestellt; AbbildungÂ 11.4 visualisiert alternativ. Beide Varianten zeigen das Gleiche. Sie kÃ¶nnen sich einen aussuchen. Hier sind beide Varianten gezeigt, damit Sie wissen, dass verschiedene Darstellungsformen mÃ¶glich sind.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schÃ¤tzen mÃ¶chte? Oder lieber nicht kontrollieren?\n\n\nDAG links-rechts\nDAG oben-unten\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. WÃ¼rde man nicht size kontrollieren, bekÃ¤me man den â€œvermengtenâ€ Effekt von size und treatment, also keine (belastbare) Aussage Ã¼ber den Effekt der Behandlung.\n\n11.2.5.2 Mehr Beispiele\n\nBeispiel 11.1 Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhÃ¶hen, wenn du heiratest. \\(\\square\\)\n\n\nBeispiel 11.2 Studien zeigen, dass Leute, die sich beeilen, zu spÃ¤t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spÃ¤t zu deiner Besprechung. \\(\\square\\)\n\n\n11.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zusÃ¤tzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht nÃ¶tig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafÃ¼r, dass es keine Konfundierung gibt.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#konfundierung",
    "href": "1150-konfundierung.html#konfundierung",
    "title": "11Â  Konfundierung",
    "section": "\n11.3 Konfundierung",
    "text": "11.3 Konfundierung\n\n11.3.1 Die Geschichte von Angie und Don\n\n\n\nğŸ§‘\n\nDon, Immobilienmogul, Auftraggeber\n\n\nğŸ‘©\n\nAngie, Data Scientistin.\n\n\nğŸ§\n\nWolfie, Post-Nerd, kommt in dieser Geschichte aber nicht vor\n\n\nğŸ“º Don und Angie\n\n11.3.2 Datensatz â€˜Hauspreise im Saratoga Countyâ€™\nImportieren Sie den Datensatz SaratogaHouses, s. KapitelÂ 11.1.3.\n\n\n\nTabelleÂ 11.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n11.3.3 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\nâ€œFinden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!â€\n\nğŸ§‘ Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\nğŸ‘© ğŸ”¬ Das ist Angie, Data Scientistin.\n\n11.3.4 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\nâ€œHey Don! Mehr Zimmer, mehr Kohle!â€ ğŸ‘© ğŸ”¬\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. AbbildungÂ 11.5.\n\n\n\n\n\n\n\nAbbildungÂ 11.5: Modell m1\n\n\n\n\n\nâ€œJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.â€\n\nğŸ‘©\n\nZu wenig! ğŸ¤¬\n\nğŸ§‘\nBerechnen wir das Modell m1; der PunktschÃ¤tzer des Parameters bedroom steht in TabelleÂ 11.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\nTabelleÂ 11.4: Parameter fÃ¼r m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die PunktschÃ¤tzer der Parameter eines Modells zurÃ¼ck, aber nicht die SchÃ¤tzbereiche. MÃ¶chten Sie beides, kÃ¶nnen Sie die Funktion parameters(modell) nutzen.4\nMit estimate_predictions kÃ¶nnen wir Vorhersagen berechnen (bzw. schÃ¤tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist â€œschÃ¤tzenâ€ vielleicht das treffendere Wort). TabelleÂ 11.5 zeigt den laut m1 vorhergesagten Hauspreis fÃ¼r ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\nTabelleÂ 11.5: Vorhersage des Hauspreises fÃ¼r ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.55e+05\n92273.66\n(-20256.77, 3.34e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.5 Don hat eine Idee\n\nâ€œIch bau eine Mauer! Genial! An die Arbeit, Angie!â€ ğŸ§‘\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\nâ€œDas ist keine gute Idee, Don.â€\n\nğŸ‘©\nBerechnen wir die Vorhersagen fÃ¼r Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. TabelleÂ 11.6.5\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\nTabelleÂ 11.6: Vorhergesagter Hauspreis laut m1 fÃ¼r ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n91169.55\n(71537.64, 4.26e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, s. AbbildungÂ 11.5.\n\nâ€œVolltreffer! Jetzt verdien ich 100 Tausend mehr! ğŸ¤‘ Ich bin der GrÃ¶ÃŸte!â€ ğŸ§‘\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: â€œ4e+05â€ ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n11.3.6 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berÃ¼cksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im â€œStrukturmodellâ€: Wenn also z.B. in unserem Modell ein wichtiger PrÃ¤diktor fehlt, so kann die Vorhersagen nicht prÃ¤zise sein. Fehler im Strukturmodell schlagen sich in breiten SchÃ¤tzintervallen (bedingt durch ein groÃŸes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berÃ¼cksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten)\n\nDie SchÃ¤tzbereiche sind in dem Fall deutlich kleiner, s. TabelleÂ 11.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\n\nTabelleÂ 11.7: Ungewissheit fÃ¼r die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\nModel-based Expectation\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3104.98\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.7 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. TabelleÂ 11.8 gibt den PunktschÃ¤tzer fÃ¼r die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\nTabelleÂ 11.8: Parameter (PunktschÃ¤tzer, keine SchÃ¤tzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36311.05\n\n\nbedrooms\n-14077.64\n\n\nlivingArea\n125.32\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? TabelleÂ 11.9 gibt Aufschluss fÃ¼r den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 QuadratfuÃŸ WohnflÃ¤che; TabelleÂ 11.10 gibt die SchÃ¤tzung (laut m2) fÃ¼r den Preis eines Hauses mit 2 Zimmern (und der gleichen WohnflÃ¤che). Die Vorhersage erhÃ¤lt man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130423.8\n\n\n\n\nTabelleÂ 11.9: Vorhersage von m2 fÃ¼r ein Haus mit 4 Zimmern und 1200 Einheiten WohnflÃ¤che\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelleÂ 11.10: Vorhersage von m2 fÃ¼r ein Haus mit 2 Zimmern und 1200 Einheiten WohnflÃ¤che\n\n\n\n  \n\n\n\n\n\n\nAndere, aber Ã¤hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt Ã¼ber die verschiedenen GrÃ¶ÃŸen von livingArea? Stellen Sie sich alle HÃ¤user mit 4 Zimmern vor (also mit verschiedenen WohnflÃ¤chen). Wir mÃ¶chten nur wissen, was so ein Haus â€œim Mittelâ€ kostet. Wir mÃ¶chten also die Mittelwerte pro bedroom schÃ¤tzen, gemittelt fÃ¼r jeden Wert von bedroom Ã¼ber livingArea. Die Ergebnisse stehen in TabelleÂ 11.11 und sind in AbbildungÂ 11.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelleÂ 11.11: Vorhersagen des Preises von HÃ¤usern mit verschiedener Zimmerzahl gemittelt Ã¼ber die verschiedenen Werte der WohnflÃ¤che; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\nâ€œDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!â€\n\nğŸ‘©\n\nâ€œVerringert!? Weniger Geld?! Oh nein!â€\n\nğŸ§‘\n\n11.3.8 Die Zimmerzahl ist negativ mit dem Preis korreliert\nâ€¦ wenn man die WohnflÃ¤che (Quadratmeter) kontrolliert, s. AbbildungÂ 11.7.\n\nâ€œNe-Ga-Tiv!â€\n\nğŸ‘©\n\n\n\n\n\nAbbildungÂ 11.7: Hauspreis stratifizieren\n\n\nQuellcode\n\n\n\n\n\n\nHinweis\n\n\n\nAussagen, gleich ob sie statistischer, wissenshaftlicher oder sonstiger Couleur sind, kÃ¶nnen immer nur dann richtig sein, wenn ihre Annahmen richtig sind. Behauptet etwa ein Modell, dass der Wert einer Immobilie steigt, wenn man mehr Zimmer hat, so ist das kein Naturgesetz, sondern eine Aussage, die nur richtig sein kann, wenn das zugrundeliegende Modell richtig ist. \\(\\square\\)\n\n\n\n11.3.9 Kontrollieren von Variablen\nğŸ’¡ Durch das Aufnehmen von PrÃ¤diktoren in die multiple Regression werden die PrÃ¤diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen PrÃ¤diktors mit \\(y\\), wenn man den (oder die) anderen PrÃ¤diktoren statistisch konstant hÃ¤lt.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom â€œNetto-Effektâ€ eines PrÃ¤diktors, oder davon, dass ein PrÃ¤diktor â€œbereinigtâ€ wurde vom (linearen) Einfluss der anderen PrÃ¤diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des PrÃ¤diktors \\(x_1\\) auf \\(y\\) anzeigen unabhÃ¤ngig vom Effekt der anderen PrÃ¤diktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines PrÃ¤diktors \\(x_1\\) wird fÃ¼r jede AusprÃ¤gung (Gruppe) des PrÃ¤diktors \\(x_2\\) berechnet.\n\n\n\n\n\n\nWichtig\n\n\n\nDas HinzufÃ¼gen von PrÃ¤diktoren kann die Gewichte der Ã¼brigen PrÃ¤diktoren Ã¤ndern. \\(\\square\\)\n\n\n\nAber welche und wie viele PrÃ¤diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nğŸ§‘\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nğŸ‘©\n\nWozu ist sie dann gut?!\n\nğŸ§‘\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur ErklÃ¤rung der Ursachen heranzuziehen: Die Regressionskoeffizienten kÃ¶nnen sich wild Ã¤ndern, wenn man PrÃ¤diktoren hinzufÃ¼gt oder weglÃ¤sst. Es kÃ¶nnen sich sogar die Vorzeichen der Regressionsgewichte Ã¤ndern; in dem Fall spricht man von einem Simpson-Paradox.\n\n\n\n11.3.10 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, weâ€™d like to know wheter an effect is â€œrealâ€ or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical â€œtestsâ€ on its way to acceptance.\n\nâ€“ McElreath (2020), S. 139\n\n11.3.11 Kausalmodell fÃ¼r Konfundierung, km1\n\nDas Kausalmodell km1 ist in AbbildungÂ 11.8 dargestellt; vgl. AbbildungÂ 11.7.\n\n\n\n\n\n\n\nAbbildungÂ 11.8: Kausalmodell km1 - Eine ErklÃ¤rung (von mehreren) fÃ¼r m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms. Eine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht. d_connected heiÃŸt, dass die betreffenden Variablen â€œverbundenâ€ sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flieÃŸt ğŸŒŠ. d_separated heiÃŸt, dass sie nicht d_connected sind.\n\n11.3.12 m2 kontrolliert die Konfundierungsvariable livingArea\n\n\nBeispiel 11.3 In AbbildungÂ 11.8 ist living area eine Konfundierungsvariable fÃ¼r den Zusammenhang von bedrooms und price. \\(\\square\\)\n\n\nDefinition 11.1 (Konfundierungsvariable) Eine Konfundierungsvariable (Konfundierer) ist eine Variable, die den Zusammenhang zwischen UV und AV verzerrt, wenn sie nicht kontrolliert wird (VanderWeele und Shpitser 2013). \\(\\square\\)\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloÃŸ?! Oh jeh!\n\nğŸ§‘\n\nWir mÃ¼ssen die Konfundierungsvariable kontrollieren.\n\nğŸ‘©\nAbbildungÂ 11.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildungÂ 11.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (â€œadjustierenâ€), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separated.\n\nDefinition 11.2 (Blockieren) Das Kontrollieren eines Konfundierers (wie living_area) â€œblocktâ€ den betreffenden Pfad, fÃ¼hrt also dazu, dass Ã¼ber diesen Pfad keine Assoziation (z.B. Korrelation) zwischwen UV (bedrooms) und AV (price) mehr vorhanden ist. UV und AV sind dann d_separated (â€œgetrenntâ€). \\(\\square\\)\n\n\n11.3.13 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, AbbildungÂ 11.10, links: Es wird (fÃ¤lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, AbbildungÂ 11.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildungÂ 11.10: Konfundierung von y und x!\n\n\nAbbildungÂ 11.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. AuÃŸerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als PrÃ¤diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\nWichtig\n\n\n\nKontrollieren Sie Konfundierer. \\(\\square\\)\n\n\n\n11.3.14 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 dÃ¼rfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in AbbildungÂ 11.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n11.3.15 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide PrÃ¤diktoren jeweils einen eigenen Beitrag zur ErklÃ¤rung der AV haben.\nDaher kÃ¶nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei KausaleinflÃ¼sse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) Ã¼ber den Mediator (b) zur AV (p) auch Mediation, s. AbbildungÂ 11.11.\n\n\n\n\n\n\n\nAbbildungÂ 11.11: Der Effekt von livingArea wird Ã¼ber den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n11.3.16 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. AbbildungÂ 11.12.\n\n\n\n\n\n\n\nAbbildungÂ 11.12: Dons Kausalmodell\n\n\n\n\n\nâ€œIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das grÃ¶ÃŸte! Alle anderen Kausalmodelle sind ein Disaster!â€\n\nğŸ§‘\n\n\nâ€œDon, nach deinem Kausalmodell mÃ¼ssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.â€\n\nğŸ§‘\nRechne doch selber die Korrelation aus, Don:\n\nâ€œÃ„h, wie ging das nochmal?â€\n\nğŸ§‘\nSo kÃ¶nntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\nâ€œBitte, gerne hab ich dir geholfen, Don.â€\n\nğŸ‘©\n\n11.3.17 UnabhÃ¤ngigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhÃ¤ngig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zusÃ¤tzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete UnabhÃ¤ngigkeit findet sich nicht in den Daten wieder, s. TabelleÂ 11.8. Also: â›ˆï¸ Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.11.\nDas Kausalmodell km2 postuliert keine UnabhÃ¤ngigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betrÃ¤gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so Ã¤hnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. ğŸ¥±\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 11.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhÃ¤ngig von livingArea (a)\nâ›ˆï¸ km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "href": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "title": "11Â  Konfundierung",
    "section": "\n11.4 DAGs: Directed Acyclic Graphs",
    "text": "11.4 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B. AbbildungÂ 11.12.\n\nDefinition 11.3 (DAG) DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen. Ein Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden. DAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung). DAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurÃ¼ckfÃ¼hren. \\(\\square\\)\n\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten Ã¼ber die Kanten, unabhÃ¤ngig von der Pfeilrichtung.\nDer DAG von km1 ist in AbbildungÂ 11.8 zu sehen.\n\n11.4.1 Leider passen potenziell viele DAGs zu einer Datenlage\nAuf Basis der in Dons Modell dargestellten (Un-)AbhÃ¤ngigkeiten der Variablen sind noch weitere Kausalmodelle mÃ¶glich.\nIn AbbildungÂ 11.13 sind diesen weiteren, mÃ¶glichen Kausalmodelle fÃ¼r Dons Modell dargestellt. Dabei sind folgende AbkÃ¼rzungen verwendet: b: bedrooms, p: price, a area (living area).\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach wÃ¤re, die Kausalstruktur der PhÃ¤nomene zu entdecken, wÃ¤ren sie lÃ¤ngst erkannt, und alle Probleme der Menschheit gelÃ¶st.\n\n\n\n\n\n\n\nAbbildungÂ 11.13: Kausalmodelle, die potenziell geeignet sind fÃ¼r Dons Fragestellung\n\n\n\n\nAlle diese DAgs in AbbildungÂ 11.8 haben die gleichen Implikationen hinsichtlich der (Un-)AbhÃ¤ngigkeiten zwischen der Variablen. Wir kÃ¶nnen also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, brÃ¤uchten wir z.B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n11.4.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als â€œKausationâ€ bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiÃŸ man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\nViele Menschen denken - fÃ¤lschlich - dass Korrelation Kausation bedeuten muss, s. AbbildungÂ 11.14.\n\n\n\n\n\n\n\nAbbildungÂ 11.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und ErklÃ¤rung\nDer â€œSchoki-DAGâ€ in AbbildungÂ 11.15 zeigt den DAG fÃ¼r das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\n\n\n\nAbbildungÂ 11.15: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#fazit",
    "href": "1150-konfundierung.html#fazit",
    "title": "11Â  Konfundierung",
    "section": "\n11.5 Fazit",
    "text": "11.5 Fazit\n\n11.5.1 Zusammenfassung\nSind zwei Variablen korreliert (abhÃ¤ngig, assoziiert), so kann es dafÃ¼r zwei GrÃ¼nde geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (â€œScheinkorrelationâ€)\n\nEine mÃ¶gliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als PrÃ¤diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so lÃ¶st sich der Scheinzusammenhang nach dem Adjustieren auf.\nLÃ¶st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der ZusammenhÃ¤nge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine kÃ¶nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nÃ¶tig, um DAGs auszuschlieÃŸen.\n\n11.5.2 Ausstieg\n\nBeispiel 11.4 (Schoki macht Nobelpreis!?) Eine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen der HÃ¶he des Schokoladenkonsums eines Landes und der Anzahl der Nobelpreise eines Landes (Messerli 2012), s. AbbildungÂ 11.16.\n\n\n\n\n\n\n\nAbbildungÂ 11.16: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle Ã¼berprÃ¼fen, so wie wir das hier tun.\n\n\n\n\n11.5.3 Vertiefung\nEs gibt viel Literatur zu dem Thema Kausalinferenz. Ein Artikel, der einen vertieften Einblick in das Thema Konfundierung liefert z.B. Tennant u.Â a. (2020) oder Suttorp u.Â a. (2015). Allerdings sollte man neben Konfundierung noch die drei anderen â€œAtomeâ€ der Kausalinferenz - Kollision, Mediation (und Nachfahre) - kennen, um gÃ¤ngige Fragen der Kausalinferenz bearbeiten zu kÃ¶nnen.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#aufgaben",
    "href": "1150-konfundierung.html#aufgaben",
    "title": "11Â  Konfundierung",
    "section": "\n11.6 Aufgaben",
    "text": "11.6 Aufgaben\n\nSammlung â€œkausalâ€",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#section",
    "href": "1150-konfundierung.html#section",
    "title": "11Â  Konfundierung",
    "section": "\n11.7 â€”",
    "text": "11.7 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. â€Chocolate Consumption, Cognitive Function, and Nobel Laureatesâ€œ. New England Journal of Medicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nSuttorp, Marit M., Bob Siegerink, Kitty J. Jager, Carmine Zoccali, und Friedo W. Dekker. 2015. â€Graphical Presentation of Confounding in Directed Acyclic Graphsâ€œ. Nephrology Dialysis Transplantation 30 (9): 1418â€“23. https://doi.org/10.1093/ndt/gfu325.\n\n\nTennant, Peter W G, Eleanor J Murray, Kellyn F Arnold, Laurie Berrie, Matthew P Fox, Sarah C Gadd, Wendy J Harrison, u.Â a. 2020. â€Use of Directed Acyclic Graphs (DAGs) to Identify Confounders in Applied Health Research: Review and Recommendationsâ€œ. International Journal of Epidemiology 50 (2): 620â€“32. https://doi.org/10.1093/ije/dyaa213.\n\n\nVanderWeele, Tyler J., und Ilya Shpitser. 2013. â€On the Definition of a Confounderâ€œ. Annals of statistics 41 (1): 196â€“220. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#lernsteuerung",
    "href": "1180-kausalatome.html#lernsteuerung",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Position im Modulverlauf\nAbbildungÂ 1.1 gibt einen Ãœberblick zum aktuellen Standort im Modulverlauf.\n\n12.1.2 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n12.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie kÃ¶nnen ihn entweder Ã¼ber die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber Ã¼ber das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kÃ¼rzerer Name, das ist leichter zu tippen\n\n\n12.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\nerklÃ¤ren, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\ndie â€œAtomeâ€ der KausalitÃ¤t eines DAGs benennen\nâ€œkausale HintertÃ¼renâ€ schlieÃŸen\n\n12.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ã„hnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#kollision",
    "href": "1180-kausalatome.html#kollision",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.2 Kollision",
    "text": "12.2 Kollision\nğŸ“º Kollision\n\n12.2.1 Kein Zusammenhang von Intelligenz und SchÃ¶nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und SchÃ¶nheit (looks), wie AbbildungÂ 12.1 illustriert. FÃ¼r geringe Intelligenzwerte gibt es eine breites Spektrum von SchÃ¶nheitswerten und fÃ¼r hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildungÂ 12.1: Kein Zusammenhang von Intelligenz und SchÃ¶nheit in den Daten\n\n\n\n\n\n12.2.2 Aber Ihre Dates sind entweder schlau oder schÃ¶n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schÃ¶n sind oder schlau - aber seltens beides gleichzeitig (schade), s. AbbildungÂ 12.2.\n\n\n\n\n\n\n\nAbbildungÂ 12.2: Ihre Datingpartner sind komischerweise entweder schlau oder schÃ¶n (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?\n\n12.2.3 DAG zur Rettung\nğŸ¦¹ ğŸ¦¸\nDer DAG in AbbildungÂ 12.3 bietet eine rettende ErklÃ¤rung.\n\n\n\n\n\n\n\nAbbildungÂ 12.3: Date als gemeinsame Wirkung von SchÃ¶nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen SchÃ¶nheit und Intelligenz.\n\n\n\n\nEine Ã¤hnliche Visualisierung des gleichen Sachverhalts zeigt AbbildungÂ 12.4.\n\n\n\n\n\n\n\nAbbildungÂ 12.4: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n12.2.4 Was ist eine Kollision?\n\nDefinition 12.1 (Kollision) Als Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) (Pearl, Glymour, und Jewell 2016, p.Â 40). \\(\\square\\)\n\nKontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. AbbildungÂ 12.3, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche PrÃ¤diktoren einer Regression hinzufÃ¼gen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nğŸ™…â€â™€ï¸ Kontrollieren Sie keine Kollisionsvariablen. \\(\\square\\)\n\n\n\n12.2.5 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchÃ¶ne Menschen ğŸª\nReiche Menschen ğŸ¤‘\n\nSehen wir davon aus, dass SchÃ¶nheit und Reichtum unabhÃ¤ngig voneinander sind.\n\nÃœbungsaufgabe 12.1 Wenn ich Ihnen sage, dass Don nicht schÃ¶n ist, aber in der Glitzer hÃ¤ufig auftaucht, was lernen wir dann Ã¼ber seine finanzielle Situation?1 \\(\\square\\)\n\n\nâ€œIch bin schÃ¶n, unglaublich schÃ¶n, und groÃŸ, groÃŸartig, tolle Gene!!!â€ ğŸ§‘\n\n\n12.2.6 Noch ein einfaches Beispiel zur Kollision\n\nâ€œSo langsam check ichâ€™s!â€ ğŸ§‘2\n\nSei Z = X + Y, wobei X und Y unabhÃ¤ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts Ã¼ber Y, da die beiden Variablen unabhÃ¤ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhÃ¤ngig, gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).3\n\n12.2.7 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildungÂ 12.3 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als PrÃ¤diktor in eine Regression zusÃ¤tzlich zu looks mit talent als PrÃ¤dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (â€œFlussâ€) von Looks Ã¼ber date nach Talent ist blockiert.\nKontrolliert man date, so Ã¶ffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr â€œblockiertâ€, die Korrelation kann â€œflieÃŸenâ€ - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n12.2.8 IQ, Fleiss und Eignung fÃ¼rs Studium\nSagen wir, Ã¼ber die Eignung fÃ¼r ein Studium wÃ¼rden nur (die individuellen AusprÃ¤gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in AbbildungÂ 12.5.\n\n\n\n\n\n\n\nAbbildungÂ 12.5: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fÃ¼rs Studium) sei definiert als die Summe von iq und fleiss, plus etwas GlÃ¼ck, s. ListingÂ 12.1.\n\n\n\nListingÂ 12.1: Eignung ist die Summe von Fleiss und Intelligenz, plus ein Quentchen GlÃ¼ck\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\n\n\n\nLaut unserem Modell setzt sich Eignung zur HÃ¤lfte aus Intelligenz und zur HÃ¤lfte aus Fleiss zusammen, plus etwas GlÃ¼ck.\n\n12.2.9 Schlagzeile â€œFleiÃŸ macht blÃ¶d!â€\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und FleiÃŸ (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das â€œEignungsmodellâ€, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. TabelleÂ 12.1.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\nTabelleÂ 12.1: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildungÂ 12.6 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildungÂ 12.6: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhÃ¤ngig von FleiÃŸ in unseren Daten, sondern abhÃ¤ngig. Nichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde Ã¼ber ZusammenhÃ¤nge auf und interpretieren die ZusammenhÃ¤nge â€“ oft vorschnell â€“ als kausal.4\n\n12.2.10 Kollisionsverzerrung nur bei Stratifizierung\n\nDefinition 12.2 (Stratifizieren) Durch Stratifizieren wird eine Stichprobe in (homogene) Untergruppen unterteilt (sog. Strata). \\(\\square\\)\n\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. AbbildungÂ 12.7.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 12.7: Stratifizierung und Scheinkorrelation. A: Keine Stratifizierung und keine Scheinkorrelation. B: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nÃ¼tzen.\nNur Kenntnis des DAGs verrÃ¤t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten PrÃ¤diktor auf, so â€œkontrolliertâ€ man diese Variable. Das Regressiongewicht des ersten PrÃ¤diktors wird â€œbereinigtâ€ um den Einfluss des zweiten PrÃ¤diktors; insofern ist der zweite PrÃ¤diktor dann â€œkontrolliertâ€.\n\n\n\n12.2.11 Einfluss von GroÃŸeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und GroÃŸeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von GroÃŸeltern auf ihre Enkel, s. AbbildungÂ 12.8, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildungÂ 12.8: Der kausale Effekt von GroÃŸeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable Ã¼bersehen haben? (S. nÃ¤chster Abschnitt). ğŸ‘»\n\n12.2.12 Der Gespenster-DAG\nğŸ‘» Es gibt â€œunheilbareâ€ DAGs, nennen wir sie â€œGespenster-DAGsâ€, in denen es nicht mÃ¶glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. AbbildungÂ 12.9. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: â€œDeine Theorie ist nicht gut, zurÃ¼ck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.â€\n\n\n\n\n\n\n\nAbbildungÂ 12.9: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollstÃ¤ndig) mÃ¶glich.\n\n\n\n\nU kÃ¶nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft. Die GroÃŸeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie. E ist sowohl fÃ¼r G als auch fÃ¼r U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad. Wenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\nDie Sache ist in diesem Fall chancenlos. Wir mÃ¼ssen diesen DAG verloren geben, McElreath (2020), S. 180; ein Gespenster-DAG. ğŸ‘»",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-hintertÃ¼r-schlieÃŸen",
    "href": "1180-kausalatome.html#die-hintertÃ¼r-schlieÃŸen",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.3 Die HintertÃ¼r schlieÃŸen",
    "text": "12.3 Die HintertÃ¼r schlieÃŸen\n\nDefinition 12.3 (HintertÃ¼r) Eine â€œHintertÃ¼râ€ ist ein nicht-kausaler Pfad zwischen einer UV und einer AV. Ein HintertÃ¼rpfad entsteht, wenn es eine alternative Route Ã¼ber eine oder mehrere Variable gibt, die UV mit der AV verbindet. Dieser Pfad verzerrt die SchÃ¤tzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. \\(\\square\\)\n\n\n12.3.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groÃŸ ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in AbbildungÂ 12.10 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 12.10: Der Preis wird sowohl von der Zimmerzahl als auch der WohnflÃ¤che beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund fÃ¼r die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\leftarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. GÃ¤be es nur nur den zweiten Pfad und wir wÃ¼rden b Ã¤ndern, so wÃ¼rde sich p nicht Ã¤ndern.\n\n12.3.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildungÂ 12.11 zeigt eine erfreuliche Situation: Die â€œHintertÃ¼râ€ zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die HintertÃ¼r geschlossen - fÃ¼hren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildungÂ 12.11: Unverzerrte SchÃ¤tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere PrÃ¤diktor im Modell enthalten ist. Da die beiden PrÃ¤diktoren unkorreliert sind, hat die Aufnahme des einen PrÃ¤diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie â€œHintertÃ¼râ€ der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berÃ¼hmte LÃ¶sung, den kausalen Pfad zu isolieren, ist ein (randomisiertes, kontrolliertes5) Experiment. Wenn wir den HÃ¤usern zufÃ¤llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen kÃ¶nnten (unabhÃ¤ngig von ihrer Quadratmeterzahl, a), wÃ¼rde sich der Graph so Ã¤ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\leftarrow a \\rightarrow p\\) geschlossen (â€œblockiertâ€).\n\n\n\n\n\n\nWichtig\n\n\n\nDie StÃ¤rke von (gut gemachten) Experimente ist, dass sie kausale HintertÃ¼ren schlieÃŸen. Damit erlauben sie (korrekte) Kausalaussagen. \\(\\square\\)\n\n\n\n12.3.3 HintertÃ¼r schlieÃŸen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die HintertÃ¼r schlieÃŸen (backdoor criterion). Wir wollen die HintertÃ¼re schlieÃŸen, da wir sonst nicht den wahren, kausalen Effekt bestimmen kÃ¶nnen.\nZum GlÃ¼ck gibt es neben Experimenten noch andere Wege, die HintertÃ¼r zu schlieÃŸen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie Konfundierer, um kausale HintertÃ¼ren zu schlieÃŸen. \\(\\square\\)\n\n\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis Ã¼ber b kein zusÃ¤tzliches Wissen Ã¼ber p. Wissen Sie hingegen nichts Ã¼ber a, lernen Sie bei Kenntnis von b auch etwas Ã¼ber p. Konditionieren ist wie â€œgegeben, dass Sie a schon kennenâ€¦â€.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "href": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.4 Die vier Atome der Kausalanalyse",
    "text": "12.4 Die vier Atome der Kausalanalyse\nAbbildungÂ 12.12 stellt die vier â€œAtomeâ€ der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so kÃ¶nnen Sie jedes beliebige Kausalsystem (DAG) entschlÃ¼sseln.\n\n\n\n\n\n\n\nAbbildungÂ 12.12: Die vier Atome der Kausalinferenz\n\n\n\n\n\n12.4.1 Mediation\n\nDefinition 12.4 (Mediator) Einen Pfad mit drei Knoten (Variablen), die Ã¼ber insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man Mediation. Der Mediator ist die Variable zwischen UV und AV [Pearl, Glymour, und Jewell (2016); p.Â 38]. \\(\\square\\)\n\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. AbbildungÂ 12.13. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y â€œvermitteltâ€ oder Ã¼bertrÃ¤gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildungÂ 12.13: Das Kausalmodell der Mediation.\n\n\n\n\n\nBeispiel 12.1 (Mediator kontrollieren?) Sollte man den Mediator m in AbbildungÂ 12.13 kontrollieren, wenn man den Kausaleffekt von x auf y schÃ¤tzen mÃ¶chte?6 \\(\\square\\)\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation â€œflieÃŸtâ€ den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlieÃŸt) die Kette (genau wie bei der Gabel).\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie den Mediator nicht. Der Pfad Ã¼ber den Mediator ist ein â€œechterâ€ Kausalpfad, keine Scheinkorrelation. \\(\\square\\)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. \\(\\square\\)\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. AbbildungÂ 12.14. In AbbildungÂ 12.14 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\). Die Summe der Effekte beider Pfade nennt man den totalen (kausalen) Effekt. Den Effekt Ã¼ber den Mediatorpfad nennt man den indirekten (kausalen) Effekt und den Pfad \\(x\\rightarrow y\\) nennt man den direkten (kaudalen) Effekt.\n\n\n\n\n\n\n\nAbbildungÂ 12.14: Partielle Mediation\n\n\n\n\n\n12.4.2 Der Nachfahre\n\nDefinition 12.5 (Nachfahre) Ein Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. AbbildungÂ 12.15. \\(\\square\\)\n\nKontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet Ã¼ber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise Ã¶ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildungÂ 12.15: Ein Nachfahre verhÃ¤lt sich Ã¤hnlich wie sein Vorfahreâ€¦\n\n\n\n\n\n12.4.3 Kochrezept zur Analyse von DAGs ğŸ‘¨â€ğŸ³\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: ğŸ“„\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geÃ¶ffnet ist.\nBeurteilen Sie fÃ¼r jeden Pfad, ob er ein HintertÃ¼rpfad ist (HintertÃ¼rpfade haben einen Pfeil, der zur UV fÃ¼hrt).\nWenn es geÃ¶ffnete Hinterpfade gibt, prÃ¼fen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlieÃŸen (falls mÃ¶glich).",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich",
    "href": "1180-kausalatome.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.5 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!",
    "text": "12.5 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!\nğŸ“º HintertÃ¼r schlieÃŸen\n\n12.5.1 HintertÃ¼r: ja oder nein?\n\n12.5.1.1 Fall 1: x-&gt;\n\n\\(\\boxed{X \\rightarrow}\\)\nAlle Pfade, die von der UV (X) wegfÃ¼hren, sind entweder â€œguteâ€ Kausalpfade oder automatisch geblockte Nicht-Kausal-Pfade. In diesem Fall mÃ¼ssen wir nichts tun.7\n\n12.5.1.2 Fall 2: -&gt;x\n\n\\(\\boxed{\\rightarrow X}\\)\nAlle Pfade, die zur UV hinfÃ¼hren, sind immer Nicht-Kausal-Pfade, HintertÃ¼ren. Diese Pfade kÃ¶nnen offen sein, dann mÃ¼ssen wir sie schlieÃŸen. Sie kÃ¶nnen auch geschlossen sein, dann mÃ¼ssen wir nichts tun.\n\n\n\n\n\n\nTipp\n\n\n\nSchlieÃŸen Sie immer offene HintertÃ¼ren, um Verzerrungen der Kausaleffekte zu verhinden. \\(\\square\\)\n\n\n\n12.5.2 bsp1\n\nUV: \\(X\\), AV: \\(Y\\), drei Kovariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\n\nAbbildungÂ 12.16: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei HintertÃ¼rpfade in AbbildungÂ 12.16:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlieÃŸt die offene HintertÃ¼r.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n12.5.3 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp2\n\nS. DAG in AbbildungÂ 12.17: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildungÂ 12.17: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen HintertÃ¼ren zu schlieÃŸen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), S. 188.\n\n12.5.4 Implizierte bedingte UnabhÃ¤ngigkeiten von bsp2\n\n\nAuch wenn die Daten nicht sagen kÃ¶nnen, welcher DAG der richtige ist, kÃ¶nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten UnabhÃ¤ngigkeiten geben uns MÃ¶glichkeiten, zu prÃ¼fen, ob wir einen DAG verwerfen (ausschlieÃŸen) kÃ¶nnen. Bedingten UnabhÃ¤ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhÃ¤ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte UnabhÃ¤ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#fazit",
    "href": "1180-kausalatome.html#fazit",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.6 Fazit",
    "text": "12.6 Fazit\n\n12.6.1 Ausstieg\nğŸ“º MusterlÃ¶sung fÃ¼r eine DAG-PrÃ¼fungsaufgabe\nğŸ“º MusterlÃ¶sung fÃ¼r schwierige DAG-PrÃ¼fungsaufgaben\n\nBeispiel 12.2 (PMI zum heutigen Stoff) Der KreativitÃ¤tsforscher Edward de Bono hat verschiedene â€œDenkmethodenâ€ vorgestellt, die helfen sollen, Probleme besser zu lÃ¶sen. Eine Methode ist die â€œPMI-Methodeâ€. PMI steht fÃ¼r Plus, Minus, Interessant. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anfÃ¼hren. Bei Interessant verzichtet man aber explizit auf eine Bewertung (im Sinne von â€œgutâ€ oder â€œschlechtâ€) und fokussiert sich auf Interessantes, Ãœberraschendes, Bemerkenswertes (vgl. De Bono (1974)).\nFÃ¼hren Sie die PMI-Methode zum heutigen Stoff durch!\n\n\nPlus: Was fanden Sie am heutigen Stoff gut, sinnvoll, nÃ¼tzlich?\n\nMinus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, nÃ¼tzlich?\n\nInteressant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! \\(\\square\\)\n\n\n12.6.2 Zusammenfassung\nğŸ“º Kausalmodelle Ã¼berprÃ¼fen\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren kÃ¶nnen, hÃ¤ngt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen kÃ¶nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. â€œDer Unterschied zwischen beiden Gruppen betrÃ¤gt etwa â€¦â€. Allerdings ist eine kausale Interpretation nicht zulÃ¤ssig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht mÃ¶glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dÃ¼rfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten Ã¤ndern sich (oft), wenn man PrÃ¤diktoren zum Modell hinzufÃ¼gt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, mÃ¶glichst viele PrÃ¤diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der â€œkausalen Atomeâ€ ist Voraussetzung zur Ableitung von KausalschlÃ¼sse in Beobachtungsstudien.\n\n12.6.3 Vertiefung\nAn weiterfÃ¼hrender Literatur sei z.B. Cummiskey u.Â a. (2020), LÃ¼bke u.Â a. (2020), Pearl, Glymour, und Jewell (2016) und Dablander (2020) empfohlen. Ein gutes Lehrbuch, das auf Kausalinferenz eingeht, ist Huntington-Klein (2022). Praktischerweise ist es Ã¶ffentlich lesbar. Das Web-Buch Causal Inference for the Brave and True sieht auch vielversprechend aus. Es gibt viele Literatur zu dem Thema; relevante Suchterme sind z.B. â€œDAGâ€, â€œcausalâ€ oder â€œcausal inferenceâ€.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#aufgaben",
    "href": "1180-kausalatome.html#aufgaben",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.7 Aufgaben",
    "text": "12.7 Aufgaben\n\nSammlung â€œkausalâ€",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#section",
    "href": "1180-kausalatome.html#section",
    "title": "12Â  Die Atome des KausalitÃ¤t",
    "section": "\n12.8 â€”",
    "text": "12.8 â€”\n\n\n\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, und Krista Watts. 2020. â€Causal Inference in Introductory Statistics Coursesâ€œ. Journal of Statistics Education 0 (Januar): 1â€“16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. â€An Introduction to Causal Inferenceâ€œ. Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische Denken. Rowohlt Taschenbuch Verlag.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. Boca Raton: CRC Press, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLÃ¼bke, Karsten, Matthias Gehrke, JÃ¶rg Horst, und Gero Szepannek. 2020. â€Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Dataâ€œ. Journal of Statistics Education, April, 1â€“17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "KausalitÃ¤t",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Die Atome des KausalitÃ¤t</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "13Â  Abschluss",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische â€œLieblingsfehlerâ€ benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik Ã¼bersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n13.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n13.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "13Â  Abschluss",
    "section": "\n13.2 Lieblinglingsfehler",
    "text": "13.2 Lieblinglingsfehler\nLieblingsfehler im Ãœberblick ğŸ¤·:\n\nPost-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrÃ¤diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n13.2.1 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·\nğŸ ğŸ Vertiefung: Dieser Abschnitt ist nicht prÃ¼fungsrelevant. ğŸï¸ ğŸ\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. TabelleÂ 13.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelleÂ 13.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. HÃ¤ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und PunktschÃ¤tzer auszulesen.\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n13.2.2 Quantile und Verteilungsfuntion verwechseln ğŸ¤·\n\n13.2.2.1 Quantil fÃ¼r \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. AbbildungÂ 13.1.\n\n\n\n\n\n\n\nAbbildungÂ 13.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) betrÃ¤gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist grÃ¶ÃŸer oder gleich dem \\(p\\)-Quantil.\n\n13.2.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. AbbildungÂ 13.2.\n\n\n\n\n\n\n\nAbbildungÂ 13.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betrÃ¤gt hier 50%, dass \\(x\\) nicht grÃ¶ÃŸer ist als 0.\n\n13.2.3 Interaktion falsch interpretieren ğŸ¤·\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kÃ¼rzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. TabelleÂ 13.2.\n\nparameters(m2)\n\n\n\n\nTabelleÂ 13.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.58\n(19.05, 30.23)\n100%\n0.999\n2272.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.58%\n1.000\n2257.00\nNormal (0.00 +- 0.22)\n\n\nvs\n14.03\n(4.82, 22.98)\n99.90%\n1.001\n1900.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.03)\n99.65%\n1.001\n2111.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelleÂ 13.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\n\n\n\nAbbildungÂ 13.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch ğŸ˜ˆ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11.\nRichtig ğŸ‘¼ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11 â€“ wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte PrÃ¤diktoren wÃ¤ren hier eine sinnvolle LÃ¶sung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "13Â  Abschluss",
    "section": "\n13.3 Kochrezepte ğŸ²",
    "text": "13.3 Kochrezepte ğŸ²\n\n13.3.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen Ã¼ber ein PhÃ¤nomen, \\(y\\), Kausalfrage finden 2. Literatur wÃ¤lzen, um mÃ¶gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese prÃ¤zisieren 4. Modell prÃ¤zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prÃ¼fen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n13.3.2 Parameter schÃ¤tzen vs.Â Hypothesen prÃ¼fen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schÃ¤tzen. Beispiel HypothesenprÃ¼fung: â€œFrauen parken im Durchschnitt schneller ein als MÃ¤nnerâ€. Beispiel ParameterschÃ¤tzung: â€œWie groÃŸ ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und MÃ¤nnern?â€\nJe ausgereifter ein Forschungsfeld, desto kÃ¼hnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nÃ¤chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nÃ¤chste Sonnenfinsternis wird in den nÃ¤chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen fÃ¼r den Klausurerfolg. KÃ¼hne Hypothesen sind wÃ¼nschenswert ğŸ¦¹\n\n13.3.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist hÃ¶her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist grÃ¶ÃŸer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "13Â  Abschluss",
    "section": "\n13.4 Kerngedanken Bayes",
    "text": "13.4 Kerngedanken Bayes\nğŸ“º Bayes in fÃ¼nf Minuten\nğŸ“º Bayes in zehn Minuten\n\n13.4.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. AbbildungÂ 13.4.\n\n\n\n\n\n\n\nAbbildungÂ 13.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist mÃ¶glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind mÃ¶glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings Ã¼bermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n13.4.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "href": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "title": "13Â  Abschluss",
    "section": "\n13.5 Beispiele fÃ¼r PrÃ¼fungsaufgaben",
    "text": "13.5 Beispiele fÃ¼r PrÃ¼fungsaufgaben\n\n13.5.1 Geben Sie den korrekten Begriff an!\nğŸŒ¬ğŸš™ğŸ™‹ï¸ğŸ‘¨â¬…ï¸Hans ğŸ‘§â¬…ï¸Anna ğŸ‘©â¬…ï¸Lise\nPuh, wie erstelle ich fÃ¼r alle Studis ein anderes RÃ¤tsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-PrÃ¼fung bekommen alle Studentis eine eigene, jeweils andere PrÃ¼fung. Teamarbeit bleibt natÃ¼rlich trotzdem untersagt.\n\n\n\n13.5.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. AbbildungÂ 13.5.\n\n\n\n\n\n\n\nAbbildungÂ 13.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 13.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge fÃ¼r x und y gibt eine kleinstmÃ¶gliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu â€œidentifizierenâ€). \\(\\square\\)\n\nâ“Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\nâ— Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n13.5.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. AbbildungÂ 13.6.\n\n\n\n\n\n\n\nAbbildungÂ 13.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n13.5.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildungÂ 13.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildungÂ 13.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set fÃ¼r den totalen Kausaleffekt: {AIS, ALN}\n\n13.5.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrÃ¼fungsfragen zu Modellen kÃ¶nnten z.B. sein:\n\nGeben Sie den PunktschÃ¤tzer (Median) fÃ¼r den PrÃ¤diktor X im Modell Y an!\nGeben Sie ein 89%-HDI fÃ¼r den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris â€¦\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI fÃ¼r den PrÃ¤diktor X im Modell Y?\nWas verÃ¤ndert sich an den Parametern, wenn Sie die PrÃ¤diktoren zentrieren/z-standardisieren?\nâ€¦",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "13Â  Abschluss",
    "section": "\n13.6 Aufgabensammlungen",
    "text": "13.6 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere â€œPrÃ¼fungsnÃ¤heâ€ kÃ¶nnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "title": "13Â  Abschluss",
    "section": "\n13.7 Viel Erfolg bei der PrÃ¼fung!",
    "text": "13.7 Viel Erfolg bei der PrÃ¼fung!\nğŸ¥³ğŸ†ğŸ€ğŸ€ğŸ€",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "13Â  Abschluss",
    "section": "\n13.8 â€”",
    "text": "13.8 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. â€The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphsâ€œ. European Psychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. â€œMisconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.â€ Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCohen, J. 1992. â€œA Power Primer.â€ Psychological\nBulletin 112 (1): 155â€“59.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas\nClark, and Krista Watts. 2020. â€œCausal Inference in Introductory\nStatistics Courses.â€ Journal of Statistics Education 0\n(January): 1â€“16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. â€œAn Introduction to Causal\nInference.â€ Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische\nDenken. Rowohlt Taschenbuch Verlag.\n\n\nForum, World Economic. 2020. â€œThe Future of\nJobs Report 2020.â€ CH-1223 Cologny/Geneva\nSwitzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\nâ€œR-Squared for Bayesian Regression Models.â€ The\nAmerican Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2020.\nâ€œRstanarm: Bayesian Applied Regression Modeling via\nStan.â€ https://mc-stan.org/rstanarm.\n\n\nHenze, Norbert. 2019. Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der\nMaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to\nResearch Design and Causality. Boca Raton: CRC\nPress, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of\nScience. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nKampen, D. van. 2014. â€œThe SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.â€ European\nPsychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter\nValues in Bayesian Estimation.â€ Advances\nin Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLÃ¼bke, Karsten, Matthias Gehrke, JÃ¶rg Horst, and Gero Szepannek. 2020.\nâ€œWhy We Should Teach Causal Inference: Examples in\nLinear Regression with Simulated Data.â€ Journal of Statistics\nEducation, April, 1â€“17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel LÃ¼decke. 2019. â€œIndices of Effect Existence\nand Significance in the Bayesian\nFramework.â€ Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. â€œChocolate Consumption,\nCognitive Function, and Nobel\nLaureates.â€ New England Journal of Medicine 367\n(16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nMittag, Hans-Joachim, and Katharina SchÃ¼ller. 2020. Statistik: Eine\nEinfÃ¼hrung mit interaktiven Elementen. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4.\n\n\nMorey, Richard D., and Jeffrey N. Rouder. 2011. â€œBayes Factor\nApproaches for Testing Interval Null Hypotheses.â€\nPsychological Methods 16 (4): 406â€“19. https://doi.org/10.1037/a0024377.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Edited by\nHerbert Keuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.\n\n\nRohrer, Julia M. 2018. â€œThinking Clearly About\nCorrelations and Causation: Graphical Causal\nModels for Observational Data.â€ Advances\nin Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nSuttorp, Marit M., Bob Siegerink, Kitty J. Jager, Carmine Zoccali, and\nFriedo W. Dekker. 2015. â€œGraphical Presentation of Confounding in\nDirected Acyclic Graphs.â€ Nephrology Dialysis\nTransplantation 30 (9): 1418â€“23. https://doi.org/10.1093/ndt/gfu325.\n\n\nTennant, Peter W G, Eleanor J Murray, Kellyn F Arnold, Laurie Berrie,\nMatthew P Fox, Sarah C Gadd, Wendy J Harrison, et al. 2020. â€œUse\nof Directed Acyclic Graphs (DAGs) to Identify Confounders\nin Applied Health Research: Review and Recommendations.â€\nInternational Journal of Epidemiology 50 (2): 620â€“32. https://doi.org/10.1093/ije/dyaa213.\n\n\nVanderWeele, Tyler J., and Ilya Shpitser. 2013. â€œOn the Definition\nof a Confounder.â€ Annals of Statistics 41 (1): 196â€“220.\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276366/.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. â€œThe\nASA Statement on p-Values:\nContext, Process, and Purpose.â€ The American\nStatistician 70 (2): 129â€“33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]