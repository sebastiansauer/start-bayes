[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "Bayes:Start!\n\n\n\nğŸš§WORK IN PROGRESSğŸš§\n\n\n\nNach diesem Kurs sollten Sie â€¦\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige einschlÃ¤gige Forschungsfragen in statistische Modelle Ã¼bersetzen und mit R auswerten kÃ¶nnen\nkausale Forschungsfragen in statistische Modelle Ã¼bersetzen und prÃ¼fen kÃ¶nnen\ndie GÃ¼te und Grenze von statistischen Modellen einschÃ¤tzen kÃ¶nnen\n\n\n\n\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\n\n\n\n\nInstallieren Sie R und seine Freunde.\nInstallieren Sie die folgende R-Pakete:\n\ntidyverse\nrstanarm\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\n\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.\n\n\n\n\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen wÃ¤hrend des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von ArbeitsbeitrÃ¤gen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      Nr\n      Thema\n      Datum\n      Kommentar\n    \n  \n  \n    1\nWas ist Inferenz?\n3. - 7. Okt. 2022\nDie erste Unterrichtsstunde fÃ¤llt auf den 7. Okt. 2023.\n    2\nWahrscheinlichkeit\n10. - 14. Okt. 22\nNA\n    3\nHallo, Bayes\n17. - 21. Okt. 22\nNA\n    4\nDie Post befragen\n24. - 28. Okt. 22\nNA\n    5\nGauss-Modelle\n31. Okt. - 4. Nov. 22\nNA\n    6\nLineare Modelle\n7. - 11. Nov. 22\nNA\n    NA\nBLOCKWOCKE\n14. - 18. Nov. 22\nKein regulÃ¤rer Unterricht\n    7\nMetrische AV\n21. - 25. Nov. 22\nNA\n    8\nFallstudien\n28. Nov. - 2. Dez. 22\nNA\n    9\nKausalinferenz 1\n5. Dez. - 9. Dez. 22\nNA\n    10\nKausalinferenz 2\n12. - 16. Dez. 22\nNA\n    11\nBinÃ¤re AV\n19. - 23. Dez. 22\nNA\n    NA\nWEIHNACHTSFERIEN\nNA\nKein Unterricht\n    12\nAbschluss\n9. Jan. 23 - 13. Jan. 23\nNA\n  \n  \n  \n\n\n\n\n\n\n\nPro Thema wird Literatur ausgewiesen.\n\n\n\nDieses Dokument wurde erzeut am/um 2022-09-08 23:58:28.\n\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2022-09-08\n pandoc   2.19.2 @ /usr/local/bin/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.2.0)\n cli           3.3.0      2022-04-25 [1] CRAN (R 4.2.0)\n colorout    * 1.2-2      2022-06-13 [1] local\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.0)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.16       2022-08-09 [1] CRAN (R 4.2.0)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n ggplot2       3.3.6.9000 2022-09-05 [1] Github (tidyverse/ggplot2@a58b48c)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt            0.7.0      2022-08-25 [1] CRAN (R 4.2.0)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.0      2022-02-22 [1] CRAN (R 4.2.0)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.0)\n lifecycle     1.0.2      2022-09-05 [1] Github (r-lib/lifecycle@f92faf7)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n purrr         0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n readxl        1.4.1      2022-08-17 [1] CRAN (R 4.2.0)\n rlang         1.0.5      2022-08-31 [1] CRAN (R 4.2.0)\n rmarkdown     2.16       2022-08-24 [1] CRAN (R 4.2.0)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.0)\n sass          0.4.2      2022-07-16 [1] CRAN (R 4.2.0)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyselect    1.1.2      2022-02-21 [1] CRAN (R 4.2.0)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n vctrs         0.4.1      2022-04-13 [1] CRAN (R 4.2.0)\n xfun          0.32       2022-08-10 [1] CRAN (R 4.2.0)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.0)\n\n [1] /Users/sebastiansaueruser/Rlibs\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "metrische-AV.html",
    "href": "metrische-AV.html",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "",
    "text": "BenÃ¶tigte R-Pakete fÃ¼r dieses Thema:"
  },
  {
    "objectID": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "href": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.1 Wissenschaft als Gerechtigkeitsprojekt",
    "text": "10.1 Wissenschaft als Gerechtigkeitsprojekt\n\n10.1.1 Meinungen als Grundlage der KonfliktlÃ¶sung ?\nContra:\n\nâ€œIch find Masken doof!â€\nâ€œImpfen ist schÃ¤dlich!â€\nâ€œCorona gibtâ€™s gar nicht!â€\n\n\n\n  \n\n\nPro:\n\nâ€œIch find Masken gut!â€\nâ€œImpfen ist nÃ¼tzlich!â€\nâ€œCorona ist gefÃ¤hrlich!â€\n\n\n\n  \n\n\nMeinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte kÃ¶nnen auf Basis von Meinungen nur schwer gelÃ¶st werden.\n\n\n10.1.2 Fakten als Grundlage der KonfliktlÃ¶sung\nWissenschaft produziert Fakten. Da Fakten universell sind (sein kÃ¶nnen), ist Wissenschaft potenziell ein Weg zur KonfliktlÃ¶sung. Warum helfen Fakten bei Konflikten?\nFakten sind neutral gegenÃ¼ber Personen. Fakten bieten daher eine Chance zur fairen Einigung.\nWann ist ein Fakt ein Fakt?\nFakten mÃ¼ssen vor allem nachprÃ¼fbar sein (Daten, Analyse und Bericht mÃ¼ssen offen zugÃ¤nglich sein).\n\n\n10.1.3 Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung\n\nThe effectiveness of full messenger RNA (mRNA) vaccination (â‰¥14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.\n\nThompson et al. (2021); vgl. auch Nasreen et al. (2021); Pormohammad et al. (2021)\nDrei Anforderungen an die QualitÃ¤t von Studien:\n\nhandwerklich gut: z.B. vergleichbare Gruppen, genaue Messinstrumente\nbescheiden: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche QualitÃ¤t der Studie zulÃ¤sst. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage berÃ¼cksichtigt.\ntransparent: Das Vorgehen, die HintergrÃ¼nde und Ziele werden offengelegt. Das betrifft auch mÃ¶glich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen\n\n\n\n10.1.4 Psychologische Intervention zur ErhÃ¶hung der Impfquote\n\n\n\n\n\nQuelle/Volltext\nDai et al. (2021)\n\n\n10.1.5 Was heiÃŸt â€œist effektivâ€?\nNasreen et al. (2021) definieren effectivity, \\(e\\), so:\n\\[e = 1 - C; C= \\frac{n_{vacc|pos}}{n_{vacc|neg}}\\]\n\n\\(C\\) nennt man das ChancenverhÃ¤ltnis (odds ratio), es beschreibt einen Bruchterm: \\(\\frac{x}{y}\\).\n\\(n_{vacc|pos}\\): Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose\n\\(n_{vacc|neg}\\): Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose\n\nBeispiel: Von den 100 Personen mit positiver Corona-Diagnose sind 10 geimpft, \\(n_{vacc|pos}=10\\). Von den 100 Personen mit negativer Corona-Diagnose sind 90 geimpft, \\(n_{vacc|neg}=90\\)\n\\[C= \\frac{10}{90} = \\frac{1}{9}; e = 1 - \\frac{1}{9} = \\frac{8}{9} \\approx 0.88\\]\nIn diesem Beispiel liegt die EffektvititÃ¤t \\(e\\) bei knapp 90%."
  },
  {
    "objectID": "metrische-AV.html#arten-von-forschungsfragen",
    "href": "metrische-AV.html#arten-von-forschungsfragen",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.2 Arten von Forschungsfragen",
    "text": "10.2 Arten von Forschungsfragen\n\n10.2.1 Deskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\n\n\n10.2.2 PrÃ¤diktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der GrÃ¶ÃŸe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts fÃ¼r die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhÃ¤lt?\n\n\n\n10.2.3 PrÃ¤skriptiv (erklÃ¤rend, kausal)\n\nIst GrÃ¶ÃŸe eine Ursache von Gewicht (bei deutschen MÃ¤nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n10.2.4 Metrische AV\n\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV.\nFÃ¼r die UV(s) sind nominale und metrische Skalenniveaus erlaubt.\nModelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt."
  },
  {
    "objectID": "metrische-AV.html#binÃ¤re-uv",
    "href": "metrische-AV.html#binÃ¤re-uv",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.3 1 binÃ¤re UV",
    "text": "10.3 1 binÃ¤re UV\n\n10.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im Ã¶ffentlichen Dienst arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwÃ¤ndigen Studie die Intelligenz vieler Kinder gemessen. ZusÃ¤tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, â€œRisikofaktorenâ€ fÃ¼r geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in AbhÃ¤ngigkeit davon, ob ihre jeweilige Mutter Ã¼ber einen Schlusabschluss (mom_hs) verfÃ¼gt? (ceteris paribus)\n\n\n\n10.3.2 IQ von Kindern, binÃ¤rer PrÃ¤diktor\n\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 <- stan_glm(\n  kid_score ~ mom_hs, \n  data = kidiq)\n\nAlternativ kÃ¶nnen Sie die Daten hier herunterladen.\nMit parameters(m10.1) bekommt man die Parameter des Modells:\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n77.61\n(73.33, 81.59)\n100%\n0%\n1.000\n4119.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.73\n(7.20, 16.63)\n100%\n0%\n1.000\n4194.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nggplot(kidiq) +\n  aes(x = mom_hs, y = kid_score) +\n  geom_jitter(width = 0.1, alpha = .5) +\n  geom_abline(slope = coef(m10.1)[2],\n              intercept = coef(m10.1)[1])  +\n  scale_x_continuous(breaks = c(0, 1))\n\n\n\n\n\n\n10.3.3 Interpretation von m10.1\nm10.1: kid_score = 78 + 12*mom_hs + error\n\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss (mom_hs = 0) verfÃ¼gen:\n\nkid_score = 78 + 0*12 + error\n\nDas Regressionsgewicht (slope, \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit MÃ¼tter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit MÃ¼tter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\nkid_score = 78 + 1*12 + error = 90 + error\n\nDie GrÃ¶ÃŸer der Konfidenzintervalle zeigt, wie genau die SchÃ¤tzung (Vorhersage) ist bzw. wie stark PrÃ¤diktor (UV) und Kriterium (AV) zusammenhÃ¤ngen.\n\n\n\n10.3.4 m10.1 als Mittelwertsdifferenz\n\nUV: binÃ¤r (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\n\nkidiq %>% \n  group_by(mom_hs) %>% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n\n0\n77.54839\n\n\n1\n89.31965\n\n\n\n\n\n\n\nIn der klassischen Statistik untersucht man diese Datensituation mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, dass prÃ¼ft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).\nIn der Bayes-Statistik betrachtet man dazu die Posteriori-Verteilung (z.B. mit 95%PI).\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von MÃ¼ttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.\n\n\n10.3.5 Antwort auf die Forschungsfrage, m10.1\n\nm10.1_post <-\n  m10.1 %>% \n  as_tibble() \n\n\n\n\n\n\n\n  \n    \n      Stichprobe aus der Post-Verteilung\n    \n    \n  \n  \n    \n      (Intercept)\n      mom_hs\n      sigma\n    \n  \n  \n    77.4\n12.9\n19.5\n    77.8\n11.3\n19.0\n    77.9\n11.0\n20.8\n    77.3\n13.0\n19.8\n    81.7\n10.2\n19.5\n  \n  \n  \n\n\n\n\n\npi_mom_hs <-\n  m10.1_post %>% \n  summarise(pi_95 = quantile(mom_hs, c(.025, .975)))\n\npi_mom_hs\n\n\n\n\n\npi_95\n\n\n\n\n7.195229\n\n\n16.634792\n\n\n\n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\).\nDie Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlieÃŸend die Posteriori-Verteilung.\n\nplot(hdi(m10.1))"
  },
  {
    "objectID": "metrische-AV.html#nullhypothesen-sind-praktisch-immer-falsch",
    "href": "metrische-AV.html#nullhypothesen-sind-praktisch-immer-falsch",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.4 Nullhypothesen sind praktisch immer falsch",
    "text": "10.4 Nullhypothesen sind praktisch immer falsch\n\n\nâ€“>\n\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, and Vehtari (2021)\n\n10.4.1 Alternativen zu Nullhypothesen\n\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\).\nNullhypothesen zu testen, ist sehr verbreitet.\nEin Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist1\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen:\n\nPosteriori-Intervalle (PI oder HDI) berichten\nRope-Konzept, Kruschke (2018)\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat."
  },
  {
    "objectID": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.5 Eine metrische plus eine nominale UV",
    "text": "10.5 Eine metrische plus eine nominale UV\n\n10.5.1 Forschungsfrage\n\nWie stark ist der Zusammenhang von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\n\ndata(\"kidiq\")  # Paket rstanarm, alternativ Ã¼ber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\nDatenquelle\n\n\n10.5.2 1 metrischer PrÃ¤diktor\n\nm10.2 <-\n  stan_glm(kid_score ~ mom_iq, data = kidiq)\n\nm10.2 %>% \n  parameters()\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n25.90\n(13.81, 37.53)\n100%\n0%\n1.000\n3532.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.49, 0.73)\n100%\n0%\n1.000\n3535.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder fÃ¼r verschiedene IQ-Werte der MÃ¼tter. Vergleicht man Teilpopulationen von MÃ¼ttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n\n10.5.3 Beide PrÃ¤diktoren, m10.3\nm10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error\n\nm10.3 <- \n  stan_glm(\n    kid_score ~ mom_hs + mom_iq, \n    refresh = 0,\n    data = kidiq)\n\nWill man nur schnell die PunktschÃ¤tzer (Median) zu den Modellparametern (auch als Koeffizienten bezeichnet), so kann man anstelle von parameters() auch schreiben:\n\ncoef(m10.3)\n\n(Intercept)      mom_hs      mom_iq \n 25.6244540   5.8574201   0.5639949 \n\n\nMÃ¶chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\ncoef(m10.3)[3]\n\n   mom_iq \n0.5639949 \n\n\n\nkidiq %>% \n  mutate(mom_hs = factor(mom_hs)) %>%  \n  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.3)[3],  # den 3. Wert aus dem Vector, den `coef()` zurÃ¼ckgibt\n              intercept = 26,\n              size = 1,\n              color = \"blue\") +\n  geom_abline(slope = coef(m10.3)[3],\n              intercept = 32,\n              color = \"red\",\n              size = 2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme(legend.position = \"bottom\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schÃ¤tzt das Modell den IQ-Wert des Kindes auf 26.\nKoeffizient zum mÃ¼tterlichen Schulabschluss: Vergleicht man Kinder von MÃ¼ttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\nKoeffizient zur mÃ¼tterlichen IQ: Vergleicht man Kinder von MÃ¼ttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus."
  },
  {
    "objectID": "metrische-AV.html#interaktion",
    "href": "metrische-AV.html#interaktion",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.6 Interaktion",
    "text": "10.6 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nImportant\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.\n\n\n\nm10.4 <- \n  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, \n                  data = kidiq, refresh = 0)\n\ncoef(m10.4)\n\n  (Intercept)        mom_hs        mom_iq mom_hs:mom_iq \n   -9.8112627    49.1923581     0.9502973    -0.4611944 \n\n\n\n\n\n\n\n\n10.6.1 Interpretation von m10.4\n\nAchsenabschnitt: IQ-SchÃ¤tzwerte fÃ¼r Kinder mit MÃ¼tter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\nmom_hs: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\nmom_iq: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit MÃ¼ttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\nInteraktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten fÃ¼r mom_iq zwischen MÃ¼tter mit bzw. ohne Schulabschluss.\n\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\nGelman, Hill, and Vehtari (2021), Kap. 10.3\n\n\n10.6.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "href": "metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.7 Zentrieren von PrÃ¤diktoren",
    "text": "10.7 Zentrieren von PrÃ¤diktoren\n\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.\nZentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist.\nMit zentrierten Werten ist eine Regression einfacher zu interpretieren.\n\n\nkidiq <-\n  kidiq %>% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq),\n         mom_hs_c = mom_hs - mean(mom_hs))\n\n\nm10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.5)\n\n    (Intercept)          mom_hs        mom_iq_c mom_hs:mom_iq_c \n     85.3309711       2.9653183       0.9606276      -0.4754285 \n\n\n\n10.7.1 Interpretation von m10.5\n\nDer Achsenabschnitt (Intercept) gibt den geschÃ¤tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\nmom_hs gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\nmom_iq_c gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten fÃ¼r mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\n\n\n\n\n\n\n\n10.7.2 Zentrieren Ã¤ndert nichts an den Vorhersagen\nm10.4:\n\nnew <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new <- posterior_predict(m10.4, newdata = new)\nmean(pred_new)\n\n[1] 85.75561\n\n\nm10.5:\n\nnew <- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new <- posterior_predict(m10.5, newdata = new)\nmean(pred_new)\n\n[1] 85.31916\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren Ã¤ndert auch nicht die Regressionskoeffizienten, da die Streuungen der PrÃ¤diktoren nicht verÃ¤ndert wurden.\n\n\n10.7.3 Perzentilintervalle aus der Posterori-Verteilung\n\neti(m10.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n1\n(Intercept)\n0.95\n81.0758449\n89.635196\nfixed\nconditional\n\n\n2\nmom_hs\n0.95\n-1.7095992\n7.693660\nfixed\nconditional\n\n\n4\nmom_iq_c\n0.95\n0.6794406\n1.250004\nfixed\nconditional\n\n\n3\nmom_hs:mom_iq_c\n0.95\n-0.7932726\n-0.174470\nfixed\nconditional\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5):\n\nhdi(m10.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n1\n(Intercept)\n0.95\n81.0229313\n89.5665715\nfixed\nconditional\n\n\n2\nmom_hs\n0.95\n-1.7925270\n7.5718510\nfixed\nconditional\n\n\n4\nmom_iq_c\n0.95\n0.6919419\n1.2586553\nfixed\nconditional\n\n\n3\nmom_hs:mom_iq_c\n0.95\n-0.7749202\n-0.1630003\nfixed\nconditional\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n\n10.7.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei MÃ¼ttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mÃ¼tterlichen Intelligenz; pro Punkt Unterschied in mÃ¼ttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). AuÃŸerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei MÃ¼tter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. ZusammenhÃ¤nge beschrieben.\n\n\n10.7.5 Relevanz von PrÃ¤diktoren\n\n\n\nMade at imgflip.com\n\n\nBetrachten wir m10.3 noch einmal.\nWelcher PrÃ¤diktor, mom_hs oder mom_hs ist wichtiger, im Sinne von stÃ¤rker mit AV kid_score verbunden?\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n13.8066119\n36.7972407\nfixed\nconditional\n\n\nmom_hs\n0.95\n1.5964447\n10.1824593\nfixed\nconditional\n\n\nmom_iq\n0.95\n0.4368564\n0.6721882\nfixed\nconditional\n\n\n\n\n\n\nDas Problem ist, dass die PrÃ¤diktoren auf verschiedenen Skalen gemessen wurden, so dass sie nicht direkt vergleichbar sind. Man kÃ¶nnte\n\ndie Skalierungen der PrÃ¤diktoren angleichen\nVorhersagegÃ¼te verschiedener Modelle vergleichen (Modell mit einem vs.Â Modell mit beiden PrÃ¤diktoren)\nâ€¦\nDazu spÃ¤ter mehr ğŸ¤“"
  },
  {
    "objectID": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.8 Eine nominale UV mit mehreren Stufen",
    "text": "10.8 Eine nominale UV mit mehreren Stufen\n\n10.8.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium haben Sie bei einem aufstrebenden Online-HÃ¤ndler angeheuert Sie sind fÃ¼r alles zustÃ¤ndig, was nach Wissenschaft oder Analyse aussieht oder sonst den Anschein erweckt, kompliziert zu sein. Aus irgendwelchen GrÃ¼nden liebt Ihre Chefin Diamanten, so dass Ihre erste Aufgabe darin besteht, Diamantenpreise zu analysieren. Das Ziel Ihrer Chefin liegt darin, zu erkennen, was ein Preis ist, fÃ¼r den ein Diamant gut verkauft werden kann. Kennt man diesen Preis, kann man sich auf die Suche machen, ob man den Diamant irgendwo gÃ¼nstiger findet. Wenn ja, macht man Gewinn. Gutes GeschÃ¤ftsmodell, meint Ihre Chefin.\n\n\nUnterscheiden sich mittlere Diamantenpreise in AbhÃ¤ngigkeit von ihrer Schliffart? (Datensatz diamonds)\n\n\n\n10.8.2 Alle Mittelwerte sind gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Schliffart.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ğŸ¤” Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere Diamantenpreise in AbhÃ¤ngigkeit von ihrer Schliffart?\n\nOder wir prÃ¼fen die Hypothese, ob die Mittelwerte â€œpraktischâ€ gleich sind, also sich â€œkaumâ€ unterscheiden. Der Grenzwert fÃ¼r â€œpraktisch gleichâ€ bzw. â€œkaum unterschiedlichâ€ ist subjektiv.\n\n\n10.8.3 Erster Blick in den Datensatz diamonds\nDatenquelle, Beschreibung des Datensatzes\n\ndiamonds_url <- \"https://tinyurl.com/up84jp5c\"\n\n\nset.seed(42)  # Zufallszahlen fÃ¼r `sample()` festlegen\ndiamonds <- \n  read_csv(diamonds_url) %>% \n  sample_n(1000) %>%  # um etwas Rechenzeit zu sparen\n  select(-1) # 1. Spalte nur laufende Nummer\n\n\ndiamonds %>% \n  select(price, cut) %>% \n  group_by(cut) %>% \n  # nehmen wir die robusten Statistiken, da Preis sehr schief ist:\n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nSkewness\nKurtosis\nn\nn_Missing\n.group\n\n\n\n\nprice\n4558.424\n2978.245\n1.647624\n2.885673\n33\n0\ncut=Fair\n\n\nprice\n4000.304\n3865.095\n1.905924\n3.518412\n102\n0\ncut=Good\n\n\nprice\n3275.998\n3515.271\n1.848450\n3.060260\n407\n0\ncut=Ideal\n\n\nprice\n4919.661\n4416.872\n1.279811\n1.038247\n230\n0\ncut=Premium\n\n\nprice\n3765.803\n3679.062\n1.788728\n3.420209\n228\n0\ncut=Very Good\n\n\n\n\n\n\n\n\n10.8.4 Ein Ãœberblick Ã¼ber die metrischen Variablen\nâ€¦ aufgeteilt in die Stufen von cut:\n\n\n\ncut=Fair\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n4558.42\n2978.25\n2498.50\n(743.00, 13853.00)\n1.65\n2.89\n33\n0\n\n\n\n\ncut=Good\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n4000.30\n3865.10\n3805\n(461.00, 18077.00)\n1.91\n3.52\n102\n0\n\n\n\n\ncut=Ideal\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n3276.00\n3515.27\n3865\n(397.00, 18168.00)\n1.85\n3.06\n407\n0\n\n\n\n\ncut=Premium\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n4919.66\n4416.87\n5310.25\n(345.00, 18493.00)\n1.28\n1.04\n230\n0\n\n\n\n\ncut=Very Good\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n3765.80\n3679.06\n3933.50\n(373.00, 18371.00)\n1.79\n3.42\n228\n0\n\n\n\n\n\nWas fÃ¤llt Ihnen auf?\n\n\n10.8.5 Visualisierung (EDA)\n\n\n\n\n\n\n  \n  \n    \n      cut\n      price_md\n      price_iqr\n    \n  \n  \n    Fair\n3,640\n1,976\n    Good\n3,090\n3,745\n    Ideal\n1,759\n3,850\n    Premium\n4,058\n5,295\n    Very Good\n2,760\n3,902\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\nPicking joint bandwidth of 904\n\n\n\n\n\n\n\n10.8.6 Mittlere Preisunterschiede in der Population\n\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 <- stan_glm(price ~ cut, data = diamonds, refresh = 0)\n# refresh=0 unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n\n\nm10.6 %>% \n  parameters()\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4526.68\n(3238.06, 5820.81)\n100%\n0%\n1.003\n1009.00\nNormal (3881.91 +- 9611.59)\n\n\ncutGood\n-533.57\n(-2029.63, 959.77)\n75.67%\n0%\n1.002\n1123.00\nNormal (0.00 +- 31742.41)\n\n\ncutIdeal\n-1253.86\n(-2603.09, 107.10)\n96.40%\n0%\n1.004\n1044.00\nNormal (0.00 +- 19554.81)\n\n\ncutPremium\n395.44\n(-1002.89, 1776.66)\n71.38%\n0%\n1.003\n1068.00\nNormal (0.00 +- 22828.05)\n\n\ncutVery Good\n-756.51\n(-2148.65, 599.54)\n85.78%\n0%\n1.004\n1039.00\nNormal (0.00 +- 22898.24)\n\n\n\n\n\n\n\n10.8.7 Interpretation von m10.6\n\ncut hat fÃ¼nf verschiedene Werte (Stufen, Faktorstufen, AusprÃ¤gungen), aber es werden nur vier angezeigt.\nDie fÃ¼nfte (Fair, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrÃ¼ckt.\nDie Koeffizienten fÃ¼r cut geben jeweils den Unterschied zur Vergleichskategorie wieder.\nDiamanten der Schliffart Fair haben laut Modell einen mittleren Preis von ca. 4300$.\nDiamanten der Schliffart Good sind laut Modell im Mittel gut 400$ billiger als Diamanten der Schliffart Fair, etc.\n\n\nplot(m10.6, regex_pars = \"^cut\")\n\n\n\n\n\n\n10.8.8 SchÃ¤tzbereiche fÃ¼r die Modellparameter\n\nm10.6 %>% \n  hdi()\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n3294.1221\n5859.2441\nfixed\nconditional\n\n\ncutGood\n0.95\n-2054.2123\n918.7443\nfixed\nconditional\n\n\ncutIdeal\n0.95\n-2517.5156\n159.8897\nfixed\nconditional\n\n\ncutPremium\n0.95\n-967.1144\n1807.1827\nfixed\nconditional\n\n\ncutVery Good\n0.95\n-2043.7011\n672.6454\nfixed\nconditional\n\n\n\n\n\n\n\n\n10.8.9 Glauben wir jetzt an Preisunterschiede?\nâ€¦ zwischen den Preis-Mittelwerten in der Population?\n\nTeilweise, denn einige SchÃ¤tzintervalle (fÃ¼r die Preisunterschiede) waren im Modell m10.6 weit von der Null entfernt, andere nicht.\nAuf Basis unseres Modells schlieÃŸen wir also (mit hoher Sicherheit) aus, dass alle Preise im Mittelwert exakt identisch sind.\nEhrlicherweise hÃ¤tte sowieso niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.\nAber: Viele Forscheris prÃ¼fen gerne die Nullhypothese, daher taucht der Begriff hier auf.\nDas Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA).\nIn der Bayes-Statistik nutzt man - wie immer - primÃ¤r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) zu inferenzstatistisch zu beurteilen.\n\n\n\n10.8.10 Modellkoeffizienten von m10.6\nDie Regressionsoeffizienten pro Stufen von cutentsprechen den Mittelwerten \\(\\hat{y_i}\\) aus der Posteriori-Verteilung. Mit coef(m10.6) kann man sie sich bequem ausgeben lassen.\n\ncoef(m10.6)\n\n (Intercept)      cutGood     cutIdeal   cutPremium cutVery Good \n   4526.6810    -533.5694   -1253.8603     395.4444    -756.5090 \n\n\n\n\\(\\hat{y}_{Fair} = 4527\\)\n\\(\\hat{y}_{Good} = -534\\)\netc."
  },
  {
    "objectID": "metrische-AV.html#priori-werte",
    "href": "metrische-AV.html#priori-werte",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.9 Priori-Werte",
    "text": "10.9 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. FÃ¼r Achsenabschnitt und die Regressionskoeffizienten werden Normalverteilungen angenommen mit Mittelwert entsprechend den Stichprobendaten und Streuung, die der 2.5-fachen der Streuung in der Stichprobe entspricht. Mehr Infos kann man sich so ausgeben lassen: prior_summary(m10.6). Wo man man Ã¼ber mehr inhaltliches Wissen verfÃ¼gt, so wird man die Priors anpassen wollen, z.B.:\n\nm10.6b <- stan_glm(price ~ cut, data = diamonds, refresh = 0,\n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(100, 100, 100, 100)),\n                   prior_intercept = normal(3000, 500))\ncoef(m10.6b)\n\n (Intercept)      cutGood     cutIdeal   cutPremium cutVery Good \n  3766.82654    105.66716    -40.76307    238.00057     78.24536 \n\n\nDie Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\nsigma(m10.6b)\n\n[1] 3831.667\n\n\nImplizit bekommt man diese Informationen mitgeteilt durch die GrÃ¶ÃŸe der Konfidenzintervalle.\n\n10.9.1 Wechsel der Referenzkategorie\n\ncut ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\n\ndiamonds <- diamonds %>% \n  mutate(cut = factor(cut))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge Ã¤ndern.\n\n\nlevels(diamonds$cut)\n\n[1] \"Fair\"      \"Good\"      \"Ideal\"     \"Premium\"   \"Very Good\"\n\n\nSetzen wir Ideal als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nlibrary(forcats)\ndiamonds <- diamonds %>% \n  mutate(cut = factor(cut),\n    cut = fct_relevel(cut, \"Ideal\"))\n\n\nlevels(diamonds$cut)\n\n[1] \"Ideal\"     \"Fair\"      \"Good\"      \"Premium\"   \"Very Good\"\n\n\n\n\n10.9.2 Wechsel der Referenzkategorie Ã¤ndert nichts Wesentliches am Modell\n\nm10.6a <- stan_glm(price ~ cut, data = diamonds, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n2894.85196\n3635.294\nfixed\nconditional\n\n\ncutFair\n0.95\n-80.74787\n2617.730\nfixed\nconditional\n\n\ncutGood\n0.95\n-84.70268\n1529.411\nfixed\nconditional\n\n\ncutPremium\n0.95\n1033.68670\n2268.562\nfixed\nconditional\n\n\ncutVery Good\n0.95\n-124.41863\n1105.342\nfixed\nconditional"
  },
  {
    "objectID": "metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "href": "metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.10 ModellgÃ¼te mit R-Quadrat bestimmen",
    "text": "10.10 ModellgÃ¼te mit R-Quadrat bestimmen\n\n10.10.1 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt.\nHÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt.\n\\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert.\nSolch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor.\nDaher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\nmit bayes_r2() kann man sich die Verteilung berechnen lassen.\n\n\n\n\nr2(m10.6)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.031 (95% CI [0.012, 0.053])\n\n\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen:\n\nm10.6_r2 <-\nm10.6 %>% \n  r2_posterior() %>% \n  as_tibble()\n\nhdi(m10.6_r2) %>% \n  plot()"
  },
  {
    "objectID": "metrische-AV.html#definition-vom-klassischen-r2",
    "href": "metrische-AV.html#definition-vom-klassischen-r2",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.11 Definition vom â€œklassischenâ€ \\(R^2\\)",
    "text": "10.11 Definition vom â€œklassischenâ€ \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\).\nAnders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\).\nAnders gesagt gibt \\(\\sigma\\) die â€œtypischeâ€ Abweichung einer Beobachtung vom vorhergesagten Wert an.\nEs ist nÃ¼tzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\):\n\\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\).\n\\(R2\\) gibt damit den Anteil der vom Modell erklÃ¤rten Varianz, \\(V\\), an.\nBerechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck Ã¤quivalent zu:\n\\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\)\nDie beiden obigen AusdrÃ¼cke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlÃ¤ssigen Ungewissheit; sie sind Ã¼bergewiss aus Bayes-Sicht."
  },
  {
    "objectID": "metrische-AV.html#bayes-r2",
    "href": "metrische-AV.html#bayes-r2",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.12 Bayesâ€™ \\(R^2\\)",
    "text": "10.12 Bayesâ€™ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der ModellgÃ¼te miteinzubeziehen:\n\\(\\text{Bayes }R^2 = \\frac{\\text{erkÃ¤rte Varianz}}{\\text{ErklÃ¤rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\)\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell.\nFÃ¼r jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklÃ¤rten Varianz:\n\\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\)\n\nGelman et al. (2019), Gelman, Hill, and Vehtari (2021), Kap. 11.7"
  },
  {
    "objectID": "metrische-AV.html#praktisch-kein-unterschied",
    "href": "metrische-AV.html#praktisch-kein-unterschied",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.13 â€œPraktischâ€ kein Unterschied",
    "text": "10.13 â€œPraktischâ€ kein Unterschied\n\nSagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar.\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\).\nDie Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte.\nDiesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope).\nJetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt.\nUnter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden.\n\nEntscheidungsregel:\n\nGroÃŸteil liegt innerhalb von Rope â¡ï¸ Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\nGroÃŸteil liegt auÃŸerhalb von Rope â¡ï¸ Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\nAnsonsten â¡ï¸ keine Entscheidung\n\nKruschke (2018)\n\n10.13.1 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\nKruschke (2018), Abbildung 1, S. 272\n\n\n10.13.2 Rope berechnen\n\nrope(m10.6)\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-384.4637\n384.4637\n0.0000000\nfixed\nconditional\n\n\ncutGood\n0.95\n-384.4637\n384.4637\n0.3239474\nfixed\nconditional\n\n\ncutIdeal\n0.95\n-384.4637\n384.4637\n0.0857895\nfixed\nconditional\n\n\ncutPremium\n0.95\n-384.4637\n384.4637\n0.3713158\nfixed\nconditional\n\n\ncutVery Good\n0.95\n-384.4637\n384.4637\n0.2631579\nfixed\nconditional\n\n\n\n\n\n\nAlle Faktorstufen von cut haben doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir kÃ¶nnen daher fÃ¼r keinen der Unterschiede das ROPE verwerfen.\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nNote\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n\n10.13.3 Visualisierung unserer Rope-Werte, m10.6\n\nEin GroÃŸteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut.\n\n\nrope(m10.6) %>% plot()\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung doch recht deutlich. Wir knÃ¶nen das Rope nicht verwerfen.\n\n\n10.13.4 Genaue Rope-Werte\n\nlibrary(bayestestR)\nrope(m10.6, range = c(-100, 100))\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\nrope(m10.6, range, c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht fÃ¼r ein PI.\n\nplot(rope(m10.6, range = c(-100, 100)))\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\n\n\n10.13.5 Beantwortung der Forschungsfrage\n\nNur das 95%-HDI fÃ¼r Schliffart â€œIdealâ€ schloss den Indifferenzbereich von Â±100â‚¬ aus, die Ã¼brigen Mittelwertsdifferenzen nicht. FÃ¼r die Ã¼brigen Differenzen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.\n\n\nDie 95%HDI fÃ¼r die Mittelwertsdifferenzen waren wie folgt: cutGood: [-2040, 953], cutIdeal: [-2645, -4], cutPremium: [-965, 1732], cutVeryGood: [-2102, 627]. Das Modell erklÃ¤rte im Median ca. 3% der Varianz, also nur einen kleinen Teil."
  },
  {
    "objectID": "metrische-AV.html#mehrere-metrische-uv",
    "href": "metrische-AV.html#mehrere-metrische-uv",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.14 Mehrere metrische UV",
    "text": "10.14 Mehrere metrische UV\n\n10.14.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhÃ¤ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa â€œIQ der Mutter ist die Ursache zum IQ des Kindesâ€) wird impliziert.\nEs geht rein darum, ZusammenhÃ¤nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. FÃ¼r solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nÃ¶tig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n\n10.14.2 Was heiÃŸt, X hÃ¤ngt mit Y zusammen?\n\nDer Begriff â€œZusammenhangâ€ ist nicht exakt.\nHÃ¤ufig wird er (fÃ¼r metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groÃŸ der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem â€œEffekt von X auf Yâ€ Ã¼bersetzt. Vorsicht: â€œEffektâ€ klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende BegrÃ¼ndung fÃ¼r einen Kausalzusammenhang.\n\nDer Korrelationskoeffizient\n\nmisst eine Art der StÃ¤rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehÃ¶rigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n\n10.14.3 Korrelationen zur Forschungsfrage\n\nkidiq %>% \n  correlation()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n< .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n< .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n< .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n< .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\nkidiq %>% \n  correlation() %>% \n  summary() %>% \n  plot()\n\n\n\n\n\n\n10.14.4 Univariate Regressionen\n\nm10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\ncoef(m10.7)\n\n(Intercept)      mom_iq \n  25.840357    0.610583 \n\n\n\ncoef(m10.8)\n\n(Intercept)     mom_age \n 70.8061260   0.7012694 \n\n\n\n\n10.14.5 Visualisierung der univariaten Regressionen\nm10.7\nSteigung: 0.6\n\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.7)[1],\n              slope = coef(m10.7)[2],\n              color = \"blue\")\n\n\n\n\nm10.8\nSteigung: 0.7\n\nkidiq %>% \n  ggplot(aes(x = mom_age, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.8)[1],\n              slope = coef(m10.8)[2],\n              color = \"blue\")\n\n\n\n\n\n\n10.14.6 Multiples Modell (beide PrÃ¤diktoren), m10.9\n\nm10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n\n(Intercept)      mom_iq     mom_age \n 17.6886001   0.6031288   0.3932556 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils â€œbereinigtâ€ vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines PrÃ¤diktors mit der AV, wobei man gleichzeitig den anderen PrÃ¤diktor konstant hÃ¤lt.\n\n\ncoef(m10.9)\n\n(Intercept)      mom_iq     mom_age \n 17.6886001   0.6031288   0.3932556 \n\n\n\n\n10.14.7 3D-Visualisierung eines Modells mit zwei PrÃ¤diktoren 1\n\n\n\n\n\n\n\n\n10.14.8 Visualisierung mit Farbe statt 3. Dimension\n\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der FarbÃ¤nderung) die VerÃ¤nderung fÃ¼r die AV (kid_score). Auf der Achse fÃ¼r mom_age sieht man, dass sich die AV kaum Ã¤ndert, wenn sich mom_age Ã¤ndert.\n\n\n10.14.9 Visualisierung in 10 Dimensionen\n\nggplot(data.frame(x=NA, y=NA)) +\n  theme(panel.background = element_rect(fill = 'lightblue'))\n\n\n\n\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere SchwÃ¤chen, eine groÃŸe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine einfache Zusammenfassung eines (ggf. hochdimensionalen) Variablenraumes.\n\n\n10.14.10 Relevanz der PrÃ¤diktoren\n\nWelcher PrÃ¤diktor ist nun â€œwichtigerâ€ oder â€œstÃ¤rkerâ€ in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age?\nmom_iq hat den grÃ¶ÃŸeren Koeffizienten.\nmom_age hat weniger Streuung.\nUm die Relevanz der PrÃ¤diktoren vergleichen zu kÃ¶nnen, mÃ¼sste man vielleicht die VerÃ¤nderung von kid_score betrachten, wenn man von kleinsten zum grÃ¶ÃŸten PrÃ¤diktorwert geht.\nAllerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden).\nSinnvoller ist es daher, die VerÃ¤nderung in der AV zu betrachten, wenn man den PrÃ¤diktor von â€œunterdurchschittlichâ€ auf â€œÃ¼berdurchschnittlichâ€ Ã¤ndert.\nDas kann man mit z-Standardisierung erreichen.\n\n\n\n10.14.11 z-Standardisierung\n\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie Ã¼ber einen Mittelwert von 0 und eine SD von 1 verfÃ¼gt:\n\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\ndata(\"kidiq\")\nkidiq2 <- \n  kidiq %>% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% \n  select(mom_iq, mom_iq_z) %>% \n  head()\n\n\n\n10.14.12 Statistiken zu den z-transformierten Variablen\n\n\n\n\n\n\n  \n  \n    \n      variable\n      n\n      mean\n      sd\n    \n  \n  \n    kid_score\n434\n86.797\n20.411\n    mom_age\n434\n22.786\n2.701\n    mom_hs\n434\n0.786\n0.411\n    mom_iq\n434\n100.000\n15.000\n  \n  \n  \n\n\n\n\n So kann man auch die z-Transformation (â€œSkalierungâ€) durchfÃ¼hren:\n\nkidiq <- \n  standardize(kidiq, append = TRUE)\n\nhead(kidiq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafÃ¼r, dass die ursprÃ¼nglichen Variablen beim Z-Standardisieren nicht Ã¼berschrieben werden, sondern angehÃ¤ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen standardisieren\n\nkidiq %>% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket:\n\n#data(kidiq)\nkidiq %>% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score)) %>% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_z2\nmom_age_z2\nkid_score_z2\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n1.4078352\n1.5602285\n-1.06793237\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n-0.7092079\n0.8197811\n0.54886757\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n1.0295443\n1.5602285\n-0.08805362\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n-0.0366907\n0.8197811\n-0.18604150\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n-0.4836193\n1.5602285\n1.38176451\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n0.5267892\n-1.7717849\n0.54886757\n\n\n\n\n\n\n\n\n10.14.13 Modell mit standardisierten PrÃ¤diktoren, m10.10\nDas Standardisieren der AV, kid_score ist nicht nÃ¶tig, um den Effekt der PrÃ¤diktoren (UV) auf die AV zu untersuchen. Standardisiert man die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darÃ¼ber, um wie viele SD-Einheiten sich die AV verÃ¤ndert, wenn sich ein PrÃ¤diktor um eine SD-Einheit verÃ¤ndert.\n\nm10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, data = kidiq, refresh = 0)\ncoef(m10.10)\n\n (Intercept)     mom_iq_z    mom_age_z \n0.0004107225 0.4430261801 0.0516987335 \n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient fÃ¼r mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_iq um eine SD-Einheit Ã¤ndert.\nDer Koeffizient fÃ¼r mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_age um eine SD-Einheit Ã¤ndert.\n\nJetzt sind die PrÃ¤diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n\n10.14.14 95%-PI\n\nparameters(m10.10) \n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4.11e-04\n(-0.08, 0.08)\n50.40%\n100%\n1.000\n4998.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0%\n1.000\n5035.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.55%\n89.05%\n1.001\n5165.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nplot(hdi(m10.10))\n\n\n\n\n\n\n10.14.15 Was ist ein kleiner, was ein groÃŸer Effekt?\n\nCohen (1988) definiert EffektstÃ¤rken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\).\nFÃ¼r kleine, mittlere und groÃŸe Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\nmittel: \\(d \\approx 0.5\\)\ngroÃŸ: \\(d \\approx 0.8\\)\n\nAuf dieser Basis schlÃ¤gt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor.\nFÃ¤llt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als â€œpraktisch nullâ€.\nRichtlinien fÃ¼r EffektstÃ¤rken sind nur NotlÃ¶sungen, die durch Sachverstand ersetzt werden sollen, wo immer mÃ¶glich.\nMan kann EffektstÃ¤rken ineinander Ã¼berfÃ¼hren, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n\n\n10.14.16 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\n\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat.\nEin vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\).\nDer â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\).\nResultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar.\nDas impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n\n\n10.14.17 Verwandtheit von Korrelation und Regression\n\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\n\\[b = r \\frac{sd_x}{sd_y}\\]\n\nm10.11 <- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq, refresh = 0)\ncoef(m10.11)\n\n (Intercept)     mom_iq_z \n-0.000102025  0.449942456 \n\n\n\nkidiq %>% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nkid_score\nmom_iq\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nkid_score\nkid_score_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nkid_score_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nmom_iq_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score_z\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\n\n\n\n\n\n\n10.14.18 ModellgÃ¼te\n\nr2(m10.10)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.204 (95% CI [0.142, 0.268])\n\n\nIst dieser Wert von \\(R2\\) â€œgutâ€? Diese Frage ist Ã¤hnlich zur Frage â€œIst das viel Geld?â€; man kann die Frage nur im Kontext beantworten.\nEine einfache LÃ¶sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklÃ¤rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufÃ¤llig hohen Werten der ModellgÃ¼te im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine â€œobjektiveâ€ Antwort auf die Frage â€œwie viel ist viel?â€ haben wollen, ziehen wir Herrn Cohen zu Rate:\n\ninterpret_r2(0.2)  # aus `easystats`\n\n[1] \"moderate\"\n(Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n\n10.14.19 Priori-Verteilung fÃ¼r m10.10 und Modelldefinition\n\nprior_summary(m10.10)  # aus rstanarm\n\nPriors for model 'm10.10' \n------\nIntercept (after predictors centered)\n ~ normal(location = -2.8e-16, scale = 2.5)\n\nCoefficients\n ~ normal(location = [0,0], scale = [2.5,2.5])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\\[\\begin{align}\n\\text{kid_score} &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{mom_iq}_i + \\beta_2\\text{mom_age}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{align}\\]\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzufÃ¼hren.\n\n\n10.14.20 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar fÃ¼r einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkÃ¤rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al. 2022) zurÃ¼ck (s. Anhang fÃ¼r Details).\n\nHier wird von einem â€œstatistischen Effektâ€ gesprochen, um klar zu machen, dass es sich lediglich um assoziative ZusammenhÃ¤nge, und nicht um kausale ZusammenhÃ¤nge, handelt. Kausale ZusammenhÃ¤nge dÃ¼rfen wir nur verkÃ¼nden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafÃ¼r finden oder c) wir ein Experiment fachgerecht durchgefÃ¼hrt haben."
  },
  {
    "objectID": "metrische-AV.html#vertiefung",
    "href": "metrische-AV.html#vertiefung",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.15 Vertiefung",
    "text": "10.15 Vertiefung\nğŸï¸VERTIEFUNGğŸï¸\n\n10.15.1 PrÃ¼fen der LinearitÃ¤tsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen PrÃ¤diktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression hÃ¤ufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schÃ¤tzen (Gelman, Hill, and Vehtari 2021).\nIst die LinearitÃ¤tsannahme erfÃ¼llt, so sollte der Residualplot nur zufÃ¤llige Streuung um \\(y=0\\) herum zeigen.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsÃ¤chlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\nkidiq <-\n  kidiq %>% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\nkidiq %>% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nHier erkennt man keine grÃ¶ÃŸeren AuffÃ¤lligkeiten.\n\n\n10.15.2 ModellprÃ¼fung mit der PPV\n\npp_check(m10.10)\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht hÃ¤ufig.\n\n\n10.15.3 Visualisierung der bereinigten Regressionskoeffizienten\n\nset.seed(42)\ndata(kidiq)\nkidiq3 <- \n  kidiq %>% \n  standardize(append = TRUE) %>% \n  sample_n(size = 300)\n\n#| results: \"hide\"\nm10.10a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)\nm10.10b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(mom_age_resid = resid(m10.10a)) %>% \n  mutate(mom_iq_resid = resid(m10.10b))\n\n\nm10.10c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)\nm10.10d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)\n\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(m10.10c_resid = resid(m10.10c)) %>% \n  mutate(m10.10d_resid = resid(m10.10d))\n\n\n\n\n\n#(m10.10a_plot + m10.10b_plot) / (m10.10c_plot + m10.10d_plot)\nplots(m10.10a_plot, m10.10b_plot, m10.10c_plot, m10.10d_plot, n_rows = 2, tags = \"A\",\n      guides = \"collect\")\n\nWarning: Removed 7 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 7 rows containing missing values (`geom_segment()`).\n\n\nWarning: Removed 11 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 11 rows containing missing values (`geom_segment()`).\n\n\nWarning: Removed 16 rows containing missing values (`geom_point()`).\nRemoved 16 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDie vertikalen Balken zeigen die Residuen.\n\nObere Reihe: Regression eines PrÃ¤diktors auf den anderen PrÃ¤diktor.\nUntere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z.\nUnten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang.\nUnten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\n\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4.11e-04\n(-0.08, 0.08)\n50.40%\n100%\n1.000\n4998.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0%\n1.000\n5035.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.55%\n89.05%\n1.001\n5165.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\n\n10.15.4 Bereinigte Regressionskoeffizienten fÃ¼r mtcars\n\nmtcars2 <-\n  mtcars %>% \n  standardize()\n\nm12a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)\nm12b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)\n\nmtcars2 <-\n  mtcars %>% \n  mutate(m12a_resid = resid(m12a)) %>% \n  mutate(m12b_resid = resid(m12b))\n\n\nm12c <- stan_glm(mpg ~ m12a_resid, data = mtcars2, refresh = 0, chains = 1)\nm12d <- stan_glm(mpg ~ m12b_resid, data = mtcars2, refresh = 0, chains = 1)\n\n\nmtcars2 <-\n  mtcars2 %>% \n  mutate(m12c_resid = resid(m12c)) %>% \n  mutate(m12d_resid = resid(m12d))\n\n\n\n\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nÃœbrigens liefern stan_glm() und lm oft Ã¤hnliche Parameterwerte (bei schwach informativen Prioriwerten):\n\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()\n\n(Intercept)          hp         cyl \n36.84877039 -0.01934222 -2.26124451 \n\n\n\nlm(mpg ~ hp + cyl, data = mtcars) %>% coef()\n\n(Intercept)          hp         cyl \n 36.9083305  -0.0191217  -2.2646936 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWenn auch die Parameterwerte eines Frequentistischen und Bayes-Modell numerisch Ã¤hnlich sein kÃ¶nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht."
  },
  {
    "objectID": "metrische-AV.html#ausblick-binÃ¤re-av",
    "href": "metrische-AV.html#ausblick-binÃ¤re-av",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.16 Ausblick: BinÃ¤re AV",
    "text": "10.16 Ausblick: BinÃ¤re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\n\ndata(mtcars)\nmtcars2 <-\n  mtcars %>% \n  standardize(append = TRUE)\n\n\nm13 <-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n\n(Intercept)       mpg_z \n  0.4060587   0.2975638 \n\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nmtcars2 %>% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\nneg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))\n\nFÃ¼r kleine Werte von mpg_z (<1.3) sagt unser Modell negative Werte fÃ¼r am voraus. Das macht keinen Sinn. MÃ¼ssen wir mal bei Gelegenheit besser machen."
  },
  {
    "objectID": "metrische-AV.html#wir-waren-fleiÃŸig",
    "href": "metrische-AV.html#wir-waren-fleiÃŸig",
    "title": "10Â  Forschungsfragen mit metrischer AV",
    "section": "10.17 Wir waren fleiÃŸig",
    "text": "10.17 Wir waren fleiÃŸig\n\nknitr::include_graphics(\"https://media.giphy.com/media/XIqCQx02E1U9W/giphy.gif\")\n\n\n\n\nQuelle\nGenug fÃ¼r heute ğŸ‘\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja, Sitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and Daniel M. Croymans. 2021. â€œBehavioural Nudges Increase COVID-19 Vaccinations.â€ Nature 597 (7876): 404â€“9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. â€œR-Squared for Bayesian Regression Models.â€ The American Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022. â€œRstanarm: Bayesian Applied Regression Modeling via Stan.â€ https://mc-stan.org/rstanarm/.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter Values in Bayesian Estimation.â€ Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B. Gubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021. â€œEffectiveness of mRNA and ChAdOx1 COVID-19 Vaccines Against Symptomatic SARS-CoV-2 Infection and Severe Outcomes with Variants of Concern in Ontario.â€ https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi, Mohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner. 2021. â€œEfficacy and Safety of COVID-19 Vaccines: A Systematic Review and Meta-Analysis of Randomized Clinical Trials.â€ Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball, Allison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021. â€œEffectiveness of Covid-19 Vaccines in Ambulatory and Inpatient Care Settings.â€ New England Journal of Medicine 385 (15): 1355â€“71. https://doi.org/10.1056/NEJMoa2110362."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja,\nSitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and\nDaniel M. Croymans. 2021. â€œBehavioural Nudges Increase\nCOVID-19 Vaccinations.â€ Nature 597 (7876):\n404â€“9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\nâ€œR-Squared for Bayesian Regression Models.â€ The\nAmerican Statistician 73 (3): 307â€“9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022.\nâ€œRstanarm: Bayesian Applied Regression Modeling via\nStan.â€ https://mc-stan.org/rstanarm/.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter Values\nin Bayesian Estimation.â€ Advances in Methods and Practices in\nPsychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B.\nGubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021.\nâ€œEffectiveness of mRNA and\nChAdOx1 COVID-19 Vaccines Against Symptomatic\nSARS-CoV-2 Infection and Severe Outcomes with\nVariants of Concern in Ontario.â€ https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi,\nMohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner.\n2021. â€œEfficacy and Safety of COVID-19 Vaccines: A\nSystematic Review and Meta-Analysis of Randomized Clinical\nTrials.â€ Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball,\nAllison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021.\nâ€œEffectiveness of Covid-19 Vaccines in Ambulatory and Inpatient\nCare Settings.â€ New England Journal of Medicine 385\n(15): 1355â€“71. https://doi.org/10.1056/NEJMoa2110362."
  }
]