[
  {
    "objectID": "0400-Verteilungen.html#lernsteuerung",
    "href": "0400-Verteilungen.html#lernsteuerung",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nden Begriff der Zufallsvariablen erlÃ¤utern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erlÃ¤utern\nden Begriff einer Gleichverteilung erlÃ¤utern\ndie Parameter einer Normalverteilung nennen und erlÃ¤utern\nzentrale Konzepte in R umsetzen\n\n5.1.2 Vorbereitung im Eigenstudium\nLesen Sie selbstÃ¤ndig, zusÃ¤tzlich zum Stoff dieses Kapitels noch Bourier (2018); dort folgende Abschnitte:\n\nKap. 6.1 (Zum Begriff Zufallsvariable)\nKap. 6.3 (Stetige Zufallsvariablen)\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung)\nKap. 7.2.3 (Normalverteilung)\n\nLÃ¶sen Sie auch die Ãœbungsaufgaben dazu.\nWeitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n5.1.3 PrÃ¼fungsrelevanter Stoff\nBeachten Sie, dass neben den Inhalten des Kapitels auch stets der vorzubereitende Stoff prÃ¼fungsrelevant ist.\n\n5.1.4 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\n\n\n5.1.5 Zentrale Begriffe\n\n5.1.5.1 Eigenschaften von Zufallsvariablen\n\nZufallsvariable (random variable)\nDiskret vs.Â stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n5.1.5.2 Verteilungen\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n5.1.6 Begleitvideos\n\nVideo 1 zum Thema Verteilungen\nVideo 2 zum Thema Verteilungen"
  },
  {
    "objectID": "0400-Verteilungen.html#zufallsvariable",
    "href": "0400-Verteilungen.html#zufallsvariable",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.2 Zufallsvariable",
    "text": "5.2 Zufallsvariable\n\nBeispiel 5.1 Schorsch sucht eine Betreuerin fÃ¼r seine Abschlussarbeit. An die ideale Betreuerin setzt er 4 Kriterien an: a) klare, schriftliche fixierte Rahmenbedingungen, b) viel Erfahrung, c) guten Ruf und d) interessante Forschungsinteressen. Je mehr dieser 4 Kriterien erfÃ¼llt sind, desto besser. Schorsch geht davon aus, dass die 4 Kriterien voneinander unabhÃ¤ngig sind (ob eines erfÃ¼llt ist oder nicht, Ã¤ndert nichts an der Wahrscheinlichkeit eines anderen Kriteriums). Schorsch interessiert sich also fÃ¼r die Anzahl der erfÃ¼llten Kriterien, also eine Zahl von 0 bis 4. Er schÃ¤tzt die Wahrscheinlichkeit fÃ¼r einen â€œTrefferâ€ in jedem seiner 4 Kriterien auf 50%. Viel GlÃ¼ck, Schorsch! Sein Zufallsexperiment hat 16 AusgÃ¤nge, s. AbbildungÂ 5.1 und TabelleÂ 5.1. Ganz schÃ¶n komplex. Eigentlich wÃ¼rden ihm ja eine Darstellung mit 5 Ergebnissen, also der â€œGutachter-Scoreâ€ von 0 bis 4 ja reichen. Wie kÃ¶nnen wir es Ã¼bersichtlicher fÃ¼r Schorsch?\\(\\square\\)\n\n\n\n\n\nAbbildungÂ 5.1: Ein Baumdiagramm mit 16 AusgÃ¤ngen, analog zur 4 MÃ¼nzwÃ¼rfen\n\n\n\n\n\n\n\nTabelleÂ 5.1: Schorschs Zufallsexperiment, Auszug der Elementarereignisse\n\ni\nElementarereignis\nPr(EE)\nTrefferzahl\nPr(Trefferzahl)\n\n\n\n1\nNNNN\n1/16\n0\n1/16\n\n\n2\nNNNT\n1/16\n1\n1/4\n\n\n3\nNNTN\n1/16\n1\n1/4\n\n\n4\nNTNN\n1/16\n1\n1/4\n\n\n5\nTNNN\n1/16\n1\n1/4\n\n\n6\nNNTT\n1/16\n2\nâ€¦\n\n\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\n\n\n\n\n\n\nSchorsch braucht also eine Ã¼bersichtlichere Darstellung; die Zahl der Treffer und ihre Wahrscheinlichkeit wÃ¼rde ihm ganz reichen. In vielen Situationen ist man an der Anzahl der Treffer interessiert. Die Wahrscheinlichkeit fÃ¼r eine bestimmte Trefferanzahl bekommt man einfach durch Addieren der Wahrscheinlichkeiten der zugehÃ¶rigen Elementarereignisse, s. TabelleÂ 5.1. Hier kommt die Zufallsvariable ins Spiel. Wir nutzen sie, um die Anzahl der Treffer in einem Zufallsexperiment zu zÃ¤hlen.\n\nDefinition 5.1 (Zufallsvariable) Die Zuordnung der Elementarereignisse eines Zufallsexperiment zu genau einer Zahl \\(\\in \\mathbb{R}\\) nennt man Zufallsvariable.\\(\\square\\)\n\nDie den Elementarereignisse zugewiesenen Zahlen nennt man Realisationen oder AusprÃ¤gungen der Zufallsvariablen\n\nBeispiel 5.2 (Lotto) Ein Lottospiel hat ca. 14 Miollionen Elementarereignisse. Die Zufallsvariable â€œAnzahl der Trefferâ€ hat nur 7 Realisationen: 0,1,â€¦,6.\\(\\square\\)\n\nEs hat sich eingebÃ¼rgert, Zufallszahlen mit \\(X\\) zu bezeichnen (oder anderen Buchstaben weit hinten aus dem Alphabet).\nMan schreibt kurz: \\(X: \\Omega \\rightarrow \\mathbb{R}\\). Um die Vorschrift der Zuordnung genauer zu bestimmen, kann man folgende Kurzschreibweise nutzen:\n\\({\\displaystyle X(\\omega )={\\begin{cases}1,&{\\text{wenn }}\\omega ={\\text{Kopf}},\\\\[6pt]0,&{\\text{wenn }}\\omega ={\\text{Zahl}}.\\end{cases}}}\\)\nAbbildungÂ 5.2 stellt diese Abbildung dar.\n\n\n\n\nflowchart LR\n  subgraph A[Ereignisraum]\n    Kopf\n    Zahl\n  end\n  subgraph B[Zufallsvariable]\n    null[0]\n    eins[1]\n  end\n  subgraph C[Wahrscheinlichkeit]\n    half[50%]\n  end\n  \n  Kopf --&gt; null\n  Zahl --&gt; eins\n  null --&gt; half\n  eins --&gt; half\n\n\nAbbildungÂ 5.2: Eine Zufallsvariable ist eine Abbildung vom Ereignisraum zu den Realisationen der Zufallsvariable. AuÃŸerdem sieht man, wie Zufallsvariablen genutzt werden, um Wahrsscheinlichkeiten zu bestimmen.\n\n\n\nZufallsverteilungen kann im zwei Artein einteilen:\n\ndiskrete Zufallsvariablen\nstetige Zufallsvariablen\n\n\n5.2.1 Diskrete Zufallsvariable\n\n5.2.1.1 Grundlagen\nEine diskrete Zufallsvariable ist dadurch gekennzeichnet, dass nur bestimmte Realisationen mÃ¶glich sind, zumeist natÃ¼rliche Zahlen, wie 0, 1, 2,â€¦, . AbbildungÂ 5.3 versinnbildlicht die Zufallsvariable des â€œGutachter-Scoresâ€, s. BeispielÂ 5.1.\n\n\n\n\nAbbildungÂ 5.3: Sinnbild einer diskreten Zufallsvariablen X fÃ¼r Schorschs Suche nach einer Betreuerin seiner Abschlussarbeit. X gibt den Score der Gutachterin wider.\n\n\n\n\nBeispiel 5.3 (Diskrete Zufallsvariablen) Â \n\nAnzahl der Bewerbungen bis zum ersten Job-Interview\nAnzahl AnlÃ¤ufe bis zum Bestehen der Statistik-Klausur\nAnzahl der Absolventen an der HS Ansbach pro Jahr\nAnzahl Treffer beim Kauf von Losen\nAnzahl BetriebsunfÃ¤lle\nAnzahl der Produkte in der Produktpalette\\(\\square\\)\n\n\n\n\nBeispiel 5.4 Der zweifache WÃ¼rfelwurf ist ein typisches Lehrbuchbeispiel fÃ¼r eine diskrete Zufallsvariable.1 Hier ist \\(S\\)2 die Augensumme des zweifachen WÃ¼rfelwurfs und \\(S\\) ist eine Zahl zwischen 2 und 12. FÃ¼r jede Realisation \\(X=x\\) kann die Wahrscheinlichkeit berechnen, AbbildungÂ 5.4 versinnbildlicht die Wahrscheinlichkeit fÃ¼r jede Realisation von \\(X\\).\\(\\square\\)\n\n\n\nAbbildungÂ 5.4: Augensumme des zweifachen WÃ¼rfelwurfs; fÃ¼r jede Realisation von S ist die zugehÃ¶rige Wahrscheinlichkeit dargestellt. Bildquelle: Tim Stellmach, Wikipedia, PD\n\nWahrscheinlichkeitsverteilungen dienen dazu, den Realisationen einer Zufallsvariable eine Wahrscheinlichkeit zuzuordnen.\n\nDefinition 5.2 (Diskrete Wahrscheinlichkeitsverteilung) Eine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) AusprÃ¤gungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu.\\(\\square\\)\n\n\nBeispiel 5.5 (Wahrscheinlichkeit des Geschlechts bei der Geburt) So hat die Variable Geschlecht eines Babies die beiden AusprÃ¤gungen MÃ¤dchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\), laut einer Studie (Gelman, Hill, und Vehtari 2021).\\(\\square\\)\n\nZwischen der deskriptiven Statistik und der Wahrscheinlichkeitstheorie bestehen enge Parallelen, TabelleÂ 5.2 stellt einige zentrale Konzepte gegenÃ¼ber.\n\n\n\n\n TabelleÂ 5.2:  GegenÃ¼berstellung von Wahrscheinlichkeitstheorie und deskriptiver\nStatistik \n  \n\n\n\n\nEine Verteilung zeigt, welche AusprÃ¤gungen eine Variable aufweist und wie hÃ¤ufig bzw. wahrscheinlich diese sind. Einfach gesprochen veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet HÃ¤ufigkeitsverteilungen (s. Abb. AbbildungÂ 5.6) von Wahrscheinlichkeitsverteilungen (Abb. AbbildungÂ 5.5).\n\n\n\n\n\n\nAbbildungÂ 5.5: Wahrscheinlichkeiten des zweifachen WÃ¼rfelwurfs\n\n\n\n\n\n\n\n\nAbbildungÂ 5.6: (relative und absolute) HÃ¤ufigkeiten des zweifachen WÃ¼rfelwurfs, 1000 Mal wiederholt\n\n\n\n\n\n\nBeispiel 5.6 (Wahrscheinlichkeitsfunktion eines WÃ¼rfels) AbbildungÂ 5.7 zeigt die Wahrscheinlichkeitsfunktion eines einfachen WÃ¼rfelwurfs.\\(\\square\\)\n\n\n\nAbbildungÂ 5.7: Wahrscheinlichkeitsfunktion eines einfachen WÃ¼rfelwurfs, Bildrechte: Olex Alexandrov, Wikipedia, PD\n\n\n\nDie HÃ¤ufigkeitsverteilung eines diskreten Merkmals \\(X\\) mit \\(k\\) AusprÃ¤gungen zeigt (vgl.@ tbl-hauef), wie hÃ¤ufig die einzelnen AusprÃ¤gungen sind. So hat die Variable Zylinder (in einem Datensatz) etwa die AusprÃ¤gungen 4,6 und 8.\\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.8: HÃ¤ufigkeitsverteilung von cyl und hp (diskretisiert in 10 KÃ¶rbe oder Gruppen)\n\n\n\n\n\n\n\n\n TabelleÂ 5.3:  Eine diskrete HÃ¤ufigkeitsverteilung, dargestellt in einer\nHÃ¤ufigkeitstabelle \n  \n\n\n\n\n\n\nAbb. AbbildungÂ 5.8, links, visualisiert die HÃ¤ufigkeitsverteilung von cyl. Ein stetiges Merkmal, wie hp (PS-Zahl), lÃ¤sst sich durch Klassenbildung in ein diskretes umwandeln (diskretisieren), s. Abb. AbbildungÂ 5.8, rechts.\n\n5.2.1.2 Wahrscheinlichkeitsfunktion\n\nDefinition 5.3 (Wahrscheinlichkeitsfunktion) Die Funktion \\(f\\), die den mÃ¶glichen Realisationen \\(x_i\\) der diskreten Zufallsvariablen \\(X\\) die Eintrittswahrscheinlichkeiten zuordnet, heiÃŸt Wahrscheinlichkeitsfunktion.\\(\\square\\)\n\n\nBeispiel 5.7 Die Wahrscheinlichkeitsfunktion fÃ¼r \\(X\\) â€œAugensumme im zweifachen WÃ¼rfelwurfâ€ ist in AbbildungÂ 5.5 visualisiert.\\(\\square\\)\n\n\nBeispiel 5.8 Die Wahrscheinlichkeitsfunktion fÃ¼r \\(X\\) â€œTreffer im einfachen MÃ¼nzwurf, mit Zahl ist Trefferâ€ ist \\(Pr(X=1)=1/2.\\), vgl. AbbildungÂ 5.2.\\(\\square\\)\n\n\n5.2.1.3 Verteilungsfunktion\n\nDefinition 5.4 (Verteilungsfunktion) Die Verteilungsfunktion \\(F\\) gibt die Wahrscheinlichkeit an, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich \\(x\\) ist.\\(\\square\\)\n\nDie Berechnung von \\(F(x)\\) erfolgt, indem die Wahrscheinlichkeiten aller mÃ¶glichen Realisationen \\(x_i\\), die kleiner oder gleich dem vorgegebenen Realisationswert \\(x\\) sind, addiert werden:\n\\(F(x) = \\sum_{x_ \\le x} Pr(X=x_i).\\)\nDie Verteilungsfunktion ist das Pendant zur kumulierten HÃ¤ufigkeitsverteilung, vgl. AbbildungÂ 5.9 und AbbildungÂ 5.10.\n\n\n\n\n\n\nAbbildungÂ 5.9: Kumulierte HÃ¤ufigkeitsverteilung, d.h. die Verteilungsfunktion \\(F(X \\le x_i)\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 5.10: Empirische Verteilungsfunktion (kumulierte HÃ¤ufigkeitsverteilung) \\(F(X \\le x_i)\\) von 1000 zweifachen MÃ¼nzwÃ¼rfen\n\n\n\n\n\n\n5.2.2 Stetige Zufallsvariablen\nAbbildungÂ 5.11 versinnbildlicht die stetige Zufallsvariable â€œKÃ¶rpergrÃ¶ÃŸeâ€, die (theoretisch, in AnnÃ¤herung) jeden beliebigen Wert zwischen 0 und (vielleicht) 3m annehmen kann.\n\n\n\n\nAbbildungÂ 5.11: Sinnbild fÃ¼r eine stetige Zufallsvariable X â€œKÃ¶rpergrÃ¶ÃŸeâ€\n\n\n\n\nDefinition 5.5 (Stetige Zufallsvariable) Eine stetige Zufallsvariable gleicht einer diskreten, nur dass alle Werte im Intervall erlaubt sind.\\(\\square\\)\n\n\nBeispiel 5.9 Â \n\nSpritverbrauch\nKÃ¶rpergewicht von Professoren\nSchnabellÃ¤ngen von Pinguinen\nGeschwindigkeit beim Geblitztwerden\\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 5.1 (Warten auf den Bus, 42 Sekunden) Sie stehen an der Bushaltestellen und warten auf den Bus. Langweilig. Da kommt Ihnen ein Gedanken in den Sinn: Wie hoch ist wohl die Wahrscheinlichkeit, dass Sie exakt 42 Sekunden auf den Bus warten mÃ¼ssen, s. AbbildungÂ 5.13? Weiterhin Ã¼berlegen Sie, dass davon auszugehen ist, dass jede Wartezeit zwischen 0 und 10 Minuten gleich wahrscheinlich ist. SpÃ¤testens nach 10 Minuten kommt der Bus, so ist die Taktung (extrem zuverlÃ¤ssig). Exakt heiÃŸt exakt, also nicht 42.1s, nicht 42.01s, nicht 42.001s, etc. bis zur x-ten Dezimale.\\(\\square\\)\n\nNicht so einfach (?). Hingegen ist die Frage, wie hoch die Wahrscheinlichkeit ist, zwischen 0 und 5 Minuten auf den Bus zu warten (\\(0&lt;x&lt;5\\)), einfach: Sie betrÃ¤gt 50%, wie man in AbbildungÂ 5.12 gut sehen kann.\n\n\n\n\nAbbildungÂ 5.12: Wie groÃŸ ist die Wahrscheinlichkeit, zwischen 0 und 5 Minuten auf den Bus zu warten? 50 Prozent!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.13: Wie groÃŸ ist die Wahrscheinlichkeit, genau 42 Sekunden auf den Bus zu warten? Hm.\n\n\n\n\n\nVergleicht man AbbildungÂ 5.13 und AbbildungÂ 5.12 kommt man (vielleicht) zu dem Schluss, dass die Wahrscheinlichkeit exakt 42s auf den Bus zu warten, praktisch Null ist. Der Grund ist, dass die FlÃ¤che des Intervalls gegen Null geht, wenn das Intervall immer schmÃ¤ler wird. Aus diesem Grund kann man bei stetigen Zufallszahlen nicht von einer Wahrscheinlichkeit eines bestimmten Punktes \\(X=x\\) sprechen. FÃ¼r einen bestimmten Punkt \\(X=x\\) kann man aber die Dichte der Wahrscheinlichkeit angeben.\nWas gleich ist in beiden Situationen (\\(Pr(X=.42)\\) und \\(Pr(0&lt;x&lt;0.5)\\)) ist die Wahrscheinlichkeitsdichte, \\(f\\). In AbbildungÂ 5.13 und AbbildungÂ 5.12 ist die Wahrscheinlichkeitsdichte gleich, \\(f=1/10=0.1\\).\n\nDefinition 5.6 (Wahrscheinlichkeitsdichte) Die Wahrscheinlichkeitsdichte \\(f(x)\\) gibt an, wie viel Wahrscheinlichkeitsmasse pro Einheit von \\(X\\) an an der Stelle \\(x\\) ist.\\(\\square\\)\n\nDie Wahrscheinlichkeitsdichte zeigt an, an welchen Stellen \\(x\\) die Wahrscheinlichkeit besonders â€œgeballtâ€ oder â€œdichtâ€ sind, s. AbbildungÂ 5.14.\n\n\nAbbildungÂ 5.14: Die Wahrscheinlichkeit, dass eine Zufallsvariable einen Wert zwischen und annimmt, entspricht dem Inhalt der FlÃ¤che unter dem Graph der Wahrscheinlichkeitsdichtefunktion. Bildrechte: 4C, Wikipedia, CC-BY-SA .\n\n\n5.2.3 Verteilungsfunktion\n\n\n\nDefinition 5.7 Die Verteilungsfunktion einer stetigen Zufallsvariablen gibt wie im diskreten Fall an, wie groÃŸ die Wahrscheinlichkeit fÃ¼r eine Realisation kleiner oder gleich einem vorgegebenen Realisationswert \\(x\\) ist.\\(\\square\\)\nDie Verteilungsfunktion \\(F(x)\\) ist analog zur kumulierten HÃ¤ufigkeitsverteilung zu verstehen, vgl. AbbildungÂ 5.15.\n\n\n\n\n\n\nAbbildungÂ 5.15: Verteilungsfunktion F fÃ¼r X=â€œWartezeit auf den Busâ€\n\n\n\n\n\n\nDefinition 5.8 (Stetige Wahrscheinlichkeitsverteilung) Bei stetigen Zufallsvariablen \\(X\\) geht man von unendlich vielen AusprÃ¤gungen aus; die Wahrscheinlichkeit einer bestimmten AusprÃ¤gung ist (praktisch) Null: \\(p(X=x_j)=0, \\quad j=1,...,+\\infty \\square\\).\n\n\nBeispiel 5.10 (Wahrscheinlichkeitsverteilung fÃ¼r die KÃ¶rpergrÃ¶ÃŸe) So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666â€¦ cm groÃŸ ist, (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\).\\(\\square\\)"
  },
  {
    "objectID": "0400-Verteilungen.html#wichtige-verteilngen",
    "href": "0400-Verteilungen.html#wichtige-verteilngen",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.3 Wichtige Verteilngen",
    "text": "5.3 Wichtige Verteilngen\n\n5.3.1 Gleichverteilung\n\n5.3.1.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jeder Wert im Ergebnisraum der zugehÃ¶rigen Zufallsvariable gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine Realisation einer Zufallsvariablen fÃ¼r plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. AbbildungÂ 5.16 zeigt ein Beispiel fÃ¼r eine (stetige) Gleichverteilung.\n\n\n\n\n\n(a) Beispiel a: Gleichverteilung min=-1, max=1. Dichte: 1/2\n\n\n\n\n\n(b) Beispiel b: Gleichverteilung min=0, max=3. Dichte: 1/3\n\n\n\nAbbildungÂ 5.16: Stetige Gleichverteilung; man beachte jeweils die Y-Achse\n\n\nAbbildungÂ 5.16, links: Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 50%, da der Bereich \\([-0.5, +0.5]\\) die HÃ¤lfte (50%) der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte gleich. AbbildungÂ 5.16, rechts: Bei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von ca. 33%, da der Bereich \\([-0.5, +0.5]\\) ein Drittel der Wahrscheinlichkeitsmasse der Verteilung beinhaltet. Bei jedem anderen Punkt \\(x\\) ist die Dichte gleich. Definierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.\n\n5.3.1.2 Simulation\nMÃ¶chte man die Verteilungsfunktion einer stetigen Zufallsvariablen berechnen, kann die Mathe ganz schÃ¶n kompliziert werden, schlieÃŸlich muss man Integrale lÃ¶sen. Aber es gibt einen Trick, wie man die Sache stark vereinfachen kann: man simuliert die Verteilung. Was bedeutet das?\nAngenommen, die Wartezeit auf einen Bus ist gleichverteilt (engl. uniform distribution); der Bus kommt regelmÃ¤ÃŸig und pÃ¼nktlich alle 10 Minuten. Die minimale Wartezeit betrÃ¤gt also 0 Minuten und die maximale 10 Minuten. Nennen wir die zugehÃ¶rige Zufallsvariable \\(X\\), das ist schÃ¶n kurz zu schreiben.\nDann schreibt man auch:\n\\[X \\sim Unif(0,10).\\]\nJa, das sieht fancy aus, ist aber dafÃ¼r schÃ¶n kurz, aber wo ist der versprochene Trick zum Vereinfachen? Kommt gleich, Moment.\nEine Frage kÃ¶nnte nun lauten, wie groÃŸ ist die Wahrscheinlichkeit, dass man zwischen 3 und 5 Minuten auf den Bus warten muss? Achtung: Hier ist der Trick. NÃ¤mlich, dass wir Integralrechnung gegen stumpfes ZÃ¤hlen eintauschen.\nComputer (und damit R) haben eingebaute Funktionen, die eine beliebige Zufallszahl ziehen kÃ¶nnen, zum Beispiel gleichverteilte. Auf Errisch heiÃŸt das Zauberwort runif():\n\nrunif(n = 1, min = 0, max = 10)\n\n\n## [1] 9.14806\n\nAuf Deutsch heiÃŸt das:\n\nğŸ‘¨â€ğŸ« â€œHey R, ich hÃ¤tte gerne eine (daher n = 1) Zufallszahl (r wie random), die gleichverteilt ist (uniform) mit min = 0 und max = 10.\n\n\nğŸ¤– Jawohl, oh herrliches Leberwesen\n\n(Zu) anschaulich gesprochen: R hat den Bus kommen lassen und es hat gut 9.1 Minuten gedauert, bis er da war. Achtung, jetzt kommtâ€™s: Jetzt lassen wir R mal \\(10^5\\) (1e5 auf Computersprech) Busse vorfahren. R soll jedes Mal notieren, wie lange man auf den Bus warten musste.3\n\nx_simu &lt;- runif(n = 1e5, min = 0, max = 10)\n\nSchauen wir uns die Verteilung an, s. AbbildungÂ 5.17.4\n\nlibrary(ggpubr)\ngghistogram(x_simu_df, x = \"x_simu\", fill = \"grey20\")\n\n\n\n\n\nAbbildungÂ 5.17: Simulation einer gleichverteiluten Zufallsvariablen\n\n\n\nOkay, unsere Verteilung sieht nicht exakt gleichverteilt, aber einigermaÃŸen. Gut genug fÃ¼r unsere Zwecke!\nSo, und jetzt kommt das Ernten. Wir kÃ¶nnen jetzt nÃ¤mlich einfach zÃ¤hlen (count()), um die Antwort auf unsere Frage (der Wartezeit 3-5 Min.) zu erhalten, s. TabelleÂ 5.4.\n\n\n\nx_simu_df %&gt;% \n  count(Schnittmenge = x &gt; 3 & x &lt; 5)\n\n\n\n\n\n\n TabelleÂ 5.4:  HÃ¤ufigkiten auslesen anstelle von Integralen berechnen \n  \n\n\n\n\n\n\nDas Zeichen & ist das logische UND, also die Schnittmenge der zwei Mengen \\(A := \\{x|x&gt;3\\}\\) und \\(B := \\{x|x&lt;5\\}\\), also \\(A \\cap B\\).\nWie man sieht, fallen ca. 20% der Stichproben in den entsprechenden Bereich.\nDa viele Probleme, wenn sie komplexer werden, kaum noch â€œanalytischâ€ (d.h. wie Ausrechnen von Integralen) lÃ¶sbar sind, greift man in der modernen (Analyse-)Welt oft lieber auf Simulationsverfahren zurÃ¼ck - Dank sei den schnellen Rechnern. FÃ¼r uns Menschen ist damit die Aufgabe des Integrierens auf schnÃ¶des ZÃ¤hlen zurÃ¼ckgefÃ¼hrt.\n\n5.3.2 Binomialverteilung\n\nDefinition 5.9 (Binomialverteilung) Die Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei Ergebnissen bzw. Elementarereignissen also. Typisches Beispiel ist ein MÃ¼nzwurf. Bei jeder Wiederholung des Zufallexperiments bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die MÃ¼nze verÃ¤ndert sich nicht durch die WÃ¼rfe (Ziehen mit ZurÃ¼cklegen, ZmZ). AuÃŸerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc.\\(\\square\\)\n\n\n5.3.2.1 Veranschaulichung\nStellen wir uns eine Kistchen5 mit 5 Losen vor, darunter 2 Treffer (Gewinn) und 3 Nieten, s. Abb. AbbildungÂ 5.18. Der Versuch lÃ¤uft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zurÃ¼ck und ziehen erneut.\n\n\n\n\nAbbildungÂ 5.18: Ein KÃ¤stchen mit 5 Losen, darunter 2 Treffer und 3 Nieten.\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nUm die Wahrscheinlichkeitsverteilung einer binomialverteilte Zufallsvariable ausrechnen zu kÃ¶nnen, muss man zwei Dinge wissen: Erstens die Anzahl der ZÃ¼ge, \\(n\\) (StichprobengrÃ¶ÃŸe) und zweitens die Trefferwahrscheinlichkeit, \\(p\\).\n\n\n\n5.3.3 Vier Lose, zwei Treffer\nWie groÃŸ ist die Wahrscheinlichkeit von \\(A^{\\prime}\\), d.h. bei \\(n=4\\) ZÃ¼gen \\(x=2\\) Treffer zu erzielen (und \\(n-x=2\\) Nieten), gegeben dass die Trefferwahrscheinlichkeit bei \\(p=2/4\\) liegt? Wir ziehen dabei ohne ZurÃ¼cklegen (ZoZ). AuÃŸerdem sind die Lose nicht zu unterscheiden (abgesehen davon, ob es Treffer oder Nieten sind).\\(\\square\\)\nWir kÃ¶nnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz, ?eq-multtheorem), vgl. AbbildungÂ 4.14. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit, \\(W\\) (Additionssatz). Das ist einfach, dauert aber. In diesem Fall ist die Wahrscheinlichkeit eines (gÃ¼nstigen) Pfades, \\(A\\):\n\\(P(A) = P(T)^2 \\cdot P(N)^2 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right) ^2\\).\n\np_a = (2/5)^2 * (3/5)^2\np_a\n## [1] 0.0576\n\nEtwas mÃ¼hevolles ZÃ¤hlen der Pfade wÃ¼rde uns zeigen, dass es \\(k=6\\) Pfade gibt, die alle die gleiche Wahrscheinlichkeit, \\(P(A)\\), aufweisen. Damit betrÃ¤gt die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 4 ZÃ¼gen):\n\\(P(A^{\\prime}) = 6 \\cdot P(A)\\).\n\np_a_strich = 6 * p_a\np_a_strich\n## [1] 0.3456\n\nMithilfe der Formel der Binomialverteilung lÃ¤sst sich das Ergebnis, die Wahrscheinlichkeit von \\(A^{\\prime}\\) schneller ausrechnen. Einfach gesprochen sieht sie so aus:\n\\[P(A^{\\prime}) = k \\cdot P(A)\\] Dabei steht \\(k\\) fÃ¼r die Anzahl der gÃ¼nstigen Pfade und \\(P(A)\\) fÃ¼r die Wahrscheinlichkeit eines gÃ¼nstigen Pfades (d.h. 2 Treffer und 2 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\nDie Anzahl der Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt, s. ?eq-binkoeff.6\n\nDefinition 5.10 (Binomialkoeffizient) Der Binomialkoeffizient gibt an, auf wie vielen verschiedenen Arten man aus einer Menge von \\(n\\) verschiedenen Objekten \\(k\\) Objekte ziehen kann (ohne ZurÃ¼cklegen und ohne Beachtung der Reihenfolge).\n\\(k = \\tbinom{n}{k}= \\frac{n!}{k!(n-k)!} \\square\\){#eq-binkoeff}\n\nLies: â€œWÃ¤hle aus \\(n\\) mÃ¶glichen Ereignissen (Pfade im Baum) \\(k\\) gÃ¼nstige Ereignisse (gÃ¼nstige Pfade) oder kÃ¼rzerâ€k aus nâ€.\n\nBeispiel 5.11 (Lotto) Wie viele Zahlenkombinationen gibt es im Lotto fÃ¼r 6 Richtige? Der Binomialkoeffizient verrÃ¤t es uns: \\(\\tbinom{49}{6}= 13\\,983\\,816\\square\\)\n\nAuf Errisch geht das so:\n\n\n\nğŸ‘¨â€ğŸ« Hey R, Wie viele MÃ¶glichkeiten gibt es, aus \\(n=4\\) Pfaden \\(k=2\\) auszuwÃ¤hlen?\n\n\n\nğŸ¤– Ã„h, Moment, oh herzliches Leberwesen\n\n\nchoose(4,2)\n## [1] 6\n\n\n\nHier ist ein Ãœberblick der mÃ¶glichen 6 Elementareignisse des Experiments: 1. TTNN, 2. TNTN, 3. TNNT, 4. NTTN ,5. NTNT, 6. NNTT.\n\nBeispiel 5.12 (BefÃ¶rderung) Aus einem Team mit 25 Personen sollen 11 Personen befÃ¶rdert werden. Wie viele mÃ¶gliche Kombinationen (von befÃ¶rderten Personen) kÃ¶nnen gebildet werden?\n\\(\\tbinom{25}{11} = \\frac{25!}{11!\\cdot(25-11)!} = 4\\,457\\,400\\)\nIn Errisch:\n\nchoose(n = 25, k = 11)\n## [1] 4457400\n\nEs gibt 4457400 Kombinationen von Teams; dabei ist die Reihenfolge der Ziehung nicht berÃ¼cksichtigt.\\(\\square\\)\n\n\n5.3.3.1 Rechnen mit R\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen.\nDie Wahrscheinlichkeit, bei 4 ZÃ¼gen 2 Treffer zu erzielen mit \\(p=2/5\\) unter der Annahme einer Binomialverteilung lÃ¤sst sich so mit R berechnen:\n\ndbinom(x = 2, size = 4, prob = 2/5)\n## [1] 0.3456\n\n\nBeispiel 5.13 (Pumpstation-Beispiel zur Binomialverteilung) In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% fÃ¤llt ein Motor aus und ist fÃ¼r den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie groÃŸ ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb fÃ¤llt?\n\\(P(X=k)\\) (oder kurz: \\(P(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an fÃ¼r das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(P(X=5)\\) ausrechnen.\n\ndbinom(x = 5, size = 7, prob = .95)\n## [1] 0.0406235\n\nEs gilt also \\(P(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist relativ gering7. Die Wahrscheinlichkeit, dass \\(k=0 \\ldots 7\\) Motoren laufen, ist in AbbildungÂ 5.19 dargestellt.\ndbinom() steht fÃ¼r die Wahrscheinlichkeitsdichte (im diskreten Fall, also hier, Wahrscheinlichkeitsfunktion genannt) und binom fÃ¼r die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die StichprobengrÃ¶ÃŸe an (hier 7 Motoren).\nDamit gilt:\n\\(P(X\\ge 5) = P(X=5) + P(X=6) + P(X=7)\\)\nBerechnen wir zunÃ¤chst die Wahrscheinlichkeit, dass 5,6 oder 7 Motoren laufen:\n\np_5 &lt;- dbinom(x = 5, size = 7, prob = .95)\np_6 &lt;- dbinom(x = 6, size = 7, prob = .95)\np_7 &lt;- dbinom(x = 7, size = 7, prob = .95)\n\n\np_5\n## [1] 0.0406235\np_6\n## [1] 0.2572822\np_7\n## [1] 0.6983373\n\nDie gesuchte Wahrscheinlichkeit, p_mind_5, ist die Summe der drei Einzelwahrscheinlichkeiten:\n\np_mind_5 &lt;- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 0.996243\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten betrÃ¤gt also 0.9962.\nDas Komplement zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also hÃ¶chstens 4 und es daher zu einem Ausfall kommt.\nNatÃ¼rlich gilt \\(P(\\bar{X}) = 1- P(X)\\).\n\np_weniger_als_4 &lt;- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.003757043\n\n\n\n\n\n\n(a) In normaler Wahrscheinlichkeit, 0&lt;p&lt;1\n\n\n\n\n\n(b) In Log-Einheiten (Basis 2), â€˜Halbierungenâ€™\n\n\n\nAbbildungÂ 5.19: Wahrscheinlichkeit, dass genau k = 0..7 Motoren laufen\n\n\nAlternativ kann man mit der Verteilungsfunktion rechnen: \\(P(X \\le 4)\\).\nIn R kann man die Funktion pbinom() nutzen (p fÃ¼r (kumulierte) Wahrscheinlichkeit), um die Verteilungsfunktion der Binomialverteilung zu berechnen:\n\npbinom(q = 4, size = 7, prob = .95)\n## [1] 0.003757043\n\nq = 4 steht fÃ¼r \\(X \\le 4\\), also fÃ¼r hÃ¶chstens 4 Treffer (arbeitende Motoren); size = 7 meint die StichprobengrÃ¶ÃŸe, hier 7 Motoren.\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Funktion, die die Wahrscheinlichkeit dafÃ¼r angibt, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich (hÃ¶chstens) einem Wert \\(X=x\\) ist, heiÃŸt Verteilungsfunktion.\n\\(F(X=x) = P(X \\le x)\\)\n\n\n\n5.3.4 Logarithmus\nDer Logarithmus zur Basis 28 gibt die â€œVerdopplungenâ€ bzw. â€œHalbierungenâ€ der Wahrscheinlichkeit an, wobei \\(ld(1/2) = -1.\\square\\)\n\nBeispiel 5.14 \\(ld(1/2) = -1:\\)\n\nlog(.5, base = 2)\n## [1] -1\n\n1/2 ist genau â€œminus 1 Verdopplungâ€ von 1 entfernt, d.h. eine Halbierung.\n\\(ld(1/4) = -2:\\)\n\nlog(1/4, base = 2)\n## [1] -2\n\n1/2 ist genau â€œminus 2 Verdopplungenâ€ von 1 entfernt, d.h. zwei Halbierungen.\n\\(ld(1/8) = -3:\\)\n\nlog(1/8, base = 2)\n## [1] -3\n\n1/8 (0.125) ist 3 Halbierungen von 1 entfernt.\\(\\square\\)\n\n\n5.3.4.1 Simulieren\nDie Binomialverteilung lÃ¤sst sich gut als â€œMÃ¼nzwurf-Verteilungâ€ auffassen.\nWerfen wir eine MÃ¼nze und sehen wir, was passiert.\n\nsample(x = c(0, 1), size = 1)\n## [1] 1\n\nMit sample() ziehen wir eine Stichprobe aus dem Ereignisraum x, hier 0 und 1. Dabei vereinbaren wir (willkÃ¼rlich), dass 0 fÃ¼r â€œKopfâ€ steht und 1 fÃ¼r â€œZahlâ€. size = 1 bedeutet, wir werfen die MÃ¼nze ein Mal (d.h. StichprobengrÃ¶ÃŸe size ist 1).\nOkay, noch an Bord? Dann werfen wir die MÃ¼nze 10 Mal:\n\nsample(x = c(0, 1), size = 10, replace = TRUE)\n##  [1] 0 1 1 1 1 0 0 1 0 1\n\nreplace = TRUE heiÃŸt, wir legen die MÃ¼nze wieder zurÃ¼ck auf den Tisch, wenn wir sie geworfen haben. Oder anders ausgedrÃ¼ckt: Ziehen mit ZurÃ¼cklegen.\nR, mach dich bereit, wirf die MÃ¼nze 1000 (\\(n=10^3\\) oder 1e3) Mal9:\n\nn &lt;- 1e3\n\nmuenze_oft &lt;- \n  sample(x = c(0, 1), size = n, replace = TRUE) \n\n\nmuenze_oft %&gt;% \n  sum()\n## [1] 539\n\nMit sum() nach dem Pfeifensymbol %&gt;% haben wir aus dem Vektor muenze_oft, der aus der ersten Zeile resultiert, die Summe ausgerechnet.\nJetzt wissen wir, wie oft die MÃ¼nze â€œZahlâ€ gezeigt hat, nÃ¤mlich 539 Mal.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie einen Zufallsversuch wiederholen, muss nicht jedes Mal das gleiche Ergebnis resultieren. Entsprechend wird bei wiederholten AusfÃ¼hrung der Funktion sample() nicht immer das gleiche Ergebnis resultieren. Wundern Sie sich also nicht, wenn bei Ihrem Computer eine Ã¤hnliche, aber nicht gleiche, Zahl herauskommt.\n\n\nVisualisieren wir mal unsere MÃ¼nzwÃ¼rfe. Dazu erstellen wir zuerst eine geeignete Tabelle, TabelleÂ 5.5.\n\nmuenz_tab &lt;-\n  tibble(\n    id = 1:n,\n    x = muenze_oft,\n    x_cumsum = cumsum(x) / id  # gibt Anteil von \"Zahl\" wieder\n  )\n\n\n\n\n\n TabelleÂ 5.5:  Die kumulierte Summe beim MÃ¼nzwurf (nur die ersten paar Zeilen) \n  \n\n\n\n\nUnd hier der Anteil von â€œZahlâ€ im Verlauf unserer MÃ¼nzwÃ¼rfe, s. AbbildungÂ 5.20.\n\nmuenz_tab %&gt;% \n  slice_head(n = 1e3) %&gt;% \n  ggplot() +\n  aes(x = id, y = x_cumsum) +\n  geom_line()\n\n\n\nAbbildungÂ 5.20: Das Gesetz der groÃŸen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten MÃ¼nzwurf\n\n\n\nGrob gesagt scheint sich ein MÃ¼nzwurf nach, naja, vielleicht 500 WÃ¼rfen â€œeinigermaÃŸenâ€ zu stabilisieren.10\n\n\n\n\n\n\nWichtig\n\n\n\nDas Gesetz der groÃŸen Zahl\nZieht man (zufÃ¤llig) immer mehr Werte aus einer Verteilung (mit endlichem Mittelwert), nÃ¤hert sich der Mittelwert der Stichprobe immer mehr mit dem Mittelwert (oft als Erwartungswert bezeichnet) der Verteilung an\n\n\n\n\n5.3.5 Normalverteilung\nNormalverteilungen haben eine charakteristische Glockenform; sie sind symmetrisch11. Normalverteilungen kÃ¶nnen sich unterscheiden Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden GrÃ¶ÃŸen (â€œParameterâ€) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. AbbildungÂ 5.21. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\n\n5.3.6 Parameter\nEin Parameter (einer Verteilung) legt die â€œVariantenâ€ einer Verteilung fest. Durch die Wahl der Parameterwerte nimmt eine Verteilung eine genaue Form an.\n\n\nAbbildungÂ 5.21: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\nBeispiel: Wie groÃŸ sind Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%:\n\n\n\n\n\n\n\nq25\n      q50\n      q75\n    \n\n160.02\n167.64\n175.26\n\n\n\n\n\nAbbildungÂ 5.22 zeigt eine Visualisierung der Quantile.\n\n\n\n\nAbbildungÂ 5.22: Quantile verschieden visualisiert\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas 25%-Quantil nennt man 1. Quartil, das 50%-Quantil auch 2. Quartil, das 75%-Quantil das 3. Quartil, und das 100%-Quantil (Maximalwert) das 4. Quartil.\n\n\n\n5.3.6.1 Normal auf dem FuÃŸballfeld\nSie und 100 Ihrer besten Freunde stehen auf der Mittellinie eines FuÃŸballfelds. Auf Kommando werfen alle jeweils eine MÃ¼nze; bei Kopf geht man einen Schritt nach links, bei Zahl nach rechts. Das wird 16 Mal wiederholt. Wie wird die Verteilung der Positionen wohl aussehen?\n\n\n\n\n\n(McElreath 2020)\n\n5.3.6.2 Normal durch Addieren\nDie Summe vieler (gleich starker) Zufallswerte (aus der gleichen Verteilung) erzeugt eine Normalverteilung; egal aus welcher Verteilung die Zufallswerte kommen (Zentraler Grenzwertsatz), vgl. AbbildungÂ 5.23.\n\n\n\n\nAbbildungÂ 5.23: Entstehen einer Normalverteilung durch Addition vieler unabhgÃ¤ngiger Ereignisse\n\n\n\nNicht verwechseln:\n\n\n\n\n\n\n\n\n\n5.3.6.3 Normalverteilung vs.Â randlastige Verteilungen\n\n\n\n\n\nBei randlastigen Verteilungen (â€œfat tailsâ€) kommen Extremereignisse viel hÃ¤ufiger vor als bei Normalverteilungen. Deshalb ist es wichtig sein, zu wissen, ob eine Normalverteilung oder eine randlastige Verteilung vorliegt. Viele statistische Methoden sind nicht zuverlÃ¤ssig bei (stark) randlastigen Methoden.\n\nBeispiel 5.15 (Beispiele fÃ¼r Normal- und randlastige Verteilungen) Â \n\n\nNormal verteilt:\n\nGrÃ¶ÃŸe\nMÃ¼nzwÃ¼rfe\nGewicht\nIQ\nBlutdruck\nAusschuss einer Maschine\n\n\nRandlastig verteilt:\n\nVermÃ¶gen\nVerkaufte BÃ¼cher\nRuhm\nAktienkurse\nErdbeben\nPandemien\nKriege\nErfolg auf Tinder\nMeteroritengrÃ¶ÃŸe\nStadtgrÃ¶ÃŸen\n\n\n\n\n\n5.3.6.4 Formel der Normalverteilung\nVereinfacht ausgedrÃ¼ckt lÃ¤sst die Normalverteilung \\(\\mathcal{N}\\) durch Exponenzieren einer Quadratfunktion beschreiben:\n\\[\\mathcal{N} \\propto e^{-x^2}\\]\nmit \\(e=2.71...\\), der Eulerschen Zahl.12\nWie man sieht (AbbildungÂ 5.24) ergibt sich eine Normalverteilung.\n\nd &lt;-\n  tibble(\n    x = seq(-3, 3, \n            length.out = 100),\n    y = exp(-x^2)\n  )\n\nggline(d, x = \"x\",y = \"y\")  # aus {ggpubr}\n\n\n\n\n\nAbbildungÂ 5.24: Wir basteln uns eine Normalverteilung\n\n\n\nEine Normalverteilung mit \\(\\mu=0\\) und \\(\\sigma=1\\) nennt man auch Standardnormalverteilung und man schreibt:\n\\[IQ \\sim \\mathcal{N}(0,1)\\]\nDie Normalverteilung wird auch Gauss-Verteilung oder Glockenkurve genannt.\n\n5.3.6.5 Simulation einer Normalverteilung\nR hat eine Funktion eingebaut zur Erzeugung von Zufallszahlen (Zufallszahlengenerator), z.B. normalverteilte. Man Ã¼bergibt dieser Funktion den gewÃ¼nschten Mittelwert und die gewÃ¼nschte Streuung und die Funktion zieht dann zufÃ¤llig Werte aus dieser Verteilung.\nDiesen Zufallszahlengenerator kann man mit einem Duschkopf vergleichen, s. AbbildungÂ 5.25. An diesem Duschkopf kann man einen Schwenker einstellen, der den Duschkopf ausrichtet, also steuert, ob die Wassertropfen weit in die eine oder die andere Richtugn fallen. Zweitens hat unser Duschkopf noch einen Streuregler, der den Wasserstrahl entweder eng bÃ¼ndelt13 oder weit auseinanderfÃ¤chert. Im ersten Fall fÃ¤llt der Wasserstrahl eng und schmal aus. Im zweiten Fall fÃ¤llt der Wasserstrahl breit aus.\n\n\nAbbildungÂ 5.25: Zufallszahlengenerator als Duschkopf\n\nQuelle: John Kruschke.\nEine Zufallszahl (random number), die normalverteilt ist, mit \\(\\mu=0\\) und \\(\\sigma=1\\) kann man in R so erzeugen:\n\nrnorm(n = 1, mean = 0, sd = 1)\n## [1] 0.2664096\n\nEin Fallbeispiel: Der Inhalt einer TÃ¼te mit Zucker, \\(X\\), sei normalverteilt mit \\(\\mu = 10002\\) g und \\(\\sigma=1.5\\) g. Aus vertragsrechtlichen GrÃ¼nden darf das FÃ¼llgewicht von 1000g nicht unterschritten werden, sonst drohen Konventionalstrafen.\nWie groÃŸ ist die Wahrscheinlichkeit, dass 1000g unterschritten werden?\nSimulieren wir uns 1e4 ZuckertÃ¼ten!\n\nn &lt;- 1e4\nd &lt;- \n  tibble(\n    id = 1:n,\n    x = rnorm(n = n, mean = 1002, sd = 1.5)\n  )\n\nhead(d)\n\n\n\n  \n\n\n\nZÃ¤hlen wir, viele der ZuckertÃ¼ten ein Gewicht von weniger als 1000g aufweisen:\n\nd %&gt;% \n  count(x &lt; 1000)\n\n\n\n  \n\n\n\nEin ziemlich14 kleiner Anteil. Rechnen wir uns noch die Anteile (proportion) aus:\n\nd %&gt;% \n  count(x &lt; 1000) %&gt;% \n  mutate(prop = n/1e4)\n\n\n\n  \n\n\n\n\n5.3.7 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. AbbildungÂ 5.26:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\nÃœbungsaufgabe 5.2 (Wie schlau muss man (nicht) sein?) Â \n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu gehÃ¶ren?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, â€¦ der Leute nicht Ã¼berschritten?\\(\\square\\)\n\n\n\n\n\nAbbildungÂ 5.26: Visualisierung der theoretischen IQ-Verteilung\n\nQuelle:: John Kruschke.\nZiehen wir zufÃ¤llig \\(1e4\\) Stichproben aus \\(\\mathcal{N}(100,15)\\) und berechnen die Quantile:\n\nd &lt;-\n  tibble(\n  iq = rnorm(n = 1e4, \n             mean = 100, \n             sd = 15))\n\nprobs &lt;- c(0.75,.5,.25,.05,.01)\n\nd_summary &lt;- d %&gt;% \n  summarise(p = probs,\n            q = quantile(iq, probs))\n\n\n\n\n\n\n\n\np\n      q\n    \n\n\n0.75\n110\n\n\n0.50\n100\n\n\n0.25\n90\n\n\n0.05\n75\n\n\n0.01\n65\n\n\n\n\n\n\nDas Quantil \\(q\\) zur kumulierten Wahrscheinlichkeit \\(p=75\\) ist 110, etc.\nUmgekehrt kÃ¶nnen wir uns auch fragen: Gegeben einer Realisation der Zufallsvariablen (z.B. IQ), was ist die zugehÃ¶rige Wahrscheinlichkeit (Wert der Verteilungsfunktion?)\n\nÃœbungsaufgabe 5.3 (Wie schlau muss man (nicht) sein, Teil 2) Â \n\nWelcher Anteil der FlÃ¤che unter der Kurve \\(p\\) gehÃ¶rt zu den IQ-Werten 75, 100, 115, 130?\nAnders gesagt: Welcher Anteil der Wahrscheinlichkeitsmasse der Verteilung liegt unter IQ=75, IQ=100, etc.?\\(\\square\\)\n\n\n\nZiehen wir Stichproben aus \\(\\mathcal{N}(100,15)\\):\n\nd &lt;-\n  tibble(\n    iq = rnorm(1e4, \n               mean = 100, \n               sd = 15)) %&gt;% \n  mutate(iq = round(iq))\n\nqs &lt;- c(75,100,115,130)\n\nd %&gt;% \n  count(p_100 = iq &lt; 100) %&gt;% \n  mutate(prop = n / sum(n)) \n\n\n\n\n\n\n\n\np_100\n      n\n      prop\n    \n\n\nFALSE\n5143\n0.51\n\n\nTRUE\n4857\n0.49\n\n\n\n\n\n\nAnstelle von iq &lt; 100 kann man iq &lt; 115 einsetzen, etc.\nDie Verteilungsfunktion (der Anteil der Wahrscheinlichkeitsmasse), p, fÃ¼r IQ-Werte nicht grÃ¶ÃŸer als 100, \\(IQ\\le100\\), ist 50%, etc.\n\n5.3.7.1 Quantile der Normalverteilung\n\n\nQuantile teilen eine Verteilung so ein, dass ein Anteil \\(p\\) kleiner oder gleich und der andere Teil \\(1-p\\) grÃ¶ÃŸer dem Quantil \\(q\\) ist.\n\n\nBeispiel: â€œ50%-Quantil = 100â€ meint, dass 50% der Elemente der Verteilung einen Wert kleiner oder gleich als 100 haben.\n\n\nDie Verteilungsfunktion F (fÃ¼r einen Wert \\(x\\)) gibt die Wahrscheinlichkeit an, dass die zugehÃ¶rige Zufallsvariable \\(X\\) einen Wert hÃ¶chstens so groÃŸ wie \\(x\\) annimmt. Sie zeigt also die kumulierte Wahrscheinlichkeit \\([-\\infty, q)\\).\n\n\nBeispiel: â€œF(100) = 50%â€ meint: Die Wahrscheinlichkeit fÃ¼r eine AusprÃ¤gung von hÃ¶chstens als 100 betrÃ¤gt 50%.\n\n\n\nSchauen wir uns die Quartile der Normalverteilung einmal nÃ¤her an. Wir gehen von einer Normalverteilung aus, wie sie zur Beschreibung von Intelligenz (IQ) verwendet wird, s. AbbildungÂ 5.27.\n\n\n\n\nAbbildungÂ 5.27: Quantile der Normalverteiltung\n\n\n\n\\[IQ \\sim \\mathcal{N}(100, 15)\\] Mit R kann man sich die beiden GrÃ¶ÃŸen komfortabel berechnen lassen:\n\nqnorm(.50, mean = 100, sd = 15)  # 50%-Quantil\npnorm(100, mean = 100, sd = 15)  # Verteilungsfunktion fÃ¼r IQ=100\n\nBetrachten wir einige wichtigen Quantile, s. AbbildungÂ 5.28.\n\n\n\n\nAbbildungÂ 5.28: Verschiedene Quantil der Normalverteilung\n\n\n\n\n5.3.7.2 Standardnormalverteilung\n\n\n\n\n\nBei \\(X=0\\):\n\nhat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 40% (Wahrscheinlichkeitsdichte)\nsind 50% der Wahrscheinlichkeitsmasse (FlÃ¤che unter der Kurve) kleiner als dieser Wert (Verteilungsfunktion).\n\nIn Summe liegen 100% der Wahrscheinlichkeitsmasse unter der Kurve.\n\n5.3.7.3 Normalverteilung als konservative Wahl\nDem Mathematiker Carl Friedrich Gauss (s. AbbildungÂ 5.29) wird die Ehre zuerkannt, die Normalverteilung eingefÃ¼hrt zu haben.\n\n\n\n\nAbbildungÂ 5.29: Zehn-Mark-Geldschein mit Gauss und Normalverteilung\n\n\n\nQuelle: Uni Greifswald, Public domain, via Wikimedia Commons\n\n\n\n\n\n\nHinweis\n\n\n\nOntologische BegrÃ¼ndung\n\nWirken viele, gleichstarke EinflÃ¼sse additiv zusammen, entsteht eine Normalverteilung (McElreath 2020), Kap. 4.1.4.\n\nEpistemologische BegrÃ¼ndung\n\nWenn wir nur wissen, dass eine Variable Ã¼ber einen endlichen Mittelwert und eine endliche Varianz verfÃ¼gt und wir keine weiteren Annahmen treffen bzw. Ã¼ber kein weiteres Vorwissen verfÃ¼gen, dann ist die Normalverteilung die plausibelste Verteilung (maximale Entropie) (McElreath 2020), Kap. 7 und 10."
  },
  {
    "objectID": "0400-Verteilungen.html#aufgaben",
    "href": "0400-Verteilungen.html#aufgaben",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.4 Aufgaben",
    "text": "5.4 Aufgaben\nZusÃ¤tzlich zu den Aufgaben im Buch:\n\nLose-Nieten-Binomial-Grid\nBsp-Binomial\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq09\niq10\nBus1\nalphafehler-inflation2\nalphafehler-inflation3\nalphafehler-inflation4"
  },
  {
    "objectID": "0400-Verteilungen.html#section",
    "href": "0400-Verteilungen.html#section",
    "title": "\n5Â  Verteilungen\n",
    "section": "\n5.5 â€”",
    "text": "5.5 â€”\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0400-Verteilungen.html#footnotes",
    "href": "0400-Verteilungen.html#footnotes",
    "title": "\n5Â  Verteilungen\n",
    "section": "",
    "text": "da einfach und deutlichâ†©ï¸\nS wie Summeâ†©ï¸\nMachen Sie das mal ohne Computer, wenn Sie ein Wochenende lang Langeweile haben.â†©ï¸\nAlternativ kann man z.B. auch ggplot verwenden: ggplot(x_simu_df, aes(x = x_simu)) +  geom_histogram(bins = 50).â†©ï¸\nIn den LehrbÃ¼chern hÃ¤ufig als Urne bezeichnet, was den bÃ¶sen Spott von â€œFriedhofstatistikâ€ nach sich zog.â†©ï¸\nwobei gelten muss \\(n \\ge k\\)â†©ï¸\nwobei â€œgeringâ€ subjektiv ist, die Betreiberfirma findet diese Wahrscheinlichkeit, dass 2 Pumpen ausfallen, wohl viel zu hoch.â†©ï¸\nals â€œLogarithmus Dualisâ€, ld, bezeichnetâ†©ï¸\nR meckert nicht bei langweiligen Aufgaben.â†©ï¸\nWas â€œeinigermaÃŸenâ€ bedeuten soll, ist kein statistischer Begriff, sondern einer, der im echten Leben von den Menschen beantwortet werden muss, die eine Entscheidung zu treffen haben.â†©ï¸\nd.h. die Schiefe (skewness) ist 0â†©ï¸\nDas Zeichen \\(y \\propto x\\) bedeutet â€œx ist proportional zu yâ€, also \\(y = mx\\).â†©ï¸\nMassagedusche, behauptet der Herstellerâ†©ï¸\nâ€œZiemlichâ€ ist natÃ¼rlich subjektiv; je nach Situation kann es zu viel oder nicht zu viel sein.â†©ï¸"
  },
  {
    "objectID": "0300-Wskt.html#lernsteuerung",
    "href": "0300-Wskt.html#lernsteuerung",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.1 Lernsteuerung",
    "text": "4.1 Lernsteuerung\n\n4.1.1 Ãœberblick\nDieses Kapitel hat die Wahrscheinlichkeitstheorie (synonym: Wahrscheinlichkeitsrechnung) bzw. das Konzept der Wahrscheinlichkeit zum Thema.1 Es geht sozusagen um die Mathematik des Zufalls.\n\n4.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erlÃ¤uternd definieren\ndie drei Arten der direkten Ermittlung von Wahrscheinlichkeit erlÃ¤utern\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n4.1.3 Eigenstudium\n\n\n\n\n\n\nWichtig\n\n\n\nDieses Kapitel ist selbstÃ¤ndig im Eigenstudium vorzubereiten vor dem Unterricht. Lesen Sie dazu die angegebene Literatur. Im Unterricht werden Fragen beantwortet und Aufgaben gemeinsam bearbeitet. Der Stoff wird aber nicht vorgestellt, sondern ist im Selbststudium vorab vorzubereiten.\\(\\square\\)\n\n\n\n4.1.4 PrÃ¼fungsrelevanter Stoff\nLesen Sie dazu Bourier (2018), Kap. 2-4. Weitere Ãœbungsaufgaben finden Sie im dazugehÃ¶rigen Ãœbungsbuch, Bourier (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nIn Ihrer Hochschul-Bibliothek kann das Buch als Ebook verfÃ¼gbar sein. PrÃ¼fen Sie, ob Ihr Dozent Ihnen weitere Hilfen im geschÃ¼tzten Bereich (Moodle) eingestellt hat.\\(\\square\\)\n\n\n\n4.1.5 Zentrale Begriffe\n\n4.1.5.1 Grundbegriffe\n\nZufallsvorgang (Zufallsexperiment)\nElementarereignis\nEreignisraum\nZufallsereignis (zufÃ¤lliges Ereignis)\nSicheres Ereignis\nUnmÃ¶gliches Ereignis\n\n4.1.5.2 Wahrscheinlichkeitsbegriffe\n\nKlassische Wahrscheinlichkeit (LaPlaceâ€™sche Wahrscheinlichkeit)\nStatistische (empirische) Wahrscheinlichkeitsermittlung\nSubjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n4.1.5.3 Wahrscheinlichkeitsrelationen\n\nVereinigung von Ereignissen\nSchnitt(menge) von Ereignissen\nKomplementÃ¤rereignis\nVollstÃ¤ndiges Ereignissystem\nAnforderungen an eine Definition von Wahrscheinlichkeit\n\n4.1.5.4 Wahrscheinlichkeitsrechnung\n\nAllgemeiner Additionsssatz\nDisjunkte Ereignisse\nAdditionssatz fÃ¼r disjunkte Ereignisse\nBedingte Wahrscheinlichkeit\n(Stochastische) UnabhÃ¤ngigkeit\nBaumdiagramm fÃ¼r gemeinsame Wahrscheinlichkeit\nAllgemeiner Multiplikationssatz\nMultiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse\nTotale Wahrscheinlichkeit\nSatz von Bayes\n\n4.1.6 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit"
  },
  {
    "objectID": "0300-Wskt.html#grundbegriffe-1",
    "href": "0300-Wskt.html#grundbegriffe-1",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.2 Grundbegriffe",
    "text": "4.2 Grundbegriffe\n\nBeispiel 4.1 Klassisches Beispiel fÃ¼r einen Zufallsvorgang ist das (einmalige oder mehrmalige) Werfen einer MÃ¼nze.\\(\\square\\)\nWerfen Sie eine MÃ¼nze! Diese hier zum Beispiel:\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10, nein, 100, nein 1000, nein: \\(10^6\\) Mal.\nNotieren Sie das Ergebnis.\\(\\square\\)\n\nOder probieren Sie die App der Brown University.\n\nDefinition 4.1 (Zufallsvorgang) Ein Zufallsvorgang oder Zufallsexperiment ist eine einigermaÃŸen klar beschriebene TÃ¤tigkeit, deren Ergebnis nicht bekannt ist. Allerdings ist die Menge mÃ¶glicher Ergebnisse sicher und die Wahrscheinlichkeit fÃ¼r die Ergebnisse kann quantifiziert werden.\\(\\square\\)\n\n\nÃœbungsaufgabe 4.1 Nennen Sie Beispiele fÃ¼r ZufallsvorgÃ¤nge!2\n\n\n\n\n\n\n\nVorsicht\n\n\n\nZufall heiÃŸt nicht, dass ein Vorgang keine Ursachen hÃ¤tte. So gehorcht der Fall einer MÃ¼nze komplett den Gesetzen der Gravitation. WÃ¼rden wir diese Gesetze und die Ausgangsbedingungen (Luftdruck, FallhÃ¶he, OberflÃ¤chenbeschaffenheit, Gewichtsverteilungen, â€¦) exakt kennen, kÃ¶nnten wir theoretisch sehr genaue Vorhersagen machen. Der â€œZufallâ€ wÃ¼rde aus dem MÃ¼nzwurf verschwinden. Man sollte â€œZufallâ€ also besser verstehen als â€œunbekanntâ€.\\(\\square\\)\n\n\n\nÃœbungsaufgabe 4.2 Mit dieser App kÃ¶nnen Sie WÃ¼rfelwÃ¼rfe simulieren und die AusgÃ¤nge dieses Zufallsexperiments beobachten.\\(\\square\\)\n\n\nDefinition 4.2 (Ereignisraum) Die mÃ¶glichen Ergebnisse eines Zufallvorgangs fasst man als Menge mit dem Namen Ereignisraum[leider gibt es eine FÃ¼lle synonymer Namen: Ereignisraum, Elementarereignisraum, Ergebnisraum oder Grundraum] zusammen. Man verwendet den griechischen Buchstaben \\(\\Omega\\) fÃ¼r diese Menge. Die Elemente \\(\\omega\\) (kleines Omega) von \\(\\Omega\\) nennt man Ergebnisse.\\(\\square\\)\n\n\nBeispiel 4.2 Beobachtet man beim WÃ¼rfelwurf (s. AbbildungÂ 4.3) die oben liegende Augenzahl, so ist\n\\[\\Omega = \\{ 1,2,3,4,5,6 \\} = \\{âš€, âš, âš‚, âšƒ, âš„, âš…\\}\\]\nein natÃ¼rlicher Grundraum (Henze 2019).\\(\\square\\)\n\n\n\n\n\nEin (sechsseitiger) WÃ¼rfel\n\nBildquelle: CC BY-SA 3.0\n\n\n\nAbbildungÂ 4.1: Ein (sechsseitiger) WÃ¼rfel, Bildquelle: Peter Steinberg, Wikipedia, CC-BY-\n\n\n\n\nDefinition 4.3 (Ereignis) Jede Teilmenge3 von \\(\\Omega\\) heiÃŸt Ereignis; \\(A \\subseteq B\\) .\\(\\square\\)\n\n\nBeispiel 4.3 Beim Mensch-Ã¤rger-dich-nicht Spielen habe ich eine 6 geworfen.4 Das Nennen wir das Ereignis \\(A\\): â€œAugenzahl 6 liegt obenâ€.\\(\\square\\)\n\\(A= \\{6\\}\\)\n\n\nDefinition 4.4 (UnmÃ¶gliches und sicheres Ereignis) Die leere Menge \\(\\varnothing\\) heiÃŸt das umÃ¶gliche, der Grundraum \\(\\Omega\\) heiÃŸt das sichere Ereignis. \\(\\square\\)\n\n\nBeispiel 4.4 (UnmÃ¶gliches Ereignis) Alois behauptet, er habe mit seinem WÃ¼rfel eine 7 geworfen. Schorsch ergÃ¤nt, sein WÃ¼rfel liege auf einer Ecke, so dass keine Augenzahl oben liegt. Draco hat seinen WÃ¼rfel runtergeschluckt.\\(\\square\\)\n\n\nBeispiel 4.5 Nach dem der WÃ¼rfel geworfen wurde, liegt eine Augenzahl zwischen 1 und 6 oben.\\(\\square\\)\n\n\nDefinition 4.5 (Elementarereignis) Jede einelementige Teilmenge \\(\\{\\omega\\}\\) von \\(\\Omega\\) heiÃŸt Elementarereignis (hÃ¤ufig mit \\(A\\) bezeichnet).\\(\\square\\)\n\n\nBeispiel 4.6 (Elementarereignis) Â \n\nSie spielen Mensch-Ã¤rger-dich-nicht. Und brauchen dringend eine 6. Sie wÃ¼rfeln. Das Ereignis \\(A = \\{1\\}\\) tritt ein.5\nSie schreiben eine Statistik-Klausur. Irgendwie haben Sie das GefÃ¼hl, das Ergebnis ist eine Zufallsexperimentâ€¦ Jedenfalls kÃ¶nnen nach Adam Riese zwei Dinge passieren: \\(\\Omega= \\{\\text{bestehen, nicht bestehen}\\}\\). Das erste der beiden Elementarereignisse tritt ein. Yeah!\nSie fÃ¼hren eine Studie durch zur Wirksamkeit einer Lern-App. Es ist nicht klar, ob die App wirklich was bringt fÃ¼r den Lernerfolg. Vereinfacht gesprochen ist der Grundraum dieses Experiments: \\(\\Omega = \\{\\text{schadet, bringt nichts, nÃ¼tzt}\\}\\). Die Daten sprechen fÃ¼r das Ereignis \\(A = \\{\\text{bringt nichts}\\}\\).\n\n\n\nDefinition 4.6 (VollstÃ¤ndiges Ereignissystem) Wird der Grundraum \\(\\Omega\\) vollstÃ¤ndig in paarweis disjunkte Ereignisse zerlegt, so bilden diese Ereignisse ein vollstÃ¤ndiges Ereignissystem, s. AbbildungÂ 4.2.\\(\\square\\)\n\n\n\nAbbildungÂ 4.2: Zerlegung des Grundraums in ein vollstÃ¤ndiges Ereignissystem\n\n\nBeispiel 4.7 Sei \\(\\Omega\\) der typische Ereignisraum des WÃ¼rfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) â€œgerade Zahlenâ€, und \\(B\\) â€œungerade Zahlenâ€. Damit haben wir ein vollstÃ¤ndiges Ereignissystem erstellt.\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\nB = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\}  \\qquad  \\hfill \\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6 }\n\n\\end{align}\\]\n\n\nBeispiel 4.8 Sei \\(\\Omega\\) der typische Ereignisraum des WÃ¼rfelwurfs. Wir zerlegen den Grundraum in zwei Ereignisse, \\(A\\) â€œ1,2,3â€, und \\(B\\) â€œ4,5,6â€. Damit haben wir ein vollstÃ¤ndiges Ereignissystem erstellt.\n\\[\\begin{align}\nA = \\{1,2,3\\} \\qquad \\qquad \\hfill  \\boxed{\\boxed{ \\color{black}{1\\; 2\\; 3}}\\; \\color{gray}{4\\; 5\\; 6}} \\\\\nB = \\{4,5, 6\\} \\qquad \\qquad  \\hfill \\boxed{\\color{gray}{1 \\; 2 \\; 3}\\; \\boxed{\\color{black}{4\\; 5 \\; 6}}} \\\\\n\n\\newline\n\\hline \\\\\n\\Omega = \\{1,2,3,4,5,6\\} \\qquad \\qquad \\hfill  \\boxed{1\\; 2\\; 3\\; 4\\; 5\\;6}\n\\end{align}\\]\n\n\nDefinition 4.7 (MÃ¤chtigkeit) Die Anzahl der Elementarereignisse eines Ereignismraums nennt man die MÃ¤chtigkeit (des Ereignisraums).6\\(\\square\\)\n\nDie MÃ¤chtigkeit von \\(\\Omega\\) bezeichnet man mit dem Symbol \\(|\\Omega|\\).\n\nBeispiel 4.9 Beim Wurf eines WÃ¼rfels mit \\(\\Omega=\\{1,2,3,4,5,6\\}\\) gibt es 6 Elementarereignisse. Die MÃ¤chtigkeit ist also 6: \\(|\\Omega|=6\\).\\(\\square\\)"
  },
  {
    "objectID": "0300-Wskt.html#direkte-ermittlung-von-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#direkte-ermittlung-von-wahrscheinlichkeiten",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.3 Direkte Ermittlung von Wahrscheinlichkeiten",
    "text": "4.3 Direkte Ermittlung von Wahrscheinlichkeiten\n\n4.3.1 Epistemologische Wahrscheinlichkeit\nVor uns liegt ein WÃ¼rfel. Schlicht, ruhig, unbesonders. Wir haben keinen Grund anzunehmen, dass eine seiner \\(n=6\\) Seiten bevorzugt nach oben zu liegen kommt. Jedes der sechs Elementarereignisse ist uns gleich plausibel; der WÃ¼rfel erscheint uns fair. In Ermangelung weiteres Wissens zu unserem WÃ¼rfel gehen wir schlicht davon aus, dass jedes der \\(n\\) Elementarereignis gleich wahrscheinlich ist. Es gibt keinerlei Notwendigkeit, den WÃ¼rfel in die Hand zu nehmen, um zu einer Wahrscheinlichkeitsaussage auf diesem Weg zu kommen. NatÃ¼rlich kÃ¶nnten wir unsere Auffassung eines fairen WÃ¼rfels testen, aber auch ohne das Testen kÃ¶nnen wir eine stringente Aussage (basierend auf unserer Annahme der Indifferenz der \\(n\\) Elementarereignisse) zur Wahrscheinlichkeit eines bestimmten (Elementar-)Ereignisses \\(A\\) kommen (Briggs 2016), s. GleichungÂ 4.1.\n\\[Pr(A) = 1/n= \\frac{1}{|\\Omega|} \\tag{4.1}\\]\n\nBeispiel 4.10 Sei \\(A\\) = â€œDer WÃ¼rfel wird beim nÃ¤chsten Wurf eine 6 zeigen.â€ Die Wahrscheinlichkeit fÃ¼r \\(A\\) ist \\(1/6. \\square\\)\n\n\nDefinition 4.8 Ein Zufallsexperiment, bei dem alle Elementarereignisse die selbe Wahrscheinlichkeit haben, nennt man man ein Laplace-Experiment.\\(\\square\\)\n\nIn Erweiterung von GleichungÂ 4.1 kÃ¶nnen wir schreiben:\n\\[Pr(A)=\\frac{\\text{Anzahl Treffer}}{\\text{Anzahl mÃ¶glicher Ergebnisse}}\\]\n\n4.3.2 Frequentistische Wahrscheinlichkeit\nIn Ermangelung einer Theorie zum Verhalten eines (uns) unbekannten Zufallsvorgangs und unter der Vermutung, dass die Elementarereignisse nicht gleichwahrscheinlich sind, bleibt uns ein einfacher (aber aufwÃ¤ndiger) Ausweg: Ausprobieren.\nAngenommen, ein Statistik-Dozent, bekannt fÃ¼r seine Vorliebe zum GlÃ¼cksspiel und scheinbar endlosen GlÃ¼cksstrÃ¤hnen, er wirft andauernd eine 6, hat seinen LieblingswÃ¼rfel versehentlich liegen gelassen. Das ist die Gelegenheit! Sie greifen sich den WÃ¼rfel, und â€¦ Ja, was jetzt? Nach kurzer Ãœberlegung kommen Sie zum Entschluss, den WÃ¼rfel einen â€œPraxistestâ€ zu unterziehen: Sie werfen ihn 1000 Mal (Puh!) und zÃ¤hlen den Anteil der 6. Falls der WÃ¼rfel fair ist, mÃ¼sste gelten \\(Pr(A=6)=1/6\\approx .17\\). Schauen wir mal!\nUnd hier der Anteil von 6 im Verlauf unserer WÃ¼rfe, s. AbbildungÂ 4.3.\n\n\n\n\nAbbildungÂ 4.3: Das Gesetz der groÃŸen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten WÃ¼rfelwurf\n\n\n\nHm, leider ist auf den ersten Blick kein Anzeichen fÃ¼r Schummeln bzw. einen gezinkten WÃ¼rfel zu finden (zumindest nicht zu Gunsten des Zwielichten Dozenten).\n\n4.3.3 Subjektive Wahrscheinlichkeit\nUm subjektiv zu einer Wahrscheinlichkeit zu kommen, sagt man einfach seine Meinung. Das hÃ¶rt sich natÃ¼rlich total plump an. Und tatsÃ¤chlich besteht die Gefahr, dass die so ermittelten Wahrscheinlichkeiten aus der Luft gegriffen, also haltlos, sind.\nAllerdings kann diese Art von Wahrscheinlichkeitsermittlung auch sehr wertvoll sein. In komplizierten Situation im echten Leben kommt man oft in die Situation, dass weder die epistemologische noch die frequentistische Variante verwendet werden kann. Dann muss man auf SchÃ¤tzungen, Vorwissen, Erfahrung, theoretischen Ãœberlengungen etc. zurÃ¼ckgreifen."
  },
  {
    "objectID": "0300-Wskt.html#indirekte-ermittlung-von-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#indirekte-ermittlung-von-wahrscheinlichkeiten",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.4 Indirekte Ermittlung von Wahrscheinlichkeiten",
    "text": "4.4 Indirekte Ermittlung von Wahrscheinlichkeiten\nDie indirekte Ermittlung von Wahrscheinlichkeiten meint das Ableiten von Wahrscheinlichkeitsaussagen, wenn man schon etwas Ã¼ber die Wahrscheinlichkeiten des Grundraums weiÃŸ. Dazu greift man auf Rechenregeln der Stochastik zurÃ¼ck. Das hÃ¶rt sich vielleicht wild an, ist aber oft ganz einfach.\n\nBeispiel 4.11 (Gezinkter WÃ¼rfel) Ein gezinkter WÃ¼rfel hat eine erhÃ¶hte Wahrscheinlichkeit fÃ¼r das Ereignis \\(A=\\)â€œ6 liegt obenâ€, und zwar gelte \\(Pr(A)=1/3\\). Was ist die Wahrscheinlichkeit, keine 6 zu wÃ¼rfeln?\\(\\square\\)7\n\nFÃ¼r das Rechnen mit Wahrscheinlichkeiten ist es hilfreich, ein paar Werkzeuge zu kennen, die wir uns im Folgenden anschauen."
  },
  {
    "objectID": "0300-Wskt.html#relationen-von-ereignissen",
    "href": "0300-Wskt.html#relationen-von-ereignissen",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.5 Relationen von Ereignissen",
    "text": "4.5 Relationen von Ereignissen\n\n4.5.1 Ãœberblick\nWir gehen von Grundraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge: \\(A \\subset B\\).\nDa wir Ereignisse als Mengen auffassen, verwenden wir im Folgenden die beiden Begriffe synonym.\nDabei nutzen wir u.a. Venn-Diagramme. Venn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren. Die folgenden Venn-Diagramme stammen von Wikipedia (En).\n\n\n\n\n\n\nWozu sind die Venn-Diagramme gut? Warum soll ich die lernen?\n\n\n\nVenn-Diagramme zeigen Kreise und ihre Ã¼berlappenden Teile; daraus lassen sich RÃ¼ckschlÃ¼sse auf Rechenregeln fÃ¼r Wahrscheinlichkeiten ableiten. Viele Menschen tun sich leichter, Rechenregeln visuell aufzufassen als mit Formeln und Zahlen alleine. Aber entscheiden Sie selbst!\\(\\square\\)\n\n\nDie folgende App versinnbildlicht das Rechnen mit Relationen von Ereignissen anhand von Venn-Diagrammen.\n\n\n4.5.2 Vereinigung von Ereignissen\n\nDefinition 4.9 (Vereinigung von Ereignissen) Vereinigt man zwei Ereignisse \\(A\\) und \\(B\\), dann besteht das neue Ereignis \\(C\\) genau aus den Elementarereignissen der vereinigten Ereignisse. Man schreibt \\(C = A \\cup B\\), lies: â€œC ist A vereinigt mit Bâ€.\\(\\square\\)\n\nAbbildungÂ 4.4 zeigt ein Venn-Diagramm zur Verdeutlichung der Vereinigung von Ereignissen.\n\n\nAbbildungÂ 4.4: \\(A \\cup B\\)\n\n\nBeispiel 4.12 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem nÃ¤chsten Wurf mindestens eines der beiden Ereignisse \\(A\\) oder \\(B\\) eintreten.\n\\[\\begin{aligned}\nA = \\{1,2\\} \\qquad \\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}} \\\\\nB = \\{2,3\\} \\qquad  \\boxed{1\\; \\boxed{2\\; 3}\\; \\color{gray}{ 4\\; 5\\; 6}} \\\\\n\\newline\n\\hline \\\\\nA \\cup B = \\{1,2,3\\} \\qquad \\boxed{\\boxed{1\\; 2\\; 3}\\; \\color{gray}{4\\; 5\\; 6}}\n\\end{aligned}\\]\n\nZur besseren Verbildlichung betrachten Sie mal diese Animation zur Vereinigung von Mengen; Quelle.\nIn R heiÃŸt die Vereinigung von Mengen union(). Praktisch zum Ausprobieren:\n\nA &lt;- c(1, 2)\nB &lt;- c(2, 3)\n\nunion(A, B)\n## [1] 1 2 3\n\n\n4.5.3 (Durch-)Schnitt von Ereignissen\n\nDefinition 4.10 (Schnittmenge von Ereignissen) Die Schnittmenge zweier Ereignisse \\(A\\) und \\(B\\) umfasst genau die Elementarereignisse, die Teil beider Ereignisse sind. Man schreibt: \\(A \\cap B.\\)8 Lies: â€œA geschnitten Bâ€. \\(\\square\\)\n\nAbbildungÂ 4.5 zeigt ein Sinnbild zur Schnittmenge zweier Ereignisse.\n\n\nAbbildungÂ 4.5: \\(A \\cap B\\)\n\n\nBeispiel 4.13 Um einen (hohen!) Geldpreis zu gewinnen, muss bei ihrem nÃ¤chsten Wurf sowohl das Ereignis \\(A\\) = â€œgerade Augenzahlâ€ als auch \\(B\\) = â€œAugenzahl grÃ¶ÃŸer 4â€.\n\\[\\begin{align}\n& A = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n& B = \\{5,6\\} \\qquad \\qquad \\hfill  \\boxed{ \\color{gray}{1\\; 2\\; 3\\; 4\\;} \\boxed{\\color{black}{5\\; 6}}} \\\\\n\\newline\n\\hline \\\\\n& A \\cap B = \\{6\\} \\qquad \\qquad \\hfill  \\boxed{\\color{gray}{1\\; 2\\; 3\\; 4\\; 5\\;} \\color{black}{6}}\n\\end{align}\\]\n\n\nA &lt;- c(2, 4, 6)\nB &lt;- c(5, 6)\nintersect(A, B)\n## [1] 6\n\n\n\n\n\n\n\nEselsbrÃ¼cke zur Vereinigungs- und Schnittmenge\n\n\n\nDas Zeichen fÃ¼r eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen fÃ¼r einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine EselbrÃ¼cke gelesen, s. AbbildungÂ 4.6.\n\n\nAbbildungÂ 4.6: EselsbrÃ¼cke fÃ¼r Vereinigungs- und Schnittmenge\n\n\n\n\n4.5.4 KomplementÃ¤rereignis\n\nDefinition 4.11 (KomplementÃ¤rereignis) Ein Ereignis \\(A\\) ist genau dann ein KomplementÃ¤rereignis zu \\(B\\), wenn es genau die Elementarereignisse von \\(\\Omega\\) umfasst, die nicht Elementarereignis des anderen Ereignisses sind, s. AbbildungÂ 4.7.\\(\\square\\)\n\nMan schreibt fÃ¼r das KomplementÃ¤rereignis von \\(A\\) oft \\(\\bar{A}\\) oder \\(\\neg A\\)9; lies â€œNicht-Aâ€ oder â€œA-querâ€.\n\nBeispiel 4.14 Beim normalen WÃ¼rfelwurf sei \\(A\\) das Ereignis â€œgerade Augenzahlâ€; das KomplementÃ¤rereignis ist dann \\(\\neg A\\) â€œungerade Augenzahlâ€.\n\\[\\begin{align}\nA = \\{2,4,6\\} \\qquad \\hfill \\boxed{\\color{gray}{1}\\; \\boxed{\\color{black}{2}}\\; \\color{gray}{3}\\; \\boxed{\\color{black}{4}}\\; \\color{gray}{5}\\; \\boxed{\\color{black}{6}}\\;} \\\\\n\\hline \\\\\n\\neg A = \\{1,3,5\\} \\qquad  \\hfill \\boxed{\\boxed{\\color{black}{1}}\\; \\color{gray}{2}\\; \\boxed{\\color{black}{3}}\\; \\color{gray}{4}\\; \\boxed{\\color{black}{5}}\\; \\color{gray}{6}\\; } \\\\\n\\end{align}\\]\n\n\n\nAbbildungÂ 4.7: \\(\\bar{A}\\)\n\n\n4.5.5 Logische Differenz\n\nDefinition 4.12 (Logische Differenz) Die logische Differenz der Ereignisse \\(A\\) und \\(B\\) ist das Ereignis, das genau aus den Elementarereignissen besteht von \\(A\\) besteht, die nicht zugleich Elementarereignis von \\(B\\) sind, s. AbbildungÂ 4.8.\\(\\square\\)\n\nDie logische Differenz von \\(A\\) zu \\(B\\) schreibt man hÃ¤ufig so: \\(A \\setminus B\\); lies â€œA minus Bâ€.\n\n\nAbbildungÂ 4.8: \\(A \\setminus B\\)\n\n\nBeispiel 4.15 Sei \\(A\\) die Menge â€œgroÃŸe Zahlenâ€ mit \\(A = \\{4,5,6 \\}\\). Sei \\(B\\) die Menge â€œgerade Zahlenâ€. Wir suchen die logische Differenz, \\(A \\setminus B\\).\n\\[\\begin{align}\nA = \\{4,5, 6\\} \\qquad \\hfill \\boxed{4\\; 5\\; 6} \\\\\nB = \\{2,4,6\\} \\qquad  \\hfill \\boxed{2\\; 4\\; 6} \\\\\n\\hline \\\\\nA \\setminus B \\qquad \\hfill \\boxed{5}\n\\end{align}\\]\n\nIn R gibt es die Funktion setdiff(), die eine Mengendifferenz ausgibt.\n\nA &lt;- c(4, 5, 6)\nB &lt;- c(2, 4, 6)\n\nsetdiff(A, B)\n## [1] 5\n\nğŸ¤¯ Von der Menge \\(A\\) die Menge \\(B\\) abzuziehen, ist etwas anderes, als von \\(B\\) die Menge \\(A\\) abzuziehen:\n\nsetdiff(B, A)\n## [1] 2\n\n\n\n\n\n\n\nVorsicht\n\n\n\n\\(A \\setminus B \\ne B \\setminus A\\).\n\n\n\n4.5.6 Disjunkte Ereignisse\nSeien \\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\).\n\\(A\\) und \\(B\\) sind disjunkt10: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. AbbildungÂ 4.9\n\n\nAbbildungÂ 4.9: Zwei disjunkte Ereignisse, dargestellt noch Ã¼berlappungsfreie Kreise\n\nQuelle: rither.de\n\nBeispiel 4.16 Â \n\nDas Ereignis \\(A\\) â€œGerade Augenzahl beim WÃ¼rfelwurfâ€, \\(A={2,4,6}\\) und das Ereignis \\(B\\) â€œUngerade Augenzahl beim WÃ¼rfelwurfâ€, \\(B={1,3,5}\\) sind disjunkt.\nDie Ereignisse â€œnormaler Wochentagâ€ und â€œWochenendeâ€ sind disjunkt.\\(\\square\\)\n\n\n\n4.5.7 Vertiefung\nAnimation zu Mengenoperationen"
  },
  {
    "objectID": "0300-Wskt.html#seq-kolmogorov",
    "href": "0300-Wskt.html#seq-kolmogorov",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.6 Anforderungen an Wahrscheinlichkeiten",
    "text": "4.6 Anforderungen an Wahrscheinlichkeiten\nWir richten eine Reihe von Forderungen an eine Definition von bzw. an das Rechnen mit Wahrscheinlichkeiten, die direkt plausibel erscheinen:11\n\n\nNichtnegativitÃ¤t: Die Wahrscheinlichkeit eines Ereignisses kann nicht negativ sein.\n\nNormierung: Das sichere Ereignis hat die Wahrscheinlichkeit 1 bzw. 100%: \\(Pr(\\Omega)=1\\); das unmÃ¶gliche Ereignis hat die Wahrscheinlichkeit 0: \\(Pr(\\emptyset)=0\\).\n\nAdditivitÃ¤t. Sind \\(A\\) und \\(B\\) disjunkt, dann ist die Wahrscheinlichkeit von \\(A\\cup B\\) die Summe der beiden Einzelwahrscheinlichkeiten von \\(A\\) und \\(B\\)."
  },
  {
    "objectID": "0300-Wskt.html#rechnen-mit-wahrscheinlichkeiten",
    "href": "0300-Wskt.html#rechnen-mit-wahrscheinlichkeiten",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.7 Rechnen mit Wahrscheinlichkeiten",
    "text": "4.7 Rechnen mit Wahrscheinlichkeiten\n\n4.7.1 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse eintritt.\n\n4.7.1.1 Disjunkte Ereignisse\nGegeben sei \\(\\Omega = {1,2,3,4,5,6}\\). Als Sinnbild: \\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\).\nGesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\).\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\n\\(P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\nBeispiel 4.17 Was ist die Wahrscheinlichkeit, an einem Samstag oder Sonntag geboren zu sein? Unter der (etwas vereinfachten) Annahme, dass alle Jahre zu gleichen Teilen aus allen Wochentagen bestehen, ist die Antwort \\(Pr(A)=1/7 + 1/7 = 2/7\\).\\(\\square\\)\n\n\n4.7.1.2 Allgemein (disjunkt oder nicht disjunkt)\nBei der Addition der Wahrscheinlichkeiten fÃ¼r \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) doppelt erfasst.12 Er muss daher noch abgezogen werden.\n\nDefinition 4.13 (Allgemeiner Additionssatz) Die Wahrscheinlichkeit, dass mindestens eines der beiden Ereignisse \\(A\\) und \\(B\\) eintritt, ist gleich der Summe ihrer Wahrscheinlichkeiten minus ihrer gemeinsamen Wahrscheinlichkeit, s. GleichungÂ 4.2.\n\\[P(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\square \\tag{4.2}\\]\n\n\n\n\n\n\n\n\nBeispiel 4.18 (Lernen und Klausur bestehen) In einem angewandten Psychologie-Studiengang sind die Studis verdonnert, zwei Statistik-Module (\\(S1, S2\\)) zu belegen. Die meisten bestehen (\\(B\\)), einige leider nicht (\\(N\\)), s. tbl-klausur2.\nEreignis \\(A\\) ist â€œKlausur Statistik 1â€ mit den Ergebnissen â€œbestandenâ€ und â€œnicht bestandenâ€. Ereignis \\(B\\) ist analog fÃ¼r â€œKlausur Statistik 2â€.\nWir suchen die Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen: \\(Pr(S_1B \\cup S_2B)\\). Nennen wir das Ereignise \\(A\\).\n\n\n\n\nTabelleÂ 4.1: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n.\nS1_B\nS1_NB\nSumme\n\n\n\nS2_B\n85\n9\n94\n\n\nS2_NB\n5\n1\n6\n\n\nSumme\n90\n10\n100\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(A) &= Pr(S_1B \\cup S_2B) \\\\\n&= Pr(S1_B) + Pr(S_2B) - Pr(S_1B \\cap S_2B)  \\\\\n&= (90 + 94 - 85) / 100 = 99 / 100\\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, mindestens eine der beiden Klausuren zu bestehen liegt bei 99%. Umgekehrt liegt die Wahrscheinlichkeit, keine der beiden Klausuren zu bestehen, liegt bei \\(Pr(\\neg A) = 1- Pr(A) = 0.01 = 1\\%\\); ein Sachverhalt, der sich auch mit einem kurzen Blick in die Datentabelle erkennen lÃ¤sst.\\(\\square\\)\n\n\n4.7.2 Bedingte Wahrscheinlichkeit\n\nDefinition 4.14 (Bedingte Wahrscheinlichkeit) Die Bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit, dass \\(A\\) eintritt, gegeben dass \\(B\\) schon eingetreten ist. \\(\\square\\)\n\nMan schreibt: \\(Pr(A|B).\\) Lies: â€œA gegeben Bâ€ oder â€œA wenn Bâ€.\n\nÃœbungsaufgabe 4.3 Schauen Sie sich mal diese Wahnsinnsanimation von Victor Powell an zu bedingten Wahrscheinlichkeiten. Hammer!\n\n\n4.7.2.1 Schema\nAbbildungÂ 4.10 illustriert gemeinsame Wahrscheinlichkeit, \\(P(A \\cap B)\\), und bedingte Wahrscheinlichkeit, \\(P(A|B)\\).\n\n\n\n\nAbbildungÂ 4.10: Illustration von gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\n\nBeispiel 4.19 (Bedingte Wahrscheinlichkeit) Sei \\(A\\) â€œSchÃ¶nes Wetterâ€ und \\(B\\) â€œKlausur steht anâ€. Dann meint \\(Pr(A|B)\\) die Wahrscheinlichkeit, dass das Wetter schÃ¶n ist, wenn gerade eine Klausur ansteht.\\(square\\)\n\n\nBeispiel 4.20 (Von PÃ¤psten und MÃ¤nnern) Man(n) beachte, dass die Wahrscheinlichkeit, Papst \\(P\\) zu sein, wenn man Mann \\(M\\) ist etwas anderes ist, als die Wahrscheinlichkeit, Mann zu sein, wenn man Papst ist: \\(Pr(P|M) \\ne Pr(M|P)\\). Das hÃ¶rt sich erst verwirrend an, aber wenn man darÃ¼ber nachdenkt, wird es sehr plausibel.\\(\\square\\)\n\n\nBeispiel 4.21 (Kalt und Regen) Die Wahrscheinlichkeit, dass es kalt ist, wenn es regnet, ist gleich der Wahrscheinlichkeit, dass es gleichzeitig kalt ist und regnet geteilt durch die Wahrscheinlichkeit, dass es regnet.\\(\\square\\)\n\n\nBeispiel 4.22 Gustav GroÃŸ-GÃ¼tz verkauft eine Tinktur13, die schlau machen soll, â€œGÃ¼tzi Gehirn GrÃ¼tzeâ€.14 Gustav trinkt die GrÃ¼tze und sagt schlaue Dinge. Was schlieÃŸen wir daraus? Sei \\(H\\) (wie Hypothese) â€œGÃ¼tzis GrÃ¼tze macht schlauâ€; sei \\(D\\) (wie Daten) die Beobachtung, dass Gustav schlaue Dinge gesagt hat. Ohne exakte Zahlen zu suchen, wie hoch ist wohl \\(Pr(D|H)\\)? In Worten: â€œWie wahrscheinlich ist es, schlaue Dinge gesagt zu haben, wenn die GrÃ¼tze wirklich schlau macht?â€. Vermutlich ist diese Wahrscheinlichkeit sehr hoch. Aber wie hoch ist wohl \\(Pr(H|D)\\)? In Worten: â€œWie wahrscheinlich ist es, dass die GrÃ¼tze wirklich schlau macht, gegeben, dass wir gesehen hat, dass jemand etwas schlaues gesagt hat, nachdem er besagte GrÃ¼tze getrunken hat?â€ Skeptische Geister werden der Meinung sein, \\(Pr(H|D)\\) ist gering. Das Beispiel zeigt u.a. \\(Pr(H|D) \\ne Pr(D|H).\\square\\)\n\nDas Berechnen einer bedingten Wahrscheinlichkeit, \\(Pr(A|B)\\), ist vergleichbar zum Filtern einer Tabelle:\n\n\n\n\nid\nA\nB\n\n\n\n1\n0\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n1\n1\n\n\nSUMME\n2\n2\n\n\n\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(P(A) = 2/4\\)\n\\(P(B) = 2/4\\)\n\\(P(A \\cap B) = 1/4\\)\n\\(P(A|B) = 1/2\\)\n\n4.7.2.2 Rechenregel\nDie Wahrscheinlichkeit fÃ¼r \\(A\\), wenn \\(B\\) schon eingetreten ist, berechnet sich so, s. GleichungÂ 4.3.\n\\[Pr(A|B) = \\frac{Pr(A \\cap B)}{Pr(B)} \\tag{4.3}\\]\n\nBeispiel 4.23 (Lernen und Klausur bestehen) Sie bereiten sich gerade auf die Klausur bei Prof.Â SÃ¼ÃŸ vor. Das heiÃŸt: Sie Ã¼berlegen, ob Sie sich auf die Klausur vorbereiten sollten. Vielleicht lohnt es sich ja gar nicht? Vielleicht ist die Wahrscheinlichkeit zu bestehen, wenn man nicht gelernt hat, sehr groÃŸ? Aber da Sie nun mal auf Fakten stehen, haben Sie sich nach einiger Recherche folgende Zahlen besorgen kÃ¶nnen, s. TabelleÂ 4.2. In der Tabelle sind die Daten von 100 Studis ausgewiesen. Ein Teil hat sich vorbereitet, ordentlich gelernt, nenen wir sie die â€œLerner. Ein anderer Teil hat nicht gelernt, \\(NL\\) bzw. \\(\\neg L\\). Ein Teil hat bestanden, \\(B\\), ein Teil nicht \\(NB\\) oder \\(\\neg B\\).\nWir suchen die Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat: \\(Pr(B |\\neg L)\\).\n\n\n\n\nTabelleÂ 4.2: Daten von 100 Studis; L: Lerner, B: Bestanden, N: Negation/Nicht\n\n.\nL\nNL\nSumme\n\n\n\nB\n80\n1\n81\n\n\nNB\n5\n14\n19\n\n\nSumme\n85\n15\n100\n\n\n\n\n\n\n\\[\\begin{aligned}\nPr(B |\\neg L) &= \\frac{Pr(B \\cap \\neg L)}{Pr(\\neg L)} \\\\\n&=\\frac{1/100}{15/100} = 1/15 \\\\\n\\end{aligned}\\]\nDie Wahrscheinlichkeit, zu bestehen, wenn man nicht gelernt hat, liegt bei 1 von 15, also ca. 7%.\\(\\square\\)\n\n\n4.7.3 Stochastische (Un-)AbhÃ¤ngigkeit\nStochastische UnabhÃ¤ngigkeit ist ein Spezialfall von AbhÃ¤ngigkeit: Es gibt sehr viele AusprÃ¤gungen fÃ¼r AbhÃ¤ngigkeit, aber nur eine fÃ¼r UnabhÃ¤ngigkeit. KÃ¶nnen wir UnabhÃ¤ngigkeit nachweisen, haben wir also eine starke Aussage getÃ¤tigt.\n\nDefinition 4.15 (Stochastische UnabhÃ¤ngigkeit) Zwei Ereignisse sind (stochastisch) unabhÃ¤ngig voneinander, wenn die Wahrscheinlichkeit von \\(A\\) nicht davon abhÃ¤ngt, ob \\(B\\) der Fall ist, s. GleichungÂ 4.4. Dann gilt:15\n\\[P(A|B) = P(A) = P(A|\\neg B). \\square \\tag{4.4}\\]\n\n\nBeispiel 4.24 (Augenfarbe und Statistikliebe) Ich vermute, dass die Ereignisse \\(A\\), â€œAugenfarbe ist blauâ€, und \\(B\\), â€œIch liebe Statistikâ€, voneinander unabhÃ¤ngig sind.\\(\\square\\)16\n\n\nBeispiel 4.25 (Ãœberleben auf der Titanic) AbhÃ¤ngig, s. AbbildungÂ 4.11, links: Ãœberleben auf der Titanic ist offenbar abhÃ¤ngig von der Passagierklasse. Auf der anderen Seite: Das Ereignis Ãœberleben auf der Titanic ist unabhÃ¤ngig vom Ereignis Alter ist eine Primzahl, s. AbbildungÂ 4.11, rechts.\\(\\square\\)\n\n\n\n\n\nAbbildungÂ 4.11: AbhÃ¤ngigkeit und UnabhÃ¤ngigkeit zweier Ereignisse\n\n\n\nZur Ab- bzw. Un-AbhÃ¤ngigkeit zweier Variablen, an Beispielen illustriert.\n\nBeispiel 4.26 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land17 (\\(B\\)) voneinander abhÃ¤ngig ( AbbildungÂ 4.12)?\n\n\n\n\nAbbildungÂ 4.12: Impfquote und Sterblichkeit sind voneinander abhÃ¤ngig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\n\nJa, da in beiden Diagrammen gilt: \\(P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\\(\\square\\)18\n\n\n4.7.4 Multiplikationssatz\nGegeben seien die Ereignisse \\(A\\) und \\(B\\). Der Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass beide Ereignisse \\(A\\) und \\(B\\) eintreten.\n\n4.7.4.1 UnabhÃ¤ngige Ereignisse\n\nBeispiel 4.27 Wir fÃ¼hren das Zufallsexperiment â€œWurf einer fairen MÃ¼nzeâ€ zwei Mal aus (AbbildungÂ 4.13). Wie groÃŸ ist die Wahrscheinlichkeit, 2 Mal Kopf zu werfen?\\(\\square\\)\n\n\n\nAbbildungÂ 4.13: Wir werfen zwei faire MÃ¼nzen\n\nAbbildungÂ 4.13 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom â€œStartâ€ (schwarzer Kreis) fÃ¼hren zwei mÃ¶gliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch BlÃ¤tter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen MÃ¼nzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der BlÃ¤tter. In diesen Diagramm gibt es vier Pfade (und BlÃ¤tter).\nDen Wurf der ersten MÃ¼nze nennen wir in gewohnter Manier \\(A\\); den Wurf der zweiten MÃ¼nze \\(B\\).\nDie Wahrscheinlichkeiten der resultierenden Ereignisse finden sich in TabelleÂ 4.3.\n\n\n\n\nTabelleÂ 4.3: Wahrscheinlichkeiten der Ereignisse im zweimaligen MÃ¼nzwurf\n\nEreignis\nPr\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\nSei \\(K_1\\) das Ereignis, mit der 1. MÃ¼nze Kopf zu werfen; sei \\(K_2\\) das Ereignis, mit der 2. MÃ¼nze Kopf zu werfen-\nWir suchen \\(Pr(K_1 \\cap K_2)\\). Aufgrund der stochastischen UnabhÃ¤ngigkeit der beiden Ereignisse gilt: \\(Pr(K_1 \\cap K_2) = Pr(K_1) \\cdot Pr(K_2)\\).\n\nPr_K1K2 &lt;- 1/2 * 1/2\nPr_K1K2\n## [1] 0.25\n\n\nDefinition 4.16 (Multiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse) Die Wahrscheinlichkeit, dass zwei unabhÃ¤ngige Ereignisse \\(A\\) und \\(B\\) gemeinsam eintreten, ist gleich dem Produkt ihrer jeweiligen Wahrscheinlichkeiten, s. ?eq-multtheorem.\n\\(Pr(A \\cap B) = Pr(AB) = Pr(A) \\cdot Pr(B) = Pr(B\\cap A) = Pr(B) \\cdot Pr(A).\\square.\\){#eq-multtheorem}\n\nMit dieser App kÃ¶nnen Sie das Baumdiagramm fÃ¼r den zweifachen MÃ¼nzwurf nÃ¤her erkunden.\n\nWir fÃ¼hren das Zufallsexperiment â€œWurf einer fairen MÃ¼nzeâ€ drei Mal aus (AbbildungÂ 4.14).\n\n\nAbbildungÂ 4.14: Wir werfen drei faire MÃ¼nzen\n\nBeim Wurf von â€œfairenâ€ MÃ¼nzen gehen wir davon aus, dass Kenntnis des Ergebnis des 1. Wurfes unsere EinschÃ¤tzung des Ergebnis des 2. Wurfes nicht verÃ¤ndert etc. Anders gesagt: Wir gehen von (stochastischer) UnabhÃ¤ngigkeit aus.\nFÃ¼r z.B. das Ereignis \\(A=\\{ZZZ\\}\\) gilt: \\(Pr(A) = 1/2 \\cdot 1/2 \\cdot 1/2 = (1/2)^3\\). Da jeder Endknoten (jedes Blatt) gleichwahrscheinlich ist, ist die Wahrscheinlichkeit jeweils gleich.\nAllgemeiner gilt: FÃ¼r ein Zufallsexpriment, das aus \\(k\\) Wiederholungen besteht und in jeder Wiederholung die Wahrscheinlichkeit \\(Pr(X)=p\\) ist, so ist die Wahrscheinlichkeit fÃ¼r einen Endkonten \\(Pr(X^k)=p^k\\).\n\n\n\n\n TabelleÂ 4.4:  AusgewÃ¤hlte Wahrscheinlichkeiten von Ereignissen im dreifachen\nMÃ¼nzwurf \n  \n\n\n\n\nDa die Endknoten disjunkte Elementarereignisse sind, kann man ihre Wahrscheinlichkeit addieren, um zu anderen (zusammengesetzten) Ereignissen zu kommen, vgl. TabelleÂ 4.4.\nAbbildungÂ 4.15 versinnbildlicht zwei unabhÃ¤ngige Ereignisse, \\(A\\) und \\(B\\), wobei die Wahrscheinlichkeit gleich ist \\(Pr(A)=Pr(B)=.5\\). Man sieht, dass die Wahrscheinlichkeit von \\(A\\) bzw. von \\(B\\) jeweils die HÃ¤lfte der FlÃ¤che ausmacht. Die Schnittmenge der FlÃ¤che von \\(A\\) und \\(B\\) entspricht einem Viertel der FlÃ¤che: \\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%.\\) In diesem Fall sind \\(A\\) und \\(B\\) unabhÃ¤ngig.\n\n\n\n\nAbbildungÂ 4.15: UnabhÃ¤ngige Ereignisse visualisiert\n\n\n\nAbbildungÂ 4.15 zeigt weiterhin, dass gilt: \\(P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\).\n\nBeispiel 4.28 (Kalt und Regen) Von McElreath (2020) stammt diese Verdeutlichung der gemeinsamen Wahrscheinlichkeit:\nWas ist die Wahrscheinlichkeit fÃ¼r kalt â„ und Regen â›ˆï¸?\nDie Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von Regen â›ˆ, wennâ€™s kalt â„ ist mal die Wahrscheinlichkeit von KÃ¤lte â„.\nEbenfalls gilt:\nDie Wahrscheinlichkeit fÃ¼r kalt und Regen ist die Wahrscheinlichkeit von KÃ¤lte â„, wennâ€™s regnet â›ˆï¸ mal die Wahrscheinlichkeit von Regen â›ˆï¸.\nDas Gesagte als Emoji-Gleichung:\n\\(P(â„ï¸ \\text{ und } â›ˆï¸) = P(â›ˆï¸ |â„ï¸ ) \\cdot P(â„ï¸) = P(â„ï¸ |â›ˆï¸ ) \\cdot P(â›ˆï¸) = P(â›ˆ \\text{ und } â„ï¸)\\) Man kann also die â€œGleichung drehenâ€.19\\(\\square\\)\n\n\nDefinition 4.17 (Kettenregel) Allgemein gesagt, spricht man von der Kettenregel der Wahrscheinlichkeitsrechnung, s. ?eq-kette.\n\\(P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\square\\){#eq-kette}\nIn Worten: Die Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) ist gleich der Wahrscheinlichkeit von \\(A\\) mal der Wahrscheinlichkeit von \\(B\\) gegeben \\(A\\).\n\n\n4.7.4.2 AbhÃ¤ngige Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung abhÃ¤ngiger Ereignisse an, s. AbbildungÂ 4.16. FÃ¼r unabhÃ¤ngige Ereignisse Ã¼brigens auch.\n\nBeispiel 4.29 In einer Urne befinden sich fÃ¼nf Kugeln, von denen vier rot sind und eine blau ist.\nwie groÃŸ ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne ZurÃ¼cklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier 2018), S. 47.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. AbbildungÂ 4.16.\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|4/5|B[1. Zug: R]\n  A --&gt;|1/5|C[1. Zug: B]\n  B --&gt;|3/4|D[2. Zug: R]\n  B --&gt;|1/4|E[2. Zug: B]\n  D --- H[Fazit: RR:  12/20]\n  E --- I[Fazit: RB: 4/20]\n  C --&gt;|4/4|F[2. Zug: R]\n  C --&gt;|0/4|G[2. Zug: B]\n  F --- J[Fazit: BR: 4/20]\n  G --- K[Fazit: BB: 0/20]\n\n\nAbbildungÂ 4.16: Baumdiagramm fÃ¼r ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abhÃ¤ngig ist vom 1. Zug.\n\n\n\nEs gilt also: \\(P(A\\cap B) = P(A) \\cdot P(B|A) \\square\\).\n\n\nBeispiel 4.30 (Bertie Botts Bohnen jeder Geschmacksrichtung) Â \n\nSei bloÃŸ vorsichtig mit denen. Wenn sie sagen jede Geschmacksrichtung, dann meinen sie es auch - Du kriegst zwar alle gewÃ¶hnlichen wie Schokolade und Pfefferminz und Erdbeere, aber auch Spinat und Leber und Kutteln. George meint, er habe mal eine mit Popelgeschmack gehabt.â€œ\n\nâ€” Ron Weasley zu Harry Potter20\nIn einem Beutel liegen \\(n=20\\) Bertie Botts Bohnen jeder Geschmacksrichtung. Uns wurde verraten, dass fast alle gut schmecken, also z.B. nach Schokolade, Pfefferminz oder Marmelade. Leider gibt es aber auch \\(x=3\\) furchtbar scheuÃŸliche Bohnen (Ohrenschmalz-Geschmacksrichtung oder Schlimmeres). Sie haben sich nun bereit erklÃ¤rt, \\(k=3\\) Bohnen zu ziehen. Und zu essen, und zwar direkt und sofort! Also, jetzt heiÃŸt es tapfer sein. Ziehen und runter damit!\nWie groÃŸ ist die Wahrscheinlichkeit, genau eine scheuÃŸliche Bohne zu erwischen?\nNutzen Sie diese App, um das auszuprobieren. Sie mÃ¼ssen in der App noch die Zahl der Bohnen (\\(n\\)) und die Zahl der scheuÃŸlichen Bohnen (\\(x\\)) einstellen.\\(\\square\\)\n\n\n4.7.5 Baumdiagramm sucht Problem\nÃœberlegen Sie sich eine Problemstellung (Aufgabenstellung), die mit folgender Baumdiagramm-App gelÃ¶st werden kann.\\(\\square\\)\n\n\n4.7.6 Totale Wahrscheinlichkeit\nAbbildungÂ 4.17 zeigt das Baumdiagramm fÃ¼r die Aufgabe Bourier (2018), S. 56.\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[A1]\n  A --&gt;|0.1|C[A2]\n  A --&gt;|0.3|D[A3]\n  B --&gt;|0.05|E[B]\n  B -.-&gt;|0.95|F[Nicht-B]\n  C --&gt;|0.02|G[B]\n  C -.-&gt;|0.98|H[Nicht-B]\n  D --&gt;|0.04|I[B]\n  D -.-&gt;|0.96|J[Nicht-B]\n\n\nAbbildungÂ 4.17: Totale Wahrscheinlichkeit\n\n\n\nGesucht ist die Wahrscheinlichkeit \\(P(B)\\); \\(A\\) ist ein vollstÃ¤ndiges Ereignissystem.\nDazu addieren wir die Wahrscheinlichkeiten der relevanten Ã„ste. Jeder Ast stellt wiederum das gemeinsame Auftreten der Ereignisse \\(A_i\\) und \\(B\\) dar.\n\nW_Ast1 &lt;- 0.6 * 0.05  # Wahrscheinlichkeit fÃ¼r Ast 1\nW_Ast2 &lt;- 0.1 * 0.02  # ... Ast 2\nW_Ast3 &lt;- 0.3 * 0.04  # ... Ast 3\nW_total &lt;- W_Ast1 + W_Ast2 + W_Ast3  # totale W.\nW_total\n## [1] 0.044\n\nDie totale Wahrscheinlichkeit betrÃ¤gt in diesem Beispiel also \\(P(B) = 4.4\\%\\).21\n\nDefinition 4.18 (Totale Wahrscheinlichkeit) Bilden die Ereignisse \\(A_1, A_2, ..., A_n\\) ein vollstÃ¤ndiges Ereignissystem und ist \\(B\\) ein beliebiges Ereignis dann gilt \\(Pr(B) = \\sum_{i=1}^n Pr(A_i) \\cdot Pr(B|A_i).\\square\\)\n\n\nIn AbbildungÂ 4.17 gilt \\(Pr(B) = 0.6 \\cdot 0.05 + 0.1 \\cdot 0.02 + 0.3 \\cdot 0.04 = 0.03 + 0.002 + 0.012 = 0.04.\\square\\)\n\n\nBeispiel 4.31 (Bertie Botts Bohnen jeder Geschmacksrichtung, Teil 2) Es ist die gleich Aufgabe wie BeispielÂ 4.30, aber jetzt lautet die Frage: Wie groÃŸ ist die Wahrscheinlichkeit, mindestens eine scheuÃŸliche Bohne zu erwischen?\\(\\square\\)"
  },
  {
    "objectID": "0300-Wskt.html#bayes-theorem",
    "href": "0300-Wskt.html#bayes-theorem",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.8 Bayesâ€™ Theorem",
    "text": "4.8 Bayesâ€™ Theorem\n\n4.8.1 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes hÃ¤ufig, wenn man Daten zu einer Wirkung \\(W\\) hat, und auf die Ursache \\(U\\) zurÃ¼ckschlieÃŸen mÃ¶chte, sinngemÃ¤ÃŸ:\n\\[W \\quad \\underrightarrow{Bayes} \\quad U\\]\nDann kann man GleichungÂ 4.7 so schreiben, s. GleichungÂ 4.5:\n\\[P(U|W) = \\frac{ P(U) \\cdot P(W|U) }{P(W)} \\tag{4.5}\\]\nEine Ã¤hnliche Situation, die in der Praxis hÃ¤ufig ist, dass man Daten \\(D\\) hat und auf die Wahrscheinlichkeit einer Hypothese \\(H\\) schlieÃŸen mÃ¶chte, s. GleichungÂ 4.6.\n\\[D \\quad \\underrightarrow{Bayes} \\quad H\\]\n\\[P(H|D) = \\frac{ P(H) \\cdot P(D|H) }{P(D)} \\tag{4.6}\\]\nGleichungÂ 4.6 fragt nach \\(P(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (GleichungÂ 4.6):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der PlausibilitÃ¤t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus StandardisierungsgrÃ¼nden dividiert man noch die totale Wahrscheinlichkeit der Daten Ã¼ber alle Hypothesen.\n\n\n4.8.2 Bayes als Baum\nGesucht sei \\(P(A_1|B)\\).\nFÃ¼r Bayesâ€™ Formel22 setzt man die Wahrscheinlichkeit des gÃ¼nstigen Ast zur Wahrscheinlichkeit aller relevanten Ã„ste, \\(P(B)\\).\n\nBeispiel 4.32 (Maschine produziert Ausschuss) Die drei Maschinen \\(M_1, M_2, M_3\\) produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. AbbildungÂ 4.18. Aufgabe: Wie groÃŸ ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde?$\n\nDer gÃ¼nstige (gesuchte) Ast ist hier schwarz gedruckt, die Ã¼brigen Ã„ste gestrichelt, s. AbbildungÂ 4.18. \\(A_i\\) zeigt das Ereignis, dass der Artikel von Maschine \\(i\\) produziert wurde. \\(B\\) ist das Ereignis â€œArtikel ist Ausschussâ€.\n\n\n\n\nflowchart LR\n  A[Start] --&gt;|0.6|B[A1]\n  A -.-&gt;|0.1|C[A2]\n  A -.-&gt;|0.3|D[A3]\n  B ---&gt;|0.05|E[B]\n  B -.-&gt;|0.95|F[Nicht-B]\n  C -.-&gt;|0.02|G[B]\n  C -.-&gt;|0.98|H[Nicht-B]\n  D -.-&gt;|0.04|I[B]\n  D -.-&gt;|0.96|J[Nicht-B]\n\n\nAbbildungÂ 4.18: GÃ¼nstige Pfade\n\n\n\n\\[P(A|B) = \\frac{P(A1 \\cap B)}{P(B)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(P(A|B)\\) betrÃ¤gt also ca. 68%.\nZur Erinnerung: \\(P(B)\\) ist die totale Wahrscheinlichkeit.\n\n4.8.3 Bayes als bedingte Wahrscheinlichkeit\nBayesâ€™ Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:\n\\(P(A|B) = \\frac{\\overbrace{ P(A\\cap B)}^\\text{umformen}}{P(B)}\\)\n\\(P(A| B)\\) kann man umformen, s. GleichungÂ 4.7:\n\\[P(A|B) =\\frac{P(A\\cap B)}{P(B)} = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\tag{4.7}\\]\nMan kann sich Bayesâ€™ Theorem auch wie folgt herleiten:\n\\(P(A\\cap B) = P(B \\cap A) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\nDann lÃ¶sen wir nach P\\((A|B)\\) auf:\n\\(P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(B)}\\)\n\n4.8.4 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayesâ€™ Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel wÃ¤re: â€œWas ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?â€.\nDas sieht dann so aus, GleichungÂ 4.8:\n\\[\n\\begin{aligned}\nP(R \\cap B |K) &= \\frac{ P(R \\cap B) \\cdot P(K|R \\cap B) }{P(D)} \\\\\n&= \\frac{ P(R ) \\cdot P(B) \\cdot P(K|R \\cap B) }{P(D)}\n\\end{aligned}\n\\tag{4.8}\\]\nHier haben wir \\(P(R \\cap B)\\) aufgelÃ¶st in \\(P(R) \\cdot P(B)\\), das ist nur zulÃ¤ssig, wenn \\(R\\) und \\(B\\) unabhÃ¤ngig sind."
  },
  {
    "objectID": "0300-Wskt.html#vertiefung-1",
    "href": "0300-Wskt.html#vertiefung-1",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.9 Vertiefung",
    "text": "4.9 Vertiefung\nBei Henze (2019) findet sich eine anspruchsvollere EinfÃ¼hrung in das Rechnen mit Wahrscheinlichkeit; dieses Kapitel behandelt ein Teil des Stoffes der Kapitel 2 und 3 von Henze (2019).\nMit dieser App, die ein zweistufiges Baumdiagramm zeigt, kÃ¶nnen Sie das Verhalten von verschiedenen Arten von Wahrscheinlichkeiten weiter untersuchen.\nDiese App lÃ¤sst dich herausfinden, ob man wirklich krank ist, wenn der Arzt es bheauptet.\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise."
  },
  {
    "objectID": "0300-Wskt.html#aufgaben",
    "href": "0300-Wskt.html#aufgaben",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.10 Aufgaben",
    "text": "4.10 Aufgaben\nBearbeiten Sie die Aufgabe in der angegeben Literatur.\n\nAdditionssatz1\nNerd-gelockert\nUrne1\nUrne2\nk-coins-k-hits\nKlausur-raten\nsicherheit\nsicherheit2\nKlausuren-bestehen\nGem-Wskt1\nGem-Wskt2\nGem-Wskt3\nwuerfel05\nwuerfel06\nBed-Wskt1\nBed-Wskt2\nBed-Wskt3\nmtcars-abhaengig\nmtcars-abhaengig-var2\nmtcars-abhaengig_var3a\nvoll-normal\ncorona-blutgruppe\ntotale-Wskt1\nKrebs1\nBayes-Theorem1"
  },
  {
    "objectID": "0300-Wskt.html#section",
    "href": "0300-Wskt.html#section",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "\n4.11 â€”",
    "text": "4.11 â€”\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“ Wahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of Modeling, Probability & Statistics. Springer.\n\n\nHenze, Norbert. 2019. Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der MaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0300-Wskt.html#footnotes",
    "href": "0300-Wskt.html#footnotes",
    "title": "\n4Â  Wahrscheinlichkeit\n",
    "section": "",
    "text": "Die Wahrscheinlichkeitstheorie bildet zusammen mit der Statistik das Fachgebiet der Stochastik.â†©ï¸\nBeispiele fÃ¼r Zufallsexperimente sind das Werfen einer MÃ¼nze, das Ziehen einer Karte aus einem Kartenspiel, das Messen eines UmweltphÃ¤nomens wie der Temperatur oder die Anzahl der Kunden, die einen Laden betreten. In jedem dieser FÃ¤lle sind die mÃ¶glichen Ergebnisse nicht im Voraus bekannt und hÃ¤ngen von nicht komplett bekannten Faktoren ab.â†©ï¸\n\\(A\\) ist eine Teilmenge von \\(B\\), wenn alle Elemente von \\(A\\) auch Teil von \\(B\\) sind.â†©ï¸\nSchon wieder.â†©ï¸\nNa toll.â†©ï¸\nDie Menge aller Teilmengen einer Menge \\(A\\) nennt man die Potenzmenge \\(\\mathcal{P}(A)\\), vgl. hier.â†©ï¸\nDie Wahrscheinlichkeit, keine 6 zu wÃ¼rfeln, liegt bei \\(2/3\\).â†©ï¸\nSynonym und kÃ¼rzer: \\(AB\\) anstelle von \\(A \\cap B\\).â†©ï¸\nmanchmal auch \\(A^C\\); C wie complementary eventâ†©ï¸\nengl. disjointâ†©ï¸\nEin Herr Kolmogorov hat das mal aufgeschrieben.â†©ï¸\nsofern sie nicht disjunkt sind, aber wenn sie diskunkt sind, so ist der Schnitt gleich Null und wir machen auch dann nichts falschâ†©ï¸\ngenauer besehen sieht sie eher aus wie eine GrÃ¼tze oder ein Breiâ†©ï¸\nSie schmeckt scheuÃŸlich.â†©ï¸\nExakte Gleichheit ist in dieser Welt empirisch schwer zu finden. Daher kann man vereinbaren, dass UnabhÃ¤ngigkeit erfÃ¼llt ist, wenn die Gleichheit â€œeinigermaÃŸenâ€ oder â€œziemlichâ€ gilt, die Gleichheit gewissermaÃŸen â€œpraktisch bedeutsamâ€ ist.â†©ï¸\nWer Daten dazu hat oder eine Theorie, der melde sich bitte bei mir.â†©ï¸\nhier mit den zwei AusprÃ¤gungen DEU und USAâ†©ï¸\n Daten von Our World in Data.â†©ï¸\nDa \\(P(A\\cap B)=Pr(B \\cap A)\\)â†©ï¸\nQuelle: https://harrypotter.fandom.com/de/wiki/Bertie_Botts_Bohnen_jeder_Geschmacksrichtungâ†©ï¸\nEinfacher als das Rechnen mit Wahrscheinlichkeiten ist es in solchen FÃ¤llen, wenn man anstelle von Wahrscheinlichkeiten absolute HÃ¤ufigkeiten zum Rechnen verwendet.â†©ï¸\nsynonym: Satz von Bayesâ†©ï¸"
  },
  {
    "objectID": "0500-Globusversuch.html#lernsteuerung",
    "href": "0500-Globusversuch.html#lernsteuerung",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nUnterschiede zwischen Modellen und der RealitÃ¤t erlÃ¤utern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (fÃ¼r binomial verteilte Zufallsvariablen)\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\nPost-Wahrscheinlichkeiten anhand der Gittermethode berechnen\n\n6.1.2 Vorbereitung im Eigenstudium\n\nStatistik 1, Kap. â€œDaten Einlesenâ€\n\n6.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\n\n\n6.1.4 Begleitvideos\n\nVideo zum Thema Globusversuch\nVideo zum Thema Ãœbungen zum Globusversuch"
  },
  {
    "objectID": "0500-Globusversuch.html#von-welten-und-golems",
    "href": "0500-Globusversuch.html#von-welten-und-golems",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.2 Von Welten und Golems",
    "text": "6.2 Von Welten und Golems\n\n6.2.1 Kleine Welt, groÃŸe Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein glÃ¼cklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb AbbildungÂ 6.1.\n\n\nAbbildungÂ 6.1: Behaims Globus: Kein Amerika\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der groÃŸen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel fÃ¼r, sagen wir, die KomplexitÃ¤t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: GlÃ¼ck gehÃ¶rt halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die groÃŸe Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der groÃŸen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen SchlÃ¼ssen und vermeintlicher Gewissheit.\nğŸ‹ Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n6.2.2 Der Golem von Prag\n\n\nAbbildungÂ 6.2: Der Golem von Prag\n\nQuelle\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle wÃ¶rtlich ausfÃ¼hrt, s. AbbildungÂ 6.2. Die Geschichte besagt, dass ein Rabbi mit ZauberkrÃ¤ften den Golem aus Lehm erschuf, um die jÃ¼dische BevÃ¶lkerung der Stadt zu schÃ¤tzen. Bei kluger FÃ¼hrung kann ein Golem NÃ¼tzliches vollbringen. Bei unÃ¼berlegter Verwendung wird er jedoch groÃŸen Schaden anrichten.\n\n6.2.3 Wissenschaftliche Modelle sind wie Golems\n\n\nâ€œYeah, ich bin ein Golem!â€ - Bildquelle: Klara Schaumann\n\n\n\nGolem\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch â€œWahrheitâ€\nMÃ¤chtig\ndumm\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nMÃ¤rchen\n\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mÃ¤chtig\nsimpler als die RealitÃ¤t\nFÃ¼hrt Befehle wÃ¶rtlich aus\nMissbrauch leicht mÃ¶glich\nNicht einmal falsch\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildungÂ 3.4 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen (TabelleÂ 6.1), wie z.B. Behaims Globus, mit der GroÃŸen Welt, die Kolumbus und wir befahren.\n\n\nTabelleÂ 6.1: Kleine Welt vs.Â groÃŸe Welt\n\n\n\n\n\nKleine Welt\nGroÃŸe Welt\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangslÃ¤ufig) die Wirklichkeit\nentspricht nicht (zwangslÃ¤ufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n6.2.4 So denkt unser Bayes-Golem\n\n\nSo denkt unser Bayes-Golem\n\nğŸ‹ Bayes-Inferenz Ã¤hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess Ã¤hnelt!"
  },
  {
    "objectID": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "0500-Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "6.3 Ein erster Versuch: Wir werfen den Globus\n\n6.3.1 Welcher Anteil der ErdoberflÃ¤che ist mit Wasser bedeckt?\n\nBeispiel 6.1 (Wasseranteil auf der ErdoberflÃ¤che) Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (AbbildungÂ 6.3)?\\(\\square\\)\n\n\n\nAbbildungÂ 6.3: Die Erde\n\nQuelle CC 4.0 BY-NC\nAnalog kÃ¶nnen wir uns vorstellen, 11 Wissenschaftlis haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus â€¦ die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.\nSo sah mein2 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\n\nğŸ‹ï¸ï¸ Besorgen Sie sich einen Globus (zur Not eine MÃ¼nze) und stellen Sie den Versuch nach!\\(\\square\\)\n\n\n6.3.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten fÃ¼hrt, nennt man den datengenierenden Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der ErdoberflÃ¤che ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie WÃ¼rfe des Globusballes sind unabhÃ¤ngig voneinander.\nWir haben kein Vorwissen Ã¼ber \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\nğŸ‹ Welche Annahmen wÃ¼rden Sie Ã¤ndern? Welche kÃ¶nnte man wegnehmen? Welche hinzufÃ¼gen? Was wÃ¤ren die Konsequenzen?\n\n6.3.3 Ein paar Fachbegriffe\n\nFÃ¼r jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige PlausibilitÃ¤t der Hypothese angibt: Priori-Verteilung.\nFÃ¼r jede Hypothese (d.h. jeden Parameterwert \\(p\\)) mÃ¶chten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung3 bekommen.\n\n6.3.4 Bayes-Updates\nDer Golem denkt eigentlich ganz vernÃ¼nftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugehÃ¶rige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung. In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als nÃ¤chstes beschaut sich der Golem die Daten und Ã¼berlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 10% betrÃ¤gt. Die zugehÃ¶rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die4 Likelihood. Als letztes bildet sich der Golem eine abschlieÃŸende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder geupatedet, s. AbbildungÂ 6.4.\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]--&gt;B[Likelihood]--&gt;C[Post-Vert.]--&gt;A\n\n\nAbbildungÂ 6.4: Updating mit Bayes\n\n\n\n\n6.3.5 Likelihood mit Binomialverteilung\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer, (bei 9) WÃ¼rfen zu bekommen, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 70%) annimmt? Diese Wahrscheinlichkeit hat einen eigenen Namen, weil sie eine wichtige Sache ist. Man mennt sie die Likelihood, \\(L\\)5.\nGeht man von einer Binomialverteilng aus, ist die Likelihood einfach zu berechnen6.\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabhÃ¤ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich Ã¤ndert7. Der Wasseranteil der Erde bleibt wÃ¤hrend des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit fÃ¼r Wasser \\(p\\) betrÃ¤gt, so bezeichnen: \\((Pr(W,L | p))\\). Diese Wahrscheinlichkeit, \\((Pr(W,L | p))\\), kann man mit der Binomialverteilung berechnen.\nMÃ¶chte man die Wahrscheinlichkeit ansprechen fÃ¼r das Ereignis â€œ5 mal Wasser und 2 mal Land, wenn wir von einem Wasseranteil von 70% ausgehenâ€, so wÃ¼rden wir kurz schreiben: \\(Pr(W=5, L=2 | p=.7)\\).\nDie Binomialverteilung zeigt die Verteilung der HÃ¤ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten MÃ¼nzwurf (und allen vergleichbaren Zufallsexperimenten): â€œMÃ¼nzwurfverteilungâ€, s. Kap. KapitelÂ 5.3.2.\nDie Formel der Binomialverteilung sieht so aus:\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L = k \\cdot P(A) \\tag{6.1}\\]\nFormel GleichungÂ 6.1 kann wie folgt auf Deutsch Ã¼bersetzen:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œW,Lâ€ gegeben p berechnet als Produkt von zwei Termen. Erstens der Quotient von der FakultÃ¤t von W plus L im ZÃ¤hler und im Nenner das Produkt von erstens der FakultÃ¤t von W mit zweitens der FakultÃ¤t von L. Der zweite Term ist das Produkt von p hoch W mal der komplementÃ¤ren Wahrscheinlichkeit von p hoch L.\n\nOder noch kÃ¼rzer:\n\nDie Wahrscheinlichkeit fÃ¼r das Ereignis â€œW,Lâ€ gegeben p berechnet als Produkt von zwei Termen. Erstens der Anzahl der gÃ¼nstigen Pfade, k und zweitens der Wahrscheinlichkeit fÃ¼r einen gÃ¼nstigen Pfad, P(A).\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange Ãœbersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und fÃ¼r uns ausrechnen. Los, R, mach mal.\n\n6.3.6 Binomialverteilung mit R\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(N=W+L=3\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?8.\n\ndbinom(x = 2, size = 3, prob = 1/2)\n## [1] 0.375\n\nVon den 8 Endkonten bzw. Pfaden sind 3 gÃ¼nstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 WÃ¼rfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-&gt; B[B - 0]\n  A -. 1/2 .-&gt; C[C - 1]\n  B -. 1/2 .-&gt; D[D - 0]\n  B -. 1/2 .-&gt; E[E - 1]\n  C -. 1/2 .-&gt; F[F - 0]\n  C -. 1/2 .-&gt; G[G - 1]\n  D -. 1/2 .-&gt; H[H - 0]\n  D -. 1/2 .-&gt; J[I - 1]\n  E -. 1/2 .-&gt; K[K - 0]\n  E -. 1/2 .-&gt; L[L - 1]\n  F -. 1/2 .-&gt; M[M - 0]\n  F -. 1/2 .-&gt; N[N - 1]\n  G -. 1/2 .-&gt; O[O - 0]\n  G -. 1/2 .-&gt; P[P - 1]\n\n\nAbbildungÂ 6.5: Wir werfen den Globus (oder eine MÃ¼nze) 3 Mal\n\n\n\nAbb. AbbildungÂ 6.5 stellt einen einfachen Baum fÃ¼r 3 GlobuswÃ¼rfe mit je zwei mÃ¶glichen Ereignissen (W vs.Â L) dar. In der ersten (obersten) Zeile (Knoten A; â€œStartâ€) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) mÃ¶gliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nFÃ¼r mehr WÃ¼rfe wÃ¼rde das Diagramm irgendwann unÃ¼bersichtlich werden.\nWas ist der Anteil der gÃ¼ltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) WÃ¼rfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\ndbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.1640625\n\nAbb AbbildungÂ 6.6 ist ein vergeblicher Versuch, so einen groÃŸen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum VerstÃ¤ndnis, kommen aber bei grÃ¶ÃŸeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\nAbbildungÂ 6.6: Wir werfen den Globus (oder eine MÃ¼nze) 9 Mal, es resultieren 512 Endknoten\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 6.2 (Globus mit 9 Treffern bei 9 WÃ¼rfen) Was ist die Wahrscheinlichkeit fÃ¼r \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\ndbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.001953125\n\nDas ist 1 gÃ¼nstiger Pfad von 512 Pfaden.\n\n\nBeispiel 6.3 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groÃŸ ist die Wahrscheinlichkeit, durch bloÃŸes MÃ¼nze werfen genau 15 Fragen richtig zu raten?9\n\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.01478577\n\nUm hÃ¶chstens 15 Treffer zu erzielen, mÃ¼ssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern addieren.\nPraktischerweise gibt es einen R-Befehl, der das fÃ¼r uns Ã¼bernimmt:\n\npbinom(q = 15, size = 20, prob = .5)\n## [1] 0.994091\n\nDie Wahrscheinlichkeit 0, 1, 2, â€¦ oder 15 Treffer zu erzielen, liegt also bei gut 99%.\n\n\nBeispiel 6.4 (3 MÃ¼nzwÃ¼rfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 MÃ¼nzwÃ¼rfen (genau) 3 Treffer (Kopf) zu erzielen?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\ndbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.125\n\n\ndbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zurÃ¼ck, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\n\n6.3.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: â€œW ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)â€. \\(N\\) gibt die Anzahl der GlobuswÃ¼rfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (â€œuniformâ€):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: â€œ\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1â€.\nMan kÃ¶nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (aprior) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich.\n\n6.3.8 Visualisierungen\nAbb. AbbildungÂ 6.7 zeigt die Binomialverteilung \\(X \\sim Bin(9, 1/2)\\).\n\n\nAbbildungÂ 6.7: Ein Beispiel fÃ¼r eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\nAbb. AbbildungÂ 5.15 zeigt eine Gleichverteilung (Uniformverteilung, Rechteckverteilung).\n\nÃœbungsaufgabe 6.1 ğŸ‹ï¸ï¸ Was fÃ¤llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? VerÃ¤ndert sich die Wahrscheinlichkeit linear?"
  },
  {
    "objectID": "0500-Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "0500-Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.4 Zur Erinnerung: Bayes Theorem",
    "text": "6.4 Zur Erinnerung: Bayes Theorem\n\n6.4.1 Herleitung Bayesâ€™ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit fÃ¼r Regen und kalt ist gleich der Wahrscheinlichkeit von Regen, gegeben kalt mal der Wahrscheinlichkeit von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wennâ€™s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n6.4.2 Herleitung Bayesâ€™ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lÃ¶sen auf nach der Posteriori-Wahrscheinlichkeit10, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods Ã¼ber alle Werte von \\(p\\). Die Aufgabe dieser GrÃ¶ÃŸe ist nur dafÃ¼r zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n6.4.3 Bayesâ€™ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)} = \\frac{\\text{Likelihood}  \\cdot \\text{Priori}}{\\text{Evidenz}}\\]\n\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\n\nBayesâ€™ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) fÃ¼ttert.\nBayesâ€™ Theorem wird hÃ¤ufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n6.4.4 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Post-Wahrscheinlichkeit ist einfach das Produkt von Likelihood und Priori.\nDas Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung GleichungÂ 6.2.\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}} \\tag{6.2}\\]\nAbb. AbbildungÂ 6.8 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\nAbbildungÂ 6.8: Prior mal Likelihood = Post\n\n\n6.4.5 Wissen updaten: Wir fÃ¼ttern Daten in das Modell\nGolems kÃ¶nnen lernen?! AbbildungÂ 6.9 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. WÃ¼rfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich fÃ¼r den Golem (das Modell). Je nach Ergebnis des Wurfes verÃ¤ndert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung verÃ¤ndert sich in AbhÃ¤ngigkeit von den Daten.\n\n\nAbbildungÂ 6.9: Unser Golem lernt\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell nÃ¼tzlich ist (prÃ¤zise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "0500-Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "href": "0500-Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.5 Bayes berechnen mit mit dem Bayes-Gitter",
    "text": "6.5 Bayes berechnen mit mit dem Bayes-Gitter\nWir erstellen uns eine kleine Tabelle, die man â€œBayes-Gitterâ€ nennen kÃ¶nnte. Dazu gehen wir so vor:\n\n6.5.1 Idee\n\nTeile den Wertebereich des Parameter in ein â€œGitterâ€ auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (â€œGitterwerteâ€).\nWÃ¤hle den Priori-Wert des Parameters fÃ¼r jeden Gitterwert.\nBerechne den Likelihood fÃ¼r Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert fÃ¼r jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nFÃ¼r jeden â€œGitterwertâ€ berechnen wir eine (Post-)Wahrscheinlichkeit. Ein Gitterwert ist eine mÃ¶gliche AusprÃ¤gung des Parameters. HÃ¤ufig entspricht eine Hypothese einem Gitterwert, etwa wenn man sagt: â€œIch glaube, die MÃ¼nze ist fairâ€, was auf einem Parameterwert von 50% herauslÃ¤uft. Dazu geben wir an, fÃ¼r wie wahrscheinlich wie apriori11 - also bevor wir irgendwelche Daten erheben - jeden einzelnen Gitterwert halten. Wir machen es uns hier einfach und halten jeden Gitterwert fÃ¼r gleich wahrscheinlich. TatsÃ¤chlich ist der konkrete Wert hier egal, entscheidend ist das VerhÃ¤ltnis der Apriori-Werte zueinander: Geben wir einigen Gitterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere fÃ¼r (apriori) doppelt so plauibel wie Letztere. Der Likelihood wird in diesem Fall mit der Binomialverteilung berechnet. Der Likelihood gibt an, wie wahrscheinlich ein Gitterwert ist gegeben einem bestimmten apriori gewÃ¤hlten Parameterwert. Die â€œEnd-Wahrscheinlichkeitâ€, die unstandardisierte Post-Wahrscheinlichkeit, die â€œhinten rauskommtâ€ ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet12. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen mÃ¶chten teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die AnsprÃ¼che an eine Wahrscheinlichkeitsverteilung erfÃ¼llt (vgl. (seq-kolmogorov?)).\n\n6.5.2 Bayes-Gitter in R berechnen\nLegen wir uns eine Tabelle mit Gitterwerten an, um deren Posteriori-Wahrscheinlichkeit zu berechnen.\nEin paar Vorarbeiten. Zuerst wÃ¤hlen wir unsere Gitterwerte; sagen wir 0, 0.1, 0.2, â€¦ , 1:\n\np_Gitter &lt;- seq(from = 0, to = 1, by = 0.1)\np_Gitter\n##  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nDann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 WÃ¼rfen) gegeben jeweils eines Gitterwerts:\n\nLikelihood &lt;- dbinom(6, size = 9, prob = p_Gitter)\nLikelihood\n##  [1] 0.000000000 0.000061236 0.002752512 0.021003948 0.074317824 0.164062500\n##  [7] 0.250822656 0.266827932 0.176160768 0.044641044 0.000000000\n\nDann packen wir das alles in eine Tabelle, s. TabelleÂ 6.2.\n\nd &lt;-\n  tibble(\n    # definiere die Hypothesen (das \"Gitter\"): \n    p_Gitter = p_Gitter,\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %&gt;%  \n    mutate(\n      # berechne Likelihood fÃ¼r jeden Gitterwert:\n      Likelihood = Likelihood,\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\nDas â€œBayes-Gitterâ€ (TabelleÂ 6.2) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\n\nTabelleÂ 6.2: Die Bayes-Box fÃ¼r den Globusversuch\n\nid\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n1\n0.0\n1\n0.00\n0.00\n0.00\n\n\n2\n0.1\n1\n0.00\n0.00\n0.00\n\n\n3\n0.2\n1\n0.00\n0.00\n0.00\n\n\n4\n0.3\n1\n0.02\n0.02\n0.02\n\n\n5\n0.4\n1\n0.07\n0.07\n0.07\n\n\n6\n0.5\n1\n0.16\n0.16\n0.16\n\n\n7\n0.6\n1\n0.25\n0.25\n0.25\n\n\n8\n0.7\n1\n0.27\n0.27\n0.27\n\n\n9\n0.8\n1\n0.18\n0.18\n0.18\n\n\n10\n0.9\n1\n0.04\n0.04\n0.04\n\n\n11\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\nFÃ¼r jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood:\n\\(\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood}\\)\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Gitterbox (also fÃ¼r jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn der Priori-Wert fÃ¼r jeden Gitterwert gleich ist, dann ist der Likelihood gleich der unstandardisierten Post-Wahrscheinlichkeit.\\(\\square\\)\n\n\nğŸ‹ï¸ Was wohl mit Post passiert, wenn wir Priori Ã¤ndern?\n\n6.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: â€œPost-Verteilungâ€), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\nAbbildungÂ 6.10 zeigt die Post-Wahrscheinlichkeit fÃ¼r 5, 10 und 20 Gitterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben.\n\n\nAbbildungÂ 6.10: Je mehr Gitterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen UmstÃ¤nden gilt:\n\nMehr Gitterwerte glÃ¤tten die AnnÃ¤herung.\nJe grÃ¶ÃŸer die Stichprobe (\\(N\\)), desto zuverlÃ¤ssiger wird unsere Berechnung.\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer TrÃ¤ume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung kÃ¶nnen Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nÃ¤chsten Kapitels."
  },
  {
    "objectID": "0500-Globusversuch.html#aufgaben",
    "href": "0500-Globusversuch.html#aufgaben",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\nRethink_2E4\nRethink_2m1\nRethink_2m2\nRethink_2m3\nRethink_2m4\nRethink_2m5\nRethink_2m6\nRethink_2m7\nkekse01\nkekse02\neuro-bayes"
  },
  {
    "objectID": "0500-Globusversuch.html#abschluss",
    "href": "0500-Globusversuch.html#abschluss",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.7 Abschluss",
    "text": "6.7 Abschluss\n\n6.7.1 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der groÃŸen Welt nÃ¼tzlich ist, steht auf einem anderen Blatt.\n\nğŸ‹ï¸ Wenn Sie auf einen Prozentwert fÃ¼r \\(W\\) tippen mÃ¼ssten, welchen wÃ¼rden Sie nehmen, laut dem Modell (und gegeben der Daten)?\n\n6.7.2 Der Globusversuch als Modell fÃ¼r zweiwertige Zufallsversuche\nDer Globusversuch ist kein prototypisches Beispiel fÃ¼r Statistik in der Praxis, zumindest nicht auf dem ersten Blick. Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist. Bei nÃ¤herer Betrachtung ist der Globusversuch prototypisch fÃ¼r ganz viele Fragestellungen:\n\nVon einem neuen Produkt von von \\(n\\) Exemplaren \\(k\\) verkauft. Auf welchen Wert \\(p\\) kann die Akzeptanzrate dieses Produkts geschÃ¤tzt werden?\nEin Chat-Bot hat von \\(n\\) Fragen \\(k\\) richtig beantwortet. Wie hoch kann die VerstÃ¤ndnisrate \\(p\\) dieses Programms geschÃ¤tzt werden?\nEine neue Krebstherapie hat von \\(n\\) â€œaustherapiertenâ€ Patientis \\(k\\) geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie geschÃ¤tzt werden?\n\nKurz: Der Globusversuch ist ein Muster fÃ¼r zweiwertige Zufallsversuche. Und solche sind hÃ¤ufig im Leben, im Business und in der Wissenschaft.\n\n6.7.3 Vertiefung\nDas â€œBayes-Paradox-Videoâ€ von 3b1b prÃ¤sentiert eine gut verstÃ¤ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber Ã¤hnlichen Darstellung wie in diesem Kapitel.\n\n6.7.4 Literatur\nBourier (2018), Kap. 6.2 und 7.1 erlÃ¤utern einige (grundlegende) theoretische HintergrÃ¼nde zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar ist dabei die Binomialverteilung. McElreath (2020), Kap. 2, stellt das Globusmodell mit mehr ErlÃ¤uterung und etwas mehr theoretischem Hintergrund vor."
  },
  {
    "objectID": "0500-Globusversuch.html#section",
    "href": "0500-Globusversuch.html#section",
    "title": "\n6Â  Globusversuch\n",
    "section": "\n6.8 â€”",
    "text": "6.8 â€”\n\n\n\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende Statistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0500-Globusversuch.html#footnotes",
    "href": "0500-Globusversuch.html#footnotes",
    "title": "\n6Â  Globusversuch\n",
    "section": "",
    "text": "wenn auch nicht als Ersterâ†©ï¸\nIhr Ergebnis kann anders aussehen, schlieÃŸlich ist es ja Zufall.â†©ï¸\n Anstatt von Priori liest man auch Prior; anstatt Posteriori auch Posteriorâ†©ï¸\noder den?â†©ï¸\n\\(\\mathfrak{L}\\) fÃ¼r Freunde alter Schriftartenâ†©ï¸\nEin GlÃ¼ck!â†©ï¸\nDie sog. â€œiid-Annahmeâ€, independently and identically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen. Jeder Wurf ist unabhÃ¤ngig von allen anderen: Das Ergebnis eines Wurfes hat keinen (stochastischen) Einfluss auf ein Ergebnis anderer WÃ¼rfe. Die Wahrscheinlichkeitsverteilung ist bei jedem Wurf identisch.â†©ï¸\nAllgemeiner spricht man auch von 2 Treffern bei 3 WÃ¼rfen (d.h. 1 â€œNicht-Trefferâ€, den wir als â€œNieteâ€ bezeichnen). Treffer werden oft mit 1 und Nieten mit 0 bezeichnetâ†©ï¸\nHey, endlich mal was fÃ¼r echte Leben!â†©ï¸\nkÃ¼rzen wir mit Post-Wahrscheinlichkeit or \\(Pr(Post)\\) abâ†©ï¸\nsynonym: prioriâ†©ï¸\nsynonym: Die Likelihoodwerte werden mit den Apriori-Werten gewichtet.â†©ï¸"
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n7.1.2 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œDaten umformenâ€\nStatistik1, Kap. â€œDaten zusammenfassenâ€\n\n7.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.2 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "7.2 Mit Stichproben die Post-Verteilung zusammenfassen\n\n7.2.1 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (â€œBayes-Boxâ€) die Postverteilung fÃ¼r den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nÃ¼tzliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) WÃ¼rfen und \\(k=10\\) Gitterwerten, also mit 10 Wasseranteilswerten zwischen 0 und 1.\nAbb. AbbildungÂ 7.1 zeigt die resultierende Post-Verteilung.\n\nn &lt;- 10\nn_success &lt;- 6\nn_trials  &lt;- 9\n\nd &lt;-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %&gt;% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nVoilÃ , die Post-Verteilung als Tabelle, auch â€œBayes-Boxâ€ (oder Bayes-Gitter) genannt: s. TabelleÂ 7.1.\n\n\n\n\n\n\n\nTabelleÂ 7.1:  Postverteilung mit der Gittermethode berechnet \n  \np_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 7.1: Die Postverteilung fÃ¼r W=6, N=9, k=10\n\n\n\nViele nÃ¼tzliche Fragen (und Antworten) leiten sich ab aus Abb. AbbildungÂ 7.1.\n\n7.2.2 Beispiele fÃ¼r Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die hÃ¶chste Wahrscheinlichkeit?\nWie ungewiss ist das Modell Ã¼ber die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n7.2.3 Bayes-Box fÃ¼r komplexe Modelle\nBisher, fÃ¼r einfache Fragestellungen hat unsere Bayes-Box, das heiÃŸt die Gittermethode bestens funktioniert: einfach, robust, formschÃ¶n1. Allerdings: Funktioniert sie auch bei komplexeren Modellen? SchlieÃŸlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 PrÃ¤diktor, dann haben wir folgende drei GrÃ¶ÃŸen2 zu schÃ¤tzen: \\(\\beta_0, \\beta_1, \\sigma\\). HÃ¶rt sich gar nicht so viel an. Aber Moment, wir mÃ¼ssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach mÃ¼ssen wir alle AusprÃ¤gungen (â€œGitterwerteâ€) der Variablen multiplizieren. Puh, das wird eine groÃŸe Zahl. Wenn wir fÃ¼r die drei GrÃ¶ÃŸen jeweils 10 AusprÃ¤gungen annehmen, was wenig ist, kÃ¤men wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 AusprÃ¤gungen wÃ¤ren es schon \\(100^3=10^6\\) Kombinationen. Das wÃ¤re doch eine recht lange Tabelle.\nBei einer multiplen Regression mit sagen wir 10 PrÃ¤diktoren mit jeweils 100 AusprÃ¤gungen rechnet das arme R bis zum jÃ¼ngsten Tag: \\(10^{100}\\). Nein, das kÃ¶nnen wir R nicht zumuten. Wir brauchen eine andere LÃ¶sung!\n\n7.2.4 Wir arbeiten jetzt mit HÃ¤ufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle kÃ¶nnen nicht mehr â€œeinfach mal ebenâ€ ausgerechnet werden; die Mathematik wird so umfangreich bzw. zu komplex.\nGlÃ¼cklicherweiÃŸe gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit HÃ¤ufigkeiten.\nPraktischerweise werden wir in KÃ¼rze einen R-Golem kennenlernen, der das fÃ¼r uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurÃ¼ck.\nLernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen fÃ¼r Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei grÃ¶ÃŸeren DatensÃ¤tzen (oder grÃ¶ÃŸeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein(Eine gute EinfÃ¼hrung in die HintergrÃ¼nde findet sich bei McElreath 2020.)\n\n7.2.5 HÃ¤ufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (â€œR-Golemsâ€) liefern uns die Post-Verteilung in Stichprobenform zurÃ¼ck.\nBevor wir uns aber mit diesen R-Werkzeugen beschÃ¤ftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. ListingÂ 7.1.\n\nListingÂ 7.1: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\nsamples &lt;-\n  d %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit ZurÃ¼cklegen\n  select(p_grid)\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit ZurÃ¼cklegen hÃ¤lt die Wahrscheinlichkeiten wÃ¤hrend des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird.\nWir begnÃ¼gen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht.\nDas Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 7.2 dargestellt.\n\n\n\n\n\n\n\nTabelleÂ 7.2:  Die ersten Zeilen der Stichproben aus der Post-Verteilung \n  \np_grid\n    \n\n0.667\n0.778\n0.556\n0.556\n0.556\n\n\n\n\n\n\nWenn Sie jetzt denken: â€œWarum machen wir das jetzt? Brauchen wir doch gar nicht!â€ - Dann haben Sie Recht. KÃ¼nftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.67 0.78 0.56 0.56 0.56 0.67 0.44 0.56 0.78 0.67 0.78 0.67 0.67 0.56 0.78\n##  [16] 0.67 0.78 0.67 0.67 0.67 0.56 0.56 0.44 0.67 0.56 0.44 0.67 0.78 0.67 0.67\n##  [31] 0.56 0.44 0.89 0.56 0.67 0.67 0.67 0.56 0.56 0.67 0.67 0.67 0.67 0.44 0.78\n##  [46] 0.44 0.56 0.56 0.67 0.44 0.67 0.67 0.89 0.78 0.44 0.56 0.67 0.56 0.89 0.67\n##  [61] 0.56 0.78 0.44 0.78 0.78 0.78 0.67 0.78 0.56 0.67 0.67 0.78 0.67 0.78 0.78\n##  [76] 0.78 0.56 0.67 0.67 0.44 0.56 0.67 0.56 0.67 0.44 0.56 0.78 0.67 0.56 0.56\n##  [91] 0.67 0.78 0.78 0.67 0.56 0.44 0.56 0.89 0.78 0.78\n\nWie sieht diese Tabelle wohl als Histogramm3 aus?\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. AbbildungÂ 7.2.\n\n\n\n\nAbbildungÂ 7.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\nAus AbbildungÂ 7.2 kÃ¶nnen wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% fÃ¼r am wahrscheinlichsten hÃ¤lt. Aber auch kleine Anteile wie 25% sind nicht auszuschlieÃŸen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie AbbildungÂ 7.2 mit AbbildungÂ 6.10: beide sind sehr Ã¤hnlich! Das Stichprobenziehen (AbbildungÂ 7.2) nÃ¤hert sich recht gut an die exakte Berechnung an (AbbildungÂ 6.10).\n\n7.2.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die AuflÃ¶sung auf \\(k=100\\) Gitterwerte (AusprÃ¤gungen) nach oben.\n\nk &lt;- 100\nn_success &lt;- 6\nn_trials  &lt;- 9\n\nd_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n                      length.out = k),  # 100 Gitterwerte\n         prior  = 1) %&gt;% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\nsamples_k100 &lt;-\n  d_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit ZurÃ¼cklegen\n\nAbbildungÂ 7.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen FÃ¤llen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der â€œtypischeâ€ Wert des Modells zu sein. AuÃŸerdem erkennt man, dass das Modell durchaus einige Streuung in der SchÃ¤tzung des Wasseranteils bereithÃ¤lt. Das Modell ist sich nicht sehr sicher, kÃ¶nnte man sagen.\n\n\n\n\nAbbildungÂ 7.3: Post-Verteilung mit 100 Gitterwerten, exakt vs.Â auf Basis von Stichproben\n\n\n\nDie Stichprobendaten nÃ¤hern sich der â€œechtenâ€ Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt â€œglattereâ€ RÃ¤nder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glÃ¤tten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. AbbildungÂ 7.4.\n\n\n\n\nAbbildungÂ 7.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schÃ¶n â€˜glattâ€™. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist."
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.3 Die Post-Verteilung befragen",
    "text": "7.3 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir kÃ¶nnen viele nÃ¼tzliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in AbbildungÂ 7.5 illustriert.\n\n\nAbbildungÂ 7.5: Fragen nach p vs.Â Fragen nach q\n\nIm linken Teildiagramm von AbbildungÂ 7.5 fragen wir: â€œWie wahrscheinlich ist ein Wasseranteil von hÃ¶chstens 80%?â€. Im rechten Teildiagramm fragen wir: â€œWelcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht Ã¼berschritten?â€.\n\n7.3.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groÃŸ ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nUm diese Frage zu beantworten, zÃ¤hlen wir einfach, wie viele Stichproben die Bedingung erfÃ¼llen:\nund und summieren die Wahrscheinlichkeiten dieser Stichproben:\nWir zÃ¤hlen (count) also die Stichproben, die sich fÃ¼r einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\n\n\n\np_grid &lt; 0.5\nn\n\n\n\nFALSE\n8329\n\n\nTRUE\n1671\n\n\n\n\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, kÃ¶nnen wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) fÃ¼r einen Wasseranteil kleiner als 50%.\n\nBeispiel 7.1 (Was macht die Funktion count?) Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem PrÃ¼fkriterium, Wasseranteil hÃ¶chstens 50%. Dann zÃ¤hlt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurÃ¼ck. Man kÃ¶nnte also auch in etwa schreiben:\n\nd %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n\n\nsum\n\n\n0.16653\n\n\n\n\n\nEinfach wie ğŸ° essen.\n\n\nBeispiel 7.2 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n\n\np_grid &gt; 0.5 & p_grid &lt; 0.75\nn\n\n\n\nFALSE\n4607\n\n\nTRUE\n5393\n\n\n\n\n\n\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n\n\nAnteil\nProzent\n\n\n\n0.4607\n46.07\n\n\n0.5393\n53.93\n\n\n\n\n\n\nAnteile von count() kÃ¶nnte man, wenn man mÃ¶chte, auch filter() verwenden:\n\nsamples %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n\n\nsum\nanteil\n\n\n0.5393\n53.93\n\n\n\n\n\n\n\nBeispiel 7.3 (Wasseranteil zwischen 90 und 100%?) Noch ein Beispiel fÃ¼r eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nsamples %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\nprop\n\n\n0.01\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% betrÃ¤gt.\n\nWir kÃ¶nnen auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem â€œGipfelâ€ des Berges, s. AbbildungÂ 7.4.\nFÃ¼r unsere Stichproben-Postverteilung, samples, s. AbbildungÂ 7.2, lÃ¤sst sich der Modus so berechnen:\n\nmap_estimate(samples$p_grid)  \n## MAP Estimate: 0.67\n\nDabei steht map fÃ¼r Maximum Aposteriori, also das Maximum der Post-Verteilung.\nBei der Gelegenheit kÃ¶nnten wir folgende, Ã¤hnliche Fragen stellen:\n\nWas ist der mittlere SchÃ¤tzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane SchÃ¤tzwert (Median)?\n\nAuf Errisch:\n\nsamples %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n\n\nmean(p_grid)\nmedian(p_grid)\n\n\n0.6375444\n0.6666667\n\n\n\n\n\n\n7.3.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchÃ¤tzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall4.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht Ã¼berschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir mÃ¶chten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist5.\n\nsamples %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n\n\nquantil90\n\n\n0.7777778\n\n\n\n\n\nLaut unserem Modell kÃ¶nnen wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu fÃ¼hren, s. AbbildungÂ 7.6.\n\nsamples %&gt;% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\nAbbildungÂ 7.6: Die Post-Verteilung im Globusversuch\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthÃ¤lt, laut dem Modell?\nDafÃ¼r â€œschneidenâ€ wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\nsamples %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n\n\nquant_05\nquant_95\n\n\n0.4444444\n0.8888889\n\n\n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n7.3.3 Zur Erinnerung: Quantile\nBeispiel: Wie groÃŸ sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die KÃ¶rpergrÃ¶ÃŸe der 25% kleinsten Studentis an, analog fÃ¼r 50%, 75%, in Inches6:\n\nspeed_gender_height &lt;- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary &lt;- \n  speed_gender_height %&gt;% \n  mutate(height_cm = height*2.54) %&gt;% \n  select(height_inch = height, height_cm) %&gt;% \n  drop_na() %&gt;% \n  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %&gt;% \n  group_by(Einheit) %&gt;% \n  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n\n\nEinheit\nq25\nq50\nq75\n\n\n\nheight_cm\n160.02\n167.64\n175.26\n\n\nheight_inch\n63.00\n66.00\n69.00\n\n\n\n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildungÂ 7.7 visualisiert die Quantile und die HÃ¤ufigkeitsverteilung.\n\n\n\n\nAbbildungÂ 7.7: GrÃ¶ÃŸenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n7.3.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht Ã¼berschritten wird. Das kÃ¶nnen wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% (von 10000) ab (entferne sie).\nSchaue, was der grÃ¶ÃŸte verbleibende Wert ist.\n\n\nsamples %&gt;% \n  arrange(p_grid) %&gt;%   # sortiere\n  slice_head(n = 9000) %&gt;%  # nur die ersten 90000\n  summarise(p90 = max(p_grid))\n\n\n\n\np90\n\n\n0.7777778\n\n\n\n\n\nDas (annÃ¤hernd) gleiche Ergebnis liefert quantile():\n\nsamples %&gt;% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n\n\nq90\n\n\n0.7777778\n\n\n\n\n\n\n7.3.5 Visualisierung der Intervalle\n\nDefinition 7.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die â€œabzuschneidendeâ€ Wahrscheinlichkeitsmasse hÃ¤lftig auf die beiden RÃ¤nder aufteilen, nennen wir Perzentilintervalle oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. AbbildungÂ 7.8, rechtes Teildiagramm.\n\n\n\n\n\nAbbildungÂ 7.8: Perzintilintervalle"
  },
  {
    "objectID": "0600-Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "href": "0600-Post.html#schiefe-posteriori-verteilungen-sind-mÃ¶glich",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich",
    "text": "7.4 Schiefe Posteriori-Verteilungen sind mÃ¶glich\nNoch einmal zum Globusversuch: Gehen wir von 3 WÃ¼rfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schlieÃŸen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 WÃ¼rfe):\n\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\np_grid\n      prior\n      likelihood\n      unstand_post\n    \n\n\n0.96\n1\n0.88\n0.88\n\n\n0.56\n1\n0.18\n0.18\n\n\n0.56\n1\n0.18\n0.18\n\n\n0.54\n1\n0.16\n0.16\n\n\n0.96\n1\n0.88\n0.88\n\n\n0.89\n1\n0.70\n0.70\n\n\n\n\n\n\nMit dieser â€œschiefenâ€ Post-Verteilung kÃ¶nnen wir gut die Auswirkungen auf das Perzentil- und das HÃ¶chste-Dichte-Intervall anschauen.\n\n7.4.1 Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall, s. Abb. AbbildungÂ 7.9.\n\n\n\n\nAbbildungÂ 7.9: Schiefe Intervalle\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\nlibrary(easystats)\n\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\np_grid\n0.5\n0.71\n0.93\n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n7.4.2 Intervalle hÃ¶chster Dichte\n\nDefinition 7.2 Intervalle hÃ¶chster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schmÃ¤lste Intervall, das den gesuchten Parameter enthÃ¤lt (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten RÃ¤nder nicht mehr gleich groÃŸ, im Sinne von enthalten nicht (zwangslÃ¤ufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen RÃ¤ndern hingegen gleich groÃŸ.\nJe symmetrischer die Verteilung, desto nÃ¤her liegen die PunktschÃ¤tzer aneinander (und umgekehrt), s. Abb. AbbildungÂ 7.10.\n\n\n\n\nAbbildungÂ 7.10: Visualisierung der PunktschÃ¤tzer bei einer schiefen Post-Verteilung\n\n\n\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen, s. TabelleÂ 7.3.\n\nsamples %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\n TabelleÂ 7.3:  50%-HDI fÃ¼r unser Globusmodell \n  \n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der ErdoberflÃ¤che) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI)."
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.5 Fazit",
    "text": "7.5 Fazit\n\n7.5.1 Intervalle hÃ¶chster Dichte vs.Â Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle Ã¤hnlich\nPerzentilintervalle sind verbreiteter\n\nIntervalle hÃ¶chster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle hÃ¶chster Dichte sind die schmalsten Intervalle fÃ¼r eine gegebene Wahrscheinlichkeitsmasse\n\n7.5.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datendatz samples, s. ListingÂ 7.1. Sagen wir, wir haben 6 Treffer bei 9 WÃ¼rfen erzielt.\nLageparmameter: Welchen mittleren Wasseranteil muss man annehmen?\n\nsamples %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n\n\nmean\nmedian\n\n\n0.6375444\n0.6666667\n\n\n\n\n\nStreuungsparameter: Wie unsicher sind wir in der SchÃ¤tzung des Wasseranteils?\n\nsamples %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n\n\n\np_sd\np_iqr\np_mad\n\n\n0.139477\n0.2222222\n0.1647333\n\n\n\n\n\nAnstelle der Streuungsparameter ist es aber Ã¼blicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel fÃ¼r einen Parameter, einer unbekannten GrÃ¶ÃŸes eines Modells."
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.6 Aufgaben",
    "text": "7.6 Aufgaben\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nfattails1\nfattails2\nReThink3e1-7"
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "\n7Â  Die Post befragen\n",
    "section": "\n7.7 â€”",
    "text": "7.7 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0600-Post.html#footnotes",
    "href": "0600-Post.html#footnotes",
    "title": "\n7Â  Die Post befragen\n",
    "section": "",
    "text": "naja, nicht unbedingt formschÃ¶n, aber mir fiel kein dritter Vorzug ein.â†©ï¸\nModellparameter genanntâ†©ï¸\nhier als Balkendiagramm, kommt fast aufs selbe raus, sieht aber etwas schÃ¶ner aus in diesem Fall, da er nur wenige Balken sindâ†©ï¸\nTatsÃ¤chlich gibt es eine Vielzahl an Begriffen, die in der Literatur nicht immer konsistent verwendet werden, etwa KompatibilitÃ¤tsintervall, Ungewissheitsintervall, Passungsbereich.â†©ï¸\nVielleicht damit es genug Berge zum Schifahren gibt.â†©ï¸\n1 Inch entspricht 2.54cmâ†©ï¸"
  },
  {
    "objectID": "0700-ppv.html#lernsteuerung",
    "href": "0700-ppv.html#lernsteuerung",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, was eine Posteriori-PrÃ¤diktiv-Verteilung (PPV) ist, und inwiefern Sie vor Ãœbergewissheit schÃ¼tzt\neine informelle ModellprÃ¼fung fÃ¼r das Beispiel aus dem Unterricht anhand der Posteriori-PrÃ¤diktiv-Verteilung durchfÃ¼hren\n\n8.1.2 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œDaten verbildlichenâ€\n\n8.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(ggpubr)  # dataviz"
  },
  {
    "objectID": "0700-ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "0700-ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.2 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.",
    "text": "8.2 Der zwielichte Dozent: Stichproben-Vert. vs.Â Post-Vert.\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem GlÃ¼cksspiel heraus1. MÃ¼nzwurf; wenn er gewinnt, mÃ¼ssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? NatÃ¼rlich nehmen Sie sofort an.\nSie spielen also MÃ¼nzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal2.\nIst die MÃ¼nze fair oder zieht der mich Ã¼ber den Tisch?, das ist die Frage, die Ihnen brennend durch den Kopf zieht.\nâ€œSind 9 von 10 Treffern noch realistisch erwartbar, wenn es mit rechten Dingen zugeht, oder beweist das Ergebnis, dass die MÃ¼nze gezinkt ist?â€\nWÃ¼tend (und mit leeren Taschen) ziehen Sie von dannen.\nZusammengefasst: Daten: 9 von 10 Treffern beim MÃ¼nzwurf. Forschungsfrage: Ist die MÃ¼nze fair?\nSchauen wir uns zunÃ¤chst einmal an, wie wahrscheinlich 9 von 10 Treffern sind, wenn die MÃ¼nze fair ist, s. AbbildungÂ 8.1, links.\nDie Stichprobenverteilung zeigt, wie wahrscheinlich die empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) sind, gegeben eines Parameterwerts \\(\\pi\\) (z.B. \\(p=0.5\\)): \\(Pr(D|\\pi)\\)3.\nAnders gesagt, die Stichprobenverteilung zeigt die Verteilung der Likelihoods eines bestimmten Parameterwerts.\nIn der Bayes-Statistik ist die Post-Verteilung Dreh- und Angelpunkt der Entscheidung Ã¼ber eine Hypothese. In AbbildungÂ 8.1 ist die Posteriori-Verteilung fÃ¼r die Daten zum zwielichten Dozent dargestellt.\n\n# Post-Verteilung:\nd_zwielicht &lt;-\n  tibble(\n    p_grid = seq( from=0 , to=1 , length.out=100),\n    prior = 1,  # Priori-Gewichte\n    likelihood = dbinom(8, size = 10, prob=p_grid) ,\n    unstandardisierte_posterior = likelihood * prior ,\n    posterior = unstandardisierte_posterior / sum(unstandardisierte_posterior))\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples_zwielicht &lt;- \n  tibble(\n    gewinnchance_muenze = sample(\n      d_zwielicht$p_grid , \n      prob=d_zwielicht$posterior, \n      size=1e4, \n      replace=TRUE)) %&gt;% \n  mutate(\n    id = row_number())\n\n\n\n\n\nAbbildungÂ 8.1: Post-Verteilung fÃ¼r den Parameter p zu den Daten des zwielichten Dozenten (9 von 10 Treffern im wiederholten MÃ¼nzwurf)\n\n\n\n\ngghistogram(samples_zwielicht,\n            x = \"gewinnchance_muenze\",\n            title = \"Posteriori-Verteilung fÃ¼r p\",\n            subtitle = \"Priori: Gleichverteilung; Daten: 9 von 10 Treffern, binomialverteilt\",\n            xlab = \"p (Gewinchance der MÃ¼nze)\",\n            fill = \"grey60\") +\n  geom_vline(xintercept = 0.5)\n\nHilfe fÃ¼r die Funktion gghistogram() finden Sie auf der Hilfeseite der Funktion.\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung.\nJetzt kÃ¶nnen wir wieder die Post-Verteilung auslesen, um die Hypothese zu beantworten. Schauen wir uns einige Beispiel dazu an.\n\nBeispiel 8.1 (EinigermaÃŸen fair?) Wie wahrscheinlich ist es, dass die MÃ¼nze â€œeinigermaÃŸenâ€ fair ist, sagen wir, eine Trefferwahrscheinlichkeit \\(0.45 &lt; \\pi &lt; 0.55\\)4 aufweist?\n\nsamples_zwielicht %&gt;% \n  count(gewinnchance_muenze &gt; 0.45 & gewinnchance_muenze &lt; 0.55) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit fÃ¼r eine â€œeinigermaÃŸen faireâ€ MÃ¼nze ist klein, etwa 5%!\n\n\nÃœbungsaufgabe 8.1 (Visualisieren Sie AbbildungÂ 8.1) Sie finden Details zur Aufgabenstellung (sowie die LÃ¶sung ğŸ™ˆ) hier.\\(\\square\\)\n\n\nBeispiel 8.2 (MÃ¼nze gezinkt?) Schauen wir uns an, wie wahrscheinlich es ist - gegeben der Daten und unserem Modell - dass die MÃ¼nze massiv gezinkt ist. â€œMassivâ€ definieren wir dabei mit â€œmindestens 70% Trefferwahrscheinlichkeitâ€5, also \\(\\pi &gt;= .7\\)6.\n\nsamples_zwielicht %&gt;% \n  count(gewinnchance_muenze &gt; .7) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n  \n\n\n\nWir finden eine recht hohe Wahrscheinlichkeit fÃ¼r eine â€œmassiveâ€ Manipulation der MÃ¼nze.\n\n\n\n\n\n\n\nWichtig\n\n\n\nIst es nicht einfach und schÃ¶n, wie wir mit Hilfe des Stichprobenziehens allerlei Forschungsfragen beantworten kÃ¶nnen? Eine Post-Verteilung aus Stichproben erlaubt uns, viele Fragen mit einfachen Methoden, nÃ¤mlich schlichtes ZÃ¤hlen, zu beantworten.\n\n\nNatÃ¼rlich kÃ¶nnte (und sollte?) man unser Modell kritisieren. Ist es wirklich sinnvoll, die Trefferwahrscheinlichkeit apriori als gleichverteilt anzunehmen? Das heiÃŸt ja, wir glauben, dass eine Trefferwahrscheinlichkeit von 99,99999% genauso wahrscheinlich ist wie 50,55555%. Auf der anderen Seite: Der Charme einer Gleichverteilung ist, dass sie objektiv ist, in dem Sinne, dass wir keinerlei Information einflieÃŸen lassen. Wir sind indifferent gegenÃ¼ber dem Parameter \\(\\pi\\), der Trefferwahrscheinlichkeit.\n\n\n\n\n\n\nHinweis\n\n\n\nIn einem zweiten Versuch kÃ¶nnten wir jetzt unsere Post-Verteilung als Priori-Verteilung nutzen. Das Ergebnis des ersten Versuchs wird dann hergenommen als Ausgangspunkt fÃ¼r einen zweiten Versuch. Damit wird das Wissen der Wissenschaft weitergegeben7, so wie es sein sollte."
  },
  {
    "objectID": "0700-ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "0700-ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.3 Mit Stichproben neue Beobachtungen simulieren",
    "text": "8.3 Mit Stichproben neue Beobachtungen simulieren\nZur Erinnerung: Der Likelihood (L) zeigt die Wahrscheinlichkeit eine Trefferzahl gegeben eines bestimmten Parameterwerts. In unseren Beispiel kÃ¶nnten wir z.B. die drei Likelihoods fÃ¼r \\(w=0,1,2\\) ausrechnen, gegeben \\(N=2\\) und \\(p = 0.5\\):\n\nL &lt;- dbinom(0:2, size = 2, prob = 0.5)\nL\n## [1] 0.25 0.50 0.25\n\nAh, die Wahrscheinlichkeit fÃ¼r 0 oder 2 Treffer betrÃ¤gt 50%, wenn \\(pi=1/2\\); fÃ¼r 1 Treffer betrÃ¤gt sie entsprechend 50%8.\n\n8.3.1 Wir simulieren die Wasserzahl bei GlobuswÃ¼rfen\nZurÃ¼ck zu unserem Globusversuch!\nWir kÃ¶nnten uns jetzt GlobusbÃ¤lle basteln mit verschiedenen Wasseranteilen, und diese oft hochwerfen. Damit kÃ¶nnten wir herausfinden, welche Trefferzahlen sich bei verschiedenen Wasseranteilen finden lassen wÃ¼rden.\nWer gerne bastelt, freut sich darauf. Kritischere Geister9 wÃ¼rden den Aufwand bemÃ¤ngeln und die Frage nach dem Zweck der Ãœbung stellen10.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn wir wissen, welche Trefferzahlen laut einem Modell zu erwarten sind, kÃ¶nnen wir die echten (beobachteten) Trefferzahlen mit den laut Modell zu erwartenden vergleichen. Damit haben wir eine Methode, mit dem wir ein Modell auf Herz und Nieren prÃ¼fen kÃ¶nnen. Ein schlechtes Modell wird mit seinen Vorhersagen an der RealitÃ¤t scheitern: Erwartung des Modells und beobachtete Daten passen nicht zusammen. Sagt ein Modell etwa \\(W=9\\) vorher bei \\(N=9\\), aber wir finden \\(W=0\\), so wird unser Vertrauen in das Modell erschÃ¼ttert sein. Simulation von Trefferzahlen sind also ein Modell, um die GlaubwÃ¼rdigkeit unseres Golems zu prÃ¼fen. (Nicht nur) bei Golems gilt: Vertrauen ist gut, Kontrolle ist besser.\n\n\nLos gehtâ€™s: Wir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zÃ¤hlen die (Wasser-)Treffer:\n\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n## [1] 0\n\nDas geht wie man sieht mit rbinom: r wie random (zufÃ¤llig) und binom wie binomial verteilt, die MÃ¼nzwurfverteilung.\nHier sind die Argumente der Funktion rbinom noch etwas nÃ¤her erklÃ¤rt:\n\nrbinom(n = Wie oft soll der Versuch wiederholt werden?,\n       size = Wie viele GlobuswÃ¼rfe pro Versuch (StichprobengrÃ¶ÃŸe),\n       prob = Wie hoch ist die Wahrscheinlichkeit fÃ¼r Wasser (bzw. fÃ¼r einen Treffer))\n\nWeiter: Warum nicht \\(n=10\\) neue Globusversuche simulieren?\n\nrbinom(n = 10, size = 2, prob = 0.7)\n##  [1] 0 2 1 1 1 1 2 1 1 2\n\nâ€œSimulierenâ€ heiÃŸt hier, wir lassen den Computer den Globus werfen, ganz anschaulich gesprochen. NatÃ¼rlich wirft der Computer nicht in Wirklichkeit einen Globus oder eine MÃ¼nze, sondern er zieht aus der Menge {0,1} eine Zahl, und wir geben die Wahrscheinlichkeit fÃ¼r jedes der beiden Elemente vor, z.B. jeweils 50%.11.\n\n\n\n\n\n\nWichtig\n\n\n\nSimulationsdaten geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann. MÃ¼nzwÃ¼rfe - und analoge Versuche, wie GlobuswÃ¼rfe - kann man in R mit rbinom erstellen (simulieren).\n\n\n\n8.3.2 Traue niemals einem Golem (einem Modell)\n\n\nNever trust a Golem\n\nQuelle: https://imgflip.com/i/5qmhmo\nImmer prÃ¼fen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsÃ¤chlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prÃ¼fen?"
  },
  {
    "objectID": "0700-ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "0700-ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.4 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "8.4 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren12:\n\ndraws &lt;- \n  tibble(\n    draws = rbinom(1e6, size = 2, prob = .7))\n\ndraws %&gt;% \n  count(draws) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n\ndraws\nn\nprop\n\n\n\n0\n89770\n0.089770\n\n\n1\n420629\n0.420629\n\n\n2\n489601\n0.489601\n\n\n\n\n\n\nDiese simulierten HÃ¤ufigkeiten sind sehr Ã¤hnlich zu den theoretisch bestimmten HÃ¤ufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen13.\n\ndbinom(0:2, size = 2, prob = .7)\n## [1] 0.09 0.42 0.49"
  },
  {
    "objectID": "0700-ppv.html#stichprobenverteilung",
    "href": "0700-ppv.html#stichprobenverteilung",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.5 Stichprobenverteilung",
    "text": "8.5 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben fÃ¼r unseren typischen Globusversuch: \\(N=9\\) GlobuswÃ¼rfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise in diesem Versuch? Die Verteilung der zu erwartenden Treffer ist in AbbildungÂ 8.2 dargestellt.\n\nn_draws &lt;- 1e6\n\ndraws_df &lt;- \n  tibble(draws = rbinom(n_draws, size = 9, prob = .7))\n\ndraws_df %&gt;% gghistogram(x = \"draws\")\n\n\n\n\n\nAbbildungÂ 8.2: Anteile (Wahrscheinlichkeit), die man fÃ¼r jede Wasserzahl in unserem Globusversuch erwarten kann\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir kÃ¶nnen jetzt prÃ¼fen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Stichprobenverteilung ist keine empirische Verteilung: Wir fÃ¼hren diese vielen Versuche nicht wirklich durch14, wir simulieren sie nur am Computer."
  },
  {
    "objectID": "0700-ppv.html#die-posterior-prÃ¤diktiv-verteilung-ppv",
    "href": "0700-ppv.html#die-posterior-prÃ¤diktiv-verteilung-ppv",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.6 Die Posterior-PrÃ¤diktiv-Verteilung (PPV)",
    "text": "8.6 Die Posterior-PrÃ¤diktiv-Verteilung (PPV)\n\n8.6.1 Was ist die PPV und wozu ist sie gut?\nUnsere Stichprobenverteilung zeigt, welche Trefferzahlen bei einem bestimmten Parameterwert, z.B. \\(\\pi=.7\\) in welchen Anteilen zu erwarten sind. Allerdings sind wir uns ja nicht sicher, dass der Wasseranteil genau 70% betrÃ¤gt. Unser (Un-)Wissen Ã¼ber den Wasseranteil wird ja gerade in der Post-Verteilung gespeichert.\nUm eine ehrliche(re) Antwort auf die Frage zu erhalten, wie viele Treffer15 zu erhalten ist, mÃ¼ssen wir die Post-Verteilung berÃ¼cksichtigen.\nWir brauche ein Stichprobenverteilung fÃ¼r jeden Wert der Post-Verteilung. Wenn wir dann die resultierenden Strichprobenverteilungen mitteln, haben wir einen ehrlichen Ãœberblick Ã¼ber die zu erwartenden Trefferzahlen. Dabei sollten wir natÃ¼rlich wahrscheinliche Parameterwerte hÃ¶her gewichten als unwahrscheinliche. So sollte etwa der (hoch wahrscheinliche) Wasseranteil von 70% ein hohes Gewicht beim Mitteln der Stichprobenverteilung erhalten; der sehr unwahrscheinliche Wasseranteil16 von 1% Wasser, sollte entsprechend weniger gewichtet werden, beim Zusammenfassen (d.h. Mittelwert bilden) der Stichprobenverteilungen.\nDie resultierende Verteilung - gemittelte Stichprobenverteilungen Ã¼ber alle Werte der Post-Verteilungen - nennt man Posterior-PrÃ¤diktiv-Verteilung (PPV).\n\n\n\n\n\n\nWichtig\n\n\n\nDie PPV entsteht als gewichteter Mittelwert der Stichprobenverteilungen. Die Gewichte sind die Wahrscheinlichkeiten (bzw. Wahrscheinlichkeitsdichten) der Post-Verteilung.\n\n\n\nBeispiel 8.3 (Magnus Lagrande braucht die PPV) Im Jahre \\(10^{99}\\) wird das Universum von Magnus Lagrande regiert. Die WeltraumbehÃ¶rde, fÃ¼r die Sie arbeiten, ist ihm unterstellt. Der Regent findet Ihre Untersuchungen zwar ganz nett, aber leider versteht er keine Wahrscheinlichkeit. Ist ihm zu abstrakt, sagt er. â€œOder kÃ¶nnen Sie mir mal so eine Wahrscheinlichkeit in die Hand geben? KÃ¶nnen Sie sagen, Achtung, da hinten rennt eine Wahrscheinlichkeit, fang sie!â€ Magnus ist also ein Freund fÃ¼r des Konkreten. Einige einflussreiche Gruppen an Statistikis unterstÃ¼tzen diese Haltung\nJedenfalls hÃ¤tte Magnus gerne eine Aussage wie â€œVermutlich sehen wir beim nÃ¤chsten Versuch irgendwas zwischen 4 und 7 Treffernâ€.\nNatÃ¼rlich haben Sie den Anspruch, eine wissenschaftlich belastbare Aussage zu tÃ¤tigen.\nWas nun? Sie mÃ¼ssen sozusagen die Post-Verteilung in eine Post-Verteilung der Beobachtungen, also der konkreten Werte - in diesem Fall die Anzahl der Wassertreffer - Ã¼bersetzen. Genau das macht die PPV fÃ¼r Sie!\n\n\n8.6.2 Visualisierung der PPV\nDer Prozess des gewichteten Zusammenfassens der Stichprobenverteilungen ist in AbbildungÂ 8.3 dargestellt.\n\n\nAbbildungÂ 8.3: PPV als gewichtetes Kombinieren der Stichprobenverteilungen\n\nQuelle: McElreath (2020)\n\n8.6.3 PPV berechnen\n\nDie PPV fÃ¼r unseren Standard-Globusversuch (\\(N=9\\)) berechnen wir so:\nWir berechnen viele (z.B. \\(10^4\\)) Stichprobenverteilungen. Dabei mÃ¼ssen wir jedes Mal fragen, wie groÃŸ die Wahrscheinlichkeit \\(\\pi\\) fÃ¼r Wasser17 ist. Wasseranteile \\(\\pi\\), die laut Post-Verteilung wahrscheinlich sind, mÃ¼ssen wir entsprechend oft als Parameterwert (\\(\\pi\\)) der Stichprobenverteilung verwenden; umgekehrt dÃ¼rfen wir nur wenige Stichprobenverteilungen fÃ¼r unwahrscheinliche Parameterwerte erstellen.\nBeispielsweise wÃ¼rden wir viele Stichprobenverteilungen fÃ¼r \\(\\pi=.7\\) erstellen; fÃ¼r \\(\\pi=0.01\\) wÃ¼rden wir wenige Stichprobenverteilungen erstellen, s. AbbildungÂ 8.3.\nGlÃ¼cklicherweise spiegelt unsere Stichproben-Postverteilung samples wahrscheinlichere Parameterwerte wieder, indem wahrscheinlichere Parameterwerte hÃ¤ufiger vorkommen.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinliche Parameterwerte kommen in der Stichproben-Postverteilung samples hÃ¤ufiger vor. Die HÃ¤ufigkeit der Parameterwerte spiegelt die Wahrscheinlichkeit der jeweiligen Parameterwerte in der (theoretischen) Postverteilung wider.\n\n\nSchauen Sie sich vielleicht zur Erinnerung noch einmal die Definition von samples an, s. ListingÂ 7.1. Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in AuszÃ¼gen) in TabelleÂ 7.2 dargestellt. Wie die Post-Verteilung auf Basis von Stichproben dann aussieht sieht man in AbbildungÂ 7.2. Globusversuche kann man mit rbinom simulieren, s. KapitelÂ 8.3.1.\nWir simulieren also viele (z.B \\(10^4\\)) Globusversuche, jeweils mit \\(N=9\\) WÃ¼rfen. Wahrscheinliche Parameterwerte, etwa \\(\\pi=7\\), sollen hÃ¤ufiger verwendet werden (bei unseren vielen Globusversuchen) als unwahrscheinliche.\nPraktischerweise sind die Werte in der Spalte p_grid in samples so hÃ¤ufig vertreten, wie ihre Wahrscheinlichkeit es erwarten lÃ¤sst. Hier ist ein Auszug aus samples:\n\nsamples %&gt;% \n  select(p_grid) %&gt;% \n  slice_head(n = 10)\n\n\n\n\n\np_grid\n\n\n\n0.78\n\n\n0.56\n\n\n0.56\n\n\n0.78\n\n\n0.44\n\n\n0.67\n\n\n0.67\n\n\n0.44\n\n\n0.56\n\n\n0.67\n\n\n\n\n\nWie man sieht, sind wahrscheinliche Parameterwerte hÃ¤ufiger vertreten.18\np_grid ist also eine Liste19 von Parameterwerten, deren HÃ¤ufigkeit die Wahrscheinlichkeit der Parameterwerte gewichtet.\nAuf dieser Basis kÃ¶nnen wir die PPV erstellen:\n\nppv &lt;- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %&gt;% \n  as_tibble()\n\nhead(ppv)\n\n\n\n\nvalue\n\n\n\n8\n\n\n4\n\n\n5\n\n\n7\n\n\n5\n\n\n4\n\n\n\n\n\n\nSchauen wir uns ein Histogramm aller Trefferzahlen an, s. AbbildungÂ 8.4.20\n\n\n\n\nAbbildungÂ 8.4: Die PPV fÃ¼r unseren Standard-Globusversuch (N=9)\n\n\n\nDie PPV unseres Modells zeigt uns (AbbildungÂ 8.4), dass wir in kÃ¼nftigen Versuchen zumeist 6 Treffer zu erwarten haben. Aber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar.\n\n\n\n\n\n\nWichtig\n\n\n\nDie PPV zeigt, welche Beobachtungen laut unserem Modell hÃ¤ufig und welche selten sind. Die PPV zeigt keine Parameterwerte, sondern welche Daten (Beobachtungen, Wasserzahlen) wir in kÃ¼nftigen Versuchen wie hÃ¤ufig erwarten kÃ¶nnen.\n\n\n\nBeispiel 8.4 (Der nÃ¤chste Planet) Nur zum SpaÃŸ spulen wir kurz die Zeit im Universum vor, sagen wir so \\(10^{99}\\) Jahre. Sie arbeiten bei einer RaumfahrtbehÃ¶rde, die nach neuen Planeten sucht. Nun wurde ein aussichtsreicher Planet gesichtet. Ihre BehÃ¶rde hat eine Studie gestartet, im Rahmen derer 9 Sonden zu diesem (weit entfernten) Planeten geschossen sind. Von den 9 Sonden sind 6 im Wasser gelandet, was aus GrÃ¼nden intergalaktischer Wasserknappheit eine gute Nachricht ist.\n\nâ€œDer nÃ¤chste Planet wird sicher 6 von 9 Wassertreffer erzielen!â€\n\nâ€“ Presse-Chefi der intergalaktischer SpaceY RaumfahrtsbehÃ¶rde\nJetzt plant Ihre BehÃ¶rde den Versuch zu wiederholen: Wieder sollen 9 Sonden zu diesem Planeten geschossen werden. Dis Presse-Chefi21 tÃ¶nt vollmundig: â€œIch bin sicher, dass wir wieder 6 von 9 Treffer, also 6 von 9 Mal Wasser, haben werden!â€.\nKann man diese Aussage mit (hoher) Sicherheit leisten? Perfekte Sicherheit gibt es bekanntlich nur, was Tod und Steuern betrifft, aber kann diese Aussage mit zumindest hoher Sicherheit geleistet werden?\nNein, die PPV (AbbildungÂ 8.4) zeigt deutlich, dass unser Wissen nicht ausreicht, um prÃ¤zise Vorhersagen Ã¼ber kÃ¼nftige AusgÃ¤nge des Versuchs zu leisten. So sind auch 5 oder 7 Treffer gut mÃ¶glich. Auch 4 oder 8 Treffer sind nicht so selten. Sogar 9 Treffer sind nicht super selten.\nDis Presse-Chefi Ihrer BehÃ¶rde sollte also den Mund nicht so voll nehmen."
  },
  {
    "objectID": "0700-ppv.html#fazit",
    "href": "0700-ppv.html#fazit",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.7 Fazit",
    "text": "8.7 Fazit\n\n8.7.1 Vorhersagen sind schwierig\nâ€¦ gerade wenn sie die Zukunft betreffen, so ein Sprichwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der hÃ¤ufigste in unseren Stichproben, aber die Vorhersagen haben eine groÃŸe Streuung, bergen also recht hohe Ungewissheit. Die PPV zeigt also, welche Beobachtungen laut unserem Modell kÃ¼nftig zu erwarten sind, s. AbbildungÂ 8.4.\nWÃ¼rde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hÃ¤tten die Vorhersagen zu wenig Streuung in den Vorhersagen, wÃ¼rden also die Ungewissheit nicht ausreichend abbilden. Es wÃ¼rde Ãœbergewissheit (Overconfidence, Overfitting) resultieren.\nWir brauchen die PPV. Ohne die PPV kÃ¶nnen wir nicht seriÃ¶s abschÃ¤tzen, wie viel Ungewissheit in unseren Vorhersagen steckt.\n\n8.7.2 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells (â€œintrinsischeâ€ Ungewissheit): Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiÃŸ, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nÃ¤chste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, mÃ¶chte man beide Arten von Ungewissheit berÃ¼cksichtigen: Das macht die Posteriori-PrÃ¤diktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prÃ¤diktiv) und mit welcher HÃ¤ufigkeit, basierend auf der Post-Verteilung.\n\n\n\n\n\n\nHinweis\n\n\n\nDer Unterschied zwischen der Post-Verteilung und der PPV ist erstmal, dass die PPV AusprÃ¤gungen in ihrer Wahrscheinlichkeit bemisst, also z.B. wie wahrscheinlich 4 von 9 Wassertreffern sind. Die Post-Verteilung bemisst die Wahrscheinlichkeit von Parameterwerten, also z.B. des Wasseranteils.\nEtwas tiefer betrachtet zeigt die PPV zwei Arten von Ungewissheit, die Post-Verteilung nur eine. Die PPV zeigt erstens die Ungewissheit zur Verteilung des Parameters (wie die Post-Verteilung), aber auch noch die intrinsische Ungewissheit. Denn auch wenn wir keine Ungewissheit zum Parameter hÃ¤tten, bliebe Ungewissheit, welche Beobachtungen sich manifestieren. Insofern ist die PVV â€œehrlicherâ€, sie spiegelt die Ungewissheit zu den Beobachtungen wider.\n\n\n\n8.7.3 Vergleich der Verteilungen\nAbbildungÂ 8.5 stellt die in diesem Kapitel diskutierten Verteilungen gegenÃ¼ber:\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-PrÃ¤diktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter BerÃ¼cksichtigung der Unsicherheit der Posteriori-Verteilung\n\n\n\n\n\nAbbildungÂ 8.5: Post- vs.Â Stichproben- vs.Â PP-Verteilungen\n\n\n\nQuelle: R. McElreath\n\n8.7.4 So viele Verteilungenâ€¦\n\nDie Posteriori-Verteilung gibt Aufschluss zur HÃ¤ufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass â€œin Wirklichkeitâ€ der Wasseranteil 70% betrÃ¤gt, also \\(\\pi=.7\\)\n\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\n\nDie PPV gibt Aufschluss zur HÃ¤ufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter DurchfÃ¼hrung, zu erwarten.\nFÃ¼r die Praxis kann das eine interessante Frage sein.\n\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklÃ¤rt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden."
  },
  {
    "objectID": "0700-ppv.html#aufgaben",
    "href": "0700-ppv.html#aufgaben",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.8 Aufgaben",
    "text": "8.8 Aufgaben\n\nZwielichter Dozent-Bayes\nWarum Bayes?\nsubjektiv-Bayes\nLikelihood2\nAnteil-Apple\nReThink3m1\nReThink3m2\nReThink3m3\nReThink3m4\nReThink3m5\nQuiz zu Verteilungen\npostvert-vis-zwielicht"
  },
  {
    "objectID": "0700-ppv.html#section",
    "href": "0700-ppv.html#section",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "\n8.9 â€”",
    "text": "8.9 â€”\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0700-ppv.html#footnotes",
    "href": "0700-ppv.html#footnotes",
    "title": "\n8Â  Vorhersage-Verteilung\n",
    "section": "",
    "text": "Hier brÃ¤uchte es ein passendes Meme; VorschlÃ¤ge bitte an mich.â†©ï¸\nwas er mit lautem GelÃ¤chter quittiertâ†©ï¸\nDas griechische kleine \\(p\\) wird â€œpiâ€ genannt und \\(\\pi\\) geschrieben. Zur Erinnerung: Parameter- oder Populationskennwerte werden in der Statistik hÃ¤ufig mit griechischen Buchstaben benannt, um sie von Stichprobenkennwerten abzugrenzen.â†©ï¸\nzwischen 45% und 55% mit anderen Wortenâ†©ï¸\nja, das ist subjektivâ†©ï¸\nFÃ¼hrende Nullen bei Anteilen werden oft weggelassen, man schreibt also oft .7 wenn man 0.7 bzw. 70% meint. Das ist nicht nur kÃ¼rzer, sondern man weiÃŸ auch direkt dass es sich um einen Anteil handelt. BehÃ¤lt man die fÃ¼hrende Null bei, etwa 0.77, so wÃ¼rde das signalisieren, dass die Zahl auch grÃ¶ÃŸer als Null sein kÃ¶nnte.â†©ï¸\nÃ¼brigens auf mathematisch gesehen ideale Art und Weise.â†©ï¸\ndas sollte uns bekannt vorkommenâ†©ï¸\noder weniger bastelfreundlicheâ†©ï¸\nbravo!â†©ï¸\nÃœbrigens kÃ¶nnen Computer nicht echten Zufall erzeugen (das kann vermutlich niemand), aber durch gewisse verzwickte Rechnungen sind die Zahlen, die der Computer uns prÃ¤sentiert, nicht oder kaum vom â€œZufallâ€ zu unterscheiden, also z.B. gleichverteilt ohne besondere Muster.â†©ï¸\nWer R nicht mag, ist eingeladen, diesen Versuch von Hand mit selbstgebastelten GlobusbÃ¤llen zu wiederholen.â†©ï¸\nBraver Golem!â†©ï¸\nNur die extremen Bastelfreunde machen dasâ†©ï¸\nIm Globusversuch ist Wasser der â€œTrefferâ€; in einem MÃ¼nzwurf-Versuch kÃ¶nnte â€œKopfâ€ der Treffer und die Anzahl der geworfenen KÃ¶pfe die Trefferzahl seinâ†©ï¸\nzumindest laut unserer Post-Verteilungâ†©ï¸\nd.h. einen Trefferâ†©ï¸\nAn dieser Stelle sollten Sie sichd die ganze Spalte p_grid anschauen, um sich von dieser Behauptung mit eigenen Augen zu Ã¼berzeugen.â†©ï¸\ntechnisch in R ein Vektorâ†©ï¸\nEs kann auch dem VerstÃ¤ndnis helfen, dass Sie sich alle Werte der Tabelle ppv selber in Ruhe anschauen, um sich zu Ã¼berzeugen, welche Wasserzahlen (Trefferzahlen) hÃ¤ufiger und welche seltener vorkommen.â†©ï¸\nIn der Zeit dieses Beispiels ist es Ã¼blich, kein fixes Geschlecht zu habenâ†©ï¸"
  },
  {
    "objectID": "0800-gauss.html#lernsteuerung",
    "href": "0800-gauss.html#lernsteuerung",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nein GauÃŸmodell spezifizieren und in R berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n9.1.2 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œModellgÃ¼teâ€\nStatistik1, Kap. â€œPunktmodelle 2â€\n\n9.1.3 BenÃ¶tigte R-Pakete\nFÃ¼r rstanarm wird ggf. weitere Software benÃ¶tigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, mÃ¼ssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio mÃ¼ssen Sie die (benÃ¶tigten!) Pakete starten.\n\n\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(DataExplorer)  # Daten verbildlichen\n\n\n9.1.4 Begleitvideos\n\nTeil 1\nTeil 2"
  },
  {
    "objectID": "0800-gauss.html#wie-groÃŸ-sind-die-kung-san",
    "href": "0800-gauss.html#wie-groÃŸ-sind-die-kung-san",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.2 Wie groÃŸ sind die !Kung San?",
    "text": "9.2 Wie groÃŸ sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n9.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. AbbildungÂ 9.1.\n\nThe ÇƒKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names ÇƒKung (ÇƒXun) and Ju are variant words for â€˜peopleâ€™, preferred by different ÇƒKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of ÇƒKung people live in the villages of Bantu pastoralists and European ranchers.\n\nQuelle\n\n\n\n\n\n(a) Kung People\n\n\n\n\n\n(b) Verbreitung der Kung-Sprachen\n\n\n\nAbbildungÂ 9.1: Die !Kung im sÃ¼dlichen Afrika\n\n\nQuelle: Internet Archive Book Images, No restrictions, via Wikimedia Commons\nQuelle: By Andrewwik.0 - Own work, CC BY-SA 4.0,]\n\n9.2.2 !Kung Data\nZuerst laden wir die Daten; Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\nDatenquelle\n\nKung_path &lt;-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd &lt;- data_read(Kung_path)  # aus dem Paket `easystats`\n\nhead(d)\n\n\n\n  \n\n\n\nWir interessieren uns fÃ¼r die GrÃ¶ÃŸe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als d2.\n\nd2 &lt;- d %&gt;% \n  filter(age &gt;= 18)\n\nnrow(d2)\n## [1] 352\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tatsÃ¤chlich recht easy, s. TabelleÂ 9.1.\n\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n\nTabelleÂ 9.1:  Statistiken der metrischen Variablen im Kung-Datensatz \n  \nVariable\n      Mean\n      SD\n      IQR\n      Min\n      Max\n      Skewness\n      Kurtosis\n      n\n      n_Missing\n    \n\n\nheight\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\nâˆ’0.48\n352.00\n0\n\n\nweight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\nâˆ’0.51\n352.00\n0\n\n\nage\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\nâˆ’0.21\n352.00\n0\n\n\nmale\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\nâˆ’2.00\n352.00\n0\n\n\n\n\n\n\n\nDie Verteilungen lassen sich mit plot_density (aus DataExplorer), s. AbbildungÂ 9.2.\n\nplot_density(d2)\n\n\n\nAbbildungÂ 9.2: Verteilungen der Variablen im Kung-Datensatz. GrÃ¶ÃŸe und Gewicht sind recht symmetrisch; Alter ist rechtsschief.\n\n\n\n\n9.2.3 Wir gehen apriori von normalverteilter GrÃ¶ÃŸe Der !Kung aus\nForschungsfrage: Wie groÃŸ sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also fÃ¼r den Mittelwert der KÃ¶rpergrÃ¶ÃŸe (erwachsener Kung beider Geschlechter), \\(\\mu\\).\n\n\nMensch\n\nQuelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, via Wikimedia Commons 3.0\nWir sind uns Ã¼ber diesen Mittelwert nicht sicher1, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178cm und Streuung von 20 cm:\n\\[\\mu \\sim \\mathcal{N}(178, 20) \\tag{9.1}\\]\nGleichungÂ 9.1 definiert ein Modell: Unsere Vorstellung der mittleren (â€œtypischenâ€) KÃ¶rpergrÃ¶ÃŸe der erwachsenen !Kung.\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.2 In einer echten Untersuchung sollte man immer einen inhaltlichen Grund fÃ¼r einen Priori-Wert haben. Oder man wÃ¤hlt â€œschwach informativeâ€ Prioris, wie das rstanarm tut: Damit lÃ¤sst man kaum Vorab-Information in das Modell einflieÃŸen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der KÃ¶rpergrÃ¶ÃŸen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. DarÃ¼ber hinaus ist eine Normalverteilung nicht unplausibel."
  },
  {
    "objectID": "0800-gauss.html#die-exponentialverteilung",
    "href": "0800-gauss.html#die-exponentialverteilung",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.3 Die Exponentialverteilung",
    "text": "9.3 Die Exponentialverteilung\n\n9.3.1 Die Apfel-fÃ¤llt-nicht-weit-vom-Stamm-Verteilung\nDarf ich vorstellen â€¦\nBevor wir unser Kung-Modell spezifizieren kÃ¶nnen, sollten wir noch Ã¼berlegen, welches Vorab-Wissen wir zur Streuung um den Mittelwert herum haben. Da wir uns nicht 100% sicher zur gesuchten GrÃ¶ÃŸe sind, mÃ¼ssen wir angeben, wie groÃŸ die Streuung um den Mittelwert sein soll. Hier werden wir eingestehen, dass wir uns auch nicht 100% sicher sind, wie groÃŸ die Streuung exakt ist. Also geben wir eine Verteilung fÃ¼r die Streuung an.\nEtwas Wissen Ã¼ber diese Verteilung haben wir:\n\nEine Streuung muss positiv sein (es gibt keine negative Streuung).\nEine Gleichverteilung der Streuung ist vielleicht mÃ¶glich, aber nicht sehr plausibel.\nWenn wir der Meinung sind, der Mittelwert betrage â€œungefÃ¤hr 178cmâ€, so halten wir 180cm fÃ¼r plausibel, aber 18000 cm fÃ¼r unmÃ¶glich und schon 200 fÃ¼r sehr unplausibel. Also: Je grÃ¶ÃŸer die die Abweichung vom Mittelwert desto unplausibler.\n\nDiese Anforderungen3 spiegeln sich in AbbildungÂ 9.3 wider. AuÃŸerdem zeigt die Abbildung verschiedene Quantile, wie das 95%-Quantil, das bei 3 liegt; 95% der Werte dieser Verteilung sind also nicht grÃ¶ÃŸer als 3.\n\n\n\n\nAbbildungÂ 9.3: Die Exponentialverteilung mit einigen ihrer Quantilen\n\n\n\nFÃ¼r eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung.\n\nEine Exponentialverteilung ist nur fÃ¼r positive Werte, \\(x&gt;0\\), definiert.\nSteigt X um eine Einheit, so Ã¤ndert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (â€œlambdaâ€).\n\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (â€œGestrecktheitâ€) der Verteilung an.\nJe grÃ¶ÃŸer die Rate \\(\\lambda\\), desto kleiner die Streuung und der Mittelwert der Verteilung.\nJe grÃ¶ÃŸer \\(1/\\lambda\\), desto grÃ¶ÃŸer die Streuung und der Mittelwert der Verteilung.\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren PlÃ¤nen passt.\n\n9.3.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zurÃ¼ckzufÃ¼hren, s. AbbildungÂ 9.4.\n\n\n\n\nAbbildungÂ 9.4: Beispiele von Expnentialverteilungen mit unterschiedlichem lambda\n\n\n\nWie wir in AbbildungÂ 9.4 sehen, kÃ¶nnte eine Exponentialverteilung mit \\(\\lambda=1/8\\) grob passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie â€œrichtigenâ€ Priori-Verteilung zu finden, bzw. die richtigen Parameter fÃ¼r die Priori-Verteilung zu wÃ¤hlen, ist nicht mÃ¶glichn, denn es gibt nicht die eine, richtige Priori-Verteilung. Eine â€œgut passendeâ€ Verteilung zu finden, ist hÃ¤ufig nicht leicht. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu wÃ¤hlen, die einen breiteren Raum an mÃ¶glichen Werten zulÃ¤sst. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie mehrere Meter KÃ¶rpergrÃ¶ÃŸe Streuung, erlauben.\n\n\nMan kann sich die Quantile der Exponentialverteilung mit qexp ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, fÃ¼r den man das Quantil haben mÃ¶chte. Mit rate wird \\(\\lambda\\) bezeichnet.\nDieser Aufruf zum Beispiel:\n\nqexp(p = .5, rate = 1/8)\n## [1] 5.545177\n\nGibt uns die Verteilungsfunktion einer Exponentialverteilung mit Rate (\\(\\lambda\\)) von 1/8 zurÃ¼ck, ca. 5.5.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich so ausgeben lassen:\n\nqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2025425 29.5110356\n\nDiese Grenzen scheinen hinreichend weit, das wir noch von den Daten Ã¼berrascht werden kÃ¶nnen, aber schmal genug, um unsinnige Werte auszuschlieÃŸen. Ein guter Start! Weiter gehtâ€™s!"
  },
  {
    "objectID": "0800-gauss.html#unser-gauss-modell-der-kung",
    "href": "0800-gauss.html#unser-gauss-modell-der-kung",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.4 Unser Gauss-Modell der !Kung",
    "text": "9.4 Unser Gauss-Modell der !Kung\n\n9.4.1 Modelldefinition\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior fÃ¼r \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior fÃ¼r \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn AbbildungÂ 9.5 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\nAbbildungÂ 9.5: Unser (erstes) Kung-Modell\n\n\n\n\n9.4.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie KÃ¶rpergrÃ¶ÃŸen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})\\]\n\n9.4.3 Prioris\nMittelwert der GrÃ¶ÃŸe ist normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)}\\]\nDie Streuung \\(\\sigma\\) der GrÃ¶ÃŸen ist exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)}\\]\n\n9.4.4 Fertig!\nJetzt haben wir unser Modell definiert!\nWeil es so schÃ¶n ist, schreiben wir es hier noch einmal auf, GleichungÂ 9.2.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) \\\\\n\\sigma &\\sim \\mathcal{E}(1/8)\n\\end{aligned}\n\\tag{9.2}\\]\nZur Berechnung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich krÃ¤ftig der Bursche, der soll die Arbeit fÃ¼r uns tun. Der Golem hÃ¶rt auf den Namen rstanarm4."
  },
  {
    "objectID": "0800-gauss.html#zufÃ¤llige-motivationsseite",
    "href": "0800-gauss.html#zufÃ¤llige-motivationsseite",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.5 ZufÃ¤llige Motivationsseite",
    "text": "9.5 ZufÃ¤llige Motivationsseite"
  },
  {
    "objectID": "0800-gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "href": "0800-gauss.html#posteriori-verteilung-des-grÃ¶ÃŸen-modells-m41",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.6 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41\n",
    "text": "9.6 Posteriori-Verteilung des GrÃ¶ÃŸen-Modells, m41\n\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m415.\n\nm41 &lt;- stan_glm(height ~ 1, data = d2, refresh = 0)\nm41_post &lt;- as_tibble(m41)  # Modellergebnis in Tabelle umwandeln\nnames(m41_post) &lt;- c(\"mu\", \"sigma\")  # schÃ¶nere Namen fÃ¼r die Spalten\n\nDas Argument refresh = 0 verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrÃ¼cke.\nstan_glm ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein â€œrichtigesâ€ Regressionsmodell. Man kÃ¶nnte sagen, wir haben eine AV (KÃ¶rpergrÃ¶ÃŸe), aber keine UV (keine PrÃ¤diktoren). GlÃ¼cklicherweise kÃ¶nnen wir auch solche â€œarmenâ€ Regressionsmodelle formulieren:\nav ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen mÃ¶chte, aber keine PrÃ¤diktoren hat (das soll die 1 symbolisieren).\nFÃ¼r das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung der Prioris von rstanarm zurÃ¼ck. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wÃ¤re, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die Posteriori-Verteilung von m41, s. AbbildungÂ 9.6.\n\nm41_post %&gt;% \n  ggplot() +\n  aes(x = mu, y = sigma) %&gt;% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\nAbbildungÂ 9.6: Die gemeinsame Verteilung von Mittelwert und Streuung.\n\n\n\nDa das Modell zwei Parameter hat, kÃ¶nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen kÃ¶nnen die Parameter korreliert sein.\nAbbildungÂ 9.6 erlaubt uns, fÃ¼r jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m42, s. AbbildungÂ 9.7.\n\n\n\n\nAbbildungÂ 9.7: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\nNatÃ¼rlich kÃ¶nnen wir auch nur einen Parameter plotten.\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung fÃ¼r \\(\\mu\\) und eine fÃ¼r \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, fÃ¼r die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte fÃ¼r \\(\\mu\\) und \\(\\sigma\\) klein: Die groÃŸe Stichprobe hat die Priori-Werte Ã¼berstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so kÃ¶nnen wir interessante Fragen stellen.\n\n\n9.6.1 Hallo, Posteriori-Verteilung\nâ€¦ wir hÃ¤tten da mal ein paar Fragen an Sie. ğŸ•µ\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person grÃ¶ÃŸer als 1,55m?\nWelche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?\nWas ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?\n\nAntworten folgen etwas weiter unten.\nAbschlieÃŸend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), AbbildungÂ 9.8.\n\n\n\n\nAbbildungÂ 9.8: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen fÃ¼r mu und fÃ¼r sigma\n\n\n\n\n9.6.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() kÃ¶nnen wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - Ã¤hnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurÃ¼ck.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so:\n\nlibrary(rstanarm)  # Paket muss gestartet sein.\n\n# berechnet Post.-Vert.:\nstan_glm(\n  # modelldefinition:\n  AV ~ UV,\n  # Datensatz:\n  data = meine_daten\n)\n\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum GrÃ¶ÃŸenmittelwert\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der GrÃ¶ÃŸen\n\n9.6.3 Ausgabe von stan_glm()\n\nWir kÃ¶nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir kÃ¶nnen es aber auch komfortabler haben â€¦ Mit dem Befehl parameters kann man sich die geschÃ¤tzten Parameterwerte einfach ausgeben lassen.\n\nm41 &lt;- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket `easystats`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n(Intercept)\n154.60\n(153.77, 155.43)\n100%\n1.000\n2835.00\nNormal (154.60 +- 19.36)\n\n\n\n\nDas Wesentliche: Unser Golem schÃ¤tzt den GrÃ¶ÃŸenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.7734451 bis 155.4341892 schÃ¤tzt.\nInformativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu spÃ¤ter mehr.\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren :-)\nWer NÃ¤heres wissen will, findet hier einen Anfang. AuÃŸerdem sei an McElreath (2020) und Gelman, Hill, und Vehtari (2021) verwiesen."
  },
  {
    "objectID": "0800-gauss.html#wie-tickt-stan_glm",
    "href": "0800-gauss.html#wie-tickt-stan_glm",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.7 Wie tickt stan_glm()?",
    "text": "9.7 Wie tickt stan_glm()?\n\n\n\n\n\nQuelle\nHier ein paar Kernimnfos zu stan_glm:\n\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan fÃ¼r uns bereit.\n\nstan_glm() ist fÃ¼r die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schÃ¤tzen, so hat man man â€¦ eine Regression ohne PrÃ¤diktor.\nEine Regression ohne PrÃ¤diktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also fÃ¼r die nicht vorhandene UV; y meint die AV (height).\n\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n9.7.1 SchÃ¤tzwerte zu den Modellparameter\nDie Parameter eines Modells sind die GrÃ¶ÃŸen, fÃ¼r die wir eine Priori-Verteilung annehmen sowie einen Likelihood und dann aus den Daten schÃ¤tzen. Ich sage schÃ¤tzen um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren.\nWie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren SchÃ¤tzungen) einfach mit parameters(modellname) auslesen.\n\n9.7.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, kÃ¶nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_m41:\n\npost_m41 &lt;- as_tibble(m41)\nhead(post_m41)\n\n\n\n  \n\n\n\nIn einer Regression ohne PrÃ¤diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss Ã¼ber unsere SchÃ¤tzwerte zu \\(\\mu\\) (der KÃ¶rpergrÃ¶ÃŸe).\n\nBeispiel 9.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;155\\)?) Â \n\n\nnames(post_m41) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_m41 %&gt;% \n  count(mu &gt; 155) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlieÃŸen, dass die Kung im Schnitt grÃ¶ÃŸer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind.\n\n\nBeispiel 9.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu&gt;165\\)?) Â \n\nnames(post_m41) &lt;- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prÃ¤gnanter\n\npost_m41 %&gt;% \n  count(mu &gt; 165) %&gt;% \n  mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nOh, diese Hypothese kÃ¶nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlieÃŸen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu &gt; 165\\) auszuschlieÃŸen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\nBeispiel 9.3 (Welche mittlere KÃ¶rpergrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, laut dem Modell m41?) Â \n\npost_m41 %&gt;% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n  \n\n\n\n\n\nBeispiel 9.4 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) Â \n\npost_m41 %&gt;% \n  eti()\n\n\n\n  \n\n\n\nEin ETI ist synonym zu PI.\n\n\nBeispiel 9.5 (Mit welcher Unsicherheit ist die SchÃ¤tzung der mittleren KÃ¶rpergrÃ¶ÃŸe behaftet?) Â \n\nm41 %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n(Intercept)\n154.60\n(153.77, 155.43)\n100%\n1.000\n2835.00\nNormal (154.60 +- 19.36)\n\n\n\n\nSeeing is believing, AbbildungÂ 9.9.\n\nm41 %&gt;% \n  parameters() %&gt;% \n  plot(show_intercept = TRUE)\n\n\n\nAbbildungÂ 9.9: Parameter von m41, nur einer: der Intercept\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren KÃ¶rpergrÃ¶ÃŸe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\nBeispiel 9.6 (Was ist der mediane SchÃ¤tzwert der mittleren KÃ¶rpergrÃ¶ÃŸe, sozusagen der â€œBest Guessâ€?) parameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\nğŸ‹ï¸ Ã„hnliche Fragen bleiben als Ãœbung fÃ¼r die Lesis. ğŸ¤“\n\n9.7.3 Standard-Prioriwerte bei stan_glm()\n\nstan_glm() nimmt fÃ¼r uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\nprior_summary(m41)\n## Priors for model 'm41' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden dafÃ¼r die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage fÃ¼r die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht â€œpures Bayesâ€, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte wÃ¤ren auch denkbar.\n\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (fÃ¼r \\(Y\\)) angenommen.\n\n\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals â€œStreuungâ€, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen.\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wÃ¤hlen, dass man nicht Ã¼bergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschlieÃŸen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflieÃŸen zu lassen und eigene Entscheidungen zu begrÃ¼nden. HÃ¤ufig sind mehrere Entscheidungen mÃ¶glich. MÃ¶chte man lieber vorsichtig sein, weil man wenig Ã¼ber den Gegenstand weiÃŸ, dann kÃ¶nnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die â€œschwachinformativâ€ ist, also nur wenig Priori-Information in das Modell einflieÃŸen lÃ¤sst.\n\n\n\n9.7.4 Wenn es schnell gehen muss\nstan_glm() ist deutlich langsamer als z.B. der befreundete Golem lm(). Der Grund fÃ¼r Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu zÃ¤hlen hat. AuÃŸerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister prÃ¼fen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat. Die Idee dabei ist, wenn alle vier DurchfÃ¼hrungen (auch â€œKettenâ€ engl., chains) genannt, zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein. Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist â€œdumm gelaufenâ€. An dieser Stelle schauen wir uns die Ketten nicht nÃ¤her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument chains steuern kann. MÃ¶chte man, dass Stan sich beeilt, so kann man chains = 1 setzen, das spart Zeit.\n\nm41a &lt;- stan_glm(height ~ 1, \n                 data = d2, \n                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit\n                 refresh = 0) \n\nparameters(m41a)"
  },
  {
    "objectID": "0800-gauss.html#modell-m42-unsere-priori-werte",
    "href": "0800-gauss.html#modell-m42-unsere-priori-werte",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.8 Modell m42: unsere Priori-Werte",
    "text": "9.8 Modell m42: unsere Priori-Werte\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einflieÃŸen, in unserem zweiten Kung-Modell, m42.\n\n9.8.1 m42\nDann lassen wir stan_glm() (Stan) unser zweites Modell berechnen.6 Dieses Mal geben wir die Priori-Werte explizit an, TabelleÂ 9.2.\n\nm42 &lt;- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\n\n\n\n\nTabelleÂ 9.2: Parameter von m42 mit eigenen Prioriwerten\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n(Intercept)\n154.62\n(153.83, 155.42)\n100%\n1.000\n2482.00\nNormal (178 +- 20)\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die in TabelleÂ 9.2 ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige FÃ¤higkeit im Studium. ğŸ¤“\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m41 und m42! Was fÃ¤llt Ihnen auf? Nichts? Gut! TatsÃ¤chlich liefern beide Modelle sehr Ã¤hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigermaÃŸen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gewÃ¤hlt waren.\n\n\n\n9.8.2 Posteriori-Verteilung und Parameter plotten\n\nm42 %&gt;% \n  as_tibble() %&gt;% \n  ggplot(aes(x = `(Intercept)`)) +\n  geom_histogram()\n\n\n\n\nEin Vergleich mehrerer Priori-Werte wÃ¤re auch nÃ¼tzlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewÃ¤hlten Priori-Werte zu Ã¼berzeugen."
  },
  {
    "objectID": "0800-gauss.html#fazit",
    "href": "0800-gauss.html#fazit",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.9 Fazit",
    "text": "9.9 Fazit\nWir haben die Posteriori-Verteilung fÃ¼r ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne PrÃ¤diktoren, betrachtet. Die Zielvariable, KÃ¶rpergrÃ¶ÃŸe (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. FÃ¼r \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung fÃ¼r \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\nğŸ§¡ Bleiben Sie dran!"
  },
  {
    "objectID": "0800-gauss.html#wahl-der-priori-werte",
    "href": "0800-gauss.html#wahl-der-priori-werte",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.10 Wahl der Priori-Werte",
    "text": "9.10 Wahl der Priori-Werte\nğŸï¸ Dieser Abschnitt ist eine VERTIEFUNG und nicht prÃ¼fungsrelevant. ğŸ\n\n9.10.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\nn &lt;- 1e4\n\nsim &lt;- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %&gt;% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd &lt;- \n  sd(sim$height) %&gt;% round()\nheight_sim_mean &lt;- \n  mean(sim$height) %&gt;% round()\n\nğŸ’­ Was denkt der Golem (m41) apriori von der GrÃ¶ÃŸe der !Kung?\nğŸ¦¾ Ziehen wir mal ein paar Stichproben auf Basis des Modells. VoilÃ :\n\np3 &lt;- \n  sim %&gt;% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MWÂ±3SD\",\n       x = \"GrÃ¶ÃŸe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\nQuellcode\n\n9.10.2 Priori-Werte prÃ¼fen mit der Priori-PrÃ¤diktiv-Verteilung\n\nDie Priori-PrÃ¤diktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\n\nSo kÃ¶nnen wir prÃ¼fen, ob die Priori-Werte vernÃ¼nftig sind.\n\nDie Priori-PrÃ¤diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an GrÃ¶ÃŸenwerten zulassen:\n\np3\n\n\n\n\nAnteil \\(h_i &gt; 200\\):\n\nanteil_groÃŸer_kung &lt;- \nsim %&gt;% \n  count( height &gt; 200) %&gt;% \n  mutate(prop = n/sum(n))\nanteil_groÃŸer_kung\n\n\n\n  \n\n\n\nğŸ¤” Sehr groÃŸe Buschleute? 17 Prozent sind grÃ¶ÃŸer als 2 Meter. Das ist diskutabel, muss aber nicht zwangslÃ¤ufig ein schlechter Prior sein.\n\n9.10.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n9.10.4 Extrem vage Priori-Verteilung fÃ¼r die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\n\n\n\nDie Streuung der GrÃ¶ÃŸen ist weit:\n\nd &lt;- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %&gt;% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\nğŸ¤” Das Modell geht apriori von ein paar Prozent Menschen mit negativer GrÃ¶ÃŸe aus. Ein Haufen Riesen ğŸ‘¹ werden auch erwartet.\nğŸ¤¯ Vage (flache, informationslose, â€œneutraleâ€, â€œobjektiveâ€) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen."
  },
  {
    "objectID": "0800-gauss.html#fazit-1",
    "href": "0800-gauss.html#fazit-1",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.11 Fazit",
    "text": "9.11 Fazit\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg."
  },
  {
    "objectID": "0800-gauss.html#aufgaben",
    "href": "0800-gauss.html#aufgaben",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.12 Aufgaben",
    "text": "9.12 Aufgaben\n\nstan_glm01\nReThink4e1\nReThink4e2\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung\nPriorwahl1"
  },
  {
    "objectID": "0800-gauss.html#section",
    "href": "0800-gauss.html#section",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "\n9.13 â€”",
    "text": "9.13 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0800-gauss.html#footnotes",
    "href": "0800-gauss.html#footnotes",
    "title": "\n9Â  Gauss-Modelle\n",
    "section": "",
    "text": "Darum machen wir hier ja die ganz Show!â†©ï¸\nDer Autor des zugrundeliegenden Fachbuchs, Richard McElreath gibt 178cm als seine KÃ¶rpergrÃ¶ÃŸe an.â†©ï¸\nâ€œDesiderataâ€â†©ï¸\nHey, ich habe ihn diesne Namen nicht gegeben.â†©ï¸\nm wie Modell und 4, weil das Modell in Kapitel 4 von McElreath (2020) in Ã¤hnlicher Form berichtet wird, und 1 weil es unsere erste Variante dieses Modells ist.â†©ï¸\nHey Stan, los, an die Arbeit!â†©ï¸"
  },
  {
    "objectID": "0900-lineare-modelle.html#lernsteuerung",
    "href": "0900-lineare-modelle.html#lernsteuerung",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\ndie Post-Verteilung fÃ¼r einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder StreuungsmaÃŸe und auch SchÃ¤tzintervalle - aus der Post-Verteilung herauslesen\nkÃ¼nftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n10.1.2 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 1â€\n\n10.1.3 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket easystats verwenden: Hier finden Sie eine Ãœbersicht aller Funktionen des Pakets.1\n\n10.1.4 Begleitvideso\n\nPrÃ¤diktoren zentrieren"
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "href": "0900-lineare-modelle.html#post-verteilung-der-regression",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.2 Post-Verteilung der Regression",
    "text": "10.2 Post-Verteilung der Regression\n\n10.2.1 Einfache Regression\nDie (einfache) Regression prÃ¼ft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhÃ¤ngen. Je mehr sie zusammenhÃ¤ngen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). HÃ¤ngen \\(X\\) und \\(Y\\) zusammen, heiÃŸt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).\nDatenquelle, McElreath (2020).\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und GrÃ¶ÃŸe (Y), AbbildungÂ 10.1.\n\nKung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd &lt;- read_csv(Kung_path)  \n\nd2 &lt;- \n  d %&gt;% \n  filter(age &gt; 18) \n\nd2 %&gt;% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\n\nAbbildungÂ 10.1: Der Zusammenhang von GrÃ¶ÃŸe und Gewicht im !Kung-Datensatz\n\n\n\n\n10.2.2 Bei jedem PrÃ¤diktorwert eine Post-Verteilung fÃ¼r \\(\\mu\\)\n\nKomfort pur: Unser Modell erlaubt uns fÃ¼r jeden beliebigen Wert des PrÃ¤diktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m42, s. AbbildungÂ 10.2.\n\n\n\n\nAbbildungÂ 10.2: FÃ¼r jeden beliebigen PrÃ¤diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgewÃ¤hlten Gewichtswerten. B: FÃ¼r jeden beliebigen Gewichtswert bekommt man eine Post-Verteilung\n\n\n\n\n10.2.3 Statistiken zum !Kung-Datensatz\nDatenquelle\nTabelleÂ 10.1 zeigt die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\nKung_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd &lt;- read_csv(Kung_path)  \n\nd2 &lt;- d %&gt;% filter(age &gt; 18)\n\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nheight\n154.6443688\n7.7735641\n12.065000\n136.52500\n179.07000\n0.1434736\n-0.4973852\n346\n0\n\n\nweight\n45.0455429\n6.4552197\n9.135626\n31.52464\n62.99259\n0.1398158\n-0.5317283\n346\n0\n\n\nage\n41.5397399\n15.8093044\n22.000000\n19.00000\n88.00000\n0.6758624\n-0.2014534\n346\n0\n\n\nmale\n0.4739884\n0.5000461\n1.000000\n0.00000\n1.00000\n0.1046415\n-2.0006483\n346\n0\n\n\n\n\n\n\n\n\n\n\nTabelleÂ 10.1: Verteiung der (metrischen) Variablen im !Kung-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nheight\n154.64\n7.77\n12.06\n(136.53, 179.07)\n0.14\n-0.50\n346\n0\n\n\nweight\n45.05\n6.46\n9.14\n(31.52, 62.99)\n0.14\n-0.53\n346\n0\n\n\nage\n41.54\n15.81\n22.00\n(19.00, 88.00)\n0.68\n-0.20\n346\n0\n\n\nmale\n0.47\n0.50\n1.00\n(0.00, 1.00)\n0.10\n-2.00\n346\n0\n\n\n\n\n\n\nWie aus TabelleÂ 10.1 abzulesen ist, betrÃ¤gt das mittlere KÃ¶rpergewicht (weight) liegt ca. 45kg (sd 7 kg).\n\n10.2.4 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\nlibrary(DataExplorer)\n\n\n10.2.4.1 Gibt es fehlende Werte?\nNein, s. Abb. AbbildungÂ 10.3.\n\nd2 %&gt;% plot_missing()\n\n\n\nAbbildungÂ 10.3: Fehlende Werte - fehlen.\n\n\n\n\n10.2.4.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. AbbildungÂ 10.4.\n\nd2 %&gt;% plot_histogram()\n\n\n\nAbbildungÂ 10.4: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n10.2.4.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. AbbildungÂ 10.5.\n\nd2 %&gt;% plot_bar()\n\n\n\nAbbildungÂ 10.5: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n10.2.4.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in AbbildungÂ 10.6 dargestellt.\n\nd2 %&gt;% plot_correlation()\n\n\n\nAbbildungÂ 10.6: Korrelationsmatrix\n\n\n\n\n10.2.4.5 Bonus\nProbieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(d2).\n\n10.2.5 PrÃ¤diktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (PrÃ¤diktor â€œzentrierenâ€, engl. to center). Wenn man den PrÃ¤diktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\alpha\\), einfacher zu verstehen. In einem Modell mit zentriertem PrÃ¤diktor (weight) gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit durchschnittlichem Gewicht an. WÃ¼rde man weight nicht zentrieren, gibt der Achsenabschnitt die GrÃ¶ÃŸe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist.\nVgl. Gelman, Hill, und Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen (mit Hilfe von center aus easystats):\n\nd3 &lt;- \n  d2 %&gt;% \n  mutate(weight_c = as.numeric(center(weight)))\n\nOder so, von Hand:\n\nd3 &lt;-\n  d2 %&gt;% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\n\nheight\n      weight\n      age\n      male\n      weight_c\n    \n\n\n152\n48\n63\n1\n3\n\n\n140\n36\n63\n0\nâˆ’9\n\n\n137\n32\n65\n0\nâˆ’13\n\n\n\n\n\n\nWie man sieht, ist die Verteilung â€œzur Seite geschobenâ€: Der Mittelwert liegt jetzt eben bei 0, s. AbbildungÂ 10.7.\n\n\n\n\nAbbildungÂ 10.7: Das Zentrieren Ã¤ndert die Verteilungsform nicht, sondern â€œschiebtâ€ die Verteilung nur zur Seite\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem PrÃ¤diktor ist, nicht d2."
  },
  {
    "objectID": "0900-lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "href": "0900-lineare-modelle.html#modell-m43-zentrierter-prÃ¤diktor",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.3 Modell m43: zentrierter PrÃ¤diktor",
    "text": "10.3 Modell m43: zentrierter PrÃ¤diktor\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wÃ¤re wohl die KÃ¶rpergrÃ¶ÃŸe? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa wÃ¤re es schÃ¶n, wenn wir die Daten so umformen kÃ¶nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum GlÃ¼ck geht das leicht: Wir zentrieren den PrÃ¤diktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n10.3.1 Modelldefinition von m43\n\nFÃ¼r jede AusprÃ¤gung des PrÃ¤diktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung fÃ¼r die abhÃ¤ngige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) fÃ¼r jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte fÃ¼r die Steigung \\(\\beta\\) und den Achsenabschnitt \\(\\alpha\\) der Regressionsgeraden. AuÃŸerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der GrÃ¶ÃŸe (height) angibt; dieser Wert wird als exonentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\).\n\\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnit (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ğŸ¤·\n\n\n\n10.3.2 Likelihood, m43\n\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m43 ist Ã¤hnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines â€œIndex-iâ€ am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern fÃ¼r jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\nâ€œDie Wahrscheinlichkeit, eine bestimmte GrÃ¶ÃŸe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))â€.\n\n\n10.3.3 Regressionsformel, m43\n\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschÃ¤tzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\alpha\\) und \\(\\beta\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der PrÃ¤diktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\nâ€œDer Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\alpha\\) und \\(\\beta\\) mal \\(\\text{weight}_i\\)â€.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\alpha\\) gibt an, wie groÃŸ \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n10.3.4 Priori-Werte des Modells m43\n\n\\[\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\n\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n\n\\(\\alpha\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine â€œRegression ohne PrÃ¤diktorenâ€ berechnet haben.\n\n\\(\\sigma\\) ist uns schon als Parameter bekannt und behÃ¤lt seine Bedeutung aus dem letzten Kapitel.\nDa height nicht zentriert ist, der Mittelwert von \\(\\alpha\\) bei 178 und nicht 0.\n\n\\(\\beta\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und GrÃ¶ÃŸe positiv (gleichsinnig) ist."
  },
  {
    "objectID": "0900-lineare-modelle.html#vertiefung-prior-prÃ¤diktiv-verteilung",
    "href": "0900-lineare-modelle.html#vertiefung-prior-prÃ¤diktiv-verteilung",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.4 Vertiefung: Prior-PrÃ¤diktiv-Verteilung",
    "text": "10.4 Vertiefung: Prior-PrÃ¤diktiv-Verteilung\nğŸï¸ VERTIEFUNG, nicht prÃ¼fungsrelevant ğŸï¸\n\n10.4.1 Moment\nğŸ¤” Moment. Dieser Prior, \\(\\beta\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und GrÃ¶ÃŸe positiv oder negativ ist? Nein, sind wir nicht.\n\n10.4.2 Priori-PrÃ¤diktiv-Verteilung fÃ¼r m43\n\nWas denkt wir bzw. unser Golem apriori Ã¼ber den Zusammenhang von GrÃ¶ÃŸe und Gewicht? Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also fÃ¼r \\(\\alpha\\), \\(\\beta\\) und \\(\\sigma\\).\n\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter fÃ¼r Prior-Pred-Verteilung\n             data = d3)\n\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n\na\n      b\n      sigma\n    \n\n\n225.2\n0.8\n0.5\n\n\n212.0\nâˆ’17.9\n25.6\n\n\n136.0\nâˆ’8.9\n18.5\n\n\n154.9\nâˆ’2.3\n3.8\n\n\n201.7\nâˆ’19.7\n17.8\n\n\n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n10.4.3 Prior-PrÃ¤diktiv-Simulation fÃ¼r m43 mit stan_glm()\n\n\nm43_prior_pred &lt;-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d3)\n\nm43_prior_pred_draws &lt;- \n  m43_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  rename(a = `(Intercept)`,\n         b = weight_c) %&gt;% \n  slice_sample(n = 50)\n\n\n10.4.4 Visualisieren der Prior-PrÃ¤diktiv-Verteilung\n\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\nğŸ¤¯ Einige dieser Regressionsgeraden sind unsinnig!\n\nd3 %&gt;% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n10.4.5 Ein positiver Wert fÃ¼r \\(\\beta\\) ist plausibler\n\n10.4.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\nğŸ‘ \\(\\beta=-20\\) wÃ¤re mit diesem Prior gut mÃ¶glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n10.4.5.2 Oh yes\nWir brÃ¤uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x&gt;0):\n\n\n\n\n\nğŸ‘ Vermutlich besser: Ein GroÃŸteil der Wahrscheinlichkeitsmasse ist \\(X&gt;0\\). Allerdings gibtâ€™s keine GewÃ¤hr, dass unser Prior â€œrichtigâ€ ist.\n\n10.4.6 Priori-PrÃ¤diktiv-Simulation, 2. Versuch\n\nm43a_prior_pred &lt;-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter fÃ¼r Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d3)\n\n\nm43a_prior_pred_draws &lt;- \n  m43a_prior_pred %&gt;% \n  as_tibble() %&gt;% \n  # Spaltennamen kÃ¼rzen: \n  rename(a = `(Intercept)`) %&gt;%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n\na\n      b\n      s\n    \n\n\n199.3\n3.8\n1.2\n\n\n186.7\n3.4\n0.6\n\n\n177.5\n2.9\n54.9\n\n\n176.0\n1.3\n0.1\n\n\n177.7\n4.4\n23.6\n\n\n\n\n\n\nDas Argument prior_PD = TRUE sorgt dafÃ¼r, dass keine Posteriori-Verteilung, sondern eine Prior-PrÃ¤diktiv-Verteilung berechnet wird.\n\n10.4.7 Visualisieren der Prior-PrÃ¤diktiv-Verteilung, m43a\n\nUnsere Priori-Werte scheinen einigermaÃŸen vernÃ¼nftige Vorhersagen zu tÃ¤tigen. Allerdings erwartet unser Golem einige Riesen.\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %&gt;% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\nDie durchgezogene horizontale Linie gibt die GrÃ¶ÃŸe des grÃ¶ÃŸten Menschens, Robert Pershing Wadlow, an.\n\n10.4.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p.Â 96.\n\n10.4.9 Hier ist unser Modell, m43a\n\n\\[\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\\]\n\n# Posteriori-Vert. berechnen:\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # Zufallszahlen festlegen\n    data = d3)\n\n\n10.4.10 Eine Zusammenfassung der Posteriori-Verteilung fÃ¼r m43a\n\n\nm43a %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nUnser Modell m43a schÃ¤tzt die typische KÃ¶rpergrÃ¶ÃŸe einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugehÃ¶rige 95%-CI keine 20 Zentimenter umfasst."
  },
  {
    "objectID": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "href": "0900-lineare-modelle.html#die-post-verteilung-befragen",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.5 Die Post-Verteilung befragen",
    "text": "10.5 Die Post-Verteilung befragen\n\n10.5.1 m43a\nSagen wir, auf Basis gut geprÃ¼fter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. GleichungÂ 10.1.\nPrioris:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{10.1}\\]\nWir nennen das Modell m43a2, s. ListingÂ 10.1.\n\nListingÂ 10.1: Modelldefinition von m43a in R\nm43a &lt;-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest fÃ¼r Reproduzierbarkeit\n    data = d3)\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die NachprÃ¼fbarkeit der Ergebnisse (â€œReproduzierbarkeitâ€) sichergestellt3. Welche Wert fÃ¼r seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung schÃ¤tzen.\n\n\n\n10.5.2 Mittelwerte von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n\nid\n      (Intercept)\n      weight_c\n      sigma\n    \n\n\n1\n155.1\n0.9\n5.0\n\n\n2\n155.5\n0.8\n5.1\n\n\n3\n155.5\n0.9\n5.1\n\n\n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters:\n\nparameters(m43a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\n\nDefinition 10.1 (Effektwahrscheinlichkeit) Die Kennzahl pd (propability of direction) gibt die Effektwahrscheinlichkeit an: Die Wahrscheinlichkeit, dass der Effekt positiv (also grÃ¶ÃŸer als Null) oder negativ ist (je nachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) Ã„hnliches wie der p-Wert in der Frequentistischen Statistik (Makowski u.Â a. 2019).\n\nAm besten das Diagramm dazu anschauen, s AbbildungÂ 10.8.\n\nplot(p_direction(m43a))\n\n\n\nAbbildungÂ 10.8: Diagramm zur Probability of Direction, Modell m43a\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) grÃ¶ÃŸer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschÃ¤ftigen in diesem Kurs.\n\n10.5.3 Visualisieren der â€œmittlerenâ€ Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). Ãœberzeugen wir uns mit einem Blick in die Post-Verteilung von m43a:\n\nm43a %&gt;% \n  as_tibble() %&gt;% \n  head()\n\n\n\n\n(Intercept)\nweight_c\nsigma\n\n\n\n155.1421\n0.8581434\n5.042898\n\n\n155.4658\n0.8348727\n5.071101\n\n\n155.4522\n0.8549260\n5.144382\n\n\n155.2342\n0.8816371\n5.352756\n\n\n155.3172\n0.8745051\n5.349856\n\n\n154.9315\n0.9030495\n5.207581\n\n\n\n\n\n\nWir kÃ¶nnen z.B. ein LagemaÃŸ wie den Median hernehmen, um die â€œmittlereâ€ Regressionsgerade zu betrachten:\n\nd3 %&gt;% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. AbbildungÂ 10.9. Mit â€œexpectationâ€ sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\nm43_expect &lt;- estimate_expectation(m43a)\nplot(m43_expect)\n\n\n\nAbbildungÂ 10.9: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n\n\n\n\n10.5.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\alpha, \\beta, \\sigma\\).\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen kÃ¶nnen.\n\n10.5.4.1 LagemaÃŸe zu den Parametern\n\nWas ist die mittlere GrÃ¶ÃŸe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der SchÃ¤tzwert fÃ¼r den Zusammenhang von Gewicht und GrÃ¶ÃŸe? (\\(\\beta_1\\))\nWas ist der SchÃ¤tzwert fÃ¼r Ungewissheit in der SchÃ¤tzung der GrÃ¶ÃŸe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert fÃ¼r z.B: \\(\\beta_1\\)?\n\nEine nÃ¼tzliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell):\n\nm43a %&gt;% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m43a, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\nm43a_post &lt;- \n  m43a %&gt;% \n  as_tibble()\n\nm43a_post %&gt;% \n  head()\n\n\n\n\n(Intercept)\nweight_c\nsigma\n\n\n\n155.1421\n0.8581434\n5.042898\n\n\n155.4658\n0.8348727\n5.071101\n\n\n155.4522\n0.8549260\n5.144382\n\n\n155.2342\n0.8816371\n5.352756\n\n\n155.3172\n0.8745051\n5.349856\n\n\n154.9315\n0.9030495\n5.207581\n\n\n\n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post.\nJetzt haben wir wieder eine schÃ¶ne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen kÃ¶nnen.\nEine Visualisierung zeigt gut sowohl Lage- als auch StreuungsmaÃŸe der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot.\n\nm43a_post %&gt;% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den hÃ¤ufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\nDer Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\nm43a_post %&gt;% \n  summarise(map_b1 = map_estimate(weight_c))\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. AbbildungÂ 10.10.\n\nm43a_post %&gt;% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\nAbbildungÂ 10.10: Die Post-Verteilung fÃ¼r den Parameter sigma, m43a\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s.@fig-m43a-plot.\n\nm43a_hdi &lt;- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\nAbbildungÂ 10.11: Die Parameter Gewicht (zentriert) und sigma des Modells m43a\n\n\n\nErgÃ¤nzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n10.5.5 StreuungsmaÃŸe zu den Parametern\n\nWie unsicher sind wir uns in den SchÃ¤tzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebrÃ¤uchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen StabilitÃ¤t.\n\n\n\n10.5.6 Ungewissheit von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung visualisiert\nDie ersten 10 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\nDie ersten 100 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\nDie ersten 1e3 Stichproben:\n\nd3 %&gt;% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %&gt;% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\nDie ersten 1000000 â€¦ okay, lassen wir es gut sein4.\nEinfacher ist die Visualisierung mit estimate_expectation:\n\nestimate_expectation(m43a, seed = 42) %&gt;% plot()\n\n\n\n\n\n10.5.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten PrÃ¤diktor misst der Achsenabschnitt die mittlere GrÃ¶ÃŸe.\n\n\n\nWelche mittlere GrÃ¶ÃŸe wird mit zu 50%, 90% bzw. 95% Wahrscheinlichkeit nicht Ã¼berschritten?\nWelche mittlere GrÃ¶ÃŸe mit zu 95% Wskt. nicht unterschritten?\nVon wo bis wo reicht der innere 50%-SchÃ¤tzbereich der mittleren GrÃ¶ÃŸe?\n\nQuantile:\n\nm43a_post %&gt;% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n\nq_50\nq_90\nq_05\n\n\n154.6548\n155.0032\n155.0951\n\n\n\n\n\n50%-PI:\n\nm43a %&gt;% \n  eti(ci = .5)\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n(Intercept)\n0.5\n154.4632928\n154.8373635\nfixed\nconditional\n\n\nweight_c\n0.5\n0.8772824\n0.9354291\nfixed\nconditional\n\n\n\n\n\n\n\n10.5.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe bei mind. 155 cm liegt?\n\nm43a_post %&gt;% \n  count(gross = `(Intercept)` &gt;= 155) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n\ngross\nn\nprop\n\n\n\nFALSE\n3593\n0.89825\n\n\nTRUE\n407\n0.10175\n\n\n\n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.1.\nWie wahrscheinlich ist es, dass die mittlere GrÃ¶ÃŸe hÃ¶chstens 154.5 cm betrÃ¤gt?\n\nm43a_post %&gt;% \n  count(klein = (`(Intercept)` &lt;= 154.5)) %&gt;% \n  mutate(prop = n / sum(n))\n\n\n\n\nklein\nn\nprop\n\n\n\nFALSE\n2833\n0.70825\n\n\nTRUE\n1167\n0.29175\n\n\n\n\n\n\nDie Wahrscheinlichkeit betrÃ¤gt 0.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nâ€š \n\n10.5.9 Typischer Bayes-Nutzer in Aktion\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\nQuelle"
  },
  {
    "objectID": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "href": "0900-lineare-modelle.html#post-verteilung-bedingt-auf-einen-prÃ¤diktorwert",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert",
    "text": "10.6 Post-Verteilung bedingt auf einen PrÃ¤diktorwert\n\n10.6.1 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der KÃ¶rpergrÃ¶ÃŸe bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche KÃ¶rpergrÃ¶ÃŸe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns Ã¼ber diesen Mittelwert?\nEtwas formaler ausgedrÃ¼ckt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten PrÃ¤diktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\nmu_at_45 &lt;-\n  m43a_post %&gt;% \n  mutate(mu_at_45 = `(Intercept)`)\n\nUnd plotten diese, s. AbbildungÂ 10.12.\n\nmu_at_45 %&gt;% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\nAbbildungÂ 10.12: Post-Verteilung der GrÃ¶ÃŸe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\nAnalog kÃ¶nnen wir fragen, wie groÃŸ wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns Ã¼ber diesen Mittelwert sind.\n50 kg, das sind 5 Ã¼ber dem Mittelwert, in zentrierten Einheiten ausgedrÃ¼ckt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle.\n\nmu_at_50 &lt;-\n  mu_at_45 %&gt;% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\n(Intercept)\nweight_c\nsigma\nmu_at_45\nmu_at_50\n\n\n\n155.1421\n0.8581434\n5.042898\n155.1421\n159.4329\n\n\n155.4658\n0.8348727\n5.071101\n155.4658\n159.6402\n\n\n155.4522\n0.8549260\n5.144382\n155.4522\n159.7269\n\n\n155.2342\n0.8816371\n5.352756\n155.2342\n159.6424\n\n\n155.3172\n0.8745051\n5.349856\n155.3172\n159.6897\n\n\n154.9315\n0.9030495\n5.207581\n154.9315\n159.4467\n\n\n\n\n\n\nDie Verteilung der mittleren GrÃ¶ÃŸe bei einem Gewicht von 50kg ist weiter â€œrechtsâ€ (Richtung hÃ¶here GrÃ¶ÃŸe) zentriert, s. AbbildungÂ 10.13.\n\nmu_at_50 %&gt;% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\nAbbildungÂ 10.13: Post-Verteilung der mittleren GrÃ¶ÃŸe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n10.6.2 LagemaÃŸe und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der KÃ¶rpergrÃ¶ÃŸe.\nWas ist das 90% PI fÃ¼r \\(\\mu|w=50\\) ?\n\nmu_at_50 %&gt;% \n  eti(mu_at_50, ci = .9)\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n(Intercept)\n0.9\n154.2144131\n155.0950875\n\n\nweight_c\n0.9\n0.8358413\n0.9763181\n\n\nsigma\n0.9\n4.8298399\n5.4758137\n\n\nmu_at_45\n0.9\n154.2144131\n155.0950875\n\n\nmu_at_50\n0.9\n158.6294638\n159.7578370\n\n\n\n\n\n\nDie mittlere GrÃ¶ÃŸe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere GrÃ¶ÃŸe wird mit 95% Wahrscheinlichkeit nicht Ã¼berschritten, wenn die Person 45kg wiegt?\n\nmu_at_45 %&gt;% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n\n\n\n\nq_95\n\n\n155.0951"
  },
  {
    "objectID": "0900-lineare-modelle.html#die-ppv-befragen",
    "href": "0900-lineare-modelle.html#die-ppv-befragen",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.7 Die PPV befragen",
    "text": "10.7 Die PPV befragen\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) gibt uns die MÃ¶glichkeit, nach der Wahrscheinlichkeit tatsÃ¤chlicher KÃ¶rpergrÃ¶ÃŸen zu fragen - und nicht nur nach mittleren KÃ¶rpergrÃ¶ÃŸen anhand der Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren KÃ¶rpergrÃ¶ÃŸe, denn das ist was wir modellieren wollten. MÃ¶chten wir Aussagen zur Wahrscheinlichkeit tatsÃ¤chlicher GrÃ¶ÃŸen treffen, brauchen wir die PPV. Allgemeiner gesagt: Die PPV macht Vorhersagen auf Basis eines Modells. FÃ¼r jede Vorhersage gibt es eine Verteilung, die wir zu einem PunktschÃ¤tzer (z.B. Median) und einem SchÃ¤tzbereich (z.B. 89%-HDI) zusammenfassen kÃ¶nnen.\n\n\nAn dieser Stelle sollten wir uns vor Augen fÃ¼hren, dass die PPV mehr Ungewissheit beinhaltet, denn sie berÃ¼cksichtigt derer zweier Arten:\n\nUngewissheit bzgl. der Modellparameter (Steigung und Achsenabschnitt der Regressionsgeraden)\nUngewissheit der Vorhersagen (das Modell macht keine perfekten Vorhersagen)\n\nDie Post-Verteilung berÃ¼cksichtigt nur die Ungewissheit in den Modellparametern, macht also nur Aussagen zur Regressionsgeraden.\nDie PPV macht Aussagen fÃ¼r konkrete Beobachtungen. Der Unterschied ist in AbbildungÂ 10.14 dargestellt; die Funktionen stammen Ã¼brigens aus easystats.\n\nestimate_prediction(m43a) %&gt;% plot()\nestimate_relation(m43a) %&gt;% plot()\n\n\n\n\n\n(a) PPV mit viel Ungewissheit\n\n\n\n\n\n(b) Post-Verteilung mit wenig(er) Ungewissheit\n\n\n\nAbbildungÂ 10.14: PPV vs.Â Post-Verteilung\n\n\n\n\n10.7.1 Perzentil-Intervalle fÃ¼r bestimmte PrÃ¤diktor-Werte\n\nWie groÃŸ ist ein !Kung-Mann mit mittlerem Gewicht?\n\n\nset.seed(42)\nestimate_prediction(m43a, data = tibble(weight_c = 0), seed = 42)\n\n\n\n\nweight_c\nPredicted\nSE\nCI_low\nCI_high\n\n\n0\n154.5787\n5.162584\n144.2798\n164.5835\n\n\n\n\n\nUnser Modell, ma43a schÃ¤tzt ca. 145cm bis 165cm.\nWir kÃ¶nnen uns auch eine Sequenz an PrÃ¤diktorwerten, die uns interessieren, erstellen, s. weight_df:\n\nweight_df &lt;- tibble(weight_c = seq(-20,20, by = 5))\n\nFÃ¼r diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\nmus &lt;- \n  estimate_prediction(m43a, data = weight_df) \n\nhead(mus)\n\n\n\n\nweight_c\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n-20\n136.5669\n5.371291\n125.8810\n147.3205\n\n\n-15\n141.0826\n5.250343\n130.6368\n151.1919\n\n\n-10\n145.7617\n5.144039\n135.5270\n155.5853\n\n\n-5\n150.0022\n5.174693\n139.5637\n159.9117\n\n\n0\n154.5556\n5.178200\n144.5177\n164.8595\n\n\n5\n159.2914\n5.138765\n149.2243\n169.2083\n\n\n\n\n\n\nUm die Perzentilintervalle zu erstellen, wird von estimate_prediction() fÃ¼r jeden PrÃ¤diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil dafÃ¼r berechnet. Sie kÃ¶nnen die Voreinstellung Ã¤ndern mittels des Arguments ci; um ein 89%-PI zu berechnen, wÃ¼rde man z.B. schreiben ci = .89.\nUm Reproduzierbarkeit sicherzustellen, haben wir mit set.seed(42) die Zufallszahlen fixiert.\nHoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedrÃ¼ckt; die PPV gibt die Ungewissheit tatsÃ¤chlicher beobachtbarer KÃ¶rpergrÃ¶ÃŸen aus, nicht nur die Ungewissheit zum Mittelwert.\nBerechnen wir die PPV fÃ¼r die bestehenden Beobachtungen aus m43a:\n\nppv_m43a &lt;- estimate_prediction(\n  m43a,\n  data = weight_df)\n\nmus \n\n\n\n\nweight_c\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n-20\n136.5669\n5.371291\n125.8810\n147.3205\n\n\n-15\n141.0826\n5.250343\n130.6368\n151.1919\n\n\n-10\n145.7617\n5.144039\n135.5270\n155.5853\n\n\n-5\n150.0022\n5.174693\n139.5637\n159.9117\n\n\n0\n154.5556\n5.178200\n144.5177\n164.8595\n\n\n5\n159.2914\n5.138765\n149.2243\n169.2083\n\n\n10\n163.6660\n5.220188\n153.4377\n174.0912\n\n\n15\n168.2456\n5.249081\n158.2699\n178.4302\n\n\n20\n172.7290\n5.322229\n162.4394\n183.2873\n\n\n\n\n\n\n\n10.7.2 Perzentilintervalle fÃ¼r verschiedenen PrÃ¤diktorwerte visualisiert\nAbbildungÂ 10.15 visualisiert die Ungewissheit von Vorhersagen laut der PPV. Die Ungewissheit in AbbildungÂ 10.15 ist die Antwort auf die Frage: â€œWie sicher sind wir uns, zur GrÃ¶ÃŸe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?â€ Eine Vorhersage bezeichnet man auch als â€œbedingte Verteilungâ€, da man den Wert einer Verteilung voraussagt, gegeben einer Bedingung, z.B. weight_c = 10.\n\n\n\n\nAbbildungÂ 10.15: Visualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV grÃ¶ÃŸer als die der Post-Verteilung.\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung, s. AbbildungÂ 10.16; je dicker die â€œKatzenaugenâ€, desto mehr Stichproben (samples) liegen vor an der Stelle, und umso genauer ist die SchÃ¤tzung.\n\n\n\n\n\nAbbildungÂ 10.16: Die PPV fÃ¼r bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu | w_i\\).\n\n10.7.3 Die PPV Ã¼ber alle Beobachtungen visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV fÃ¼r einen bestimmten PrÃ¤diktorwert, z.B. bei einer Person mittleren Gewichts. Wir kÃ¶nnen auch den Mittelwert Ã¼ber alle bedingten PPV anschauen, sozusagen die â€œMaster-PPVâ€ oder â€œunbedingte PPVâ€ oder schlicht PPV. Vergleichen wir die echten Werte fÃ¼r height, \\(y\\), mit den von der PPV simulierten Werten fÃ¼r height, \\(y_{rep}\\), s. AbbildungÂ 10.17.\n\ncheck_predictions(m43a)  # aus easystatss\n\n\n\nAbbildungÂ 10.17: Vergleich der Vorhersagen fÃ¼r y (leichte, blaue Linien) mit der beobachteten Verteilung von y\n\n\n\n?check_predictions zeigt Hilfe fÃ¼r diese Funktion. Die Funktion zeigt die Vorhersagen fÃ¼r die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n10.7.4 Fragen an die Master-PPV\n\nWie groÃŸ sind die !Kung im Schnitt?\nWelche GrÃ¶ÃŸe wird von 90% der Personen nicht Ã¼berschritten?\nWie groÃŸ sind die 10% kleinsten?\n\n\nppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\nhead(ppv_m43a)\n\n\n\n\nweight_condition\nheight\n\n\n\n1\n132.5265\n\n\n2\n136.7188\n\n\n3\n147.7576\n\n\n4\n143.1540\n\n\n5\n156.0412\n\n\n6\n157.4500\n\n\n\n\n\n\n\nppv_m43a &lt;-\n  ppv_m43a &lt;- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\nhead(ppv_m43a)\n\n\n\n\nweight_condition\nheight\n\n\n\n1\n144.0829\n\n\n2\n144.6354\n\n\n3\n141.7168\n\n\n4\n153.3734\n\n\n5\n153.9631\n\n\n6\n157.1561\n\n\n\n\n\n\n\nppv_m43a %&gt;% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n\n\n\nq_10\nheight_mean\nq_50\nq_90\n\n\n137.6442\n154.7309\n154.7682\n171.8652\n\n\n\n\n\nWas ist der 50% Bereich der KÃ¶rpergrÃ¶ÃŸe?\n\nppv_m43a %&gt;% \n  eti(ci = .5)\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\nheight\n0.5\n144.9652\n165.2586"
  },
  {
    "objectID": "0900-lineare-modelle.html#aufgaben",
    "href": "0900-lineare-modelle.html#aufgaben",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.8 Aufgaben",
    "text": "10.8 Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nLikelihood2\nPost-befragen1\nPostvert-Regr-01\nregression1a\nRegression2\nBed-Post-Wskt1\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\npenguins-stan-01"
  },
  {
    "objectID": "0900-lineare-modelle.html#section",
    "href": "0900-lineare-modelle.html#section",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "\n10.9 â€”",
    "text": "10.9 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel LÃ¼decke. 2019. â€Indices of Effect Existence and Significance in the Bayesian Frameworkâ€œ. Frontiers in Psychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "0900-lineare-modelle.html#footnotes",
    "href": "0900-lineare-modelle.html#footnotes",
    "title": "\n10Â  Lineare Modelle\n",
    "section": "",
    "text": "Da es viele Funktionen sind, bietet es sich an mit Strg-F auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.â†©ï¸\nWer ist hier fÃ¼r die Namensgebung zustÃ¤ndig? Besoffen oder was?â†©ï¸\noder zumindest besser sichergestelltâ†©ï¸\nIm Standard beschert uns stan_glm() 4000 Stichproben.â†©ï¸"
  },
  {
    "objectID": "1000-metrische-AV.html#lernsteuerung",
    "href": "1000-metrische-AV.html#lernsteuerung",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnenâ€¦\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme Ã¼bersetzen\ntypische Forschungsfragen auswerten\n\n11.1.2 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. â€œGeradenmodelle 2â€\n\n11.1.3 R-Pakete\nIn diesem Kapite lwerden folgende R-Pakete benÃ¶tigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n11.1.4 Begleitvideos\n\nTeil 1\nTeil 2"
  },
  {
    "objectID": "1000-metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "href": "1000-metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.2 Wissenschaft als Gerechtigkeitsprojekt",
    "text": "11.2 Wissenschaft als Gerechtigkeitsprojekt\n\n11.2.1 Meinungen als Grundlage der KonfliktlÃ¶sung ?\n\n\nContra:\n\nâ€œIch find Masken doof!â€\nâ€œImpfen ist schÃ¤dlich!â€\nâ€œCorona gibtâ€™s gar nicht!â€\n\n\nPro:\n\nâ€œIch find Masken gut!â€\nâ€œImpfen ist nÃ¼tzlich!â€\nâ€œCorona ist gefÃ¤hrlich!â€\n\n\n\nMeinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte kÃ¶nnen auf Basis von Meinungen nur schwer gelÃ¶st werden.\n\n11.2.2 Fakten als Grundlage der KonfliktlÃ¶sung\nWissenschaft produziert Fakten. Da Fakten universell sind (sein kÃ¶nnen), ist Wissenschaft potenziell ein Weg zur KonfliktlÃ¶sung. Warum helfen Fakten bei Konflikten?\nFakten sind neutral gegenÃ¼ber Personen. Fakten bieten daher eine Chance zur fairen Einigung.\nWann ist ein Fakt ein Fakt?\nFakten mÃ¼ssen vor allem nachprÃ¼fbar sein (Daten, Analyse und Bericht mÃ¼ssen offen zugÃ¤nglich sein).\n\n11.2.3 Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung\n\nThe effectiveness of full messenger RNA (mRNA) vaccination (â‰¥14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.\n\nThompson u.Â a. (2021); vgl. auch Nasreen u.Â a. (2021); Pormohammad u.Â a. (2021)\nDrei Anforderungen an die QualitÃ¤t von Studien:\n\n\nhandwerklich gut: z.B. vergleichbare Gruppen, genaue Messinstrumente\n\nbescheiden: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche QualitÃ¤t der Studie zulÃ¤sst. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage berÃ¼cksichtigt.\n\ntransparent: Das Vorgehen, die HintergrÃ¼nde und Ziele werden offengelegt. Das betrifft auch mÃ¶glich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen\n\n11.2.4 Psychologische Intervention zur ErhÃ¶hung der Impfquote\nDai u.Â a. (2021) zeigen den Effekt einer psychologischen Intervention zur ErhÃ¶hung der Impfquote, s. AbbildungÂ 11.1.\n\nHere we present two sequential randomized controlled trials to test the effect of behavioural interventions on the uptake of COVID-19 vaccines. â€¦ We designed text-based reminders that make vaccination salient and easy, and delivered them to participants drawn from a healthcare system one day (first randomized controlled trial) (n = 93,354 participants; clinicaltrials number NCT04800965) and eight days (second randomized controlled trial) (n = 67,092 individuals; clinicaltrials number NCT04801524) after they received a notification of vaccine eligibility. The first reminder boosted appointment and vaccination rates within the healthcare system by 6.07 (84%) and 3.57 (26%) percentage points, respectively; the second reminder increased those outcomes by 1.65 and 1.06 percentage points, respectively. The first reminder had a greater effect when it was designed to make participants feel ownership of the vaccine dose.\n\n\n\n\n\nAbbildungÂ 11.1: a, b, Proportion of participants in each condition who scheduled an appointment for the first dose of the COVID-19 vaccine at UCLA Health between 15:00 h on the first reminder date and 23:59 h on the fifth day following the first reminder date (a) and the proportion of participants in each condition who obtained the first dose of the COVID-19 vaccine at UCLA Health within four weeks of the first reminder date (b). Error bars represent Â± 1 s.e.m. The number of participants in each condition (from left to right in each panel) is 18,629, 18,592, 18,757, 18,627 and 18,749.\n\n\n\nQuelle/Volltext\n\n11.2.5 Was heiÃŸt â€œist effektivâ€?\nNasreen u.Â a. (2021) definieren effectivity, \\(e\\), so:\n\\[e = 1 - C; C= \\frac{n_{vacc|pos}}{n_{vacc|neg}}\\]\n\n\n\\(C\\) nennt man das ChancenverhÃ¤ltnis (odds ratio), es beschreibt einen Bruchterm: \\(\\frac{x}{y}\\).\n\n\\(n_{vacc|pos}\\): Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose\n\n\\(n_{vacc|neg}\\): Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose\n\nBeispiel: Von den 100 Personen mit positiver Corona-Diagnose sind 10 geimpft, \\(n_{vacc|pos}=10\\). Von den 100 Personen mit negativer Corona-Diagnose sind 90 geimpft, \\(n_{vacc|neg}=90\\)\n\\[C= \\frac{10}{90} = \\frac{1}{9}; e = 1 - \\frac{1}{9} = \\frac{8}{9} \\approx 0.88\\]\nIn diesem Beispiel liegt die EffektvititÃ¤t \\(e\\) bei knapp 90%."
  },
  {
    "objectID": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "href": "1000-metrische-AV.html#arten-von-forschungsfragen",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.3 Arten von Forschungsfragen",
    "text": "11.3 Arten von Forschungsfragen\n\n11.3.1 Nach dem Erkenntnisziel\nDeskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von GrÃ¶ÃŸe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\nPrÃ¤diktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der GrÃ¶ÃŸe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts fÃ¼r die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhÃ¤lt?\n\nPrÃ¤skriptiv (erklÃ¤rend, kausal)\n\nIst GrÃ¶ÃŸe eine Ursache von Gewicht (bei deutschen MÃ¤nnern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklÃ¤rend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehÃ¶rt.\n\n\n\n11.3.2 Nach dem Skalenniveau\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus.\nFÃ¼r die UV(s) sind nominale und metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.\n\n11.3.3 Varianten von Forschungsfragen\nIm Folgenden sind beispielhafte, hÃ¤ufig verwendete Arten von Forschungsfragen aufgefÃ¼hrt. FÃ¼r jede Variante ist ein Beispiel, die Modellformel, der DAG, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.\nDabei wird folgende Nomenklatur verwendet:\n\n\ny: metrische abhÃ¤ngige Variable\n\ng: Gruppierungsvariable; nominal skalierter unabhÃ¤ngige Variable (querschnittlich)\n\nb: binÃ¤re Variable\n\nx: metrische unabhÃ¤ngige Variable\n\nu: ungemessene Variable"
  },
  {
    "objectID": "1000-metrische-AV.html#eine-binÃ¤re-uv",
    "href": "1000-metrische-AV.html#eine-binÃ¤re-uv",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.4 Eine binÃ¤re UV",
    "text": "11.4 Eine binÃ¤re UV\n\n11.4.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im Ã¶ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwÃ¤ndigen Studie die Intelligenz vieler Kinder gemessen. ZusÃ¤tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, â€œRisikofaktorenâ€ fÃ¼r geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in AbhÃ¤ngigkeit davon, ob ihre jeweilige Mutter Ã¼ber einen Schlusabschluss (mom_hs, \\(x=1\\)) verfÃ¼gt (bzw. nicht, \\(x=0\\))? (ceteris paribus)1.\n\nFormaler ausgedrÃ¼ckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (GleichungÂ 11.1):\n\\[\\mu_{x=1|\\alpha, \\beta, \\sigma} \\ne \\mu_{x=0|\\alpha, \\beta, \\sigma} \\tag{11.1}\\]\nDie Modellformel zur Forschungsfrage lautet: y ~ b.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 11.2 dargestellt.\n\n\n\n\nAbbildungÂ 11.2: DAG fÃ¼r y ~ b\n\n\n\n\n11.4.2 IQ von Kindern, binÃ¤rer PrÃ¤diktor\n\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 &lt;- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\nAlternativ kÃ¶nnen Sie die Daten hier herunterladen.\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. TabelleÂ 11.1.\n\n\n\n\nTabelleÂ 11.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt)\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nIn AbbildungÂ 11.3 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\nestimate_expectation(m10.1) %&gt;% plot()\n\n\n\n\n\nAbbildungÂ 11.3: Kinder, deren MÃ¼tter Ã¼ber einen Schulabschluss verfÃ¼gen, haben im Mittel einen hÃ¶heren Intelligenztestwert, laut dem vorliegenden Modell\n\n\n\n\n11.4.3 Interpretation von m10.1\n\nm10.1: kid_score = 78 + 12*mom_hs + error\n\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren MÃ¼tter Ã¼ber keinen Schulabschluss (mom_hs = 0) verfÃ¼gen:\n\nkid_score = 78 + 0*12 + error\n\nDas Regressionsgewicht (slope, \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit MÃ¼tter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit MÃ¼tter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\nkid_score = 78 + 1*12 + error = 90 + error\n\nDie GrÃ¶ÃŸer der Konfidenzintervalle zeigt, wie genau die SchÃ¤tzung (Vorhersage) ist bzw. wie stark PrÃ¤diktor (UV) und Kriterium (AV) zusammenhÃ¤ngen.\n\n11.4.4 m10.1 als Mittelwertsdifferenz\n\nUV: binÃ¤r (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\nHey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heiÃŸen kid_score_avg. An die Arbeit!\n\nkidiq %&gt;% \n  group_by(mom_hs) %&gt;% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n0\n77.54839\n\n\n1\n89.31965\n\n\n\n\n\n\nIn der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation mit einem t-Test. Der t-Test ist ein inferenzstatistisches Verfahren, das prÃ¼ft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).2 In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von MÃ¼ttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.\n\n11.4.5 Antwort auf die Forschungsfrage, m10.1\n\nBetrachten wir die Ergebnisse von m10.1. Hier sind die ersten paar Zeilen.\n\nm10.1_post &lt;-\n  m10.1 %&gt;% \n  as_tibble() \n\nnames(m10.1_post) &lt;- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schÃ¶nere Namen\n\n\n\n\n\n\n\n\n\nStichprobe aus der Post-Verteilung\n    \n\nAchsenabschnitt\n      momhs\n      sigma\n    \n\n\n\n75.9\n14.1\n19.7\n\n\n78.3\n12.7\n19.6\n\n\n77.5\n11.2\n18.8\n\n\n75.5\n14.8\n21.9\n\n\n79.3\n10.9\n20.1\n\n\n\n\n\n\nBerechnen wir ein 95%-PI von Hand:3\n\npi_mom_hs &lt;-\n  m10.1_post %&gt;% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n\n  \n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von MÃ¼ttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschlieÃŸend die Posteriori-Verteilung, s. AbbildungÂ 11.4.\n\nplot(eti(m10.1))\n\n\n\nAbbildungÂ 11.4: Das 95% ETI zum (statistischen) Effekt des mÃ¼tterlichen Schulabschlusses\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem â€œEffektâ€ zu sprechen, lÃ¤sst in den meisten KÃ¶pfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang.\n\n11.4.6 Variante zur Forschungsfrage\nUnsere Psychologin kÃ¶nnte auch folgende Hypothese formulieren:\n\nDie Wahrscheinlichkeit fÃ¼r ein Kind mit guten Testwerten (y) ist hÃ¶her, wenn die Mutter Ã¼ber einen Schulabschluss verfÃ¼gt.\n\nPrÃ¤ziser formuliert:\n\\[Pr(y &gt; 100|x=1, \\alpha, \\beta, \\sigma) &gt; Pr(y &gt; 100|x=0, \\alpha, \\beta, \\sigma)\\]\nDer vertikale Balken â€œ|â€ liest sich als â€œgegeben, dassâ€. Hier wird auf die Wahrscheinlichkeit fÃ¼r ein Testergebnis \\(y&gt;100\\), gegeben, dass die Mutter Ã¼ber einen Schulabschluss verfÃ¼gt (\\(x=1\\)) und gegeben der Modellparameter \\(\\alpha, \\beta, \\sigma\\)."
  },
  {
    "objectID": "1000-metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "1000-metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.5 Eine metrische plus eine nominale UV",
    "text": "11.5 Eine metrische plus eine nominale UV\n\n11.5.1 Forschungsfrage\n\nWie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 11.5 dargestellt.\n\n\n\n\nAbbildungÂ 11.5: DAG fÃ¼r y ~ b\n\n\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle TabelleÂ 11.2 dargestellt.\n\ndata(\"kidiq\")  # Paket rstanarm, alternativ Ã¼ber CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\nTabelleÂ 11.2: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\nDatenquelle\n\n11.5.2 1 metrischer PrÃ¤diktor\nBerechnen wir folgendens Modell: kid_score ~ mom_iq (m10.2), s. Tab. TabelleÂ 11.3.\n\nm10.2 &lt;-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %&gt;% \n  parameters()\n\n\n\n\n\nTabelleÂ 11.3: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\nVisualisieren wir uns noch das Modell m10.2, s. AbbildungÂ 11.6.\n\nkidiq %&gt;% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\nAbbildungÂ 11.6: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, s. AbbildungÂ 11.7.\n\nplot(estimate_expectation(m10.2))\n\n\n\nAbbildungÂ 11.7: Die geschÃ¤tzten Erwartungswerte von m10.2 visualisiert\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder fÃ¼r verschiedene IQ-Werte der MÃ¼tter. Vergleicht man Teilpopulationen von MÃ¼ttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n11.5.3 Beide PrÃ¤diktoren, m10.3\n\nBerechnen wir als nÃ¤chstes ein Modell mit beiden PrÃ¤diktoren: kid_score ~ mom_hs + mom_iq, s. TabelleÂ 11.4.\n\nm10.3 &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\nTabelleÂ 11.4: Parameter des Modells m10.3 (ohne sigma)\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. PunktschÃ¤tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\nm10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error\nMÃ¶chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\nAber natÃ¼rlich ist es mÃ¶glich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. AbbildungÂ 11.8.\n\nkidiq2 &lt;-\n  kidiq %&gt;% \n  mutate(mom_hs = as.factor(mom_hs))\n\nm10.3a &lt;- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq2)\n\nplot(estimate_expectation(m10.3a))\n\n\n\nAbbildungÂ 11.8: Der Effekt von sowohl mÃ¼tterlicher Intelligenz als auch mÃ¼tterlichem Schulabschluss.\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schÃ¤tzt das Modell den IQ-Wert des Kindes auf 26.\n\nKoeffizient zum mÃ¼tterlichen Schulabschluss: Vergleicht man Kinder von MÃ¼ttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\n\nKoeffizient zur mÃ¼tterlichen IQ: Vergleicht man Kinder von MÃ¼ttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus."
  },
  {
    "objectID": "1000-metrische-AV.html#interaktion",
    "href": "1000-metrische-AV.html#interaktion",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.6 Interaktion",
    "text": "11.6 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen. Liegt keine Interaktion vor, so sind die Geraden parallel.\\(\\square\\)\n\n\nWir berechnen mit m10.4 folgendes Modell: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. AbbildungÂ 11.9 und TabelleÂ 11.5.\n\nm10.4 &lt;- \n  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\nTabelleÂ 11.5: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n-10.59\n(-37.44, 16.30)\n77.62%\n1.001\n1427.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n49.76\n(21.49, 79.27)\n100%\n1.003\n1401.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.001\n1412.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq\n-0.47\n(-0.78, -0.17)\n99.85%\n1.003\n1367.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 11.9: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt fÃ¼r diese Daten kaum zu interpretieren ist.\n\n\n\nDie Modellformel zur Forschungsfrage lautet: y ~ x + b + x:b.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 11.10 dargestellt.\n\n\n\n\nAbbildungÂ 11.10: DAG fÃ¼r y ~ x + b + x:b\n\n\n\n\n11.6.1 Interpretation von m10.4\n\n\n\nAchsenabschnitt: IQ-SchÃ¤tzwerte fÃ¼r Kinder mit MÃ¼tter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\n\nmom_hs: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\n\nmom_iq: Unterschied der IQ-SchÃ¤tzwerte zwischen Kindern mit MÃ¼ttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\n\nInteraktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten fÃ¼r mom_iq zwischen MÃ¼tter mit bzw. ohne Schulabschluss.\n\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\nGelman, Hill, und Vehtari (2021), Kap. 10.3\n\n11.6.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "1000-metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "href": "1000-metrische-AV.html#zentrieren-von-prÃ¤diktoren",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.7 Zentrieren von PrÃ¤diktoren",
    "text": "11.7 Zentrieren von PrÃ¤diktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert. Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq.\nMan kÃ¶nnte auch mom_hs zentrieren, aber fÃ¼r eine einfache Interpretation ist es meist nÃ¼tzlich, nur metrische PrÃ¤diktoren zu zentrieren.\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n\n\n\n\nFixed Effects\n\nParameter\nMedian\n\n\n\n(Intercept)\n85.31\n\n\nmom_hs\n2.91\n\n\nmom_iq_c\n0.97\n\n\nmom_hs:mom_iq_c\n-0.48\n\n\n\n\n\n\n11.7.1 Interpretation von m10.5\n\n\nDer Achsenabschnitt (Intercept) gibt den geschÃ¤tzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\n\nmom_hs gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\n\nmom_iq_c gibt den Unterschied im geschÃ¤tzten IQ des Kindes an, wenn man MÃ¼tter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\n\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten fÃ¼r mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nm10.5 ist in AbbildungÂ 11.11 dargestellt.\n\n\n\n\nAbbildungÂ 11.11: m10.5: Interaktionsmodell mit zentriertem PrÃ¤diktor fÃ¼r mÃ¼tterlicher Intelligenz\n\n\n\n\n11.7.2 Zentrieren Ã¤ndert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new &lt;- posterior_predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.64842\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5:\n\nnew &lt;- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new &lt;- posterior_predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.75137\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren Ã¤ndert auch nicht die Regressionskoeffizienten, da die Streuungen der PrÃ¤diktoren nicht verÃ¤ndert wurden.\n\n11.7.3 Perzentilintervalle aus der Posterori-Verteilung\nTabelleÂ 11.6 zeigt die PunktschÃ¤tzer der Parameter fÃ¼r m10.5 sowie ihre Perzentilintervalle4. Nutzen Sie dafÃ¼r parameters(m10.5), s. TabelleÂ 11.6.\n\n\n\n\nTabelleÂ 11.6: Parameter von m10.5 und ETIs\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(80.99, 89.72)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.69)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.67, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. TabelleÂ 11.7.\n\nparameters(m10.5, ci_method = \"hdi\") %&gt;% \n  display()\n\n\n\nTabelleÂ 11.7: Parameter von m10.5 und HDIs\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n85.31\n(81.26, 89.88)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.70)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.79, -0.17)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n11.7.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei MÃ¼ttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mÃ¼tterlichen Intelligenz; pro Punkt Unterschied in mÃ¼ttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). AuÃŸerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei MÃ¼tter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. ZusammenhÃ¤nge beschrieben. FÃ¼r kausale Aussagen ist mehr nÃ¶tig, als einen statistischen Zusammenhang festzustellen."
  },
  {
    "objectID": "1000-metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "1000-metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.8 Eine nominale UV mit mehreren Stufen",
    "text": "11.8 Eine nominale UV mit mehreren Stufen\n\n11.8.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in; Ihre Kompetenz als Wirtschaftspsychologi war heiÃŸ begehrt. Von Statistik wollte niemand etwas wissenâ€¦ Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt fÃ¼hrte Sie in die Antarktisâ€¦ Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um GrÃ¶ÃŸenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren KÃ¶rpergewichte der drei Pinguinarten?\n\nDie Modellformel zur Forschungsfrage lautet: y ~ g.\nDer DAG zur Modellformel sieht aus in AbbildungÂ 11.12 dargestellt.\n\n\n\n\nAbbildungÂ 11.12: DAG fÃ¼r y ~ g\n\n\n\n\n11.8.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ğŸ¤” Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere KÃ¶rpergewichte in AbhÃ¤ngigkeit von der Pinguinart?\n\nAlternativ kÃ¶nnen wir die Hypothese prÃ¼fen, ob die Mittelwerte â€œpraktischâ€ gleich sind, also sich â€œkaumâ€ unterscheiden. Der Grenzwert fÃ¼r â€œpraktisch gleichâ€ bzw. â€œkaum unterschiedlichâ€ ist subjektiv. Dazu in KapitelÂ 11.11 mehr.\n\n11.8.3 Erster Blick in den Datensatz penguins\n\n\n\nPalmer Penguins\n\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Quelle der Daten:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\n#| results: \"hide\"\n#| message: false\npenguins &lt;- \n  read_csv(penguins_url)\n\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz, TabelleÂ 11.8.\n\npenguins %&gt;% \n  select(body_mass_g, species) %&gt;% \n  group_by(species) %&gt;% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\n TabelleÂ 11.8:  Die Verteilung des KÃ¶rpergewichts pro Spezies der Pinguine \n  \n\n\n\n\nWas fÃ¤llt Ihnen auf?\n\n11.8.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. AbbildungÂ 11.13?\n\n\n\n\nAbbildungÂ 11.13: Verteilung des KÃ¶rpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.8.5 Mittlere Gewichtsunterschiede in der Population\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und TabelleÂ 11.9.\n\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrÃ¼ckt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nm10.6 %&gt;% parameters()\n\n\n\n\n\nTabelleÂ 11.9: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3700.35\n(3629.70, 3774.26)\n100%\n1.000\n4156.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n33.23\n(-101.11, 164.89)\n68.08%\n1.000\n4139.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.51\n(1265.81, 1486.61)\n100%\n1.000\n4201.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n11.8.6 Interpretation von m10.6\n\nDie UV hat drei verschiedene Stufen (Werte, AusprÃ¤gungen; hier: Spezies), aber es werden in TabelleÂ 11.9 nur zwei Stufen angezeigt (also eine weniger) zusÃ¤tzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrÃ¼ckt (Intercept). Die Koeffizienten fÃ¼r species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in AbbildungÂ 11.14 verdeutlicht.\n\nplot(hdi(m10.6)) + scale_fill_okabeito()\n\n\n\nAbbildungÂ 11.14: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\nDas Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (d.Â Details hier).\n\n11.8.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich hÃ¶her als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich Ã¤hnlich.\nWie in AbbildungÂ 11.14 ersichtlich, Ã¼berlappt sich der SchÃ¤tzbereich fÃ¼r den Parameter von Gentoo nicht mit der Null; hingegen Ã¼berlappt sich der SchÃ¤tzbereich des Parameters fÃ¼r Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hÃ¤tte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prÃ¼fen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primÃ¤r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen."
  },
  {
    "objectID": "1000-metrische-AV.html#priori-werte",
    "href": "1000-metrische-AV.html#priori-werte",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.9 Priori-Werte",
    "text": "11.9 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. FÃ¼r Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfÃ¼r Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: prior_summary(modell):\n\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWo man man Ã¼ber mehr inhaltliches Wissen verfÃ¼gt, so wird man die Prioris anpassen wollen, z.B.:\n\nm10.6b &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(500, 500)),  # betas, Streuung\n  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n  prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3704.89008         22.93895       1356.65099\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\nm10.6c &lt;- stan_glm(\n  body_mass_g ~ species, \n  data = penguins, \n  refresh = 0,\n  seed = 42,\n  prior = normal(location = c(0, 0),  # betas, Mittelwert\n                 scale = c(2.5, 2.5),  # betas, Streuung\n                 autoscale = TRUE),  # in z-Einheiten\n  prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                           autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.99471         32.08176       1374.15711\n\nDen Parameter fÃ¼r die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\nsigma(m10.6b)\n## [1] 463.7358\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die GrÃ¶ÃŸe der Konfidenzintervalle.\nÃœbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren5.\n\n11.9.1 Wechsel der Referenzkategorie\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species))\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge Ã¤ndern.\n\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nlibrary(forcats)\npenguins &lt;- penguins %&gt;% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\nBeachten Sie, dass dazu das Paket forcats verfÃ¼gbar sein muss.\nJetzt haben wir die Referenzkategorie geÃ¤ndert:\n\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\nDer Wechsel der Referenzkategorie Ã¤ndert nichts Wesentliches am Modell, s. TabelleÂ 11.10.\n\nm10.6a &lt;- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nTabelleÂ 11.10: m10.6a mit geÃ¤nderter Referenzkategorie; die Effekte der UVs bleiben gleich.\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 4993.36, 5158.93]\n\n\nspeciesAdelie\n[-1483.37, -1259.84]\n\n\nspeciesChinstrap\n[-1482.17, -1200.79]"
  },
  {
    "objectID": "1000-metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "href": "1000-metrische-AV.html#modellgÃ¼te-mit-r-quadrat-bestimmen",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.10 ModellgÃ¼te mit R-Quadrat bestimmen",
    "text": "11.10 ModellgÃ¼te mit R-Quadrat bestimmen\n\n11.10.1 ModellgÃ¼te mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklÃ¤rt. - HÃ¶here Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklÃ¤rt. \\(R^2\\) wird normalerweise auf Basis eines PunktschÃ¤tzers definiert. Solch eine Definition lÃ¤sst aber viel Information - Ã¼ber die Ungewissheit der SchÃ¤tzung - auÃŸen vor. Daher ist es wÃ¼nschenswert, diese Information in \\(R^2\\) einflieÃŸen zu lassen: Bayes-R-Quadrat.\n\n\n\nr2(m10.6)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.667 (95% CI [0.619, 0.712])\n\nMÃ¶chte man es ausfÃ¼hrlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. AbbildungÂ 11.15.\n\nm10.6_r2 &lt;-\nm10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\nAbbildungÂ 11.15: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n11.10.2 Definition vom â€œklassischenâ€ \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die â€œtypischeâ€ Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nÃ¼tzlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklÃ¤rten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck Ã¤quivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen AusdrÃ¼cke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlÃ¤ssigen Ungewissheit; sie sind Ã¼bergewiss aus Bayes-Sicht.\n\n11.10.3 Bayesâ€™ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der ModellgÃ¼te miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkÃ¤rte Varianz}}{\\text{ErklÃ¤rte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. FÃ¼r jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklÃ¤rten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. (gelman_r_squared_2019?), Gelman, Hill, und Vehtari (2021), Kap. 11.7."
  },
  {
    "objectID": "1000-metrische-AV.html#sec-rope",
    "href": "1000-metrische-AV.html#sec-rope",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.11 Nullhypothesen sind praktisch immer falsch",
    "text": "11.11 Nullhypothesen sind praktisch immer falsch\nNullhypothesen sind fast immer falsch, s. AbbildungÂ 11.16.\n\n\n\n\nAbbildungÂ 11.16: Du testest Nullhypothesen?\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, und Vehtari (2021)\n\n11.11.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest mÃ¶glich ist6\nEin anderer Grund ist vermutlich, â€¦ wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\nRope-Konzept (Kruschke 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n11.11.2 â€œPraktischâ€ kein Unterschied: Das Rope-Konzept\nSagen wir, wenn sich zwei Preismittelwerte um hÃ¶chstens \\(d=100\\)â‚¬ unterscheiden, gilt dieser Unterschied fÃ¼r uns als â€œpraktisch gleichâ€, â€œpraktisch kein Unterschiedâ€ bzw. vernachlÃ¤ssigbar. Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Ãœberlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Ã„quivalenzzone, Bereich eines vernachlÃ¤ssigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prÃ¼fen wir, ob ein â€œGroÃŸteilâ€ der Posteriori-Stichproben im Rope liegt. Unter â€œGroÃŸteilâ€ wird hÃ¤ufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroÃŸteil liegt innerhalb von Rope â¡ï¸ Annahme der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nGroÃŸteil liegt auÃŸerhalb von Rope â¡ï¸ Ablehnung der Nullhypothese â€œpraktisch kein Effektâ€, \\(H_0\\)\n\nAnsonsten â¡ï¸ keine Entscheidung\n\n11.11.3 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\nAbbildungÂ 11.17: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\nAbbildungÂ 11.17 illustriert die Entscheidungsregel zum ROPE fÃ¼r mehrere Situatioenen (Kruschke 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett auÃŸerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung mÃ¶glich; die Datenlage ist unklar.\n\n11.11.4 Rope berechnen\nDen Rope berechnet man mit rope(model).\n\nrope(m10.6)\n\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen betrÃ¤chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir kÃ¶nnen daher fÃ¼r diese Gruppe das ROPE nicht verwerfen.\nAber: Gentoo liegt zu 0% im Rope. FÃ¼r Gentoo kÃ¶nnen wir das Rope verwerfen.\nDas hÃ¶rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n11.11.5 Visualisierung unserer Rope-Werte, m10.6\n\nEin GroÃŸteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber kÃ¶nnen wir umgekehrt sagen, dass ein GroÃŸteil auÃŸerhalb liegt? Das erkennt man optisch ganz gut.\n\n\nplot(rope(m10.6)) + scale_fill_okabeito()\n\n\n\n\nDas ROPE druchkreuzt die â€œBergeâ€ der Posteriori-Verteilung fÃ¼r Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir kÃ¶nnen das Rope fÃ¼r Chinstrap nicht verwerfen, aber auch nicht bestÃ¤tigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom â€œblauen Flussâ€ des Rope: Gentoo liegt auÃŸerhalb des Rope. Es gibt einen â€œsubstanziellenâ€ Unterschied, grÃ¶ÃŸer als das ROPE. Wir verwerfen die â€œPraktisch-Null-Hypotheseâ€ in diesem Fall.\n\n11.11.6 Finetuning des Rope\nWir kÃ¶nnen festlegen, was wir unter â€œpraktischer Ã„quivalenzâ€ verstehen, also die Grenzen des Ropes verÃ¤ndern. Sagen wir, 100 Gramm sind unsere Grenze fÃ¼r einen vernachlÃ¤ssigbaren Effekt, s. AbbildungÂ 11.18.\n\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\nAbbildungÂ 11.18: ROPE mit selber eingestellter Grenze von Â±100 (Gramm)\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so Ã¤ndern, wenn man mÃ¶chte:\n\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht fÃ¼r ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.\n\n11.11.7 Beantwortung der Forschungsfrage\nFÃ¼r die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. FÃ¼r Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs mÃ¶glich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt."
  },
  {
    "objectID": "1000-metrische-AV.html#mehrere-metrische-uv",
    "href": "1000-metrische-AV.html#mehrere-metrische-uv",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.12 Mehrere metrische UV",
    "text": "11.12 Mehrere metrische UV\n\n11.12.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhÃ¤ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa â€œIQ der Mutter ist die Ursache zum IQ des Kindesâ€) wird impliziert.\nEs geht rein darum, ZusammenhÃ¤nge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. FÃ¼r solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nÃ¶tig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n11.12.2 Was heiÃŸt, X hÃ¤ngt mit Y zusammen?\n\nDer Begriff â€œZusammenhangâ€ ist nicht exakt.\nHÃ¤ufig wird er (fÃ¼r metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\n\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\n\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groÃŸ der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem â€œEffekt von X auf Yâ€ Ã¼bersetzt. Vorsicht: â€œEffektâ€ klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende BegrÃ¼ndung fÃ¼r einen Kausalzusammenhang.\n\n\nDer Korrelationskoeffizient\n\nmisst eine Art der StÃ¤rke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehÃ¶rigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n11.12.3 Korrelationen zur Forschungsfrage\n\nkidiq %&gt;% \n  correlation()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n&lt; .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n&lt; .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n&lt; .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\nTabelleÂ 11.11 zeigt die Korrelationsmatrix als Korrelationsmatrix:\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary()\n\n\n\n\n\nTabelleÂ 11.11: Die Korrelationen zwischen den Variablen der Tabelle kidiq\n\nParameter\nmom_age\nmom_iq\nmom_hs\n\n\n\nkid_score\n0.09\n0.45***\n0.24***\n\n\nmom_hs\n0.21***\n0.28***\n\n\n\nmom_iq\n0.09\n\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\nNÃ¼tzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, AbbildungÂ 11.19.\n\nkidiq %&gt;% \n  correlation() %&gt;% \n  summary() %&gt;% \n  plot()\n\n\n\nAbbildungÂ 11.19: Visualisierung der Korrelationsmatrix als Heatmap\n\n\n\n\n11.12.4 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro PrÃ¤diktor, also eine fÃ¼r mom_iq und eine fÃ¼r mom_age.\n\nm10.7 &lt;- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 &lt;- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\nHier die Ergebnisse fÃ¼r mom_iq:\n\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.8244519   0.6097893\n\nHier die Ergebnisse fÃ¼r mom_age:\n\ncoef(m10.8)\n## (Intercept)     mom_age \n##   70.945281    0.696008\n\n\n11.12.5 Visualisierung der univariaten Regressionen\nIn AbbildungÂ 11.20 ist die univariate Regression mit jeweils einem der beiden PrÃ¤diktoren dargestellt.\nm10.7: Die Steigung betrÃ¤gt 0.6. m10.8: Die Steigung betrÃ¤gt 0.7.\n\n\n\n\nAbbildungÂ 11.20: Zwei univariate Regressionen\n\n\n\nUnivariate Regressionen\n\n11.12.6 Multiples Modell (beide PrÃ¤diktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein PrÃ¤diktor im Modell aufgenommen ist.\n\nm10.9 &lt;- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.7681798   0.6039808   0.3846929\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils â€œbereinigtâ€ vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines PrÃ¤diktors mit der AV, wobei man gleichzeitig den anderen PrÃ¤diktor konstant hÃ¤lt.\n\n\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.7681798   0.6039808   0.3846929\n\n\n11.12.7 3D-Visualisierung eines Modells mit zwei PrÃ¤diktoren 1\nIn AbbildungÂ 11.21 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\nAbbildungÂ 11.21: 3D-Visualisierung von m10.9 (zwei PrÃ¤diktoren)\n\n\n\n11.12.8 Visualisierung mit Farbe statt 3. Dimension\n3D-Visualisierungen haben Vorteile, aber auch Nachteile; AbbildungÂ 11.22 zeigt eine alternative Visualisierung, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\nAbbildungÂ 11.22: Modell m10.9; die FarbverlÃ¤ufe zeigen der Wert der abhÃ¤ngigen Variablen\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der FarbÃ¤nderung) die VerÃ¤nderung fÃ¼r die AV (kid_score). Auf der Achse fÃ¼r mom_age sieht man, dass sich die AV kaum Ã¤ndert, wenn sich mom_age Ã¤ndert.\n\n11.12.9 Visualisierung in 10 Dimensionen\nAbbildungÂ 11.23 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\nAbbildungÂ 11.23: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere SchwÃ¤chen, eine groÃŸe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n11.12.10 Relevanz der PrÃ¤diktoren\nWoher weiÃŸ man, welcher PrÃ¤diktor am stÃ¤rksten mit der AV zusammenhÃ¤ngt? Man kÃ¶nnte auch sagen: Welcher PrÃ¤diktor (welche UV) am â€œwichtigstenâ€ ist oder den â€œstÃ¤rksten Einflussâ€ auf die AV ausÃ¼bt? Bei solchen kausal konnotierten AusdrÃ¼cken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann fÃ¼r sich nur Muster in den Daten, also ZusammenhÃ¤nge bzw. Unterschiede, entdecken, s. AbbildungÂ 11.24.\n\n\nAbbildungÂ 11.24: Made at imgflip.com\n\nWelcher PrÃ¤diktor ist nun â€œwichtigerâ€ oder â€œstÃ¤rkerâ€ in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)?\n\n\nmom_iq hat den grÃ¶ÃŸeren Koeffizienten.\n\nmom_age hat weniger Streuung.\n\nUm die Relevanz der PrÃ¤diktoren vergleichen zu kÃ¶nnen, mÃ¼sste man vielleicht die VerÃ¤nderung von kid_score betrachten, wenn man von kleinsten zum grÃ¶ÃŸten PrÃ¤diktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die VerÃ¤nderung in der AV zu betrachten, wenn man den PrÃ¤diktor von â€œunterdurchschnittlichâ€ auf â€œÃ¼berdurchschnittlichâ€ Ã¤ndert. Das kann man mit z-Standardisierung erreichen.\n\n11.12.11 z-Standardisierung\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie Ã¼ber einen Mittelwert von 0 und eine SD von 1 verfÃ¼gt:\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\ndata(\"kidiq\")\nkidiq2 &lt;- \n  kidiq %&gt;% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %&gt;% \n  select(mom_iq, mom_iq_z) %&gt;% \n  head()\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten7. Die Standardisierung ist Ã¤hnlich zur Vergabe von ProzentrÃ¤ngen: â€œDieser Messwert gehÃ¶rt zu den Top-3-Prozentâ€. Diese Aussage ist bedeutsam fÃ¼r Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen fÃ¼r verschiedene Verteilungen mÃ¶glich.\n\n11.12.12 Statistiken zu den z-transformierten Variablen\nTabelleÂ 11.2 zeigt die Verteilung der (metrischen) Variablen im Datensatz kidiq.\nMetrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:\n\nder Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer AusprÃ¤gung bezieht)\nInteraktionen sind einfacher zu interpretieren (aus dem gleichen Grund)\nPrioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)\ndie Effekte verschiedener PrÃ¤diktoren sind einfacher in ihrer GrÃ¶ÃŸe zu vergleichen, da dann mit gleicher Skalierung/Streuung\nkleine und Ã¤hnlich groÃŸe Wertebereich erleichtern dem Golem die Rechenarbeit\n\nMan kann die z-Transformation (â€œSkalierungâ€) mit standardize (aus easystats) durchfÃ¼hren, s. TabelleÂ 11.12.\n\nkidiq_z &lt;- \n  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte\n\n\n\n\n\nTabelleÂ 11.12: z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\npred_m10.9\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\npred_m10.9_z\n\n\n\n65\n1\n121.12\n27\n101.31\n-1.07\n0.52\n1.41\n1.56\n1.56\n\n\n98\n1\n89.36\n25\n81.36\n0.55\n0.52\n-0.71\n0.82\n-0.60\n\n\n85\n1\n115.44\n27\n97.88\n-0.09\n0.52\n1.03\n1.56\n1.19\n\n\n83\n1\n99.45\n25\n87.45\n-0.19\n0.52\n-0.04\n0.82\n0.06\n\n\n115\n1\n92.75\n27\n84.17\n1.38\n0.52\n-0.48\n1.56\n-0.30\n\n\n98\n0\n107.90\n18\n89.86\n0.55\n-1.91\n0.53\n-1.77\n0.32\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafÃ¼r, dass die ursprÃ¼nglichen Variablen beim z-Standardisieren nicht Ã¼berschrieben werden, sondern angehÃ¤ngt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren, indem man das Argument select nutzt.\n\nkidiq %&gt;% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. TabelleÂ 11.13. Dazu verwendet man den Befehl scale().\n\nkidiq %&gt;% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score))\n\n\n\n\n\n TabelleÂ 11.13:  Z-Standardisierung ohne Extrapaketâ€"
  },
  {
    "objectID": "1000-metrische-AV.html#modell-m10.10",
    "href": "1000-metrische-AV.html#modell-m10.10",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.13 Modell m10.10\n",
    "text": "11.13 Modell m10.10\n\nIm Modell m10.10 sind die PrÃ¤diktoren z-standardisiesrt. Das Standardisieren der AV, kid_score ist nicht nÃ¶tig, um den Effekt der PrÃ¤diktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darÃ¼ber, um wie viele SD-Einheiten sich die AV verÃ¤ndert, wenn sich ein PrÃ¤diktor um eine SD-Einheit verÃ¤ndert.\n\nm10.10 &lt;- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq_z, \n                   refresh = 0)\ncoef(m10.10)\n## (Intercept)    mom_iq_z   mom_age_z \n## 0.000371288 0.444807424 0.050682655\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient fÃ¼r mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_iq um eine SD-Einheit Ã¤ndert.\nDer Koeffizient fÃ¼r mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) Ã¤ndert, wenn sich mom_age um eine SD-Einheit Ã¤ndert.\n\nJetzt sind die PrÃ¤diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n11.13.1 95%-PI\nMit parameters kÃ¶nnen wir uns ein PI fÃ¼r m10.10 ausgeben lassen, s. AbbildungÂ 11.25; im Standard wird ein 95%-ETI berichtet8.\n\nparameters(m10.10) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n3.71e-04\n(-0.08, 0.08)\n50.42%\n1.000\n4856.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n1.001\n5008.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.17%\n1.000\n3966.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nplot(eti(m10.10)) + scale_fill_okabeito()\n\n\n\nAbbildungÂ 11.25: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI fÃ¼r m10.10\n\n\n\n\n11.13.2 Was ist ein kleiner, was ein groÃŸer Effekt?\nCohen (1988) definiert EffektstÃ¤rken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\). FÃ¼r kleine, mittlere und groÃŸe Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\n\nmittel: \\(d \\approx 0.5\\)\n\ngroÃŸ: \\(d \\approx 0.8\\)\n\n\nAuf dieser Basis schlÃ¤gt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor. FÃ¤llt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als â€œpraktisch nullâ€. Richtlinien fÃ¼r EffektstÃ¤rken sind nur NotlÃ¶sungen, die durch Sachverstand ersetzt werden sollen, wo immer mÃ¶glich. Man kann EffektstÃ¤rken ineinander Ã¼berfÃ¼hren, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n11.13.3 VernachlÃ¤ssigbarer Regressionseffekt\nKruschke (2018) schlÃ¤gt vor, einen Regressionskoeffizienten unter folgenden UmstÃ¤nden als â€œpraktisch Nullâ€ zu bezeichnen:\nWenn eine VerÃ¤nderung Ã¼ber â€œpraktisch den ganzen Wertebereichâ€ von \\(x\\) nur einen vernachlÃ¤ssigbaren Effekt auf \\(y\\) hat. Ein vernachlÃ¤ssigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der â€œpraktisch ganze Wertebereichâ€ von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine VerÃ¤nderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlÃ¤ssigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) fÃ¼r z-standardisierte Variablen.\n\n11.13.4 ModellgÃ¼te\n\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.141, 0.268])\n\nIst dieser Wert von \\(R2\\) â€œgutâ€? Diese Frage ist Ã¤hnlich zur Frage â€œIst das viel Geld?â€; man kann die Frage nur im Kontext beantworten.\nEine einfache LÃ¶sung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklÃ¤rt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufÃ¤llig hohen Werten der ModellgÃ¼te im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine â€œobjektiveâ€ Antwort auf die Frage â€œwie viel ist viel?â€ haben wollen, ziehen wir Herrn Cohen zu Rate:\n\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\nDanke, Herr Cohen!\n\n11.13.5 Priori-Verteilung fÃ¼r m10.10 und Modelldefinition\nStan hat fÃ¼r uns folgende Prioris ausgesucht:\n\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\nWie gesagt, Stan nimmt dafÃ¼r einfach die empirischen Mittelwerte und Streuungen her9.\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. GleichungÂ 11.2.\n\\[\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{11.2}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.10. Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzufÃ¼hren.\n\n11.13.6 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar fÃ¼r einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkÃ¤rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich u.Â a. 2020) zurÃ¼ck (s. Anhang fÃ¼r Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem â€œstatistischen Effektâ€ gesprochen, um klar zu machen, dass es sich lediglich um assoziative ZusammenhÃ¤nge, und nicht um kausale ZusammenhÃ¤nge, handelt. Kausale ZusammenhÃ¤nge dÃ¼rfen wir nur verkÃ¼nden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafÃ¼r finden oder c) wir ein Experiment fachgerecht durchgefÃ¼hrt haben."
  },
  {
    "objectID": "1000-metrische-AV.html#vertiefung",
    "href": "1000-metrische-AV.html#vertiefung",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.14 Vertiefung",
    "text": "11.14 Vertiefung\nğŸï¸VERTIEFUNG, nicht prÃ¼fungsrelevantğŸï¸\n\n11.14.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\\[b = r \\frac{sd_x}{sd_y}\\]\nBerechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen und betrachten die PunktschÃ¤tzer fÃ¼r die Regressionskoeffizienten:\n\nm10.11 &lt;- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)\ncoef(m10.11)\n##  (Intercept)     mom_iq_z \n## 0.0004288487 0.4470145558\n\nVergleichen Sie diese Werte mit der Korrelation, s. TabelleÂ 11.14.10\n\nkidiq_z %&gt;% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %&gt;% \n  correlation() |&gt; \n  display()\n\n\nTabelleÂ 11.14: ?(caption)\n\n\n\n\n(a) Correlation Matrix (pearson-method)\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nkid_score\nkid_score_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nkid_score_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\nmom_iq\nmom_iq_z\n1.00\n(1.00, 1.00)\nInf\n&lt; .001***\n\n\nkid_score_z\nmom_iq_z\n0.45\n(0.37, 0.52)\n10.42\n&lt; .001***\n\n\n\n\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\n\nKorrelationen der z-transformierten Variablen im Datensatz kidiq\n\n\n\n\n\n11.14.2 PrÃ¼fen der LinearitÃ¤tsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen PrÃ¤diktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression hÃ¤ufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schÃ¤tzen (Gelman, Hill, und Vehtari 2021).\nIst die LinearitÃ¤tsannahme erfÃ¼llt, so sollte der Residualplot nur zufÃ¤llige Streuung um \\(y=0\\) herum zeigen, s. AbbildungÂ 11.26.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsÃ¤chlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\nkidiq &lt;-\n  kidiq %&gt;% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\nkidiq %&gt;% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\nAbbildungÂ 11.26: Die Verteilung der Fehler scheint keinem starken Trend (in AbhÃ¤ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\nHier erkennt man keine grÃ¶ÃŸeren AuffÃ¤lligkeiten.\n\n11.14.3 ModellprÃ¼fung mit der PPV\n\npp_check(m10.10)\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht hÃ¤ufig.\n\n11.14.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\n\n\nAbbildungÂ 11.27: Bereinigte Regressionskoeffizienten\n\n\n\nAbbildungÂ 11.27 zeigt in der oberen Reihe die Regression eines PrÃ¤diktors auf den anderen PrÃ¤diktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heiÃŸt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhÃ¤ngt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n11.14.5 Bayesianisch gleich Frequentistisch?\nÃœbrigens liefern stan_glm() und lm oft Ã¤hnliche Ergebnisse (bei schwach informativen Prioriwerten):\n\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %&gt;% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %&gt;% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Ergebnisse eines Frequentistischen und Bayes-Modell numerisch Ã¤hnlich sein kÃ¶nnen, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.\n\n\n\n11.14.6 Post: Bayes in fÃ¼nf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem."
  },
  {
    "objectID": "1000-metrische-AV.html#ausblick-binÃ¤re-av",
    "href": "1000-metrische-AV.html#ausblick-binÃ¤re-av",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.15 Ausblick: BinÃ¤re AV",
    "text": "11.15 Ausblick: BinÃ¤re AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\ndata(mtcars)\nmtcars2 &lt;-\n  mtcars %&gt;% \n  standardize(append = TRUE)\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m13: am ~ mpg_z:\n\nm13 &lt;-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nmtcars2 %&gt;% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\nneg_am &lt;- predict(m13, newdata = tibble(mpg_z = -1.3))\n\nFÃ¼r kleine Werte von mpg_z (&lt;1.3) sagt unser Modell negative Werte fÃ¼r am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. MÃ¼ssen wir mal bei Gelegenheit besser machen.\nWir waren fleiÃŸig â€¦\n\n\n\n\n\nQuelle\nGenug fÃ¼r heute. ğŸ‘"
  },
  {
    "objectID": "1000-metrische-AV.html#fazit",
    "href": "1000-metrische-AV.html#fazit",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.16 Fazit",
    "text": "11.16 Fazit\n\n\n\n\n\n\nWichtig\n\n\n\nKontinuierliches Lernen ist der SchlÃ¼ssel zum Erfolg."
  },
  {
    "objectID": "1000-metrische-AV.html#aufgaben",
    "href": "1000-metrische-AV.html#aufgaben",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.17 Aufgaben",
    "text": "11.17 Aufgaben\n\nAnova-skalenniveau\nNullhyp-Beispiel\nttest-skalenniveau\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\n\nRegression3  \n\ndiamonds-nullhyp-mws\nstan_glm_parameterzahl\nstan_glm_prioriwerte\nzwert-berechnen\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope-regr\nrope1\nrope2\nrope3\nrope4"
  },
  {
    "objectID": "1000-metrische-AV.html#section",
    "href": "1000-metrische-AV.html#section",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "\n11.18 â€”",
    "text": "11.18 â€”\n\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja, Sitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, und Daniel M. Croymans. 2021. â€Behavioural Nudges Increase COVID-19 Vaccinationsâ€œ. Nature 597 (7876): 404â€“9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, und Sam Brilleman. 2020. â€Rstanarm: Bayesian Applied Regression Modeling via Stan.â€œ https://mc-stan.org/rstanarm.\n\n\nKruschke, John K. 2018. â€Rejecting or Accepting Parameter Values in Bayesian Estimationâ€œ. Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B. Gubbay, Sarah A. Buchan, Deshayne B. Fell, u.Â a. 2021. â€Effectiveness of mRNA and ChAdOx1 COVID-19 Vaccines Against Symptomatic SARS-CoV-2 Infection and Severe Outcomes with Variants of Concern in Ontarioâ€œ. https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi, Mohammad Hossein Razizadeh, Diana L. Turner, und Raymond J. Turner. 2021. â€Efficacy and Safety of COVID-19 Vaccines: A Systematic Review and Meta-Analysis of Randomized Clinical Trialsâ€œ. Vaccines (Cold Spring Harbor Laboratory Press) 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball, Allison L. Naleway, Toan C. Ong, Malini B. DeSilva, u.Â a. 2021. â€Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient Care Settingsâ€œ. New England Journal of Medicine 385 (15): 1355â€“71. https://doi.org/10.1056/NEJMoa2110362."
  },
  {
    "objectID": "1000-metrische-AV.html#footnotes",
    "href": "1000-metrische-AV.html#footnotes",
    "title": "\n11Â  Forschungsfragen mit metrischer AV\n",
    "section": "",
    "text": "HÃ¤ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - â€œgrÃ¶ÃŸer als/kleiner alsâ€ - zu formulieren, anstelle der hier verwendeteten â€œempirisch Ã¤rmerenâ€ einfachen, ungerichteten Ungleichheit. SchÃ¶ner wÃ¤re natÃ¼rlich noch prÃ¤ziser als â€œIch erwarte einen grÃ¶ÃŸeren Wertâ€, also z.B. â€œIch erwarte einen Wert von 42!â€â†©ï¸\nGenauer gesagt wird geprÃ¼ft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.â†©ï¸\nkomfortabler geht es mit eti(m10.1).â†©ï¸\nauch ETI (Equal Tails Interval) genanntâ†©ï¸\ns. Details hier.â†©ï¸\nMittlerweile gibt es AnsÃ¤tze fÃ¼r einem Verfahren Ã¤hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.â†©ï¸\nam nÃ¼tzlichsten ist diese Standardisierung bei normal verteilten Variablen.â†©ï¸\nZumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen kÃ¶nnen sich Ã¤ndern. Am besten in der Dokumentation nachlesen: ?parameters.â†©ï¸\nNicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute SchÃ¤tzer der echten Parameter sein mÃ¼ssten, wenn die Stichprobe, die wir ihm angeschleppt hÃ¤tten, tatsÃ¤chlich gut istâ€¦â†©ï¸\nIgnorieren Sie die Zeile mit dem Befehl display(). Dieser Befehl dient nur dazu, die Ausgabe zu verschÃ¶nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.â†©ï¸"
  },
  {
    "objectID": "1100-kausal.html#lernsteuerung",
    "href": "1100-kausal.html#lernsteuerung",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 R-Pakete\nFÃ¼r dieses Kapitel benÃ¶tigen Sie folgende R-Pakete:\n\nlibrary(dagitty)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n12.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerklÃ¤ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\ndie â€œAtomeâ€ der KausalitÃ¤t eines DAGs benennen\nâ€œkausale HintertÃ¼renâ€ schlieÃŸen"
  },
  {
    "objectID": "1100-kausal.html#statistik-was-soll-ich-tun",
    "href": "1100-kausal.html#statistik-was-soll-ich-tun",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.2 Statistik, was soll ich tun?",
    "text": "12.2 Statistik, was soll ich tun?\n\n12.2.1 Studie A: Ã–strogen\n\n12.2.1.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 12.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\n\n\n\n\nTabelleÂ 12.1:  Daten zur Studie A \n  \nGruppe\n      Mit Medikament\n      Ohne Medikament\n    \n\n\nMÃ¤nner\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nFrauen\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei MÃ¤nnern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und MÃ¤nnern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n12.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Ã–strogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Ã–strogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in AbbildungÂ 12.1 dargestellt.\n\n\n\n\nAbbildungÂ 12.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender Ã¼ber drug) auf recovery\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige LÃ¶sung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder â€œSchichtenâ€ (â€œStrataâ€)\n\n\n\n12.2.2 Studie B: Blutdruck\n\n12.2.2.1 Medikament einnehmen?\nMit Blick auf TabelleÂ 12.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\n\n\n\nTabelleÂ 12.2:  Daten zur Wirksamkeit eines Medikaments (Studie B) \n  \nGruppe\n      Ohne Medikament\n      Mit Medikament\n    \n\n\ngeringer Blutdruck\n81/87 Ã¼berlebt (93%)\n234/270 Ã¼berlebt (87%)\n\n\nhoher Blutdruck\n192/263 Ã¼berlebt (73%)\n55/80 Ã¼berlebt (69%)\n\n\nGesamt\n273/350 Ã¼berlebt (78%)\n289/350 Ã¼berlebt (83%)\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher QualitÃ¤t (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe Ã¼ber beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? Pearl, Glymour, und Jewell (2016)\n\n12.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schÃ¤dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell ist in AbbildungÂ 12.2 dargestellt.\n\n\n\n\nAbbildungÂ 12.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schÃ¤dlich\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nÃ¼tzlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wÃ¤re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wÃ¤re.\n\n\n\n12.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs AbbildungÂ 12.1 und AbbildungÂ 12.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen fÃ¼r Handlungen - war nur mÃ¶glich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n12.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht fÃ¼r KausalschlÃ¼sse. ğŸ§Ÿ Statistik plus Theorie erlaubt KausalschlÃ¼sse. ğŸ“šâ•ğŸ“Š ğŸŸ° ğŸ¤©\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r Entscheidungen (â€œWas soll ich tun?â€) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n12.2.5 Vertiefung1\n\n\n12.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ã„rzte tendieren zu Behandlung A bei groÃŸen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ã„rzte zu Behandlung B.\nSollte ein Patient, der nicht weiÃŸ, ob sein Nierenstein groÃŸ oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach SteingrÃ¶ÃŸe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wÃ¤hlt?\nDie GrÃ¶ÃŸe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (â€œKetteâ€) von GrÃ¶ÃŸe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. DarÃ¼ber hinaus gibt es noch einen Einfluss von GrÃ¶ÃŸe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in AbbildungÂ 12.3 dargestellt; AbbildungÂ 12.4 visualisiert alternativ.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schÃ¤tzen mÃ¶chte? Oder lieber nicht kontrollieren?\n\n\n\n\nAbbildungÂ 12.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\nAbbildungÂ 12.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. WÃ¼rde man nicht size kontrollieren, bekÃ¤me man den â€œvermengtenâ€ Effekt von size und treatment, also keine (belastbare) Aussage Ã¼ber den Effekt der Behandlung.\n\n12.2.5.2 Mehr Beispiele\nNehmen Sie Bezug zu folgenden Aussagen:\n\nStudien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhÃ¶hen, wenn du heiratest.\n\n\nStudien zeigen, dass Leute, die sich beeilen, zu spÃ¤t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spÃ¤t zu deiner Besprechung.\n\n\n12.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zusÃ¤tzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht nÃ¶tig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafÃ¼r, dass es keine Konfundierung gibt."
  },
  {
    "objectID": "1100-kausal.html#konfundierung",
    "href": "1100-kausal.html#konfundierung",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.3 Konfundierung",
    "text": "12.3 Konfundierung\n\n12.3.1 Datensatz â€˜Hauspreise im Saratoga Countyâ€™\nWir nutzen den Datensatz Saratoga County; s. TabelleÂ 12.3. Hier gibt es eine Beschreibung des Datensatzes.\n\nd_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\n\n\n\n\n TabelleÂ 12.3:  Saratoga-County-Datensatz \n  \n\n\n\n\n\n12.3.2 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\nâ€œFinden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!â€\n\nğŸ§‘ Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\nğŸ‘© ğŸ”¬ Das ist Angie, Data Scientistin.\n\n12.3.3 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\nâ€œHey Don! Mehr Zimmer, mehr Kohle!â€ ğŸ‘© ğŸ”¬\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. AbbildungÂ 12.5.\n\n\n\n\nAbbildungÂ 12.5: Modell m1\n\n\n\n\nâ€œJedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.â€\n\nğŸ‘©\n\nZu wenig! ğŸ¤¬\n\nğŸ§‘\nBerechnen wir das Modell m1; der PunktschÃ¤tzer des Parameters bedroom steht in TabelleÂ 12.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\n\n TabelleÂ 12.4:  Parameter fÃ¼r m1 \n  \n\n\n\n\npoint_estimates(modell) gibt die PunktschÃ¤tzer der Parameter eines Modells zurÃ¼ck, aber nicht die SchÃ¤tzbereiche. MÃ¶chten Sie beides, kÃ¶nnen Sie die Funktion parameters(modell) nutzen.2\nMit estimate_predictions kÃ¶nnen wir Vorhersagen berechnen (bzw. schÃ¤tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist â€œschÃ¤tzenâ€ vielleicht das treffendere Wort). TabelleÂ 12.5 zeigt den laut m1 vorhergesagten Hauspreis fÃ¼r ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\n\nTabelleÂ 12.5: Vorhersage des Hauspreises fÃ¼r ein Haus mit 2 Zimmern\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.58e+05\n89053.60\n(-11396.62, 3.36e+05)\n\n\n\nVariable predicted: price\n\n\n\n12.3.4 Don hat eine Idee\n\nâ€œIch bau eine Mauer! Genial! An die Arbeit, Angie!â€ ğŸ§‘\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\nâ€œDas ist keine gute Idee, Don.â€\n\nğŸ‘©\nBerechnen wir die Vorhersagen fÃ¼r Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. TabelleÂ 12.6.3\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\n\nTabelleÂ 12.6: Vorhergesagter Hauspreis laut m1 fÃ¼r ein Haus mit 4 Zimmern\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.51e+05\n88063.92\n(79913.23, 4.27e+05)\n\n\n\nVariable predicted: price\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, AbbildungÂ 12.5.\n\nâ€œVolltreffer! Jetzt verdien ich 100 Tausend mehr! ğŸ¤‘ Ich bin der GrÃ¶ÃŸte!â€ ğŸ§‘\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: â€œ4e+05â€ ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n12.3.5 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berÃ¼cksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im â€œStrukturmodellâ€: Wenn also z.B. in unserem Modell ein wichtiger PrÃ¤diktor fehlt, so kann die Vorhersagen nicht prÃ¤zise sein. Fehler im Strukturmodell schlagen sich in breiten SchÃ¤tzintervallen (bedingt durch ein groÃŸes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berÃ¼cksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\n\nDie SchÃ¤tzbereiche sind in dem Fall deutlich kleiner, s. TabelleÂ 12.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\nTabelleÂ 12.7: ?(caption)\n\n\n\n\n(a) Model-based Expectation\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3097.48\n(2.47e+05, 2.59e+05)\n\n\n\n\n\n\nVariable predicted: price\n\n\n\n\nUngewissheit fÃ¼r die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\n\n12.3.6 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. TabelleÂ 12.8 gibt den PunktschÃ¤tzer fÃ¼r die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\n\nTabelleÂ 12.8: Parameter (PunktschÃ¤tzer, keine SchÃ¤tzung der Ungewissheit) von m2\n\nParameter\nMedian\n\n\n\n(Intercept)\n36780.69\n\n\nbedrooms\n-14238.34\n\n\nlivingArea\n125.41\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? TabelleÂ 12.9 gibt Aufschluss fÃ¼r den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 QuadratfuÃŸ WohnflÃ¤che; TabelleÂ 12.10 gibt die SchÃ¤tzung (laut m2) fÃ¼r den Preis eines Hauses mit 2 Zimmern (und der gleichen WohnflÃ¤che). Die Vorhersage erhÃ¤lt man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130335.6\n\n\n\n\n\n TabelleÂ 12.9:  Vorhersage von m2 fÃ¼r ein Haus mit 4 Zimmern und 1200\nEinheiten WohnflÃ¤che \n  \n\n\n\n\n\n\n\n\n TabelleÂ 12.10:  Vorhersage von m2 fÃ¼r ein Haus mit 2 Zimmern und 1200\nEinheiten WohnflÃ¤che \n  \n\n\n\n\nAndere, aber Ã¤hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt Ã¼ber die verschiedenen GrÃ¶ÃŸen von livingArea? Stellen Sie sich alle HÃ¤user mit 4 Zimmern vor (also mit verschiedenen WohnflÃ¤chen). Wir mÃ¶chten nur wissen, was so ein Haus â€œim Mittelâ€ kostet. Wir mÃ¶chten also die Mittelwerte pro bedroom schÃ¤tzen, gemittelt fÃ¼r jeden Wert von bedroom Ã¼ber livingArea. Die Ergebnisse stehen in TabelleÂ 12.11 und sind in AbbildungÂ 12.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\n\n TabelleÂ 12.11:  Vorhersagen des Preises von HÃ¤usern mit verschiedener Zimmerzahl\ngemittelt Ã¼ber die verschiedenen Werte der WohnflÃ¤che; basierend auf\nm2. \n  \n\n\n\n\n\n\n\n\nAbbildungÂ 12.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\nâ€œDie Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!â€\n\nğŸ‘©\n\nâ€œVerringert!? Weniger Geld?! Oh nein!â€\n\nğŸ§‘\n\n12.3.7 Die Zimmerzahl ist negativ mit dem Preis korreliert\nâ€¦ wenn man die WohnflÃ¤che (Quadratmeter) kontrolliert, s. AbbildungÂ 12.7.\n\nâ€œNe-Ga-Tiv!â€\n\nğŸ‘©\n\n\nAbbildungÂ 12.7: Hauspreis stratifizieren\n\nQuellcode"
  },
  {
    "objectID": "1100-kausal.html#kontrollieren-von-variablen",
    "href": "1100-kausal.html#kontrollieren-von-variablen",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.4 Kontrollieren von Variablen",
    "text": "12.4 Kontrollieren von Variablen\nğŸ’¡ Durch das Aufnehmen von PrÃ¤diktoren in die multiple Regression werden die PrÃ¤diktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen PrÃ¤diktors mit \\(y\\), wenn man den (oder die) anderen PrÃ¤diktoren statistisch konstant hÃ¤lt.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom â€œNetto-Effektâ€ eines PrÃ¤diktors, oder davon, dass ein PrÃ¤diktor â€œbereinigtâ€ wurde vom (linearen) Einfluss der anderen PrÃ¤diktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des PrÃ¤diktors \\(x_1\\) auf \\(y\\) anzeigen unabhÃ¤ngig vom Effekt der anderen PrÃ¤diktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines PrÃ¤diktors \\(x_1\\) wird fÃ¼r jede AusprÃ¤gung (Gruppe) des PrÃ¤diktors \\(x_2\\) berechnet.\n\n12.4.1 Das HinzufÃ¼gen von PrÃ¤diktoren kann die Gewichte der Ã¼brigen PrÃ¤diktoren Ã¤ndern\n\nAber welche und wie viele PrÃ¤diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nğŸ§‘\n\nLeider kann die Statistik keine Antwort darauf geben.\n\nğŸ‘©\n\nWozu ist sie dann gut?!\n\nğŸ§‘\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur ErklÃ¤rung der Ursachen heranzuziehen: Die Regressionskoeffizienten kÃ¶nnen sich wild Ã¤ndern, wenn man PrÃ¤diktoren hinzufÃ¼gt oder weglÃ¤sst. Es kÃ¶nnen sich sogar die Vorzeichen der Regressionsgewichte Ã¤ndern; in dem Fall spricht man von einem Simpson-Paradox."
  },
  {
    "objectID": "1100-kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "href": "1100-kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.5 Welches Modell richtig ist, kann die Statistik nicht sagen",
    "text": "12.5 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, weâ€™d like to know wheter an effect is â€œrealâ€ or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical â€œtestsâ€ on its way to acceptance.\n\nMcElreath (2020), S. 139\n\n12.5.1 Kausalmodell fÃ¼r Konfundierung, km1\n\nDas Kausalmodell km1 ist in AbbildungÂ 12.8 dargestellt; vgl. AbbildungÂ 12.7.\n\n\n\n\nAbbildungÂ 12.8: Kausalmodell km1 - Eine ErklÃ¤rung (von mehreren) fÃ¼r m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms.\nEine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht.\nd_connected heiÃŸt, dass die betreffenden Variablen â€œverbundenâ€ sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flieÃŸt ğŸŒŠ. d_separated heiÃŸt, dass sie nicht d_connected sind.\n\n12.5.2 m2 kontrolliert die Konfundierungsvariable livingArea\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloÃŸ?! Oh jeh!\n\nğŸ§‘\n\nWir mÃ¼ssen die Konfundierungsvariable kontrollieren.\n\nğŸ‘©\nAbbildungÂ 12.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\nAbbildungÂ 12.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\nDurch das Kontrollieren (â€œadjustierenâ€), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separeted.\n\n12.5.3 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, AbbildungÂ 12.10, links: Es wird (fÃ¤lschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, AbbildungÂ 12.10, rechts.\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\nAbbildungÂ 12.10: Konfundierung von y und x!\n\n\nAbbildungÂ 12.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. AuÃŸerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als PrÃ¤diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\nQuellcode\n\n12.5.4 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 dÃ¼rfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in AbbildungÂ 12.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n12.5.5 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide PrÃ¤diktoren jeweils einen eigenen Beitrag zur ErklÃ¤rung der AV haben.\nDaher kÃ¶nnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei KausaleinflÃ¼sse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) Ã¼ber den Mediator (b) zur AV (p) auch Mediation, s. AbbildungÂ 12.11.\n\n\n\n\nAbbildungÂ 12.11: Der Effekt von livingArea wird Ã¼ber den Mediator bedrooms auf price vermittelt.\n\n\n\n\n12.5.6 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. AbbildungÂ 12.12.\n\n\n\n\nAbbildungÂ 12.12: Dons Kausalmodell\n\n\n\n\nâ€œIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das grÃ¶ÃŸte! Alle anderen Kausalmodelle sind ein Disaster!â€\n\nğŸ§‘\n\n\nâ€œDon, nach deinem Kausalmodell mÃ¼ssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.â€\n\nğŸ§‘\nRechne doch selber die Korrelation aus, Don:\n\nâ€œÃ„h, wie ging das nochmal?â€\n\nğŸ§‘\nSo kÃ¶nntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z.B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\nâ€œBitte, gerne hab ich dir geholfen, Don.â€\n\nğŸ‘©\n\n12.5.7 UnabhÃ¤ngigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 12.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhÃ¤ngig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zusÃ¤tzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete UnabhÃ¤ngigkeit findet sich nicht in den Daten wieder, s. TabelleÂ 12.8. Also: â›ˆï¸ Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. AbbildungÂ 12.11.\nDas Kausalmodell km2 postuliert keine UnabhÃ¤ngigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betrÃ¤gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so Ã¤hnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. ğŸ¥±\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. AbbildungÂ 12.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhÃ¤ngig von livingArea (a)\nâ›ˆï¸ km3 passt nicht zu den Daten/zum Modell!"
  },
  {
    "objectID": "1100-kausal.html#dags-directed-acyclic-graphs",
    "href": "1100-kausal.html#dags-directed-acyclic-graphs",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.6 DAGs: Directed Acyclic Graphs",
    "text": "12.6 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B. AbbildungÂ 12.12.\n\nDAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.\nEin Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.\nDAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).\nDAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurÃ¼ckfÃ¼hren.\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten Ã¼ber die Kanten, unabhÃ¤ngig von der Pfeilrichtung.\n\nDer DAG von km1 ist in AbbildungÂ 12.8 zu sehen.\n\n12.6.1 Leider passen potenziell viele DAGs zu einer Datenlage\nb: bedrooms, p: price, a area (living area)\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach wÃ¤re, die Kausalstruktur der PhÃ¤nomene zu entdecken, wÃ¤ren sie lÃ¤ngst erkannt, und alle Probleme der Menschheit gelÃ¶st.\nIn AbbildungÂ 12.13 sind mÃ¶gliche Kausalmodelle fÃ¼r Dons Studie dargestellt.\n\n\n\n\nAbbildungÂ 12.13: Kausalmodelle, die potenziell geeignet sind fÃ¼r Dons Fragestellung\n\n\n\nAlle diese DAgs in AbbildungÂ 12.8 haben die gleichen Implikationen hinsichtlich der (Un-)AbhÃ¤ngigkeiten zwischen der Variablen. Wir kÃ¶nnen also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, brÃ¤uchten wir z.B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n12.6.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als â€œKausationâ€ bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiÃŸ man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\nViele Menschen denken - fÃ¤lschlich - dass Korrelation Kausation bedeuten muss, s. AbbildungÂ 12.14.\n\n\n\n\nAbbildungÂ 12.14: xkcd zum Thema Kausation\n\n\n\nQuelle und ErklÃ¤rung\n\n12.6.3 Zwischenfazit\nSind zwei Variablen korreliert (abhÃ¤ngig, assoziiert), so kann es dafÃ¼r zwei GrÃ¼nde geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (â€œScheinkorrelationâ€)\n\nEine mÃ¶gliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als PrÃ¤diktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so lÃ¶st sich der Scheinzusammenhang nach dem Adjustieren auf.\nLÃ¶st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der ZusammenhÃ¤nge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine kÃ¶nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nÃ¶tig, um DAGs auszuschlieÃŸen.\n\n12.6.4 Schoki macht Nobelpreis! (?)\nğŸï¸ Vertiefung ğŸï¸\nEine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen (HÃ¶he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli 2012), s. AbbildungÂ 12.15.\n\n\n\n\nAbbildungÂ 12.15: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle Ã¼berprÃ¼fen, so wie wir das hier tun.\n\n\nDer â€œSchoki-DAGâ€ in AbbildungÂ 12.16 zeigt den DAG fÃ¼r das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\nAbbildungÂ 12.16: Macht Schokolade Nobelpreise?"
  },
  {
    "objectID": "1100-kausal.html#kollision",
    "href": "1100-kausal.html#kollision",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.7 Kollision",
    "text": "12.7 Kollision\n\n12.7.1 Kein Zusammenhang von Intelligenz und SchÃ¶nheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und SchÃ¶nheit (looks), wie AbbildungÂ 12.17 illustriert. FÃ¼r geringe Intelligenzwerte gibt es eine breites Spektrum von SchÃ¶nheitswerten und fÃ¼r hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\nAbbildungÂ 12.17: Kein Zusammenhang von Intelligenz und SchÃ¶nheit in den Daten\n\n\n\nGott ist gerecht (?)\n\n12.7.2 Aber Ihre Dates sind entweder schlau oder schÃ¶n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schÃ¶n sind oder schlau - aber seltens beides gleichzeitig (schade), s. AbbildungÂ 12.18.\n\n\n\n\nAbbildungÂ 12.18: Ihre Datingpartner sind komischerweise entweder schlau oder schÃ¶n (aber nicht beides), zumindest in der Tendenz.\n\n\n\nWie kann das sein?"
  },
  {
    "objectID": "1100-kausal.html#dag-zur-rettung",
    "href": "1100-kausal.html#dag-zur-rettung",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.8 DAG zur Rettung",
    "text": "12.8 DAG zur Rettung\nğŸ¦¹ ğŸ¦¸\nDer DAG in AbbildungÂ 12.19 bietet eine rettende ErklÃ¤rung.\n\n\n\n\nAbbildungÂ 12.19: Date als gemeinsame Wirkung von SchÃ¶nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen SchÃ¶nheit und Intelligenz.\n\n\n\nEine Ã¤hnliche Visualisierung des gleichen Sachverhalts zeigt AbbildungÂ 12.20.\n\n\n\n\nAbbildungÂ 12.20: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n12.8.1 Was ist eine Kollision?\nAls Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen). Kontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. AbbildungÂ 12.19, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche PrÃ¤diktoren einer Regression hinzufÃ¼gen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n12.8.2 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchÃ¶ne Menschen\nReiche Menschen\n\nSehen wir davon aus, dass SchÃ¶nheit und Reichtum unabhÃ¤ngig voneinander sind.\nWenn ich Ihnen sage, dass Don nicht schÃ¶n ist, aber in der Glitzer hÃ¤ufig auftaucht, was lernen wir dann Ã¼ber seine finanzielle Situation?4\n\nâ€œIch bin schÃ¶n, unglaublich schÃ¶n, und groÃŸ, groÃŸartig, tolle Gene!!!â€ ğŸ§‘\n\n\n12.8.3 Noch ein einfaches Beispiel zur Kollision\n\nâ€œSo langsam check ichâ€™s!â€ ğŸ§‘\n\nSei Z = X + Y, wobei X und Y unabhÃ¤ngig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts Ã¼ber Y, da die beiden Variablen unabhÃ¤ngig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhÃ¤ngig, gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).5\n\n12.8.4 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildungÂ 12.19 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z.B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als PrÃ¤diktor in eine Regression zusÃ¤tzlich zu looks mit talent als PrÃ¤dikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (â€œFlussâ€) von Looks Ã¼ber date nach Talent ist blockiert.\nKontrolliert man date, so Ã¶ffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr â€œblockiertâ€, die Korrelation kann â€œflieÃŸenâ€ - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n12.8.5 IQ, Fleiss und Eignung fÃ¼rs Studium\nSagen wir, Ã¼ber die Eignung fÃ¼r ein Studium wÃ¼rden nur (die individuellen AusprÃ¤gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in AbbildungÂ 12.21.\n\n\n\n\nAbbildungÂ 12.21: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fÃ¼rs Studium) sei definiert als die Summe von iq und fleiss, plus etwas GlÃ¼ck:\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\nLaut unserem Modell setzt sich Eignung zur HÃ¤lfte aus Intelligenz und zur HÃ¤lfte aus Fleiss zusammen, plus etwas GlÃ¼ck.\n\n12.8.6 Schlagzeile â€œSchlauheit macht Studentis faul!â€\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und FleiÃŸ (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das â€œEignungsmodellâ€, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. TabelleÂ 12.12.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\n\nTabelleÂ 12.12: Zum Zusammenhang von Fleiss und Talent\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\nAbbildungÂ 12.22 zeigt das Modell und die Daten.\n\n\n\n\nAbbildungÂ 12.22: Der Zusammenhang von Fleiss und IQ\n\n\n\nIQ ist nicht unabhÃ¤ngig von FleiÃŸ in unseren Daten, sondern abhÃ¤ngig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde Ã¼ber ZusammenhÃ¤nge auf und interpretieren die ZusammenhÃ¤nge â€“ oft vorschnell â€“ als kausal.6\n\n12.8.7 Kollisionsverzerrung nur bei Stratifizierung\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. AbbildungÂ 12.23.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\nAbbildungÂ 12.23: Stratifizierung und Scheinkorrelation\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nÃ¼tzen.\nNur Kenntnis des DAGs verrÃ¤t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten PrÃ¤diktor auf, so â€œkontrolliertâ€ man diese Variable. Das Regressiongewicht des ersten PrÃ¤diktors wird â€œbereinigtâ€ um den Einfluss des zweiten PrÃ¤diktors; insofern ist der zweite PrÃ¤diktor dann â€œkontrolliertâ€.\n\n\n\n12.8.8 Einfluss von GroÃŸeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und GroÃŸeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von GroÃŸeltern auf ihre Enkel, s. AbbildungÂ 12.24, \\(G \\rightarrow K\\).\n\n\n\n\nAbbildungÂ 12.24: Der kausale Effekt von GroÃŸeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable Ã¼bersehen haben? (S. nÃ¤chster Abschnitt). ğŸ‘»\n\n12.8.9 Der Gespenster-DAG\nğŸ‘»\nEs gibt â€œunheilbareâ€ DAGs, nennen wir sie â€œGespenster-DAGsâ€, in denen es nicht mÃ¶glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. AbbildungÂ 12.25. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: â€œDeine Theorie ist nicht gut, zurÃ¼ck an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.â€\n\n\n\n\nAbbildungÂ 12.25: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollstÃ¤ndig) mÃ¶glich.\n\n\n\n\nU kÃ¶nnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft.\nDie GroÃŸeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\nE ist sowohl fÃ¼r G als auch fÃ¼r U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\n\nDie Sache ist in diesem Fall chancenlos. Wir mÃ¼ssen diesen DAG verloren geben, McElreath (2020), S. 180."
  },
  {
    "objectID": "1100-kausal.html#die-hintertÃ¼r-schlieÃŸen",
    "href": "1100-kausal.html#die-hintertÃ¼r-schlieÃŸen",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.9 Die HintertÃ¼r schlieÃŸen",
    "text": "12.9 Die HintertÃ¼r schlieÃŸen\n\n12.9.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groÃŸ ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in AbbildungÂ 12.26 dargestellt.\n\n\n\n\nAbbildungÂ 12.26: Der Preis wird sowohl von der Zimmerzahl als auch der WohnflÃ¤che beeinflusst\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund fÃ¼r die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\rightarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. GÃ¤be es nur nur den zweiten Pfad und wir wÃ¼rden b Ã¤ndern, so wÃ¼rde sich p nicht Ã¤ndern.\n\n12.9.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildungÂ 12.27 zeigt eine erfreuliche Situation: Die â€œHintertÃ¼râ€ zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die HintertÃ¼r geschlossen - fÃ¼hren also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\nAbbildungÂ 12.27: Unverzerrte SchÃ¤tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere PrÃ¤diktor im Modell enthalten ist. Da die beiden PrÃ¤diktoren unkorreliert sind, hat die Aufnahme des einen PrÃ¤diktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\nDie â€œHintertÃ¼râ€ der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berÃ¼hmte LÃ¶sung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment. Wenn wir den HÃ¤usern zufÃ¤llig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen kÃ¶nnten (unabhÃ¤ngig von ihrer Quadratmeterzahl, a), wÃ¼rde sich der Graph so Ã¤ndern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\rightarrow a \\rightarrow p\\) geschlossen (â€œblockiertâ€).\n\n12.9.3 HintertÃ¼r schlieÃŸen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die HintertÃ¼r schlieÃŸen (backdoor criterion).\nWir wollen die HintertÃ¼re schlieÃŸen, da wir sonst nicht den wahren, kausalen Effekt bestimmen kÃ¶nnen.\nZum GlÃ¼ck gibt es neben Experimenten noch andere Wege, die HintertÃ¼r zu schlieÃŸen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis Ã¼ber b kein zusÃ¤tzliches Wissen Ã¼ber p. Wissen Sie hingegen nichts Ã¼ber a, lernen Sie bei Kenntnis von b auch etwas Ã¼ber p. Konditionieren ist wie â€œgegeben, dass Sie a schon kennenâ€¦â€.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)\n\n12.9.4 Die vier Atome der Kausalanalyse\nAbbildungÂ 12.28 stellt die vier â€œAtomeâ€ der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so kÃ¶nnen Sie jedes beliebige Kausalsystem (DAG) entschlÃ¼sseln.\n\n\n\n\nAbbildungÂ 12.28: Die vier Atome der Kausalinferenz\n\n\n\n\n12.9.5 Mediation\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. AbbildungÂ 12.29. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y â€œvermitteltâ€ oder Ã¼bertrÃ¤gt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\nAbbildungÂ 12.29: Das Kausalmodell der Mediation.\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation â€œflieÃŸtâ€ den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schlieÃŸt) die Kette (genau wie bei der Gabel).\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. AbbildungÂ 12.30. In AbbildungÂ 12.30 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\). Die Summe der Effekte beider Pfade nennt man den totalen (kausalen) Effekt. Den Effekt Ã¼ber den Mediatorpfad nennt man den indirekten (kausalen) Effekt und den Pfad \\(x\\rightarrow y\\) nennt man den direkten (kaudalen) Effekt.\n\n\n\n\nAbbildungÂ 12.30: Partielle Mediation"
  },
  {
    "objectID": "1100-kausal.html#der-nachfahre",
    "href": "1100-kausal.html#der-nachfahre",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.10 Der Nachfahre",
    "text": "12.10 Der Nachfahre\nEin Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. AbbildungÂ 12.31. Kontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet Ã¼ber m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise Ã¶ffnen, da m eine Kollisionsvariable ist.\n\n\n\n\nAbbildungÂ 12.31: Ein Nachfahre verhÃ¤lt sich Ã¤hnlich wie sein Vorfahreâ€¦\n\n\n\n\n12.10.1 Kochrezept zur Analyse von DAGs\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geÃ¶ffnet ist.\nBeurteilen Sie fÃ¼r jeden Pfad, ob er ein HintertÃ¼rpfad ist (HintertÃ¼rpfade haben einen Pfeil, der zur UV fÃ¼hrt).\nWenn es geÃ¶ffnete Hinterpfade gibt, prÃ¼fen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlieÃŸen (falls mÃ¶glich)."
  },
  {
    "objectID": "1100-kausal.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich-bsp1",
    "href": "1100-kausal.html#schlieÃŸen-sie-die-hintertÃ¼r-wenn-mÃ¶glich-bsp1",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.11 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp1\n",
    "text": "12.11 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp1\n\nUV: \\(X\\), AV: \\(Y\\), drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\nAbbildungÂ 12.32: Puh, ein schon recht komplizierter DAG\n\n\n\nEs gibt zwei HintertÃ¼rpfade in AbbildungÂ 12.32:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schlieÃŸt die offene HintertÃ¼r.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n12.11.1 SchlieÃŸen Sie die HintertÃ¼r (wenn mÃ¶glich)!, bsp2\n\nS. DAG in AbbildungÂ 12.33: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\nAbbildungÂ 12.33: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\nKontrollieren Sie diese Variablen, um die offenen HintertÃ¼ren zu schlieÃŸen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), â€šS. 188.\n\n12.11.2 Implizierte bedingte UnabhÃ¤ngigkeiten von bsp2\n\nEin Graph ohne Us ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme. Auch wenn die Daten nicht sagen kÃ¶nnen, welcher DAG der richtige ist, kÃ¶nnen wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten UnabhÃ¤ngigkeiten geben uns MÃ¶glichkeiten, zu prÃ¼fen, ob wir einen DAG verwerfen (ausschlieÃŸen) kÃ¶nnen. Bedingten UnabhÃ¤ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhÃ¤ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte UnabhÃ¤ngigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S"
  },
  {
    "objectID": "1100-kausal.html#fazit",
    "href": "1100-kausal.html#fazit",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.12 Fazit",
    "text": "12.12 Fazit\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren kÃ¶nnen, hÃ¤ngt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen kÃ¶nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. â€œDer Unterschied zwischen beiden Gruppen betrÃ¤gt etwa â€¦â€. Allerdings ist eine kausale Interpretation nicht zulÃ¤ssig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht mÃ¶glich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dÃ¼rfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten Ã¤ndern sich (oft), wenn man PrÃ¤diktoren zum Modell hinzufÃ¼gt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, mÃ¶glichst viele PrÃ¤diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der â€œkausalen Atomeâ€ ist Voraussetzung zur Ableitung von KausalschlÃ¼sse in Beobachtungsstudien."
  },
  {
    "objectID": "1100-kausal.html#aufgaben",
    "href": "1100-kausal.html#aufgaben",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.13 Aufgaben",
    "text": "12.13 Aufgaben\n\nSammlung â€œkausalâ€"
  },
  {
    "objectID": "1100-kausal.html#section",
    "href": "1100-kausal.html#section",
    "title": "12Â  Kausalinferenz",
    "section": "\n12.14 â€”",
    "text": "12.14 â€”\n\n\n\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. â€Chocolate Consumption, Cognitive Function, and Nobel Laureatesâ€œ. New England Journal of Medicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. â€Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Dataâ€œ. Advances in Methods and Practices in Psychological Science 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629."
  },
  {
    "objectID": "1100-kausal.html#footnotes",
    "href": "1100-kausal.html#footnotes",
    "title": "12Â  Kausalinferenz",
    "section": "",
    "text": "Dieser Abschnitt ist prÃ¼fungsrelevant, birgt aber nichts Neues.â†©ï¸\nIn aller Regel macht es mehr Sinn, die SchÃ¤tzbereiche der PunktschÃ¤tzer auch zu betrachten. Nur die PunktschÃ¤tzer zu betrachten vernachlÃ¤ssigt wesentliche Information.â†©ï¸\nAnstelle von estimate_relation() kann man auch (einfacher vielleicht) predict() verwenden: predict(m1, newdata = dons_new_house). Allerdings gibt predict() nur den vorhergesagten Wert aus. estimate_prediction() gibt noch zusÃ¤tzlich das Vorhersageintervall aus, berÃ¼cksichtigt also die (doppelte) Ungewissheit der Vorhersage. Mit anderen Worten: estimate_prediction gibt die PPV aus.â†©ï¸\nDon muss reich sein.â†©ï¸\nDer horizontale Balken â€œ|â€ bedeutet â€œgegeben, dassâ€. Ein Beispiel lautet \\(Pr(A|B)\\): â€œDie Wahrscheinlichkeit von A, gegeben dass B der Fall ist.â†©ï¸\nEhrlicherweise muss man zugeben, dass auch wissenschaftliche Berichte Daten Ã¼ber ZusammenhÃ¤nge gerne kausal interpretieren, oft vorschnell.â†©ï¸"
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie kÃ¶nnen â€¦\n\nerlÃ¤utern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische â€œLieblingsfehlerâ€ benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik Ã¼bersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n13.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)"
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.2 Lieblinglingsfehler",
    "text": "13.2 Lieblinglingsfehler\nLieblingsfehler im Ãœberblick ğŸ¤·:\n\nPost-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrÃ¤diktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt"
  },
  {
    "objectID": "1200-abschluss.html#post-prÃ¤d-verteilung-ppv-und-post-verteilung-verwechseln",
    "href": "1200-abschluss.html#post-prÃ¤d-verteilung-ppv-und-post-verteilung-verwechseln",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.3 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·",
    "text": "13.3 Post-PrÃ¤d-Verteilung (PPV) und Post-Verteilung verwechseln ğŸ¤·\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. TabelleÂ 13.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\n\n TabelleÂ 13.1:  Postverteilung in Stichprobenform (m1) \n  \n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. HÃ¤ufig ist es aber bequemer, z.B. mit parameters(m1) Post-Intervalle und PunktschÃ¤tzer auszulesen.\nDie Posterior-PrÃ¤diktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n\n\nname\nvalue\n\n\n\nMazda RX4\n24.37754\n\n\nMazda RX4 Wag\n27.79282\n\n\nDatsun 710\n22.27664\n\n\nHornet 4 Drive\n26.68591\n\n\nHornet Sportabout\n10.76491"
  },
  {
    "objectID": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "href": "1200-abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.4 Quantile und Verteilungsfuntion verwechseln ğŸ¤·",
    "text": "13.4 Quantile und Verteilungsfuntion verwechseln ğŸ¤·\n\n13.4.1 Quantil fÃ¼r \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. AbbildungÂ 13.1.\n\n\n\n\nAbbildungÂ 13.1: 50%-Quantil\n\n\n\nDas 50%-Quantil (.5-Quantil) betrÃ¤gt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist grÃ¶ÃŸer oder gleich dem \\(p\\)-Quantil.\n\n13.4.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. AbbildungÂ 13.2.\n\n\n\n\nAbbildungÂ 13.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit betrÃ¤gt hier 50%, dass \\(x\\) nicht grÃ¶ÃŸer ist als 0."
  },
  {
    "objectID": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "href": "1200-abschluss.html#interaktion-falsch-interpretieren",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.5 Interaktion falsch interpretieren ğŸ¤·",
    "text": "13.5 Interaktion falsch interpretieren ğŸ¤·\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kÃ¼rzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. TabelleÂ 13.2.\n\nparameters(m2)\n\n\n\n\n\nTabelleÂ 13.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.65\n(18.91, 30.09)\n100%\n1.002\n2045.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.92%\n1.001\n2022.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.92\n(4.72, 23.05)\n99.88%\n1.002\n1378.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.03)\n99.52%\n1.002\n1540.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\nTabelleÂ 13.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\nAbbildungÂ 13.3: Parameter von m2 visualisiert\n\n\n\nFalsch ğŸ˜ˆ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11.\nRichtig ğŸ‘¼ Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 betrÃ¤gt ca. -0.11 â€“ wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte PrÃ¤diktoren wÃ¤ren hier eine sinnvolle LÃ¶sung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8"
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.6 Kochrezepte ğŸ²",
    "text": "13.6 Kochrezepte ğŸ²\n\n13.6.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen Ã¼ber ein PhÃ¤nomen, \\(y\\), Kausalfrage finden 2. Literatur wÃ¤lzen, um mÃ¶gliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese prÃ¤zisieren 4. Modell prÃ¤zisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prÃ¼fen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n13.6.2 Parameter schÃ¤tzen vs.Â Hypothesen prÃ¼fen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schÃ¤tzen. Beispiel HypothesenprÃ¼fung: â€œFrauen parken im Durchschnitt schneller ein als MÃ¤nnerâ€. Beispiel ParameterschÃ¤tzung: â€œWie groÃŸ ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und MÃ¤nnern?â€\nJe ausgereifter ein Forschungsfeld, desto kÃ¼hnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nÃ¤chste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nÃ¤chste Sonnenfinsternis wird in den nÃ¤chsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen fÃ¼r den Klausurerfolg. KÃ¼hne Hypothesen sind wÃ¼nschenswert ğŸ¦¹\n\n13.6.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist hÃ¶her als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist grÃ¶ÃŸer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]"
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.7 Kerngedanken Bayes",
    "text": "13.7 Kerngedanken Bayes\n\n13.7.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. AbbildungÂ 13.4.\n\n\n\n\nAbbildungÂ 13.4: Post-Verteilung (HDI) von m3\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist mÃ¶glich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind mÃ¶glich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings Ã¼bermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n13.7.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]"
  },
  {
    "objectID": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "href": "1200-abschluss.html#beispiele-fÃ¼r-prÃ¼fungsaufgaben",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.8 Beispiele fÃ¼r PrÃ¼fungsaufgaben",
    "text": "13.8 Beispiele fÃ¼r PrÃ¼fungsaufgaben\n\n13.8.1 Geben Sie den korrekten Begriff an!\nğŸŒ¬ğŸš™ğŸ™‹ï¸ğŸ‘¨â¬…ï¸Hans ğŸ‘§â¬…ï¸Anna ğŸ‘©â¬…ï¸Lise\nPuh, wie erstelle ich fÃ¼r alle Studis ein anderes RÃ¤tsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-PrÃ¼fung bekommen alle Studentis eine eigene, jeweils andere PrÃ¼fung. Teamarbeit bleibt natÃ¼rlich trotzdem untersagt.\n\n\n\n13.8.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. AbbildungÂ 13.5.\n\n\n\n\nAbbildungÂ 13.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\nâ“Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\nâ— Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n13.8.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. AbbildungÂ 13.6.\n\n\n\n\nAbbildungÂ 13.6: Ein DAG mit vielen Variablen\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n13.8.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildungÂ 13.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\nAbbildungÂ 13.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\nMinimales Adjustment-Set fÃ¼r den totalen Kausaleffekt: {AIS, ALN}\n\n13.8.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrÃ¼fungsfragen zu Modellen kÃ¶nnten z.B. sein:\n\nGeben Sie den PunktschÃ¤tzer (Median) fÃ¼r den PrÃ¤diktor X im Modell Y an!\nGeben Sie ein 89%-HDI fÃ¼r den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris â€¦\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI fÃ¼r den PrÃ¤diktor X im Modell Y?\nWas verÃ¤ndert sich an den Parametern, wenn Sie die PrÃ¤diktoren zentrieren/z-standardisieren?\nâ€¦"
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prÃ¼fung",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.9 Viel Erfolg bei der PrÃ¼fung!",
    "text": "13.9 Viel Erfolg bei der PrÃ¼fung!\nğŸ¥³ğŸ†"
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "\n13Â  Abschluss\n",
    "section": "\n13.10 â€”",
    "text": "13.10 â€”\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. â€The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphsâ€œ. European Psychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press."
  },
  {
    "objectID": "1200-abschluss.html#footnotes",
    "href": "1200-abschluss.html#footnotes",
    "title": "\n13Â  Abschluss\n",
    "section": "",
    "text": "langweiligesâ†©ï¸\nFahr-Hier-Hans-Anna-Lise: Varianzanalyseâ†©ï¸"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. â€œMisconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.â€ Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, GÃ¼nther. 2018. Wahrscheinlichkeitsrechnung Und SchlieÃŸende\nStatistik: Praxisorientierte EinfÃ¼hrung: Mit Aufgaben Und LÃ¶sungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nâ€”â€”â€”. 2022. Statistik-Ãœbungen: Beschreibende Statistik â€“\nWahrscheinlichkeitsrechnung â€“ SchlieÃŸende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja,\nSitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and\nDaniel M. Croymans. 2021. â€œBehavioural Nudges Increase\nCOVID-19 Vaccinations.â€ Nature 597 (7876):\n404â€“9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2020.\nâ€œRstanarm: Bayesian Applied Regression Modeling via\nStan.â€ https://mc-stan.org/rstanarm.\n\n\nHenze, Norbert. 2019. Stochastik: Eine EinfÃ¼hrung mit GrundzÃ¼gen der\nMaÃŸtheorie: Inkl. zahlreicher ErklÃ¤rvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nKampen, D. van. 2014. â€œThe SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.â€ European\nPsychiatry 29 (7): 437â€“48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter Values\nin Bayesian Estimation.â€ Advances in Methods and Practices in\nPsychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel LÃ¼decke. 2019. â€œIndices of Effect Existence and\nSignificance in the Bayesian Framework.â€ Frontiers in\nPsychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. â€œChocolate Consumption, Cognitive\nFunction, and Nobel Laureates.â€ New England Journal of\nMedicine 367 (16): 1562â€“64. https://doi.org/10.1056/NEJMon1211064.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B.\nGubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021.\nâ€œEffectiveness of mRNA and\nChAdOx1 COVID-19 Vaccines Against Symptomatic\nSARS-CoV-2 Infection and Severe Outcomes with Variants of\nConcern in Ontario.â€ https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi,\nMohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner.\n2021. â€œEfficacy and Safety of COVID-19 Vaccines:\nA Systematic Review and Meta-Analysis of Randomized\nClinical Trials.â€ Vaccines (Cold Spring Harbor Laboratory\nPress) 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nRohrer, Julia M. 2018. â€œThinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational\nData.â€ Advances in Methods and Practices in Psychological\nScience 1 (1): 27â€“42. https://doi.org/10.1177/2515245917745629.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball,\nAllison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021.\nâ€œEffectiveness of Covid-19 Vaccines in Ambulatory and Inpatient\nCare Settings.â€ New England Journal of Medicine 385\n(15): 1355â€“71. https://doi.org/10.1056/NEJMoa2110362.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. â€œThe\nASA Statement on p-Values:\nContext, Process, and Purpose.â€ The American\nStatistician 70 (2): 129â€“33. https://doi.org/10.1080/00031305.2016.1154108."
  }
]