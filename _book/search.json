[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "Bayes:Start!\n\n\n\n🚧WORK IN PROGRESS🚧\n\n\n\nNach diesem Kurs sollten Sie …\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden können\ngängige einschlägige Forschungsfragen in statistische Modelle übersetzen und mit R auswerten können\nkausale Forschungsfragen in statistische Modelle übersetzen und prüfen können\ndie Güte und Grenze von statistischen Modellen einschätzen können\n\n\n\n\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, möglichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\n\n\n\n\nInstallieren Sie R und seine Freunde.\nInstallieren Sie die folgende R-Pakete:\n\ntidyverse\nrstanarm\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\n\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.\n\n\n\n\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen während des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeiträgen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      Nr\n      Thema\n      Datum\n      Kommentar\n    \n  \n  \n    1\nWas ist Inferenz?\n3. - 7. Okt. 2022\nDie erste Unterrichtsstunde fällt auf den 7. Okt. 2023.\n    2\nWahrscheinlichkeit\n10. - 14. Okt. 22\nNA\n    3\nHallo, Bayes\n17. - 21. Okt. 22\nNA\n    4\nDie Post befragen\n24. - 28. Okt. 22\nNA\n    5\nGauss-Modelle\n31. Okt. - 4. Nov. 22\nNA\n    6\nLineare Modelle\n7. - 11. Nov. 22\nNA\n    NA\nBLOCKWOCKE\n14. - 18. Nov. 22\nKein regulärer Unterricht\n    7\nMetrische AV\n21. - 25. Nov. 22\nNA\n    8\nFallstudien\n28. Nov. - 2. Dez. 22\nNA\n    9\nKausalinferenz 1\n5. Dez. - 9. Dez. 22\nNA\n    10\nKausalinferenz 2\n12. - 16. Dez. 22\nNA\n    11\nBinäre AV\n19. - 23. Dez. 22\nNA\n    NA\nWEIHNACHTSFERIEN\nNA\nKein Unterricht\n    12\nAbschluss\n9. Jan. 23 - 13. Jan. 23\nNA\n  \n  \n  \n\n\n\n\n\n\n\nPro Thema wird Literatur ausgewiesen.\n\n\n\nDieses Dokument wurde erzeut am/um 2022-09-08 23:58:28.\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2022-09-08\n pandoc   2.19.2 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.2.0)\n cli           3.3.0      2022-04-25 [1] CRAN (R 4.2.0)\n colorout    * 1.2-2      2022-06-13 [1] local\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.0)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.16       2022-08-09 [1] CRAN (R 4.2.0)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n ggplot2       3.3.6.9000 2022-09-05 [1] Github (tidyverse/ggplot2@a58b48c)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt            0.7.0      2022-08-25 [1] CRAN (R 4.2.0)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.0      2022-02-22 [1] CRAN (R 4.2.0)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.0)\n lifecycle     1.0.2      2022-09-05 [1] Github (r-lib/lifecycle@f92faf7)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n purrr         0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n readxl        1.4.1      2022-08-17 [1] CRAN (R 4.2.0)\n rlang         1.0.5      2022-08-31 [1] CRAN (R 4.2.0)\n rmarkdown     2.16       2022-08-24 [1] CRAN (R 4.2.0)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.0)\n sass          0.4.2      2022-07-16 [1] CRAN (R 4.2.0)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyselect    1.1.2      2022-02-21 [1] CRAN (R 4.2.0)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n vctrs         0.4.1      2022-04-13 [1] CRAN (R 4.2.0)\n xfun          0.32       2022-08-10 [1] CRAN (R 4.2.0)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.0)\n\n [1] /Users/sebastiansaueruser/Rlibs\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "metrische-AV.html",
    "href": "metrische-AV.html",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "",
    "text": "Benötigte R-Pakete für dieses Thema:"
  },
  {
    "objectID": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "href": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.1 Wissenschaft als Gerechtigkeitsprojekt",
    "text": "10.1 Wissenschaft als Gerechtigkeitsprojekt\n\n10.1.1 Meinungen als Grundlage der Konfliktlösung ?\nContra:\n\n“Ich find Masken doof!”\n“Impfen ist schädlich!”\n“Corona gibt’s gar nicht!”\n\n\n\n  \n\n\nPro:\n\n“Ich find Masken gut!”\n“Impfen ist nützlich!”\n“Corona ist gefährlich!”\n\n\n\n  \n\n\nMeinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte können auf Basis von Meinungen nur schwer gelöst werden.\n\n\n10.1.2 Fakten als Grundlage der Konfliktlösung\nWissenschaft produziert Fakten. Da Fakten universell sind (sein können), ist Wissenschaft potenziell ein Weg zur Konfliktlösung. Warum helfen Fakten bei Konflikten?\nFakten sind neutral gegenüber Personen. Fakten bieten daher eine Chance zur fairen Einigung.\nWann ist ein Fakt ein Fakt?\nFakten müssen vor allem nachprüfbar sein (Daten, Analyse und Bericht müssen offen zugänglich sein).\n\n\n10.1.3 Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung\n\nThe effectiveness of full messenger RNA (mRNA) vaccination (≥14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.\n\nThompson et al. (2021); vgl. auch Nasreen et al. (2021); Pormohammad et al. (2021)\nDrei Anforderungen an die Qualität von Studien:\n\nhandwerklich gut: z.B. vergleichbare Gruppen, genaue Messinstrumente\nbescheiden: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche Qualität der Studie zulässt. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage berücksichtigt.\ntransparent: Das Vorgehen, die Hintergründe und Ziele werden offengelegt. Das betrifft auch möglich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen\n\n\n\n10.1.4 Psychologische Intervention zur Erhöhung der Impfquote\n\n\n\n\n\nQuelle/Volltext\nDai et al. (2021)\n\n\n10.1.5 Was heißt “ist effektiv”?\nNasreen et al. (2021) definieren effectivity, \\(e\\), so:\n\\[e = 1 - C; C= \\frac{n_{vacc|pos}}{n_{vacc|neg}}\\]\n\n\\(C\\) nennt man das Chancenverhältnis (odds ratio), es beschreibt einen Bruchterm: \\(\\frac{x}{y}\\).\n\\(n_{vacc|pos}\\): Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose\n\\(n_{vacc|neg}\\): Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose\n\nBeispiel: Von den 100 Personen mit positiver Corona-Diagnose sind 10 geimpft, \\(n_{vacc|pos}=10\\). Von den 100 Personen mit negativer Corona-Diagnose sind 90 geimpft, \\(n_{vacc|neg}=90\\)\n\\[C= \\frac{10}{90} = \\frac{1}{9}; e = 1 - \\frac{1}{9} = \\frac{8}{9} \\approx 0.88\\]\nIn diesem Beispiel liegt die Effektvitität \\(e\\) bei knapp 90%."
  },
  {
    "objectID": "metrische-AV.html#arten-von-forschungsfragen",
    "href": "metrische-AV.html#arten-von-forschungsfragen",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.2 Arten von Forschungsfragen",
    "text": "10.2 Arten von Forschungsfragen\n\n10.2.1 Deskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von Größe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\n\n\n10.2.2 Prädiktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der Größe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts für die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhält?\n\n\n\n10.2.3 Präskriptiv (erklärend, kausal)\n\nIst Größe eine Ursache von Gewicht (bei deutschen Männern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n10.2.4 Metrische AV\n\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV.\nFür die UV(s) sind nominale und metrische Skalenniveaus erlaubt.\nModelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt."
  },
  {
    "objectID": "metrische-AV.html#binäre-uv",
    "href": "metrische-AV.html#binäre-uv",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.3 1 binäre UV",
    "text": "10.3 1 binäre UV\n\n10.3.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im öffentlichen Dienst arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwändigen Studie die Intelligenz vieler Kinder gemessen. Zusätzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, “Risikofaktoren” für geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in Abhängigkeit davon, ob ihre jeweilige Mutter über einen Schlusabschluss (mom_hs) verfügt? (ceteris paribus)\n\n\n\n10.3.2 IQ von Kindern, binärer Prädiktor\n\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 <- stan_glm(\n  kid_score ~ mom_hs, \n  data = kidiq)\n\nAlternativ können Sie die Daten hier herunterladen.\nMit parameters(m10.1) bekommt man die Parameter des Modells:\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n77.61\n(73.33, 81.59)\n100%\n0%\n1.000\n4119.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.73\n(7.20, 16.63)\n100%\n0%\n1.000\n4194.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nggplot(kidiq) +\n  aes(x = mom_hs, y = kid_score) +\n  geom_jitter(width = 0.1, alpha = .5) +\n  geom_abline(slope = coef(m10.1)[2],\n              intercept = coef(m10.1)[1])  +\n  scale_x_continuous(breaks = c(0, 1))\n\n\n\n\n\n\n10.3.3 Interpretation von m10.1\nm10.1: kid_score = 78 + 12*mom_hs + error\n\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren Mütter über keinen Schulabschluss (mom_hs = 0) verfügen:\n\nkid_score = 78 + 0*12 + error\n\nDas Regressionsgewicht (slope, \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit Mütter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit Mütter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\nkid_score = 78 + 1*12 + error = 90 + error\n\nDie Größer der Konfidenzintervalle zeigt, wie genau die Schätzung (Vorhersage) ist bzw. wie stark Prädiktor (UV) und Kriterium (AV) zusammenhängen.\n\n\n\n10.3.4 m10.1 als Mittelwertsdifferenz\n\nUV: binär (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\n\nkidiq %>% \n  group_by(mom_hs) %>% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n\n0\n77.54839\n\n\n1\n89.31965\n\n\n\n\n\n\n\nIn der klassischen Statistik untersucht man diese Datensituation mit einem t-Test.\nDer t-Test ist ein inferenzstatistisches Verfahren, dass prüft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\).\nIn der Bayes-Statistik betrachtet man dazu die Posteriori-Verteilung (z.B. mit 95%PI).\n\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von Müttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.\n\n\n10.3.5 Antwort auf die Forschungsfrage, m10.1\n\nm10.1_post <-\n  m10.1 %>% \n  as_tibble() \n\n\n\n\n\n\n\n  \n    \n      Stichprobe aus der Post-Verteilung\n    \n    \n  \n  \n    \n      (Intercept)\n      mom_hs\n      sigma\n    \n  \n  \n    77.4\n12.9\n19.5\n    77.8\n11.3\n19.0\n    77.9\n11.0\n20.8\n    77.3\n13.0\n19.8\n    81.7\n10.2\n19.5\n  \n  \n  \n\n\n\n\n\npi_mom_hs <-\n  m10.1_post %>% \n  summarise(pi_95 = quantile(mom_hs, c(.025, .975)))\n\npi_mom_hs\n\n\n\n\n\npi_95\n\n\n\n\n7.195229\n\n\n16.634792\n\n\n\n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von Müttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\).\nDie Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschließend die Posteriori-Verteilung.\n\nplot(hdi(m10.1))"
  },
  {
    "objectID": "metrische-AV.html#nullhypothesen-sind-praktisch-immer-falsch",
    "href": "metrische-AV.html#nullhypothesen-sind-praktisch-immer-falsch",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.4 Nullhypothesen sind praktisch immer falsch",
    "text": "10.4 Nullhypothesen sind praktisch immer falsch\n\n\n–>\n\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, and Vehtari (2021)\n\n10.4.1 Alternativen zu Nullhypothesen\n\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\).\nNullhypothesen zu testen, ist sehr verbreitet.\nEin Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest möglich ist1\nEin anderer Grund ist vermutlich, … wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen:\n\nPosteriori-Intervalle (PI oder HDI) berichten\nRope-Konzept, Kruschke (2018)\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat."
  },
  {
    "objectID": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.5 Eine metrische plus eine nominale UV",
    "text": "10.5 Eine metrische plus eine nominale UV\n\n10.5.1 Forschungsfrage\n\nWie stark ist der Zusammenhang von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\n\ndata(\"kidiq\")  # Paket rstanarm, alternativ über CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\nDatenquelle\n\n\n10.5.2 1 metrischer Prädiktor\n\nm10.2 <-\n  stan_glm(kid_score ~ mom_iq, data = kidiq)\n\nm10.2 %>% \n  parameters()\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n25.90\n(13.81, 37.53)\n100%\n0%\n1.000\n3532.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.49, 0.73)\n100%\n0%\n1.000\n3535.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\n\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder für verschiedene IQ-Werte der Mütter. Vergleicht man Teilpopulationen von Müttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n\n10.5.3 Beide Prädiktoren, m10.3\nm10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error\n\nm10.3 <- \n  stan_glm(\n    kid_score ~ mom_hs + mom_iq, \n    refresh = 0,\n    data = kidiq)\n\nWill man nur schnell die Punktschätzer (Median) zu den Modellparametern (auch als Koeffizienten bezeichnet), so kann man anstelle von parameters() auch schreiben:\n\ncoef(m10.3)\n\n(Intercept)      mom_hs      mom_iq \n 25.6244540   5.8574201   0.5639949 \n\n\nMöchte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\ncoef(m10.3)[3]\n\n   mom_iq \n0.5639949 \n\n\n\nkidiq %>% \n  mutate(mom_hs = factor(mom_hs)) %>%  \n  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.3)[3],  # den 3. Wert aus dem Vector, den `coef()` zurückgibt\n              intercept = 26,\n              size = 1,\n              color = \"blue\") +\n  geom_abline(slope = coef(m10.3)[3],\n              intercept = 32,\n              color = \"red\",\n              size = 2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme(legend.position = \"bottom\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schätzt das Modell den IQ-Wert des Kindes auf 26.\nKoeffizient zum mütterlichen Schulabschluss: Vergleicht man Kinder von Müttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\nKoeffizient zur mütterlichen IQ: Vergleicht man Kinder von Müttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus."
  },
  {
    "objectID": "metrische-AV.html#interaktion",
    "href": "metrische-AV.html#interaktion",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.6 Interaktion",
    "text": "10.6 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nImportant\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.\n\n\n\nm10.4 <- \n  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, \n                  data = kidiq, refresh = 0)\n\ncoef(m10.4)\n\n  (Intercept)        mom_hs        mom_iq mom_hs:mom_iq \n   -9.8112627    49.1923581     0.9502973    -0.4611944 \n\n\n\n\n\n\n\n\n10.6.1 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Schätzwerte für Kinder mit Mütter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\nmom_hs: Unterschied der IQ-Schätzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\nmom_iq: Unterschied der IQ-Schätzwerte zwischen Kindern mit Müttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\nInteraktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten für mom_iq zwischen Mütter mit bzw. ohne Schulabschluss.\n\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\nGelman, Hill, and Vehtari (2021), Kap. 10.3\n\n\n10.6.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "metrische-AV.html#zentrieren-von-prädiktoren",
    "href": "metrische-AV.html#zentrieren-von-prädiktoren",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.7 Zentrieren von Prädiktoren",
    "text": "10.7 Zentrieren von Prädiktoren\n\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.\nZentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist.\nMit zentrierten Werten ist eine Regression einfacher zu interpretieren.\n\n\nkidiq <-\n  kidiq %>% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq),\n         mom_hs_c = mom_hs - mean(mom_hs))\n\n\nm10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.5)\n\n    (Intercept)          mom_hs        mom_iq_c mom_hs:mom_iq_c \n     85.3309711       2.9653183       0.9606276      -0.4754285 \n\n\n\n10.7.1 Interpretation von m10.5\n\nDer Achsenabschnitt (Intercept) gibt den geschätzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\nmom_hs gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\nmom_iq_c gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten für mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\n\n\n\n\n\n\n\n10.7.2 Zentrieren ändert nichts an den Vorhersagen\nm10.4:\n\nnew <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new <- posterior_predict(m10.4, newdata = new)\nmean(pred_new)\n\n[1] 85.75561\n\n\nm10.5:\n\nnew <- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new <- posterior_predict(m10.5, newdata = new)\nmean(pred_new)\n\n[1] 85.31916\n\n\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren ändert auch nicht die Regressionskoeffizienten, da die Streuungen der Prädiktoren nicht verändert wurden.\n\n\n10.7.3 Perzentilintervalle aus der Posterori-Verteilung\n\neti(m10.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n1\n(Intercept)\n0.95\n81.0758449\n89.635196\nfixed\nconditional\n\n\n2\nmom_hs\n0.95\n-1.7095992\n7.693660\nfixed\nconditional\n\n\n4\nmom_iq_c\n0.95\n0.6794406\n1.250004\nfixed\nconditional\n\n\n3\nmom_hs:mom_iq_c\n0.95\n-0.7932726\n-0.174470\nfixed\nconditional\n\n\n\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5):\n\nhdi(m10.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n1\n(Intercept)\n0.95\n81.0229313\n89.5665715\nfixed\nconditional\n\n\n2\nmom_hs\n0.95\n-1.7925270\n7.5718510\nfixed\nconditional\n\n\n4\nmom_iq_c\n0.95\n0.6919419\n1.2586553\nfixed\nconditional\n\n\n3\nmom_hs:mom_iq_c\n0.95\n-0.7749202\n-0.1630003\nfixed\nconditional\n\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n\n10.7.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei Müttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mütterlichen Intelligenz; pro Punkt Unterschied in müttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). Außerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei Mütter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. Zusammenhänge beschrieben.\n\n\n10.7.5 Relevanz von Prädiktoren\n\n\n\nMade at imgflip.com\n\n\nBetrachten wir m10.3 noch einmal.\nWelcher Prädiktor, mom_hs oder mom_hs ist wichtiger, im Sinne von stärker mit AV kid_score verbunden?\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n13.8066119\n36.7972407\nfixed\nconditional\n\n\nmom_hs\n0.95\n1.5964447\n10.1824593\nfixed\nconditional\n\n\nmom_iq\n0.95\n0.4368564\n0.6721882\nfixed\nconditional\n\n\n\n\n\n\nDas Problem ist, dass die Prädiktoren auf verschiedenen Skalen gemessen wurden, so dass sie nicht direkt vergleichbar sind. Man könnte\n\ndie Skalierungen der Prädiktoren angleichen\nVorhersagegüte verschiedener Modelle vergleichen (Modell mit einem vs. Modell mit beiden Prädiktoren)\n…\nDazu später mehr 🤓"
  },
  {
    "objectID": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.8 Eine nominale UV mit mehreren Stufen",
    "text": "10.8 Eine nominale UV mit mehreren Stufen\n\n10.8.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium haben Sie bei einem aufstrebenden Online-Händler angeheuert Sie sind für alles zuständig, was nach Wissenschaft oder Analyse aussieht oder sonst den Anschein erweckt, kompliziert zu sein. Aus irgendwelchen Gründen liebt Ihre Chefin Diamanten, so dass Ihre erste Aufgabe darin besteht, Diamantenpreise zu analysieren. Das Ziel Ihrer Chefin liegt darin, zu erkennen, was ein Preis ist, für den ein Diamant gut verkauft werden kann. Kennt man diesen Preis, kann man sich auf die Suche machen, ob man den Diamant irgendwo günstiger findet. Wenn ja, macht man Gewinn. Gutes Geschäftsmodell, meint Ihre Chefin.\n\n\nUnterscheiden sich mittlere Diamantenpreise in Abhängigkeit von ihrer Schliffart? (Datensatz diamonds)\n\n\n\n10.8.2 Alle Mittelwerte sind gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Schliffart.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? 🤔 Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere Diamantenpreise in Abhängigkeit von ihrer Schliffart?\n\nOder wir prüfen die Hypothese, ob die Mittelwerte “praktisch” gleich sind, also sich “kaum” unterscheiden. Der Grenzwert für “praktisch gleich” bzw. “kaum unterschiedlich” ist subjektiv.\n\n\n10.8.3 Erster Blick in den Datensatz diamonds\nDatenquelle, Beschreibung des Datensatzes\n\ndiamonds_url <- \"https://tinyurl.com/up84jp5c\"\n\n\nset.seed(42)  # Zufallszahlen für `sample()` festlegen\ndiamonds <- \n  read_csv(diamonds_url) %>% \n  sample_n(1000) %>%  # um etwas Rechenzeit zu sparen\n  select(-1) # 1. Spalte nur laufende Nummer\n\n\ndiamonds %>% \n  select(price, cut) %>% \n  group_by(cut) %>% \n  # nehmen wir die robusten Statistiken, da Preis sehr schief ist:\n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nSkewness\nKurtosis\nn\nn_Missing\n.group\n\n\n\n\nprice\n4558.424\n2978.245\n1.647624\n2.885673\n33\n0\ncut=Fair\n\n\nprice\n4000.304\n3865.095\n1.905924\n3.518412\n102\n0\ncut=Good\n\n\nprice\n3275.998\n3515.271\n1.848450\n3.060260\n407\n0\ncut=Ideal\n\n\nprice\n4919.661\n4416.872\n1.279811\n1.038247\n230\n0\ncut=Premium\n\n\nprice\n3765.803\n3679.062\n1.788728\n3.420209\n228\n0\ncut=Very Good\n\n\n\n\n\n\n\n\n10.8.4 Ein Überblick über die metrischen Variablen\n… aufgeteilt in die Stufen von cut:\n\n\n\ncut=Fair\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n4558.42\n2978.25\n2498.50\n(743.00, 13853.00)\n1.65\n2.89\n33\n0\n\n\n\n\ncut=Good\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n4000.30\n3865.10\n3805\n(461.00, 18077.00)\n1.91\n3.52\n102\n0\n\n\n\n\ncut=Ideal\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n3276.00\n3515.27\n3865\n(397.00, 18168.00)\n1.85\n3.06\n407\n0\n\n\n\n\ncut=Premium\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n4919.66\n4416.87\n5310.25\n(345.00, 18493.00)\n1.28\n1.04\n230\n0\n\n\n\n\ncut=Very Good\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nprice\n3765.80\n3679.06\n3933.50\n(373.00, 18371.00)\n1.79\n3.42\n228\n0\n\n\n\n\n\nWas fällt Ihnen auf?\n\n\n10.8.5 Visualisierung (EDA)\n\n\n\n\n\n\n  \n  \n    \n      cut\n      price_md\n      price_iqr\n    \n  \n  \n    Fair\n3,640\n1,976\n    Good\n3,090\n3,745\n    Ideal\n1,759\n3,850\n    Premium\n4,058\n5,295\n    Very Good\n2,760\n3,902\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\nPicking joint bandwidth of 904\n\n\n\n\n\n\n\n10.8.6 Mittlere Preisunterschiede in der Population\n\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 <- stan_glm(price ~ cut, data = diamonds, refresh = 0)\n# refresh=0 unterdrückt Ausgabe der Posteriori-Stichproben\n\n\nm10.6 %>% \n  parameters()\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4526.68\n(3238.06, 5820.81)\n100%\n0%\n1.003\n1009.00\nNormal (3881.91 +- 9611.59)\n\n\ncutGood\n-533.57\n(-2029.63, 959.77)\n75.67%\n0%\n1.002\n1123.00\nNormal (0.00 +- 31742.41)\n\n\ncutIdeal\n-1253.86\n(-2603.09, 107.10)\n96.40%\n0%\n1.004\n1044.00\nNormal (0.00 +- 19554.81)\n\n\ncutPremium\n395.44\n(-1002.89, 1776.66)\n71.38%\n0%\n1.003\n1068.00\nNormal (0.00 +- 22828.05)\n\n\ncutVery Good\n-756.51\n(-2148.65, 599.54)\n85.78%\n0%\n1.004\n1039.00\nNormal (0.00 +- 22898.24)\n\n\n\n\n\n\n\n10.8.7 Interpretation von m10.6\n\ncut hat fünf verschiedene Werte (Stufen, Faktorstufen, Ausprägungen), aber es werden nur vier angezeigt.\nDie fünfte (Fair, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrückt.\nDie Koeffizienten für cut geben jeweils den Unterschied zur Vergleichskategorie wieder.\nDiamanten der Schliffart Fair haben laut Modell einen mittleren Preis von ca. 4300$.\nDiamanten der Schliffart Good sind laut Modell im Mittel gut 400$ billiger als Diamanten der Schliffart Fair, etc.\n\n\nplot(m10.6, regex_pars = \"^cut\")\n\n\n\n\n\n\n10.8.8 Schätzbereiche für die Modellparameter\n\nm10.6 %>% \n  hdi()\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n3294.1221\n5859.2441\nfixed\nconditional\n\n\ncutGood\n0.95\n-2054.2123\n918.7443\nfixed\nconditional\n\n\ncutIdeal\n0.95\n-2517.5156\n159.8897\nfixed\nconditional\n\n\ncutPremium\n0.95\n-967.1144\n1807.1827\nfixed\nconditional\n\n\ncutVery Good\n0.95\n-2043.7011\n672.6454\nfixed\nconditional\n\n\n\n\n\n\n\n\n10.8.9 Glauben wir jetzt an Preisunterschiede?\n… zwischen den Preis-Mittelwerten in der Population?\n\nTeilweise, denn einige Schätzintervalle (für die Preisunterschiede) waren im Modell m10.6 weit von der Null entfernt, andere nicht.\nAuf Basis unseres Modells schließen wir also (mit hoher Sicherheit) aus, dass alle Preise im Mittelwert exakt identisch sind.\nEhrlicherweise hätte sowieso niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.\nAber: Viele Forscheris prüfen gerne die Nullhypothese, daher taucht der Begriff hier auf.\nDas Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA).\nIn der Bayes-Statistik nutzt man - wie immer - primär die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) zu inferenzstatistisch zu beurteilen.\n\n\n\n10.8.10 Modellkoeffizienten von m10.6\nDie Regressionsoeffizienten pro Stufen von cutentsprechen den Mittelwerten \\(\\hat{y_i}\\) aus der Posteriori-Verteilung. Mit coef(m10.6) kann man sie sich bequem ausgeben lassen.\n\ncoef(m10.6)\n\n (Intercept)      cutGood     cutIdeal   cutPremium cutVery Good \n   4526.6810    -533.5694   -1253.8603     395.4444    -756.5090 \n\n\n\n\\(\\hat{y}_{Fair} = 4527\\)\n\\(\\hat{y}_{Good} = -534\\)\netc."
  },
  {
    "objectID": "metrische-AV.html#priori-werte",
    "href": "metrische-AV.html#priori-werte",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.9 Priori-Werte",
    "text": "10.9 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. Für Achsenabschnitt und die Regressionskoeffizienten werden Normalverteilungen angenommen mit Mittelwert entsprechend den Stichprobendaten und Streuung, die der 2.5-fachen der Streuung in der Stichprobe entspricht. Mehr Infos kann man sich so ausgeben lassen: prior_summary(m10.6). Wo man man über mehr inhaltliches Wissen verfügt, so wird man die Priors anpassen wollen, z.B.:\n\nm10.6b <- stan_glm(price ~ cut, data = diamonds, refresh = 0,\n                   prior = normal(location = c(100, 100, 100, 100),\n                                  scale = c(100, 100, 100, 100)),\n                   prior_intercept = normal(3000, 500))\ncoef(m10.6b)\n\n (Intercept)      cutGood     cutIdeal   cutPremium cutVery Good \n  3766.82654    105.66716    -40.76307    238.00057     78.24536 \n\n\nDie Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\nsigma(m10.6b)\n\n[1] 3831.667\n\n\nImplizit bekommt man diese Informationen mitgeteilt durch die Größe der Konfidenzintervalle.\n\n10.9.1 Wechsel der Referenzkategorie\n\ncut ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\n\ndiamonds <- diamonds %>% \n  mutate(cut = factor(cut))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge ändern.\n\n\nlevels(diamonds$cut)\n\n[1] \"Fair\"      \"Good\"      \"Ideal\"     \"Premium\"   \"Very Good\"\n\n\nSetzen wir Ideal als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\nlibrary(forcats)\ndiamonds <- diamonds %>% \n  mutate(cut = factor(cut),\n    cut = fct_relevel(cut, \"Ideal\"))\n\n\nlevels(diamonds$cut)\n\n[1] \"Ideal\"     \"Fair\"      \"Good\"      \"Premium\"   \"Very Good\"\n\n\n\n\n10.9.2 Wechsel der Referenzkategorie ändert nichts Wesentliches am Modell\n\nm10.6a <- stan_glm(price ~ cut, data = diamonds, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n2894.85196\n3635.294\nfixed\nconditional\n\n\ncutFair\n0.95\n-80.74787\n2617.730\nfixed\nconditional\n\n\ncutGood\n0.95\n-84.70268\n1529.411\nfixed\nconditional\n\n\ncutPremium\n0.95\n1033.68670\n2268.562\nfixed\nconditional\n\n\ncutVery Good\n0.95\n-124.41863\n1105.342\nfixed\nconditional"
  },
  {
    "objectID": "metrische-AV.html#modellgüte-mit-r-quadrat-bestimmen",
    "href": "metrische-AV.html#modellgüte-mit-r-quadrat-bestimmen",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.10 Modellgüte mit R-Quadrat bestimmen",
    "text": "10.10 Modellgüte mit R-Quadrat bestimmen\n\n10.10.1 Modellgüte mit \\(R^2\\) bestimmen\n\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklärt.\nHöhere Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklärt.\n\\(R^2\\) wird normalerweise auf Basis eines Punktschätzers definiert.\nSolch eine Definition lässt aber viel Information - über die Ungewissheit der Schätzung - außen vor.\nDaher ist es wünschenswert, diese Information in \\(R^2\\) einfließen zu lassen: Bayes-R-Quadrat.\nmit bayes_r2() kann man sich die Verteilung berechnen lassen.\n\n\n\n\nr2(m10.6)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.031 (95% CI [0.012, 0.053])\n\n\nMöchte man es ausführlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen:\n\nm10.6_r2 <-\nm10.6 %>% \n  r2_posterior() %>% \n  as_tibble()\n\nhdi(m10.6_r2) %>% \n  plot()"
  },
  {
    "objectID": "metrische-AV.html#definition-vom-klassischen-r2",
    "href": "metrische-AV.html#definition-vom-klassischen-r2",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.11 Definition vom “klassischen” \\(R^2\\)",
    "text": "10.11 Definition vom “klassischen” \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\).\nAnders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\).\nAnders gesagt gibt \\(\\sigma\\) die “typische” Abweichung einer Beobachtung vom vorhergesagten Wert an.\nEs ist nützlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\):\n\\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\).\n\\(R2\\) gibt damit den Anteil der vom Modell erklärten Varianz, \\(V\\), an.\nBerechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck äquivalent zu:\n\\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\)\nDie beiden obigen Ausdrücke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlässigen Ungewissheit; sie sind übergewiss aus Bayes-Sicht."
  },
  {
    "objectID": "metrische-AV.html#bayes-r2",
    "href": "metrische-AV.html#bayes-r2",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.12 Bayes’ \\(R^2\\)",
    "text": "10.12 Bayes’ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellgüte miteinzubeziehen:\n\\(\\text{Bayes }R^2 = \\frac{\\text{erkärte Varianz}}{\\text{Erklärte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\)\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell.\nFür jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklärten Varianz:\n\\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\)\n\nGelman et al. (2019), Gelman, Hill, and Vehtari (2021), Kap. 11.7"
  },
  {
    "objectID": "metrische-AV.html#praktisch-kein-unterschied",
    "href": "metrische-AV.html#praktisch-kein-unterschied",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.13 “Praktisch” kein Unterschied",
    "text": "10.13 “Praktisch” kein Unterschied\n\nSagen wir, wenn sich zwei Preismittelwerte um höchstens \\(d=100\\)€ unterscheiden, gilt dieser Unterschied für uns als “praktisch gleich”, “praktisch kein Unterschied” bzw. vernachlässigbar.\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\).\nDie Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Überlegungen geleitet sein sollte.\nDiesen Bereich bezeichnen wir den Indifferenzbereich (Äquivalenzzone, Bereich eines vernachlässigbaren Unterschieds oder Region of practical equivalence, Rope).\nJetzt prüfen wir, ob ein “Großteil” der Posteriori-Stichproben im Rope liegt.\nUnter “Großteil” wird häufig das 95%-HDI verstanden.\n\nEntscheidungsregel:\n\nGroßteil liegt innerhalb von Rope ➡️ Annahme der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\nGroßteil liegt außerhalb von Rope ➡️ Ablehnung der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\nAnsonsten ➡️ keine Entscheidung\n\nKruschke (2018)\n\n10.13.1 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\nKruschke (2018), Abbildung 1, S. 272\n\n\n10.13.2 Rope berechnen\n\nrope(m10.6)\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-384.4637\n384.4637\n0.0000000\nfixed\nconditional\n\n\ncutGood\n0.95\n-384.4637\n384.4637\n0.3239474\nfixed\nconditional\n\n\ncutIdeal\n0.95\n-384.4637\n384.4637\n0.0857895\nfixed\nconditional\n\n\ncutPremium\n0.95\n-384.4637\n384.4637\n0.3713158\nfixed\nconditional\n\n\ncutVery Good\n0.95\n-384.4637\n384.4637\n0.2631579\nfixed\nconditional\n\n\n\n\n\n\nAlle Faktorstufen von cut haben doch einen beträchtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir können daher für keinen der Unterschiede das ROPE verwerfen.\nDas hört sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nNote\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n\n10.13.3 Visualisierung unserer Rope-Werte, m10.6\n\nEin Großteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber können wir umgekehrt sagen, dass ein Großteil außerhalb liegt? Das erkennt man optisch ganz gut.\n\n\nrope(m10.6) %>% plot()\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\nDas ROPE druchkreuzt die “Berge” der Posteriori-Verteilung doch recht deutlich. Wir knönen das Rope nicht verwerfen.\n\n\n10.13.4 Genaue Rope-Werte\n\nlibrary(bayestestR)\nrope(m10.6, range = c(-100, 100))\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so ändern, wenn man möchte:\n\nrope(m10.6, range, c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht für ein PI.\n\nplot(rope(m10.6, range = c(-100, 100)))\n\nPossible multicollinearity between cutIdeal and cutGood (r = 0.84), cutPremium and cutGood (r = 0.8), cutVery Good and cutGood (r = 0.81), cutPremium and cutIdeal (r = 0.89), cutVery Good and cutPremium (r = 0.87). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n\n\n\n10.13.5 Beantwortung der Forschungsfrage\n\nNur das 95%-HDI für Schliffart “Ideal” schloss den Indifferenzbereich von ±100€ aus, die übrigen Mittelwertsdifferenzen nicht. Für die übrigen Differenzen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs möglich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.\n\n\nDie 95%HDI für die Mittelwertsdifferenzen waren wie folgt: cutGood: [-2040, 953], cutIdeal: [-2645, -4], cutPremium: [-965, 1732], cutVeryGood: [-2102, 627]. Das Modell erklärte im Median ca. 3% der Varianz, also nur einen kleinen Teil."
  },
  {
    "objectID": "metrische-AV.html#mehrere-metrische-uv",
    "href": "metrische-AV.html#mehrere-metrische-uv",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.14 Mehrere metrische UV",
    "text": "10.14 Mehrere metrische UV\n\n10.14.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhängig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa “IQ der Mutter ist die Ursache zum IQ des Kindes”) wird impliziert.\nEs geht rein darum, Zusammenhänge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. Für solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nötig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n\n10.14.2 Was heißt, X hängt mit Y zusammen?\n\nDer Begriff “Zusammenhang” ist nicht exakt.\nHäufig wird er (für metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groß der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem “Effekt von X auf Y” übersetzt. Vorsicht: “Effekt” klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begründung für einen Kausalzusammenhang.\n\nDer Korrelationskoeffizient\n\nmisst eine Art der Stärke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehörigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n\n10.14.3 Korrelationen zur Forschungsfrage\n\nkidiq %>% \n  correlation()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n< .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n< .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n< .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n< .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\n\nkidiq %>% \n  correlation() %>% \n  summary() %>% \n  plot()\n\n\n\n\n\n\n10.14.4 Univariate Regressionen\n\nm10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\ncoef(m10.7)\n\n(Intercept)      mom_iq \n  25.840357    0.610583 \n\n\n\ncoef(m10.8)\n\n(Intercept)     mom_age \n 70.8061260   0.7012694 \n\n\n\n\n10.14.5 Visualisierung der univariaten Regressionen\nm10.7\nSteigung: 0.6\n\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.7)[1],\n              slope = coef(m10.7)[2],\n              color = \"blue\")\n\n\n\n\nm10.8\nSteigung: 0.7\n\nkidiq %>% \n  ggplot(aes(x = mom_age, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.8)[1],\n              slope = coef(m10.8)[2],\n              color = \"blue\")\n\n\n\n\n\n\n10.14.6 Multiples Modell (beide Prädiktoren), m10.9\n\nm10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n\n(Intercept)      mom_iq     mom_age \n 17.6886001   0.6031288   0.3932556 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils “bereinigt” vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines Prädiktors mit der AV, wobei man gleichzeitig den anderen Prädiktor konstant hält.\n\n\ncoef(m10.9)\n\n(Intercept)      mom_iq     mom_age \n 17.6886001   0.6031288   0.3932556 \n\n\n\n\n10.14.7 3D-Visualisierung eines Modells mit zwei Prädiktoren 1\n\n\n\n\n\n\n\n\n10.14.8 Visualisierung mit Farbe statt 3. Dimension\n\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farbänderung) die Veränderung für die AV (kid_score). Auf der Achse für mom_age sieht man, dass sich die AV kaum ändert, wenn sich mom_age ändert.\n\n\n10.14.9 Visualisierung in 10 Dimensionen\n\nggplot(data.frame(x=NA, y=NA)) +\n  theme(panel.background = element_rect(fill = 'lightblue'))\n\n\n\n\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schwächen, eine große Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine einfache Zusammenfassung eines (ggf. hochdimensionalen) Variablenraumes.\n\n\n10.14.10 Relevanz der Prädiktoren\n\nWelcher Prädiktor ist nun “wichtiger” oder “stärker” in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age?\nmom_iq hat den größeren Koeffizienten.\nmom_age hat weniger Streuung.\nUm die Relevanz der Prädiktoren vergleichen zu können, müsste man vielleicht die Veränderung von kid_score betrachten, wenn man von kleinsten zum größten Prädiktorwert geht.\nAllerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden).\nSinnvoller ist es daher, die Veränderung in der AV zu betrachten, wenn man den Prädiktor von “unterdurchschittlich” auf “überdurchschnittlich” ändert.\nDas kann man mit z-Standardisierung erreichen.\n\n\n\n10.14.11 z-Standardisierung\n\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie über einen Mittelwert von 0 und eine SD von 1 verfügt:\n\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\ndata(\"kidiq\")\nkidiq2 <- \n  kidiq %>% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% \n  select(mom_iq, mom_iq_z) %>% \n  head()\n\n\n\n10.14.12 Statistiken zu den z-transformierten Variablen\n\n\n\n\n\n\n  \n  \n    \n      variable\n      n\n      mean\n      sd\n    \n  \n  \n    kid_score\n434\n86.797\n20.411\n    mom_age\n434\n22.786\n2.701\n    mom_hs\n434\n0.786\n0.411\n    mom_iq\n434\n100.000\n15.000\n  \n  \n  \n\n\n\n\n So kann man auch die z-Transformation (“Skalierung”) durchführen:\n\nkidiq <- \n  standardize(kidiq, append = TRUE)\n\nhead(kidiq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafür, dass die ursprünglichen Variablen beim Z-Standardisieren nicht überschrieben werden, sondern angehängt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen standardisieren\n\nkidiq %>% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket:\n\n#data(kidiq)\nkidiq %>% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score)) %>% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_z2\nmom_age_z2\nkid_score_z2\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n1.4078352\n1.5602285\n-1.06793237\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n-0.7092079\n0.8197811\n0.54886757\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n1.0295443\n1.5602285\n-0.08805362\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n-0.0366907\n0.8197811\n-0.18604150\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n-0.4836193\n1.5602285\n1.38176451\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n0.5267892\n-1.7717849\n0.54886757\n\n\n\n\n\n\n\n\n10.14.13 Modell mit standardisierten Prädiktoren, m10.10\nDas Standardisieren der AV, kid_score ist nicht nötig, um den Effekt der Prädiktoren (UV) auf die AV zu untersuchen. Standardisiert man die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darüber, um wie viele SD-Einheiten sich die AV verändert, wenn sich ein Prädiktor um eine SD-Einheit verändert.\n\nm10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, data = kidiq, refresh = 0)\ncoef(m10.10)\n\n (Intercept)     mom_iq_z    mom_age_z \n0.0004107225 0.4430261801 0.0516987335 \n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient für mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_iq um eine SD-Einheit ändert.\nDer Koeffizient für mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_age um eine SD-Einheit ändert.\n\nJetzt sind die Prädiktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n\n10.14.14 95%-PI\n\nparameters(m10.10) \n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4.11e-04\n(-0.08, 0.08)\n50.40%\n100%\n1.000\n4998.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0%\n1.000\n5035.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.55%\n89.05%\n1.001\n5165.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\nplot(hdi(m10.10))\n\n\n\n\n\n\n10.14.15 Was ist ein kleiner, was ein großer Effekt?\n\nCohen (1988) definiert Effektstärken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\).\nFür kleine, mittlere und große Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\nmittel: \\(d \\approx 0.5\\)\ngroß: \\(d \\approx 0.8\\)\n\nAuf dieser Basis schlägt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor.\nFällt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als “praktisch null”.\nRichtlinien für Effektstärken sind nur Notlösungen, die durch Sachverstand ersetzt werden sollen, wo immer möglich.\nMan kann Effektstärken ineinander überführen, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n\n\n10.14.16 Vernachlässigbarer Regressionseffekt\nKruschke (2018) schlägt vor, einen Regressionskoeffizienten unter folgenden Umständen als “praktisch Null” zu bezeichnen:\n\nWenn eine Veränderung über “praktisch den ganzen Wertebereich” von \\(x\\) nur einen vernachlässigbaren Effekt auf \\(y\\) hat.\nEin vernachlässigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\).\nDer “praktisch ganze Wertebereich” von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\).\nResultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Veränderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlässigbar.\nDas impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) für z-standardisierte Variablen.\n\n\n\n10.14.17 Verwandtheit von Korrelation und Regression\n\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\n\\[b = r \\frac{sd_x}{sd_y}\\]\n\nm10.11 <- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq, refresh = 0)\ncoef(m10.11)\n\n (Intercept)     mom_iq_z \n-0.000102025  0.449942456 \n\n\n\nkidiq %>% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nkid_score\nmom_iq\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nkid_score\nkid_score_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nkid_score_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nmom_iq_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score_z\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\n\n\n\n\n\n\n10.14.18 Modellgüte\n\nr2(m10.10)\n\n# Bayesian R2 with Compatibility Interval\n\n  Conditional R2: 0.204 (95% CI [0.142, 0.268])\n\n\nIst dieser Wert von \\(R2\\) “gut”? Diese Frage ist ähnlich zur Frage “Ist das viel Geld?”; man kann die Frage nur im Kontext beantworten.\nEine einfache Lösung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklärt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufällig hohen Werten der Modellgüte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine “objektive” Antwort auf die Frage “wie viel ist viel?” haben wollen, ziehen wir Herrn Cohen zu Rate:\n\ninterpret_r2(0.2)  # aus `easystats`\n\n[1] \"moderate\"\n(Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n\n10.14.19 Priori-Verteilung für m10.10 und Modelldefinition\n\nprior_summary(m10.10)  # aus rstanarm\n\nPriors for model 'm10.10' \n------\nIntercept (after predictors centered)\n ~ normal(location = -2.8e-16, scale = 2.5)\n\nCoefficients\n ~ normal(location = [0,0], scale = [2.5,2.5])\n\nAuxiliary (sigma)\n ~ exponential(rate = 1)\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\\[\\begin{align}\n\\text{kid_score} &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{mom_iq}_i + \\beta_2\\text{mom_age}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{align}\\]\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuführen.\n\n\n10.14.20 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar für einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkärt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich et al. 2022) zurück (s. Anhang für Details).\n\nHier wird von einem “statistischen Effekt” gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenhänge, und nicht um kausale Zusammenhänge, handelt. Kausale Zusammenhänge dürfen wir nur verkünden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafür finden oder c) wir ein Experiment fachgerecht durchgeführt haben."
  },
  {
    "objectID": "metrische-AV.html#vertiefung",
    "href": "metrische-AV.html#vertiefung",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.15 Vertiefung",
    "text": "10.15 Vertiefung\n🏎️VERTIEFUNG🏎️\n\n10.15.1 Prüfen der Linearitätsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen Prädiktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression häufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schätzen (Gelman, Hill, and Vehtari 2021).\nIst die Linearitätsannahme erfüllt, so sollte der Residualplot nur zufällige Streuung um \\(y=0\\) herum zeigen.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsächlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\nkidiq <-\n  kidiq %>% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\nkidiq %>% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nHier erkennt man keine größeren Auffälligkeiten.\n\n\n10.15.2 Modellprüfung mit der PPV\n\npp_check(m10.10)\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht häufig.\n\n\n10.15.3 Visualisierung der bereinigten Regressionskoeffizienten\n\nset.seed(42)\ndata(kidiq)\nkidiq3 <- \n  kidiq %>% \n  standardize(append = TRUE) %>% \n  sample_n(size = 300)\n\n#| results: \"hide\"\nm10.10a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)\nm10.10b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(mom_age_resid = resid(m10.10a)) %>% \n  mutate(mom_iq_resid = resid(m10.10b))\n\n\nm10.10c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)\nm10.10d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)\n\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(m10.10c_resid = resid(m10.10c)) %>% \n  mutate(m10.10d_resid = resid(m10.10d))\n\n\n\n\n\n#(m10.10a_plot + m10.10b_plot) / (m10.10c_plot + m10.10d_plot)\nplots(m10.10a_plot, m10.10b_plot, m10.10c_plot, m10.10d_plot, n_rows = 2, tags = \"A\",\n      guides = \"collect\")\n\nWarning: Removed 7 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 7 rows containing missing values (`geom_segment()`).\n\n\nWarning: Removed 11 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 11 rows containing missing values (`geom_segment()`).\n\n\nWarning: Removed 16 rows containing missing values (`geom_point()`).\nRemoved 16 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDie vertikalen Balken zeigen die Residuen.\n\nObere Reihe: Regression eines Prädiktors auf den anderen Prädiktor.\nUntere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z.\nUnten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhängt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang.\nUnten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhängt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\n\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n4.11e-04\n(-0.08, 0.08)\n50.40%\n100%\n1.000\n4998.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0%\n1.000\n5035.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n88.55%\n89.05%\n1.001\n5165.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\n\n10.15.4 Bereinigte Regressionskoeffizienten für mtcars\n\nmtcars2 <-\n  mtcars %>% \n  standardize()\n\nm12a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)\nm12b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)\n\nmtcars2 <-\n  mtcars %>% \n  mutate(m12a_resid = resid(m12a)) %>% \n  mutate(m12b_resid = resid(m12b))\n\n\nm12c <- stan_glm(mpg ~ m12a_resid, data = mtcars2, refresh = 0, chains = 1)\nm12d <- stan_glm(mpg ~ m12b_resid, data = mtcars2, refresh = 0, chains = 1)\n\n\nmtcars2 <-\n  mtcars2 %>% \n  mutate(m12c_resid = resid(m12c)) %>% \n  mutate(m12d_resid = resid(m12d))\n\n\n\n\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nÜbrigens liefern stan_glm() und lm oft ähnliche Parameterwerte (bei schwach informativen Prioriwerten):\n\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()\n\n(Intercept)          hp         cyl \n36.84877039 -0.01934222 -2.26124451 \n\n\n\nlm(mpg ~ hp + cyl, data = mtcars) %>% coef()\n\n(Intercept)          hp         cyl \n 36.9083305  -0.0191217  -2.2646936 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWenn auch die Parameterwerte eines Frequentistischen und Bayes-Modell numerisch ähnlich sein können, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht."
  },
  {
    "objectID": "metrische-AV.html#ausblick-binäre-av",
    "href": "metrische-AV.html#ausblick-binäre-av",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.16 Ausblick: Binäre AV",
    "text": "10.16 Ausblick: Binäre AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: Hängen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\n\ndata(mtcars)\nmtcars2 <-\n  mtcars %>% \n  standardize(append = TRUE)\n\n\nm13 <-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n\n(Intercept)       mpg_z \n  0.4060587   0.2975638 \n\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\nmtcars2 %>% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\nneg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))\n\nFür kleine Werte von mpg_z (<1.3) sagt unser Modell negative Werte für am voraus. Das macht keinen Sinn. Müssen wir mal bei Gelegenheit besser machen."
  },
  {
    "objectID": "metrische-AV.html#wir-waren-fleißig",
    "href": "metrische-AV.html#wir-waren-fleißig",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.17 Wir waren fleißig",
    "text": "10.17 Wir waren fleißig\n\nknitr::include_graphics(\"https://media.giphy.com/media/XIqCQx02E1U9W/giphy.gif\")\n\n\n\n\nQuelle\nGenug für heute 👍\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja, Sitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and Daniel M. Croymans. 2021. “Behavioural Nudges Increase COVID-19 Vaccinations.” Nature 597 (7876): 404–9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” The American Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022. “Rstanarm: Bayesian Applied Regression Modeling via Stan.” https://mc-stan.org/rstanarm/.\n\n\nKruschke, John K. 2018. “Rejecting or Accepting Parameter Values in Bayesian Estimation.” Advances in Methods and Practices in Psychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B. Gubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021. “Effectiveness of mRNA and ChAdOx1 COVID-19 Vaccines Against Symptomatic SARS-CoV-2 Infection and Severe Outcomes with Variants of Concern in Ontario.” https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi, Mohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner. 2021. “Efficacy and Safety of COVID-19 Vaccines: A Systematic Review and Meta-Analysis of Randomized Clinical Trials.” Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball, Allison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021. “Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient Care Settings.” New England Journal of Medicine 385 (15): 1355–71. https://doi.org/10.1056/NEJMoa2110362."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja,\nSitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and\nDaniel M. Croymans. 2021. “Behavioural Nudges Increase\nCOVID-19 Vaccinations.” Nature 597 (7876):\n404–9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\n“R-Squared for Bayesian Regression Models.” The\nAmerican Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022.\n“Rstanarm: Bayesian Applied Regression Modeling via\nStan.” https://mc-stan.org/rstanarm/.\n\n\nKruschke, John K. 2018. “Rejecting or Accepting Parameter Values\nin Bayesian Estimation.” Advances in Methods and Practices in\nPsychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B.\nGubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021.\n“Effectiveness of mRNA and\nChAdOx1 COVID-19 Vaccines Against Symptomatic\nSARS-CoV-2 Infection and Severe Outcomes with\nVariants of Concern in Ontario.” https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi,\nMohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner.\n2021. “Efficacy and Safety of COVID-19 Vaccines: A\nSystematic Review and Meta-Analysis of Randomized Clinical\nTrials.” Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball,\nAllison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021.\n“Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient\nCare Settings.” New England Journal of Medicine 385\n(15): 1355–71. https://doi.org/10.1056/NEJMoa2110362."
  }
]