[
  {
    "objectID": "1050-Schaetzen-Testen.html#lernsteuerung",
    "href": "1050-Schaetzen-Testen.html#lernsteuerung",
    "title": "\n9  Schätzen vs. Testen\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n9.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können…\n\nden Unterschied zwischen dem Schätzen von Modellparametern und dem Testen von Hypothesen erläutern\nVor- und Nachteile des Schätzens und Testens diskutieren\nDas ROPE-Konzept erläutern und anwenden\nDie Güte von Regressionsmodellen einschätzen und berechnen\n\n9.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an (Kruschke 2018).\n\n9.1.4 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benötigt:\n\nlibrary(rstanarm)   # Bayes-Modelle\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.5 Benötigte Daten\nWir benötigen in diesem Kapitel folgenden Datensatz: penguins.\nSie können den Datensatz penguins entweder via dem Pfad importieren:\n\npenguins_url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\npenguins &lt;- read.csv(penguins_url)\n\n Download \nOder via dem zugehörigen R-Paket:\n\ndata(\"penguins\", package = \"palmerpenguins\")\n\nBeide Möglichkeit sind okay.\n\n9.1.6 Einstieg\nBetrachten Sie die zwei folgenden Aussagen, die jeweils ein Forschungsziel angeben:\n\n“Lernen für die Klausur bringt etwas!”\n“Wie viel bringt Lernen für die Klausur?”\n\n\nBeispiel 9.1 Diskutieren Sie die epistemologische Ausrichtung sowie mögliches Für und Wider der beiden Ausrichtungen! \\(\\square\\)",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#schätzen-oder-testen",
    "href": "1050-Schaetzen-Testen.html#schätzen-oder-testen",
    "title": "\n9  Schätzen vs. Testen\n",
    "section": "\n9.2 Schätzen oder Testen?",
    "text": "9.2 Schätzen oder Testen?\nForschungsfragen kann man, allgemein gesprochen, auf zwei Arten beantworten:\n\n\nHypothesen prüfend: “Die Daten widerlegen die Hypothese (nicht)”\n\nParameter schätzend: “Der Effekt von X auf Y liegt zwischen A und B”.\n\n\n9.2.1 Hypothesen prüfen\nHypothesen prüfende Analysen kommen zu einer Ja-Nein-Aussage bzgl. einer Hypothese. Genauer muss man sagen: Im besten Fall kommen sie zu einer Ja-Nein-Aussage. Es kann natürlich sein, dass die Datenlage so nebelig oder das Problem so knifflig ist, dass man ehrlicherweise zugeben muss, dass man sich nicht sicher ist oder sagar komplett im Dunkeln tappt.\n\nBeispiel 9.2 (“Lernen erhöht den Prüfungserfolg”) Die Hypothese Lernen erhöht den Prüfungserfolg kann durch eine Studie und eine entsprechende Analyse grundsätzlich folgende drei Ergebnisse finden. 1) Die Daten widersprechen der Hypothese: Lernen bringt offenbar doch nichts für den Klausurerfolg. 2) Die Daten unterstützen die Hypothese: Lernen erhöht den Prüfungserfolg. 3) Die Daten sind uneindeutig, es ist keine Aussage zum Einfluss von Lernen auf den Prüfungserfolg möglich. \\(\\square\\)\n\nDas Prüfen einer Hypothese kann zu drei Arten von Ergebnissen führen. Die ersten beiden sind informationsreich, die dritte ist informationsarm.\n\n🟢 Die Daten widersprechen der Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese ablehnen (verwerfen, sagt man), also als falsch (falsifziert) betrachten oder zumindest hat die Glaubwürdigkeit der Hypothese gelitten.\n🟥 Die Daten unterstützen die Hypothese: Auf Basis der Daten (und des Modells) muss man die Hypothese annehmen (oder kann die Gegenthese zumindest nicht verwerfen). Oder zumindest hat die Hypothese an Glaubwürdigkeit gewonnen.\n❓ Die Datenlage ist unklar; zum Teil unterstützen die Daten die Hypothese zum Teil widersprechen sie ihr. Man kann keine oder kaum Schlüsse aus den Daten ziehen. In diesem Fall gibt es keinen Erkenntnisgewinn.\n\nHypothesen prüfen ist binär in dem Sinne, dass sie zu “Schwarz-Weiß-Ergebnissen” führen (sofern die Datenlage stark genug ist).\n\n\n\n\n\n\nWichtig\n\n\n\nEine gängige Variante des Hypothesen testen1 ist das Testen der Hypothese “kein Effekt” (Null Effekt), man spricht vom Nullhypothesen testen. \\(\\square\\)\n\n\n\n9.2.2 Beispiele für Nullhypothesen\n\n“Lernen bringt nichts”\n“Frauen und Männer parken gleich schnell ein”\n“Es gibt keinen Zusammenhang von Babies und Störchen”\n“Früher war es auch nicht besser (sondern gleich gut)”\n“Bei Frauen ist der Anteil, derer, die Statistik mögen gleich hoch wie bei Männern” (Null Unterschied zwischen den Geschlechtern) \\(\\square\\)\n\nVorteil des Hypothesen testen ist das klare, einfache Ergebnisse, was die Entscheidungsfindung unterstützen kann, da es die Komplexität reduziert.\n\n\n\n\n\n\nMan kann Hypothesen nicht bestätigen\n\n\n\nKarl Poppers These, dass man Hypothesen nicht bestätigen (verifizieren) kann, hat großen Einfluss auf die Wissenschaftstheorie (und Epistemologie allgemein) ausgeübt (Popper 2013). Schlagend ist das Beispiel zur Hypothese “Alle Schwäne sind weiß”. Auch eine große Stichprobe an weißen Schwänen kann die Wahrheit der Hypothese nicht beweisen. Schließlich ist es möglich, dass wir den schwarzen Schwan einfach noch nicht gefunden haben.2 Umgekehrt reicht die (zuverlässige) Beobachtung eines einzelnen schwarzen Schwans, um die Hypothese zu widerlegen (falsifizieren). \\(\\square\\)\n\n\n\n\n\n\n\n\nWirklich nicht?\n\n\n\nIn der Wissenschaftspraxis werden die meisten Hypothesen probabilistisch untersucht. Komplett sichere Belege, wie in Poppers Beispiel mit dem schwarzen Schwan, gibt es nicht. Das bedeutet, dass Evidenz im bestätigenden wie im widerlegenden Sinne tendenziell (probabilistisch) zu betrachten ist. Auf dieser Basis und der Basis zuverlässiger, repräsentativer Daten erscheint plausibel, dass Hypothesen sowohl bestätigt als auch widerlegt werden können (Kruschke 2018; Morey und Rouder 2011). \\(\\square\\)\n\n\n\n9.2.3 Parameter schätzen\nBeim Parameter schätzen untersucht man, wie groß ein Effekt ist, etwa der Zusammenhang zwischen X und Y. Es geht also um eine Skalierung, um ein wieviel und nicht um ein “ja/nein”, was beim Hypothesen testen der Fall ist.\nBeim Parameter schätzen gibt es zwei Varianten:\n\n⚫️ Punktschätzung: Das Schätzen eines einzelnen Parameterwerts, sozusagen ein “Best Guess”\n📏 Bereichsschätzung: Das Schätzen eines Bereichs plausibler oder wahrscheinlicher Parameterwerte\n\nAllerdings kann man das Parameter schätzen auch wie einen Hypothesentest nutzen: Ist ein bestimmter Wert, etwa die Null, nicht im Schätzbereich enthalten, so kann man die Hypothese verwerfen, dass der Parameter gleich diesem Wert (etwa Null) ist.\n\nBeispiel 9.3 (Parameterschätzen als Nullhypothesentest)  \n\nForschungsfrage: Sind männliche Pinguine im Schnitt schwerer als weibliche Tiere?\n\nGleichung 9.1 formalisiert diese Forschungsfrage als statistische Hypothese \\(H\\).\n\\[H: \\mu_M \\ge \\mu_F \\rightarrow d = \\mu_M - \\mu_F \\ge 0 \\tag{9.1}\\]\nDer Unterschied zwischen den Mittelwerten, \\(d\\), ist genau dann Null, wenn \\(\\beta_1\\) in unserem Regressionsmodell m1 gleich Null ist. Entsprechend gilt \\(d \\ge 0\\) wenn \\(\\beta_1 \\ge 0\\).\n\nm1 &lt;- stan_glm(\n  body_mass_g ~ sex, \n  data = penguins, \n  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n  seed = 42  # zur Reproduzierbarkeit\n)\n\nDann zählen wir einfach den Anteil der Stichproben in der Post-Verteilung für die UV sexmale, die einen Wert größer Null aufweisen:\n\nm1_post &lt;-\n  m1 |&gt; \n  as_tibble()\n\nm1_post |&gt; \n  count(sexmale &lt; 0)\n\n\n  \n\n\n\n100% (4000 von 4000) Stichproben finden einen Wert größer Null für sexmale, dass also weibliche Tiere leichter bzw. männliche Tiere schwerer sind. Entsprechend finden 0% der Stichproben einen Wert, der für das Gegenteil spricht (das weibliche Tiere schwerer wären). Damit resümieren wir, dass unser Modell 100% Wahrscheinlichkeit für die Hypothese einräumt: \\(p_H = 1\\). \\(\\square\\)\n\nVorteil der Parameterschätzung ist die Nuanciertheit des Ergebnisses, die der Komplexität echter Systeme besser Rechnung trägt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#sec-rope",
    "href": "1050-Schaetzen-Testen.html#sec-rope",
    "title": "\n9  Schätzen vs. Testen\n",
    "section": "\n9.3 ROPE: Bereich von “praktisch Null”",
    "text": "9.3 ROPE: Bereich von “praktisch Null”\n📺 Teil 2\nNullhypothesen sind fast immer falsch, s. Abbildung 9.1.\n\n\n\n\n\n\n\nAbbildung 9.1: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true. (Gelman, Hill, und Vehtari 2021)\n\n\n9.3.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z. B.: \\(\\rho=0\\), \\(\\rho_1 = \\rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest möglich ist.3\nEin anderer Grund ist vermutlich, … wir haben es schon immer so gemacht. 🤷‍♀️\nAlternativen zum Testen von Nullhypothesen sind:\n\nPosteriori-Intervalle (PI oder HDI) berichten\n\nRope-Konzept (Kruschke 2018)\n\nWahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\nWahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n9.3.2 “Praktisch” kein Unterschied: Das Rope-Konzept\n📺 ROPE-Video\n\nBeispiel 9.4 (Beispiele für ROPE) Sagen wir, wenn sich zwei Preismittelwerte um höchstens \\(d=100\\)€ unterscheiden, gilt dieser Unterschied für uns als “praktisch gleich”, “praktisch kein Unterschied” bzw. vernachlässigbar.\nBei Pinguinarten definiert eine Biologin nach umfangreichem Studium der Literatur, dass ein Unterschied von max. 100g “vernachlässigbar wenig” ist.\nEine findige Geschäftsfrau entscheidet für ihre Firma, dass ein Umssatzunterschied von 100k Euro “praktisch irrelevant” sei. \\(\\square\\)\n\nNimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Überlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Äquivalenzzone, Bereich eines vernachlässigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prüfen wir, ob ein “Großteil” der Posteriori-Stichproben im Rope liegt. Unter “Großteil” wird häufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroßteil liegt innerhalb von Rope ➡️ Annahme der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\n\nGroßteil liegt außerhalb von Rope ➡️ Ablehnung der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\n\nAnsonsten ➡️ keine Entscheidung\n\nMit “Großteil” meinen wir (per Default) das 95%-HDI (der Posteriori-Verteilung).\n\n9.3.3 Vernachlässigbarer Regressionseffekt\nKruschke (2018) schlägt vor, einen Regressionskoeffizienten unter folgenden Umständen als “praktisch Null” zu bezeichnen:\nWenn eine Veränderung über “praktisch den ganzen Wertebereich” von \\(x\\) nur einen vernachlässigbaren Effekt auf \\(y\\) hat. Ein vernachlässigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der “praktisch ganze Wertebereich” von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Veränderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlässigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) für z-standardisierte Variablen.\n\n\n\n\n\n\nROPE-Defaults\n\n\n\nIm der Voreinstellung umfasst die Größe des ROPE ±5% der SD der AV. \\(\\square\\)\n\n\n\n9.3.4 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\n\n\nAbbildung 9.2: Die Entscheidungsregeln zum ROPE illustiert.\n\n\n\n\nAbbildung 9.2 illustriert die Entscheidungsregel zum ROPE für mehrere Situatioenen (Kruschke 2018, Abb. 1, S. 272):\n\nLiegt das HDI komplett außerhalb des ROPE, verwirft man die Nullhypothese.\nLiegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.\nAnsonsten ist keine Entscheidung möglich; die Datenlage ist unklar.\n\n9.3.5 Rope berechnen\nHier ist das Modell, das Gewicht als Funktion der Pinguinart erklärt (m10.6).\n\nm10.6 &lt;- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n                  seed = 42  # zur Reproduzierbarkeit\n                  )\n\nDen Rope berechnet man mit rope(model).\n\nrope(m10.6)\n\n\n  \n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen beträchtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. Wir können d. h.r für diese Gruppe das ROPE nicht verwerfen. Die Datenlage ist unklar. Es ist keine abschließende Entscheidung über die Hypothese möglich.\nAber: Gentoo liegt zu 0% im Rope. Für Gentoo können wir das Rope verwerfen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\nDas hört sich abstrakt an? Dann lassen Sie uns das lieber visualisieren. 🎨\n\n9.3.6 Visualisierung unserer Rope-Werte, m10.6\nEin Großteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope. Aber können wir umgekehrt sagen, dass ein Großteil außerhalb liegt? Das erkennt man optisch ganz gut, s. Abbildung 9.3.\n\nrope(m10.6) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n(a) Diagramm mit rope(m10.6) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n(b) Diagramm mit parameters(m10.6) %&gt;% plot()\n\n\n\n\n\n\nAbbildung 9.3: Rope und HDI überlappen bei Chinstrap, aber nicht bei Gentoo. Im ersten Fall nehmen wir die Rope-Null-Hypothese an, im zweiten Fall verwerfen wir sie.\n\n\nDas ROPE druchkreuzt die “Berge” der Posteriori-Verteilung für Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir können das Nullhypothese für Chinstrap nicht verwerfen, aber auch nicht bestätigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom “blauen Fluss” des Rope: Gentoo liegt außerhalb des Rope. Es gibt einen “substanziellen” Unterschied, größer als das ROPE. Wir verwerfen die “Praktisch-Null-Hypothese” in diesem Fall.\n\n9.3.7 Finetuning des Rope\nWir können festlegen, was wir unter “praktischer Äquivalenz” verstehen, also die Grenzen des Ropes verändern. Sagen wir, 100 Gramm sind unsere Grenze für einen vernachlässigbaren Effekt, s. Abbildung 9.4.\n\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 9.4: ROPE mit selber eingestellter Grenze von ±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so ändern, wenn man möchte:\n\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\nETI (equal tails interval) steht für ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI4 sich im Rope befindet.\n\n9.3.8 Beantwortung der Forschungsfrage\nFür die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. Für Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs möglich: Es ist plausibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#modellgüte",
    "href": "1050-Schaetzen-Testen.html#modellgüte",
    "title": "\n9  Schätzen vs. Testen\n",
    "section": "\n9.4 Modellgüte",
    "text": "9.4 Modellgüte\n\n\n\n\n\n\n\n\n\n\n\n9.4.1 Wozu Modellgüte?\nHat man ein Modell aufgestellt und geprüft und Ergebnisse erhalten, möchte man wissen, wie belastbar diese Ergebnisse sind. Ein Hinweis zur Belastbarkeit des Modellergebnisse liefern Kennwerte der Modellgüte. Diese Kennwerte zielen z. B. darauf ab, wie präzise die Aussagen des Modells sind. Je präziser die Aussagen eines Modells, desto nützlicher ist es natürlich. Bei einer Parameterschätzung erhält man auch Informationen zur Präzision der Schätzung: Ist der Schätzbereich schmal, so ist die Schätzung präzise (und vice versa). Allerdings könnte ein Modell aus mehreren Parameterschätzungen bestehen, die unterschiedlich präzise sind. Da kann es helfen, eine zusammenfassen Beurteilung zur Präzision, oder allgemeiner zur Güte des Modells, zu erhalten.\nIm Folgenden ist eine Kennzahl von mehreren gebräuchlichen und sinnvollen vorgestellt, \\(R^2\\).\n\n9.4.2 Modellgüte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklärt. - Höhere Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklärt. \\(R^2\\) wird normalerweise auf Basis eines Punktschätzers definiert. Solch eine Definition lässt aber viel Information - über die Ungewissheit der Schätzung - außen vor. Daher ist es wünschenswert, diese Information in \\(R^2\\) einfließen zu lassen: Bayes-R-Quadrat.\n\n\n\n\n\nMöchte man es ausführlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. Abbildung 9.5.\n\nm10.6_r2 &lt;-\n  m10.6 %&gt;% \n  r2_posterior() %&gt;% \n  as_tibble()\n\nhdi(m10.6_r2) %&gt;% \n  plot()\n\n\n\n\n\n\nAbbildung 9.5: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n9.4.3 Definition vom “klassischen” \\(R^2\\)\n\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die “typische” Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nützlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklärten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck äquivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen Ausdrücke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlässigen Ungewissheit; sie sind übergewiss aus Bayes-Sicht.\n\n9.4.4 Bayes’ \\(R^2\\)\n\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellgüte miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkärte Varianz}}{\\text{Erklärte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. Für jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklärten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u. a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#fazit",
    "href": "1050-Schaetzen-Testen.html#fazit",
    "title": "\n9  Schätzen vs. Testen\n",
    "section": "\n9.5 Fazit",
    "text": "9.5 Fazit\nObwohl das Testen von Hypothesen im Moment verbreiteter ist, spricht einiges zugunsten der Vorzüge der Parameterschätzung. Möchte man aber, um sich bestimmter bestehender Forschung anzunähern, einen Hypothesentest, speziell den Test einer Nullhypothese verwenden, so bietet sich das ROPE-Verfahren an.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "1050-Schaetzen-Testen.html#aufgaben",
    "href": "1050-Schaetzen-Testen.html#aufgaben",
    "title": "\n9  Schätzen vs. Testen\n",
    "section": "\n9.6 Aufgaben",
    "text": "9.6 Aufgaben\n\nWskt-Schluckspecht\nwskt-mtcars-1l\nrope-regr\nrope1\nrope2\nrope3\n\n\n\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. „R-Squared for Bayesian Regression Models“. The American Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKruschke, John K. 2018. „Rejecting or Accepting Parameter Values in Bayesian Estimation“. Advances in Methods and Practices in Psychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nMorey, Richard D., und Jeffrey N. Rouder. 2011. „Bayes Factor Approaches for Testing Interval Null Hypotheses“. Psychological Methods 16 (4): 406–19. https://doi.org/10.1037/a0024377.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Herausgegeben von Herbert Keuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.",
    "crumbs": [
      "Lineare Modelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Schätzen vs. Testen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#lernsteuerung",
    "href": "0600-Post.html#lernsteuerung",
    "title": "6  Die Post befragen",
    "section": "6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n\n6.1.2 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n6.1.3 Begleitliteratur\nDer Stoff dieses Kapitels orientiert sich an McElreath (2020), Kap. 3.1 und 3.2.\n\n\n6.1.4 Vorbereitung im Eigenstudium\n\nStatistik1, Kap. “Daten umformen”\nStatistik1, Kap. “Daten zusammenfassen”\n\n\n\n6.1.5 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # optional\n\n\n\n6.1.6 Begleitvideos\n\nPlaylist QM2",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "0600-Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6  Die Post befragen",
    "section": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.2.1 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (“Bayes-Box”) die Postverteilung für den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nützliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) Würfen, bei Apriori-Indifferenz gegenüber den Parameterwerten. Und sagen wir \\(k=11\\) Gitterwerten1, also mit 10 Wasseranteilswerten zwischen 0 und 1.\n\nÜbungsaufgabe 6.1 (Welcher Paramterwert hat die höchste Posteriori-Wahrscheinlichkeit?)  \n\n\n\n\n\n\nLösung\n\n\n\n\n\nAufgrund der Apriori-Indifferenz entsprechen die Posteriori-Wahrscheinlichkeiten den Likelihoods. Die höchste Wahrscheinlichkeit (d. h. Likelihood) hat derjenige Parameterwert, zu dem die Daten am besten passen, und das ist 6/9 = 2/3, d. Listing 6.1. \\(\\square\\)\n\n\n\n\n\n\n\n\nListing 6.1: Bayes-Box mit 6 Wasser bei 9 Versuchen\n\n\nn &lt;- 11\nn_success &lt;- 6          \nn_trials  &lt;- 9\np_grid &lt;- seq(from = 0, to = 1, length.out = n)\nL &lt;- dbinom(n_success, size = n_trials, prob = p_grid)\n\nd &lt;-\n  tibble(p_grid = p_grid,prior  = 1) %&gt;% \n  mutate(likelihood = L) %&gt;% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\n\n\nSequenz von 0 bis 1 mit der Länge n=11 Schritte, das gibt uns die Parameterwerte\nLikelihood mit 6 Treffern bei 9 Würfen und das Ganze jeweils für alle 11 Parameterwerte\nDann packen wir alles in eine Tabelle.\n\n\n\nAbb. Abbildung 6.1 zeigt die resultierende Bayes-Box; vor allem ist die Post-Verteilung wichtig.\n\nlibrary(ggpubr)\nggline(d, x = \"p_grid\", y = \"post\") \n\n\n\n\n\n\n\n\n\nAbbildung 6.1: Die Postverteilung für W=6, N=9, k=10\n\n\n\n\n\nVoilà, die Post-Verteilung als Tabelle, auch “Bayes-Box” (oder Bayes-Gitter) genannt: s. Tabelle 6.1.\n\n\n\n\nTabelle 6.1: Postverteilung mit der Gittermethode berechnet\n\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.0\n1\n0.00\n0.00\n0.00\n\n\n0.1\n1\n0.00\n0.00\n0.00\n\n\n0.2\n1\n0.00\n0.00\n0.00\n\n\n0.3\n1\n0.02\n0.02\n0.02\n\n\n0.4\n1\n0.07\n0.07\n0.07\n\n\n0.5\n1\n0.16\n0.16\n0.16\n\n\n0.6\n1\n0.25\n0.25\n0.25\n\n\n0.7\n1\n0.27\n0.27\n0.27\n\n\n0.8\n1\n0.18\n0.18\n0.18\n\n\n0.9\n1\n0.04\n0.04\n0.04\n\n\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.2 Bayes-Box automatisiert\nÜbrigens kann man die Berechnung der Bayes-Box auch automatisieren, s. Tabelle 6.2 und Listing 6.2, z. B. so:2\nEntweder so:\n\nsource(\"https://raw.githubusercontent.com/sebastiansauer/prada/master/R/NAME_bayesbox.R\") \nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\nMit source importiert man eine R-Skriptdatei. In diesem Fall steht dort der Code für die Funktion bayesbox.\nOder Sie starten das R-Paket, wo die Funktion wohnt:\n\n\n\n\nListing 6.2: Funktion bayesbox, auch im Paket prada erhältlich\n\n\nlibrary(prada)\nbayesbox(hyps = p_grid, priors = 1, liks = L)\n\n\n\n\n\n\nTabelle 6.2: Eine Bayes-Box ‘automatisiert’ erstellt, mit Hilfe der Funktion bayesbox\n\n\n\n\n  \n\n\n\n\n\n\n\nDas Paket prada steht nicht im Standard-R-App-Store (“CRAN”), sondern auf Github. Sie könnnen es so installieren: devtools::install_github(\"sebastiansauer/prada\").\nDie Funktion verhält sich wie eine gewöhnliche Bayes-Box: Bei hyps schreibt man die Hypothesen (bzw. Parameterwerte) auf. Bei priors die Priori-Werte und bei liks die Likelihoods der jeweiligen Hypothesn.\n\n\n\n\n\n\n\n\n\n\n\n\nViele nützliche Fragen (und Antworten) leiten sich ab aus Abb. Abbildung 6.1.\n\nBeispiel 6.1 (Beispiele für Fragen an die Post-Verteilung)  \n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die höchste Wahrscheinlichkeit?\nWie ungewiss ist das Modell über die Parameterwerte?\n\netc. \\(\\square\\)\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.2.3 Bayes-Box für komplexe Modelle\nBisher, für einfache Fragestellungen hat unsere Bayes-Box, das heißt die Gittermethode bestens funktioniert: einfach, robust, formschön3. Allerdings: Funktioniert sie auch bei komplexeren Modellen? Schließlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 Prädiktor, dann haben wir folgende drei Größen4 zu schätzen: \\(\\beta_0, \\beta_1, \\sigma\\). Hört sich gar nicht so viel an. Aber Moment, wir müssten dann z. B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z. B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach müssen wir alle Ausprägungen (“Gitterwerte”) der Variablen multiplizieren. Puh, das wird eine große Zahl. Wenn wir für die drei Größen jeweils 10 Ausprägungen annehmen, was wenig ist, kämen wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 Ausprägungen wären es schon \\(100^3=10^6\\) Kombinationen. Das wäre doch eine recht lange Tabelle.5\nBei einer multiplen Regression mit sagen wir 10 Prädiktoren mit jeweils 100 Ausprägungen rechnet das arme R bis zum jüngsten Tag: \\(10^{100}\\).\n\n🤖 Bitte tue mir das nicht an!\n\n\n👨‍🏫 Schon gut, das können wir R nicht zumuten. Wir brauchen eine andere Lösung!\n\n\n\n6.2.4 Wir arbeiten jetzt mit Häufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle können nicht mehr “einfach mal eben” ausgerechnet werden; die Mathematik wird zu umfangreich bzw. zu komplex. Glücklicherweiße gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht. Dieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit Häufigkeiten. Praktischerweise werden wir in Kürze einen R-Golem kennenlernen, der das für uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurück. Lernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung mit Häufigkeiten (d. h. in Stichprobenform) ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen für Bayes auf Stichproben eingestellt.\n\n\nDie Bayes-Box-Methode6 ist bei größeren Datensätzen (oder größeren Modellen) zu unpraktisch. In der Praxis werden d. h.r andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein7\n\n\n6.2.5 Häufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (“R-Golems”) liefern uns die Post-Verteilung in Stichprobenform zurück. Bevor wir uns aber mit diesen R-Werkzeugen beschäftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform. Erstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. Listing 6.3.\n\n\n\nListing 6.3: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\n\n\nsamples &lt;-\n  d %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %&gt;%  # Ziehe mit Zurücklegen\n  select(p_grid)\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d. h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit Zurücklegen hält die Wahrscheinlichkeiten während des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird. Wir begnügen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht. Das Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in Auszügen) in Tabelle 6.3 dargestellt.\nWenn Sie jetzt denken: “Warum machen wir das jetzt? Brauchen wir doch gar nicht!” - Dann haben Sie Recht. Künftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\n\n\nTabelle 6.3 zeigt die ersten Zeilen der Stichproben aus der Post-Verteilung.\n\n\n\n\nTabelle 6.3: Stichproben-Post-Verteilung\n\n\n\n\n\n\n\n\n\np_grid\n\n\n\n\n0.500\n\n\n0.700\n\n\n0.800\n\n\n0.800\n\n\n0.800\n\n\n\n\n\n\n\n\n\n\n\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.5 0.7 0.8 0.8 0.8 0.5 0.4 0.6 0.3 0.6 0.6 0.7 0.7 0.8 0.7 0.6 0.8 0.6\n##  [19] 0.6 0.8 0.6 0.5 0.6 0.8 0.9 0.5 0.7 0.8 0.8 0.5 0.6 0.7 0.7 0.6 0.8 0.5\n##  [37] 0.7 0.8 0.5 0.8 0.7 0.6 0.8 0.5 0.3 0.4 0.7 0.4 0.4 0.6 0.8 0.4 0.3 0.6\n##  [55] 0.4 0.5 0.8 0.7 0.5 0.6 0.5 0.6 0.8 0.6 0.7 0.8 0.7 0.6 0.7 0.6 0.2 0.8\n##  [73] 0.6 0.7 0.7 0.6 0.4 0.4 0.6 0.4 0.7 0.6 0.8 0.6 0.6 0.6 0.6 0.7 0.7 0.6\n##  [91] 0.5 0.6 0.9 0.7 0.8 0.7 0.7 0.9 0.6 0.6\n\n\n\nSo sieht unsere “Stichproben-Bayesbox” als Balkendiagramm aus, s. Abbildung 6.2.\n\nSyntaxOutput\n\n\n\nsamples |&gt; \n  count(p_grid) |&gt; \n  ggbarplot(x = \"p_grid\", y = \"n\") \n\n\n\n\n\n\n\n\n\n\n\nAbbildung 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n\n\nAus Abbildung 6.2 können wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% für am wahrscheinlichsten hält. Aber auch kleine Anteile wie 25% sind nicht auszuschließen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie Abbildung 6.2 mit Abbildung 5.10: beide sind sehr ähnlich! Das Stichprobenziehen (Abbildung 6.2) nähert sich recht gut an die exakte Berechnung an (Abbildung 5.10).\n\n\n6.2.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die Auflösung auf \\(k=100\\) Gitterwerte (Ausprägungen) nach oben.\n\n1k &lt;- 100\n2n_success &lt;- 6\n3n_trials  &lt;- 9\n\nd_k100 &lt;-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n4                      length.out = k),\n5         prior  = 1) %&gt;%\n6  mutate(likelihood = dbinom(n_success,\n                             size = n_trials, \n                             prob = p_grid)) %&gt;% \n7  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n1\n\n\\(k=100\\) Gitterwerte\n\n2\n\n6 Treffer (Wasser)\n\n3\n\n9 Versuche\n\n4\n\nBayes-Box anlegen mit 100 Zeilen, d. h. 100 Parameterwerten\n\n5\n\nApriori indifferent: Alle Hypothesen haben die gleiche Apriori-Plausibilität\n\n6\n\nDie Likelihood ist binomialverteilt.\n\n7\n\nPost-Verteilung berechnen wie gewohnt.\n\n\n\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\nsamples_k100 &lt;-\n  d_k100 %&gt;%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\nAbbildung 6.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen Fällen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der “typische” Wert des Modells zu sein. Außerdem erkennt man, dass das Modell durchaus einige Streuung in der Schätzung des Wasseranteils bereithält. Das Modell ist sich nicht sehr sicher, könnte man sagen.\n\n\n\n\n\n\n\n\nAbbildung 6.3: Post-Verteilung mit 100 Gitterwerten, exakt vs. auf Basis von Stichproben\n\n\n\n\n\nDie Stichprobendaten nähern sich der “echten” Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt “glattere” Ränder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glätten die Verteilung.\n\n\nJetzt die Post-Verteilung noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. Abbildung 6.4.\n\n\n\n\n\n\n\n\nAbbildung 6.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schön ‘glatt’. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#die-post-verteilung-befragen",
    "href": "0600-Post.html#die-post-verteilung-befragen",
    "title": "6  Die Post befragen",
    "section": "6.3 Die Post-Verteilung befragen",
    "text": "6.3 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n📺 Die Post-Verteilung auslesen\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir können viele nützliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abbildung 6.5 schematisch illustriert.\n\n\n\n\n\n\nAbbildung 6.5: Fragen nach p vs. Fragen nach q\n\n\n\nIm linken Teildiagramm von Abbildung 6.5 fragen wir: “Wie wahrscheinlich ist ein Wasseranteil von höchstens 80%?”. Im rechten Teildiagramm fragen wir: “Welcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht überschritten?”.\n\n6.3.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groß ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt? Um diese Frage zu beantworten, zählen wir einfach, wie viele Stichproben die Bedingung erfüllen, und summieren die Wahrscheinlichkeiten dieser Stichproben. Wir zählen (count) also die Stichproben, die sich für einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, können wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) für einen Wasseranteil kleiner als 50%.\n\nBeispiel 6.2 (Was macht die Funktion count?) Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem Prüfkriterium, Wasseranteil höchstens 50%. Dann zählt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurück. \\(\\square\\)\n\n\n\nWir zählen wie oft der Wasseranteil weniger als 50% beträgt:\n\nsamples %&gt;%\n  count(p_grid &lt; .5) \n\n\n  \n\n\n\n\nMan könnte also alternativ auch schreiben:\n\nd %&gt;%\n  filter(p_grid &lt; .5) %&gt;%\n  summarise(sum = sum(post))\n\n\n  \n\n\n\n\n\n\nBeispiel 6.3 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\nWir zählen die Stichproben, die diesen Kriterien entsprechen:\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75)\n\n\n  \n\n\n\n\n🤖 Ich würde empfehlen, die Anzahl noch in Anteile umzurechnen. Die kann man dann als Wahrscheinlichkeiten auffassen.\n\n\n👨‍🏫 Das wollte ich auch gerade sagen…\n\n\nsamples %&gt;% \n  count(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n  \n\n\n\nAnteile von count() könnte man, wenn man möchte, auch filter() verwenden:\n\nsamples %&gt;% \n  filter(p_grid &gt; .5 & p_grid &lt; .75) %&gt;% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n  \n\n\n\nFertig 😄 \\(\\square\\)\n\n\nBeispiel 6.4 (Wasseranteil zwischen 90& und 100%?) Noch ein Beispiel für eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nSyntaxOutput\n\n\n\nsamples %&gt;% \n  count(p_grid &gt;= .9 & p_grid &lt;= 1) %&gt;% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\n  \n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% beträgt. \\(\\square\\)\n\n\nÜbungsaufgabe 6.2 (Wasseranteil höchstens 50%?)  \n\n👩‍🔬 Mit welcher Wahrscheinlichkeit ist der Planet höchstens zur Hälfte mit Wasser bedeckt?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsamples %&gt;% count(p_grid &lt;= .5)\n\n\n  \n\n\n\n\n\n\n\nWir können auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem “Gipfel” des Berges, s. Abbildung 6.4.\nFür unsere Stichproben-Postverteilung, samples, s. Abbildung 6.2, lässt sich der Modus so berechnen:\n\nmap_estimate(samples$p_grid)  \n\n\n  \n\n\n\nDabei steht map für Maximum Aposteriori, also das Maximum der Post-Verteilung.\n\nÜbungsaufgabe 6.3 Bei der Gelegenheit könnten wir folgende, ähnliche Fragen stellen:\n\nWas ist der mittlere Schätzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane Schätzwert (Median)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsamples %&gt;% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n  \n\n\n\n\n\n\n\n\n\n6.3.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchätzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall8.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht überschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir möchten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist9.\n\nsamples %&gt;% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n  \n\n\n\nLaut unserem Modell können wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu führen, s. Abbildung 6.4.\n\n\n\n\n\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthält, laut dem Modell?\nDafür “schneiden” wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\nsamples %&gt;% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n  \n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n\n6.3.3 Zur Erinnerung: Quantile\nBeispiel: Wie groß sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z. B. 25% zeigt die Körpergröße der 25% kleinsten Studentis an, analog für 50%, 75%, in Inches10:\n\n# speed_gender_height &lt;- read.csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n1data(\"speed_gender_height\", package = \"openintro\")\n\nheight_summary &lt;- \n  speed_gender_height %&gt;% \n2  mutate(height_cm = height*2.54) %&gt;%\n  select(height_inch = height, height_cm) %&gt;% \n3  drop_na() %&gt;%\n4  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %&gt;%\n5  group_by(Einheit) %&gt;%\n6  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n1\n\nDaten importieren\n\n2\n\nInch in Zentimeter umrechnen\n\n3\n\nZeilen mit fehlenden Werten löschen\n\n4\n\nIn die Langform pivotieren\n\n5\n\nGruppieren nach Einheit (Inch, Zentimeter)\n\n6\n\nQuantile berechnen (Q1, Q2, Q3)\n\n\n\n\n\n  \n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildung 6.6 visualisiert die Quantile und die Häufigkeitsverteilung.\n\n\n\n\n\n\n\n\nAbbildung 6.6: Größenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n\n\nÜbungsaufgabe 6.4 (Welcher Parameterwert ist der wahrscheinlich größte?) Übersetzen wir “wahrscheinlich” größte in “mit einer Wahrscheinlichkeit von 99% gibt es keinen größeren”.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(quant99 = quantile(p_grid, p = .99))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der höchste zu erwartende Wasseranteil 0.9.\n\n\n\n\n\nÜbungsaufgabe 6.5 (Welcher Parameterwert ist der wahrscheinlich kleinste?) Übersetzen wir “wahrscheinlich” kleinste in “mit einer Wahrscheinlichkeit von 99% gibt es keinen kleineren”.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .01))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 99% ist der kleinste zu erwartende Wasseranteil 0.3 – immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\nÜbungsaufgabe 6.6 (Welcher Parameterwert ist der “vermutlich” kleinste?) In der “wirklichen” Welt sind Aussagen nicht immer präzise. Sagen wir, die Chefin der Weltraumbehörde hat in einem Presse-Statement von der “vermutlichen Untergrenze” hinsichtlich des Wasseranteils gesprochen.\nÜbersetzen wir “vermutlich” kleinste in “mit einer Wahrscheinlichkeit von 90% gibt es keinen kleineren”.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsamples |&gt; \n  summarise(wahrscheinlich_kleinste = \n              quantile(p_grid, p = .1))\n\n\n  \n\n\n\nMit einer Wahrscheinlichkeit von 90% ist der kleinste zu erwartende Wasseranteil 0.5 – immer auf Basis unserer beobachteten Daten und der Vorannahmen.\n\n\n\n\n\n\n6.3.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht überschritten wird. Das können wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% (von 10000) ab (entferne sie).\nSchaue, was der größte verbleibende Wert ist.\n\n\nsamples %&gt;% \n  arrange(p_grid) %&gt;%   # sortiere\n  slice_head(n = 9000) %&gt;%  # nur die ersten 90%\n  summarise(p90 = max(p_grid))\n\n\n  \n\n\n\nDas (annähernd) gleiche Ergebnis liefert quantile():\n\nsamples %&gt;% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n  \n\n\n\n\n\n6.3.5 Visualisierung der Intervalle\n\nDefinition 6.1 (Perzentilintervall (PI)) Intervalle (Bereiche), die die “abzuschneidende” Wahrscheinlichkeitsmasse hälftig auf die beiden Ränder aufteilen, nennen wir Perzentilintervalle oder (synonym) Equal-Tails-Intervalle (ETI), s. Abb. Abbildung 6.7, rechtes Teildiagramm.11 \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Intervall der Post-Verteilung mit den unteren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\n\n\n\n\n(b) Intervall der Post-Verteilung mit den mitteleren 80% der Wahrscheinlichkeit\n\n\n\n\n\n\n\nAbbildung 6.7: Perzintilintervalle\n\n\n\nDas 10%, 20%, … 100%-Quantil12 (auf Basis von samples_k100) sind in Abbildung 6.8 illustriert.\n\n\n\n\n\n\nAbbildung 6.8: Quantile in 10%-Schritenn durch die Verteilung von samples_k100",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "href": "0600-Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "title": "6  Die Post befragen",
    "section": "6.4 Schiefe Posteriori-Verteilungen sind möglich",
    "text": "6.4 Schiefe Posteriori-Verteilungen sind möglich\nNoch einmal zum Globusversuch: Gehen wir von 3 Würfen mit 3 Mal Wasser (Treffer) aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schließen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 Würfe), s. Listing 6.4:\n\n\n\n\nListing 6.4: Schiefe Post-Verteilung in einer Bayes-Box\n\n\nd_33 &lt;- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %&gt;% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %&gt;% \n  mutate(unstand_post = likelihood * prior) %&gt;% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 &lt;- \n  d_33 %&gt;% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\n\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\n\n\n\n\n0.93\n1\n0.80\n0.80\n\n\n0.87\n1\n0.66\n0.66\n\n\n0.51\n1\n0.13\n0.13\n\n\n0.53\n1\n0.15\n0.15\n\n\n0.70\n1\n0.34\n0.34\n\n\n0.24\n1\n0.01\n0.01\n\n\n\n\n\n\n\nMit dieser “schiefen” Post-Verteilung können wir gut die Auswirkungen auf das Perzentil- und das Höchste-Dichte-Intervall anschauen.\n\n6.4.1 Perzentil-Intervall\nHier z. B. ein 50%-Perzentilintervall, s. Abb. Abbildung 6.9.\n\n\n\n\n\n\n\n\nAbbildung 6.9: Schiefe Intervalle\n\n\n\n\n\nEin Perzentilintervall (ETI, PI) kann, wenn es dumm läuft, den wahrscheinlichsten Parameterwert nicht enthalten, diesen Wert also plausiblen Wert also zurückweisen. Das ist nicht so toll.\nEin Highest-Density-Intervall (HDI13) ist schmäler als der Perzintilintervall und enthält immer den wahrscheinlichsten Parameterwert.\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z. B. so ausgeben lassen:\n\nsamples_33 %&gt;% \n  select(p_grid) %&gt;% \n  eti(ci = .5)  # Paket `easystats`\n\n\n\n\n\n  \n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.4.2 Intervalle höchster Dichte\n\nDefinition 6.2 Intervalle höchster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als das schmälste Intervall, das den gesuchten Parameter enthält (in Bezug auf ein gegebenes Modell).\n\nDer wahrscheinlichste Parameterwert (\\(1\\)) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten Ränder nicht mehr gleich groß, im Sinne von enthalten nicht (zwangsläufig) die gleiche Wahrscheinlichkeitsmasse. Bei PI ist die Wahrscheinlichkeitsmasse in diesen Rändern hingegen gleich groß.\nJe symmetrischer die Verteilung, desto näher liegen die Punktschätzer aneinander (und umgekehrt), s. Abb. Abbildung 6.10.\n\n\n\n\n\n\n\n\nAbbildung 6.10: Visualisierung der Punktschätzer bei einer schiefen Post-Verteilung\n\n\n\n\n\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen, s. Tabelle 6.4.\n\nsamples %&gt;% \n  select(p_grid) %&gt;% \n  hdi(ci = .5)  # aus dem Paket `{easystats}`\n\n\n\n\n\nTabelle 6.4: 50%-HDI für unser Globusmodell\n\n\n\n\n  \n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfläche) sich im von ca. .67 bis .78 befindet (auf Basis eines HDI).",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#fazit",
    "href": "0600-Post.html#fazit",
    "title": "6  Die Post befragen",
    "section": "6.5 Fazit",
    "text": "6.5 Fazit\n\n6.5.1 Intervalle höchster Dichte vs. Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle ähnlich\nPerzentilintervalle sind verbreiteter\nIntervalle höchster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle höchster Dichte sind die schmalsten Intervalle für eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n6.5.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datensatz samples, s. Listing 6.3. Sagen wir, wir haben 6 Treffer bei 9 Würfen erzielt.\nLageparameter: Welchen mittleren Wasseranteil kann man erwarten?\n\nsamples %&gt;% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n  \n\n\n\nStreuungsparameter: Wie unsicher sind wir in der Schätzung des Wasseranteils?\n\nsamples %&gt;% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  # Mean Absolute Deviation, Mittlerer Absolutfehler\n\n\n  \n\n\n\nAnstelle der Streuungsparameter ist es aber üblicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel für einen Parameter, einer unbekannten Größes eines Modells.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#aufgaben",
    "href": "0600-Post.html#aufgaben",
    "title": "6  Die Post befragen",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nfattails1\nfattails2\nReThink3e1-7\nWeinhaendler\nRethink3m1\nRethink3m2\nKaefer2\ngroesse2\ngroesse1\nAnteil-Apple\nKung-height\nzwielichter-dozent-bayes",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "0600-Post.html#section",
    "href": "0600-Post.html#section",
    "title": "6  Die Post befragen",
    "section": "6.7 —",
    "text": "6.7 —\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Bayes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Die Post befragen</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "1 Einführung",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#ihr-lernerfolg",
    "href": "index.html#ihr-lernerfolg",
    "title": "Start:Bayes!",
    "section": "\n1.1 Ihr Lernerfolg",
    "text": "1.1 Ihr Lernerfolg\n\n1.1.1 Lernziele\nNach diesem Kurs sollten Sie …\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden können\ngängige einschlägige Forschungsfragen in statistische Modelle übersetzen und mit R auswerten können\nkausale Forschungsfragen in statistische Modelle übersetzen und prüfen können\ndie Güte und Grenze von statistischen Modellen einschätzen können\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nKurz gesagt, warum soll ich das lernen?\nStatistische Analysen sind die Grundlage für Entscheidungen: Nehmen wir zum Beispiel an, Sie haben Sie 50 Frauen und Männer vor eine Einpark-Aufgabe gestellt (natürlich alles schön standardisiert und kontrolliert) - Wer am schnellsten ein Auto einparken kann. Das Ergebnis: Frauen können schneller einparken als Männer, im Durchschnitt. Das hätten wir also geklärt. Aber haben wir das ganz sicher geklärt? Mit welcher Sicherheit? Bekanntlich sind in dieser Welt nur Steuern und der Tod sicher; sonstige Aussagen leider nicht und damit unsere Einpark-Studie und sonstige statistische Analysen auch nicht. Ja, ich weiß, das ist jetzt ein harter Schlag für Sie… Aber die gute Nachricht ist: Wir können angeben, wie (un)sicher wir bei mit einer Aussage (“Frauen parken schneller…”) sind. Zum Beispiel könnten wir uns zu 99% oder zu 51% sicher sein - und wie sicher wir uns sind, macht schon einen Unterschied. Wenn Sie nächste Woche ei Fahri für Ihren neuen Rolls Royce anheuern, müssen Sie ja wissen, ob es besser eine Frau oder ein Mann sein soll.\nKurz gesagt: In diesem Kurs lernen Sie, wie Sie die Unsicherheit eines statistischen Ergebnisses beziffern.\nWarum ist das wichtig?\nDa fast keine Aussage auf dieser Welt 100% sicher ist, müssen wir wissen, wie sicher eine Aussage ist, wenn wir eine Entscheidung treffen wollen.\nWozu brauche ich das im Job?\nIhr Boss wird wissen wollen, wie sicher Sie sich sind, wenn Sie sagen “laut meiner Analyse sollten wir unser Werk in Ansbach/Peking/Timbuktu bauen”. Sind Sie sich zu 50%, 90% oder 99,9% sicher, dass Ihre Aussage richtig ist? Wichtige Frage im echten Leben.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es üblich, statistische Ergebnisse hinsichtlich ihrer Unsicherheit zu beziffern.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den “Top 20 job roles in increasing and decreasing demand across industries” (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 Modulüberblick\nAbbildung 1.1 gibt einen Überblick zu den Inhalten des Kurses.\n\n\n\n\n\nflowchart LR\n  subgraph Wskt[Wahrscheinlichkeit]\n    Inferenz --&gt; Ungewissheit --&gt; Verteilungen\n  end \n  subgraph Bayes\n    Globus --&gt; Post\n  end \n  subgraph Regression\n    Gauss --&gt; Einfach --&gt; Anwendung\n  end \n  subgraph Kausalität\n    Kausalstart\n  end \n  Wskt --&gt; Bayes --&gt; Regression --&gt; Kausalität\n\n\n\n\nAbbildung 1.1: Modulverlauf im Überblick. Die einezlenn Schritte entsprechen in etwa den Kapiteln dieses Buchs.\n\n\n\n\n\n1.1.4 Modulverlauf\nTabelle 1.1 gibt einen Überblick, welches Thema in welcher Woche bzw. wann behandelt wird. Pro Woche wird ein Thema behandelt.\n\n\n\n\n\n\nTipp\n\n\n\nEs ist nützlich für Sie, die Tabelle Tabelle 1.1 immer mal wieder zu konsultieren, damit sie wissen, welche Themen als nächstes behandelt werden. \\(\\square\\)\n\n\n\n\n\nTabelle 1.1: Themen des Moduls im Zeitverlauf\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nInferenz\n2.-8. Okt.\nNA\n\n\n2\nWahrscheinlichkeit\n9.-15. Okt.\nNA\n\n\n3\nVerteilungen\n16.-22. Okt.\nNA\n\n\n4\nGlobusversuch\n23.-29. Okt.\nNA\n\n\n5\nAufhol-Woche\n30.-5. Nov.\nNA\n\n\n6\nDie Post befragen\n5.-12. Nov.\nNA\n\n\n7\nGauss-Modelle\n13.-19. Nov.\nNA\n\n\nNA\nNA\n20.-26. Nov.\nBlockwoche: Kein regulärer Unterricht\n\n\n8\nLineare Modelle\n27.-3. Dez.\nNA\n\n\n9\nMetrische AV\n4.-10. Dez.\nNA\n\n\n10\nKonfundierung\n11.-17. Dez\nNA\n\n\n11\nKausalatome\n18.-24. Dez.\nNA\n\n\nNA\nNA\nNA\nJahreswechsel: Kein Unterricht\n\n\n12\nAbschluss\n8.-14. Jan. 24\nNA\n\n\n\n\n\n\n\n\n\n\n1.1.5 Voraussetzungen\nFür dieses Kurs wird folgendes Wissen vorausgesetzt:\n\ngrundlegende Kenntnis im Umgang mit R, möglichst auch mit dem tidyverse\n\ngrundlegende Kenntnis der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\nDieses Wissen wird z. B. im Online-Buch “Statistik1” vermittelt. Alle Inhalte daraus werden in diesem Kurs benötigt.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#lernhilfen",
    "href": "index.html#lernhilfen",
    "title": "Start:Bayes!",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nHier finden Sie einen Überblick zu Lernhilfen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Start:Bayes!",
    "section": "\n1.3 Software",
    "text": "1.3 Software\nSie benötigen R, RStudio und einige R-Pakete insbesondere rstanarm für diesen Kurs.\nHier finden Sie Installationshinweise.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Start:Bayes!",
    "section": "\n1.4 Hinweise",
    "text": "1.4 Hinweise\n\n\n\n\n\n\nHinweis\n\n\n\nAlle formalen Hinweise (Prüfung, Unterrichtsorganisation, …) sind auf der Seite https://hinweisbuch.netlify.app/ zu finden. \\(\\square\\)\n\n\n\n📺 Playlist QM2)\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine Prüfung in diesem Modul ist jedes Semester möglich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#tutorium",
    "href": "index.html#tutorium",
    "title": "Start:Bayes!",
    "section": "\n1.5 Tutorium",
    "text": "1.5 Tutorium\nFür dieses Modul wird ggf. ein Tutorium angeboten.\nDer Besuch des Tutoriums ist zu empfehlen. Arbeiten Sie auch das Materials auf der Webseite des Tutoriums durch.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#prüfung",
    "href": "index.html#prüfung",
    "title": "Start:Bayes!",
    "section": "\n1.6 Prüfung",
    "text": "1.6 Prüfung\nDas aktuelle Prüfungsformat ist: Open-Book-Prüfung.\n\nAllgemeine Prüfungshinweise\nPrüfungsformat: Open-Book-Prüfung\nHinweise zu quantitativen Prüfungen\nPrüfungsvorbereitung\n\nIn Kapitel 13 finden sich weitere Hinweise auch mit Blick zu Aufgabensammlungen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Start:Bayes!",
    "section": "\n1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2023). Start:Bayes!. https://start-bayes.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren können:\n@book{sauer_startbayes,\n    title = {Start:Bayes},\n    rights = {CC-BY-NC},\n    url = {https://start-bayes.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2023},\n}\nHier ist die DOI:\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Start:Bayes!",
    "section": "\n1.8 Zum Autor",
    "text": "1.8 Zum Autor\nNähere Hinweise zum Autor, Sebastian Sauer, finden Sie hier.\n\n\n\n\nForum, World Economic. 2020. „The Future of Jobs Report 2020“. CH-1223 Cologny/Geneva Switzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#lernsteuerung",
    "href": "1150-konfundierung.html#lernsteuerung",
    "title": "11  Konfundierung",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n11.1.2 R-Pakete\nFür dieses Kapitel benötigen Sie folgende R-Pakete:\n\nlibrary(dagitty)  # DAGs zeichnen\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n11.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. Tabelle 11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie können ihn entweder über die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber über das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kürzerer Name, das ist leichter zu tippen\n\n\n11.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerklären, was eine Konfundierung ist\nDAGs lesen und zeichen\nKonfundierung in einem DAG erkennen\n\n11.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ähnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).\n\n11.1.6 Überblick\nIn diesem Kapitel steigen wir ein in das Themengebiet Kausalanalyse (oder synonym Kausalinferenz). Wir beschäftigen uns also mit der für die Wissenschaft (und den Rest des Universums) zentralen Frage, was die Ursache eines Phänomens ist. In diesem ersten Kapitel zu dem Thema geht es um einen häufigen Fall von “Scheinkorrelation”, also eines Zusammenhangs zwischen UV und AV, der aber gar kein echter kausaler ist, sondern nur Schein. Bei diesem Scheinzusammenhang handelt es sich um die Konfundierung. Im nächsten Kapitel schauen wir uns die verbleibenden Grundbausteine der Kausalinferenz an.\n\n11.1.7 Einstieg\n\n11.1.8 Von Störchen und Babies\nKennen Sie die Geschichte von Störchen und Babies? Ich meine nicht die aus dem Biologieunterricht in der fünften Klasse, sondern in einem statistischen Zusammenhang. Was war da noch mal die Moral von der Geschichte?1 \\(\\square\\)\n\n11.1.9 Erlaubt eine Regressionsanalyse Kausalschlüsse?\nFindet man in einer Regressionsanalyse einen “Effekt”, also ein Regressionsgewicht ungleich Null, heißt das dann, dass die UV die Ursache der AV ist?2 Erklären Sie diesen Sachverhalt genauer. \\(\\square\\)",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "href": "1150-konfundierung.html#statistik-was-soll-ich-tun",
    "title": "11  Konfundierung",
    "section": "\n11.2 Statistik, was soll ich tun?",
    "text": "11.2 Statistik, was soll ich tun?\n\n11.2.1 Studie A: Östrogen\n\n11.2.1.1 Medikament einnehmen?\nMit Blick auf Tabelle 11.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\nTabelle 11.1: Daten zur Studie A\n\n\n\n\n\n\nGruppe\nMit Medikament\nOhne Medikament\n\n\n\nMänner\n81/87 überlebt (93%)\n234/270 überlebt (87%)\n\n\nFrauen\n192/263 überlebt (73%)\n55/80 überlebt (69%)\n\n\nGesamt\n273/350 überlebt (78%)\n289/350 überlebt (83%)\n\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualität (Beobachtungsstudie). Bei Männern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und Männern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt (Pearl, Glymour, und Jewell 2016)?\n\n11.2.1.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Östrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Östrogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in Abbildung 11.1 dargestellt.\n\n\n\n\n\n\n\nAbbildung 11.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender über drug) auf recovery\n\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d. h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg. Achtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige Lösung. Stratifizieren bedeutet, den Gesamtdatensatz in Gruppen oder “Schichten” (“Strata”).\n\n\n\n11.2.2 Studie B: Blutdruck\n\n11.2.2.1 Medikament einnehmen?\nMit Blick auf Tabelle 11.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\nTabelle 11.2: Daten zur Wirksamkeit eines Medikaments (Studie B)\n\n\n\n\n\n\nGruppe\nOhne Medikament\nMit Medikament\n\n\n\ngeringer Blutdruck\n81/87 überlebt (93%)\n234/270 überlebt (87%)\n\n\nhoher Blutdruck\n192/263 überlebt (73%)\n55/80 überlebt (69%)\n\n\nGesamt\n273/350 überlebt (78%)\n289/350 überlebt (83%)\n\n\n\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualität (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe über beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt (Pearl, Glymour, und Jewell 2016)?\n\n11.2.2.2 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schädlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell von Studie B ist in Abbildung 11.2 dargestellt.\n\n\n\n\n\n\n\nAbbildung 11.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schädlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nützlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wäre falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wäre.\n\n\n\n11.2.3 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs Abbildung 11.1 und Abbildung 11.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich. Aber: Die Daten sind identisch.\nKausale Interpretation - und damit Entscheidungen für Handlungen - war nur möglich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n11.2.4 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht für Kausalschlüsse. 🧟\nStatistik plus Theorie erlaubt Kausalschlüsse. 📚➕📊 🟰 🤩\n\n\n\n\n\n\nWichtig\n\n\n\nFür Entscheidungen (“Was soll ich tun?”) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n11.2.5 Vertiefung3\n\n\n11.2.5.1 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ärzte tendieren zu Behandlung A bei großen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ärzte zu Behandlung B.\nSollte ein Patient, der nicht weiß, ob sein Nierenstein groß oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach Steingröße) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wählt?\nDie Größe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (“Kette”) von Größe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. Darüber hinaus gibt es noch einen Einfluss von Größe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in Abbildung 11.3 dargestellt; Abbildung 11.4 visualisiert alternativ. Beide Varianten zeigen das Gleiche. Sie können sich einen aussuchen. Hier sind beide Varianten gezeigt, damit Sie wissen, dass verschiedene Darstellungsformen möglich sind.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schätzen möchte? Oder lieber nicht kontrollieren?\n\n\nDAG links-rechts\nDAG oben-unten\n\n\n\n\n\n\n\n\n\n\nAbbildung 11.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 11.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. Würde man nicht size kontrollieren, bekäme man den “vermengten” Effekt von size und treatment, also keine (belastbare) Aussage über den Effekt der Behandlung.\n\n11.2.5.2 Mehr Beispiele\n\nBeispiel 11.1 Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhöhen, wenn du heiratest. \\(\\square\\)\n\n\nBeispiel 11.2 Studien zeigen, dass Leute, die sich beeilen, zu spät zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spät zu deiner Besprechung. \\(\\square\\)\n\n\n11.2.6 Zwischenfazit\nBei Beobachtungsstudien ist aus den Daten alleine nicht herauszulesen, ob eine Intervention wirksam ist, ob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt. Damit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist. Nur Kenntnis des Kausalmodells zusätzlich zu den Daten erlaubt, eine Entscheidung sinnvoll zu treffen.\nBei experimentellen Daten ist die Kenntnis des Kausalmodells nicht nötig (wenn das Experiment handwerklich gut gestaltet ist): Das Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen dafür, dass es keine Konfundierung gibt.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#konfundierung",
    "href": "1150-konfundierung.html#konfundierung",
    "title": "11  Konfundierung",
    "section": "\n11.3 Konfundierung",
    "text": "11.3 Konfundierung\n\n11.3.1 Die Geschichte von Angie und Don\n\n\n\n🧑\n\nDon, Immobilienmogul, Auftraggeber\n\n\n👩\n\nAngie, Data Scientistin.\n\n\n🧞\n\nWolfie, Post-Nerd, kommt in dieser Geschichte aber nicht vor\n\n\n📺 Don und Angie\n\n11.3.2 Datensatz ‘Hauspreise im Saratoga County’\nImportieren Sie den Datensatz SaratogaHouses, s. Kapitel 11.1.3.\n\n\n\nTabelle 11.3: Saratoga-County-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n11.3.3 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\n“Finden Sie den Wert meiner Immobilie heraus! Die Immobilie muss viel wert sein!”\n\n🧑 Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich.\n\n👩 🔬 Das ist Angie, Data Scientistin.\n\n11.3.4 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\n“Hey Don! Mehr Zimmer, mehr Kohle!” 👩 🔬\n\nModell 1 (m1) modelliert den Hauspreis als Funktion der Zimmerzahl, s. Abbildung 11.5.\n\n\n\n\n\n\n\nAbbildung 11.5: Modell m1\n\n\n\n\n\n“Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.”\n\n👩\n\nZu wenig! 🤬\n\n🧑\nBerechnen wir das Modell m1; der Punktschätzer des Parameters bedroom steht in Tabelle 11.4.\n\nm1 &lt;- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n\n\n\n\nTabelle 11.4: Parameter für m1\n\n\n\n  \n\n\n\n\n\n\npoint_estimates(modell) gibt die Punktschätzer der Parameter eines Modells zurück, aber nicht die Schätzbereiche. Möchten Sie beides, können Sie die Funktion parameters(modell) nutzen.4\nMit estimate_predictions können wir Vorhersagen berechnen (bzw. schätzen; die Vorhersagen sind ja mit Ungewissheit verbunden, d. h.r ist “schätzen” vielleicht das treffendere Wort). Tabelle 11.5 zeigt den laut m1 vorhergesagten Hauspreis für ein Haus mit 2 Zimmern.\n\ndons_house &lt;- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\nTabelle 11.5: Vorhersage des Hauspreises für ein Haus mit 2 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n2.00\n1.56e+05\n91070.04\n(-20656.00, 3.36e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.5 Don hat eine Idee\n\n“Ich bau eine Mauer! Genial! An die Arbeit, Angie!” 🧑\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\n“Das ist keine gute Idee, Don.”\n\n👩\nBerechnen wir die Vorhersagen für Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. Tabelle 11.6.5\n\ndons_new_house &lt;- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\npredict(m1, newdata = dons_new_house)\n\n\n\n\nTabelle 11.6: Vorhergesagter Hauspreis laut m1 für ein Haus mit 4 Zimmern\n\n\n\nModel-based Prediction\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.54e+05\n89308.41\n(78344.42, 4.32e+05)\n\n\nVariable predicted: price\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1, s. Abbildung 11.5.\n\n“Volltreffer! Jetzt verdien ich 100 Tausend mehr! 🤑 Ich bin der Größte!” 🧑\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: “4e+05” ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n11.3.6 R-Funktionen, um Beobachtungen vorhersagen\npredict(m1, dons_new_house) oder point_estimate(m1, dons_new_house) sagt einen einzelnen Wert vorher (den sog. Punktschätzer der Vorhersage).6 Ein Intervall wird nicht ausgegeben.\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berücksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im “Strukturmodell”: Wenn also z. B. in unserem Modell ein wichtiger Prädiktor fehlt, so kann die Vorhersagen nicht präzise sein. Fehler im Strukturmodell schlagen sich in breiten Schätzintervallen (bedingt durch ein großes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berücksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten)\n\nDie Schätzbereiche sind in dem Fall deutlich kleiner, s. Tabelle 11.7.\n\nestimate_expectation(m1, dons_new_house)\n\n\n\n\nTabelle 11.7: Ungewissheit für die Parameter, also die Regressionsgerade, nicht die Beobachtungen\n\n\n\nModel-based Expectation\n\nbedrooms\nPredicted\nSE\n95% CI\n\n\n4.00\n2.53e+05\n3168.87\n(2.47e+05, 2.59e+05)\n\n\nVariable predicted: price\n\n\n\n\n\n\n11.3.7 Modell 2\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea. Tabelle 11.8 gibt den Punktschätzer für die Koeffizienten wider.\n\nm2 &lt;- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n\n\n\n\nTabelle 11.8: Parameter (Punktschätzer, keine Schätzung der Ungewissheit) von m2\n\n\n\nPoint Estimate\n\nParameter\nMedian\n\n\n\n(Intercept)\n36533.15\n\n\nbedrooms\n-14138.79\n\n\nlivingArea\n125.35\n\n\n\n\n\n\n\n\nWas sind die Vorhersagen des Modell? Tabelle 11.9 gibt Aufschluss für den laut m2 vorhersagten Kaufpreis eines Hauses mit 4 Zimmern und 1200 Quadratfuß Wohnfläche; Tabelle 11.10 gibt die Schätzung (laut m2) für den Preis eines Hauses mit 2 Zimmern (und der gleichen Wohnfläche). Die Vorhersage erhält man mit dem Befehl predict():\n\npredict(m2, newdata = data.frame(bedrooms = 4, livingArea = 1200))\n##        1 \n## 130463.8\n\n\n\n\nTabelle 11.9: Vorhersage von m2 für ein Haus mit 4 Zimmern und 1200 Einheiten Wohnfläche\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTabelle 11.10: Vorhersage von m2 für ein Haus mit 2 Zimmern und 1200 Einheiten Wohnfläche\n\n\n\n  \n\n\n\n\n\n\nAndere, aber ähnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer gemittelt über die verschiedenen Größen von livingArea? Stellen Sie sich alle Häuser mit 4 Zimmern vor (also mit verschiedenen Wohnflächen). Wir möchten nur wissen, was so ein Haus “im Mittel” kostet. Wir möchten also die Mittelwerte pro bedroom schätzen, gemittelt für jeden Wert von bedroom über livingArea. Die Ergebnisse stehen in Tabelle 11.11 und sind in Abbildung 11.6 visualisiert.\n\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\nTabelle 11.11: Vorhersagen des Preises von Häusern mit verschiedener Zimmerzahl gemittelt über die verschiedenen Werte der Wohnfläche; basierend auf m2.\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 11.6: Hauspreis als Funktion der Zimmerzahl, laut m2\n\n\n\n\n\n“Die Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!”\n\n👩\n\n“Verringert!? Weniger Geld?! Oh nein!”\n\n🧑\n\n11.3.8 Die Zimmerzahl ist negativ mit dem Preis korreliert\n… wenn man die Wohnfläche (Quadratmeter) kontrolliert, s. Abbildung 11.7.\n\n“Ne-Ga-Tiv!”\n\n👩\n\n\n\n\n\nAbbildung 11.7: Hauspreis stratifizieren\n\n\nQuellcode\n\n\n\n\n\n\nHinweis\n\n\n\nAussagen, gleich ob sie statistischer, wissenshaftlicher oder sonstiger Couleur sind, können immer nur dann richtig sein, wenn ihre Annahmen richtig sind. Behauptet etwa ein Modell, dass der Wert einer Immobilie steigt, wenn man mehr Zimmer hat, so ist das kein Naturgesetz, sondern eine Aussage, die nur richtig sein kann, wenn das zugrundeliegende Modell richtig ist. \\(\\square\\)\n\n\n\n11.3.9 Kontrollieren von Variablen\n💡 Durch das Aufnehmen von Prädiktoren in die multiple Regression werden die Prädiktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen Prädiktors mit \\(y\\), wenn man den (oder die) anderen Prädiktoren statistisch konstant hält.\nMan nennt die Koeffizienten einer multiplen Regression d. h.r auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom “Netto-Effekt” eines Prädiktors, oder davon, dass ein Prädiktor “bereinigt” wurde vom (linearen) Einfluss der anderen Prädiktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Prädiktors \\(x_1\\) auf \\(y\\) anzeigen unabhängig vom Effekt der anderen Prädiktoren, \\(x_2,x_3,...\\) auf \\(y\\).\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Prädiktors \\(x_1\\) wird für jede Ausprägung (Gruppe) des Prädiktors \\(x_2\\) berechnet.\n\n\n\n\n\n\nWichtig\n\n\n\nDas Hinzufügen von Prädiktoren kann die Gewichte der übrigen Prädiktoren ändern. \\(\\square\\)\n\n\n\nAber welche und wie viele Prädiktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\n🧑\n\nLeider kann die Statistik keine Antwort darauf geben.\n\n👩\n\nWozu ist sie dann gut?!\n\n🧑\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erklärung der Ursachen heranzuziehen: Die Regressionskoeffizienten können sich wild ändern, wenn man Prädiktoren hinzufügt oder weglässt. Es können sich sogar die Vorzeichen der Regressionsgewichte ändern; in dem Fall spricht man von einem Simpson-Paradox.\n\n\n\n11.3.10 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, we’d like to know wheter an effect is “real” or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical “tests” on its way to acceptance.\n\n– McElreath (2020), S. 139\n\n11.3.11 Kausalmodell für Konfundierung, km1\n\nDas Kausalmodell km1 ist in Abbildung 11.8 dargestellt; vgl. Abbildung 11.7.\n\n\n\n\n\n\n\nAbbildung 11.8: Kausalmodell km1 - Eine Erklärung (von mehreren) für m1 bzw. die Daten, die m1 zugrunde liegen\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms. Eine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht. d_connected heißt, dass die betreffenden Variablen “verbunden” sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss fließt 🌊. d_separated heißt, dass sie nicht d_connected sind.\n\n11.3.12 m2 kontrolliert die Konfundierungsvariable livingArea\n\n\nBeispiel 11.3 In Abbildung 11.8 ist living area eine Konfundierungsvariable für den Zusammenhang von bedrooms und price. \\(\\square\\)\n\n\nDefinition 11.1 (Konfundierungsvariable) Eine Konfundierungsvariable (Konfundierer) ist eine Variable, die den Zusammenhang zwischen UV und AV verzerrt, wenn sie nicht kontrolliert wird (vanderweele_definition_2013?). \\(\\square\\)\n\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloß?! Oh jeh!\n\n🧑\n\nWir müssen die Konfundierungsvariable kontrollieren.\n\n👩\nAbbildung 11.9 zeigt, dass bedrooms und price unkorreliert werden (d_separated), wenn man living area kontrolliert.\n\n\n\n\n\n\n\nAbbildung 11.9: Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\n\n\n\n\nDurch das Kontrollieren (“adjustieren”), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separated.\n\nDefinition 11.2 (Blockieren) Das Kontrollieren eines Konfundierers (wie living_area) “blockt” den betreffenden Pfad, führt also dazu, dass über diesen Pfad keine Assoziation (z. B. Korrelation) zwischwen UV (bedrooms) und AV (price) mehr vorhanden ist. UV und AV sind dann d_separated (“getrennt”). \\(\\square\\)\n\n\n11.3.13 Konfundierer kontrollieren\nGehen wir in diesem Abschnitt davon aus, dass km1 richtig ist.\nOhne Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x, Abbildung 11.10, links: Es wird (fälschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation. Mit Kontrollieren der Konfundierungsvariablen: Regressionsmodell y ~ x + group, Abbildung 11.10, rechts.\n\n\n\n\n\n\n\n\n\n(a) Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\n\n\n\n\n\n\n\n\n\n(b) Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\n\n\n\n\n\n\nAbbildung 11.10: Konfundierung von y und x!\n\n\nAbbildung 11.10, rechts, zeigt korrekt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird. Außerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable group durch Aufnahme als Prädiktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\nWichtig\n\n\n\nKontrollieren Sie Konfundierer. \\(\\square\\)\n\n\n\n11.3.14 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\nLaut km1 dürfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert, wie in Abbildung 11.8 dargestellt. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n11.3.15 Kausalmodell 2, km2\n\nUnser Modell m2 sagt uns, dass beide Prädiktoren jeweils einen eigenen Beitrag zur Erklärung der AV haben.\nDaher könnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei Kausaleinflüsse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) über den Mediator (b) zur AV (p) auch Mediation, s. Abbildung 11.11.\n\n\n\n\n\n\n\nAbbildung 11.11: Der Effekt von livingArea wird über den Mediator bedrooms auf price vermittelt.\n\n\n\n\n\n11.3.16 Dons Kausalmodell, km3\n\nSo sieht Dons Kausalmodell aus, s. Abbildung 11.12.\n\n\n\n\n\n\n\nAbbildung 11.12: Dons Kausalmodell\n\n\n\n\n\n“Ich glaube aber an mein Kausalmodell. Mein Kausalmodell ist das größte! Alle anderen Kausalmodelle sind ein Disaster!”\n\n🧑\n\n\n“Don, nach deinem Kausalmodell müssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.”\n\n🧑\nRechne doch selber die Korrelation aus, Don:\n\n“Äh, wie ging das nochmal?”\n\n🧑\nSo könntest du das rechnen, Don: correlation(d, select = c(\"bedrooms\", \"livingArea\")). Oder z. B. so:\n\ndons_r &lt;- d %&gt;% \n  summarise(cor(bedrooms, livingArea))\n\nDie Korrelation liegt also bei 0.66\n\n“Bitte, gerne hab ich dir geholfen, Don.”\n\n👩\n\n11.3.17 Unabhängigkeiten laut der Kausalmodelle\nkm1: b: bedrooms, p: price, a area (living area), s. Abbildung 11.8.\nDas Kausalmodell km1 behauptet: \\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhängig von price, wenn man livingArea kontrolliert.\nKontrollieren einer Variable \\(Z\\) erreicht man auf einfache Art, indem man sie in zusätzlich zur vermuteten Ursache \\(X\\) in die Regressionsgleichung mit aufnimmt, also y ~ x + z.\nAber diese behauptete Unabhängigkeit findet sich nicht in den Daten wieder, s. Tabelle 11.8. Also: ⛈️ Passt nicht zu den Daten!\nkm2 b: bedrooms, p: price, a area (living area), s. Abbildung 11.11.\nDas Kausalmodell km2 postuliert keine Unabhängigkeiten: Laut km2sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n\n\n\n\n\nHinweis\n\n\n\nEin Modell, in dem alle Variablen miteinander korreliert sind, nennt man auch satuiert oder saturiertes Modell. So ein Modell ist empirisch schwach. Denn: Behauptet ein Modell, dass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 beträgt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). So ein Modell ist wissenschaftlich wenig wert. Das ist so ähnlich wie ein Modell, das voraussagt, dass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein, so werden wir nicht gerade beeindruckt sein. 🥱\n\n\nFazit: km2 passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\nkm3: b: bedrooms, p: price, a area (living area), s. Abbildung 11.12.\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhängig von livingArea (a)\n⛈️ km3 passt nicht zu den Daten/zum Modell!",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "href": "1150-konfundierung.html#dags-directed-acyclic-graphs",
    "title": "11  Konfundierung",
    "section": "\n11.4 DAGs: Directed Acyclic Graphs",
    "text": "11.4 DAGs: Directed Acyclic Graphs\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z. B. Abbildung 11.12.\n\nDefinition 11.3 (DAG) DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen. Ein Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden. DAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung). DAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurückführen. \\(\\square\\)\n\n\nDefinition 11.4 (Pfad) Ein Pfad ist ein Weg durch den DAG, von Knoten zu Knoten über die Kanten, unabhängig von der Pfeilrichtung. \\(\\square\\)\n\nDer DAG von km1 ist in Abbildung 11.8 zu sehen.\n\n11.4.1 Leider passen potenziell viele DAGs zu einer Datenlage\nAuf Basis der in Dons Modell dargestellten (Un-)Abhängigkeiten der Variablen sind noch weitere Kausalmodelle möglich.\nIn Abbildung 11.13 sind diesen weiteren, möglichen Kausalmodelle für Dons Modell dargestellt. Dabei sind folgende Abkürzungen verwendet: b: bedrooms, p: price, a area (living area).\nJa, der Job der Wissenschaft ist kein Zuckerschlecken. Aber wenn es einfach wäre, die Kausalstruktur der Phänomene zu entdecken, wären sie längst erkannt, und alle Probleme der Menschheit gelöst.\n\n\n\n\n\n\n\nAbbildung 11.13: Kausalmodelle, die potenziell geeignet sind für Dons Fragestellung\n\n\n\n\nAlle diese DAgs in Abbildung 11.8 haben die gleichen Implikationen hinsichtlich der (Un-)Abhängigkeiten zwischen der Variablen. Wir können also leider empirisch nicht bestimmen, welcher der DAGs der richtige ist. Um den richtigen DAG zu identifizieren, bräuchten wir z. B. einen reichhaltigeren DAG, also mit mehr Variablen.\n\n11.4.2 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (hochtrabend) als “Kausation” bezeichnen.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiß man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt (McElreath 2020). \\(\\square\\)\n\n\n\nDefinition 11.5 (Kausale Abhängigkeit) Ist \\(X\\) die Ursache von \\(Y\\), so hängt \\(Y\\) von \\(X\\) ab: \\(Y\\) ist (kausal) abhängig von \\(X\\). \\(\\square\\)\n\nViele Menschen denken - fälschlich - dass Korrelation Kausation bedeuten muss, s. Abbildung 11.14.\n\n\n\n\n\n\n\nAbbildung 11.14: xkcd zum Thema Kausation\n\n\n\n\nQuelle und Erklärung\n\nBeispiel 11.4 (Der Schoki-Dag) Der “Schoki-DAG” in Abbildung 11.15 zeigt den DAG für das Schokoloaden-Nobelpreis-Modell. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 11.15: Macht Schokolade Nobelpreise?",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#fazit",
    "href": "1150-konfundierung.html#fazit",
    "title": "11  Konfundierung",
    "section": "\n11.5 Fazit",
    "text": "11.5 Fazit\n\n11.5.1 Zusammenfassung\nSind zwei Variablen korreliert (abhängig, assoziiert), so kann es dafür zwei Gründe geben:\n\nKausaler (“echter”) Zusammenhang\nNichtkausaler Zusammenhang (“Scheinkorrelation”)\n\nMan ist daran interessiert, echten (also kausalen) Zusammenhang aufzudecken7 und Scheinkorrelation auszuschließen.\nEine von zwei möglichen Ursachen einer Scheinkorrelation ist Konfundierung.8\nKonfundierung kann man aufdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z. B. indem man ihn als Prädiktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so löst sich der Scheinzusammenhang nach dem Adjustieren auf.\nLöst sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenhänge nach Adjustieren um, so spricht man einem Simpson-Paradox.\nDie Daten alleine können nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nötig, um DAGs auszuschließen.\n\n11.5.2 Ausstieg\n\nBeispiel 11.5 (Schoki macht Nobelpreis!?) Eine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen der Höhe des Schokoladenkonsums eines Landes und der Anzahl der Nobelpreise eines Landes (Messerli 2012), s. Abbildung 11.16.\n\n\n\n\n\n\n\nAbbildung 11.16: Je mehr Schoki, desto mehr Nobelpreise\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. Um Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen, muss man die Kausalmodelle überprüfen, so wie wir das hier tun.\n\n\n\n\n11.5.3 Vertiefung\nEs gibt viel Literatur zu dem Thema Kausalinferenz. Ein Artikel, der einen vertieften Einblick in das Thema Konfundierung liefert z. B. (tennant_use_2020?) oder (suttorp_graphical_2015?). Allerdings sollte man neben Konfundierung noch die drei anderen “Atome” der Kausalinferenz - Kollision, Mediation (und Nachfahre) - kennen, um gängige Fragen der Kausalinferenz bearbeiten zu können.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#aufgaben",
    "href": "1150-konfundierung.html#aufgaben",
    "title": "11  Konfundierung",
    "section": "\n11.6 Aufgaben",
    "text": "11.6 Aufgaben\n\nSammlung “kausal”",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1150-konfundierung.html#section",
    "href": "1150-konfundierung.html#section",
    "title": "11  Konfundierung",
    "section": "\n11.7 —",
    "text": "11.7 —\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. „Chocolate Consumption, Cognitive Function, and Nobel Laureates“. New England Journal of Medicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. „Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data“. Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Konfundierung</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#lernsteuerung",
    "href": "1180-kausalatome.html#lernsteuerung",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Position im Modulverlauf\nAbbildung 1.1 gibt einen Überblick zum aktuellen Standort im Modulverlauf.\n\n12.1.2 R-Pakete\nFür dieses Kapitel benötigen Sie folgende R-Pakete:\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n12.1.3 Daten\nWir nutzen den Datensatz Saratoga County; s. Tabelle 11.3. Hier gibt es eine Beschreibung des Datensatzes.\n Download \nSie können ihn entweder über die Webseite herunterladen:\n\nSaratogaHouses_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\nd &lt;- read.csv(SaratogaHouses_path)\n\nOder aber über das Paket mosaic importieren:\n\ndata(\"SaratogaHouses\", package = \"mosaicData\")\nd &lt;- SaratogaHouses  # kürzerer Name, das ist leichter zu tippen\n\n\n12.1.4 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerklären, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\nerklären, warum ein statistisches Modell ohne Kausalmodell zumeist keine Kausalaussagen treffen kann\ndie “Atome” der Kausalität eines DAGs benennen\n“kausale Hintertüren” schließen\n\n12.1.5 Begleitliteratur\nDieses Kapitel vermittelt die Grundlagen der Kausalinferenz mittels graphischer Modelle. Ähnliche Darstellungen wie in diesem Kapitel findet sich bei Rohrer (2018).",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#kollision",
    "href": "1180-kausalatome.html#kollision",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.2 Kollision",
    "text": "12.2 Kollision\n📺 Kollision\n\n12.2.1 Kein Zusammenhang von Intelligenz und Schönheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und Schönheit (looks), wie Abbildung 12.1 illustriert. Für geringe Intelligenzwerte gibt es eine breites Spektrum von Schönheitswerten und für hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\n\n\nAbbildung 12.1: Kein Zusammenhang von Intelligenz und Schönheit in den Daten\n\n\n\n\n\n12.2.2 Aber Ihre Dates sind entweder schlau oder schön\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schön sind oder schlau - aber seltens beides gleichzeitig (schade), s. Abbildung 12.2.\n\n\n\n\n\n\n\nAbbildung 12.2: Ihre Datingpartner sind komischerweise entweder schlau oder schön (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?\n\n12.2.3 DAG zur Rettung\n🦹 🦸\nDer DAG in Abbildung 12.3 bietet eine rettende Erklärung.\n\n\n\n\n\n\n\nAbbildung 12.3: Date als gemeinsame Wirkung von Schönheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Schönheit und Intelligenz.\n\n\n\n\nEine ähnliche Visualisierung des gleichen Sachverhalts zeigt Abbildung 12.4.\n\n\n\n\n\n\n\nAbbildung 12.4: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n12.2.4 Was ist eine Kollision?\n\nDefinition 12.1 (Kollision) Als Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen) (Pearl, Glymour, und Jewell 2016, p. 40). \\(\\square\\)\n\nKontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. Abbildung 12.3, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche Prädiktoren einer Regression hinzufügen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n\n\n\n\nTipp\n\n\n\n🙅‍♀️ Kontrollieren Sie keine Kollisionsvariablen. \\(\\square\\)\n\n\n\n12.2.5 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchöne Menschen 🪞\nReiche Menschen 🤑\n\nSehen wir davon aus, dass Schönheit und Reichtum unabhängig voneinander sind.\n\nÜbungsaufgabe 12.1 Wenn ich Ihnen sage, dass Don nicht schön ist, aber in der Glitzer häufig auftaucht, was lernen wir dann über seine finanzielle Situation?1 \\(\\square\\)\n\n\n“Ich bin schön, unglaublich schön, und groß, großartig, tolle Gene!!!” 🧑\n\n\n12.2.6 Noch ein einfaches Beispiel zur Kollision\n\n“So langsam check ich’s!” 🧑2\n\nSei Z = X + Y, wobei X und Y unabhängig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts über Y, da die beiden Variablen unabhängig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhängig, gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).3\n\n12.2.7 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildung 12.3 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursachen.\nKontrollieren kann z. B. bedeuten:\n\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\n\n\nKontrollieren mit Regression: Durch Aufnahme von date als Prädiktor in eine Regression zusätzlich zu looks mit talent als Prädikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (“Fluss”) von Looks über date nach Talent ist blockiert.\nKontrolliert man date, so öffnet sich der Pfad Looks -&gt; date -&gt; talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr “blockiert”, die Korrelation kann “fließen” - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n12.2.8 IQ, Fleiss und Eignung fürs Studium\nSagen wir, über die Eignung für ein Studium würden nur (die individuellen Ausprägungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in Abbildung 12.5.\n\n\n\n\n\n\n\nAbbildung 12.5: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fürs Studium) sei definiert als die Summe von iq und fleiss, plus etwas Glück, s. Listing 12.1.\n\n\n\nListing 12.1: Eignung ist die Summe von Fleiss und Intelligenz, plus ein Quentchen Glück\n\nset.seed(42)  # Reproduzierbarkeit\nN &lt;- 1e03  \n\nd_eignung &lt;-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung &gt; 0, 1, 0) \n  )\n\n\n\n\nLaut unserem Modell setzt sich Eignung zur Hälfte aus Intelligenz und zur Hälfte aus Fleiss zusammen, plus etwas Glück.\n\n12.2.9 Schlagzeile “Fleiß macht blöd!”\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Fleiß (f) bei Studentis (s). Ergebnis: Ein negativer Zusammenhang!?\nBerechnen wir das “Eignungsmodell”, aber nur mit Studis (studium == 1, also ohne Nicht-Studis), s. Tabelle 12.1.\n\nm_eignung &lt;-\n  stan_glm(iq ~ fleiss, data = d_eignung %&gt;%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\nTabelle 12.1: Zum Zusammenhang von Fleiss und Talent\n\n\n\nHighest Density Interval\n\nParameter\n95% HDI\n\n\n\n(Intercept)\n[ 0.70, 0.86]\n\n\nfleiss\n[-0.53, -0.36]\n\n\n\n\n\n\n\n\nAbbildung 12.6 zeigt das Modell und die Daten.\n\n\n\n\n\n\n\nAbbildung 12.6: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhängig von Fleiß in unseren Daten, sondern abhängig. Nichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde über Zusammenhänge auf und interpretieren die Zusammenhänge – oft vorschnell – als kausal.4\n\n12.2.10 Kollisionsverzerrung nur bei Stratifizierung\n\nDefinition 12.2 (Stratifizieren) Durch Stratifizieren wird eine Stichprobe in (homogene) Untergruppen unterteilt (sog. Strata). \\(\\square\\)\n\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. Abbildung 12.7.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\n\n\nAbbildung 12.7: Stratifizierung und Scheinkorrelation. A: Keine Stratifizierung und keine Scheinkorrelation. B: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nützen.\nNur Kenntnis des DAGs verrät die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten Prädiktor auf, so “kontrolliert” man diese Variable. Das Regressiongewicht des ersten Prädiktors wird “bereinigt” um den Einfluss des zweiten Prädiktors; insofern ist der zweite Prädiktor dann “kontrolliert”.\n\n\n\n12.2.11 Einfluss von Großeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und Großeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\n\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\n\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von Großeltern auf ihre Enkel, s. Abbildung 12.8, \\(G \\rightarrow K\\).\n\n\n\n\n\n\n\nAbbildung 12.8: Der kausale Effekt von Großeltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable übersehen haben? (S. nächster Abschnitt). 👻\n\n12.2.12 Der Gespenster-DAG\n👻 Es gibt “unheilbare” DAGs, nennen wir sie “Gespenster-DAGs”, in denen es nicht möglich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. Abbildung 12.9. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: “Deine Theorie ist nicht gut, zurück an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.”\n\n\n\n\n\n\n\nAbbildung 12.9: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollständig) möglich.\n\n\n\n\nU könnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft. Die Großeltern wohnen woanders (in Spanien), d. h.r wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie. E ist sowohl für G als auch für U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad. Wenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\nDie Sache ist in diesem Fall chancenlos. Wir müssen diesen DAG verloren geben, McElreath (2020), S. 180; ein Gespenster-DAG. 👻",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-hintertür-schließen",
    "href": "1180-kausalatome.html#die-hintertür-schließen",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.3 Die Hintertür schließen",
    "text": "12.3 Die Hintertür schließen\n\nDefinition 12.3 (Hintertür) Eine “Hintertür” ist ein nicht-kausaler Pfad zwischen einer UV und einer AV. Ein Hintertürpfad entsteht, wenn es eine alternative Route über eine oder mehrere Variable gibt, die UV mit der AV verbindet. Dieser Pfad verzerrt die Schätzwerte des kausalen Einflusses, wenn er nicht kontrolliert wird. \\(\\square\\)\n\n\n12.3.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groß ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in Abbildung 12.10 dargestellt.\n\n\n\n\n\n\n\nAbbildung 12.10: Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfläche beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund für die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\leftarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. Gäbe es nur nur den zweiten Pfad und wir würden b ändern, so würde sich p nicht ändern.\n\n12.3.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildung 12.11 zeigt eine erfreuliche Situation: Die “Hintertür” zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die Hintertür geschlossen - führen also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\n\n\nAbbildung 12.11: Unverzerrte Schätzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Prädiktor im Modell enthalten ist. Da die beiden Prädiktoren unkorreliert sind, hat die Aufnahme des einen Prädiktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie “Hintertür” der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berühmte Lösung, den kausalen Pfad zu isolieren, ist ein (randomisiertes, kontrolliertes5) Experiment. Wenn wir den Häusern zufällig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen könnten (unabhängig von ihrer Quadratmeterzahl, a), würde sich der Graph so ändern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\leftarrow a \\rightarrow p\\) geschlossen (“blockiert”).\n\n\n\n\n\n\nWichtig\n\n\n\nDie Stärke von (gut gemachten) Experimente ist, dass sie kausale Hintertüren schließen. Damit erlauben sie (korrekte) Kausalaussagen. \\(\\square\\)\n\n\n\n12.3.3 Hintertür schließen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die Hintertür schließen (backdoor criterion). Wir wollen die Hintertüre schließen, da wir sonst nicht den wahren, kausalen Effekt bestimmen können.\nZum Glück gibt es neben Experimenten noch andere Wege, die Hintertür zu schließen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie Konfundierer, um kausale Hintertüren zu schließen. \\(\\square\\)\n\n\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis über b kein zusätzliches Wissen über p. Wissen Sie hingegen nichts über a, lernen Sie bei Kenntnis von b auch etwas über p. Konditionieren ist wie “gegeben, dass Sie a schon kennen…”.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "href": "1180-kausalatome.html#die-vier-atome-der-kausalanalyse",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.4 Die vier Atome der Kausalanalyse",
    "text": "12.4 Die vier Atome der Kausalanalyse\nAbbildung 12.12 stellt die vier “Atome” der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so können Sie jedes beliebige Kausalsystem (DAG) entschlüsseln.\n\n\n\n\n\n\n\nAbbildung 12.12: Die vier Atome der Kausalinferenz\n\n\n\n\n\n12.4.1 Mediation\n\nDefinition 12.4 (Mediator) Einen Pfad mit drei Knoten (Variablen), die über insgesamt zwei Kanten verbunden sind, wobei die Pfeile von UV zu Mediator und von Mediator zur AV zeigen, nennt man Mediation. Der Mediator ist die Variable zwischen UV und AV [Pearl, Glymour, und Jewell (2016); p. 38]. \\(\\square\\)\n\nDie Mediation (synonym: Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten (eines Pfades) die gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. Abbildung 12.13. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y “vermittelt” oder überträgt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\n\n\nAbbildung 12.13: Das Kausalmodell der Mediation mit x als UV, m als Mediator und Y als AV.\n\n\n\n\n\nBeispiel 12.1 (Mediator kontrollieren?) Sollte man den Mediator m in Abbildung 12.13 kontrollieren, wenn man den Kausaleffekt von x auf y schätzen möchte?6 \\(\\square\\)\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation “fließt” den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schließt) die Kette (genau wie bei der Gabel).\n\n\n\n\n\n\nTipp\n\n\n\nKontrollieren Sie den Mediator nicht. Der Pfad über den Mediator ist ein “echter” Kausalpfad, keine Scheinkorrelation. \\(\\square\\)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Kontrollieren eines Mediators ist ein Fehler, wenn man am gesamten (totalen) Kausaleffekt von UV zu AV interessiert ist. \\(\\square\\)\n\n\nEs kann auch angenommen werden, dass der Mediator nicht der einzige Weg von X zu Y ist, s. Abbildung 12.14. In Abbildung 12.14 gibt es zwei kausale Pfade von X zu Y: \\(x\\rightarrow m \\rightarrow y\\) und \\(x \\rightarrow y\\).\n\nDefinition 12.5 (Effekt) Gibt es eine (von (praktisch) Null verschiedene) kausale Assoziation der UV auf die AV, so hängt die AV von der UV (kausal) ab. Man spricht von einem Effekt (der UV auf die AV). \\(\\square\\)\n\n\nDefinition 12.6 (Totaler Effekt) Die Summe der Effekte aller (kausalen) Pfade von UV zu AV nennt man den totalen (kausalen) Effekt. \\(\\square\\)\n\n\nDefinition 12.7 (Indirekter Effekt) Den (kausalen) Effekt über den Mediatorpfad (von \\(X\\) über \\(M\\) zu \\(Y\\)) nennt man den indirekten (kausalen) Effekt. \\(\\square\\)\n\n\nDefinition 12.8 (Direkter Effekt) Ein Effekt, der nur aus dem Pfad \\(x\\rightarrow y\\) besteht, also ohne keine Zwischenglieder, nennt man in Abgrenzung zum indirekten Effekt, direkten (kausalen) Effekt. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 12.14: Partielle Mediation: Es gibt einen direkten Effekt (X-&gt;Y) und einen indirekten Effekt (X-&gt;M-&gt;Y).\n\n\n\n\n\n12.4.2 Der Nachfahre\n\nDefinition 12.9 (Nachfahre) Ein Nachfahre (engl. descendent) ist eine Variable, die von einer anderen Variable beeinflusst7 wird, s. Abbildung 12.15. \\(\\square\\)\n\nKontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet über m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise öffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\n\n\nAbbildung 12.15: Ein Nachfahre verhält sich ähnlich wie sein Vorfahre…\n\n\n\n\n\n12.4.3 Kochrezept zur Analyse von DAGs 👨‍🍳\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht: 📄\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geöffnet ist.\nBeurteilen Sie für jeden Pfad, ob er ein Hintertürpfad ist (Hintertürpfade haben einen Pfeil, der zur UV führt).\nWenn es geöffnete Hinterpfade gibt, prüfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schließen (falls möglich).",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#schließen-sie-die-hintertür-wenn-möglich",
    "href": "1180-kausalatome.html#schließen-sie-die-hintertür-wenn-möglich",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.5 Schließen Sie die Hintertür (wenn möglich)!",
    "text": "12.5 Schließen Sie die Hintertür (wenn möglich)!\n📺 Hintertür schließen\n\n12.5.1 Hintertür: ja oder nein?\n\n12.5.1.1 Fall 1: x-&gt;\n\n\\(\\boxed{X \\rightarrow}\\)\nAlle Pfade, die von der UV (X) wegführen, sind entweder “gute” Kausalpfade oder automatisch geblockte Nicht-Kausal-Pfade. In diesem Fall müssen wir nichts tun.8\n\n12.5.1.2 Fall 2: -&gt;x\n\n\\(\\boxed{\\rightarrow X}\\)\nAlle Pfade, die zur UV hinführen, sind immer Nicht-Kausal-Pfade, Hintertüren. Diese Pfade können offen sein, dann müssen wir sie schließen. Sie können auch geschlossen sein, dann müssen wir nichts tun.\n\n\n\n\n\n\nTipp\n\n\n\nSchließen Sie immer offene Hintertüren, um Verzerrungen der Kausaleffekte zu verhinden. \\(\\square\\)\n\n\n\n12.5.2 bsp1\n\nUV: \\(X\\), AV: \\(Y\\), drei Kovariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n\n\nAbbildung 12.16: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei Hintertürpfade in Abbildung 12.16:\n\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schließt die offene Hintertür.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n12.5.3 Schließen Sie die Hintertür (wenn möglich)!, bsp2\n\nS. DAG in Abbildung 12.17: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\n\n\nAbbildung 12.17: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintertüren zu schließen:\n\nentweder \\(A\\) und \\(M\\)\n\noder \\(S\\)\n\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), S. 188.\n\n12.5.4 Implizierte bedingte Unabhängigkeiten von bsp2\n\n\nAuch wenn die Daten nicht sagen können, welcher DAG der richtige ist, können wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten Unabhängigkeiten geben uns Möglichkeiten, zu prüfen, ob wir einen DAG verwerfen (ausschließen) können. Bedingten Unabhängigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhängig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte Unabhängigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#fazit",
    "href": "1180-kausalatome.html#fazit",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.6 Fazit",
    "text": "12.6 Fazit\n\n12.6.1 Ausstieg\n📺 Musterlösung für eine DAG-Prüfungsaufgabe\n📺 Musterlösung für schwierige DAG-Prüfungsaufgaben\n\nBeispiel 12.2 (PMI zum heutigen Stoff) Der Kreativitätsforscher Edward de Bono hat verschiedene “Denkmethoden” vorgestellt, die helfen sollen, Probleme besser zu lösen. Eine Methode ist die “PMI-Methode”. PMI steht für Plus, Minus, Interessant. Bei Plus und Minus soll man eine Bewertung von Positiven bzw. Negativen bzgl. eines Sachverhaltes anführen. Bei Interessant verzichtet man aber explizit auf eine Bewertung (im Sinne von “gut” oder “schlecht”) und fokussiert sich auf Interessantes, Überraschendes, Bemerkenswertes (vgl. De Bono (1974)).\nFühren Sie die PMI-Methode zum heutigen Stoff durch!\n\n\nPlus: Was fanden Sie am heutigen Stoff gut, sinnvoll, nützlich?\n\nMinus: Was finden Sie am heutigen Stoff nicht gut, sinvoll, nützlich?\n\nInteressant: Was finden Sie am heutigen Stoff bemerkenswert, interessant, nachdenkenswert?\n\nReichen Sie die Antworten an der von der Lehrkraft angezeigten Stelle ein! \\(\\square\\)\n\n\n12.6.2 Zusammenfassung\n📺 Kausalmodelle überprüfen\nWie (und sogar ob) Sie statistische Ergebnisse (z. B. eines Regressionsmodells) interpretieren können, hängt von der epistemologischen Zielrichtung der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen können die Ergebnisse (z. B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. “Der Unterschied zwischen beiden Gruppen beträgt etwa …”. Allerdings ist eine kausale Interpretation nicht zulässig.\nBei prognostischen Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z. B. auf Basis der PPV. Kausalaussagen sind zwar nicht möglich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dürfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten ändern sich (oft), wenn man Prädiktoren zum Modell hinzufügt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, möglichst viele Prädiktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der “kausalen Atome” ist Voraussetzung zur Ableitung von Kausalschlüsse in Beobachtungsstudien.\n\n12.6.3 Vertiefung\nAn weiterführender Literatur sei z. B. Cummiskey u. a. (2020), Lübke u. a. (2020), Pearl, Glymour, und Jewell (2016) und Dablander (2020) empfohlen. Ein gutes Lehrbuch, das auf Kausalinferenz eingeht, ist Huntington-Klein (2022). Praktischerweise ist es öffentlich lesbar. Das Web-Buch Causal Inference for the Brave and True sieht auch vielversprechend aus. Es gibt viele Literatur zu dem Thema; relevante Suchterme sind z. B. “DAG”, “causal” oder “causal inference”.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#aufgaben",
    "href": "1180-kausalatome.html#aufgaben",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.7 Aufgaben",
    "text": "12.7 Aufgaben\n\nSammlung “kausal”",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1180-kausalatome.html#section",
    "href": "1180-kausalatome.html#section",
    "title": "12  Die Atome des Kausalität",
    "section": "\n12.8 —",
    "text": "12.8 —\n\n\n\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, und Krista Watts. 2020. „Causal Inference in Introductory Statistics Courses“. Journal of Statistics Education 0 (Januar): 1–16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. „An Introduction to Causal Inference“. Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische Denken. Rowohlt Taschenbuch Verlag.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. Boca Raton: CRC Press, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLübke, Karsten, Matthias Gehrke, Jörg Horst, und Gero Szepannek. 2020. „Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Data“. Journal of Statistics Education, April, 1–17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. „Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data“. Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.",
    "crumbs": [
      "Kausalität",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Die Atome des Kausalität</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lernsteuerung",
    "href": "1200-abschluss.html#lernsteuerung",
    "title": "13  Abschluss",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerläutern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische “Lieblingsfehler” benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik übersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n13.1.2 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\n13.1.3 Begleitvideos\n\nFragestunde QM2\nPlaylist QM2\nLieblingsfehler",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#lieblinglingsfehler",
    "href": "1200-abschluss.html#lieblinglingsfehler",
    "title": "13  Abschluss",
    "section": "\n13.2 Lieblinglingsfehler",
    "text": "13.2 Lieblinglingsfehler\nLieblingsfehler im Überblick 🤷:\n\nPost-Präd-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrädiktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt\n\n\n13.2.1 Post-Präd-Verteilung (PPV) und Post-Verteilung verwechseln 🤷\n🏎 🏎 Vertiefung: Dieser Abschnitt ist nicht prüfungsrelevant. 🏎️ 🏎\nBerechnen wir unser Standard-mtcars-Modell: mpg ~ hp.\n\nm1 &lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten, s. Tabelle 13.1.\n\npost_verteilung &lt;- m1 %&gt;% \n  as_tibble()\nhead(post_verteilung)\n\n\nTabelle 13.1: Postverteilung in Stichprobenform (m1)\n\n\n\n  \n\n\n\n\n\n\nDiese Tabelle kann man hernehmen, um Fragen zu Post-Verteilung zu beantworten. Häufig ist es aber bequemer, z. B. mit parameters(m1) Post-Intervalle und Punktschätzer auszulesen.\nDie Posterior-Prädiktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n  \n\n\n\n\n13.2.2 Quantile und Verteilungsfuntion verwechseln 🤷\n\n13.2.2.1 Quantil für \\(p\\)\n\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind. s. Abbildung 13.1.\n\n\n\n\n\n\n\nAbbildung 13.1: 50%-Quantil\n\n\n\n\nDas 50%-Quantil (.5-Quantil) beträgt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist größer oder gleich dem \\(p\\)-Quantil.\n\n13.2.2.2 Verteilungsfunktion \\(F\\)\n\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt, s. Abbildung 13.2.\n\n\n\n\n\n\n\nAbbildung 13.2: Verteilungsfunktion F(x=0)=1/2\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit beträgt hier 50%, dass \\(x\\) nicht größer ist als 0.\n\n13.2.3 Interaktion falsch interpretieren 🤷\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kürzer als) mpg ~ hp + vs + hp:vs.\n\n\n\nm2 &lt;- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\nModellkoeffizienten, s. Tabelle 13.2.\n\nparameters(m2)\n\n\n\n\nTabelle 13.2: Parameter von m2\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n(Intercept)\n24.58\n(19.10, 30.36)\n100%\n1.002\n1851.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.67%\n1.001\n1860.00\nNormal (0.00 +- 0.22)\n\n\nvs\n14.05\n(4.18, 23.19)\n99.72%\n1.001\n1517.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.20, -0.02)\n99.28%\n1.000\n1668.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\n\nTabelle 13.2 zeigt die Visualisierung der Parameter von m2.\n\nplot(parameters(m2))\n\n\n\n\n\n\nAbbildung 13.3: Parameter von m2 visualisiert\n\n\n\n\nFalsch 😈 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11.\nRichtig 👼 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11 – wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Prädiktoren wären hier eine sinnvolle Lösung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kochrezepte",
    "href": "1200-abschluss.html#kochrezepte",
    "title": "13  Abschluss",
    "section": "\n13.3 Kochrezepte 🍲",
    "text": "13.3 Kochrezepte 🍲\n\n13.3.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen über ein Phänomen, \\(y\\), Kausalfrage finden 2. Literatur wälzen, um mögliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese präzisieren 4. Modell präzisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prüfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n13.3.2 Parameter schätzen vs. Hypothesen prüfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schätzen. Beispiel Hypothesenprüfung: “Frauen parken im Durchschnitt schneller ein als Männer”. Beispiel Parameterschätzung: “Wie groß ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und Männern?”\nJe ausgereifter ein Forschungsfeld, desto kühnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nächste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nächste Sonnenfinsternis wird in den nächsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen für den Klausurerfolg. Kühne Hypothesen sind wünschenswert 🦹\n\n13.3.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist höher als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist größer als Null):\n\\[\\mu_1 &gt; \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 &gt; 0 \\Leftrightarrow \\mu_d &gt; 0\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#kerngedanken-bayes",
    "href": "1200-abschluss.html#kerngedanken-bayes",
    "title": "13  Abschluss",
    "section": "\n13.4 Kerngedanken Bayes",
    "text": "13.4 Kerngedanken Bayes\n📺 Bayes in fünf Minuten\n📺 Bayes in zehn Minuten\n\n13.4.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\nm3 &lt;- stan_glm(mpg ~ hp, data = mtcars)\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI, s. Abbildung 13.4.\n\n\n\n\n\n\n\nAbbildung 13.4: Post-Verteilung (HDI) von m3\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z. B. zu einem 95%-PI) ist möglich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind möglich, z. B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings übermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n13.4.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#beispiele-für-prüfungsaufgaben",
    "href": "1200-abschluss.html#beispiele-für-prüfungsaufgaben",
    "title": "13  Abschluss",
    "section": "\n13.5 Beispiele für Prüfungsaufgaben",
    "text": "13.5 Beispiele für Prüfungsaufgaben\n\n13.5.1 Geben Sie den korrekten Begriff an!\n🌬🚙🙋️👨⬅️Hans 👧⬅️Anna 👩⬅️Lise\nPuh, wie erstelle ich für alle Studis ein anderes Rätsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-Prüfung bekommen alle Studentis eine eigene, jeweils andere Prüfung. Teamarbeit bleibt natürlich trotzdem untersagt.\n\n\n\n13.5.2 DAG mit doppelter Konfundierung\nPuh, jetzt kommt ein wilder DAG, s. Abbildung 13.5.\n\n\n\n\n\n\n\nAbbildung 13.5: Ein DAG mit doppelter Konfundierung. Ist hier noch zu helfen?\n\n\n\n\n\nDefinition 13.1 (Minimale Adjustierungsmenge) die Minimale Adjustierungsmenge für x und y gibt eine kleinstmögliche Menge an an Knoten eines DAGs an, die zu adjustieren sind, um den kausalen Effekt von x auf y zu bestimmen (zu “identifizieren”). \\(\\square\\)\n\n❓Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n❗ Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\nJa, dem DAG ist zu helfen.\n\n13.5.3 DAG mit vielen Variablen\nJe nach dem wie komplex Ihre Theorie ist, ist Ihr DAG auch komplex, s. Abbildung 13.6.\n\n\n\n\n\n\n\nAbbildung 13.6: Ein DAG mit vielen Variablen\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\nTrotz der vielen Variablen, ist der kausale Effekt von E auf D recht gut zu identifizieren.\n\n13.5.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nvan Kampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\nAbbildung 13.7 zeigt den DAG von van Kampen (2014) zu den Symptomen der Schizophrenie.\n\n\n\n\n\n\n\nAbbildung 13.7: Ein DAG zu den Symptomen der Schizophrenie\n\n\n\n\nMinimales Adjustment-Set für den totalen Kausaleffekt: {AIS, ALN}\n\n13.5.5 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrüfungsfragen zu Modellen könnten z. B. sein:\n\nGeben Sie den Punktschätzer (Median) für den Prädiktor X im Modell Y an!\nGeben Sie ein 89%-HDI für den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris …\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI für den Prädiktor X im Modell Y?\nWas verändert sich an den Parametern, wenn Sie die Prädiktoren zentrieren/z-standardisieren?\n…",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#aufgabensammlungen",
    "href": "1200-abschluss.html#aufgabensammlungen",
    "title": "13  Abschluss",
    "section": "\n13.6 Aufgabensammlungen",
    "text": "13.6 Aufgabensammlungen\nFolgende Tags auf dem Datenwerk beinhalten relevante Aufgaben3:\n\nbayes\nbayes-grid\ndag\nqm2\nprobability\npost\nrope\n\nBesondere “Prüfungsnähe” könnten diese Sammlungen haben:\n\nqm2-pruefung\nexam-22\nquiz1-qm2-ws23\nVerteilungen-Quiz",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#fragenspeicher",
    "href": "1200-abschluss.html#fragenspeicher",
    "title": "13  Abschluss",
    "section": "\n13.7 Fragenspeicher",
    "text": "13.7 Fragenspeicher\n\nFRAGE: Wo finde ich eine Probeklausur? – ANTWORT: Dieser Tag stellt Fragen einer Probeprüfung zusammen.\nFRAGE: Wie bereite ich mich gut auf die Prüfung vor? – ANTWORT: Hier finden Sie Tipps zur Prüfungsvorbereitung.\nFRAGE: Wenn man ‘(Intercept)’ benutzt, welche Anführungszeichen sind die richtigen? Bei verschiedenen Anführungszeichen, also ’ oder ` oder ´ kommen entweder keine oder sogar verschiedene Ergebnisse raus. – ANTWORT: Normalerweise ist innerhalb von R-Befehlen aus dem Tidyverse keine Anführungsstriche für Spaltennamen nötig. Wenn es allerdings ein “verbotener” Name ist, muss man aufpassen. (Intercept) ist so ein verbotener Variablenname. Warum verboten? Ein “braver” Variablenname (in R) muss mit einem Buchstaben beginnen und darf keine Sonderzeichen ((, {, #, etc.) enthalten. Hat man aber einen an sich unerlaubten Variablennamen, so kann man den trotzdem verwenden, wenn man ihn mit Backticks (`) umgibt, also wie in \\(Intercept)\\). Doppelte und einfache Anführungsstriche sind in R übrigens beide okay, wenn man etwa einen String (Text) auszeichnen will, aber im Rahmen von Tidyverse nicht nötig für Variablennamen.\nFRAGE: Woher weiß ich, dass ich die Prädiktoren vorher zentrieren muss? Kann man das aus der Aufgabenstellung irgendwie herauslesen? Z.B. wie bei Tutorium Aufgabe 10.1 d). – ANTWORT: Es gibt mehrere Gründe, Variablen zu zentrieren, dazu zählen 1) bessere Interpretation des Intercepts, 2) bessere Interpretation von Interaktionseffekten, 3) Verringerung von Kollinearität. Die Steigung (beta 1) verändert sich (fast immer) aber nicht durch das Zentrieren, ebenso wie R-Quadrat.\nFRAGE: Bei der Bearbeitung der Prüfung heute ist ein Fehler aufgekommen, den ich bis jetzt nicht verstehe. Deshalb war es auch für mich nicht möglich die Aufgabe zu bearbeiten. Die AV high Aufteilung in die Werte 0 und 1 (0 = AV &lt;= median (AV)) (1 =AV &gt; median(AV) hat geklappt. Die UV high Aufteilung in die Werte 0 und 1 (0 = UV &lt;= median (UV)) (1 =UV &gt; median(UV) hat dabei aber nicht geklappt. Anstatt die Werte 0 und 1 bei der neuen UV_high Spalte zu bekommen, kommen nur Nas raus. Auch mit dem Befehl drop_na hat es nicht geklappt. Dies habe ich nicht nur mit dem RStudio auf meinem Computer versucht sondern auch über die Cloud über mein IPad. (Bei beiden Geräten kam es zuvor noch nie zu Problemen) Hier mein R-Code:\n\n\nlibrary(tidyverse)\n#library(easystats)\n#library(rstanarm)\n\ndata(\"msleep\", package = \"ggplot2\")\n\nmsleep1 &lt;-\n  msleep |&gt; \n    mutate(av_high = case_when(awake &gt; median(awake) ~ 1,\n                               awake &lt;= median(awake) ~ 0))\n\nmsleep2 &lt;-\n  msleep1 |&gt; \n    mutate(uv_high = case_when(sleep_rem &gt; median(sleep_rem) ~ 1,\n                               sleep_rem &lt;= median(sleep_rem) ~ 0))\n  \nmsleep2 |&gt; \ncount(uv_high)\n\n\n  \n\n\n\nANTWORT: Sie haben nicht die fehlenden Werte ausgeschlossen. Wenn Sie die fehlenden Wert ausschließen, dann klappt es:\n\nmsleep2 &lt;-\n  msleep1 |&gt; \n  drop_na(sleep_rem) |&gt;  # fehlende Werte aus `sleep_rem` entfernen\n    mutate(uv_high = case_when(sleep_rem &gt; median(sleep_rem) ~ 1,\n                               sleep_rem &lt;= median(sleep_rem) ~ 0))\n  \nmsleep2 |&gt; \ncount(uv_high)\n\n\n  \n\n\n\n\nFRAGE: Ich habe meine Lösungswege mit Ihren abgeglichen und finde keinen bedeutenden Unterschied. Dennoch erhalte ich andere Ergebnisse, welche nicht im Toleranzbereich liegen. Um das nochmals zu überprüfen, habe ich Ihre Lösungswege 1:1 in mein RStudio übertragen, aber auch dann erhalte ich nicht die angegebene Lösung. – ANTWORT: Es sollte ein Modell berechnet werden mit z-transformierten Variablen. Für die UV war der ROPE anzugeben. Leider haben Sie vergessen, die Daten zu z-transformieren.\n\nHier ist das Modell ohne z-Transformation:\n\nlibrary(rstanarm)\nlibrary(easystats)\nlibrary(dplyr)\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nm1 &lt;- stan_glm(bill_length_mm ~ year, data = penguins)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 3.6e-05 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.09 seconds (Warm-up)\n## Chain 1:                0.133 seconds (Sampling)\n## Chain 1:                0.223 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 3.9e-05 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.115 seconds (Warm-up)\n## Chain 2:                0.18 seconds (Sampling)\n## Chain 2:                0.295 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 3.3e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.107 seconds (Warm-up)\n## Chain 3:                0.223 seconds (Sampling)\n## Chain 3:                0.33 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 0.000137 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.37 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.176 seconds (Warm-up)\n## Chain 4:                0.158 seconds (Sampling)\n## Chain 4:                0.334 seconds (Total)\n## Chain 4:\n\nrope(m1)\n\n\n  \n\n\n\nHier ist das Modell mit z-Transformation:\n\np2 &lt;- \n  penguins |&gt; \n  select(bill_length_mm, year) |&gt; \n  standardise()\n\nm2 &lt;- stan_glm(bill_length_mm ~ year, data = p2)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 8e-05 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.092 seconds (Warm-up)\n## Chain 1:                0.15 seconds (Sampling)\n## Chain 1:                0.242 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 0.000111 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.11 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.079 seconds (Warm-up)\n## Chain 2:                0.149 seconds (Sampling)\n## Chain 2:                0.228 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 3.7e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.087 seconds (Warm-up)\n## Chain 3:                0.129 seconds (Sampling)\n## Chain 3:                0.216 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 3.8e-05 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.095 seconds (Warm-up)\n## Chain 4:                0.134 seconds (Sampling)\n## Chain 4:                0.229 seconds (Total)\n## Chain 4:\n\nrope(m2)\n\n\n  \n\n\n\nDer Wert von m2 findet sich in der Musterlösung. Man beachte, dass sich die Rope-Werte von m1 und m2 deutlich unterscheiden.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#viel-erfolg-bei-der-prüfung",
    "href": "1200-abschluss.html#viel-erfolg-bei-der-prüfung",
    "title": "13  Abschluss",
    "section": "\n13.8 Viel Erfolg bei der Prüfung!",
    "text": "13.8 Viel Erfolg bei der Prüfung!\n🥳🏆🍀🍀🍀",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "1200-abschluss.html#section",
    "href": "1200-abschluss.html#section",
    "title": "13  Abschluss",
    "section": "\n13.9 —",
    "text": "13.9 —\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. „The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs“. European Psychiatry 29 (7): 437–48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2. Aufl. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Abschluss",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Badenes-Ribera, Laura, Dolores Frias-Navarro, Bryan Iotti, Amparo\nBonilla-Campos, and Claudio Longobardi. 2016. “Misconceptions of\nthe p-Value Among Chilean and Italian Academic\nPsychologists.” Frontiers in Psychology 7. https://www.frontiersin.org/article/10.3389/fpsyg.2016.01247.\n\n\nBourier, Günther. 2018. Wahrscheinlichkeitsrechnung Und Schließende\nStatistik: Praxisorientierte Einführung: Mit Aufgaben Und Lösungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden\n[Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik –\nWahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nBriggs, William M. 2016. Uncertainty: The Soul of\nModeling, Probability & Statistics. Springer.\n\n\nCohen, J. 1992. “A Power Primer.” Psychological\nBulletin 112 (1): 155–59.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas\nClark, and Krista Watts. 2020. “Causal Inference in Introductory\nStatistics Courses.” Journal of Statistics Education 0\n(January): 1–16. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nDablander, Fabian. 2020. “An Introduction to Causal\nInference.” Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/b3fkw.\n\n\nDe Bono, Edward. 1974. Edward de Bono: Das Spielerische\nDenken. Rowohlt Taschenbuch Verlag.\n\n\nForum, World Economic. 2020. “The Future of Jobs Report\n2020.” CH-1223 Cologny/Geneva Switzerland:\nWorld Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\n“R-Squared for Bayesian Regression Models.” The\nAmerican Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2020.\n“Rstanarm: Bayesian Applied Regression Modeling via\nStan.” https://mc-stan.org/rstanarm.\n\n\nHenze, Norbert. 2019. Stochastik: Eine Einführung mit Grundzügen der\nMaßtheorie: Inkl. zahlreicher Erklärvideos. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-59563-3.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to\nResearch Design and Causality. Boca Raton: CRC\nPress, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nJaynes, E. T. 2014. Probability Theory: The Logic of\nScience. 1. https://doi.org/10.1007/s13398-014-0173-7.2.\n\n\nKampen, D. van. 2014. “The SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal\nChains Based on the Language of Directed Graphs.” European\nPsychiatry 29 (7): 437–48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. “Rejecting or Accepting Parameter Values\nin Bayesian Estimation.” Advances in Methods and Practices in\nPsychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLübke, Karsten, Matthias Gehrke, Jörg Horst, and Gero Szepannek. 2020.\n“Why We Should Teach Causal Inference: Examples in\nLinear Regression with Simulated Data.” Journal of Statistics\nEducation, April, 1–17. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel Lüdecke. 2019. “Indices of Effect Existence and\nSignificance in the Bayesian Framework.” Frontiers in\nPsychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. “Chocolate Consumption, Cognitive\nFunction, and Nobel Laureates.” New England Journal of\nMedicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nMorey, Richard D., and Jeffrey N. Rouder. 2011. “Bayes Factor\nApproaches for Testing Interval Null Hypotheses.”\nPsychological Methods 16 (4): 406–19. https://doi.org/10.1037/a0024377.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West\nSussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Edited by Herbert\nKeuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational\nData.” Advances in Methods and Practices in Psychological\nScience 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. “The\nASA Statement on p-Values:\nContext, Process, and Purpose.” The American\nStatistician 70 (2): 129–33. https://doi.org/10.1080/00031305.2016.1154108.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]