[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "nicht gleich zu Beginn, aber nach 2-3 Wochen↩︎\nfalls Sie die Pakete schon installiert haben, könnten Sie mal in RStudio auf “update.packages” klicken↩︎"
  },
  {
    "objectID": "Pruefung.html",
    "href": "Pruefung.html",
    "title": "1  Prüfung",
    "section": "",
    "text": "Die Prüfungsleistung besteht aus einer Open-Book-Prüfung."
  },
  {
    "objectID": "Pruefung.html#grundsätzliches",
    "href": "Pruefung.html#grundsätzliches",
    "title": "1  Prüfung",
    "section": "1.2 Grundsätzliches",
    "text": "1.2 Grundsätzliches\nDie folgenden Hinweise gelten grundsätzlich, d.h. soweit nicht anders in der jeweiligen Prüfung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von Prüfungshinweisen kann zu Punkteabzug oder Nichtbestehen führen."
  },
  {
    "objectID": "Pruefung.html#wiederholungsprüfungen",
    "href": "Pruefung.html#wiederholungsprüfungen",
    "title": "1  Prüfung",
    "section": "1.3 Wiederholungsprüfungen",
    "text": "1.3 Wiederholungsprüfungen\n\nWenn Sie bei einer Prüfung durchgefallen sein sollten, so haben Sie grundsätzlich die Möglichkeit, die Prüfung zu wiederholen.\nDenken Sie daran, sich rechtzeitig für Prüfungsleistungen anzumelden; beachten Sie die Fristen.\nDie Termine für die Wiederholungsprüfungen werden stets zusammen/zeitgleich mit denen der regulären Prüfungen bekannt gegeben.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine Wiederholungsprüfung.\nRelevanter Stoff und formale Bedingungen (wie Prüfungsform) sind grundsätzlich identisch zur letzten abgehaltenen Prüfung des Moduls (d.h. sofern nicht anders angegeben). Daher sind Wiederholungsprüfungen vom Anspruch vergleichbar wie die reguläre Klausur. Die Prüfungen sollen möglichst gleich vom Anspruch sein, um Fairness zu gewährleisten.\nBeachten Sie immer die Hinweise, die für die Wiederholungsprüfung angegeben sind. Im Einzelfall keine eine Wiederholungsprüfung von der vorherigen Prüfung stärker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen Wiederholungsprüfung veröffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine Wiederholungsprüfung. Stattdessen können Sie ggf. an der regulären Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist möglich, dass der Stoff sich dann substanziell ändert; meist halten sich die Änderungen (im Stoff) aber in Rahmen.\nSprechen Sie die Moduldozentis an für Details zur Prüfung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine Prüfung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben, es kommt auf den Einzelfall an. Grundsätzlich rate ich aber dazu, Prüfungen nicht zu verschieben: Schließlich könnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum Prüfungsrecht sprechen Sie bitte die Studienberatung an."
  },
  {
    "objectID": "Pruefung.html#prüfungsstoff",
    "href": "Pruefung.html#prüfungsstoff",
    "title": "1  Prüfung",
    "section": "1.4 Prüfungsstoff",
    "text": "1.4 Prüfungsstoff\nPrüfungsrelevanter Stoff ist alles, was im Unterricht behandelt wurde, sofern es nicht explizit (und schriftlich) als “nicht prüfungsrelevant” gekennzeichnet ist."
  },
  {
    "objectID": "Pruefung.html#bearbeitungshinweise",
    "href": "Pruefung.html#bearbeitungshinweise",
    "title": "1  Prüfung",
    "section": "1.5 Bearbeitungshinweise",
    "text": "1.5 Bearbeitungshinweise\n\n1.5.0.1 Allgemeine Hinweise\n\nVerwenden Sie Standardwerte (defaults) der R-Funktionen.\nFindet sich in einer Auswahlliste möglicher Antworten nicht die exakte Lösung, wählen Sie die am besten passende.\nTreffen Sie Annahmen, wo nötig.\nDie Prüfung besteht auch aus Single- bzw. Multiple-Choice- (MC-)-Aufgaben mit mehreren Antwortoptionen.\nBei Multiple-Choice-Aufgaben (MC-Aufgaben) ist zumeist genau eine Antwortoption auszuwählen aus vier oder fünf Antwortoptionen.\nIm Zweifel ist eine Aussage auf den Stoff, so wie im Unterricht behandelt, zu beziehen.\nBei Fragen zu R-Syntax spielen Aspekte wie Enter-Taste o.Ä. bei der Beantwortung der Frage keine Rolle; diese Aspekte dürfen zu ignorieren.\nJede Aussage einer MC-Aufgabe ist entweder richtig oder falsch (aber nicht beides oder keines).\nDie MC-Aufgaben sind nur mit Kreuzen zu beantworten; Text wird bei der Korrektur nicht berücksichtigt.\nJede Aussage gilt ceteris paribus (unter sonst gleichen Umständen). Aussagen der Art „A ist B“ (z.B. “Menschen sind sterblich”) sind nur dann als richtig auszuwählen, wenn die Aussage immer richtig ist.\nFalls Sie bei einer Aufgabe mehrere Antworten finden, aber nur nach einer gefragt ist, geben Sie nur eine an.\nFalls mehrere (widersprüchliche) Antworten gegeben wurden, wird im Zweifel die erst genannte gewertet.\nDie Aufgabenstellung in einer Moodle-Prüfung wird erst sichtbar, wenn Sie den Prüfungsbedingungen zugestimmt haben und die Prüfungszeit begonnen hat.\n\n\n\n1.5.1 Aufgaben zur Datenanalyse\n\nJe nach Spracheinstellung in Moodle kann es sein, dass Sie als Dezimaltrennzeichen ein Komma oder einen Punkt verwenden müssen. Moodle weist Sie, wenn Sie die Aufgabe verlassen, darauf hin, falls eine Zahl nicht als Zahl erkannt wurde.\nRunden Sie ggf. auf eine Dezimalstelle.\nVerwenden Sie Methoden der Bayes-Statistik für inferenzstatistische Analysen.\nGeben Sie keine Prozentzahlen an, sondern Anteile (also nicht “50%”, sondern “0.5” bzw. “0,5”).\nBei Aufgaben, die eine Zahl als Antwort verlangen, ist nur eine Zahl anzugeben (nicht etwa Buchstaben).\nBei Aufgaben zur “Bayes-Box” (Erstellung einer Gitterwert-Tabelle) gelten folgende Maßgaben:\n\nHandelt es sich um Parameter mit einem begrenzten Wertebereich (wie etwa Anteile), so ist der ganze Wertebereich zu modellieren. Es sind 100 verschiedene Parameterwerte zu berechnen.\nHandelt es sich um Parameter \\(X\\) mit einem unbegrenzten Wertebereich (wie normalverteilte Variablen), so ist der Wertebereich \\(X-2\\sigma \\le X \\le X+2\\sigma\\) zu simulieren.\n\nAlle Berechnungen, die Zufallszahlen beinhalten, sollen mit fixierten Startwert der Zufallszahlen durchgeführt werden. Es ist die Zahl 42 zu verwenden.\nWie auch bei den übrigen Hinweisen gelten diese Maßgaben nur soweit in der Prüfung nicht explizit andere Hinweise gegeben wurden.\nWenn Stichproben simuliert werden sollen, ziehen Sie \\(10^3\\) Zufallsstichproben.\nIn einigen Aufgaben kann verlangt sein, dass Sie einen bestimmten Datensatz in R importieren sollen. In diesem Fall wird vorausgesetzt, dass Ihnen diese Bezugsquelle von Datensätzen bekannt ist und dass Sie wissen, wie man einen Datensatz in R importiert."
  },
  {
    "objectID": "Pruefung.html#teilnahmebedingungen",
    "href": "Pruefung.html#teilnahmebedingungen",
    "title": "1  Prüfung",
    "section": "1.6 Teilnahmebedingungen",
    "text": "1.6 Teilnahmebedingungen\n\nDie Prüfung ist selbständig, also alleine nur durch Sie, ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der Prüfung sind einzuhalten.\nEs dürfen nur die explizit als zulässig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulässigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, Bücher sowie Quellen aus dem Internet.\nDie Übernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wörtliche Übernahme (“copy-paste”) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulässig.\nBei technischen Problemen ist sofort der Prüfer bzw. die Prüferin zu verständigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die Prüfung bzw. Teile daraus (z.B. Prüfungsfragen) zu speichern oder weiterzugeben.\nIm Übrigen gelten die allgemeinen Prüfungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht Prüflingen, kommuniziert werden während der Prüfung. Dies gilt auch für den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den Prüfer, wenn Sie meinen, es liege ein technisches Problem vor.\nDas Nichtbeachten der Regeln kann zu Notenabzug oder Nichtbestehen führen."
  },
  {
    "objectID": "Pruefung.html#organisatorische-hinweise",
    "href": "Pruefung.html#organisatorische-hinweise",
    "title": "1  Prüfung",
    "section": "1.7 Organisatorische Hinweise",
    "text": "1.7 Organisatorische Hinweise\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prüfungsrelevant.\nIm Übrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung für formale oder rechtliche Fragen.\nWährend der Prüfung werden nur Fragen beantwortet, die für die Bearbeitung zwingend nötig sind (etwa bei technischen Problemen).\nEs werden keine Fragen der Art “Ist diese Aufgabe klar formuliert?” beantwortet während der Prüfung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der Prüfung=. Der Prüfer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der Prüfung ist nur möglich, wenn Sie den Teilnahmebedingungen der Prüfung zustimmen.\nDie Aufgabenstellung der Prüfung wird nur während des Prüfungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppenteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte Prüfungsuhrzeit (Beginn, Ende).\nPrüfungszeitraum, Aufgabenstellung und sonstige Materialien können variieren zwischen den Prüflingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusätzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der Prüfung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor erhöht."
  },
  {
    "objectID": "Pruefung.html#open-book-prüfungen",
    "href": "Pruefung.html#open-book-prüfungen",
    "title": "1  Prüfung",
    "section": "1.8 Open-Book-Prüfungen",
    "text": "1.8 Open-Book-Prüfungen\nEinige Prüfungen werden als “Take-home-Prüfung” im “Open-Book-Format” geschrieben. Was bedeutet dies?\n“Take-home-Prüfung”: Sie bearbeiten die Prüfung in Ihrem privaten Umgebung in Moodle oder in Räumlichkeiten der Hochschule. Eine Überwachung per Kamera findet nicht statt.\n“Open-Book-Prüfung”: Sie dürfen Hilfsmittel wie Bücher und Folien während der Prüfung nutzen.\nIhre Prüferin/Ihr Prüfer informiert Sie über das Format Ihrer Prüfung."
  },
  {
    "objectID": "Pruefung.html#zeitrahmen-der-prüfung",
    "href": "Pruefung.html#zeitrahmen-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.9 Zeitrahmen der Prüfung",
    "text": "1.9 Zeitrahmen der Prüfung\nDie Prüfung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die Prüfung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). Verspätete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der Prüfung wird Ihnen von Ihrer Prüferin bzw. Ihrem Prüfer bekannt gegeben."
  },
  {
    "objectID": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prüfung",
    "href": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prüfung",
    "title": "1  Prüfung",
    "section": "1.10 Technische und organisatorische Anforderungen einer Open-Book-Prüfung",
    "text": "1.10 Technische und organisatorische Anforderungen einer Open-Book-Prüfung\nUm an einer Open-Book-Prüfung teilzunehmen, benötigen Sie IT-Ausstattung sowie Räumlichkeiten. An IT-Ausstattung benötigen Sie einen Computer mit Internetanschluss; ein Smartphone reicht nicht aus. Nutzen Sie Ihr eigenes Gerät (Computer) für die Prüfung; die Hochschule stellt Ihnen keinen Computer zur Verfügung. Sie benötigen keine Webcam und kein Mikrofon. Ein Tablett oder Smartphone reicht nicht für die Prüfung. An Software benötigen Sie Zugang zu Ihrem Moodle-Konto, was einen aktuellen Internet-Browser voraussetzt. Zu den organisatorischen Anforderungen gehören ein Raum, in dem Sie die Prüfung ungestört bearbeiten können sowie ein Internetanschluss zum Bearbeiten der Klausur in Moodle. Bitte benutzen Sie während der Prüfung nicht den Zurück-Button in Ihrem Browser, wenn Sie zu einer vorherigen Frage zurückgehen wollen. Nutzen Sie die in der Prüfung zur Verfügung gestellten Funktionen/Buttons dafür."
  },
  {
    "objectID": "Pruefung.html#technische-probleme-während-der-prüfung",
    "href": "Pruefung.html#technische-probleme-während-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.11 Technische Probleme während der Prüfung",
    "text": "1.11 Technische Probleme während der Prüfung\nIm Falle eines technischen Problems auf Seiten der Prüfungsinfrastruktur ist sofort der Prüfer zu informieren. Ein Beispiel für so ein Problem wäre etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der Prüfer bzw. die Hochschule keine Gewähr übernimmt für Probleme mit Ihrer eigenen Ausstattung."
  },
  {
    "objectID": "Pruefung.html#prüfungsrecht",
    "href": "Pruefung.html#prüfungsrecht",
    "title": "1  Prüfung",
    "section": "1.12 Prüfungsrecht",
    "text": "1.12 Prüfungsrecht\nFür die Open-Book-Prüfungg gilt die aktuelle Prüfungsordnung; die Open-Book-Prüfung fällt nicht unter die BayFEV."
  },
  {
    "objectID": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "href": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "title": "1  Prüfung",
    "section": "1.13 Bitte formulieren Sie Beanstandungen nachvollziehbar",
    "text": "1.13 Bitte formulieren Sie Beanstandungen nachvollziehbar\nFalls Sie einen Fehler in einer Aufgabenstellung finden (die der Prüfer zu bestanden hat): Freuen Sie sich! In diesem Fall wird zu Ihren Gunsten entschieden.\nDamit ich Ihre Beanstandung prüfen kann, ist es nötig, dass ich Ihre Beanstandung nachprüfen kann: Zeigen Sie mir meinen Fehler. Es reicht nicht zu sagen “es hat bei mir nicht funktioniert”. Wenn Sie etwa der Meinung sind, dass es die Variable “year” im Datensatz “penguins” nicht gebe, dann schicken Sie mir den R-Code, der an ansprechender Stelle einen Fehler aufwirft (aber ansonsten lauffähig ist). Ein Screenshot kann in einigen Situationen helfen, wenn aber nur ein Teil der Syntax zu sehen ist, ist er nicht ausreichend: Wenn der Befehl data(penguins) nicht funktioniert, so ist zu prüfen, ob Sie vorab mit library(palmerpenguins) das relevante Paket gestartet haben. Andernfalls kann data(penguins) nicht funktionieren und der Fehler läge damit bei Ihnen.\nHier finden Sie Hinweise für einfache, reproduzierbare Beispiele (ERBies); vgl. Sauer (2019), Kap. 3.8.2 (S. 33).\nDie gleiche Messlatte lege ich an mich an: Ich stelle eine Musterlösung (bei der Einsichtnahme) zur Verfügung, die reproduzierbar die Lösung aufzeigt. Sprich: Wenn der R-Code bei mir durchläuft, so wird er auch bei Ihnen durchlaufen."
  },
  {
    "objectID": "Pruefung.html#datenschutz",
    "href": "Pruefung.html#datenschutz",
    "title": "1  Prüfung",
    "section": "1.14 Datenschutz",
    "text": "1.14 Datenschutz\nPersönliche Daten werden an eine Stellen übermittelt: Moodle (über bzw. in Ihre Konto). Es findet keine Überwachung statt, weder kamaragestützt, akustisch oder softwaregestützt."
  },
  {
    "objectID": "Pruefung.html#plagiatskontrolle",
    "href": "Pruefung.html#plagiatskontrolle",
    "title": "1  Prüfung",
    "section": "1.15 Plagiatskontrolle",
    "text": "1.15 Plagiatskontrolle\nIhre Prüfungsarbeiten können auf Plagiate hin untersucht werden. Dabei kommen auch automatisierte Verfahren zum Einsatz. Ihre Arbeiten werden dabei nicht online gestellt und auch nicht Dritten zugänglich gemacht. Alle Prüfungen finden auf Rechnern statt, zu denen nur die Prüfer/innen Zugang habe. Es werden keine persönlichen Daten (von Ihnen) weitergegeben.\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Überlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getäuscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafür bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit “nicht bestanden” bewertet). Die genauen Konsequenzen legt die Prüfungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire Prüfung heißt: Gleiche Chancen für alle, und gute Leistung soll belohnt werden, Täuschung nicht."
  },
  {
    "objectID": "Pruefung.html#typische-fehler-in-der-prüfung",
    "href": "Pruefung.html#typische-fehler-in-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.16 Typische Fehler in der Prüfung",
    "text": "1.16 Typische Fehler in der Prüfung\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heißt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heißt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter “Environment” angezeigt wird. Außerdem können Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort können Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das zugehörige R-Paket gestartet zu haben: Mit data(datensatz) können Sie den Datensatz datensatz nur dann verfügbar machen, wenn das Paket, in dem datensatz “wohnt”, mit library(paketname) gestartet worden ist. So “wohnt” z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Übung (und weitere Erklärung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins.\nVerwenden einer Funktion, ohne das zugehörige R-Paket vorab gestartet zu haben.\nDas Laden zu vieler R-Pakete, die gar nicht benötigt werden, mit dem Ergebnis, dass es mehrere Funktionen des gleichen Namens gibt (z.B. filter()). Das führt dann zu Verwirrung, da dann z.B. nicht die Funktion filter aus tidyverse (dplyr) verwendet wird, wie Sie annehmen, sondern eine Funktion gleichen Namens aus einem anderen Paket, das Sie auch gestartet haben. Tipp: Starten Sie nur die Pakete, die Sie für die Aufgabe benötigen. Zumeist sind das immer die gleichen wenigen Pakete."
  },
  {
    "objectID": "Pruefung.html#hinweise-zu-scheinmängeln",
    "href": "Pruefung.html#hinweise-zu-scheinmängeln",
    "title": "1  Prüfung",
    "section": "1.17 Hinweise zu Scheinmängeln",
    "text": "1.17 Hinweise zu Scheinmängeln\nImmer wieder kommt es vor, dass Studierende Beanstandungen zu einer Prüfung vorbringen. Teilweise sind diese gerechtfertigt, teilweise nicht. Im Folgenden sehen Sie eine Auswahl an nicht gerechtfertigten Beanstandungen, also nur scheinbaren Mängeln, keine wirklichen Mängel, in einer Prüfung.\n\n“Das zu wählende Vorgehen war nicht 100% klar” – Wenn Sie der Meinung sind, dass das zu wählende Vorgehen (zum Lösen der Aufgabe) nicht komplett klar ist, treffen Sie Annahmen und weisen Sie darauf hin, dass Sie Annahmen getroffen haben. Zum anderen halten Sie sich an das Vorgehen aus dem Unterricht (bzw. den Unterlagen und der Literatur, die im Unterricht verwendet wurde). Eine andere Situation läge vor, wenn die Aufgabe nicht lösbar ist ohne weitere Angaben lösbar ist(“Ist ein Effekt bei n=100 signifikant?”). Im Falle einer nicht lösbaren Aufgabe liegt fer Fehler beim Prüfer.\n“Ich sollte einen Punkt (ein Komma) als Dezimaltrennzeichen verwenden, aber Moodle hat ein Komma (einen Punkt) verlangt!” – Je nach Spracheinstellung in Moodle kann es sein, dass Moodle nur einen Punkt als Dezimaltrennzeichen bzw. ein Komma als Dezimaltrennzeichen verwendet. Moodle weist Sie aber darauf hin, wenn eine Zahl nicht als Zahl erkannt wird, und zwar wenn Sie zur nächsten Aufgabe geben. Sie können also ohne Probleme den Fehler korrigieren. Darüber hinaus ist bei den Prüfungshinweisen vorab auf diesen Punkt verwiesen."
  },
  {
    "objectID": "Inferenz.html#lernsteuerung",
    "href": "Inferenz.html#lernsteuerung",
    "title": "2  Inferenz",
    "section": "2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Definition von Inferenzstatistik sowie Beispiele für inferenzstatistische Fragestellungen nennen\nzentrale Begriffe nennen und in Grundzügen erklären\nden Nutzen von Inferenzstatistik nennen\nerläutern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nauch anhand von Beispielen erklären, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs. Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklären können\n\n\n\n2.1.2 Begleitvideos\n\nVideo zur Inferenz, Teil 1\nVideo zur Inferenz, Teil 2"
  },
  {
    "objectID": "Inferenz.html#wozu-ist-statistik-überhaupt-da",
    "href": "Inferenz.html#wozu-ist-statistik-überhaupt-da",
    "title": "2  Inferenz",
    "section": "2.2 Wozu ist Statistik überhaupt da?",
    "text": "2.2 Wozu ist Statistik überhaupt da?\nJa, diese Frage haben Sie sich auch schon mal gestellt?\nAbb. Abbildung 2.1 gibt einen Überblick über die Ziele der Statistik.\n\n\n\n\n\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n\n\n\n\n\nAbbildung 2.1: A taxonomy of statistical goals\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nZiele existieren nicht “in echt” in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heißt, dass man sich nach Beliebem Ziele ausdenken kann. Allerdings hülfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen überzeugen kann."
  },
  {
    "objectID": "Inferenz.html#was-ist-inferenz",
    "href": "Inferenz.html#was-ist-inferenz",
    "title": "2  Inferenz",
    "section": "2.3 Was ist Inferenz?",
    "text": "2.3 Was ist Inferenz?\n\n2.3.1 Inferenz als Generalisieren\nStatistische Inferenz sieht sich drei “Herausforderungen” gegenüber, laut Gelman, Hill, und Vehtari (2021), Kap. 1.1. Diese betreffen das Schließen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\nVon der Stichprobe aus die Grundgesamtheit (Population)\nVon der Experimental- auf die Kontrollgruppe (Kausalinferenz)\nVon einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs beschäftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n\n\n\nWichtig\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schließen, bzw. vom Konrketen auf das Abstrakte."
  },
  {
    "objectID": "Inferenz.html#stichprobe-vs.-population",
    "href": "Inferenz.html#stichprobe-vs.-population",
    "title": "2  Inferenz",
    "section": "2.4 Stichprobe vs. Population",
    "text": "2.4 Stichprobe vs. Population\nNehmen wir an, wir möchten herausfinden, wie groß der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A1.\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\nWir müssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe für die Grundgesamtheit schließen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. Abbildung 2.2.\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nAbbildung 2.2: Population vs. sample (Image credit: Karsten Luebke)\n\n\nHäufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!2. Man schreibt: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei repräsentativ für die Grundgesamtheit aller Studierender. Messerscharf schließen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n2.4.1 Deskriptiv- vs. Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtungen, könnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. Abbildung 2.3. Einteilungen in Schubladen existieren nicht auf der Welt, sondern in unserem Kopf: Sie besitzen keine ontologische Realität, sondern eine epistemologische. Sie sind frei, sich andere Einteilungen der Statistik auszudenken. Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee überzeugen kann.\n\n\n\nAbbildung 2.3: Deskriptiv- vs. Inferenzstatistik\n\n\nDeskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\nInferenzstatistik schließt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\n🏋 Schließen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n2.4.2 Wozu ist die Inferenstatistik gut?\n\n\n\n\n\n\nHinweis\n\n\n\nInferenz bedeutet Schließen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schlüsse zu ziehen.\n🏋️️ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Üben Sie jetzt schon mal.\n\n\n2.4.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFür jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle Tabelle 2.1.\n\n\n\n\nTabelle 2.1: Bezeichnungen für Kennwerte\n\n\nKennwert\nStichprobe\nGrundgesamtheit\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\n\n\n\n\n\nFür Statistiken (Daten einer Stichprobe) verwendet man lateinische Buchstaben; für Parameter (Population) verwendet man griechische Buchstaben.\n🏋️ Geben Sie die griechischen Buchstaben für typische Statistiken an!\n\n\n2.4.4 Schätzen von Parametern einer Grundgesamtheit\nMeist begnügt man sich beim Analysieren von Daten nicht mit Aussagen für eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit Schätzungen begnügen.\nSchätzwerte werden mit einem “Dach” über dem Kennwert gekennzeichnet, z.B.\n\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchätzwert\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n2.4.5 Beispiele für inferenzstatistische Fragestellungen\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\).\nDie Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} > \\bar{X}_{V2}\\)\nSind diese Unterschiede “zufällig” oder “substanziell”? Gilt also \\(\\mu_{V1} > \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)?\nWie groß ist die Wahrscheinlichkeit3 \\(Pr(\\mu_{V1} > \\mu_{V2})\\)?\n\n🏋️ Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!"
  },
  {
    "objectID": "Inferenz.html#modellieren",
    "href": "Inferenz.html#modellieren",
    "title": "2  Inferenz",
    "section": "2.5 Modellieren",
    "text": "2.5 Modellieren\n\n2.5.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft - wie auch oft in der Technik, Wirtschaft oder im Alltag - betrachtet man einen Teil der Welt näher, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berücksichtigen ist nicht möglich. Wir müssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nötig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die für unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\n\n\n\n\n\nWichtig\n\n\n\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n\n\nAuf die Statistik bezogen heißt das, dass man einen Datensatz zu zusammenfasst, dass man das Wesentliche erkennt. Was ist das “Wesentliche”? Meist interessiert man sich für die Ursachen eines Phänomens? Etwa: “Wie kommt es bloß, dass ich ohne zu lernen die Klausur so gut bestanden habe?”4 Noch allgemeiner ist vom häufig am Zusammenhang von X und Y interessiert, s. Abbildung 2.4, linker Teil, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\n\nflowchart LR\nX --> Y\n\n\nX1 --> Y2\nX2 --> Y2\n\n\n\n\n\n\n\n\nAbbildung 2.4: oben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\nDas Diagramm hat Sie nicht so vom Hocker? Okay, ein statistisches Modell kann natürlich komplexer sein, z.B. wie in Abb. Abbildung 2.4, rechter Teil, dargestellt.\nEs hört sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n\n2.5.2 Vertiefung\nLesen Sie die Einführung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nHinweis\n\n\n\nNutzen Sie die Übersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch."
  },
  {
    "objectID": "Inferenz.html#regression",
    "href": "Inferenz.html#regression",
    "title": "2  Inferenz",
    "section": "2.6 Regression",
    "text": "2.6 Regression\nEinflussreiche Leute schwören auf die Regressionsanalyse (Abbildung 2.5).\n\n\n\nAbbildung 2.5: One regression\n\n\n\n2.6.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmessen: Für vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schöner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nHinweis\n\n\n\nRegression + Inferenz = 💖\n\n\nAlternativ zur Regression könnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni Münster als Ausschnitt (!) aufgeführt.\nAuf dieser Basis kann man meditieren, welches statistischen Verfahren man für eine bestimmte Fragestellung verwenden sollte, s. Abb. Abbildung 2.6.\n\n\n\nAbbildung 2.6: Wähle deine Statistik mit Bedacht\n\n\n\n\n2.6.2 Viele statistische Verfahren sind Spezialfälle der Regression\nWie Jonas Kristoffer Lindeløv uns erklärt, sind viele statistische Verfahren, wie der sog. t-Test Spezialfälle der Regression, s. Abb. Abbildung 2.7.\n\n\n\nAbbildung 2.7: Common statistical tests as linear models\n\n\n\n\n2.6.3 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; Abb. Abbildung 2.8.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nAnhan der Gleichung erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet. Dabei wird X nicht mit “fortgeschrittenen” Transformationen wie Quadradieren oder Exponenzieren beglückt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n\n\n\nAbbildung 2.8: Die Regressionsgerade in voller Pracht"
  },
  {
    "objectID": "Inferenz.html#unsicherheit",
    "href": "Inferenz.html#unsicherheit",
    "title": "2  Inferenz",
    "section": "2.7 Unsicherheit",
    "text": "2.7 Unsicherheit\n\n2.7.1 Inferenz beinhaltet Unsicherheit\nInferenzstatistische Schlüsse sind mit Unsicherheit behaftet: Schließlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), möchte aber vom Teil auf das Ganze schließen.\n\n\n\n\n\n\nWichtig\n\n\n\nNichts Genaues weiß man nicht: Schließt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen über das Ganze betrifft.\n\n\nSchließt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. Schließlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen für die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer möglich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n\n\n\n\n\nHinweis\n\n\n\nUnter einem zufälligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nächsten Würfelwurfs. Zufällig bedeutet nicht (zwangsläufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines Würfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\n🏋 Welche physikalischen Randbedingungen wirken wohl auf einen Münzwurf ein?\n\n\n2.7.2 Beispiele zur Quantifizierung von Ungewissheit\nAussagen mit Unsicherheit können unterschiedlich präzise formuliert sein.\n\nMorgen regnet’s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert für Methode \\(A\\) höher als für Methode \\(B\\).\nDie Maschine fällt demnächst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nächsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n🏋 Geben Sie weitere Beispiele an!\n\n\n2.7.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. Abbildung 2.9.\n\nWie (un)gewiss ist man sich über den Wert des Regressionsgewichts?\nWie (un)gewiss ist man sich über den Wert von Y? Schließlich könnte es ja Einflüsse (X) geben, die man nicht berücksichtigt hat.\n\n\n\n\n\n\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 übersehen? .-> B\n\n\n\n\n\n\nAbbildung 2.9: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n\n2.7.4 Ich weiß, was ich nicht weiß: Ungewissheit angeben\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der Schätzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schätzt, lässt aber offen wie sicher (präzise) die Schätzung ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Schätzung schließt sogar 41% oder 43% aus.\n\n\n\n\n\n\nWichtig\n\n\n\nEine Inferenz nennt man auch Schätzung. Es sollte immer die Genauigkeit (Ungewissheit) der Schätzung angegeben werden.\n\n\nIm Rahmen der Regressionsanalyse schlägt sich die Ungewissheit an zwei Stellen nieder:\n\nzur Lage der Regressionsgeraden (\\(\\beta_0\\), \\(\\beta_1\\))\nzu Einflüssen (X), die unser Modell nicht kennt (\\(\\epsilon, \\sigma\\))\n\n\n\n2.7.5 Visualisierung von Ungewissheit\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem Punktschätzer. Punktschäter beinhalten keine Angabe der Schätz(un)gen auigkeit, s. Abb. Abbildung 2.10, links.\n\n\n\n\n\nAbbildung 2.10: Eine Punktschätzung und ihre Ungewissheit\n\n\n\n\nRot markiert: Die Punktschätzung von mpg für hp=200.\n🏋 Geben Sie ein vergleichbares Beispiel an!\nIn Abb. Abbildung 2.10, rechts, ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur Stärke des Zusammenhangs von X und Y?\nAuch wenn wir uns sicher im Hinblick auf die Regressionsgewichte in Abb. Abbildung 2.11 bliebe eine Restungewissheit: Unsere Schätzungen wären auch dann nicht sicher, nicht fehlerfrei. Das liegt daran, da das Modell nicht alle Einflüsse auf Y berücksichtigt, sondern nur einen, hier als X bezeichnet.\nIn Abb. Abbildung 2.11 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die “Restungewissheit” dargestellt. In diesem Fall spricht man von einem “Vorhersageintervall”, da man nicht nur von “typischen Fällen” auf der Regressiongeraden spricht, sondern für echte Fälle Vorhersagen (Schätzungen) tätigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n\n\n\nAbbildung 2.11: Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\n\n\n\n\nWie man sieht, wird die Ungewissheit größer, wenn man beide Arten der Ungewissheit berücksichtigt. Das Vorhersage-Intervall berücksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\n\n2.7.6 Konfidenzintervall\nWir sehen hier, dass ein “Ungewissheitskorridor” angegeben wird. Entsprechend wird nicht ein Punktschätzer, sondern ein Schätzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich5\nEin Konfidenzintervall wird häufig mit 90% oder 95% Genauigkeit angegeben. Im Kontext der Bayes-Analyse ist das einfach zu interpretieren. Sagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall für den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt. Dieser Befund läßt sich so interpretieren: “Laut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.”\n\n\n\n\n\n\nWichtig\n\n\n\nEin Konfidenzintervall gibt einen Schätzbereich plausibler Werte für den gesuchten Wert in der Population (den Parameter) an.\n\n\n🏋 Interpretieren Sie den Ungewissheitskorridor!"
  },
  {
    "objectID": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "2  Inferenz",
    "section": "2.8 Klassische vs. Bayes-Inferenz",
    "text": "2.8 Klassische vs. Bayes-Inferenz\n\n2.8.1 Klassische Inferenz: Frequentismus\n\nDie Berücksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurückgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein\nWahrscheinlichkeit wird über relative Häufigkeiten definiert.\nEs ist nicht möglich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie häufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr häufig wiederholt ist.\nEin Großteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.8.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) fließt explizit in die Analyse ein (zusammen mit den Daten).\nWenn das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen für Hypothesen möglich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (für gängige Computer) komfortabel geworden.\n\n\n\n2.8.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.8.3.1 Frequentismus\nDie zentrale Statistik heißt der p-Wert\nDer p-Wert ist so definiert: “Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufällig verschieden und auf Basis unseres Modells)?”\nFindet man \\(p<.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von “(statistischer) Signifikanz” und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n\n2.8.3.2 Bayes-Statistik\nDie zentrale Statistik ist die Posteriori-Verteilung.\nDie Posteriori-Verteilung beantwortet uns die Frage: “Wie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?”\n🏋 Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\nIn diesem Post wird für Bayes geworben und (vielleicht einseitig) Stellung pro Bayes bezogen.\n\n\n\n2.8.4 Frequentist und Bayesianer\nIm Cartoon 1132 von xkcd wird sich über das Nicht-Berücksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. Abbildung 2.12.\n\n\n\nAbbildung 2.12: Frequentist wettet mit Bayesianer\n\n\nQuelle\n\n\n2.8.5 Der p-Wert ist wenig intuitiv\n\n\nfrom Imgflip Meme Generator\n\n\n\n2.8.6 Beispiel zum Nutzen von Apriori-Wissen 1\nEin Betrunkener behauptet, er könne hellsehen. Er wirft eine Münze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die Münze fair ist, dass Ergebnis also “zufällig” ist.\nUnser Vorwissen lässt uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zufälligkeit des Ergebnisses wohl nicht verwerfen.\n\n\n2.8.7 Beispiel zum Nutzen von Apriori-Wissen 2\nEine Studie (vgl. Gelman, Hill, und Vehtari (2021)) fand einen “großen Effekt” auf das Einkommen von Babies, eine Stunde pro Woche während zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\).\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% höher (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lässt uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lässt. Wir würden den Effekt lieber in einem konservativeren Intervall schätzen (enger um Null)."
  },
  {
    "objectID": "Inferenz.html#literatur",
    "href": "Inferenz.html#literatur",
    "title": "2  Inferenz",
    "section": "2.9 Literatur",
    "text": "2.9 Literatur\nBei Gelman, Hill, und Vehtari (2021), Kap. 1 findet sich eine Darstellung ähnlich zu der in diesem Kapitel."
  },
  {
    "objectID": "Inferenz.html#aufgaben",
    "href": "Inferenz.html#aufgaben",
    "title": "2  Inferenz",
    "section": "2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2\ninferenz-fuer-alle\nadjustieren1\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  },
  {
    "objectID": "Wskt.html#lernsteuerung",
    "href": "Wskt.html#lernsteuerung",
    "title": "3  Wahrscheinlichkeit",
    "section": "3.1 Lernsteuerung",
    "text": "3.1 Lernsteuerung\n\n3.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Grundbegriffe der Wahrscheinlichkeitsrechnung erläuternd definieren\ndie drei Arten der direkten Ermittlung von Wahrscheinlichkeit erläutern\ntypische Relationen (Operationen) von Ereignissen anhand von Beispielen veranschaulichen\nmit Wahrscheinlichkeiten rechnen\n\n\n\n3.1.2 Prüfungsrelevanter Stoff\nLesen Sie dazu Bourier (2018), Kap. 2-4. Weitere Übungsaufgaben finden Sie im dazugehörigen Übungsbuch, Bourier (2022).\n\n\n3.1.3 Zentrale Begriffe\n\n3.1.3.1 Grundbegriffe\n\nZufallsvorgang (Zufallsexperiment)\nElementarereignis\nEreignisraum\nZufallsereignis (zufälliges Ereignis)\nSicheres Ereignis\nUnmögliches Ereignis\n\n\n\n3.1.3.2 Wahrscheinlichkeitsbegriffe\n\nKlassische Wahrscheinlichkeit (LaPlace’sche Wahrscheinlichkeit)\nStatistische (empirische) Wahrscheinlichkeitsermittlung\nSubjektive (Bayes) Wahrscheinlichkeitsermittlung\n\n\n\n3.1.3.3 Wahrscheinlichkeitsrelationen\n\nVereinigung von Ereignissen\nSchnitt(menge) von Ereignissen\nKomplementärereignis\nVollständiges Ereignissystem\nKolmogorovs Definition von Wahrscheinlichkeit\n\n\n\n3.1.3.4 Wahrscheinlichkeitsrechnung\n\nAllgemeiner Additionsssatz\nDisjunkte Ereignisse\nAdditionssatz für disjunkte Ereignisse\nBedingte Wahrscheinlichkeit\n(Stochastische) Unabhängigkeit\nBaumdiagramm für gemeinsame Wahrscheinlichkeit\nAllgemeiner Multiplikationssatz\nMultiplikationssatz für unabhängige Ereignisse\nTotale Wahrscheinlichkeit\nSatz von Bayes\n\n\n\n\n3.1.4 Begleitvideos\n\nVideo zum Thema Wahrscheinlichkeit"
  },
  {
    "objectID": "Wskt.html#unterstützung-wahrscheinlichkeit-in-bildern",
    "href": "Wskt.html#unterstützung-wahrscheinlichkeit-in-bildern",
    "title": "3  Wahrscheinlichkeit",
    "section": "3.2 Unterstützung: Wahrscheinlichkeit in Bildern",
    "text": "3.2 Unterstützung: Wahrscheinlichkeit in Bildern\nWahrscheinlichkeit in Bildern: zur einfachen Erschließung des Materials, ein Unterstützungsangebot.\nIm Folgenden sind einige Schlüsselbegriffe und -regeln in (ver-)einfach(t)er Form schematisch bzw. visuell dargestellt mit dem Ziel, den Stoff einfacher zu erschließen.\n\n3.2.1 Zufall\nWerfen Sie eine Münze!\nDiese hier zum Beispiel:\n\n\n\n\n\nQuelle: By OpenClipartVectors, CC0\nWiederholen Sie den Versuch 10, nein, 100, nein 1000, nein: \\(10^6\\) Mal.\nNotieren Sie das Ergebnis!\nOder probieren Sie die App der Brown University.\n\n\n3.2.2 Relationen von Mengen\nVenn-Diagramme eigenen sich, um typische Operationen (Relationen) auf Mengen zu visualisieren.\n\n3.2.2.1 Überblick\nDie folgenden Diagramme stammen von Wikipedia (En).\nWir gehen von Ereignisraum \\(\\Omega\\) aus, mit dem Ereignis \\(A\\) als Teilmenge: \\(A \\subset B\\).\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\n\n\n\n\n\n\n\\(A \\cup B\\)\n\n\n\n\n\n\n\n\n\n\\(\\bar{A}\\)\n\n\n\n\n\n\n\n\\(A \\setminus B\\)\n\n\n\n\nAbbildung 3.1: Typische Mengenoperationen\n\n\n\n\n3.2.2.2 Disjunkte Ereignisse\n(Engl. disjoint events)\n\\(A= \\{1,2,3\\}; B= \\{4,5,6\\}\\)\n\\(A\\) und \\(B\\) sind disjunkt: ihre Schnittmenge ist leer: \\(A \\cap B = \\emptyset\\), s. ?fig-disjunkt\n\n\n\n\n\n\n\n3.2.2.3 Eselsbrücke zur Vereinigungs- und Schnittmenge\nDas Zeichen für eine Vereinigung zweier Mengen kann man leicht mit dem Zeichen für einen Schnitt zweier Mengen leicht verwechseln; daher kommt eine Eselbrücke gelesen, s. Abbildung 3.2.\n\n\n\nAbbildung 3.2: Eselsbrücke für Vereinigungs- und Schnittmenge\n\n\nQuelle: rither.de\n\n\n3.2.2.4 Animationen\nAnimation zu Mengenoperationen\nAnimation zur Vereinigung von Mengen\nQuelle\n\n\n\n3.2.3 Additionssatz\nDer Additionssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass mindestens eines der Ereignisse eintritt.\n\n3.2.3.1 Diskunkte Ereignisse\n\\(\\Omega = {1,2,3,4,5,6}\\)\n\\(\\boxed{1\\; 2\\; 3\\; 4\\; 5\\; 6}\\)\nGesucht sei die Wahrscheinlichkeit des Ereignis \\(A=\\{1,2\\}\\).\n\\(\\boxed{\\boxed{1\\; 2}\\; \\color{gray}{ 3\\; 4\\; 5\\; 6}}\\)\n\\(P(1 \\cup 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\)\n\n\n3.2.3.2 Allgemein (disjunkt oder nicht disjunkt)\nBei der Addition der Wahrscheinlichkeiten für \\(A\\) und \\(B\\) wird der Schnitt \\(A\\cap B\\) doppelt erfasst. Er muss daher noch abgezogen werden (vgl. Abbildung 3.3):\n\\[P(A \\cup B) = P(A) + P(B) - P(A\\cap B)\\]\n\n\n\n\n\n\n\n\\(A \\cup B\\)\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\n\n\n\nAbbildung 3.3: Die Schnittmenge muss beim Vereinigen abgezogen werden, damit sie nicht doppelt gezählt wird.\n\n\n\n\n\n3.2.4 Bedingte Wahrscheinlichkeit\n\n3.2.4.1 Animation\nSchauen Sie sich mal diese Wahnsinnsanimation von Victor Powell an. Hammer!\n\n\n3.2.4.2 Schema\nAbb. Abbildung 3.4 illustriert gemeinsame Wahrscheinlichkeit, $P(A B) und bedingte Wahrscheinlichkeit, \\(P(A|B)\\).\n\n\n\n\n\nAbbildung 3.4: Illustration von gemeinsamer und bedingter Wahrscheinlichkeit\n\n\n\n\nBedingte Wahrscheinlichkeit ist vergleichbar zu Filtern einer Tabelle:\n\n\nCode\nd <- \n  tibble::tribble(\n      ~id, ~A, ~B,\n      \"1\", 0L, 0L,\n      \"2\", 0L, 1L,\n      \"3\", 1L, 0L,\n      \"4\", 1L, 1L,\n  \"SUMME\", 2L, 2L\n  )\n\n\nEs ergeben sich folgende Wahrscheinlichkeiten:\n\\(P(A) = 2/4\\)\n\\(P(B) = 2/4\\)\n\\(P(A \\cap B) = 1/4\\)\n\\(P(A|B) = 1/2\\)\n\n\n\n3.2.5 (Un-)Abhängigkeit\nStochastische Unabhängigkeit ist ein Spezialfall von Abhängigkeit: Es gibt sehr viele Ausprägungen für Abhängigkeit, aber nur eine für Unabhängigkeit. Können wir Unabhängigkeit nachweisen, haben wir also eine starke Aussage getätigt.\n\n\n\nAbhängig, s. Abbildung 3.5, links: Überleben auf der Titanic ist offenbar abhängig von der Passagierklasse. Auf der anderen Seite: Das Ereignis Überleben auf der Titanic ist unabhängig vom Ereignis Alter ist eine Primzahl, s. Abbildung 3.5, rechts.\n\n\n\n\n\nAbbildung 3.5: Abhängigkeit und Unabhängigkeit zweier Ereignisse\n\n\n\n\nZur Ab- bzw. Un-Abhängigkeit zweier Variablen, an Beispielen illustriert.\n\nBeispiel 3.1 (Zusammenhang von Covidsterblichkeit und Impfquote) Sind die Ereignisse Tod durch Covid bzw. Impfquote (\\(A\\)) und Land1 (\\(B\\)) voneinander abhängig (Abb. Abbildung 3.6)?\n\n\n\n\n\nAbbildung 3.6: Impfquote und Sterblichkeit sind voneinander abhängig (bezogen auf Covid, auf Basis vorliegender Daten)\n\n\n\n\nJa, da in beiden Diagrammen gilt: \\(P(A|B) \\ne Pr(A) \\ne Pr(A|\\neg B)\\).\nDaten von Our World in Data.\n\n\n\n3.2.6 Multiplikationssatz\nDer Multiplikationssatz wird verwendet, wenn wir an der Wahrscheinlichkeit interessiert sind, dass alle Ereignisse eintreten.\n\n3.2.6.1 Unabhängige Ereignisse\nWir werfen eine faire Münze zwei Mal (Abb. Abbildung 3.7).\n\n\n\nAbbildung 3.7: Wir werfen 2 faire Münzen\n\n\nAbb. Abbildung 3.7 zeigt ein Baumdiagramm. Jeder Kasten (Knoten) zeigt ein Ergebnis. Die Pfeile (Kanten) symbolisieren die Abfolge des Experiments: Vom “Start” (schwarzer Kreis) führen zwei mögliche Ergebniss ab, jeweils mit Wahrscheinlichkeit 1/2. Die untersten Knoten nennt man auch Blätter (Endknoten), sie zeigen das Endresultat des (in diesem Fall) zweifachen Münzwurfs. Der Weg vom Start zu einem bestimmten Blatt nennt man Pfad. Die Anzahl der Pfade entspricht der Anzahl der Blätter. In diesen Diagramm gibt es vier Pfade (und Blätter).\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n\n0K\n1/2 * 1/2 = 1/4\n\n\n1K\n1/4 + 1/4 = 1/2\n\n\n2K\n1/2 * 1/2 = 1/4\n\n\n\n\n\n\nWir werfen eine faire Münze drei Mal (Abb. Abbildung 3.8)\n\n\n\nAbbildung 3.8: Wir werfen drei faire Münzen\n\n\n\n\n\n\n\n\nEreignis\nPr\n\n\n\n\n0K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n1K\n1/8 + 1/8 + 1/8 = 3/8\n\n\n2K\n3 * 1/8 = 3/8\n\n\n3K\n1/2 * 1/2 * 1/2 = 1/8\n\n\n\n\n\n\n\\(Pr(AB) = Pr(A) \\cdot Pr(B) = 50\\% \\cdot 50\\% = 25\\%\\)\n\n\n\n\n\nAbbildung 3.9: Unabhängige Ereignisse visualisiert\n\n\n\n\nAbb. Abbildung 3.9 zeigt, dass gilt: \\(P(A\\cap B) = P(A) \\cdot P(B) = P(B) \\cdot P(A)\\).\n\n\n3.2.6.2 Kalt und Regen\nVon McElreath (2020) stammt diese Verdeutlichung der gmeinsamen Wahrscheinlichkeit:\nWas ist die Wahrscheinlichkeit für kalt ❄ und Regen ⛈️?\nDie Wahrscheinlichkeit für kalt und Regen ist die Wahrscheinlichkeit von Regen ⛈, wenn’s kalt ❄ ist mal die Wahrscheinlichkeit von Kälte ❄.\nEbenfalls gilt:\nDie Wahrscheinlichkeit für kalt und Regen ist die Wahrscheinlichkeit von Kälte ❄, wenn’s regnet ⛈️ mal die Wahrscheinlichkeit von Regen ⛈️.\nDas Gesagte als Emoji-Gleichung:\n\\(P(❄️ und ⛈️) = P(⛈️ |❄️ ) \\cdot P(❄️) = P(❄️ |⛈️ ) \\cdot P(⛈️) = P(⛈️ und ❄️)\\)\nAllgemein:\n\\(P(A\\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\nMan kann also die “Gleichung drehen”.\n\n\n3.2.6.3 Abhängige Ereignisse\nEin Baumdiagramm bietet sich zur Visualisierung abhängiger Ereignisse an, s. Abb. Abbildung 3.10. Für unabhängige Ereignisse übrigens auch.\nIn einer Urne befinden sich fünf Kugeln, von denen vier rot sind und eine blau ist.\nwie groß ist die Wahrscheinlichkeit, dass bei zwei Ziehungen ohne Zurücklegen (ZOZ) zwei rote Kugeln gezogen werden (Bourier 2018), S. 47.\nHier ist unsere Urne:\n\\[\\boxed{\\color{red}{R, R, R, R}, \\color{blue}B}\\]\nUnd jetzt ziehen wir. Hier ist das Baumdiagramm, s. Abb. Abbildung 3.10.\n\n\n\n\n\nflowchart LR\n  A[Start] -->|4/5|B[1. Zug: R]\n  A -->|1/5|C[1. Zug: B]\n  B -->|3/4|D[2. Zug: R]\n  B -->|1/4|E[2. Zug: B]\n  D --- H[Fazit: RR:  12/20]\n  E --- I[Fazit: RB: 4/20]\n  C -->|4/4|F[2. Zug: R]\n  C -->|0/4|G[2. Zug: B]\n  F --- J[Fazit: BR: 4/20]\n  G --- K[Fazit: BB: 0/20]\n\n\n\n\n\nAbbildung 3.10: Baumdiagramm für ein ein zweistufiges Zufallsereignis, wobei der 2. Zug (Stufe) abhängig ist vom 1. Zug.\n\n\n\n\nEs gilt also: \\(P(A\\cap B) = P(A) \\cdot P(B|A)\\).\n\n\n\n3.2.7 Totale Wahrscheinlichkeit\nAbbildung 3.11 zeigt das Baumdiagramm für die Aufgabe Bourier (2018), S. 56.\n\n\n\n\n\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -->|0.1|C[A2]\n  A -->|0.3|D[A3]\n  B -->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n\n\n\n\n\nAbbildung 3.11: Totale Wahrscheinlichkeit\n\n\n\n\nGesucht ist die Wahrscheinlichkeit \\(P(B)\\).\nDazu addieren wir die Warhscheinlichkeiten der relevanten Äste.\n\n\nCode\nW_total <- 0.6 * 0.05 + 0.1 * 0.02 + 0.3 * 0.04\nW_total\n## [1] 0.044\n\n\nDie totale Wahrscheinlichkeit beträgt also \\(P(B) = 4.4\\%\\).\nEinfacher noch ist es, wenn man anstelle von Wahrscheinlichkeiten absolute Häufigkeiten verwendet.\n\n\n3.2.8 Bayes\n\n3.2.8.1 Bayes als Baum\nGesucht sei \\(P(A_1|B)\\).\nFür Bayes’ Formel setzt man die Wahrscheinlichkeit des günstigen Ast zur Wahrscheinlichkeit aller relevanten Äste, \\(P(B)\\).\nDer günstige Ast ist hier schwarz gedruckt, die übrigen Äste gestrichelt, s. Abbildung 3.12.\n\n\n\n\n\nflowchart LR\n  A[Start] -->|0.6|B[A1]\n  A -.->|0.1|C[A2]\n  A -.->|0.3|D[A3]\n  B --->|0.05|E[B]\n  B -.->|0.95|F[Nicht-B]\n  C -.->|0.02|G[B]\n  C -.->|0.98|H[Nicht-B]\n  D -.->|0.04|I[B]\n  D -.->|0.96|J[Nicht-B]\n\n\n\n\n\nAbbildung 3.12: Günstige Pfade\n\n\n\n\n\\[P(A|B) = \\frac{P(A1 \\cap B)}{P(B)} = \\frac{0.6 \\cdot 0.05}{0.03 + 0.002 + 0.012} = \\frac{0.03}{0.044} \\approx 0.68\\]\n\\(P(A|B)\\) beträgt also ca. 68%.\nZur Erinnerung: \\(P(B)\\) ist die totale Wahrscheinlichkeit."
  },
  {
    "objectID": "Wskt.html#bayes-theorem",
    "href": "Wskt.html#bayes-theorem",
    "title": "3  Wahrscheinlichkeit",
    "section": "3.3 Bayes’ Theorem",
    "text": "3.3 Bayes’ Theorem\n\n3.3.1 Bayes als bedingte Wahrscheinlichkeit\nBayes’ Theorem ist auch nur eine normale bedingte Wahrscheinlichkeit:\n\\(P(A|B) = \\frac{\\overbrace{ P(A\\cap B)}^\\text{umformen}}{P(B)}\\)\n\\(P(A\\cap B)\\) kann man umformen, s. Gleichung 3.1:\n\\[P(A|B) =\\frac{P(A\\cap B)}{P(B)} = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\tag{3.1}\\]\nMan kann sich Bayes’ Theorem auch wie folgt herleiten:\n\\(P(A\\cap B) = P(B \\cap A) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\nDann lösen wir nach P\\((A|B)\\) auf:\n\\(P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(B)}\\)\n\n\n3.3.2 Wozu wird Bayes in der Praxis genutzt?\nIn der Praxis nutzt man Bayes häufig, wenn man Daten zu einer Wirkung \\(W\\) hat, und auf die Ursache \\(U\\) zurückschließen möchte, sinngemäß:\n\\(W \\quad \\underrightarrow{Bayes} \\quad U\\).\nDann kann man Gleichung 3.1 so schreiben, s. Gleichung 3.2:\n\\[P(U|W) = \\frac{ P(U) \\cdot P(W|U) }{P(W)} \\tag{3.2}\\]\nEine ähnliche Situation, die in der Praxis häufig ist, dass man Daten \\(D\\) hat und auf die Wahrscheinlichkeit einer Hypothese \\(H\\) schließen möchte, s. Gleichung 3.3.\n\\(D \\quad \\underrightarrow{Bayes} \\quad H\\).\n\\[P(H|D) = \\frac{ P(H) \\cdot P(D|H) }{P(D)} \\tag{3.3}\\]\nGleichung 3.3 fragt nach \\(P(H|D)\\):\n\nWas ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)\n\nUnd antwortet so (Gleichung 3.3):\n\nDiese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der Plausibilität (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgründen dividiert man noch die totale Wahrscheinlichkeit der Daten über alle Hypothesen.\n\n\n\n3.3.3 Zusammengesetzte Hypothesen\nDas ist vielleicht ein bisschen fancy, aber man kann Bayes’ Theorem auch nutzen, um die Wahrscheinlichkeit einer zusammengesetzten Hypothese zu berechnen: \\(H = H_1 \\cap H_2\\). Ein Beispiel wäre: “Was ist die Wahrscheinlichkeit, dass es Regen (\\(R\\)) und Blitzeis (\\(B\\)) gibt, wenn es kalt (\\(K\\)) ist?”.\nDas sieht dann so aus, Gleichung 3.4:\n\\[\n\\begin{aligned}\nP(R \\cap B |K) &= \\frac{ P(R \\cap B) \\cdot P(K|R \\cap B) }{P(D)} \\\\\n&= \\frac{ P(R ) \\cdot P(B) \\cdot P(K|R \\cap B) }{P(D)}\n\\end{aligned}\n\\tag{3.4}\\]\nHier haben wir \\(P(R \\cap B)\\) aufgelöst in \\(P(R) \\cdot P(B)\\), das ist nur zulässig, wenn \\(R\\) und \\(B\\) unabhängig sind.\n\n3.3.3.1 Bayes-Video von 3b1b\nDas Video zu Bayes von 3b1b verdeutlicht das Vorgehen der Bayes-Methode auf einfache und anschauliche Weise."
  },
  {
    "objectID": "Wskt.html#aufgaben",
    "href": "Wskt.html#aufgaben",
    "title": "3  Wahrscheinlichkeit",
    "section": "3.4 Aufgaben",
    "text": "3.4 Aufgaben\nZusätzlich zu den Aufgaben im Buch:\n\nmtcars-abhaengig\nvoll-normal\ncorona-blutgruppe\nBed-Wskt2\nGem-Wskt1\nwuerfel01\nwuerfel02\nwuerfel03\nwuerfel04\n\n\n\n\n\nBourier, Günther. 2018. Wahrscheinlichkeitsrechnung und schließende Statistik: praxisorientierte Einführung: mit Aufgaben und Lösungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik – Wahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "Verteilungen.html",
    "href": "Verteilungen.html",
    "title": "4  Verteilungen",
    "section": "",
    "text": "Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nden Begriff der Zufallsvariablen erläutern\ndie Begriffe von Wahrscheinlichkeitsdichte und Verteilungsfunktion erläutern und anhand einfacher Beispiele ausrechnen\nden Begriff einer Gleichverteilung erläutern und einfache Fallbeispiele ausrechnen\ndie Parameter einer Normalverteilung nennen und erläutern\n\n\n\n\nLesen Sie zusätzlich zum Stoff dieses Kapitels noch Bourier (2018), folgende Abschnitte:\n\nKap. 6.1 (Zum Begriff Zufallsvariable)\nKap. 6.3 (Stetige Zufallsvariablen)\nKap. 7.1.1 (Binomialverteilung)\nKap. 7.2.1 (Gleichverteilung) und 7.2.3 (Normalverteilung)\n\nLösen Sie auch die Übungsaufgaben dazu.\nWeitere Übungsaufgaben finden Sie im dazugehörigen Übungsbuch, Bourier (2022).\n\n\n\n\n\nCode\nlibrary(patchwork)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\nZufallsvariable (random variable)\nDiskret vs. stetig\nWahrscheinlichkeitsdichte (Dichte, (probability) density, f)\nWahrscheinlichkeitsfunktion (kumulierte Wahrscheinlichkeit, Wahrscheinlichkeitsmasse)\n\n\n\n\n\nGleichverteilung\nNormalverteilung\nStandardnormalverteilung\n\n\n\n\n\n\nVideo 1 zum Thema Verteilungen\nVideo 2 zum Thema Verteilungen"
  },
  {
    "objectID": "Verteilungen.html#verteilungen-1",
    "href": "Verteilungen.html#verteilungen-1",
    "title": "4  Verteilungen",
    "section": "4.2 Verteilungen",
    "text": "4.2 Verteilungen\n\n\n\n\n\n\nWichtig\n\n\n\nEine Verteilung zeigt, welche Ausprägungen eine Variable aufweist und wie häufig bzw. wahrscheinlich diese sind. Einfach gesprochen, veranschaulicht eine Balken- oder Histogramm eine Verteilung. Man unterscheidet Häufigkeitsverteilungen (s. Abb. Abbildung 4.1) von Wahrscheinlichkeitsverteilungen (Abb. Abbildung 4.2).\n\n\n\n4.2.1 Häufigkeitsverteilung\nDie Häufigkeitsverteilung eines diskreten Merkmals \\(X\\) mit \\(k\\) Ausprägungen zeigt, wie häufig die einzelnen Ausprägungen sind. So hat die Variable Zylinder (in einem Datensatz) etwa die Ausprägungen 4,6 und 8.\n\n\nCode\ndata(mtcars)\n  mtcars %>% \n    count(cyl)\n\n\n\n\n\n\ncyl\nn\n\n\n\n\n4\n11\n\n\n6\n7\n\n\n8\n14\n\n\n\n\n\n\nAbb. Abbildung 4.1, links, visualisiert die Häufigkeitsverteilung von cyl.\n\n\n\n\n\nAbbildung 4.1: Häufigkeitsverteilung von cyl und hp (diskretisiert in 10 Körbe oder Gruppen)\n\n\n\n\n:::\nEin stetiges Merkmal, wie hp (PS-Zahl), lässt sich durch Klassenbildung diskretisieren, s. Abb. ?fig-mtcars-freq-dens, rechts.\n\n\n4.2.2 Wahrscheinlichkeitsverteilung\nWahrscheinlichkeitsverteilungen dienen dazu, Ereignissen einer Zufallsvariable eine Wahrscheinlichkeit zuzuordnen.\nEine diskrete Wahrscheinlichkeitsverteilung der (diskreten) Zufallsvariablen \\(X\\) ordnet jeder der \\(k\\) Ausprägungen \\(X=x\\) eine Wahrscheinlichkeit \\(p\\) zu. So hat die Variable Geschlecht eines Babies die beiden Ausprägungen Mädchen und Junge mit den Wahrscheinlichkeiten \\(p_M = 51.2\\%\\) bzw. \\(p_J = 48.8\\%\\) (Gelman, Hill, und Vehtari 2021).\nBei stetigen Zufallsvarialben \\(X\\) geht man von unendlich vielen Ausprägungen aus; die Wahrscheinlichkeit einer bestimmten Ausprägung ist (praktisch) Null: \\(p(X=x_j)=0, \\quad j=1,...,+\\infty\\). So ist die Wahrscheinlichkeit, dass eine Person exakt 166,66666666… cm groß ist, (praktisch) Null. Man gibt stattdessen die Dichte der Wahrscheinlichkeit an: Das ist die Wahrscheinlichkeit(smasse) pro Einheit von \\(X\\)."
  },
  {
    "objectID": "Verteilungen.html#gleichverteilung",
    "href": "Verteilungen.html#gleichverteilung",
    "title": "4  Verteilungen",
    "section": "4.3 Gleichverteilung",
    "text": "4.3 Gleichverteilung\n\n4.3.1 Indifferenz als Grundlage\nEine Gleichverteilung nimmt an, dass jeder Wert im Ergebnisraum der zugehörigen Zufallsvariable gleichwahrscheinlich ist. Wenn man keinen hinreichenden Grund hat, eine Realisation einer Zufallsvariablen für plausibler als einen anderen zu halten, ist eine Gleichverteilung eine passende Verteilung. Gleichverteilungen gibt es im diskreten und im stetigen Fall.\nAbb. Abbildung 4.2 zeigt ein Beispiel für eine (stetige) Gleichverteilung.\n\n\n\n\n\nAbbildung 4.2: Gleichverteilung min=-1, max=1\n\n\n\n\nBei \\(X=0\\) hat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 50%.\nDefinierendes Kennzeichen einer Gleichverteilung ist die konstante Dichte.\n\n\n4.3.2 Simulation\nMöchte man die Verteilungsfunktion einer stetigen Zufallsvariablen berechnen, kann das ganz schön kompliziert werden, schließlich muss man Integrale lösen. Aber es gibt einen Trick, wie man die Sache stark vereinfachen kann: man simuliert die Verteilung. Was bedeutet das?\nAngenommen, die Wartezeit auf einen Bus ist gleichverteilt (engl. uniform distribution); der Bus kommt regelmäßig und püunktlich alle 10 Minuten. Die minimale Wartezeit beträgt also 0 Minuten und die maximale 10 Minuten. Nennen wir die zugehörige Zufallsvariable \\(X\\), das ist schön kurz.\nDann schreibt man auch:\n\\[X \\sim Unif(0,10).\\]\nJa, das sieht fancy aus, aber wo ist der versprochene Trick zum Vereinfachen? Kommt gleich, Moment.\nEine Frage könnte nun lauten, wie groß ist die Wahrscheinlichkeit, dass man zwischen 3 und 5 Minuten auf den Bus warten muss?\nDer Trick ist, dass wir Integralrechnung gegen stumpfes Zählen eintauschen.\nComputer (und damit R) haben eingebaut Funktionen, die eine beliebige Zufallszahl ziehen können, zum Beispiel gleichverteilt\nAuf Errisch heißt das Zauberwort runif():\n\n\nCode\nrunif(n = 1, min = 0, max = 10)\n\n\n\n## [1] 9.14806\n\nAuf Deutsch heißt das: “Hey R, ich hätte gerne eine (daher n = 1) Zufallszahl r wie random, die gleichverteilt ist (uniform) mit min = 0 und max = 10.\n(Zu) anschaulich gesprochen: R hat den Bus kommen lassen und es hat gut 9.1 Minuten gedauert, bis er da war.\nAchtung, jetzt kommt’s: Jetzt lassen wir R mal \\(10^5\\) (1e5 auf Computersprech) Busse vorfahren. R soll jedes Mal notieren, wie lange man auf den Bus warten musste.1\n\n\nCode\nx_simu <- runif(n = 1e5, min = 0, max = 10)\n\n\n\n\n\nSchauen wir uns die Verteilung an, Abbildung 4.3.\n\n\nCode\nggplot(x_simu_df) +\n  aes(x = x_simu) +\n  geom_histogram(bins = 50)\n\n\n\n\n\nAbbildung 4.3: Simulation einer gleichverteiluten Zufallsvariablen\n\n\n\n\nOkay, unsere Verteilung sieht nicht exakt gleichverteilt, aber einigermaßen. Gut genug für unsere Zwecke!\nSo, und jetzt kommt das Ernten. Wir können jetzt nämlich einfach zählen (count()), um die Antwort auf unsere Frage (der Wartezeit 3-5 Min.) zu erhalten.\n\n\nCode\nx_simu_df %>% \n  count(Schnittmenge = x > 3 & x < 5)\n\n\n\n\n\n\nSchnittmenge\nn\n\n\n\n\nFALSE\n80072\n\n\nTRUE\n19928\n\n\n\n\n\n\nDas Zeichen & ist das logische UND, also die Schnittmenge der zwei Mengen \\(A := \\{x|x>3\\}\\) und \\(B := \\{x|x<5\\}\\), also \\(A \\cap B\\).\nWie man sieht, fallen ca. 20% der Stichproben in den entsprechenden Bereich.\nDa viele Probleme, wenn sie komplexer werden, kaum noch analytisch (wie Integrieren) ausrechenbar sind, greift man in der modernen (Analyse-)Welt oft lieber auf Simulationsverfahren zurück - Dank sei den schnellen Rechnern. Für uns Menschen ist damit die Aufgabe des Integrierens auf schnödes Zählen zurückgeführt."
  },
  {
    "objectID": "Verteilungen.html#sec-bin-distrib",
    "href": "Verteilungen.html#sec-bin-distrib",
    "title": "4  Verteilungen",
    "section": "4.4 Binomialverteilung",
    "text": "4.4 Binomialverteilung\n\n\n\n\n\n\nWichtig\n\n\n\nDie Binomialverteilung dient zur Darstellung der Wahrscheinlichkeit der Ergebnisse eines wiederholten binomialen Zufallexperiments, eines Zufallsexperiments mit zwei Ergebnissen also. Typisches Beispiel ist ein Münzwurf. Bei jeder Wiederholung des Zufallexperiments bleibt die Wahrscheinlichkeit der Ergebnisse gleich: Die Münze verändert sich nicht durch die Würfe (Ziehen mit Zurücklegen). Außerdem hat ein bestimmtes Ergebnis im ersten Wurf keinen Einfluss auf die Wahrscheinlichkeit eines bestimmten Ergebnisses im zweiten Wurf, etc.\n\n\n\n4.4.1 Veranschaulichung\nStellen wir uns eine Kistchen2 mit 5 Losen vor, darunter 2 Treffer (Gewinn) und 3 Nieten, s. Abb. Abbildung 4.4. Der Versuch läuft so ab: Wir ziehen ein Los, schauen ob es ein Treffer ist oder nicht, legen es zurück und ziehen erneut.\n\n\n\n\n\nAbbildung 4.4: Ein Kästchen mit 5 Losen, darunter 2 Treffer und 3 Nieten.\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nUm die Wahrscheinlichkeitsverteilung einer binomialverteilte Zufallsvariable ausrechnen zu können, muss man zwei Dinge wissen: Erstens die Anzahl der Züge, \\(n\\) (Stichprobengröße) und zweitens die Trefferwahrscheinlichkeit, \\(p\\).\n\n\nWie groß ist die Wahrscheinlichkeit von \\(A^{\\prime}\\), d.h. bei \\(n=4\\) Zügen \\(x=2\\) Treffer zu erzielen, gegeben dass die Trefferwahrscheinlichkeit bei \\(p=2/4\\) liegt?\nWir könnten jetzt ein Baumdiagramm zeichnen und pro Pfad die Wahrscheinlichkeit ausrechnen (Multiplikationssatz), s. Abbildung 3.8. Die Summe der Wahrscheinlichkeiten der Pfade ist dann die gesuchte Wahrscheinlichkeit, \\(W\\) (Additionssatz). Das ist einfach, dauert aber.\nIn diesem Fall ist die Wahrscheinlichkeit eines (günstigen) Pfades, \\(A\\):\n\\(P(A) = P(T)^2 \\cdot P(N)^2 = \\left( \\frac{2}{5} \\right)^2 \\cdot \\left( \\frac{3}{5} \\right) ^2\\).\n\n\nCode\np_a = (2/5)^2 * (3/5)^2\np_a\n## [1] 0.0576\n\n\nEtwas mühevolles Zählen der Pfade würde uns zeigen, dass es \\(k=6\\) Pfade gibt, die alle die gleiche Wahrscheinlichkeit, \\(P(A)\\), aufweisen.\nDamit beträgt die Wahrscheinlichkeit des gesuchten Ereignisses \\(A^{\\prime}\\) (2 Treffer bei 4 Zügen):\n\\(P(A^{\\prime}) = 6 \\cdot P(A)\\).\n\n\nCode\np_a_strich = 6 * p_a\np_a_strich\n## [1] 0.3456\n\n\nMithilfe der Formel der Binomialverteilung lässt sich das Ergebnis, die Wahrscheinlichkeit von \\(A^{\\prime}\\) schneller ausrechnen. Einfach gesprochen sieht sie so aus:\n\\[P(A^{\\prime}) = k \\cdot P(A)\\] Dabei steht \\(k\\) für die Anzahl der günstigen Pfade und \\(P(A)\\) für die Wahrscheinlichkeit eines günstigen Pfades (d.h. 2 Treffer und 2 Nieten) und alle Pfade haben die gleiche Wahrscheinlichkeit.\nDie Anzahl der Pfade kann man mit dem Binomialkoeffizient ausrechnen, den man so darstellt:\n\\(\\tbinom{n}{k}\\)\nLies: “Wähle aus \\(n\\) möglichen Ereignissen (Pfade im Baum) \\(k\\) günstige Ereignisse (günstige Pfade).\nAuf Errisch geht das so:\n\n\nCode\nchoose(4,2)\n## [1] 6\n\n\n\n\n4.4.2 Rechnen mit R\nDie Binomialverteilung ist in R eingebaut; man kann sich leicht entsprechende Wahrscheinlichkeiten ausrechnen lassen.\nDie Wahrscheinlichkeit, bei 4 Zügen 2 Treffer zu erzielen mit \\(p=2/5\\) unter der Annahme einer Binomialverteilung lässt sich so mit R berechnen:\n\n\nCode\ndbinom(x = 2, size = 4, prob = 2/5)\n## [1] 0.3456\n\n\n\nBeispiel 4.1 (Pumpstation-Beispiel zur Binomialverteilung) In einer Pumpstation arbeiten 7 Motoren, die wir als identisch annehmen. Mit einer Wahrscheinlichkeit von 5% fällt ein Motor aus und ist für den Rest des Tages nicht einsatzbereit. Der Betrieb kann aufrecht erhalten werden, solange mindestens 5 Motoren arbeiten. Wie groß ist die Wahrscheinlichkeit, dass die Pumpstation aus dem Betrieb fällt?\n\\(P(X=k)\\) (oder kurz: \\(P(k)\\)) gibt die Wahrscheinlichkeit (Wahrscheinlichkeitsfunktion) an für das Ereignis, dass k Motoren arbeiten.\nLassen wir R mal \\(P(X=5)\\) ausrechnen.\n\n\nCode\ndbinom(x = 5, size = 7, prob = .95)\n## [1] 0.0406235\n\n\nEs gilt also \\(P(X=5) \\approx .04\\). Die Wahrscheinlichkeit, dass (nur) 5 Motoren laufen an einem beliebigen Tag ist relativ gering3.\ndbinom() steht für die Wahrscheinlichkeitsdichte (im diskreten Fall, also hier, Wahrscheinlichkeitsfunktion genannt) und binom für die Binomialverteilung. x gibt die Anzahl der Treffer an (das gesuchte Ereignis, hier 5 Motoren arbeiten); size gibt die Stichprobengröße an (hier 7 Motoren).\nDamit gilt:\n\\(P(X\\ge 5) = P(X=5) + P(X=6) + P(X=7)\\)\n\n\nCode\np_5 <- dbinom(x = 5, size = 7, prob = .95)\np_6 <- dbinom(x = 6, size = 7, prob = .95)\np_7 <- dbinom(x = 7, size = 7, prob = .95)\n\np_mind_5 <- p_5 + p_6 + p_7\n\np_mind_5\n## [1] 0.996243\n\n\nDie Wahrscheinlichkeit, dass mind. 5 Motoren arbeiten beträgt also 0.9962.\nDas Komplement zu diesem Ereignis ist, dass nicht mind. 5 Motoren arbeiten, also höchstens 4 und es daher zu einem Ausfall kommt.\nNatürlich gilt \\(P(\\bar{X}) = 1- P(X)\\).\n\n\nCode\np_weniger_als_4 <- 1 - p_mind_5\np_weniger_als_4\n## [1] 0.003757043\n\n\nAlternativ kann man mit der Verteilungsfunktion rechnen: \\(P(X \\le 4)\\).\nIn R kann man dafür die Funktion pbinom() nutzen (p für (kumulierte) Wahrscheinlichkeit).\n\n\nCode\npbinom(q = 4, size = 7, prob = .95)\n## [1] 0.003757043\n\n\nq = 4 steht für \\(X \\le 4\\), also für höchstens 4 Treffer (arbeitende Motoren); size = 7 meint die Stichprobengröße, hier 7 Motoren.\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Funktion, die die Wahrscheinlichkeit dafür angibt, dass die diskrete Zufallsvariable \\(X\\) eine Realisation annimmt, die kleiner oder gleich (höchstens) einem Wert \\(X=x\\) ist, heißt Verteilungsfunktion.\n\\(F(X=x) = P(X \\le x)\\)\n\n\n\n\n4.4.3 Simulieren\nDie Binomialverteilung lässt sich gut als “Münzwurf-Verteilung” auffassen.\nWerfen wir eine Münze und sehen wir, was passiert.\n\n\nCode\nsample(x = c(0, 1), size = 1)\n## [1] 1\n\n\nMit sample() ziehen wir eine Stichprobe aus dem Ereignisraum x, hier 0 und 1. Dabei vereinbaren wir (willkürlich), dass 0 für “Kopf” steht und 1 für “Zahl”. size = 1 bedeutet, wir werfen die Münze ein Mal (d.h. Stichprobengröße size ist 1).\nOkay, noch an Bord? Dann werfen wir die Münze 10 Mal:\n\n\nCode\nsample(x = c(0, 1), size = 10, replace = TRUE)\n##  [1] 0 1 1 1 1 0 0 1 0 1\n\n\nreplace = TRUE heißt, wir legen die Münze wieder zurück auf den Tisch, wenn wir sie geworfen haben. Oder anders ausgedrückt: Ziehen mit Zurücklegen.\nR, mach dich bereit, wirf die Münze 1000 (\\(n=10^3\\) oder 1e3) Mal4:\n\n\nCode\nn <- 1e3\n\nmuenze_oft <- \n  sample(x = c(0, 1), size = n, replace = TRUE) \n\n\nmuenze_oft %>% \n  sum()\n## [1] 539\n\n\nMit sum() nach dem Pfeifensymbol %>% haben wir aus dem Vektor muenze_oft, der aus der ersten Zeile resultiert, die Summe ausgerechnet.\nJetzt wissen wir, wie oft die Münze “Zahl” gezeigt hat, nämlich 539 Mal.\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie einen Zufallsversuch wiederholen, muss nicht jedes Mal das gleiche Ergebnis resultieren. Entsprechend wird bei wiederholten Ausführung der Funktion sample() nicht immer das gleiche Ergebnis resultieren. Wundern Sie sich also nicht, wenn bei Ihrem Computer eine ähnliche, aber nicht gleiche, Zahl herauskommt.\n\n\nVisualisieren wir mal unsere Münzwürfe. Dazu erstellen wir zuerst eine geeignete Tabelle:\n\n\nCode\nmuenz_tab <-\n  tibble(\n    id = 1:n,\n    x = muenze_oft,\n    x_cumsum = cumsum(x) / id  # gibt Anteil von \"Zahl\" wieder\n  )\n\nhead(muenz_tab)\n\n\n\n\n\n\nid\nx\nx_cumsum\n\n\n\n\n1\n1\n1.0000000\n\n\n2\n1\n1.0000000\n\n\n3\n0\n0.6666667\n\n\n4\n0\n0.5000000\n\n\n5\n1\n0.6000000\n\n\n6\n1\n0.6666667\n\n\n\n\n\n\nUnd hier der Anteil von “Zahl” im Verlauf unserer Münzwürfe, s. Abbildung 4.5.\n\n\nCode\nmuenz_tab %>% \n  slice_head(n = 1e3) %>% \n  ggplot() +\n  aes(x = id, y = x_cumsum) +\n  geom_line()\n\n\n\n\n\nAbbildung 4.5: Das Gesetz der großen Zahl am Beispiel der Stabilisierung des Trefferanteils beim wiederholten Münzwurf\n\n\n\n\nGrob gesagt scheint sich ein Münzwurf nach, naja, vielleicht 500 Würfen “einigermaßen” zu stabilisieren.5\n\n\n\n\n\n\nWichtig\n\n\n\nDas Gesetz der großen Zahl\nZieht man (zufällig) immer mehr Werte aus einer Verteilung (mit endlichem Mittelwert), nähert sich der Mittelwert der Stichprobe immer mehr mit dem Mittelwert (oft als Erwartungswert bezeichnet) der Verteilung an"
  },
  {
    "objectID": "Verteilungen.html#normalverteilung",
    "href": "Verteilungen.html#normalverteilung",
    "title": "4  Verteilungen",
    "section": "4.5 Normalverteilung",
    "text": "4.5 Normalverteilung\nNormalverteilungen haben eine charakteristische Glockenform. Normalverteilungen können sich unterscheiden in ihrem Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden Größen (“Parameter”) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. Abbildung 4.6. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\n\n\n\nAbbildung 4.6: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\n\nBeispiel: Wie groß sind Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die Körpergröße der 25% kleinsten Studentis an, analog für 50%, 75%:\n\n\n\n\n\n\n  \n  \n    \n      q25\n      q50\n      q75\n    \n  \n  \n    160.02\n167.64\n175.26\n  \n  \n  \n\n\n\n\nVisualisierung der Quantile:\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas 25%-Quantil nennt man 1. Quartil, das 50%-Quantil auch 2. Quartil, das 75%-Quantil das 3. Quartil, und das 100%-Quantil (Maximalwert) das 4. Quartil.\n\n\n\n4.5.1 Normal auf dem Fußballfeld\nSie und 100 Ihrer besten Freunde stehen auf der Mittellinie eines Fußballfelds. Auf Kommando werfen alle jeweils eine Münze; bei Kopf geht man einen Schritt nach links, bei Zahl nach rechts. Das wird 16 Mal wiederholt. Wie wird die Verteilung der Positionen wohl aussehen?\n\n\n\n\n\n(McElreath 2020)\n\n\n4.5.2 Normal durch Addieren\nDie Summe vieler (gleich starker) Zufallswerte (aus der gleichen Verteilung) erzeugt eine Normalverteilung; egal aus welcher Verteilung die Zufallswerte kommen (Zentraler Grenzwertsatz), vgl. Abbildung 4.7.\n\n\n\n\n\nAbbildung 4.7: Entstehen einer Normalverteilung durch Addition vieler unabhgängiger Ereignisse\n\n\n\n\nNicht verwechseln:\n\n\n\n\n\n\n\n\n\n\n\n4.5.3 Normalverteilung vs. randlastige Verteilungen\n\n\n\n\n\nBei randlastigen Verteilungen (“fat tails”) kommen Extremereignisse viel häufiger vor als bei Normalverteilungen. Deshalb ist es wichtig sein, zu wissen, ob eine Normalverteilung oder eine randlastige Verteilung vorliegt. Viele statistische Methoden sind nicht zuverlässig bei (stark) randlastigen Methoden.\n\n\n4.5.4 Beispiele für Normal- und randlastige Verteilungen\nNormal verteilt:\n\nGröße\nMünzwürfe\nGewicht\nIQ\nBlutdruck\nAusschuss einer Maschine\n\nRandlastig verteilt:\n\nVermögen\nVerkaufte Bücher\nRuhm\nAktienkurse\nErdbeben\nPandemien\nKriege\nErfolg auf Tinder\nMeteroritengröße\nStadtgrößen\n\n\n\n4.5.5 Formel der Normalverteilung\nVereinfacht ausgedrückt lässt die Normalverteilung \\(\\mathcal{N}\\) durch Exponenzieren einer Quadratfunktion beschreiben:\n\\[\\mathcal{N} \\propto e^{-x^2}\\]\nmit \\(e=2.71...\\), der Eulerschen Zahl.6\n\n\nCode\nd <-\n  tibble(\n    x = seq(-3, 3, \n            length.out = 100),\n    y = exp(-x^2)\n  )\n\nd %>% \n  ggplot() +\n  aes(x = x, y = y) +\n  geom_line()\n\n\n\n\n\n\n\nEine Normalverteilung mit \\(\\mu=0\\) und \\(\\sigma=1\\) nennt man auch Standardnormalverteilung und man schreibt:\n\\[IQ \\sim \\mathcal{N}(0,1)\\]\nDie Normalverteilung wird auch Gauss-Verteilung oder Glockenkurve genannt.\n\n\n4.5.6 Simulation einer Normalverteilung\nR hat eine Funktion eingebaut zur Erzeugung von Zufallszahlen (Zufallszahlengenerator), z.B. normalverteilte. Man übergibt dieser Funktion den gewünschten Mittelwert und die gewünschte Streuung und die Funktion zieht dann zufällig Werte aus dieser Verteilung.\nDiesen Zufallszahlengenerator kann man mit einem Duschkopf vergleichen, s. Abbildung 4.8. An diesem Duschkopf kann man einen Schwenker einstellen, der den Duschkopf ausrichtet, also steuert, ob die Wassertropfen weit in die eine oder die andere Richtugn fallen. Zweitens hat unser Duschkopf noch einen Streuregler, der den Wasserstrahl entweder eng bündelt7 oder weit auseinanderfächert. Im ersten Fall fällt der Wasserstrahl eng und schmal aus. Im zweiten Fall fällt der Wasserstrahl breit aus.\n\n\n\nAbbildung 4.8: Zufallszahlengenerator als Duschkopf\n\n\nQuelle: John Kruschke.\nEine Zufallszahl (random number), die normalverteilt ist, mit \\(\\mu=0\\) und \\(\\sigma=1\\) kann man in R so erzeugen:\n\n\nCode\nrnorm(n = 1, mean = 0, sd = 1)\n## [1] 0.2664096\n\n\nEin Fallbeispiel: Der Inhalt einer Tüte mit Zucker, \\(X\\), sei normalverteilt mit \\(\\mu = 10002\\) g und \\(\\sigma=1.5\\) g. Aus vertragsrechtlichen Gründen darf das Füllgewicht von 1000g nicht unterschritten werden, sonst drohen Konventionalstrafen.\nWie groß ist die Wahrscheinlichkeit, dass 1000g unterschritten werden?\nSimulieren wir uns 1e4 Zuckertüten!\n\n\nCode\nn <- 1e4\nd <- \n  tibble(\n    id = 1:n,\n    x = rnorm(n = n, mean = 1002, sd = 1.5)\n  )\n\nhead(d)\n\n\n\n\n\n\nid\nx\n\n\n\n\n1\n1002.479\n\n\n2\n1001.216\n\n\n3\n1003.320\n\n\n4\n1001.173\n\n\n5\n1001.465\n\n\n6\n1003.843\n\n\n\n\n\n\nZählen wir, viele der Zuckertüten ein Gewicht von weniger als 1000g aufweisen:\n\n\nCode\nd %>% \n  count(x < 1000)\n\n\n\n\n\n\nx < 1000\nn\n\n\n\n\nFALSE\n9013\n\n\nTRUE\n987\n\n\n\n\n\n\nEin ziemlich8 kleiner Anteil. Rechnen wir uns noch die Anteile (proportion) aus:\n\n\nCode\nd %>% \n  count(x < 1000) %>% \n  mutate(prop = n/1e4)\n\n\n\n\n\n\nx < 1000\nn\nprop\n\n\n\n\nFALSE\n9013\n0.9013\n\n\nTRUE\n987\n0.0987\n\n\n\n\n\n\n\n\n4.5.7 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. Abbildung 4.9:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu gehören?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, … der Leute nicht überschritten?\n\n\n\n\nAbbildung 4.9: Visualisierung der theoretischen IQ-Verteilung\n\n\nQuelle:: John Kruschke.\nZiehen wir zufällig \\(1e4\\) Stichproben aus \\(\\mathcal{N}(100,15)\\) und berechnen die Quantile:\n\n\nCode\nd <-\n  tibble(\n  iq = rnorm(n = 1e4, \n             mean = 100, \n             sd = 15))\n\nprobs <- c(0.75,.5,.25,.05,.01)\n\nd_summary <- d %>% \n  summarise(p = probs,\n            q = quantile(iq, probs))\n\n\n\n\n\n\n\n\n  \n  \n    \n      p\n      q\n    \n  \n  \n    0.75\n110\n    0.50\n100\n    0.25\n90\n    0.05\n75\n    0.01\n65\n  \n  \n  \n\n\n\n\nDas Quantil \\(q\\) zur kumulierten Wahrscheinlichkeit \\(p=75\\) ist 110, etc.\nUmgekehrt können wir uns auch fragen: Gegeben einer Realisation der Zufallsvariablen (z.B. IQ), was ist die zugehörige Wahrscheinlichkeit (Wert der Verteilungsfunktion?)\n\nWelcher Anteil der Fläche unter der Kurve \\(p\\) gehört zu den IQ-Werten 75, 100, 115, 130?\nAnders gesagt: Welcher Anteil der Wahrscheinlichkeitsmasse der Verteilung liegt unter IQ=75, IQ=100, etc.?\n\nZiehen wir Stichproben aus \\(\\mathcal{N}(100,15)\\):\n\n\nCode\nd <-\n  tibble(\n    iq = rnorm(1e4, \n               mean = 100, \n               sd = 15)) %>% \n  mutate(iq = round(iq))\n\nqs <- c(75,100,115,130)\n\nd %>% \n  count(p_100 = iq < 100) %>% \n  mutate(prop = n / sum(n)) \n\n\n\n\n\n\n\n\n  \n  \n    \n      p_100\n      n\n      prop\n    \n  \n  \n    FALSE\n5143\n0.51\n    TRUE\n4857\n0.49\n  \n  \n  \n\n\n\n\nAnstelle von iq < 100 kann man iq < 115 einsetzen, etc.\n\n\n\nDie Verteilungsfunktion (der Anteil der Wahrscheinlichkeitsmasse), p, für IQ-Werte nicht größer als 100, \\(IQ\\le100\\), ist 50%, etc.\n\n\n4.5.8 Quantile der Normalverteilung\n\nQuantile teilen eine Verteilung so ein, dass ein Anteil \\(p\\) kleiner oder gleich und der andere Teil \\(1-p\\) größer dem Quantil \\(q\\) ist.\n\nBeispiel: “50%-Quantil = 100” meint, dass 50% der Elemente der Verteilung einen Wert kleiner oder gleich als 100 haben.\n\nDie Verteilungsfunktion F (für einen Wert \\(x\\)) gibt die Wahrscheinlichkeit an, dass die zugehörige Zufallsvariable \\(X\\) einen Wert höchstens so groß wie \\(x\\) annimmt. Sie zeigt also die kumulierte Wahrscheinlichkeit \\([-\\infty, q)\\).\n\nBeispiel: “F(100) = 50%” meint: Die Wahrscheinlichkeit für eine Ausprägung von höchstens als 100 beträgt 50%.\n\n\nSchauen wir uns die Quartile der Normalverteilung einmal näher an. Wir gehen von einer Normalverteilung aus, wie sie zur Beschreibung von Intelligenz (IQ) verwendet wird, s. Abbildung 4.10.\n\n\n\n\n\nAbbildung 4.10: Quantile der Normalverteiltung\n\n\n\n\n\\[IQ \\sim \\mathcal{N}(100, 15)\\] Mit R kann man sich die beiden Größen komfortabel berechnen lassen:\n\n\nCode\nqnorm(.50, mean = 100, sd = 15)  # 50%-Quantil\npnorm(100, mean = 100, sd = 15)  # Verteilungsfunktion für IQ=100\n\n\nBetrachten wir einige wichtigen Quantile, s. Abbildung 4.11.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 4.11: Verschiedene Quantil der Normalverteilung\n\n\n\n\n\n\n4.5.9 Standardnormalverteilung\n\n\n\n\n\nBei \\(X=0\\):\n\nhat eine Einheit von \\(X\\) die Wahrscheinlichkeitsmasse von 40% (Wahrscheinlichkeitsdichte)\nsind 50% der Wahrscheinlichkeitsmasse (Fläche unter der Kurve) kleiner als dieser Wert (Verteilungsfunktion).\n\nIn Summe liegen 100% der Wahrscheinlichkeitsmasse unter der Kurve.\n\n\n4.5.10 Normalverteilung als konservative Wahl\nDem Mathematiker Carl Friedrich Gauss (s. Abbildung 4.12) wird die Ehre zuerkannt, die Normalverteilung eingeführt zu haben.\n\n\n\n\n\nAbbildung 4.12: Zehn-Mark-Geldschein mit Gauss und Normalverteilung\n\n\n\n\nQuelle: Uni Greifswald, Public domain, via Wikimedia Commons\n\n\n\n\n\n\nHinweis\n\n\n\nOntologische Begründung\n\nWirken viele, gleichstarke Einflüsse additiv zusammen, entsteht eine Normalverteilung (McElreath 2020), Kap. 4.1.4.\n\nEpistemologische Begründung\n\nWenn wir nur wissen, dass eine Variable über einen endlichen Mittelwert und eine endliche Varianz verfügt und wir keine weiteren Annahmen treffen bzw. über kein weiteres Vorwissen verfügen, dann ist die Normalverteilung die plausibelste Verteilung (maximale Entropie) (McElreath 2020), Kap. 7 und 10."
  },
  {
    "objectID": "Verteilungen.html#aufgaben",
    "href": "Verteilungen.html#aufgaben",
    "title": "4  Verteilungen",
    "section": "4.6 Aufgaben",
    "text": "4.6 Aufgaben\nZusätzlich zu den Aufgaben im Buch:\n\nLose-Nieten-Binomial-Grid\nBsp-Binomial\n\n\n\n\n\nBourier, Günther. 2018. Wahrscheinlichkeitsrechnung und schließende Statistik: praxisorientierte Einführung: mit Aufgaben und Lösungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik – Wahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage. Wiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "Globusversuch.html",
    "href": "Globusversuch.html",
    "title": "5  Globusversuch",
    "section": "",
    "text": "Bayes:Start"
  },
  {
    "objectID": "Globusversuch.html#lernsteuerung",
    "href": "Globusversuch.html#lernsteuerung",
    "title": "5  Globusversuch",
    "section": "5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nUnterschiede zwischen Modellen und der Realität erläutern\ndie Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen\ndie weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren\nPost-Wahrscheinlichkeiten anhand der Gittermethode berechnen\n\n\n\n5.1.2 Benötigte R-Pakete\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\n5.1.3 Begleitvideos\n\nVideo zum Thema Globusversuch\nVideo zum Thema Übungen zum Globusversuch"
  },
  {
    "objectID": "Globusversuch.html#von-welten-und-golems",
    "href": "Globusversuch.html#von-welten-und-golems",
    "title": "5  Globusversuch",
    "section": "5.2 Von Welten und Golems",
    "text": "5.2 Von Welten und Golems\n\n5.2.1 Kleine Welt, große Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika1. Das war aber ein glücklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb Abbildung 5.1.\n\n\n\nAbbildung 5.1: Behaims Globus: Kein Amerika\n\n\nQuelle: Ernst Ravenstein, Wikimedia, Public Domain\nDie kleine Welt des Modells entsprach hier nicht der großen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel für, sagen wir, die Komplexität wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Glück gehört halt auch dazu.\n\n\n\n\n\n\nHinweis\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die große Welt, ist nicht die Erde.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der großen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schlüssen und vermeintlicher Gewissheit.\n🏋 Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n\n5.2.2 Der Golem von Prag\n\n\n\nAbbildung 5.2: Der Golem von Prag\n\n\nQuelle\nDer Golem von Prag, die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle wörtlich ausführt, s@fig-golem-prag. Die Geschichte besagt, dass ein Rabbi mit Zauberkräften den Golem aus Lehm erschuf, um die jüdische Bevölkerung der Stadt zu schätzen. Bei kluger Führung kann ein Golem Nützliches vollbringen. Bei unüberlegter Verwendung wird er jedoch großen Schaden anrichten.\n\n\n5.2.3 Wissenschaftliche Modelle sind wie Golems\nGolem\n\n\n\n“Yeah, ich bin ein Golem!” - Bildquelle: Klara Schaumann\n\n\nEigenschaften des Golems:\n\nBesteht aus Lehm\nBelebt durch “Wahrheit”\nMächtig\ndumm\nFührt Befehle wörtlich aus\nMissbrauch leicht möglich\nMärchen\n\nModell\nEigenschaften eines Modells:\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mächtig\nsimpler als die Realität\nFührt Befehle wörtlich aus\nMissbrauch leicht möglich\nNicht einmal falsch\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir bauen Golems.\n\n\nAbbildung 2.4 stellt ein Sinnbild von Modellen dar.\nVergleichen wir die kleine Welt unserer Modellen, wie Behaims Globus, mit der Großen Welt, die Kolumbus und wir befahren.\n\nKleine Welt vs. große Welt\n\n\n\n\n\n\nKleine Welt\nGroße Welt\n\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangsläufig) die Wirklichkeit\nentspricht nicht (zwangsläufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n5.2.4 So denkt unser Bayes-Golem\n\n\n\nSo denkt unser Bayes-Golem\n\n\n🏋 Bayes-Inferenz ähnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess ähnelt!"
  },
  {
    "objectID": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "5  Globusversuch",
    "section": "5.3 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.3 Ein erster Versuch: Wir werfen den Globus\n\n5.3.1 Welcher Anteil der Erdoberfläche ist mit Wasser bedeckt?\nUnsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (Abbildung 5.3)?\n\n\n\nAbbildung 5.3: Die Erde\n\n\nQuelle CC 4.0 BY-NC\nAnalog können wir uns vorstellen, 11 Wissenschaftlis haben jeweils eine andere Hypothese zum Wasseranteil, \\(\\pi\\), der Erde. Die erste Person hat die Hypothese \\(\\pi_1 = 0\\), die zweite Person geht von \\(\\pi_2 = 0.1\\) aus … die 11. Person von \\(\\pi_{11} = 1\\).\nUm die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.\nSo sah mein2 Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\n🏋️️ Besorgen Sie sich einen Globus (zur Not eine Münze) und stellen Sie den Versuch nach!\n\n\n5.3.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten führt, nennt man den datengenierenden Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der Erdoberfläche ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie Würfe des Globusballes sind unabhängig voneinander.\nWir haben kein Vorwissen über \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\n🏋 Welche Annahmen würden Sie ändern? Welche könnte man wegnehmen? Welche hinzufügen? Was wären die Konsequenzen?\n\n\n5.3.3 Ein paar Fachbegriffe\n\nFür jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilität der Hypothese angibt: Priori-Verteilung.\nFür jede Hypothese (d.h. jeden Parameterwert \\(p\\)) möchten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung3 bekommen.\n\n\n\n5.3.4 Bayes-Updates\nDer Golem denkt eigentlich ganz vernünftig: Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugehörige Wahrscheinlichkeitsverteilung nennt man Priori-Verteilung. In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel. Als nächstes beschaut sich der Golem die Daten und überlegt, wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 10% beträgt. Die zugehörige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die4 Likelihood. Als letztes bildet sich der Golem eine abschließende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man Posteriori-Verteilung. Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten. Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder geupatedet, s. Abbildung 5.4.\n\n\n\n\n\n\ngraph LR\nA[Priori-Vert.]-->B[Likelihood]-->C[Post-Vert.]-->A\n\n\n\n\n\nAbbildung 5.4: Updating mit Bayes\n\n\n\n\n\n\n5.3.5 Likelihood mit Binomialverteilung\nWie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer, (bei 9) Würfen zu bekommen, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 70%) annimmt? Diese Wahrscheinlichkeit hat einen eigenen Namen, weil sie eine wichtige Sache ist. Man mennt sie die Likelihood, \\(L\\)5.\nGeht man von einer Binomialverteilng aus, ist die Likelihood einfach zu berechnen6.\nWenn wir eine Binomialverteilung annehmen, dann gehen wir davon aus, dass die Daten unabhängig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich ändert7. Der Wasseranteil der Erde bleibt während des Versuchs gleich (durchaus plausibel).\nLassen Sie uns im Folgenden die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit für Wasser \\(p\\) beträgt, so bezeichnen: \\((Pr(W,L | p))\\). Diese Wahrscheinlichkeit, \\((Pr(W,L | p))\\), kann man mit der Binomialverteilung berechnen.\nMöchte man die Wahrscheinlichkeit ansprechen für das Ereignis “5 mal Wasser und 2 mal Land, wenn wir von einem Wasseranteil von 70% ausgehen”, so würden wir kurz schreiben: \\(Pr(W=5, L=2 | p=.7)\\).\nDie Binomialverteilung zeigt die Verteilung der Häufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten Münzwurf (und allen vergleichbaren Zufallsexperimenten): “Münzwurfverteilung”, s. Kap. Kapitel 4.4.\nDie Formel der Binomialverteilung sieht so aus:\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L = k \\cdot P(A) \\tag{5.1}\\]\nFormel Gleichung 5.1 kann wie folgt auf Deutsch übersetzen:\n\nDie Wahrscheinlichkeit für das Ereignis “W,L” gegeben p berechnet als Produkt von zwei Termen. Erstens der Quotient von der Fakultät von W plus L im Zähler und im Nenner das Produkt von erstens der Fakultät von W mit zweitens der Fakultät von L. Der zweite Term ist das Produkt von p hoch W mal der komplementären Wahrscheinlichkeit von p hoch L.\n\nOder noch kürzer:\n\nDie Wahrscheinlichkeit für das Ereignis “W,L” gegeben p berechnet als Produkt von zwei Termen. Erstens der Anzahl der günstigen Pfade, k und zweitens der Wahrscheinlichkeit für einen günstigen Pfad, P(A).\n\nPuh, Formeln sind vielleicht doch ganz praktisch, wenn man sich diese lange Übersetzung der Formel in Prosa duchliest. Noch praktischer ist es aber, dass es Rechenmaschinen gibt, die die Formel kennen und für uns ausrechnen. Los, R, mach mal.\n\n\n5.3.6 Binomialverteilung mit R\nWas ist der Anteil der gültigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 2 mal \\(W\\) bei \\(N=W+L=3\\) Würfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?8.\n\n\nCode\ndbinom(x = 2, size = 3, prob = 1/2)\n## [1] 0.375\n\n\nVon den 8 Endkonten bzw. Pfaden sind 3 günstig. Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 Würfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich); 3/8 sind 0.375.\n\n\n\n\n\nflowchart TD\n  A[A - Start] -. 1/2 .-> B[B - 0]\n  A -. 1/2 .-> C[C - 1]\n  B -. 1/2 .-> D[D - 0]\n  B -. 1/2 .-> E[E - 1]\n  C -. 1/2 .-> F[F - 0]\n  C -. 1/2 .-> G[G - 1]\n  D -. 1/2 .-> H[H - 0]\n  D -. 1/2 .-> J[I - 1]\n  E -. 1/2 .-> K[K - 0]\n  E -. 1/2 .-> L[L - 1]\n  F -. 1/2 .-> M[M - 0]\n  F -. 1/2 .-> N[N - 1]\n  G -. 1/2 .-> O[O - 0]\n  G -. 1/2 .-> P[P - 1]\n\n\n\n\n\nAbbildung 5.5: Wir werfen den Globus (oder eine Münze) 3 Mal\n\n\n\n\nAbb. Abbildung 5.5 stellt einen einfachen Baum für 3 Globuswürfe mit je zwei möglichen Ereignissen (W vs. L) dar. In der ersten (obersten) Zeile (Knoten A; “Start”) ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand. Jetzt Achtung: Sie werfen den Globusball hoch. Die Pfeile zeigen zu den (zwei) mögliche Ergebnissen. Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. Die Ergebnisse sind hier mit 0 und 1 bezeichnet (das eine eine einfache und weiteinsetzbare Notation). Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar. Die vierte Zeile (Knoten H bis P) stellt die Ergebnisse des des dritten Wurfes dar.\nFür mehr Würfe würde das Diagramm irgendwann unübersichtlich werden.\nWas ist der Anteil der gültigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) Würfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\n\nCode\ndbinom(x = 6, size = 9, prob = 1/2)\n## [1] 0.1640625\n\n\nAbb Abbildung 5.6 ist ein vergeblicher Versuch, so einen großen Baum (\\(n=9\\)) darzustellen.\n\n\n\n\n\n\nHinweis\n\n\n\nVisualisierungen wie Baumdiagramme sind eine praktische Hilfe zum Verständnis, kommen aber bei größeren Daten schnell an ihre Grenze.\n\n\n\n\n\n\n\nAbbildung 5.6: Wir werfen den Globus (oder eine Münze) 3 Mal\n\n\n\n\nJetzt folgen einige Beispiele.\n\nBeispiel 5.1 (Globus mit 9 Treffern bei 9 Würfen) Was ist die Wahrscheinlichkeit für \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\n\nCode\ndbinom(x = 9, size = 9, prob = 1/2)\n## [1] 0.001953125\n\n\nDas ist 1 günstiger Pfad von 512 Pfaden.\n\n\nBeispiel 5.2 (Klausur mit 20-Richtig-Falsch-Fragen) Ei Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groß ist die Wahrscheinlichkeit, durch bloßes Münze werfen genau 15 Fragen richtig zu raten?9.\n\n\nCode\ndbinom(x = 15, size = 20, prob = .5)\n## [1] 0.01478577\n\n\nUm höchstens 15 Treffer zu erzielen, müssten wir die Wahrscheinlichkeiten von 0 bis 15 Treffern addieren.\nPraktischerweise gibt es einen R-Befehl, der das für uns übernimmt:\n\n\nCode\npbinom(q = 15, size = 20, prob = .5)\n## [1] 0.994091\n\n\nDie Wahrscheinlichkeit 0, 1, 2, … oder 15 Treffer zu erzielen, liegt also bei gut 99%.\n\n\nBeispiel 5.3 (3 Münzwürfe mit 3 Treffern) Was ist die Wahrscheinlichkeit bei 3 Münzwürfen (genau) 3 Treffer (Kopf) zu erzielen?\nDas ist eine Frage an die Binomialverteilung; in R kann man das mit der Funktion dbinom beantworten.\n\n\nCode\ndbinom(x = 3, size = 3, prob = 1/2)\n## [1] 0.125\n\n\n\ndbinom gibt uns die Wahrscheinlichkeit von x Treffern, bei size Versuchen zurück, wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit prob.\n\n\n5.3.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: “W ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)”. \\(N\\) gibt die Anzahl der Globuswürfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (“uniform”):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: “\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1”.\nMan könnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (aprior) indifferent, jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich.\n\n\n5.3.8 Visualisierungen\nAbb. Abbildung 5.7 zeigt die Binomialverteilung \\(X \\sim Bin(9, 1/2)\\).\n\n\n\n\n\nAbbildung 5.7: Ein Beispiel für eine Binomialverteilung mit Parametern N=9 und p=1/2.\n\n\n\n\n\n\n\n🏋️️ Was fällt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Verändert sich die Wahrscheinlichkeit linear?"
  },
  {
    "objectID": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "5  Globusversuch",
    "section": "5.4 Zur Erinnerung: Bayes Theorem",
    "text": "5.4 Zur Erinnerung: Bayes Theorem\n\n5.4.1 Herleitung Bayes’ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit für Regen und kalt ist gleich der Wahrscheinlichkeit von Regen, gegeben kalt mal der Wahrscheinlichkeit von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wenn’s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n\n5.4.2 Herleitung Bayes’ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lösen auf nach der Posteriori-Wahrscheinlichkeit10, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods über alle Werte von \\(p\\). Die Aufgabe dieser Größe ist nur dafür zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n\n5.4.3 Bayes’ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)} = \\frac{\\text{Likelihood}  \\cdot \\text{Priori}}{\\text{Evidenz}}\\]\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayes’ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) füttert.\nBayes’ Theorem wird häufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n\n\n5.4.4 Posteriori als Produkt von Priori und Likelihood\nDie unstandardisierte Post-Wahrscheinlichkeit ist einfach das Produkt von Likelihood und Priori.\nDas Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren. Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung Gleichung 5.2.\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}} \\tag{5.2}\\]\nAbb. Abbildung 5.8 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist. Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.\n\n\n\nAbbildung 5.8: Prior mal Likelihood = Post\n\n\n\n\n5.4.5 Wissen updaten: Wir füttern Daten in das Modell\nGolems können lernen?! Abbildung 5.9 zeigt die Post-Verteilung, nach \\(n=1, 2, ...,n=9\\) Datenpunkten, d.h. Würfen mit dem Globusball. Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich für den Golem (das Modell). Je nach Ergebnis des Wurfes verändert sich die Wahrscheinlichkeit der Parameterwerte, kurz gesagt, die Post-Verteilung verändert sich in Abhängigkeit von den Daten.\n\n\n\nAbbildung 5.9: Unser Golem lernt\n\n\nInsofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell nützlich ist (präzise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "href": "Globusversuch.html#bayes-berechnen-mit-mit-dem-bayes-gitter",
    "title": "5  Globusversuch",
    "section": "5.5 Bayes berechnen mit mit dem Bayes-Gitter",
    "text": "5.5 Bayes berechnen mit mit dem Bayes-Gitter\nWir erstellen uns eine kleine Tabelle, die man “Bayes-Gitter” nennen könnte. Dazu gehen wir so vor:\n\n5.5.1 Idee\n\nTeile den Wertebereich des Parameter in ein “Gitter” auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (“Gitterwerte”).\nWähle den Priori-Wert des Parameters für jeden Gitterwert.\nBerechne den Likelihood für Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert für jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\nFür jeden “Gitterwert” berechnen wir eine (Post-)Wahrscheinlichkeit. Ein Gitterwert ist eine mögliche Ausprägung des Parameters. Häufig entspricht eine Hypothese einem Gitterwert, etwa wenn man sagt: “Ich glaube, die Münze ist fair”, was auf einem Parameterwert von 50% herausläuft. Dazu geben wir an, für wie wahrscheinlich wie apriori11 - also bevor wir irgendwelche Daten erheben - jeden einzelnen Gitterwert halten. Wir machen es uns hier einfach und halten jeden Gitterwert für gleich wahrscheinlich. Tatsächlich ist der konkrete Wert hier egal, entscheidend ist das Verhältnis der Apriori-Werte zueinander: Geben wir einigen Gitterwerten den Wert 2, aber anderen den Wert 1, so halten wir Erstere für (apriori) doppelt so plauibel wie Letztere. Der Likelihood wird in diesem Fall mit der Binomialverteilung berechnet. Der Likelihood gibt an, wie wahrscheinlich ein Gitterwert ist gegeben einem bestimmten apriori gewählten Parameterwert. Die “End-Wahrscheinlichkeit”, die unstandardisierte Post-Wahrscheinlichkeit, die “hinten rauskommt” ist das Produkt von Priori-Wert und Likelihood. Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet12. Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen möchten teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. Damit haben wir dann die Kolmogorov-Ansprüche an eine Wahrscheinlichkeitsverteilung erfüllt.\n\n\n5.5.2 Bayes-Gitter in R berechnen\nLegen wir uns eine Tabelle mit Gitterwerten an, um deren Posteriori-Wahrscheinlichkeit zu berechnen.\n\n\nCode\nd <-\n  tibble(\n    # definiere die Hypothesen (das \"Gitter\"): \n    p_Gitter = seq(from = 0, to = 1, by = 0.1),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %>%  \n    mutate(\n      # berechne Likelihood für jeden Gitterwert:\n      Likelihood = dbinom(6, size = 9, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\n\nDas “Bayes-Gitter” (Tabelle 5.1) zeigt, wie sich die Post-Verteilung berechnet.\n\n\n\n\nTabelle 5.1: Die Bayes-Box für den Globusversuch\n\n\nid\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n1\n0.0\n1\n0.00\n0.00\n0.00\n\n\n2\n0.1\n1\n0.00\n0.00\n0.00\n\n\n3\n0.2\n1\n0.00\n0.00\n0.00\n\n\n4\n0.3\n1\n0.02\n0.02\n0.02\n\n\n5\n0.4\n1\n0.07\n0.07\n0.07\n\n\n6\n0.5\n1\n0.16\n0.16\n0.16\n\n\n7\n0.6\n1\n0.25\n0.25\n0.25\n\n\n8\n0.7\n1\n0.27\n0.27\n0.27\n\n\n9\n0.8\n1\n0.18\n0.18\n0.18\n\n\n10\n0.9\n1\n0.04\n0.04\n0.04\n\n\n11\n1.0\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\nFür jede Hypothese (Spalte id) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood:\n\\(\\text{Post}_{\\text{unstand}} = \\text{Priori} \\cdot \\text{Likelihood}\\)\nUm zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten, teilen wir in jeder Zeile der Gitterbox (also für jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten.\n🏋️ Was wohl mit Post passiert, wenn wir Priori ändern?\n\n\n5.5.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: “Post-Verteilung”), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\nAbbildung 5.10 zeigt die Post-Wahrscheinlichkeit für 5, 10 und 20 Gitterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben.\n\n\n\nAbbildung 5.10: Je mehr Gitterwerte, desto genauer wird die Verteilung wiedergegeben.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nUnter sonst gleichen Umständen gilt:\n\nMehr Gitterwerte glätten die Annäherung.\nJe größer die Stichprobe (\\(N\\)), desto zuverlässiger wird unsere Berechnung.\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer Träume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung können Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nächsten Kapitels."
  },
  {
    "objectID": "Globusversuch.html#aufgaben",
    "href": "Globusversuch.html#aufgaben",
    "title": "5  Globusversuch",
    "section": "5.6 Aufgaben",
    "text": "5.6 Aufgaben\n\nRethink_2E4\nRethink_2m1\nRethink_2m2\nRethink_2m3\nRethink_2m4\nRethink_2m5\nRethink_2m6\nRethink_2m7\nkekse01\nkekse02\neuro-bayes"
  },
  {
    "objectID": "Globusversuch.html#abschluss",
    "href": "Globusversuch.html#abschluss",
    "title": "5  Globusversuch",
    "section": "5.7 Abschluss",
    "text": "5.7 Abschluss\n\n5.7.1 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der großen Welt nützlich ist, steht auf einem anderen Blatt.\n\n🏋️ Wenn Sie auf einen Prozentwert für \\(W\\) tippen müssten, welchen würden Sie nehmen, laut dem Modell (und gegeben der Daten)?\n\n\n5.7.2 Vertiefung\nDas “Bayes-Paradox-Video” von 3b1b präsentiert eine gut verständliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, aber ähnlichen Darstellung wie in diesem Kapitel.\n\n\n5.7.3 Literatur\nBourier (2018), Kap. 6.2 und 7.1 erläutern einige (grundlegende) theoretische Hintergründe zu diskreten Zufallsvariablen und Wahrscheinlichkeitsverteilungen. Wichtigstes Exemplar ist dabei die Binomialverteilung. McElreath (2020), Kap. 2, stellt das Globusmodell mit mehr Erläuterung und etwas mehr theoretischem Hintergrund vor.\n\n\n\n\nBourier, Günther. 2018. Wahrscheinlichkeitsrechnung und schließende Statistik: praxisorientierte Einführung: mit Aufgaben und Lösungen. 9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Gabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "Post.html",
    "href": "Post.html",
    "title": "6  Die Post befragen",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Post.html#lernsteuerung",
    "href": "Post.html#lernsteuerung",
    "title": "6  Die Post befragen",
    "section": "6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Post-Verteilung anhand einer Stichprobenverteilung auslesen\nFragen nach Wahrscheinlichkeitsanteilen der Post-Verteilung anhand der Stichprobenverteilung beantworten\nFragen nach Quantilen anhand der Stichprobenverteilung beantworten\n\n\n\n6.1.2 Benötigte R-Pakete\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\n6.1.3 Begleitvideos"
  },
  {
    "objectID": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6  Die Post befragen",
    "section": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.2 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.2.1 Zur Erinnerung: Gitterwerte in R berechnen\nBerechnen wir mit der Gittermethode (“Bayes-Box”) die Postverteilung für den Globusversuch.\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nützliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) Würfen und \\(k=10\\) Gitterwerten, also mit 10 Wasseranteilswerten zwischen 0 und 1.\nAbb. Abbildung 6.1 zeigt die resultierende Post-Verteilung.\n\n\nCode\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\nVoilà, die Post-Verteilung als Tabelle, auch “Bayes-Box” (oder Bayes-Gitter) genannt: s. Tabelle 6.1.\n\n\n\n\n\n\nTabelle 6.1:  Postverteilung mit der Gittermethode berechnet \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0.00\n1\n0.00\n0.00\n0.00\n    0.11\n1\n0.00\n0.00\n0.00\n    0.22\n1\n0.00\n0.00\n0.01\n    0.33\n1\n0.03\n0.03\n0.04\n    0.44\n1\n0.11\n0.11\n0.12\n    0.56\n1\n0.22\n0.22\n0.24\n    0.67\n1\n0.27\n0.27\n0.30\n    0.78\n1\n0.20\n0.20\n0.23\n    0.89\n1\n0.06\n0.06\n0.06\n    1.00\n1\n0.00\n0.00\n0.00\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nAbbildung 6.1: Die Postverteilung für W=6, N=9, k=10\n\n\n\n\n\n\n\nViele nützliche Fragen (und Antworten) leiten sich ab aus Abb. Abbildung 6.1.\n\n\n6.2.2 Beispiele für Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die höchste Wahrscheinlichkeit?\nWie ungewiss ist das Modell über die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.2.3 Bayes-Box für komplexe Modelle\nBisher, für einfache Fragestellungen hat unsere Bayes-Box, das heißt die Gittermethode bestens funktioniert: einfach, robust, formschön1. Allerdings: Funktioniert sie auch bei komplexeren Modellen? Schließlich wollen wir ja auch irgendwann Regressionsmodelle berechnen. Angenommen, wir haben ein Regressionsmodell mit 1 Prädiktor, dann haben wir folgende drei Größen2 zu schätzen: \\(\\beta_0, \\beta_1, \\sigma\\). Hört sich gar nicht so viel an. Aber Moment, wir müssten dann z.B. die Frage beantworten, wie wahrscheinlich die Daten aposteriori sind, wenn z.B. \\(\\beta_0 = -3.14\\) und \\(\\beta_1 = 2.71\\) und \\(\\sigma = 0.70\\). Demnach müssen wir alle Ausprägungen (“Gitterwerte”) der Variablen multiplizieren. Puh, das wird eine große Zahl. Wenn wir für die drei Größen jeweils 10 Ausprägungen annehmen, was wenig ist, kämen wir \\(10\\cdot10\\cdot10= 1000=10^3\\) Kombinationen. Bei 100 Ausprägungen wären es schon \\(100^3=10^6\\) Kombinationen. Das wäre doch eine recht lange Tabelle.\nBei einer multiplen Regression mit sagen wir 10 Prädiktoren mit jeweils 100 Ausprägungen rechnet das arme R bis zum jüngsten Tag: $10^{100}. Nein, das können wir R nicht zumuten. Wir brauchen eine andere Lösung!\n\n\n6.2.4 Wir arbeiten jetzt mit Häufigkeit, nicht mit Wahrscheinlichkeit\nKurz gesagt: Komplexere Bayes-Modelle können nicht mehr “einfach mal eben” ausgerechnet werden; die Mathematik wird so umfangreich bzw. zu komplex.\nGlücklicherweiße gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit Häufigkeiten.\nPraktischerweise werden wir in Kürze einen R-Golem kennenlernen, der das für uns erledigt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurück.\nLernen wir jetzt also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handhaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen für Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei größeren Datensätzen (oder größeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Wie diese Verfahren funktionieren sind aber nicht mehr Gegenstand dieses Kurses. Wir wenden Sie einfach an, freuen uns und lassen es damit gut sein(Eine gute Einführung in die Hintergründe findet sich bei McElreath 2020.)\n\n\n6.2.5 Häufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (“R-Golems”) liefern uns die Post-Verteilung in Stichprobenform zurück.\nBevor wir uns aber mit diesen R-Werkzeugen beschäftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d), s. Listing 6.1.\n\nListing 6.1: Wir stellen eine Tabelle mit Stichproben aus der Post-Verteilung\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Zeilen,\n    weight_by = post,  # Gewichte nach Post-Wskt.,\n    replace = T)  %>%  # Ziehe mit Zurücklegen\n  select(p_grid)\n\n\n\n\nDie Wahrscheinlichkeit, einen bestimmten Parameterwert (d.h. aus der Spalte p_grid) aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit Zurücklegen hält die Wahrscheinlichkeiten während des Ziehens konstant. Das Argument weight_by legt die Wahrscheinlichkeit fest, mit der eine Zeile gezogen wird.\nWir begnügen uns mit der Spalte mit den Wasseranteilswerten (Parameterwerten), p_grid, die anderen Spalten brauchen wir nicht.\nDas Ergebnis, Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in Auszügen) in Tabelle 6.2 dargestellt.\n\n\n\n\n\n\nTabelle 6.2:  Die ersten Zeilen der Stichproben aus der Post-Verteilung \n  \n  \n    \n      p_grid\n    \n  \n  \n    0.333\n    0.667\n    0.667\n    0.667\n    0.667\n  \n  \n  \n\n\n\n\n\nWenn Sie jetzt denken: “Warum machen wir das jetzt? Brauchen wir doch gar nicht!” - Dann haben Sie Recht. Künftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten, weil es damit viel einfacher ist.\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n##   [1] 0.33 0.67 0.67 0.67 0.67 0.56 0.78 0.78 0.78 0.56 0.67 0.56 0.67 0.44 0.44\n##  [16] 0.56 0.67 0.67 0.67 0.56 0.78 0.67 0.56 0.56 0.78 0.56 0.67 0.33 0.67 0.44\n##  [31] 0.67 0.56 0.56 0.67 0.78 0.67 0.67 0.89 0.67 0.89 0.89 0.44 0.44 0.89 0.67\n##  [46] 0.78 0.56 0.44 0.78 0.67 0.56 0.56 0.67 0.56 0.56 0.78 0.56 0.56 0.56 0.89\n##  [61] 0.78 0.56 0.67 0.44 0.78 0.67 0.78 0.67 0.56 0.56 0.56 0.56 0.33 0.56 0.56\n##  [76] 0.67 0.67 0.67 0.78 0.56 0.78 0.67 0.78 0.67 0.44 0.67 0.56 0.89 0.67 0.89\n##  [91] 0.56 0.89 0.67 0.78 0.67 0.67 0.44 0.56 0.56 0.67\n\nWie sieht diese Tabelle wohl als Histogramm3 aus?\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. Abbildung 6.2.\n\n\n\n\n\nAbbildung 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\nAus Abbildung 6.2 können wir einfach auslesen, wie wahrscheinlich gewisse Parameterwerte sind. So sehen wir, dass das Modell Parameterwerte (Wasseranteil, \\(\\pi\\)) zwischen ca. 50% und 70% für am wahrscheinlichsten hält. Aber auch kleine Anteile wie 25% sind nicht auszuschließen (auf Basis der Daten und der Modellannahmen).\nVergleichen Sie Abbildung 6.2 mit Abbildung 5.10: beide sind sehr ähnlich! Das Stichprobenziehen (Abbildung 6.2) nähert sich recht gut an die exakte Berechnung an (Abbildung 5.10).\n\n\n6.2.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die Auflösung auf \\(k=100\\) Gitterwerte (Ausprägungen) nach oben.\n\n\nCode\nk <- 100\nn_success <- 6\nn_trials  <- 9\n\nd_k100 <-\n  tibble(p_grid = seq(from = 0, \n                      to = 1, \n                      length.out = k),  # 100 Gitterwerte\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\n\n\\(d_k100\\) ist eine Bayes-Box mit \\(W=6, N=9, k=100\\).\nUnd daraus ziehen wir uns \\(n=1000\\) Stichproben:\n\n\nCode\nsamples_k100 <-\n  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1000,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\n\nAbbildung 6.3 zeigt sowohl die exakte Post-Verteilung als auch die Post-Verteilung auf Basis von Stichproben. Im mittleren Teildiagramm sind die Stichproben einzeln als Kreis dargestellt. Im rechten Teildiagramm sind die gleichen Daten als Dichtediagramm dargestellt. In allen Fällen erkennt man gut die zentrale Tendenz: ein Wasseranteil von 70% scheint der “typische” Wert des Modells zu sein. Außerdem erkennt man, dass das Modell durchaus einige Streuung in der Schätzung des Wasseranteils bereithält. Das Modell ist sich nicht sehr sicher, könnte man sagen.\n\n\n\n\n\nAbbildung 6.3: Post-Verteilung mit 100 Gitterwerten, exakt vs. auf Basis von Stichproben\n\n\n\n\nDie Stichprobendaten nähern sich der “echten” Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt “glattere” Ränder.\n\n\n\n\n\n\nHinweis\n\n\n\nMehr Stichproben und mehr Gitterwerte glätten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung, s. Abbildung 6.4.\n\n\n\n\n\nAbbildung 6.4: Post-Verteilung mit vielen Stichproben und vielen Parameterwerten (Gitterwerten): schön ‘glatt’. Mittelwert (MW), Modus und Median (Md) liegen eng nebeneinander, da die Verteilung recht symmetrisch ist."
  },
  {
    "objectID": "Post.html#die-post-verteilung-befragen",
    "href": "Post.html#die-post-verteilung-befragen",
    "title": "6  Die Post befragen",
    "section": "6.3 Die Post-Verteilung befragen",
    "text": "6.3 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir können viele nützliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeiten (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abbildung 6.5 illustriert.\n\n\n\nAbbildung 6.5: Fragen nach p vs. Fragen nach q\n\n\nIm linken Teildiagramm von Abbildung 6.5 fragen wir: “Wie wahrscheinlich ist ein Wasseranteil von höchstens 80%?”. Im rechten Teildiagramm fragen wir: “Welcher Wasseranteil wird mit einer Wahrscheinlichkeit von 78% nicht überschritten?”.\n\n6.3.1 Fragen nach Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groß ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nUm diese Frage zu beantworten, zählen wir einfach, wie viele Stichproben die Bedingung erfüllen:\nund und summieren die Wahrscheinlichkeiten dieser Stichproben:\nWir zählen (count) also die Stichproben, die sich für einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\n\nCode\nsamples %>%\n  count(p_grid < .5) \n\n\n\n\n\n\np_grid < 0.5\nn\n\n\n\n\nFALSE\n8362\n\n\nTRUE\n1638\n\n\n\n\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, können wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) für einen Wasseranteil kleiner als 50%.^[Der Befehl count macht Folgendes: Er gruppiert die Stichprobe nach dem Prüfkriterium, Wasseranteil höchstens 50%. Dann zählt er in jeder der beiden Teiltabelle die Zeilen und liefert diese zwei Zahlen dann zurück. Man könnte also auch in etwa schreiben:\n\n\nCode\nd %>%\n  filter(p_grid < .5) %>%\n  summarise(sum = sum(post))\n\n\n\n\n\n\nsum\n\n\n\n\n0.16653\n\n\n\n\n\n\nEinfach wie 🍰 essen.\n\nBeispiel 6.1 (Wasseranteil zwischen 50 und 75%?) Noch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter (Wasseranteil) zwischen 0.5 und 0.75?\n\n\nCode\nsamples %>% \n  count(p_grid > .5 & p_grid < .75)\n\n\n\n\n\n\np_grid > 0.5 & p_grid < 0.75\nn\n\n\n\n\nFALSE\n4563\n\n\nTRUE\n5437\n\n\n\n\n\n\n\n\nCode\nsamples %>% \n  count(p_grid > .5 & p_grid < .75) %>% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n\n\n\n\n\nAnteil\nProzent\n\n\n\n\n0.4563\n45.63\n\n\n0.5437\n54.37\n\n\n\n\n\n\nAnteile von count() könnte man, wenn man möchte, auch filter() verwenden:\n\n\nCode\nsamples %>% \n  filter(p_grid > .5 & p_grid < .75) %>% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n\n\n\n\n\nsum\nanteil\n\n\n\n\n0.5437\n54.37\n\n\n\n\n\n\n\n\nBeispiel 6.2 (Wasseranteil zwischen 90 und 100%?) Noch ein Beispiel für eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\n\nCode\nsamples %>% \n  count(p_grid >= .9 & p_grid <= 1) %>% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n\n\n\n\n\nprop\n\n\n\n\n0.01\n\n\n\n\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% beträgt.\n\nWir können auch fragen, welcher Parameterwert am wahrscheinlichsten ist; dieser Wert entspricht dem “Gipfel” des Berges, s. Abbildung 6.4.\nFür unsere Stichproben-Postverteilung, samples, s. Abbildung 6.2, lässt sich der Modus so berechnen:\n\n\nCode\nmap_estimate(samples$p_grid)  \n## MAP Estimate: 0.67\n\n\nDabei steht map für Maximum Aposteriori, also das Maximum der Post-Verteilung.\nBei der Gelegenheit könnten wir folgende, ähnliche Fragen stellen:\n\nWas ist der mittlere Schätzwert (Mittelwert) zum Wasseranteil laut Post-Verteilung?\nWas ist der mediane Schätzwert (Median)?\n\nAuf Errisch:\n\n\nCode\nsamples %>% \n  summarise(mean(p_grid),\n            median(p_grid))\n\n\n\n\n\n\nmean(p_grid)\nmedian(p_grid)\n\n\n\n\n0.6369333\n0.6666667\n\n\n\n\n\n\n\n\n6.3.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nWichtig\n\n\n\nSchätzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall4.\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht überschritten, laut unserem Modell? (Gesucht sind also die unteren 90% der Posteriori-Wahrscheinlichkeit) Wir möchten also ziemlich sicher, was die Obergrenze an Wasser auf diesem Planeten ist5.\n\n\nCode\nsamples %>% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n\n\n\n\n\nquantil90\n\n\n\n\n0.7777778\n\n\n\n\n\n\nLaut unserem Modell können wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu führen, s. fig-post99.\n\n\nCode\nsamples %>% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\n\n\nAbbildung 6.6: Die Post-Verteilung im Globusversuch\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthält, laut dem Modell?\nDafür “schneiden” wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchen Parameterwerten wir als Grenzwerte landen:\n\n\nCode\nsamples %>% \n  summarise(\n    quant_05 = quantile(p_grid, 0.05),\n    quant_95 = quantile(p_grid, 0.95))\n\n\n\n\n\n\nquant_05\nquant_95\n\n\n\n\n0.4444444\n0.8888889\n\n\n\n\n\n\nSolche Fragen lassen sich also mit Hilfe von Quantilen beantworten.\n\n\n6.3.3 Zur Erinnerung: Quantile\nBeispiel: Wie groß sind die Studentis (Quelle des Datensatzes)?\nDas Quantil von z.B. 25% zeigt die Körpergröße der 25% kleinsten Studentis an, analog für 50%, 75%, in Inches6:\n\n\nCode\nspeed_gender_height <- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary <- \n  speed_gender_height %>% \n  mutate(height_cm = height*2.54) %>% \n  select(height_inch = height, height_cm) %>% \n  drop_na() %>% \n  pivot_longer(everything(), names_to = \"Einheit\", values_to = \"Messwert\") %>% \n  group_by(Einheit) %>% \n  summarise(q25 = quantile(Messwert, prob = .25),\n            q50 = quantile(Messwert, prob = .5),\n            q75 = quantile(Messwert, prob = .75))\n\nheight_summary\n\n\n\n\n\n\nEinheit\nq25\nq50\nq75\n\n\n\n\nheight_cm\n160.02\n167.64\n175.26\n\n\nheight_inch\n63.00\n66.00\n69.00\n\n\n\n\n\n\nDas 25%-Quantil nennt man auch 1. Quartil; das 50%-Quantil (Median) auch 2. Quartil und das 75%-Quantil auch 3. Quartil.\nAbbildung 6.7 visualisiert die Quantile und die Häufigkeitsverteilung.\n\n\n\n\n\nAbbildung 6.7: Größenverteilung von 1325 amerikanischen Studentis\n\n\n\n\n\n\n6.3.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht überschritten wird. Das können wir mit im Datensatz samples so erreichen.\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% ab.\nSchaue, was der größte verbleibende Wert ist.\n\n\n\nCode\nsamples %>% \n  arrange(p_grid) %>%   # sortiere\n  slice_head(n = 9000) %>%  # nur die ersten 90000, also die obersten 1000 abschneiden\n  summarise(p90 = max(p_grid))\n\n\n\n\n\n\np90\n\n\n\n\n0.7777778\n\n\n\n\n\n\nDas (annähernd) gleiche Ergebnis liefert quantile():\n\n\nCode\nsamples %>% \n  summarise(q90 = quantile(p_grid, .9))\n\n\n\n\n\n\nq90\n\n\n\n\n0.7777778\n\n\n\n\n\n\n\n\n6.3.5 Visualisierung der Intervalle\nIntervalle (Bereiche), die die “abzuschneidende” Wahrscheinlichkeitsmasse hälftig auf die beiden Ränder aufteilen, nennen wir Perzentilintervalle oder Equal-Tails-Intervalle (ETI), s. Abb. Abbildung 6.8, rechtes Teildiagramm.\n\n\n\n\n\nAbbildung 6.8: Perzintilintervalle"
  },
  {
    "objectID": "Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "href": "Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "title": "6  Die Post befragen",
    "section": "6.4 Schiefe Posteriori-Verteilungen sind möglich",
    "text": "6.4 Schiefe Posteriori-Verteilungen sind möglich\nNoch einmal zum Globusversuch: Gehen wir von 3 Würfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schließen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 Würfe):\n\n\nCode\nd_33 <- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %>% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% \n  mutate(unstand_post = likelihood * prior) %>% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 <- \n  d_33 %>% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n    \n  \n  \n    0.95\n1\n0.86\n0.86\n    0.56\n1\n0.18\n0.18\n    0.84\n1\n0.59\n0.59\n    0.91\n1\n0.75\n0.75\n    0.98\n1\n0.94\n0.94\n    0.33\n1\n0.04\n0.04\n  \n  \n  \n\n\n\n\nMit dieser “schiefen” Post-Verteilung können wir gut die Auswirkungen auf das Perzentil- und das Höchste-Dichte-Intervall anschauen.\n\n6.4.1 50%-Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall, s. Abb. Abbildung 6.9.\n\n\n\n\n\nAbbildung 6.9: Schiefe Intervalle\n\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\n\nCode\nlibrary(easystats)\n\nsamples_33 %>% \n  select(p_grid) %>% \n  eti(ci = .5)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np_grid\n0.5\n0.71\n0.93\n\n\n\n\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.4.2 50%-Intervall höchster Dichte\nIntervalle höchster Dichte (Highest density Intervals, HDI oder HDPI) sind definiert als die schmälsten Intervalle, die den gesuchten Parameter enthalten.\nDer wahrscheinlichste Parameterwert (1) ist im Intervall enthalten, was Sinn macht. Bei einem HDI sind die abgeschnitten Ränder nicht mehr gleich groß, im Sinne von enthalten nicht (zwangsläufig) die gleiche Wahrscheinlichkeitsmasse.\nJe symmetrischer die Verteilung, desto näher liegen die Punktschätzer aneinander (und umgekehrt), s. Abb. Abbildung 6.10.\n\n\n\n\n\nAbbildung 6.10: Visualisierung der Punktschätzer bei einer schiefen Post-Verteilung\n\n\n\n\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen:\n\n\nCode\nsamples %>% \n  select(p_grid) %>% \n  bayestestR::hdi(ci = .5)  # aus dem Paket `bayestestR`\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\np_grid\n0.5\n0.6666667\n0.7777778\n\n\n\n\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfläche) sich in diesem Bereich befindet (auf Basis eines HDI).\n\n\n\n\n\n\nHinweis\n\n\n\nDas R-Paket {bayestestR} ist Teil des Meta-Pakets {easystats}. Es reicht, wenn Sie easystats laden, damit wird bayestestR automatisch geladen."
  },
  {
    "objectID": "Post.html#fazit",
    "href": "Post.html#fazit",
    "title": "6  Die Post befragen",
    "section": "6.5 Fazit",
    "text": "6.5 Fazit\n\n6.5.1 Intervalle höchster Dichte vs. Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle ähnlich\nPerzentilintervalle sind verbreiteter\nIntervalle höchster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle höchster Dichte sind die schmalsten Intervalle für eine gegebene Wahrscheinlichkeitsmasse\n\n\n\n6.5.2 Zusammenfassung\nFassen wir zentrale Punkte an einem Beispiel zusammen.\nIm Globusversuch, Datendatz samples, s. Listing 6.1. Sagen wir, wir haben 6 Treffer bei 9 Würfen erzielt.\nLageparmameter: Welchen mittleren Wasseranteil muss man annehmen?\n\n\nCode\nsamples %>% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n\n\n\n\n\nmean\nmedian\n\n\n\n\n0.6369333\n0.6666667\n\n\n\n\n\n\nStreuungsparameter: Wie unsicher sind wir in der Schätzung des Wasseranteils?\n\n\nCode\nsamples %>% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n\n\n\n\n\np_sd\np_iqr\np_mad\n\n\n\n\n0.1389354\n0.2222222\n0.1647333\n\n\n\n\n\n\nAnstelle der Streuungsparameter ist es aber üblicher, ein HDI oder PI anzugeben.\n\n\n\n\n\n\nWichtig\n\n\n\nAlles Wasser oder was? Im Beispiel dieses Kapitels haben wir unser gefragt, was wohl der Wasseranteil auf dem Planeten Erde ist. Halten Sie sich klar vor Augen: Der Wasseranteil ist ein Beispiel für einen Parameter, einer unbekannten Größes eines Modells."
  },
  {
    "objectID": "Post.html#aufgaben",
    "href": "Post.html#aufgaben",
    "title": "6  Die Post befragen",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\niq01\niq02\niq03\niq04\niq05\niq06\niq07\niq08\niq10\nfattails1\nfattails2\nReThink3e1-7\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "ppv.html",
    "href": "ppv.html",
    "title": "7  Vorhersage-Verteilung",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "ppv.html#lernsteuerung",
    "href": "ppv.html#lernsteuerung",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerläutern, was eine Posteriori-Prädiktiv-Verteilung (PPV) ist, und inwiefern Sie vor Übergewissheit schützt\neine informelle Modellprüfung für das Beispiel aus dem Unterricht anhand der Posteriori-Prädiktiv-Verteilung durchführen\n\n\n\n7.1.2 Benötigte R-Pakete\n\n\nCode\nlibrary(tidyverse)"
  },
  {
    "objectID": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.2 Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.",
    "text": "7.2 Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem Glücksspiel heraus1. Münzwurf; wenn er gewinnt, müssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? Natürlich nehmen Sie sofort an.\nSie spielen also Münzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal2.\nIst die Münze fair oder zieht der mich über den Tisch?, das ist die Frage, die Ihnen brennend durch den Kopf zieht.\n“Sind 9 von 10 Treffern noch realistisch erwartbar, wenn es mit rechten Dingen zugeht, oder beweist das Ergebnis, dass die Münze gezinkt ist?”\nWütend (und mit leeren Taschen) ziehen Sie von dannen.\nZusammengefasst: Daten: 9 von 10 Treffern beim Münzwurf. Forschungsfrage: Ist die Münze fair?\nSchauen wir uns zunächst einmal an, wie wahrscheinlich 9 von 10 Treffern sind, wenn die Münze fair ist, s. Abbildung 7.1.\n\n\n\n\n\nAbbildung 7.1: Stichprobenverteilung einer fairen Münze\n\n\n\n\nDie Stichprobenverteilung zeigt, wie wahrscheinlich die empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) sind, gegeben eines Parameterwerts \\(\\pi\\) (z.B. \\(p=0.5\\)): \\(Pr(D|\\pi)\\)3.\nAnders gesagt, die Stichprobenverteilung zeigt die Verteilung der Likelihoods eines bestimmten Parameterwerts.\n\n\n\n\n\n\nHinweis\n\n\n\nDer p-Wert\nDer p-Wert ist die zentrale Statistik der Inferenzstatistik. Er wird genutzt, um über die Ablehnung einer Hypothese zu entscheiden. In diesem Fall entspricht der p-Wert dem türkis markierten Flächenanteil in Abbildung 7.1. Ist dieser Anteil kleiner als 5% (der Gesamtfläche im Balkendiagramm), so wird die Hypothese (hier: faire Münze) verworfen. Allgemeiner gesprochne berechnet sich der p-Wert als Summe der Likelihoods, die mindestens so extrem sind wie das beobachtete empirische Ergebnis.\n\n\nIn der Bayes-Statistik ist die Post-Verteilung Dreh- und Angelpunkt der Entscheidung über eine Hypothese. In Abbildung 7.2 ist die Posteriori-Verteilung für die Daten zum zwielichten Dozent dargestellt.\n\n\nCode\n# Post-Verteilung:\nd_zwielicht <-\n  tibble(\n    p_grid = seq( from=0 , to=1 , length.out=100),\n    prior = 1,  # Priori-Gewichte\n    likelihood = dbinom(8, size = 10, prob=p_grid) ,\n    unstandardisierte_posterior = likelihood * prior ,\n    posterior = unstandardisierte_posterior / sum(unstandardisierte_posterior))\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples_zwielicht <- \n  tibble(\n    gewinnchance_muenze = sample(\n      d_zwielicht$p_grid , \n      prob=d_zwielicht$posterior, \n      size=1e4, \n      replace=TRUE)) %>% \n  mutate(\n    id = row_number())\n\n\n\n\n\n\n\nAbbildung 7.2: Post-Verteilung zu den Daten des zwielichten Dozenten (9 von 10 Treffern im wiederholten Münzwurf)\n\n\n\n\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung.\nJetzt können wir wieder die Post-Verteilung auslesen, um die Hypothese zu beantworten. Schauen wir uns einige Beispiel dazu an.\n\nBeispiel 7.1 (Einigermaßen fair?) Wie wahrscheinlich ist es, dass die Münze “einigermaßen” fair ist, sagen wir, eine Trefferwahrscheinlichkeit \\(0.45 < \\pi < 0.55\\)4 aufweist?\n\n\nCode\nsamples_zwielicht %>% \n  count(gewinnchance_muenze > 0.45 & gewinnchance_muenze < 0.55) %>% \n  mutate(prop = n/sum(n))\n\n\n\n\n\n\ngewinnchance_muenze > 0.45 & gewinnchance_muenze < 0.55\nn\nprop\n\n\n\n\nFALSE\n9506\n0.9506\n\n\nTRUE\n494\n0.0494\n\n\n\n\n\n\nDie Wahrscheinlichkeit für eine “einigermaßen faire” Münze ist klein, etwa 5%!\n\n\nBeispiel 7.2 (Münze gezinkt?) Schauen wir uns an, wie wahrscheinlich es ist - gegeben der Daten und unserem Modell - dass die Münze massiv gezinkt ist. “Massiv” definieren wir dabei mit “mindestens 70% Trefferwahrscheinlichkeit”5, also \\(\\pi >= .7\\)6.\n\n\nCode\nsamples_zwielicht %>% \n  count(gewinnchance_muenze > .7) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\ngewinnchance_muenze > 0.7\nn\nprop\n\n\n\n\nFALSE\n3159\n0.3159\n\n\nTRUE\n6841\n0.6841\n\n\n\n\n\n\nWir finden eine recht hohe Wahrscheinlichkeit für eine “massive” Manipulation der Münze.\n\n\n\n\n\n\n\nWichtig\n\n\n\nIst es nicht einfach und schön, wie wir mit Hilfe des Stichprobenziehens allerlei Forschungsfragen beantworten können? Eine Post-Verteilung aus Stichproben erlaubt uns, viele Fragen mit einfachen Methoden, nämlich schlichtes Zählen, zu beantworten.\n\n\nNatürlich könnte (und sollte?) man unser Modell kritisieren. Ist es wirklich sinnvoll, die Trefferwahrscheinlichkeit apriori als gleichverteilt anzunehmen? Das heißt ja, wir glauben, dass eine Trefferwahrscheinlichkeit von 99,99999% genauso wahrscheinlich ist wie 50,55555%. Auf der anderen Seite: Der Charme einer Gleichverteilung ist, dass sie objektiv ist, in dem Sinne, dass wir keinerlei Information einfließen lassen. Wir sind indifferent gegenüber dem Parameter \\(\\pi\\), der Trefferwahrscheinlichkeit.\n\n\n\n\n\n\nHinweis\n\n\n\nIn einem zweiten Versuch könnten wir jetzt unsere Post-Verteilung als Priori-Verteilung nutzen. Das Ergebnis des ersten Versuchs wird dann hergenommen als Ausgangspunkt für einen zweiten Versuch. Damit wird das Wissen der Wissenschaft weitergegeben7, so wie es sein sollte."
  },
  {
    "objectID": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.3 Mit Stichproben neue Beobachtungen simulieren",
    "text": "7.3 Mit Stichproben neue Beobachtungen simulieren\nZur Erinnerung: Der Likelihood (L) zeigt die Wahrscheinlichkeit eine Trefferzahl gegeben eines bestimmten Parameterwerts. In unseren Beispiel könnten wir z.B. die drei Likelihoods für \\(w=0,1,2\\) ausrechnen, gegeben \\(N=2\\) und \\(p = 0.5\\):\n\n\nCode\nL <- dbinom(0:2, size = 2, prob = 0.5)\nL\n## [1] 0.25 0.50 0.25\n\n\nAh, die Wahrscheinlichkeit für 0 oder 2 Treffer beträgt 50%, wenn \\(pi=1/2\\); für 1 Treffer beträgt sie entsprechend 50%8.\n\n7.3.1 Wir simulieren die Wasserzahl bei Globuswürfen\nZurück zu unserem Globusversuch!\nWir könnten uns jetzt Globusbälle basteln mit verschiedenen Wasseranteilen, und diese oft hochwerfen. Damit könnten wir herausfinden, welche Trefferzahlen sich bei verschiedenen Wasseranteilen finden lassen würden.\nWer gerne bastelt, freut sich darauf. Kritischere Geister9 würden den Aufwand bemängeln und die Frage nach dem Zweck der Übung stellen10.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn wir wissen, welche Trefferzahlen laut einem Modell zu erwarten sind, können wir die echten (beobachteten) Trefferzahlen mit den laut Modell zu erwartenden vergleichen. Damit haben wir eine Methode, mit dem wir ein Modell auf Herz und Nieren prüfen können. Ein schlechtes Modell wird mit seinen Vorhersagen an der Realität scheitern: Erwartung des Modells und beobachtete Daten passen nicht zusammen. Sagt ein Modell etwa \\(W=9\\) vorher bei \\(N=9\\), aber wir finden \\(W=0\\), so wird unser Vertrauen in das Modell erschüttert sein. Simulation von Trefferzahlen sind also ein Modell, um die Glaubwürdigkeit unseres Golems zu prüfen. (Nicht nur) bei Golems gilt: Vertrauen ist gut, Kontrolle ist besser.\n\n\nLos geht’s: Wir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zählen die (Wasser-)Treffer:\n\n\nCode\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n## [1] 0\n\n\nDas geht wie man sieht mit rbinom: r wie random (zufällig) und binom wie binomial verteilt, die Münzwurfverteilung.\nHier sind die Argumente der Funktion rbinom noch etwas näher erklärt:\n\n\nCode\nrbinom(n = Wie oft soll der Versuch wiederholt werden?,\n       size = Wie viele Globuswürfe pro Versuch (Stichprobengröße),\n       prob = Wie hoch ist die Wahrscheinlichkeit für Wasser (bzw. für einen Treffer))\n\n\nWeiter: Warum nicht \\(n=10\\) neue Globusversuche simulieren?\n\n\nCode\nrbinom(n = 10, size = 2, prob = 0.7)\n##  [1] 0 2 1 1 1 1 2 1 1 2\n\n\n“Simulieren” heißt hier, wir lassen den Computer den Globus werfen, ganz anschaulich gesprochen. Natürlich wirft der Computer nicht in Wirklichkeit einen Globus oder eine Münze, sondern er zieht aus der Menge {0,1} eine Zahl, und wir geben die Wahrscheinlichkeit für jedes der beiden Elemente vor, z.B. jeweils 50%.11.\n\n\n\n\n\n\nWichtig\n\n\n\nSimulationsdaten geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann. Münzwürfe - und analoge Versuche, wie Globuswürfe - kann man in R mit rbinom erstellen (simulieren).\n\n\n\n\n7.3.2 Traue niemals einem Golem (einem Modell)\n\n\n\nNever trust a Golem\n\n\nQuelle: https://imgflip.com/i/5qmhmo\nImmer prüfen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsächlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prüfen?"
  },
  {
    "objectID": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.4 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "7.4 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren12:\n\n\nCode\ndraws <- \n  tibble(\n    draws = rbinom(1e6, size = 2, prob = .7))\n\ndraws %>% \n  count(draws) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\ndraws\nn\nprop\n\n\n\n\n0\n89770\n0.089770\n\n\n1\n420629\n0.420629\n\n\n2\n489601\n0.489601\n\n\n\n\n\n\nDiese simulierten Häufigkeiten sind sehr ähnlich zu den theoretisch bestimmten Häufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen13.\n\n\nCode\ndbinom(0:2, size = 2, prob = .7)\n## [1] 0.09 0.42 0.49"
  },
  {
    "objectID": "ppv.html#stichprobenverteilung",
    "href": "ppv.html#stichprobenverteilung",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.5 Stichprobenverteilung",
    "text": "7.5 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben für unseren typischen Globusversuch: \\(N=9\\) Globuswürfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise in diesem Versuch? Die Verteilung der zu erwartenden Treffer ist in Abbildung 7.3 dargestellt.\n\n\nCode\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = rbinom(n_draws, size = 9, prob = .7))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n\n\n\n\n\n\n\nAbbildung 7.3: Anteile (Wahrscheinlichkeit), die man für jede Wasserzahl in unserem Globusversuch erwarten kann\n\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir können jetzt prüfen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Stichprobenverteilung ist keine empirische Verteilung: Wir führen diese vielen Versuche nicht wirklich durch14, wir simulieren sie nur am Computer."
  },
  {
    "objectID": "ppv.html#die-posterior-prädiktiv-verteilung-ppv",
    "href": "ppv.html#die-posterior-prädiktiv-verteilung-ppv",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.6 Die Posterior-Prädiktiv-Verteilung (PPV)",
    "text": "7.6 Die Posterior-Prädiktiv-Verteilung (PPV)\n\n7.6.1 Was ist die PPV und wozu ist sie gut?\nUnsere Stichprobenverteilung zeigt, welche Trefferzahlen bei einem bestimmten Parameterwert, z.B. \\(\\pi=.7\\) in welchen Anteilen zu erwarten sind. Allerdings sind wir uns ja nicht sicher, dass der Wasseranteil genau 70% beträgt. Unser (Un-)Wissen über den Wasseranteil wird ja gerade in der Post-Verteilung gespeichert.\nUm eine ehrliche(re) Antwort auf die Frage zu erhalten, wie viele Treffer15 zu erhalten ist, müssen wir die Post-Verteilung berücksichtigen.\nWir brauche ein Stichprobenverteilung für jeden Wert der Post-Verteilung. Wenn wir dann die resultierenden Strichprobenverteilungen mitteln, haben wir einen ehrlichen Überblick über die zu erwartenden Trefferzahlen. Dabei sollten wir natürlich wahrscheinliche Parameterwerte höher gewichten als unwahrscheinliche. So sollte etwa der (hoch wahrscheinliche) Wasseranteil von 70% ein hohes Gewicht beim Mitteln der Stichprobenverteilung erhalten; der sehr unwahrscheinliche Wasseranteil16 von 1% Wasser, sollte entsprechend weniger gewichtet werden, beim Zusammenfassen (d.h. Mittelwert bilden) der Stichprobenverteilungen.\nDie resultierende Verteilung - gemittelte Stichprobenverteilungen über alle Werte der Post-Verteilungen - nennt man Posterior-Prädiktiv-Verteilung (PPV).\n\n\n\n\n\n\nWichtig\n\n\n\nDie PPV entsteht als gewichteter Mittelwert der Stichprobenverteilungen. Die Gewichte sind die Wahrscheinlichkeiten (bzw. Wahrscheinlichkeitsdichten) der Post-Verteilung.\n\n\n\nBeispiel 7.3 (Magnus Lagrande braucht die PVV) Im Jahre \\(10^{99}\\) wird das Universum von Magnus Lagrande regiert. Die Weltraumbehörde, für die Sie arbeiten, ist ihm unterstellt. Der Regent findet Ihre Untersuchungen zwar ganz nett, aber leider versteht er keine Wahrscheinlichkeit. Ist ihm zu abstrakt, sagt er. “Oder können Sie mir mal so eine Wahrscheinlichkeit in die Hand geben? Können Sie sagen, Achtung, da hinten rennt eine Wahrscheinlichkeit, fang sie!” Magnus ist also ein Freund für des Konkreten. Einige einflussreiche Gruppen an Statistiks unterstützen diese Haltung\nJedenfalls hätte Magnus gerne eine Aussage wie “Vermutlich sehen wir beim nächsten Versuch irgendwas zwischen 4 und 7 Treffern”.\nNatürlich haben Sie den Anspruch, eine wissenschaftlich belastbare Aussage zu tätigen.\nWas nun? Sie müssen sozusagen die Post-Verteilung in eine Post-Verteilung der Beobachtungen, also der konkreten Werte - in diesem Fall die Anzahl der Wassertreffer - übersetzen. Genau das macht die PPV für Sie!\n\n\n\n7.6.2 Visualisierung der PPV\nDer Prozess des gewichteten Zusammenfassens der Stichprobenverteilungen ist in Abbildung 7.4 dargestellt.\n\n\n\nAbbildung 7.4: PPV als gewichtetes Kombinieren der Stichprobenverteilungen\n\n\nQuelle: McElreath (2020)\n\n\n7.6.3 PPV berechnen\nDie PPV für unseren Standard-Globusversuch (\\(N=9\\)) berechnen wir so:\nWir berechnen viele (z.B. \\(10^4\\)) Stichprobenverteilungen. Dabei müssen wir jedes Mal fragen, wie groß die Wahrscheinlichkeit \\(\\pi\\) für Wasser17 ist. Wasseranteile \\(\\pi\\), die laut Post-Verteilung wahrscheinlich sind, müssen wir entsprechend oft als Parameterwert (\\(\\pi\\)) der Stichprobenverteilung verwenden; umgekehrt dürfen wir nur wenige Stichprobenverteilungen für unwahrscheinliche Parameterwerte erstellen.\nBeispielsweise würden wir viele Stichprobenverteilungen für \\(\\pi=.7\\) erstellen; für \\(\\pi=0.01\\) würden wir wenige Stichprobenverteilungen erstellen, s. Abbildung 7.4.\nGlücklicherweise spiegelt unsere Stichproben-Postverteilung samples wahrscheinlichere Parameterwerte wieder, indem wahrscheinlichere Parameterwerte häufiger vorkommen.\n\n\n\n\n\n\nHinweis\n\n\n\nWahrscheinliche Parameterwerte kommen in der Stichproben-Postverteilung samples häufiger vor. Die Häufigkeit der Parameterwerte spiegelt die Wahrscheinlichkeit der jeweiligen Parameterwerte in der (theoretischen) Postverteilung wider.\n\n\nSchauen Sie sich vielleicht zur Erinnerung noch einmal die Definition von samples an, s. Listing 6.1. Tabelle samples, die aus Stichproben aus der Post-Verteilung besteht, ist (in Auszügen) in Tabelle 6.2 dargestellt. Wie die Post-Verteilung auf Basis von Stichproben dann aussieht sieht man in Abbildung 6.2. Globusversuche kann man mit rbinom simulieren, s. Kapitel 7.3.1.\nWir simulieren also viele (z.B \\(10^4\\)) Globusversuche, jeweils mit \\(N=9\\) Würfen. Wahrscheinliche Parameterwerte, etwa \\(\\pi=7\\), sollen häufiger verwendet werden (bei unseren vielen Globusversuchen) als unwahrscheinliche.\nPraktischerweise sind die Werte in der Spalte p_grid in samples so häufig vertreten, wie ihre Wahrscheinlichkeit es erwarten lässt. Hier ist ein Auszug aus samples:\n\n\nCode\nsamples %>% \n  select(p_grid) %>% \n  slice_head(n = 10)\n\n\n\n\n\n\np_grid\n\n\n\n\n0.6666667\n\n\n0.4444444\n\n\n0.7777778\n\n\n0.6666667\n\n\n0.6666667\n\n\n0.7777778\n\n\n0.6666667\n\n\n0.6666667\n\n\n0.8888889\n\n\n0.8888889\n\n\n\n\n\n\nWie man sieht, sind wahrscheinliche Parameterwerte häufiger vertreten.18\np_grid ist also eine Liste19 von Parameterwerten, deren Häufigkeit die Wahrscheinlichkeit der Parameterwerte gewichtet.\nAuf dieser Basis können wir die PPV erstellen:\n\n\nCode\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nhead(ppv)\n\n\n\n\n\n\nvalue\n\n\n\n\n7\n\n\n5\n\n\n7\n\n\n6\n\n\n5\n\n\n5\n\n\n\n\n\n\nSchauen wir uns ein Histogramm aller Trefferzahlen an, s. Abbildung 7.5.20\n\n\n\n\n\nAbbildung 7.5: Die PPV für unseren Standard-Globusversuch (N=9)\n\n\n\n\nDie PPV unseres Modells zeigt uns (Abbildung 7.5), dass wir in künftigen Versuchen zumeist 6 Treffer zu erwarten haben. Aber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar.\n\n\n\n\n\n\nWichtig\n\n\n\nDie PPV zeigt, welche Beobachtungen laut unserem Modell häufig und welche selten sind. Die PPV zeigt keine Parameterwerte, sondern welche Daten (Beobachtungen, Wasserzahlen) wir in künftigen Versuchen wie häufig erwarten können.\n\n\n\nBeispiel 7.4 (Der nächste Planet) Nur zum Spaß spulen wir kurz die Zeit im Universum vor, sagen wir so \\(10^{99}\\) Jahre. Sie arbeiten bei einer Raumfahrtbehörde, die nach neuen Planeten sucht. Nun wurde ein aussichtsreicher Planet gesichtet. Ihre Behörde hat eine Studie gestartet, im Rahmen derer 9 Sonden zu diesem (weit entfernten) Planeten geschossen sind. Von den 9 Sonden sind 6 im Wasser gelandet, was aus Gründen intergalaktischer Wasserknappheit eine gute Nachricht ist.\n\n“Der nächste Planet wird sicher 6 von 9 Wassertreffer erzielen!”\n\n– Presse-Chefi der intergalaktischer SpaceY Raumfahrtsbehörde\nJetzt plant Ihre Behörde den Versuch zu wiederholen: Wieder sollen 9 Sonden zu diesem Planeten geschossen werden. Dis Presse-Chefi21 tönt vollmundig: “Ich bin sicher, dass wir wieder 6 von 9 Treffer, also 6 von 9 Mal Wasser, haben werden!”.\nKann man diese Aussage mit (hoher) Sicherheit leisten? Perfekte Sicherheit gibt es bekanntlich nur, was Tod und Steuern betrifft, aber kann diese Aussage mit zumindest hoher Sicherheit geleistet werden?\nNein, die PPV (Abbildung 7.5) zeigt deutlich, dass unser Wissen nicht ausreicht, um präzise Vorhersagen über künftige Ausgänge des Versuchs zu leisten. So sind auch 5 oder 7 Treffer gut möglich. Auch 4 oder 8 Treffer sind nicht so selten. Sogar 9 Treffer sind nicht super selten.\nDis Presse-Chefi Ihrer Behörde sollte also den Mund nicht so voll nehmen."
  },
  {
    "objectID": "ppv.html#fazit",
    "href": "ppv.html#fazit",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.7 Fazit",
    "text": "7.7 Fazit\n\n7.7.1 Vorhersagen sind schwierig\n… gerade wenn sie die Zukunft betreffen, so ein Sprichwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der häufigste in unseren Stichproben, aber die Vorhersagen haben eine große Streuung, bergen also recht hohe Ungewissheit. Die PPV zeigt also, welche Beobachtungen laut unserem Modell künftig zu erwarten sind, s. Abbildung 7.5.\nWürde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hätten die Vorhersagen zu wenig Streuung in den Vorhersagen, würden also die Ungewissheit nicht ausreichend abbilden. Es würde Übergewissheit (Overconfidence, Overfitting) resultieren.\nWir brauchen die PPV. Ohne die PPV können wir nicht seriös abschätzen, wie viel Ungewissheit in unseren Vorhersagen steckt.\n\n\n7.7.2 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells (“intrinsische” Ungewissheit): Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiß, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nächste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, möchte man beide Arten von Ungewissheit berücksichtigen: Das macht die Posteriori-Prädiktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prädiktiv) und mit welcher Häufigkeit, basierend auf der Post-Verteilung.\n\n\n\n\n\n\nHinweis\n\n\n\nDer Unterschied zwischen der Post-Verteilung und der PPV ist erstmal, dass die PPV Ausprägungen in ihrer Wahrscheinlichkeit bemisst, also z.B. wie wahrscheinlich 4 von 9 Wassertreffern sind. Die Post-Verteilung bemisst die Wahrscheinlichkeit von Parameterwerten, also z.B. des Wasseranteils.\nEtwas tiefer betrachtet zeigt die PPV zwei Arten von Ungewissheit, die Post-Verteilung nur eine. Die PPV zeigt erstens die Ungewissheit zur Verteilung des Parameters (wie die Post-Verteilung), aber auch noch die intrinsische Ungewissheit. Denn auch wenn wir keine Ungewissheit zum Parameter hätten, bliebe Ungewissheit, welche Beobachtungen sich manifestieren. Insofern ist die PVV “ehrlicher”, sie spiegelt die Ungewissheit zu den Beobachtungen wider.\n\n\n\n\n7.7.3 Vergleich der Verteilungen\nAbbildung 7.6 stellt die in diesem Kapitel diskutierten Verteilungen gegenüber:\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-Prädiktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter Berücksichtigung der Unsicherheit der Posteriori-Verteilung\n\n\n\n\n\n\nAbbildung 7.6: Post- vs. Stichproben- vs. PP-Verteilungen\n\n\n\n\nQuelle: R. McElreath\n\n\n7.7.4 So viele Verteilungen…\n\nDie Posteriori-Verteilung gibt Aufschluss zur Häufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass “in Wirklichkeit” der Wasseranteil 70% beträgt, also \\(\\pi=.7\\)\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\nDie PPV gibt Aufschluss zur Häufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter Durchführung, zu erwarten.\nFür die Praxis kann das eine interessante Frage sein.\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklärt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden."
  },
  {
    "objectID": "ppv.html#aufgaben",
    "href": "ppv.html#aufgaben",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.8 Aufgaben",
    "text": "7.8 Aufgaben\n\nZwielichter Dozent-Bayes\nWarum Bayes?\nsubjektiv-Bayes\nLikelihood2\nAnteil-Apple\nReThink3m1\nReThink3m2\nReThink3m3\nReThink3m4\nReThink3m5\nQuiz zu Verteilungen\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "gauss.html",
    "href": "gauss.html",
    "title": "8  Gauss-Modelle",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "gauss.html#lernsteuerung",
    "href": "gauss.html#lernsteuerung",
    "title": "8  Gauss-Modelle",
    "section": "8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nein Gaussmodell spezifizieren und inR berechnen\nan Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt\n\n\n\n8.1.2 Benötigte R-Pakete\nFür rstanarm wird ggf. weitere Software benötigt.\n\n\n\n\n\n\nHinweis\n\n\n\nSoftware, und das sind R-Pakete, müssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio müssen Sie die (benötigten!) Pakete starten.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n\n8.1.3 Begleitvideos\n\nTeil 1\nTeil 2"
  },
  {
    "objectID": "gauss.html#wie-groß-sind-die-kung-san",
    "href": "gauss.html#wie-groß-sind-die-kung-san",
    "title": "8  Gauss-Modelle",
    "section": "8.2 Wie groß sind die !Kung San?",
    "text": "8.2 Wie groß sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\nIn diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung, s. Abbildung 8.1.\nThe ǃKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names ǃKung (ǃXun) and Ju are variant words for ‘people’, preferred by different ǃKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of ǃKung people live in the villages of Bantu pastoralists and European ranchers.\nQuelle\n\n\n\n\n\n\n\n(a) Kung People\n\n\n\n\n\n\n\n(b) Verbreitung der Kung-Sprachen\n\n\n\n\nAbbildung 8.1: Die !Kung im südlichen Afrika\n\n\nQuelle: Internet Archive Book Images, No restrictions, via Wikimedia Commons\nQuelle: By Andrewwik.0 - Own work, CC BY-SA 4.0,]\n\n\n8.2.2 !Kung Data\nZuerst laden wir die Daten; Quelle der Daten ist McElreath (2020) mit Bezug auf Howell.\nDatenquelle\n\n\nCode\nKung_path <-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd <- data_read(Kung_path)  # aus dem Paket `easystats`\n\nhead(d)\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n151.765\n47.82561\n63\n1\n\n\n139.700\n36.48581\n63\n0\n\n\n136.525\n31.86484\n65\n0\n\n\n156.845\n53.04191\n41\n1\n\n\n145.415\n41.27687\n51\n0\n\n\n163.830\n62.99259\n35\n1\n\n\n\n\n\n\nWir interessieren uns für die Größe der erwachsenen !Kung, also filtern wir die Daten entsprechend und speichern die neue Tabelle als d2.\n\n\nCode\nd2 <- d %>% \n  filter(age >= 18)\n\nnrow(d2)\n## [1] 352\n\n\n\\(N=352\\).\nLassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. {easystats} macht das tatsächlich recht easy.\n\n\nCode\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n\n  \n  \n    \n      Variable\n      Mean\n      SD\n      IQR\n      Min\n      Max\n      Skewness\n      Kurtosis\n      n\n      n_Missing\n    \n  \n  \n    height\n154.60\n7.74\n12.06\n136.53\n179.07\n0.15\n−0.48\n352.00\n0\n    weight\n44.99\n6.46\n9.19\n31.07\n62.99\n0.13\n−0.51\n352.00\n0\n    age\n41.14\n15.97\n23.00\n18.00\n88.00\n0.67\n−0.21\n352.00\n0\n    male\n0.47\n0.50\n1.00\n0.00\n1.00\n0.13\n−2.00\n352.00\n0\n  \n  \n  \n\n\n\n\n\n\n8.2.3 Wir gehen apriori von normalverteilter Größe Der !Kung aus\nForschungsfrage: Wie groß sind die erwachsenen !Kung im Durchschnitt?\nWir interessieren uns also für den Mittelwert der Körpergröße (erwachsener Kung beider Geschlechter), \\(\\mu\\).\n\n\n\nMensch\n\n\nQuelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, via Wikimedia Commons 3.0\nWir sind uns über diesen Mittelwert nicht sicher1, und unsere Ungewissheit quantifizieren wir anhand einer Normalverteilung mit Mittelwert von 178cm und Streuung von 20 cm:\n\\[\\mu \\sim \\mathcal{N}(178, 20)\\]\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.2 In einer echten Untersuchung sollte man immer einen inhaltlichen Grund für einen Priori-Wert haben. Oder man wählt “schwach informative” Prioris, wie das {rstanarm} tut: Damit lässt man kaum Vorab-Information in das Modell einfließen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).\n\n\n\n\n\n\nHinweis\n\n\n\nWir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: Eine Gleichverteilung der Körpergrößen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. Darüber hinaus ist eine Normalverteilung nicht unplausibel."
  },
  {
    "objectID": "gauss.html#die-exponentialverteilung",
    "href": "gauss.html#die-exponentialverteilung",
    "title": "8  Gauss-Modelle",
    "section": "8.3 Die Exponentialverteilung",
    "text": "8.3 Die Exponentialverteilung\n\n8.3.1 Die Apfel-fällt-nicht-weit-vom-Stamm-Verteilung\nDarf ich vorstellen …\nBevor wir unser Kung-Modell spezifizieren können, sollten wir noch überlegen, welches Vorab-Wissen wir zur Streuung um den Mittelwert herum haben. Da wir uns nicht 100% sicher zur gesuchten Größe sind, müssen wir angeben, wie groß die Streuung um den Mittelwert sein soll. Hier werden wir eingestehen, dass wir uns auch nicht 100% sicher sind, wie groß die Streuung exakt ist. Also geben wir eine Verteilung für die Streuung an.\nEtwas Wissen über diese Verteilung haben wir:\n\nEine Streuung muss positiv sein (es gibt keine negative Streuung).\nEine Gleichverteilung der Streuung ist vielleicht möglich, aber nicht sehr plausibel.\nWenn wir der Meinung sind, der Mittelwert betrage “ungefähr 178cm”, so halten wir 180cm für plausibel, aber 18000 cm für unmöglich und schon 200 für sehr unplausibel. Also: Je größer die die Abweichung vom Mittelwert desto unplausibler.\n\nDiese Anforderungen3 spiegeln sich in Abbildung 8.2 wider. Außerdem zeigt die Abbilung verschiedene Quantile, wie das 95%-Quantil, das bei 3 liegt; 95% der Werte dieser Verteilung sind also nicht größer als 3.\n\n\nCode\nd <-\n  tibble(\n    x = seq(0, 5,.1),\n    y = dexp(x, rate = 1)\n  )\n\n\nd_qs <-\n  tibble(\n    prob = c(0.05, .25, .50, .75, .95),\n    q = qexp(prob) \n  )\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line() +\n  geom_area(fill = \"grey60\") +\n  geom_vline(data = d_qs,\n             aes(xintercept = q)) +\n  geom_label(data = d_qs,\n             aes(x = q, \n                 label = prob,\n                 y = prob)) +\n  labs(\n       caption = \"Vertikale Striche zeigen die Quantile für 5%, 25%, 50%, 75%, 95%\",\n       y = \"Dichte\")\n\n\n\n\n\nAbbildung 8.2: Die Exponentialverteilung mit einigen ihrer Quantilen\n\n\n\n\nFür eine exponentialverteilte Variable \\(X\\) schreibt man auch:\n\\[X \\sim \\operatorname{Exp}(1)\\]\nEine Verteilung dieser Form nennt man Exponentialverteilung.\n\nEine Exponentialverteilung ist nur für positive Werte, \\(x>0\\), definiert.\nSteigt X um eine Einheit, so ändert sich Y um einen konstanten Faktor.\nSie hat nur einen Parameter, genannt Rate oder \\(\\lambda\\) (“lambda”).\n\\(\\frac{1}{\\lambda}\\) gibt gleichzeitig Mittelwert und Streuung (“Gestrecktheit”) der Verteilung an.\nJe größer die Rate \\(\\lambda\\), desto kleiner die Streuung und der Mittelwert der Verteilung.\nJe größer \\(1/\\lambda\\), desto größer die Streuung und der Mittelwert der Verteilung.\n\nOhne auf die mathematischen Eigenschaften im Detail einzugehen, halten wir fest, dass der Graph dieser Funktion gut zu unseren Plänen passt.\n\n\n8.3.2 Visualisierung verschiedener Exponentialverteilungen\nSchauen wir uns einige Beispiele von Exponentialverteilungen an. Unterschiede in Exponentialverteilungen sind rein auf Unterschiede in \\(\\lambda\\) (lambda) zurückzuführen, s. Abbildung 8.3.\n\n\n\n\n\n\n\n\nAbbildung 8.3: Beispiele von Expnentialverteilungen mit unterschiedlichem lambda\n\n\n\n\nWie wir in Abbildung 8.3 sehen, könnte eine Exponentialverteilung mit \\(\\lambda=1/8\\) grob passen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie “richtigen” Priori-Verteilung zu finden, bzw. die richtigen Parameter für die Priori-Verteilung zu wählen, ist nicht möglichn, denn es gibt nicht die eine, richtige Priori-Verteilung. Eine “gut passende” Verteilung zu finden, ist häufig nicht leicht. Gut beraten ist man mit der Regel, im Zweifel lieber eine liberale Verteilung zu wählen, die einen breiteren Raum an möglichen Werten zulässt. Allerdings sollte man nicht das Baby mit dem Wasser auskippen und extreme Werte, wie mehrere Meter Körpergröße Streuung, erlauben.\n\n\nMan kann sich die Quantile der Exponentialverteilung mit qexp ausgeben lassen, wobei mit man p den Wert der Verteilungsfunktion angibt, für den man das Quantil haben möchte. Mit rate wird \\(\\lambda\\) bezeichnet.\nDieser Aufruf zum Beispiel:\n\n\nCode\nqexp(p = .5, rate = 1/8)\n## [1] 5.545177\n\n\nGibt uns die Verteilungsfunktion einer Exponentialverteilung mit Rate (\\(\\lambda\\)) von 1/8 zurück, ca. 5.5.\nDie Grenzen der inneren 95% dieser Verteilung kann man sich so ausgeben lassen:\n\n\nCode\nqexp(p = c(0.025, .975), rate = 1/8)\n## [1]  0.2025425 29.5110356\n\n\nDiese Grenzen scheinen hinreichend weit, das wir noch von den Daten überrascht werden können, aber schmal genug, um unsinnige Werte auszuschließen. Ein guter Start! Weiter geht’s!"
  },
  {
    "objectID": "gauss.html#unser-gauss-modell-der-kung",
    "href": "gauss.html#unser-gauss-modell-der-kung",
    "title": "8  Gauss-Modelle",
    "section": "8.4 Unser Gauss-Modell der !Kung",
    "text": "8.4 Unser Gauss-Modell der !Kung\n\n8.4.1 Modelldefinition\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior für \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior für \\(\\sigma\\): \\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\nDaher: \\(95\\%KI( \\mu): 178 \\pm 40\\)\nIn Abbildung 8.4 sind unsere Priori-Verteilungen visualisiert.\n\n\n\n\n\nAbbildung 8.4: Unser (erstes) Kung-Modell\n\n\n\n\n\n\n8.4.2 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\nDie Körpergrößen der einzelnen Personen \\(h_i\\) nehmen wir als normalverteilt an mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})\\]\n\n\n8.4.3 Prioris\nMittelwert der Größe ist normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)}\\]\nDie Streuung \\(\\sigma\\) der Größen ist exponentialverteil mit \\(\\lambda = 1/8\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(1/8)}\\]\n\n\n8.4.4 Fertig!\nJetzt haben wir unser Modell definiert!\nWeil es so schön ist, schreiben wir es hier noch einmal auf, Gleichung 8.1.\n\\[\n\\begin{aligned}\nh_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\n\\mu &\\sim \\mathcal{N}(178, 20) \\\\\n\\sigma &\\sim \\mathcal{E}(1/8)\n\\end{aligned}\n\\tag{8.1}\\]\nZur Berechnung nutzen wir jetzt dieses Mal aber nicht die Gittermethode (Bayes-Box), sondern lassen R die Arbeit verrichten.\nDa gibt es einen neuen Golem, ziemlich kräftig der Bursche, der soll die Arbeit für uns tun. Der Golem hört auf den Namen rstanarm4."
  },
  {
    "objectID": "gauss.html#zufällige-motivationsseite",
    "href": "gauss.html#zufällige-motivationsseite",
    "title": "8  Gauss-Modelle",
    "section": "8.5 Zufällige Motivationsseite",
    "text": "8.5 Zufällige Motivationsseite"
  },
  {
    "objectID": "gauss.html#posteriori-verteilung-des-größen-modells-m41",
    "href": "gauss.html#posteriori-verteilung-des-größen-modells-m41",
    "title": "8  Gauss-Modelle",
    "section": "8.6 Posteriori-Verteilung des Größen-Modells, m41",
    "text": "8.6 Posteriori-Verteilung des Größen-Modells, m41\nOkay, Golem, an die Arbeit! Berechne uns das Kung-Modell! Nennen wir das Modell m415.\n\n\nCode\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)\nm41_post <- as_tibble(m41)  # Modellergebnis in Tabelle umwandeln\nnames(m41_post) <- c(\"mu\", \"sigma\")  # schönere Namen für die Spalten\n\n\nDas Argument refresh = 0 verhindert, dass die Details zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrücke.\nstan_glm ist eine Funktion, mit der man Regressionsmodelle berechnen kann. Nun haben wir in diesem Fall kein “richtiges” Regressionsmodell. Man könnte sagen, wir haben eine AV (Körpergröße), aber keine UV (keine Prädiktoren). Glücklicherweise können wir auch solche “armen” Regressionsmodelle formulieren:\nav ~ 1 bzw. in unserem Beispiel height ~ 1 bedeutet, dass man nur die Verteilung der AV berechnen möchte, aber keine Prädiktoren hat (das soll die 1 symbolisieren).\nFür das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung der Prioris von rstanarm zurück. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wäre, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die Posteriori-Verteilung von m41, s. Abbildung 8.5.\n\n\nCode\nm41_post %>% \n  ggplot() +\n  aes(x = mu, y = sigma) %>% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\n\nAbbildung 8.5: Die gemeinsame Verteilung von Mittelwert und Streuung.\n\n\n\n\nDa das Modell zwei Parameter hat, können wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen können die Parameter korreliert sein.\nAbbildung 8.5 erlaubt uns, für jede Kombination von Mittelwert und Streuung zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.\nHier sind noch zwei andere Visualisierungen der Post-Verteilung von m42, s. Abbildung 8.6.\n\n\n\n\n\nAbbildung 8.6: Die Postverteilung in unterschiedlicher Darstellung\n\n\n\n\nNatürlich können wir auch nur einen Parameter plotten.\nFassen wir die Ergebnisse dieses Modells zusammen:\n\nWir bekommen eine Wahrscheinlichkeitsverteilung für \\(\\mu\\) und eine für \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, für die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte für \\(\\mu\\) und \\(\\sigma\\) klein: Die große Stichprobe hat die Priori-Werte überstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so können wir interessante Fragen stellen.\n\n\n8.6.1 Hallo, Posteriori-Verteilung\n… wir hätten da mal ein paar Fragen an Sie. 🕵\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person größer als 1,55m?\nWelche mittlere Körpergröße wird mit 95% Wahrscheinlichkeit nicht überschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die Schätzung der mittleren Körpergröße behaftet?\nWas ist der mediane Schätzwert der mittleren Körpergröße, sozusagen der “Best Guess”?\n\nAntworten folgen etwas weiter unten.\nAbschließend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\), Abbildung 8.7.\n\n\n\n\n\nAbbildung 8.7: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen für mu und für sigma\n\n\n\n\n\n\n8.6.2 Posteriori-Stichproben mit stan_glm() berechnen\nMit stan_glm() können wir komfortabel die Posteriori-Verteilung berechnen. Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - ähnlich. Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). Gibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurück.\nGrob gesagt berechnen wir die Post-Verteilung mit stan_glm so:\n\n\nCode\nlibrary(rstanarm)  # Paket muss gestartet sein.\n\n# berechnet Post.-Vert.:\nstan_glm(\n  # modelldefinition:\n  AV ~ UV,\n  # Datensatz:\n  data = meine_daten\n)\n\n\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior zum Größenmittelwert\n\\(\\sigma \\sim \\mathcal{E}(0.125)\\), Prior zur Streuung der Größen\n\n\n8.6.3 Ausgabe von stan_glm()\nWir können, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, und diese z.B. plotten.\nWir können es aber auch komfortabler haben … Mit dem Befehl parameters kann man sich die geschätzten Parameterwerte einfach ausgeben lassen.\n\n\nCode\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket `easystats`\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.60\n(153.79, 155.35)\n100%\n1.001\n3030.00\nNormal (154.60 +- 19.36)\n\n\n\n\n\nDas Wesentliche: Unser Golem schätzt den Größenmittelwert der Kung auf ca. 155cm bzw. auf einen Bereich von etwa 153.7875529 bis 155.3477557 schätzt.\nInformativ ist vielleicht noch, dass wir den Prior erfahren, der im Modell verwendet wurde. Dazu später mehr.\nIn dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie pd, Rhat und ESS. Kein Problem: Einfach ignorieren :-)\nWer Näheres wissen will, findet hier einen Anfang. Außerdem sei an McElreath (2020) und Gelman, Hill, und Vehtari (2021) verwiesen."
  },
  {
    "objectID": "gauss.html#wie-tickt-stan_glm",
    "href": "gauss.html#wie-tickt-stan_glm",
    "title": "8  Gauss-Modelle",
    "section": "8.7 Wie tickt stan_glm()?",
    "text": "8.7 Wie tickt stan_glm()?\n\n\n\n\n\nQuelle\nHier ein paar Kernimnfos zu stan_glm:\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan für uns bereit.\nstan_glm() ist für die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schätzen, so hat man man … eine Regression ohne Prädiktor.\nEine Regression ohne Prädiktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also für die nicht vorhandene UV; y meint die AV (height).\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\nMehr findet sich in der Dokumentation von RstanArm.\n\n8.7.1 Schätzwerte zu den Modellparameter\nDie Parameter eines Modells sind die Größen, für die wir eine Priori-Verteilung annehmen sowie einen Likelihood und dann aus den Daten schätzen. Ich sage schätzen um hervorzuheben, dass wir die wahren Werte nicht kennen, sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren.\nWie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren Schätzungen) einfach mit parameters(modellname) auslesen.\n\n\n8.7.2 Stichproben aus der Posteriori-Verteilung ziehen\nWie wir es vom Globusversuch gewohnt sind, können wir aber auch Stichproben aus der Post-Verteilung ziehen.\nHier die ersten paar Zeilen von post_m41:\n\n\nCode\npost_m41 <- as_tibble(m41)\nhead(post_m41)\n\n\n\n\n\n\n(Intercept)\nsigma\n\n\n\n\n154.6373\n8.317947\n\n\n154.9276\n7.638285\n\n\n154.4969\n7.023710\n\n\n154.7020\n7.918491\n\n\n155.1503\n7.580628\n\n\n153.9865\n7.471944\n\n\n\n\n\n\nIn einer Regression ohne Prädiktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte (Intercept) Aufschluss über unsere Schätzwerte zu \\(\\mu\\) (der Körpergröße).\n\n\nBeispiel 8.1 (Mit welcher Wahrscheinlichkeit ist \\(\\mu>155\\)?) \n\nCode\nnames(post_m41) <- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prägnanter\n\npost_m41 %>% \n  count(mu > 155) %>% \n  mutate(prop = n/sum(n))\n\n\n\n\n\n\nmu > 155\nn\nprop\n\n\n\n\nFALSE\n3374\n0.8435\n\n\nTRUE\n626\n0.1565\n\n\n\n\n\n\nDie Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschließen, dass die Kung im Schnitt größer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind.\n\n\n\nBeispiel 8.2 (Mit welcher Wahrscheinlichkeit ist \\(\\mu>165\\)?) \n\nCode\nnames(post_m41) <- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist prägnanter\n\npost_m41 %>% \n  count(mu > 165) %>% \n  mutate(prop = n/sum(n))\n\n\n\n\n\n\nmu > 165\nn\nprop\n\n\n\n\nFALSE\n4000\n1\n\n\n\n\n\n\nOh, diese Hypothese können wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschließen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese \\(\\mu > 165\\) auszuschließen ist nur dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.\n\n\n\nBeispiel 8.3 (Welche mittlere Körpergröße wird mit 95% Wahrscheinlichkeit nicht überschritten, laut dem Modell m41?) \n\nCode\npost_m41 %>% \n  summarise(q95 = quantile(mu, .95))\n\n\n\n\n\n\nq95\n\n\n\n\n155.2329\n\n\n\n\n\n\n\n\n\nBeispiel 8.4 (In welchem 90%-PI liegt \\(\\mu\\) vermutlich?) \n\nCode\npost_m41 %>% \n  eti()\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\nmu\n0.95\n153.787553\n155.347756\n\n\nsigma\n0.95\n7.202283\n8.358525\n\n\n\n\n\n\nEin ETI ist synonym zu PI.\n\n\n\nBeispiel 8.5 (Mit welcher Unsicherheit ist die Schätzung der mittleren Körpergröße behaftet?) \n\nCode\nm41 %>% \n  parameters()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n154.5979\n0.95\n153.7876\n155.3478\n1\n1.000545\n3030.146\nnormal\n154.5971\n19.35583\n\n\n\n\n\n\nSeeing is believing:\n\n\nCode\nm41 %>% \n  parameters() %>% \n  plot(show_intercept = TRUE)\n\n\n\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren Körpergröße liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\n\n\nBeispiel 8.6 (Was ist der mediane Schätzwert der mittleren Körpergröße, sozusagen der “Best Guess”?) parameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\n\n🏋️ Ähnliche Fragen bleiben als Übung für die Lesis 🤓.\n\n\n8.7.3 Standard-Prioriwerte bei stan_glm()\nstan_glm() nimmt für uns Priori-Wert an. Welche das sind, kann man sich so anzeigen lassen:\n\n\nCode\nprior_summary(m41)\n## Priors for model 'm41' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 155, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 155, scale = 19)\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.13)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben. Es werden dafür die Stichproben-Daten als Priori-Daten verwendet: Mittelwerte und Streuungen der AV werden als Grundlage für die Priori-Verteilungen herangezogen. Strenggenommen ist das nicht “pures Bayes”, weil die Priori-Werte ja vorab, also vor Kenntnis der Daten bestimmt werden sollen. Bitte reichen Sie Ihre Beschwerden bei Andrew Gelman ein.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. Die Voreinstellung ist nicht zwingend; andere Werte wären auch denkbar.\n\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (für \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals “Streuung”, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen.\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wählen, dass man nicht übergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschließen.\n\n\n\n\n\n\nWichtig\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einfließen zu lassen und eigene Entscheidungen zu begründen. Häufig sind mehrere Entscheidungen möglich. Möchte man lieber vorsichtig sein, weil man wenig über den Gegenstand weiß, dann könnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die “schwachinformativ” ist, also nur wenig Priori-Information ind das Modell einfließen lässt."
  },
  {
    "objectID": "gauss.html#modell-m42-unsere-priori-werte",
    "href": "gauss.html#modell-m42-unsere-priori-werte",
    "title": "8  Gauss-Modelle",
    "section": "8.8 Modell m42: unsere Priori-Werte",
    "text": "8.8 Modell m42: unsere Priori-Werte\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einfließen, in unserem zweiten Kung-Modell, m42.\n\n8.8.1 m42\nDann lassen wir stan_glm() unser zweites Modell berechnen. Dieses Mal geben wir die Priori-Werte explizit an.\n\n\nCode\nm42 <- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.125),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nPrior_Distribution\nPrior_Location\nPrior_Scale\n\n\n\n\n(Intercept)\n154.6083\n0.95\n153.8345\n155.3875\n1\n1.00001\n2901.489\nnormal\n178\n20\n\n\n\n\n\n\nWir haben noch nicht alle Informationen kennengelernt, die hier ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige Fähigkeit im Studium 🤓.\n\n\n\n\n\n\nWichtig\n\n\n\nVergleichen Sie die Parameterwerte von m41 und m42! Was fällt Ihnen auf? Nichts? Gut! Tatsächlich liefern beide Modelle sehr ähnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, weil wir genug Daten haben. Hat man einigermaßen viele Daten, so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gewählt waren.\n\n\n\n\n\n\n\n8.8.2 Posteriori-Verteilung und Parameter plotten\n\n\nCode\nm42 %>% \n  as_tibble() %>% \n  ggplot(aes(x = `(Intercept)`)) +\n  geom_histogram()\n\n\n\n\n\nEin Vergleich mehrerer Priori-Werte wäre auch nützlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewählten Priori-Werte zu überzeugen."
  },
  {
    "objectID": "gauss.html#fazit",
    "href": "gauss.html#fazit",
    "title": "8  Gauss-Modelle",
    "section": "8.9 Fazit",
    "text": "8.9 Fazit\nWir haben die Posteriori-Verteilung für ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Prädiktoren, betrachtet. Die Zielvariable, Körpergröße (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen. Für \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung für \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n\n\n🧡 Bleiben Sie dran!"
  },
  {
    "objectID": "gauss.html#wahl-der-priori-werte",
    "href": "gauss.html#wahl-der-priori-werte",
    "title": "8  Gauss-Modelle",
    "section": "8.10 Wahl der Priori-Werte",
    "text": "8.10 Wahl der Priori-Werte\n🏎️ Dieser Abschnitt ist eine VERTIEFUNG und nicht prüfungsrelevant. 🏎\n\n8.10.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\n\nCode\nn <- 1e4\n\nsim <- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %>% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd <- \n  sd(sim$height) %>% round()\nheight_sim_mean <- \n  mean(sim$height) %>% round()\n\n\n💭 Was denkt der Golem (m41) apriori von der Größe der !Kung?\n🦾 Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voilà:\n\n\nCode\np3 <- \n  sim %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MW±3SD\",\n       x = \"Größe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\n\nQuellcode\n\n\n8.10.2 Priori-Werte prüfen mit der Priori-Prädiktiv-Verteilung\n\nDie Priori-Prädiktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo können wir prüfen, ob die Priori-Werte vernünftig sind.\n\nDie Priori-Prädiktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Größenwerten zulassen:\n\n\nCode\np3\n\n\n\n\n\nAnteil \\(h_i > 200\\):\n\n\nCode\nanteil_großer_kung <- \nsim %>% \n  count( height > 200) %>% \n  mutate(prop = n/sum(n))\nanteil_großer_kung\n\n\n\n\n\n\nheight > 200\nn\nprop\n\n\n\n\nFALSE\n8296\n0.8296\n\n\nTRUE\n1704\n0.1704\n\n\n\n\n\n\n🤔 Sehr große Buschleute? 17 Prozent sind größer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsläufig ein schlechter Prior sein.\n\n\n8.10.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n8.10.4 Extrem vage Priori-Verteilung für die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n\nCode\n# simulate\nset.seed(4)\n\nsim2 <-\n  tibble(sample_mu    = rnorm(n, mean = 178, sd = 100),\n         sample_sigma = rexp(n, rate = .01)) %>% \n  mutate(height = rnorm(n, mean = sample_mu, sd = sample_sigma))\n\n# compute the values we'll use to break on our x axis\nbreaks <-\n  c(mean(sim2$height) - 3 * sd(sim2$height), 0, mean(sim2$height), mean(sim2$height) + 3 * sd(sim2$height)) %>% \n    round(digits = 0)\n\n# this is just for aesthetics\ntext <-\n  tibble(height = 272 - 25,\n         y      = .0013,\n         label  = \"größter Mann\",\n         angle  = 90)\n\n# plot\np4 <-\n  sim2 %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"black\") +\n  geom_vline(xintercept = 0, color = \"grey92\") +\n  geom_vline(xintercept = 272, color = \"grey92\", linetype = 3) +\n  geom_text(data = text,\n            aes(y = y, label = label, angle = angle),\n            color = \"grey92\") +\n  scale_x_continuous(breaks = breaks, \n                     limits = c(-400, 700)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\\nmu ~ dnorm(178, 100)\\nsigma ~ E(0.01)\",\n       x = \"Größe\",\n       caption = \"X-Achse zeigt MW±3SD\") +\n  theme(panel.grid = element_blank()) \n\np4\n\n\n\n\n\nDie Streuung der Größen ist weit:\n\n\nCode\nd <- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n\n🤔 Das Modell geht apriori von ein paar Prozent Menschen mit negativer Größe aus. Ein Haufen Riesen 👹 werden auch erwartet.\n🤯 Vage (flache, informationslose, “neutrale”, “objektive”) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen."
  },
  {
    "objectID": "gauss.html#aufgaben",
    "href": "gauss.html#aufgaben",
    "title": "8  Gauss-Modelle",
    "section": "8.11 Aufgaben",
    "text": "8.11 Aufgaben\n\nstan_glm01\nReThink4e1\nReThink4e2\nReThink4e3\nKung-height\nPupil-size\nIQ-Studentis\nPriori-Streuung\nPriorwahl1\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "lineare-modelle.html",
    "href": "lineare-modelle.html",
    "title": "9  Lineare Modelle",
    "section": "",
    "text": "Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Post-Verteilung für einfache lineare Modelle in R berechnen\nzentrale Informationen zu Modellparametern - wie Lage- oder Streuungsmaße und auch Schätzintervalle - aus der Post-Verteilung herauslesen\nkünftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n\n\n\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket {easystats} verwenden: Hier finden Sie eine Übersicht aller Funktionen des Pakets.1\n\n\n\n\nPrädiktoren zentrieren"
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-der-regression",
    "href": "lineare-modelle.html#post-verteilung-der-regression",
    "title": "9  Lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\nDie (einfache) Regression prüft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhängen. Je mehr sie zusammenhängen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt). Hängen \\(X\\) und \\(Y\\) zusammen, heißt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwischen \\(X\\) und \\(Y\\) gibt. Linear ist ein Zusammenhang, wenn der Zuwachs in \\(Y\\) relativ zu \\(X\\) konstant ist: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).\nDatenquelle, McElreath (2020).\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und Größe (Y), Abbildung 9.1.\n\n\nCode\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd <- read_csv(Kung_path)  \n\nd2 <- \n  d %>% \n  filter(age > 18) \n\nd2 %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nAbbildung 9.1: Der Zusammenhang von Größe und Gewicht im !Kung-Datensatz\n\n\n\n\n\n\n9.2.2 Bei jedem Prädiktorwert eine Post-Verteilung für \\(\\mu\\)\nKomfort pur: Unser Modell erlaubt uns für jeden beliebigen Wert des Prädiktors eine Post-Verteilung (von \\(\\mu\\)) zu berechnen.\nHier am Beispiel von m42, s. Abbildung 9.2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 9.2: Für jeden beliebigen Prädiktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgewählten Gewichtswerten. B: Für jeden beliebigen Gewichtswert bekommt man eine Post-Verteilung\n\n\n\n\n\n\n9.2.3 Statistiken zum !Kung-Datensatz\nDatenquelle\nHier sind die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n\nCode\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd <- read_csv(Kung_path)  \n\nd2 <- d %>% filter(age > 18)\n\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nheight\n154.6443688\n7.7735641\n12.065000\n136.52500\n179.07000\n0.1434736\n-0.4973852\n346\n0\n\n\nweight\n45.0455429\n6.4552197\n9.135626\n31.52464\n62.99259\n0.1398158\n-0.5317283\n346\n0\n\n\nage\n41.5397399\n15.8093044\n22.000000\n19.00000\n88.00000\n0.6758624\n-0.2014534\n346\n0\n\n\nmale\n0.4739884\n0.5000461\n1.000000\n0.00000\n1.00000\n0.1046415\n-2.0006483\n346\n0\n\n\nweight_c\n0.0000000\n6.4552197\n9.135626\n-13.52090\n17.94705\n0.1398158\n-0.5317283\n346\n0\n\n\n\n\n\n\nDas mittlere Körpergewicht (weight) liegt bei ca. 45kg (sd 7 kg).\n\n\n9.2.4 Etwas mehr EDA\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\nCode\nlibrary(DataExplorer)\n\n\n\n9.2.4.1 Gibt es fehlende Werte?\nNein, s. Abb. Abbildung 9.3.\n\n\nCode\nd2 %>% plot_missing()\n\n\n\n\n\nAbbildung 9.3: Fehlende Werte - fehlen.\n\n\n\n\n\n\n9.2.4.2 Verteilung der numerischen Variablen\nBetrachten wir die Verteilung der numerischen Variablen des Datensatzes, s. Abbildung 9.4.\n\n\nCode\nd2 %>% plot_histogram()\n\n\n\n\n\nAbbildung 9.4: Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\n\n\n\n\n\n\n9.2.4.3 Verteilung der kategorialen Variablen\nBetrachten wir die Verteilung der kategorialen Variablen des Datensatzes, s. Abbildung 9.5.\n\n\nCode\nd2 %>% plot_bar()\n\n\n\n\n\nAbbildung 9.5: Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\n\n\n\n\n\n\n9.2.4.4 Korrelationen\nDie Korrelationen der (numerischen) Variablen sind in Abbildung 9.6 dargestellt.\n\n\nCode\nd2 %>% plot_correlation()\n\n\n\n\n\nAbbildung 9.6: Korrelationsmatrix\n\n\n\n\n\n\n9.2.4.5 Bonus\nProbieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: create_report(d2).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.5 Prädiktor zentrieren\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Prädiktor “zentrieren”). Wenn man den Prädiktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\alpha\\), einfacher zu verstehen. In einem Modell mit zentriertem Prädiktor (weight) gibt der Achsenabschnitt die Größe einer Person mit durchschnittlichem Gewicht an. Würde man weight nicht zentrieren, gibt der Achsenabschnitt die Größe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist.\nVgl. Gelman, Hill, und Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen:\n\n\nCode\nd3 <- \n  d2 %>% \n  center(weight)\n\n\nOder so, von Hand:\n\n\nCode\nd3 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\n\n  \n  \n    \n      height\n      weight\n      age\n      male\n      weight_c\n    \n  \n  \n    152\n48\n63\n1\n3\n    140\n36\n63\n0\n−9\n    137\n32\n65\n0\n−13\n  \n  \n  \n\n\n\n\nWie man sieht, ist die Verteilung “zur Seite geschoben”: Der Mittelwert liegt jetzt eben bei 0.\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem Prädiktor ist, nicht d2."
  },
  {
    "objectID": "lineare-modelle.html#modell-m43-zentrierter-prädiktor",
    "href": "lineare-modelle.html#modell-m43-zentrierter-prädiktor",
    "title": "9  Lineare Modelle",
    "section": "9.3 Modell m43: zentrierter Prädiktor",
    "text": "9.3 Modell m43: zentrierter Prädiktor\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wäre wohl die Körpergröße? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa wäre es schön, wenn wir die Daten so umformen könnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Glück geht das leicht: Wir zentrieren den Prädiktor (Gewicht)!\n\n\n\n\n\n\nWichtig\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m43\nFür jede Ausprägung des Prädiktors (weight_centered), \\(wc_i\\), wird eine Post-Verteilung für die abhängige Variable (height, \\(h_i\\)) berechnet. Der Mittelwert \\(\\mu\\) für jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel). Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel). Wir brauchen Priori-Werte für die Steigung \\(\\beta\\) und den Achsenabschnitt \\(\\alpha\\) der Regressionsgeraden. Außerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Größe (height) angibt; dieser Wert wird als exonentialverteilt angenommen. Der Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\).\n\\[\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDer Achsenabschnit (engl. intercept) eines Regressionsmodell wird in der Literatur oft mit \\(\\beta_0\\) bezeichnet, aber manchmal auch mit \\(\\alpha\\). Und manchmal mit noch anderen Buchstaben, das Alphabet ist weit. 🤷\n\n\n\n\n9.3.2 Likelihood, m43\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\nDer Likelihood von m43 ist ähnlich zu den vorherigen Modellen (m41, m42). Nur gibt es jetzt ein kleines “Index-i” am \\(\\mu\\) und am \\(h\\) (h wie heights). Es gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern für jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\). Lies etwa so:\n\n“Die Wahrscheinlichkeit, eine bestimmte Größe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))”.\n\n\n\n9.3.3 Regressionsformel, m43\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschätzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\alpha\\) und \\(\\beta\\) ist \\(\\mu\\) ohne Ungewissheit bekannt. \\(\\text{weight}_i\\) ist der Prädiktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz). Lies etwa so:\n\n“Der Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\alpha\\) und \\(\\beta\\) mal \\(\\text{weight}_i\\)”.\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight. \\(\\beta\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden). \\(\\alpha\\) gibt an, wie groß \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n9.3.4 Priori-Werte des Modells m43\n\\[\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\\]\n\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n\\(\\alpha\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine “Regression ohne Prädiktoren” berechnet haben.\n\\(\\sigma\\) ist uns schon als Parameter bekannt und behält seine Bedeutung aus dem letzten Kapitel.\nDa height nicht zentriert ist, der Mittelwert von \\(\\alpha\\) bei 178 und nicht 0.\n\\(\\beta\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Größe positiv (gleichsinnig) ist."
  },
  {
    "objectID": "lineare-modelle.html#vertiefung-prior-prädiktiv-verteilung",
    "href": "lineare-modelle.html#vertiefung-prior-prädiktiv-verteilung",
    "title": "9  Lineare Modelle",
    "section": "9.4 Vertiefung: Prior-Prädiktiv-Verteilung",
    "text": "9.4 Vertiefung: Prior-Prädiktiv-Verteilung\n🏎️ VERTIEFUNG, nicht prüfungsrelevant 🏎️\n\n9.4.1 Moment\n🤔 Moment. Dieser Prior, \\(\\beta\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Größe positiv oder negativ ist? Nein, sind wir nicht.\n\n\n9.4.2 Priori-Prädiktiv-Verteilung für m43\nWas denkt wir bzw. unser Golem apriori über den Zusammenhang von Größe und Gewicht? Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also für \\(\\alpha\\), \\(\\beta\\) und \\(\\sigma\\).\n\n\nCode\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter für Prior-Pred-Verteilung\n             data = d2)\n\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      sigma\n    \n  \n  \n    177.9\n4.3\n2.8\n    158.4\n−6.0\n2.3\n    173.9\n6.4\n22.1\n    155.8\n−8.6\n3.7\n    189.0\n−12.6\n3.8\n  \n  \n  \n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n9.4.3 Prior-Prädiktiv-Simulation für m43 mit stan_glm()\n\n\nCode\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d2)\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\n\n\n\n\n\n9.4.4 Visualisieren der Prior-Prädiktiv-Verteilung\n\n\nCode\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n🤯 Einige dieser Regressionsgeraden sind unsinnig!\n\n\nCode\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die Größe des größten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.5 Ein positiver Wert für \\(\\beta\\) ist plausibler\n\n9.4.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\n👎 \\(\\beta=-20\\) wäre mit diesem Prior gut möglich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n9.4.5.2 Oh yes\nWir bräuchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):\n\n\n\n\n\n👍 Vermutlich besser: Ein Großteil der Wahrscheinlichkeitsmasse ist \\(X>0\\). Allerdings gibt’s keine Gewähr, dass unser Prior “richtig” ist.\n\n\n\n9.4.6 Priori-Prädiktiv-Simulation, 2. Versuch\n\n\nCode\nm43a_prior_pred <-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter für Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d2)\n\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  # Spaltennamen kürzen: \n  rename(a = `(Intercept)`) %>%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      s\n    \n  \n  \n    222.6\n0.8\n7.0\n    187.7\n3.8\n5.2\n    194.1\n2.7\n20.5\n    172.9\n1.1\n5.6\n    180.6\n1.0\n3.4\n  \n  \n  \n\n\n\n\nDas Argument prior_PD = TRUE sorgt dafür, dass keine Posteriori-Verteilung, sondern eine Prior-Prädiktiv-Verteilung berechnet wird.\n\n\n9.4.7 Visualisieren der Prior-Prädiktiv-Verteilung, m43a\nUnsere Priori-Werte scheinen einigermaßen vernünftige Vorhersagen zu tätigen. Allerdings erwartet unser Golem einige Riesen.\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\n\nDie durchgezogene horizontale Linie gibt die Größe des größten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p. 96.\n\n\n9.4.9 Hier ist unser Modell, m43a\n\\[\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\\]\n\n\nCode\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n\n\n\n\n9.4.10 Eine Zusammenfassung der Posteriori-Verteilung für m43a\n\n\nCode\nm43a %>% \n  parameters()\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.09, 155.21)\n100%\n0.999\n4132.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.83, 0.99)\n100%\n1.000\n3837.00\nNormal (5 +- 3)\n\n\n\n\n\nUnser Modell m43a schätzt die typische Körpergröße einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugehörige 95%-CI keine 20 Zentimenter umfasst."
  },
  {
    "objectID": "lineare-modelle.html#die-post-verteilung-befragen",
    "href": "lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9  Lineare Modelle",
    "section": "9.5 Die Post-Verteilung befragen",
    "text": "9.5 Die Post-Verteilung befragen\n\n9.5.1 m43a\nSagen wir, auf Basis gut geprüfter Evidenz haben wir folgendes Modell festgelegt: height ~ weight_c, s. Gleichung 9.1.\nPrioris:\n\\[\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1) \\tag{9.1}\\]\nWir nennen das Modell m43a2, s. Listing 9.1.\n\nListing 9.1: Modelldefinition von m43a in R\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest für Reproduzierbarkeit\n    data = d3)\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit seed kann man die Zufallszahlen fixieren, so dass jedes Mal die gleichen Werte resultieren. So ist die Nachprüfbarkeit der Ergebnisse (“Reproduzierbarkeit”) sichergestellt3. Welche Wert für seed man verwendet, ist egal, solange alle den gleichen verwenden. Der Autor verwendet z.B. oft den Wert 42. Zur Erinnerung: Der Golem zieht Zufallszahlen, damit erstellt er Stichproben, die die Postverteilung schätzen.\n\n\n\n\n9.5.2 Mittelwerte von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n  \n  \n    \n      id\n      (Intercept)\n      weight_c\n      sigma\n    \n  \n  \n    1\n155.1\n0.9\n5.0\n    2\n155.5\n0.8\n5.1\n    3\n155.5\n0.9\n5.1\n  \n  \n  \n\n\n\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle parameters:\n\n\nCode\nparameters(m43a)\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nDie Kennzahl pd (propability of direction) gibt die Wahrscheinlichkeit an, dass der Effekt positiv (also größer als Null) oder negativ ist (jenachdem ob der Median des Effekts positiv oder negativ ist). pd gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt. Damit ist er so etwas (grob!) Ähnliches wie der p-Wert in der Frequentistischen Statistik (Makowski u. a. 2019).\nAm besten das Diagramm dazu anschauen, s Abbildung 9.7.\n\n\nCode\nplot(p_direction(m43a))\n\n\n\n\n\nAbbildung 9.7: Diagramm zur Probability of Direction, Modell m43a\n\n\n\n\nRhat und ESS sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein. Rhat sollte nicht (viel) größer als 1 oder 1,01 sein. ESS (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschäftigen in diesem Kurs.\n\n\n9.5.3 Visualisieren der “mittleren” Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\). Überzeugen wir uns mit einem Blick in die Post-Verteilung von m43a:\n\n\nCode\nm43a %>% \n  as_tibble() %>% \n  head()\n\n\n\n\n\n\n(Intercept)\nweight_c\nsigma\n\n\n\n\n155.1421\n0.8581434\n5.042898\n\n\n155.4658\n0.8348727\n5.071101\n\n\n155.4522\n0.8549260\n5.144382\n\n\n155.2342\n0.8816371\n5.352756\n\n\n155.3172\n0.8745051\n5.349856\n\n\n154.9315\n0.9030495\n5.207581\n\n\n\n\n\n\nWir können z.B. ein Lagemaß wie den Median hernehmen, um die “mittlere” Regressionsgerade zu betrachten:\n\n\nCode\nd2 %>% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion estimate_expectation benutzt, s. Abbildung 9.8. Mit “expectation” sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n\nCode\nm43_expect <- estimate_expectation(m43a)\nplot(m43_expect)\n\n\n\n\n\nAbbildung 9.8: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n\n\n\n\n\n\n9.5.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\alpha, \\beta, \\sigma\\).\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen können.\n\n9.5.4.1 Lagemaße zu den Parametern\n\nWas ist die mittlere Größe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Schätzwert für den Zusammenhang von Gewicht und Größe? (\\(\\beta_1\\))\nWas ist der Schätzwert für Ungewissheit in der Schätzung der Größe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert für z.B: \\(\\beta_1\\)?\n\nEine nützliche Zusammenfassung der Post-Verteilung bekommt man mit parameters(modell):\n\n\nCode\nm43a %>% \n  parameters()\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.14, 155.19)\n100%\n0.999\n3214.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.82, 0.99)\n100%\n1.001\n4134.00\nNormal (5 +- 3)\n\n\n\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. m43a, mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\nCode\nm43a_post <- \n  m43a %>% \n  as_tibble()\n\nm43a_post %>% \n  head()\n\n\n\n\n\n\n(Intercept)\nweight_c\nsigma\n\n\n\n\n155.1421\n0.8581434\n5.042898\n\n\n155.4658\n0.8348727\n5.071101\n\n\n155.4522\n0.8549260\n5.144382\n\n\n155.2342\n0.8816371\n5.352756\n\n\n155.3172\n0.8745051\n5.349856\n\n\n154.9315\n0.9030495\n5.207581\n\n\n\n\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post.\nJetzt haben wir wieder eine schöne Tabelle mit Stichproben aus der Post-Verteilung, die wir wie gewohnt befragen können.\nEine Visualisierung zeigt gut sowohl Lage- als auch Streuungsmaße der Parameter, zumindest grob.,\nOder man erstellt selber ein Diagramm mit ggplot.\n\n\nCode\nm43a_post %>% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den häufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\nDer Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\n\nCode\nm43a_post %>% \n  summarise(map_b1 = map_estimate(weight_c))\n\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert, s. Abbildung 9.9.\n\n\nCode\nm43a_post %>% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\n\nAbbildung 9.9: Die Post-Verteilung für den Parameter sigma, m43a\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%, s.@fig-m43a-plot.\n\n\nCode\nm43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\n\nAbbildung 9.10: Die Parameter Gewicht (zentriert) und sigma des Modells m43a\n\n\n\n\nErgänzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n\n\n9.5.5 Streuungsmaße zu den Parametern\n\nWie unsicher sind wir uns in den Schätzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nHinweis\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebräuchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilität.\n\n\n\n\n9.5.6 Ungewissheit von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung visualisiert\nDie ersten 10 Stichproben:\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\n\nDie ersten 100 Stichproben:\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\n\nDie ersten 1e3 Stichproben:\n\n\nCode\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\n\nDie ersten 1000000 … okay, lassen wir es gut sein4.\nEinfacher ist die Visualisierung mit estimate_expectation:\n\n\nCode\nestimate_expectation(m43a) %>% plot()\n\n\n\n\n\n\n\n9.5.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Bei einem zentrierten Prädiktor misst der Achsenabschnitt die mittlere Größe.\n\n\n\nWelche mittlere Größe wird mit zu 50%, 90% bzw. 95% Wahrscheinlichkeit nicht überschritten?\nWelche mittlere Größe mit zu 95% Wskt. nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Schätzbereich der mittleren Größe?\n\nQuantile:\n\n\nCode\nm43a_post %>% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n\n\n\n\n\n\nq_50\nq_90\nq_05\n\n\n\n\n154.6548\n155.0032\n155.0951\n\n\n\n\n\n\n50%-PI:\n\n\nCode\nm43a %>% \n  eti(ci = .5)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.5\n154.4632928\n154.8373635\nfixed\nconditional\n\n\nweight_c\n0.5\n0.8772824\n0.9354291\nfixed\nconditional\n\n\n\n\n\n\n\n\n9.5.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Größe bei mind. 155 cm liegt?\n\n\nCode\nm43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\ngross\nn\nprop\n\n\n\n\nFALSE\n3593\n0.89825\n\n\nTRUE\n407\n0.10175\n\n\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit beträgt 0.1.\nWie wahrscheinlich ist es, dass die mittlere Größe höchstens 154.5 cm beträgt?\n\n\nCode\nm43a_post %>% \n  count(klein = (`(Intercept)` <= 154.5)) %>% \n  mutate(prop = n / sum(n))\n\n\n\n\n\n\nklein\nn\nprop\n\n\n\n\nFALSE\n2833\n0.70825\n\n\nTRUE\n1167\n0.29175\n\n\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit beträgt 0.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ \n\n\n9.5.9 Typischer Bayes-Nutzer in Aktion\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle"
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prädiktorwert",
    "href": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prädiktorwert",
    "title": "9  Lineare Modelle",
    "section": "9.6 Post-Verteilung bedingt auf einen Prädiktorwert",
    "text": "9.6 Post-Verteilung bedingt auf einen Prädiktorwert\n\n9.6.1 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der Körpergröße bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche Körpergröße ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns über diesen Mittelwert?\nEtwas formaler ausgedrückt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Prädiktorwerten aus, gilt in dem Fall weight_c = 0. Erstellen wir uns dazu eine Tabelle:\n\n\nCode\nmu_at_45 <-\n  m43a_post %>% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nUnd plotten diese, s. Abbildung 9.11.\n\n\nCode\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n\n\n\n\n\nAbbildung 9.11: Post-Verteilung der Größe (laut unserem Modell) bei einem Gewicht von 45kg\n\n\n\n\nAnalog können wir fragen, wie groß wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns über diesen Mittelwert sind.\n50 kg, das sind 5 über dem Mittelwert, in zentrierten Einheiten ausgedrückt also weight_c = 5. Auch dazu erstellen wir uns eine Tabelle.\n\n\nCode\nmu_at_50 <-\n  mu_at_45 %>% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n\n\n\n\n\n\n(Intercept)\nweight_c\nsigma\nmu_at_45\nmu_at_50\n\n\n\n\n155.1421\n0.8581434\n5.042898\n155.1421\n159.4329\n\n\n155.4658\n0.8348727\n5.071101\n155.4658\n159.6402\n\n\n155.4522\n0.8549260\n5.144382\n155.4522\n159.7269\n\n\n155.2342\n0.8816371\n5.352756\n155.2342\n159.6424\n\n\n155.3172\n0.8745051\n5.349856\n155.3172\n159.6897\n\n\n154.9315\n0.9030495\n5.207581\n154.9315\n159.4467\n\n\n\n\n\n\nDie Verteilung der mittleren Größe bei einem Gewicht von 50kg ist weiter “rechts” (Richtung höhere Größe) zentriert, s. Abbildung 9.12.\n\n\nCode\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\n\n\n\n\nAbbildung 9.12: Post-Verteilung der mittleren Größe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\n\n\n\n\n\n\n9.6.2 Lagemaße und Streuungen\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der Körpergröße.\nWas ist das 90% PI für \\(\\mu|w=50\\) ?\n\n\nCode\nmu_at_50 %>% \n  eti(mu_at_50, ci = .9)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\n(Intercept)\n0.9\n154.2144131\n155.0950875\n\n\nweight_c\n0.9\n0.8358413\n0.9763181\n\n\nsigma\n0.9\n4.8298399\n5.4758137\n\n\nmu_at_45\n0.9\n154.2144131\n155.0950875\n\n\nmu_at_50\n0.9\n158.6294638\n159.7578370\n\n\n\n\n\n\nDie mittlere Größe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\nWelche mittlere Größe wird mit 95% Wahrscheinlichkeit nicht überschritten, wenn die Person 45kg wiegt?\n\n\nCode\nmu_at_45 %>% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n\n\n\n\n\n\nq_95\n\n\n\n\n155.0951"
  },
  {
    "objectID": "lineare-modelle.html#die-ppv-befragen",
    "href": "lineare-modelle.html#die-ppv-befragen",
    "title": "9  Lineare Modelle",
    "section": "9.7 Die PPV befragen",
    "text": "9.7 Die PPV befragen\nDie Posterior-Prädiktiv-Verteilung (PPV) gibt uns die Möglichkeit, nach der Wahrscheinlichkeit tatsächlicher Körpergrößen zu fragen - und nicht nur nach mittleren Körpergrößen anhand der Post-Verteilung.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren Körpergröße, denn das ist was wir modellieren wollten. Möchten wir Aussagen zur Wahrscheinlichkeit tatsächlicher Größen treffen, brauchen wir die PPV.\n\n\n\n9.7.1 Perzentil-Intervalle für verschiedenen Prädiktor-Werte\nWir erstellen uns eine Sequenz an Prädiktorwerten, die uns interessieren, weight_df:\n\n\nCode\nweight_df <- tibble(weight_c = seq(-20,20, by = 5))\n\n\nFür diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\n\nCode\nmus <- \n  predictive_interval(\n    m43a, \n    seed = 42,\n    newdata = weight_df) %>% \n  as_tibble() %>% \n  bind_cols(weight_df)\n\nhead(mus)\n\n\n\n\n\n\n5%\n95%\nweight_c\n\n\n\n\n128.1147\n145.1597\n-20\n\n\n132.4176\n149.6384\n-15\n\n\n136.9562\n154.3366\n-10\n\n\n141.3568\n158.6287\n-5\n\n\n146.0105\n163.4098\n0\n\n\n150.4892\n167.5851\n5\n\n\n\n\n\n\nUm die Perzentilintervalle zu erstellen, wird von predictive_interval() für jeden Prädiktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil dafür berechnet. Sie können die Voreinstellung ändern mittels des Arguments prob; um ein 89%-PI zu berechnen, würde man z.B. schreiben prob = .89.\nUm Reproduzierbarkeit sicherzustellen, haben wir mit seed = 42 die Zufallszahlen fixiert.\nWir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine Körpergröße von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI). Hoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedrückt; die PPV gibt die Ungewissheit tatsächlicher beobachtbarer Körpergrößen aus, nicht nur die Ungewissheit zum Mittelwert.\nBerechnen wir die PPV für m43a:\n\n\nCode\nppv_m43a <- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %>% \n  as_tibble() %>% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\n\nHier ist ein Auszug aus der PPV-Tabelle:\n\n\n\n\n\n\n  \n  \n    \n      weight_c\n      5%\n      95%\n    \n  \n  \n    −20.0\n128.1\n145.2\n    −15.0\n132.4\n149.6\n    −10.0\n137.0\n154.3\n    −5.0\n141.4\n158.6\n    0.0\n146.0\n163.4\n    5.0\n150.5\n167.6\n  \n  \n  \n\n\n\n\n\n\n9.7.2 Perzentilintervalle für verschiedenen Prädiktorwerte visualisiert\n?fig-m43a-nochmal visualisiert die Ungewissheit von Vorhersagen laut der PPV. Die Ungewissheit in ?fig-m43a-nochmal ist die Antwort auf die Frage: “Wie sicher sind wir uns, zur Größe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?” Eine Vorhersage bezeichnet man auch als “bedingte Verteilung”, da man den Wert einer Verteilung voraussagt, gegeben einer Bedingung, z.B. weight_c = 10.\n\n\n\n\n\nVisualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV größer als die der Post-Verteilung.\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung, s. Abbildung 9.13; je dicker die “Katzenaugen”, desto mehr Stichproben (samples) liegen vor an der Stelle, und umso genauer ist die Schätzung.\n\n\n\n\n\nAbbildung 9.13: Die PPV für bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu | w_i\\).\n\n\n9.7.3 Die PPV visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV für einen bestimmten Prädiktorwert, z.B. bei einer Person mittleren Gewichts. Wir können auch den Mittelwert über alle bedingten PPV anschauen, sozusagen die “Master-PPV” oder “unbedingte PPV” oder schlicht PPV. Vergleichen wir die echten Werte für height, \\(y\\), mit den von der PPV simulierten Werten für height, \\(y_{rep}\\), s. Abbildung 9.14.\n\n\nCode\ncheck_predictions(m43a) \n\n\n\n\n\nAbbildung 9.14: Vergleich der Vorhersagen für y (leichte, blaue Linien) mit der beobachteten Verteilung von y\n\n\n\n\n?check_predictions zeigt Hilfe für diese Funktion. Die Funktion zeigt die Vorhersagen für die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n9.7.4 Fragen an die PPV\n\nWie groß sind die !Kung im Schnitt?\nWelche Größe wird von 90% der Personen nicht überschritten?\nWie groß sind die 10% kleinsten?\n\n\n\nCode\nppv_m43a %>% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n\n\n\n\n\nq_10\nheight_mean\nq_50\nq_90\n\n\n\n\n137.0299\n154.6521\n154.6775\n171.8119\n\n\n\n\n\n\nWas ist der 50% Bereich der Körpergröße?\n\n\nCode\nppv_m43a %>% \n  eti(ci = .5)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\n\n\n\n\nheight\n0.5\n144.8201\n165.2368"
  },
  {
    "objectID": "lineare-modelle.html#aufgaben",
    "href": "lineare-modelle.html#aufgaben",
    "title": "9  Lineare Modelle",
    "section": "9.8 Aufgaben",
    "text": "9.8 Aufgaben\n\nBayes-Ziel1\nBayesmod-bestimmen01\nLikelihood2\nPost-befragen1\nPostvert-Regr-01\nregression1a\nRegression2\nBed-Post-Wskt1\nPriorwahl1\nBayesmod-bestimmen02\nAussagen-einfache-Regr\nLikelihood-identifizieren\nPriorwahl2\npenguins-stan-01\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel Lüdecke. 2019. „Indices of Effect Existence and Significance in the Bayesian Framework“. Frontiers in Psychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "metrische-AV.html",
    "href": "metrische-AV.html",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "",
    "text": "Benötigte R-Pakete für dieses Thema:\n\n\nCode\nsuppressPackageStartupMessages(\"rstanarm\")\n## [1] \"rstanarm\"\n#| message: false\n#| results: \"hide\"\n#| warnings: false\nlibrary(rstanarm)\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n\n\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können…\n\ntypische, deskriptive Forschungsfragen spezifizieren als Regression\nForschungsfragen in Regressionsterme übersetzen\ntypische Forschungsfragen auswerten\n\n\n\n\n\nTeil 1\nTeil 2"
  },
  {
    "objectID": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "href": "metrische-AV.html#wissenschaft-als-gerechtigkeitsprojekt",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.2 Wissenschaft als Gerechtigkeitsprojekt",
    "text": "10.2 Wissenschaft als Gerechtigkeitsprojekt\n\n10.2.1 Meinungen als Grundlage der Konfliktlösung ?\nContra:\n\n“Ich find Masken doof!”\n“Impfen ist schädlich!”\n“Corona gibt’s gar nicht!”\n\n\n\n  \n\n\nPro:\n\n“Ich find Masken gut!”\n“Impfen ist nützlich!”\n“Corona ist gefährlich!”\n\n\n\n  \n\n\nMeinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte können auf Basis von Meinungen nur schwer gelöst werden.\n\n\n10.2.2 Fakten als Grundlage der Konfliktlösung\nWissenschaft produziert Fakten. Da Fakten universell sind (sein können), ist Wissenschaft potenziell ein Weg zur Konfliktlösung. Warum helfen Fakten bei Konflikten?\nFakten sind neutral gegenüber Personen. Fakten bieten daher eine Chance zur fairen Einigung.\nWann ist ein Fakt ein Fakt?\nFakten müssen vor allem nachprüfbar sein (Daten, Analyse und Bericht müssen offen zugänglich sein).\n\n\n10.2.3 Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung\n\nThe effectiveness of full messenger RNA (mRNA) vaccination (≥14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.\n\nThompson u. a. (2021); vgl. auch Nasreen u. a. (2021); Pormohammad u. a. (2021)\nDrei Anforderungen an die Qualität von Studien:\n\nhandwerklich gut: z.B. vergleichbare Gruppen, genaue Messinstrumente\nbescheiden: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche Qualität der Studie zulässt. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage berücksichtigt.\ntransparent: Das Vorgehen, die Hintergründe und Ziele werden offengelegt. Das betrifft auch möglich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen\n\n\n\n10.2.4 Psychologische Intervention zur Erhöhung der Impfquote\nDai u. a. (2021) zeigen den Effekt einer psychologischen Intervention zur Erhöhung der Impfquote, s. Abbildung 10.1.\n\nHere we present two sequential randomized controlled trials to test the effect of behavioural interventions on the uptake of COVID-19 vaccines. … We designed text-based reminders that make vaccination salient and easy, and delivered them to participants drawn from a healthcare system one day (first randomized controlled trial) (n = 93,354 participants; clinicaltrials number NCT04800965) and eight days (second randomized controlled trial) (n = 67,092 individuals; clinicaltrials number NCT04801524) after they received a notification of vaccine eligibility. The first reminder boosted appointment and vaccination rates within the healthcare system by 6.07 (84%) and 3.57 (26%) percentage points, respectively; the second reminder increased those outcomes by 1.65 and 1.06 percentage points, respectively. The first reminder had a greater effect when it was designed to make participants feel ownership of the vaccine dose.\n\n\n\n\n\n\nAbbildung 10.1: a, b, Proportion of participants in each condition who scheduled an appointment for the first dose of the COVID-19 vaccine at UCLA Health between 15:00 h on the first reminder date and 23:59 h on the fifth day following the first reminder date (a) and the proportion of participants in each condition who obtained the first dose of the COVID-19 vaccine at UCLA Health within four weeks of the first reminder date (b). Error bars represent ± 1 s.e.m. The number of participants in each condition (from left to right in each panel) is 18,629, 18,592, 18,757, 18,627 and 18,749.\n\n\n\n\nQuelle/Volltext\n\n\n10.2.5 Was heißt “ist effektiv”?\nNasreen u. a. (2021) definieren effectivity, \\(e\\), so:\n\\[e = 1 - C; C= \\frac{n_{vacc|pos}}{n_{vacc|neg}}\\]\n\n\\(C\\) nennt man das Chancenverhältnis (odds ratio), es beschreibt einen Bruchterm: \\(\\frac{x}{y}\\).\n\\(n_{vacc|pos}\\): Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose\n\\(n_{vacc|neg}\\): Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose\n\nBeispiel: Von den 100 Personen mit positiver Corona-Diagnose sind 10 geimpft, \\(n_{vacc|pos}=10\\). Von den 100 Personen mit negativer Corona-Diagnose sind 90 geimpft, \\(n_{vacc|neg}=90\\)\n\\[C= \\frac{10}{90} = \\frac{1}{9}; e = 1 - \\frac{1}{9} = \\frac{8}{9} \\approx 0.88\\]\nIn diesem Beispiel liegt die Effektvitität \\(e\\) bei knapp 90%."
  },
  {
    "objectID": "metrische-AV.html#arten-von-forschungsfragen",
    "href": "metrische-AV.html#arten-von-forschungsfragen",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.3 Arten von Forschungsfragen",
    "text": "10.3 Arten von Forschungsfragen\n\n10.3.1 Nach dem Erkenntnisziel\nDeskriptiv (beschreibend)\n\nWie stark ist der (lineare) Zusammenhang \\(r\\) von Größe und Gewicht?\nWie stark ist der (lineare) Zusammenhang \\(b\\) von Lernzeit und Note?\nBevorzugen unsere Kunden Webshop A oder B?\n\nPrädiktiv (prognostisch, vorhersagend)\n\nWie schwer ist ein deutscher Mann der Größe 1,80m im Schnitt?\nWelche Note kann man erwarten, wenn man nichts für die Klausur lernt?\nWieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufhält?\n\nPräskriptiv (erklärend, kausal)\n\nIst Größe eine Ursache von Gewicht (bei deutschen Männern)?\nWenn ich 100 Stunden lerne, welche Note schreibe ich dann?\nHat die Art des Webshops einen Einfluss auf unseren Umsatz?\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Erkenntnisziel wissenschaftlicher Studien ist zumeist erklärend. Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse) kann man nicht feststellen, zu welchem Erkenntnisziel die Studie gehört.\n\n\n\n\n10.3.2 Nach dem Skalenniveau\nWir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit metrischer AV. Andere Skalenniveaus bei der AV klammern wir aus.\nFür die UV(s) sind nominale und metrische Skalenniveaus erlaubt. Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt."
  },
  {
    "objectID": "metrische-AV.html#eine-binäre-uv",
    "href": "metrische-AV.html#eine-binäre-uv",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.4 Eine binäre UV",
    "text": "10.4 Eine binäre UV\n\n10.4.1 Forschungsfrage\nHintergrund:\nEine Psychologin, die im öffentlichen Dienst arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufwändigen Studie die Intelligenz vieler Kinder gemessen. Zusätzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, “Risikofaktoren” für geringere Intelligenz zu entdecken.\nForschungsfrage:\n\nUnterscheidet sich der mittlere IQ-Wert (kid_score) von Kindern in Abhängigkeit davon, ob ihre jeweilige Mutter über einen Schlusabschluss (mom_hs) verfügt? (ceteris paribus)\n\n\n\n10.4.2 IQ von Kindern, binärer Prädiktor\n\n\nCode\ndata(\"kidiq\")  # Paket rstanarm\nm10.1 <- stan_glm(\n  kid_score ~ mom_hs, \n  seed = 42,\n  data = kidiq)\n\n\nAlternativ können Sie die Daten hier herunterladen.\nMit parameters(m10.1) bekommt man die Parameter des Modells, s. Tabelle 10.1.\n\n\n\n\nTabelle 10.1: Parameter des Modells m10.1 (sigma ist nicht dargestellt)\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n77.56\n(73.28, 81.64)\n100%\n1.001\n3917.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n11.80\n(7.18, 16.48)\n100%\n1.001\n3789.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nIn Abbildung 10.2 ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.\n\n\nCode\nggplot(kidiq) +\n  aes(x = mom_hs, y = kid_score) +\n  geom_jitter(width = 0.1, alpha = .5) +\n  geom_abline(slope = coef(m10.1)[2],\n              intercept = coef(m10.1)[1])  +\n  scale_x_continuous(breaks = c(0, 1))\n\n\n\n\n\nAbbildung 10.2: Kinder, deren Mütter über einen Schulabschluss verfügen, haben im Mittel einen höheren Intelligenztestwert, laut dem vorliegenden Modell\n\n\n\n\n\n\n10.4.3 Interpretation von m10.1\nm10.1: kid_score = 78 + 12*mom_hs + error\n\nDer Achsensabschnitt (intercept, \\(\\beta_0\\) oder auch mit \\(\\alpha\\) bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren Mütter über keinen Schulabschluss (mom_hs = 0) verfügen:\n\nkid_score = 78 + 0*12 + error\n\nDas Regressionsgewicht (slope, \\(\\beta\\)) ist der Unterschied im IQ-Wert von Kindern mit Mütter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit Mütter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.\n\nkid_score = 78 + 1*12 + error = 90 + error\n\nDie Größer der Konfidenzintervalle zeigt, wie genau die Schätzung (Vorhersage) ist bzw. wie stark Prädiktor (UV) und Kriterium (AV) zusammenhängen.\n\n\n\n10.4.4 m10.1 als Mittelwertsdifferenz\n\nUV: binär (zweistufig nominal/kategorial)\nAV: metrisch (quantitativ)\n\nHey R-Golem! Nimm den Datensatz kidiq, gruppiere nach mom_hs und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll heißen kid_score_avg. An die Arbeit!\n\n\nCode\nkidiq %>% \n  group_by(mom_hs) %>% \n  summarise(kid_score_avg = \n              mean(kid_score))\n\n\n\n\n\n\nmom_hs\nkid_score_avg\n\n\n\n\n0\n77.54839\n\n\n1\n89.31965\n\n\n\n\n\n\nIn der klassischen Statistik untersucht man diese Datensituation mit einem t-Test. Der t-Test ist ein inferenzstatistisches Verfahren, dass prüft, ob die Mittelwertsdifferenz (in der Population) \\(\\mu_d\\) Null ist: \\(\\mu_d = 0\\). In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).\nDer mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von Müttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.\n\n\n10.4.5 Antwort auf die Forschungsfrage, m10.1\nBetrachten wir die Ergebnisse von m10.1. Hier sind die ersten paar Zeilen.\n\n\nCode\nm10.1_post <-\n  m10.1 %>% \n  as_tibble() \n\nnames(m10.1_post) <- c(\"Achsenabschnitt\", \"momhs\", \"sigma\")  # schönere Namen\n\n\n\n\n\n\n\n\n  \n    \n      Stichprobe aus der Post-Verteilung\n    \n    \n  \n  \n    \n      Achsenabschnitt\n      momhs\n      sigma\n    \n  \n  \n    80.7\n9.4\n20.3\n    78.2\n12.2\n19.0\n    73.8\n16.0\n19.7\n    75.2\n13.6\n18.4\n    79.6\n11.1\n20.4\n  \n  \n  \n\n\n\n\nBerechnen wir ein 95%-PI von Hand:1\n\n\nCode\npi_mom_hs <-\n  m10.1_post %>% \n  summarise(pi_95 = quantile(momhs, c(.025, .975)))\n\npi_mom_hs\n\n\n\n\n\n\npi_95\n\n\n\n\n7.177759\n\n\n16.482883\n\n\n\n\n\n\nMit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von Müttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, laut unserem Modell: \\(95\\%PI: [7,16]\\). Die Hypothese, dass es keinen Unterschied oder einen Unterschied in die andere Richtung geben sollte, ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.\nVisualisieren wir abschließend die Posteriori-Verteilung, s. Abbildung 10.3.\n\n\nCode\nplot(eti(m10.1))\n\n\n\n\n\nAbbildung 10.3: Das 95% ETI zum (statistischen) Effekt des mütterlichen Schulabschlusses\n\n\n\n\nZur Einnerung: Korrelation ungleich Kausation. Von einem “Effekt” zu sprechen, lässt in den meisten Köpfen wohl die Assoziation zu einem kausalen Effekt entstehen. Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung, die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein einfacher Zusammenhang."
  },
  {
    "objectID": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "href": "metrische-AV.html#eine-metrische-plus-eine-nominale-uv",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.5 Eine metrische plus eine nominale UV",
    "text": "10.5 Eine metrische plus eine nominale UV\n\n10.5.1 Forschungsfrage\n\nWie stark ist der Zusammenhang von jeweils Schulabschluss der Mutter (mom_hs) und IQ der Mutter (mom_iq) auf den IQ des Kindes (kid_score) ?\n\nDeskriptive Statistiken zum Datensatz sind in Tabelle Tabelle 10.2 dargestellt.\n\n\nCode\ndata(\"kidiq\")  # Paket rstanarm, alternativ über CSV einlesen\ndescribe_distribution(kidiq)\n\n\n\n\n\n\nTabelle 10.2: Variablen und ihre Verteilung im Datenatz kidiq\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\n\nDatenquelle\n\n\n10.5.2 1 metrischer Prädiktor\nBerechnen wir folgendens Modell: kid_score ~ mom_iq (m10.2), s. Tab. Tabelle 10.3.\n\n\nCode\nm10.2 <-\n  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)\n\nm10.2 %>% \n  parameters()\n\n\n\n\n\n\nTabelle 10.3: Parameter des Modells m10.2\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n25.78\n(14.04, 36.99)\n100%\n1.000\n3518.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.61\n(0.50, 0.73)\n100%\n1.000\n3486.00\nNormal (0.00 +- 3.40)\n\n\n\n\n\n\nkid_score = 26 + 0.6 * mom_iq + error\nVisualisieren wir uns noch das Modell m10.2, s. Abbildung 10.4.\n\n\nCode\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.2)[2],\n              intercept = coef(m10.2)[1],\n              color = \"blue\")\n\n\n\n\n\nAbbildung 10.4: Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)\n\n\n\n\nAlternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, s. Abbildung 10.5\n\n\nCode\nplot(estimate_expectation(m10.2))\n\n\n\n\n\nAbbildung 10.5: Die geschätzten Erwartungswerte von m10.2 visualisiert\n\n\n\n\nDie Linie zeigt die vorhergesagten IQ-Werte der Kinder für verschiedene IQ-Werte der Mütter. Vergleicht man Teilpopulationen von Müttern mit mittleren Unterschied von einem IQ-Punkt, so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern im Durchschnitt, laut dem Modell m10.2. Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.\n\n\n10.5.3 Beide Prädiktoren, m10.3\nBerechnen wir als nächstes ein Modell mit beiden Prädiktoren: kid_score ~ mom_hs + mom_iq, s. Tabelle 10.4.\n\n\nCode\nm10.3 <- \n  stan_glm(\n    kid_score ~ mom_iq + mom_hs, \n    refresh = 0,\n    seed = 42,\n    data = kidiq)\n\n\n\n\n\n\nTabelle 10.4: Parameter des Modells m10.3 (ohne sigma)\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n25.74\n(13.87, 36.76)\n100%\n1.001\n3961.00\nNormal (86.80 +- 51.03)\n\n\nmom_iq\n0.57\n(0.45, 0.69)\n100%\n1.001\n3456.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs\n6.04\n(1.62, 10.15)\n99.60%\n0.999\n3616.00\nNormal (0.00 +- 124.21)\n\n\n\n\n\n\nWill man nur schnell die Koeffizienten des Modells (d.h. Punktschätzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von parameters(mein_modell) auch coef(mein_modell) schreiben:\n\n\nCode\ncoef(m10.3)\n## (Intercept)      mom_iq      mom_hs \n##  25.7447712   0.5654851   6.0376396\n\n\nm10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error\nMöchte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:\n\n\nCode\ncoef(m10.3)[3]\n##  mom_hs \n## 6.03764\n\n\nAber natürlich ist es möglich (und einfacher) anstelle von coef den Befehl parameters zu verwenden.\nUnd die Visualisierung des Modells m10.3, s. Abbildung 10.6.2\n\n\nCode\nkidiq %>% \n  mutate(mom_hs = factor(mom_hs)) %>%  \n  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +\n  geom_point(alpha = .7) +\n  geom_abline(slope = coef(m10.3)[3],  # den 3. Wert aus dem Vector, den `coef()` zurückgibt\n              intercept = 26,\n              linewidth = 1,\n              color = \"blue\") +\n  geom_abline(slope = coef(m10.3)[3],\n              intercept = 32,\n              color = \"red\",\n              linewidth = 2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme(legend.position = \"bottom\") +\n  scale_x_continuous(limits = c(0, 140))\n\n\n\n\n\nAbbildung 10.6: Der Effekt von sowohl mütterlicher Intelligenz als auch mütterlichem Schulabschluss. Es ist gut zu erkennen, dass der Achsenabschnitt für die Daten nicht interpretierbar ist.\n\n\n\n\n\nAchsenabschnitt: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann schätzt das Modell den IQ-Wert des Kindes auf 26.\nKoeffizient zum mütterlichen Schulabschluss: Vergleicht man Kinder von Müttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.\nKoeffizient zur mütterlichen IQ: Vergleicht man Kinder von Müttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus."
  },
  {
    "objectID": "metrische-AV.html#interaktion",
    "href": "metrische-AV.html#interaktion",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.6 Interaktion",
    "text": "10.6 Interaktion\nIn m10.3 hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen. Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).\n\n\n\n\n\n\nWichtig\n\n\n\nLiegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.\n\n\nWir berechnen mit m10.4 folgendes Modell: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, s. Abbildung 10.7 und Tabelle 10.5\n\n\nCode\nm10.4 <- \n  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, \n           seed = 42,\n           data = kidiq, \n           refresh = 0)\n\n\n\n\n\n\nTabelle 10.5: Parameter von m10.4\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-10.59\n(-37.44, 16.30)\n77.62%\n1.001\n1427.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n49.76\n(21.49, 79.27)\n100%\n1.003\n1401.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq\n0.96\n(0.67, 1.25)\n100%\n1.001\n1412.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq\n-0.47\n(-0.78, -0.17)\n99.85%\n1.003\n1367.00\nNormal (0.00 +- 1.16)\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 10.7: Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt für diese Daten kaum zu interpretieren ist.\n\n\n\n\n\n10.6.1 Interpretation von m10.4\n\nAchsenabschnitt: IQ-Schätzwerte für Kinder mit Mütter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.\nmom_hs: Unterschied der IQ-Schätzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.\nmom_iq: Unterschied der IQ-Schätzwerte zwischen Kindern mit Müttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.\nInteraktion: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten für mom_iq zwischen Mütter mit bzw. ohne Schulabschluss.\n\nmom_hs=0:\nkid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq\n\n          = -11 + 1.1*mom_iq\n\n\nmom_hs=1: \nkid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq\n\n          = 40 + 0.6*mom_iq\nGelman, Hill, und Vehtari (2021), Kap. 10.3\n\n\n10.6.2 Nach der Interpretation von 20 unzentrierten Koeffizienten\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "metrische-AV.html#zentrieren-von-prädiktoren",
    "href": "metrische-AV.html#zentrieren-von-prädiktoren",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.7 Zentrieren von Prädiktoren",
    "text": "10.7 Zentrieren von Prädiktoren\nUnter Zentrieren (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert. Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist. Mit zentrierten Werten ist eine Regression einfacher zu interpretieren. Hier zentrieren wir (nur) mom_iq.\nMan könnte auch mom_hs zentrieren, aber für eine einfache Interpretation ist es meist nützlich, nur metrische Prädiktoren zu zentrieren.\n\n\nCode\nkidiq <-\n  kidiq %>% \n  mutate(mom_iq_c = mom_iq - mean(mom_iq))\n\nm10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, \n                  data = kidiq, \n                  seed = 42,\n                  refresh = 0)\ncoef(m10.5)\n\n\n\n## NULL\n\n\n10.7.1 Interpretation von m10.5\n\nDer Achsenabschnitt (Intercept) gibt den geschätzten IQ des Kindes an, wenn man eine Mutter mittlerer Intelligenz und ohne Schulabschluss betrachtet.\nmom_hs gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.\nmom_iq_c gibt den Unterschied im geschätzten IQ des Kindes an, wenn man Mütter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.\nmom_hs:mom_iq_c gibt den Unterschied in den Koeffizienten für mom_iq_c an zwischen den beiden Grupen von mom_hs.\n\nm10.5 ist in Abbildung 10.8 dargestellt.\n\n\n\n\n\nAbbildung 10.8: m10.5: Interaktionsmodell mit zentriertem Prädiktor für mütterlicher Intelligenz\n\n\n\n\n\n\n10.7.2 Zentrieren ändert nichts an den Vorhersagen\nBetrachten wir die Vorhersagen von m10.4:\n\n\nCode\nnew <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))\npred_new <- posterior_predict(m10.4, newdata = new)\nmean(pred_new)\n## [1] 85.07282\n\n\nUnd vergleichen wir mit diesen die Vorhersagen von m10.5:\n\n\nCode\nnew <- tibble(mom_hs = 0, mom_iq_c = 0)\npred_new <- posterior_predict(m10.5, newdata = new)\nmean(pred_new)\n## [1] 85.30389\n\n\nWir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.\nAuch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): \\(\\sigma_{m10.4}= 18\\); \\(\\sigma_{m10.5}= 18\\).\nDas Zentrieren ändert auch nicht die Regressionskoeffizienten, da die Streuungen der Prädiktoren nicht verändert wurden.\n\n\n10.7.3 Perzentilintervalle aus der Posterori-Verteilung\n?tbl-m105 zeigt die Punktschätzer der Parameter für m10.5 sowie ihre Perzentilintervalle3. Nutzen Sie dafür parameters(m10.5).\n\n\nTabelle 10.6: ?(caption)\n\n\n\n\n(a) Fixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n85.31\n(80.99, 89.72)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.69)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.67, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.78, -0.16)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\n\n\nParameter von m10.5 und ETIs\n\n\n\nHighest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich komfortabel ausgeben lassen mit hdi(m10.5) oder mit parameters(m10.5, ci_method = \"hdi\"), s. ?tbl-m105-hdi\n\n\nCode\nparameters(m10.5, ci_method = \"hdi\") %>% \n  display()\n\n\n\nParameter von m10.5 und HDIs \n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n85.31\n(81.26, 89.88)\n100%\n1.001\n2610.00\nNormal (86.80 +- 51.03)\n\n\nmom_hs\n2.91\n(-1.89, 7.70)\n88.00%\n1.001\n2832.00\nNormal (0.00 +- 124.21)\n\n\nmom_iq_c\n0.97\n(0.68, 1.24)\n100%\n1.002\n1982.00\nNormal (0.00 +- 3.40)\n\n\nmom_hs:mom_iq_c\n-0.48\n(-0.79, -0.17)\n99.78%\n1.002\n1992.00\nNormal (0.00 +- 3.87)\n\n\n\n\n\nIm Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.\n\n\n10.7.4 Beantworten der Forschungsfrage\n\nDas Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei Müttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der mütterlichen Intelligenz; pro Punkt Unterschied in müttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). Außerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei Mütter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).\n\n \n\n\n  \n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDas Modell macht keine kausalen Aussagen. Es werden lediglich Unterschiede bzw. Zusammenhänge beschrieben. Für kausale Aussagen ist mehr nötig, als einen Zusammenhang festzustellen."
  },
  {
    "objectID": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "href": "metrische-AV.html#eine-nominale-uv-mit-mehreren-stufen",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.8 Eine nominale UV mit mehreren Stufen",
    "text": "10.8 Eine nominale UV mit mehreren Stufen\n\n10.8.1 Forschungsfrage\nHintergrund:\nNach Ihrem Studium wurden Sie reich als Unternehmensberater:in; Ihre Kompetenz als Wirtschaftspsychologi war heiß begehrt. Von Statistik wollte niemand etwas wissen… Doch nach einiger Zeit kamen Sie in eine Sinnkrise. Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen. Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot als Nachwuchswissenschaftler:in.\nIhr Forschungsprojekt führte Sie in die Antarktis… Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.\nIhre Aufgabe bestand nun darin, Pinguine zu untersuchen. Genauer gesagt ging es um Größenunterschiede zwischen drei Pinguinarten. Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.\n\n\nUnterscheiden sich die mittleren Körpergewichte der drei Pinguinarten?\n\n\n\n10.8.2 Alle Mittelwerte sind gleich, exakt gleich (?)\n\nFormal: \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) mit \\(k\\) verschiedenen Gruppen von Pinguinarten.\nHypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als Nullhypothesen bezeichnen.\nMoment. Dass sich alle Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? 🤔 Daher ist die bessere Forschungsfrage:\n\n\nWie sehr unterscheiden sich mittlere Körpergewichte in Abhängigkeit von der Pinguinart?\n\nAlternativ können wir die Hypothese prüfen, ob die Mittelwerte “praktisch” gleich sind, also sich “kaum” unterscheiden. Der Grenzwert für “praktisch gleich” bzw. “kaum unterschiedlich” ist subjektiv. Dazu in Kapitel 10.11 mehr.\n\n\n10.8.3 Erster Blick in den Datensatz penguins\nDatenquelle, Beschreibung des Datensatzes\nHier ist die Quelle der Daten:\n\n\nCode\npenguins_url <- \"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\"\n\n#| results: \"hide\"\n#| message: false\npenguins <- \n  read_csv(penguins_url)\n\n\nHier ist die Verteilung des Gewichts jeder Spezies im Datensatz:\n\n\nCode\npenguins %>% \n  select(body_mass_g, species) %>% \n  group_by(species) %>% \n  describe_distribution(range = FALSE, iqr = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nSkewness\nKurtosis\nn\nn_Missing\n.group\n\n\n\n\nbody_mass_g\n3700.662\n458.5661\n0.2853361\n-0.5737376\n151\n1\nspecies=Adelie\n\n\nbody_mass_g\n3733.088\n384.3351\n0.2474331\n0.5933789\n68\n0\nspecies=Chinstrap\n\n\nbody_mass_g\n5076.016\n504.1162\n0.0696349\n-0.7227912\n123\n1\nspecies=Gentoo\n\n\n\n\n\n\nWas fällt Ihnen auf?\n\n\n10.8.4 Visualisierung (EDA)\nHier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, s. Abbildung 10.9, Abbildung 10.10, Abbildung 10.11 ?\n\n\n\n\n\nAbbildung 10.9: Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Violine\n\n\n\n\nAbbildung 10.10 zeigt die Gewichtsverteilung pro Spezies als “Bergrücken” (geom_ridges).\n\n\n\n\n\nAbbildung 10.10: Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Ridges\n\n\n\n\nAbbildung 10.11 zeigt die Gewichtsverteilung pro Spezies als “halbe Violinen” (geom_ridges), sozusagen Dichtediagramme um 90 Grad gedreht.\n\n\nCode\npenguins %>% \n  ggplot(aes(x = species, y = body_mass_g, fill = species)) +\n  geom_violindot(fill_dots = \"black\")\n\n\n\n\n\nAbbildung 10.11: Verteilung des Körpergewichts dreier Arten von Pinguinen - Geom Violindot\n\n\n\n\n\n\n10.8.5 Mittlere Gewichtsunterschiede in der Population\nBerechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. m10.6 und Tabelle 10.7.\n\n\nCode\noptions(mc.cores = parallel::detectCores())  # Turbo einschalten\n\nm10.6 <- stan_glm(body_mass_g ~ species, \n                  data = penguins, \n                  refresh = 0,  # unterdrückt Ausgabe der Posteriori-Stichproben\n                  seed = 42)\n\n\nm10.6 %>% \n  parameters()\n\n\n\n\n\n\nTabelle 10.7: Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n3700.35\n(3629.70, 3774.26)\n100%\n1.000\n4156.00\nNormal (4201.75 +- 2004.89)\n\n\nspeciesChinstrap\n33.23\n(-101.11, 164.89)\n68.08%\n1.000\n4139.00\nNormal (0.00 +- 5015.92)\n\n\nspeciesGentoo\n1374.51\n(1265.81, 1486.61)\n100%\n1.000\n4201.00\nNormal (0.00 +- 4171.63)\n\n\n\n\n\n\n\n\n10.8.6 Interpretation von m10.6\nDie UV hat drei verschiedene Stufen (Werte, Ausprägungen; hier: Spezies), aber es werden in Tabelle 10.7 nur zwei Stufen angezeigt (also eine weniger) zusätzlich zum Achsenabsdhnitt. Die fehlende Stufe (Adelie, nicht ausgegeben) ist die Vergleichs- oder Referenzkategorie (baseline) und ist im Achsenabschnitt ausgedrückt (Intercept). Die Koeffizienten für species geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder. Pinguine der Spezies Adelie haben laut Modell ein mittleres Gewicht von ca. 3700g. Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies Adelie, etc.\nDer Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in Abbildung 10.12 verdeutlicht.\n\n\nCode\nplot(hdi(m10.6))\n\n\n\n\n\nAbbildung 10.12: Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)\n\n\n\n\n\n\n10.8.7 Glauben wir jetzt an Gruppeneffekte?\nGlauben wir jetzt, auf Basis der Modellparameter, an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?\nEs scheinen sich nicht alle Gruppen voneinander zu unterscheiden. So ist der Mittelwert der Gruppe Gentoo deutlich höher als der der beiden anderen Gruppen. Umgekehrt sind sich die Pinguinarten Adelie und Chinstrap in ihren Mittelwerten ziemlich ähnlich.\nWie in Abbildung 10.12 ersichtlich, überlappt sich der Schätzbereich für den Parameter von Gentoo nicht mit der Null; hingegen überlappt sich der Schätzbereich des Parameters für Chinstrap deutlich mit der Nullinie.\nAuf Basis unseres Modells schließen wir also (mit hoher Sicherheit) aus, dass alle Mittelwerte exakt identisch sind.\nEhrlicherweise hätte sowieso (fast) niemand geglaubt, dass die exakte Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null. Aber: Viele Forschis prüfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese. Das Verfahren der Frequentistischen Statistik, um die Nullhypothese \\(\\mu_1 = \\mu_2 = \\ldots = \\mu_k\\) zu testen, nennt man Varianzanalyse (analysis of variance, kurz ANOVA). In der Bayes-Statistik nutzt man - wie immer - primär die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art) inferenzstatistisch zu beurteilen."
  },
  {
    "objectID": "metrische-AV.html#priori-werte",
    "href": "metrische-AV.html#priori-werte",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.9 Priori-Werte",
    "text": "10.9 Priori-Werte\nUnser Modell m10.6 hat schwach informierte (weakly informative) Priors. Für Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:\n\nAchsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen\nmit Mittelwert entsprechend den Stichprobendaten\nund einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht\nfür Sigma wird eine Exponentialverteilung mit Rate \\(\\lambda=1\\) angenommen, skaliert mit der Streuung der AV.\n\nMehr Infos kann man sich so ausgeben lassen: prior_summary(modell):\n\n\nCode\nprior_summary(m10.6)\n## Priors for model 'm10.6' \n## ------\n## Intercept (after predictors centered)\n##   Specified prior:\n##     ~ normal(location = 4202, scale = 2.5)\n##   Adjusted prior:\n##     ~ normal(location = 4202, scale = 2005)\n## \n## Coefficients\n##   Specified prior:\n##     ~ normal(location = [0,0], scale = [2.5,2.5])\n##   Adjusted prior:\n##     ~ normal(location = [0,0], scale = [5015.92,4171.63])\n## \n## Auxiliary (sigma)\n##   Specified prior:\n##     ~ exponential(rate = 1)\n##   Adjusted prior:\n##     ~ exponential(rate = 0.0012)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWo man man über mehr inhaltliches Wissen verfügt, so wird man die Prioris anpassen wollen, z.B.:\n\n\nCode\nm10.6b <- stan_glm(body_mass_g ~ species, \n                   data = penguins, \n                   refresh = 0,\n                   seed = 42,\n                   prior = normal(location = c(0, 0),  # betas, Mittelwert\n                                  scale = c(500, 500)),  # betas, Streuung\n                   prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung\n                   prior_aux = exponential(0.001)\n)\ncoef(m10.6b)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3704.89008         22.93895       1356.65099\n\n\nAnstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher. Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz autoscale = TRUE an.\n\n\nCode\nm10.6c <- stan_glm(body_mass_g ~ species, \n                   data = penguins, \n                   refresh = 0,\n                   seed = 42,\n                   prior = normal(location = c(0, 0),  # betas, Mittelwert\n                                  scale = c(2.5, 2.5),  # betas, Streuung\n                                  autoscale = TRUE),  # in z-Einheiten\n                   prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung\n                                            autoscale = TRUE), \n                   prior_aux = exponential(1, autoscale = TRUE)\n)\ncoef(m10.6c)\n##      (Intercept) speciesChinstrap    speciesGentoo \n##       3700.99471         32.08176       1374.15711\n\n\nDen Parameter für die Streuung des Modells, \\(\\sigma\\), kann man sich mit sigma(modell) ausgeben lassen:\n\n\nCode\nsigma(m10.6b)\n## [1] 463.7358\n\n\nImplizit bekommt man die Informationen zu \\(\\sigma\\) mitgeteilt durch die Größe der Konfidenzintervalle.\nÜbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren4.\n\n10.9.1 Wechsel der Referenzkategorie\n\nspecies ist eine nominale Variable, da passt in R der Typ factor (Faktor) am besten. Aktuell ist der Typ noch character (Text):\n\n\n\nCode\npenguins <- penguins %>% \n  mutate(species = factor(species))\n\n\nIm Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge ändern.\n\n\nCode\nlevels(penguins$species)\n## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n\nSetzen wir Gentoo als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:\n\n\nCode\nlibrary(forcats)\npenguins <- penguins %>% \n  mutate(species = factor(species),\n    species = fct_relevel(species, \"Gentoo\"))\n\n\nBeachten Sie, dass dazu das Paket forcats verfügbar sein muss.\nJetzt haben wir die Referenzkategorie geändert:\n\n\nCode\nlevels(penguins$species)\n## [1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\n\nDer Wechsel der Referenzkategorie ändert nichts Wesentliches am Modell:\n\n\nCode\nm10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)\nhdi(m10.6a)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n4994.870\n5155.267\nfixed\nconditional\n\n\nspeciesAdelie\n0.95\n-1478.109\n-1262.373\nfixed\nconditional\n\n\nspeciesChinstrap\n0.95\n-1471.435\n-1203.731\nfixed\nconditional"
  },
  {
    "objectID": "metrische-AV.html#modellgüte-mit-r-quadrat-bestimmen",
    "href": "metrische-AV.html#modellgüte-mit-r-quadrat-bestimmen",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.10 Modellgüte mit R-Quadrat bestimmen",
    "text": "10.10 Modellgüte mit R-Quadrat bestimmen\n\n10.10.1 Modellgüte mit \\(R^2\\) bestimmen\n\\(R^2\\) gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erklärt. - Höhere Wert von \\(R^2\\) bedeuten, dass das Modell die Daten besser erklärt. \\(R^2\\) wird normalerweise auf Basis eines Punktschätzers definiert. Solch eine Definition lässt aber viel Information - über die Ungewissheit der Schätzung - außen vor. Daher ist es wünschenswert, diese Information in \\(R^2\\) einfließen zu lassen: Bayes-R-Quadrat.\n\n\n\n\nCode\nr2(m10.6)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.667 (95% CI [0.619, 0.712])\n\n\nMöchte man es ausführlicher, und im Komfort einer Bayes-Analyse schwelgen, so kann man sich die Posteriori-Verteilung von \\(R2\\) ausgeben lassen, s. ?fig-m106-r2.\n\n\nCode\nm10.6_r2 <-\nm10.6 %>% \n  r2_posterior() %>% \n  as_tibble()\n\nhdi(m10.6_r2) %>% \n  plot()\n\n\n\n\n\nAbbildung 10.13: Die Verteilung von R-Quadrat im Modell m10.6\n\n\n\n\n\n\n10.10.2 Definition vom “klassischen” \\(R^2\\)\nWie genau sind die Vorhersagen des Modells? \\(\\sigma\\) (Vorhersagefehler) quantifiziert die Streuung der Residuen \\(r_i = y_i - X_i\\hat{\\beta}\\), mit \\(\\hat{y}_i = X_i\\hat{\\beta}\\). Anders gesagt: \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots = X\\hat{\\beta}\\). Anders gesagt gibt \\(\\sigma\\) die “typische” Abweichung einer Beobachtung vom vorhergesagten Wert an. Es ist nützlich, \\(\\sigma\\) in Bezug zu setzen zur Streuung der AV, \\(sd_y=s_y\\): \\(R^2 = 1- (\\hat{\\sigma}^2/s^2_y)\\). \\(R2\\) gibt damit den Anteil der vom Modell erklärten Varianz, \\(V\\), an. Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck äquivalent zu: \\(R^2=V_{i=1}^n \\hat{y}_i/s_y^2\\) Die beiden obigen Ausdrücke nehmen \\(\\hat{y}_i\\) als fix (sicher) an und vernachlässigen Ungewissheit; sie sind übergewiss aus Bayes-Sicht.\n\n\n10.10.3 Bayes’ \\(R^2\\)\nBesser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellgüte miteinzubeziehen: \\(\\text{Bayes }R^2 = \\frac{\\text{erkärte Varianz}}{\\text{Erklärte Varianz + Residualvarianz}}= \\frac{V_{mod}}{V_{mod} + V_{res}}\\).\n\\(V_{mod}\\) ist die Varianz in der PPV mit \\(s = 1, \\ldots, S\\) simulierten Stichproben, \\(V(\\hat{y}_i)\\) und \\(V_{res}\\) ist die Residualvarianz im Modell. Für jede Stichprobe \\(s\\) berechnet man die vorhergesagten Werte, \\(\\hat{y}_i^s\\), die Residualvarianz \\(\\sigma^2_s\\) und den Anteil der erklärten Varianz: \\(\\text{Bayes }R^2_s = \\frac{V(\\hat{y}_i^s)}{V(\\hat{y}_i^s+\\sigma_s^2)}\\), vgl. Gelman u. a. (2019), Gelman, Hill, und Vehtari (2021), Kap. 11.7."
  },
  {
    "objectID": "metrische-AV.html#sec-rope",
    "href": "metrische-AV.html#sec-rope",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.11 Nullhypothesen sind praktisch immer falsch",
    "text": "10.11 Nullhypothesen sind praktisch immer falsch\nNullhypothesen sind fast immer falsch, s. Abbildung 10.14.\n\n\n\n\n\nAbbildung 10.14: Du testest Nullhypothesen?\n\n\n\n\nQuelle: Imgflip Meme Generator\n\nWe do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have some effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.\n\nGelman, Hill, und Vehtari (2021)\n\n10.11.1 Alternativen zu Nullhypothesen\nNullhypothesen, \\(H_0\\), sind z.B.: \\(\\rho=0\\), \\(\\rho_1 = rho_2\\), \\(\\mu_1 = \\mu_2\\), \\(\\mu=0\\), \\(\\beta_1=0\\). Nullhypothesen zu testen, ist sehr verbreitet. Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest möglich ist5\nEin anderer Grund ist vermutlich, … wir haben es schon immer so gemacht.\nAlternativen zum Testen von Nullhypothesen sind:\n- Posteriori-Intervalle (PI oder HDI)  berichten\n- Rope-Konzept, @kruschke_rejecting_2018\n- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.\n- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.\n\n\n10.11.2 “Praktisch” kein Unterschied: Das Rope-Konzept\nSagen wir, wenn sich zwei Preismittelwerte um höchstens \\(d=100\\)€ unterscheiden, gilt dieser Unterschied für uns als “praktisch gleich”, “praktisch kein Unterschied” bzw. vernachlässigbar. Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer Nullhypothese: \\(H_0\\). Die Wahl von \\(d\\) ist subjektiv in dem Sinne als sie von inhaltlichen Überlegungen geleitet sein sollte. Diesen Bereich bezeichnen wir den Indifferenzbereich (Äquivalenzzone, Bereich eines vernachlässigbaren Unterschieds oder Region of practical equivalence, Rope). Jetzt prüfen wir, ob ein “Großteil” der Posteriori-Stichproben im Rope liegt. Unter “Großteil” wird häufig das 95%-HDI verstanden (das ist auch der Standard der R-Funktion rope(), die wir hier nutzen).\nEntscheidungsregel nach Kruschke (2018):\n\nGroßteil liegt innerhalb von Rope ➡️ Annahme der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\nGroßteil liegt außerhalb von Rope ➡️ Ablehnung der Nullhypothese “praktisch kein Effekt”, \\(H_0\\)\nAnsonsten ➡️ keine Entscheidung\n\n\n\n10.11.3 HDI-Rope-Entscheidungsregel visualisiert\n\n\n\n\n\nKruschke (2018), Abbildung 1, S. 272\n\n\n10.11.4 Rope berechnen\nDen Rope berechnet man mit rope(model).\n\n\nCode\nrope(m10.6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-80.19545\n80.19545\n0.0000000\nfixed\nconditional\n\n\nspeciesChinstrap\n0.95\n-80.19545\n80.19545\n0.7434211\nfixed\nconditional\n\n\nspeciesGentoo\n0.95\n-80.19545\n80.19545\n0.0000000\nfixed\nconditional\n\n\n\n\n\n\nDie Faktorstufe Chinstrap von species hat doch einen beträchtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE.\nWir können daher für diese Gruppe das ROPE nicht verwerfen.\nAber: Gentoo liegt zu 0% im Rope. Für Gentoo können wir das Rope verwerfen.\nDas hört sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.\n\n\n\n\n\n\nHinweis\n\n\n\nDie angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. help(rope).\n\n\n\n\n10.11.5 Visualisierung unserer Rope-Werte, m10.6\n\nEin Großteil der Posteriori-Masse von m10.6 liegt nicht innerhalb des Rope.\nAber können wir umgekehrt sagen, dass ein Großteil außerhalb liegt? Das erkennt man optisch ganz gut.\n\n\n\nCode\nrope(m10.6) %>% plot()\n\n\n\n\n\nDas ROPE druchkreuzt die “Berge” der Posteriori-Verteilung für Chinstrap deutlich. Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope. Wir können das Rope für Chinstrap nicht verwerfen, aber auch nicht bestätigen.\nGentoo hingegen wird vom vom Rope nicht durchkreuzt, es ist weit entfernt vom “blauen Fluss” des Rope: Gentoo liegt außerhalb des Rope. Es gibt einen “substanziellen” Unterschied, größer als das ROPE. Wir verwerfen die “Praktisch-Null-Hypothese” in diesem Fall.\n\n\n10.11.6 Finetuning des Rope\nWir können festlegen, was wir unter “praktischer Äquivalenz” verstehen, also die Grenzen des Ropes verändern. Sagen wir, 100 Gramm sind unsere Grenze für einen vernachlässigbaren Effekt, s. Abbildung 10.15.\n\n\nCode\nrope(m10.6, range = c(-100, 100))\nplot(rope(m10.6, range = c(-100, 100)))\n\n\n\n\n\nAbbildung 10.15: ROPE mit selber eingestellter Grenze von ±100 (Gramm)\n\n\n\n\nIm Standard werden 95%-HDI berichtet, das kann man so ändern, wenn man möchte:\n\n\nCode\nrope(m10.6, range = c(-100,100), ci = .89, ci_method = \"ETI\")\n\n\nETI (equal tails interval) steht für ein PI. Jetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.\n\n\n10.11.7 Beantwortung der Forschungsfrage\nFür die Spezeis Gentoo wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. Für Chinstrap hingegen ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs möglich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt."
  },
  {
    "objectID": "metrische-AV.html#mehrere-metrische-uv",
    "href": "metrische-AV.html#mehrere-metrische-uv",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.12 Mehrere metrische UV",
    "text": "10.12 Mehrere metrische UV\n\n10.12.1 Forschungsfrage\n\nStehen sowohl der IQ der Mutter als auch, unabhängig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?\n\n\nDas ist wieder eine deskriptive Forschungsfrage. Keine Kausalwirkung (etwa “IQ der Mutter ist die Ursache zum IQ des Kindes”) wird impliziert.\nEs geht rein darum, Zusammenhänge in den Daten - bzw. in der Population - aufzuzeigen.\nViele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. Für solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist nötig.\n\nDatenquelle als CSV-Datei oder alternativ:\n\n\nCode\nlibrary(rstanarm)\ndata(\"kidiq\")\n\n\n\n\n10.12.2 Was heißt, X hängt mit Y zusammen?\n\nDer Begriff “Zusammenhang” ist nicht exakt.\nHäufig wird er (für metrische Variablen) verstanden als\n\nlineare Korrelation \\(\\rho\\) bzw. \\(r\\)\nlineare Regression \\(\\beta\\), bzw. \\(b\\)\n\nDer Regressionskoeffizient\n\nmisst die Steigung der Regressionsgerade\nzeigt, wie groß der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden\nwird manchmal mit dem “Effekt von X auf Y” übersetzt. Vorsicht: “Effekt” klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begründung für einen Kausalzusammenhang.\n\nDer Korrelationskoeffizient\n\nmisst eine Art der Stärke des linearen Zusammenhangs\nzeigt, wie klein die Vorhersagefehler der zugehörigen Regrssion im Schnitt sind.\nKorrelation ist nicht (automatisch) Kausation.\n\n\n\n\n10.12.3 Korrelationen zur Forschungsfrage\n\n\nCode\nkidiq %>% \n  correlation()\n\n\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt(432)\np\n\n\n\n\nkid_score\nmom_hs\n0.24\n(0.15, 0.32)\n5.07\n< .001***\n\n\nkid_score\nmom_iq\n0.45\n(0.37, 0.52)\n10.42\n< .001***\n\n\nkid_score\nmom_age\n0.09\n(-2.15e-03, 0.18)\n1.92\n0.111\n\n\nmom_hs\nmom_iq\n0.28\n(0.19, 0.37)\n6.13\n< .001***\n\n\nmom_hs\nmom_age\n0.21\n(0.12, 0.30)\n4.57\n< .001***\n\n\nmom_iq\nmom_age\n0.09\n(-2.54e-03, 0.18)\n1.91\n0.111\n\n\n\np-value adjustment method: Holm (1979) Observations: 434\n\n\nOder als Korrelationsmatrix:\n\n\nCode\nkidiq %>% \n  correlation() %>% \n  summary()\n\n\n\n\n\n\nParameter\nmom_age\nmom_iq\nmom_hs\n\n\n\n\nkid_score\n0.0919982\n0.4482758\n0.2369164\n\n\nmom_hs\n0.2145284\n0.2827094\nNA\n\n\nmom_iq\n0.0916084\nNA\nNA\n\n\n\n\n\n\n\n\nCode\nkidiq %>% \n  correlation() %>% \n  summary() %>% \n  plot()\n\n\n\n\n\n\n\n10.12.4 Univariate Regressionen\nWir berechnen jeweils eine univariate Regression, pro Prädiktor, also eine für mom_iq und eine für mom_age.\n\n\nCode\nm10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)\nm10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)\n\n\nHier die Ergebnisse für mom_iq:\n\n\nCode\ncoef(m10.7)\n## (Intercept)      mom_iq \n##  25.7778123   0.6108659\n\n\nHier die Ergebnisse für mom_age:\n\n\nCode\ncoef(m10.8)\n## (Intercept)     mom_age \n##  71.0528981   0.6914317\n\n\n\n\n10.12.5 Visualisierung der univariaten Regressionen\nIn Abbildung 10.16 ist die univariate Regression mit jeweils einem der beiden Prädiktoren dargestellt.\nm10.7: Die Steigung beträgt 0.6. m10.8: Die Steigung beträgt 0.7.\n\n\nCode\np1 <- \n  kidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.7)[1],\n              slope = coef(m10.7)[2],\n              color = \"blue\") \n\np2 <- \nkidiq %>% \n  ggplot(aes(x = mom_age, y = kid_score)) +\n  geom_point() +\n  geom_abline(intercept = coef(m10.8)[1],\n              slope = coef(m10.8)[2],\n              color = \"blue\")\n\nplots(p1, p2,\n      title = c(\"m10.7: Die univariate Regression mit dem Alter der Mutter als Prädiktor\",\n        \"m10.8: Die univariate Regression mit dem IQ der Mutter als Prädiktor\"))\n\n\n\n\n\nAbbildung 10.16: Zwei univariate Regressionen\n\n\n\n\nUnivariate Regressionen\n\n\n10.12.6 Multiples Modell (beide Prädiktoren), m10.9\nm10.9 stellt das multiple Regressionsmodell dar; multipel bedeutet in diesem Fall, dass mehr als ein Prädiktor im Modell aufgenommen ist.\n\n\nCode\nm10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, \n                  data = kidiq, \n                  refresh = 0)\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.5161986   0.6040883   0.3804400\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.\n\n\n\nBei einer multiplen Regression ist ein Regressionsgewicht jeweils “bereinigt” vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.\nDas bedeutet, man betrachtet den den Zusammenhang eines Prädiktors mit der AV, wobei man gleichzeitig den anderen Prädiktor konstant hält.\n\n\n\nCode\ncoef(m10.9)\n## (Intercept)      mom_iq     mom_age \n##  17.5161986   0.6040883   0.3804400\n\n\n\n\n10.12.7 3D-Visualisierung eines Modells mit zwei Prädiktoren 1\nIn Abbildung 10.17 ist das Modell m10.9 in 3D dargestellt via Plotly.\n\n\n\n\n\nAbbildung 10.17: 3D-Visualisierung von m10.9 (zwei Prädiktoren)\n\n\n\n\n\n10.12.8 Visualisierung mit Farbe statt 3. Dimension\n3D-Visualisierungen haben Vorteile, aber auch Nachteile; Abbildung 10.18 zeigt eine alternative Visualisierung, in der die 3. Dimension durch eine Farbschattierung ersetzt ist.\n\n\n\n\n\nAbbildung 10.18: Modell m10.9; die Farbverläufe zeigen der Wert der abhängigen Variablen\n\n\n\n\nAuf der Achse von mom_iq erkennt man deutlich (anhand der Farbänderung) die Veränderung für die AV (kid_score). Auf der Achse für mom_age sieht man, dass sich die AV kaum ändert, wenn sich mom_age ändert.\n\n\n10.12.9 Visualisierung in 10 Dimensionen\nAbbildung 10.19 visualisiert den Zusammenhang von 10 Variablen untereinander.\n\n\n\n\n\nAbbildung 10.19: So sieht der Zusammenhang im 10-dimensionalen Raum aus\n\n\n\n\nLeider macht mein Hirn hier nicht mit. Unsere Schwächen, eine große Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.\nDaher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.\n\n\n10.12.10 Relevanz der Prädiktoren\nWoher weiß man, welcher Prädiktor am stärksten mit der AV zusammenhängt? Man könnte auch sagen: Welcher Prädiktor (welche UV) am “wichtigsten” ist oder den “stärksten Einfluss” auf die AV ausübt? Bei solchen kausal konnotierten Ausdrücken muss man vorsichtig sein: Die Regressionsanalyse als solche ist keine Kausalanalyse. Die Regressionsanalyse - wie jede statistische Methoden - kann für sich nur Muster in den Daten, also Zusammenhänge bzw. Unterschiede, entdecken, s. Abbildung 10.20.\n\n\n\nAbbildung 10.20: Made at imgflip.com\n\n\nWelcher Prädiktor ist nun “wichtiger” oder “stärker” in Bezug auf den Zusammenhang mit der AV, mom_iq oder mom_age (Modell m10.9)?\n\nmom_iq hat den größeren Koeffizienten.\nmom_age hat weniger Streuung.\n\nUm die Relevanz der Prädiktoren vergleichen zu können, müsste man vielleicht die Veränderung von kid_score betrachten, wenn man von kleinsten zum größten Prädiktorwert geht. Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden). Sinnvoller ist es daher, die Veränderung in der AV zu betrachten, wenn man den Prädiktor von “unterdurchschnittlich” auf “überdurchschnittlich” ändert. Das kann man mit z-Standardisierung erreichen.\n\n\n10.12.11 z-Standardisierung\nz-Standardisierung bedeutet, eine Variable so zu transformieren, dass sie über einen Mittelwert von 0 und eine SD von 1 verfügt:\n\\[z = \\frac{x - \\bar{x}}{sd(x)}\\]\n\n\nCode\ndata(\"kidiq\")\nkidiq2 <- \n  kidiq %>% \n  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% \n  select(mom_iq, mom_iq_z) %>% \n  head()\n\n\nDer Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten6. Die Standardisierung ist ähnlich zur Vergabe von Prozenträngen: “Dieser Messwert gehört zu den Top-3-Prozent”. Diese Aussage ist bedeutsam für Variablen mit verschiedenem Mittelwert und Streuung. So werden vergleichende Aussagen für verschiedene Verteilungen möglich.\n\n\n10.12.12 Statistiken zu den z-transformierten Variablen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nkid_score\n86.80\n20.41\n28.00\n(20.00, 144.00)\n-0.46\n-0.16\n434\n0\n\n\nmom_hs\n0.79\n0.41\n0.00\n(0.00, 1.00)\n-1.40\n-0.05\n434\n0\n\n\nmom_iq\n100.00\n15.00\n21.67\n(71.04, 138.89)\n0.47\n-0.57\n434\n0\n\n\nmom_age\n22.79\n2.70\n4.00\n(17.00, 29.00)\n0.18\n-0.63\n434\n0\n\n\n\n\n\nMan kann auch die z-Transformation (“Skalierung”) mit standardize durchführen:\n\n\nCode\nkidiq <- \n  standardize(kidiq, append = TRUE)\n\nhead(kidiq)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n\n\n\n\n\n\nDer Schalter append = TRUE sorgt dafür, dass die ursprünglichen Variablen beim Z-Standardisieren nicht überschrieben werden, sondern angehängt werden (mit einem Suffix _z).\nMan kann auch nur einzelne Variablen mit standardize standardisieren.\n\n\nCode\nkidiq %>% \n  standardize(select = c(\"mom_iq\", \"mom_age\", \"kid_score\"))\n\n\nMan kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket:\n\n\nCode\n#data(kidiq)\nkidiq %>% \n  mutate(mom_iq_z2 = scale(mom_iq),\n         mom_age_z2 = scale(mom_age),\n         kid_score_z2 = scale(kid_score)) %>% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_age\nkid_score_z\nmom_hs_z\nmom_iq_z\nmom_age_z\nmom_iq_z2\nmom_age_z2\nkid_score_z2\n\n\n\n\n65\n1\n121.11753\n27\n-1.0679324\n0.521631\n1.4078352\n1.5602285\n1.4078352\n1.5602285\n-1.06793237\n\n\n98\n1\n89.36188\n25\n0.5488676\n0.521631\n-0.7092079\n0.8197811\n-0.7092079\n0.8197811\n0.54886757\n\n\n85\n1\n115.44316\n27\n-0.0880536\n0.521631\n1.0295443\n1.5602285\n1.0295443\n1.5602285\n-0.08805362\n\n\n83\n1\n99.44964\n25\n-0.1860415\n0.521631\n-0.0366907\n0.8197811\n-0.0366907\n0.8197811\n-0.18604150\n\n\n115\n1\n92.74571\n27\n1.3817645\n0.521631\n-0.4836193\n1.5602285\n-0.4836193\n1.5602285\n1.38176451\n\n\n98\n0\n107.90184\n18\n0.5488676\n-1.912647\n0.5267892\n-1.7717849\n0.5267892\n-1.7717849\n0.54886757"
  },
  {
    "objectID": "metrische-AV.html#modell-m10.10",
    "href": "metrische-AV.html#modell-m10.10",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.13 Modell m10.10",
    "text": "10.13 Modell m10.10\nIm Modell m10.10 sind die Prädiktoren z-standardisiesrt. Das Standardisieren der AV, kid_score ist nicht nötig, um den Effekt der Prädiktoren (UV) auf die AV zu untersuchen. Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage darüber, um wie viele SD-Einheiten sich die AV verändert, wenn sich ein Prädiktor um eine SD-Einheit verändert.\n\n\nCode\nm10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, \n                   data = kidiq, \n                   refresh = 0)\ncoef(m10.10)\n##   (Intercept)      mom_iq_z     mom_age_z \n## -0.0007527543  0.4434725898  0.0511782491\n\n\n\nDer Achsenabschnitt gibt den Mittelwert der AV (kid_score) an, da kid_score_z = 0 identisch ist zum Mittelwert von kid_score.\nDer Koeffizient für mom_iq_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_iq um eine SD-Einheit ändert.\nDer Koeffizient für mom_age_z gibt an, um wie viele SD-Einheiten sich kid_score (die AV) ändert, wenn sich mom_age um eine SD-Einheit ändert.\n\nJetzt sind die Prädiktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar:\n\nMan sieht, dass die Intelligenz der Mutter deutlich wichtiger ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).\n\n\n10.13.1 95%-PI\nMit parameters können wir uns ein PI für m10.10 ausgeben lassen, s. Abbildung 10.21; im Standard wird ein ETI berichtet.\n\n\nCode\nparameters(m10.10) \n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-7.53e-04\n(-0.09, 0.09)\n50.50%\n0.999\n5170.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0.999\n5501.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.72%\n0.999\n4884.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\n\nCode\nplot(eti(m10.10))\n\n\n\n\n\nAbbildung 10.21: Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI für m10.10\n\n\n\n\n\n\n10.13.2 Was ist ein kleiner, was ein großer Effekt?\nCohen (1988) definiert Effektstärken in Bezug auf Mittelwertsvergleiche anhand von \\(d=(\\mu_1 - \\mu_o) / \\sigma\\). Für kleine, mittlere und große Werte gab er folgende Richtwerte:\n\nklein: \\(d \\approx 0.2\\)\nmittel: \\(d \\approx 0.5\\)\ngroß: \\(d \\approx 0.8\\)\n\nAuf dieser Basis schlägt Kruschke (2018) einen Rope von \\(\\pm0.1\\) vor. Fällt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als “praktisch null”. Richtlinien für Effektstärken sind nur Notlösungen, die durch Sachverstand ersetzt werden sollen, wo immer möglich. Man kann Effektstärken ineinander überführen, s. hier, z.B. von Korrelation (r) zu Cohens d oder \\(R^2\\).\n\n\n10.13.3 Vernachlässigbarer Regressionseffekt\nKruschke (2018) schlägt vor, einen Regressionskoeffizienten unter folgenden Umständen als “praktisch Null” zu bezeichnen:\nWenn eine Veränderung über “praktisch den ganzen Wertebereich” von \\(x\\) nur einen vernachlässigbaren Effekt auf \\(y\\) hat. Ein vernachlässigbarer Effekt ist dabei \\(\\hat{y}= \\pm 0.1 sd_y\\). Der “praktisch ganze Wertebereich” von \\(x\\) sei \\(\\bar{x} \\pm 2 sd_x\\). Resultiert der Vergleich von \\(\\bar{x} -2 sd\\) mit \\(\\bar{x}+2sd\\) nur eine Veränderung in \\(\\hat{y}\\) von \\(\\bar{y} - 0.1sd_y\\) auf \\(\\bar{y} + 0.1 sd_y\\), so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachlässigbar. Das impliziert Rope-Grenzen von \\(\\beta_x = \\pm 0.05\\) für z-standardisierte Variablen.\n\n\n10.13.4 Modellgüte\n\n\nCode\nr2(m10.10)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.205 (95% CI [0.144, 0.270])\n\n\nIst dieser Wert von \\(R2\\) “gut”? Diese Frage ist ähnlich zur Frage “Ist das viel Geld?”; man kann die Frage nur im Kontext beantworten.\nEine einfache Lösung ist immer, Modelle zu vergleichen. Dann kann man angeben, welches Modell die Daten am besten erklärt, z.B. auf Basis von \\(R^2\\).\nZu beachten ist, dass das Modell theoretisch fundiert sein sollte. Vergleicht man viele Modelle aufs Geratewohl, so muss man von zufällig hohen Werten der Modellgüte im Einzelfall ausgehen.\nWenn Sie aber unbedingt eine “objektive” Antwort auf die Frage “wie viel ist viel?” haben wollen, ziehen wir Herrn Cohen zu Rate:\n\n\nCode\ninterpret_r2(0.2)  # aus `easystats`\n## [1] \"moderate\"\n## (Rules: cohen1988)\n\n\nDanke, Herr Cohen!\n\n\n10.13.5 Priori-Verteilung für m10.10 und Modelldefinition\nStan hat für uns folgende Prioris ausgesucht:\n\n\nCode\nprior_summary(m10.10)  # aus rstanarm\n## Priors for model 'm10.10' \n## ------\n## Intercept (after predictors centered)\n##  ~ normal(location = -2.8e-16, scale = 2.5)\n## \n## Coefficients\n##  ~ normal(location = [0,0], scale = [2.5,2.5])\n## \n## Auxiliary (sigma)\n##  ~ exponential(rate = 1)\n## ------\n## See help('prior_summary.stanreg') for more details\n\n\nWie gesagt, Stan nimmt dafür einfach die empirischen Mittelwerte und Streuungen her7.\nStans Ausgabe kann man in Mathe-Sprech so darstellen, s. Gleichung 10.1.\n\\[\n\\begin{aligned}\n\\text{kidscore}  &\\sim \\mathcal{N}(0,2.5)\\\\\n\\mu_i &= \\alpha + \\beta_1\\text{momiq}_i + \\beta_2\\text{momage}_i \\\\\n\\alpha &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_1 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\beta_2 &\\sim \\mathcal{N}(0,2.5)\\\\\n\\sigma &\\sim \\mathcal{E}(1)\n\\end{aligned}\n\\tag{10.1}\\]\nMan beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird: Bei mittlerer Intelligenz und mittlerem Alter der Mutter wird mittlere Intelligenz des Kindes erwartet in m10.10. Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.\nSchreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuführen.\n\n\n10.13.6 Beantwortung der Forschungsfrage\n\nDas Modell spricht sich klar für einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erkärt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm (Goodrich u. a. 2022) zurück (s. Anhang für Details).\n\n\n\n\n\n\n\nWichtig\n\n\n\nHier wird von einem “statistischen Effekt” gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenhänge, und nicht um kausale Zusammenhänge, handelt. Kausale Zusammenhänge dürfen wir nur verkünden, wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege dafür finden oder c) wir ein Experiment fachgerecht durchgeführt haben."
  },
  {
    "objectID": "metrische-AV.html#vertiefung",
    "href": "metrische-AV.html#vertiefung",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.14 Vertiefung",
    "text": "10.14 Vertiefung\n🏎️VERTIEFUNG, nicht prüfungsrelevant🏎️\n\n10.14.1 Verwandtheit von Korrelation und Regression\nSind X und Y z-standardisiert, so sind Korrelation und Regression identisch.\n\\[b = r \\frac{sd_x}{sd_y}\\]\n\n\nCode\nm10.11 <- \n  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq, refresh = 0)\ncoef(m10.11)\n##   (Intercept)      mom_iq_z \n## -0.0006129979  0.4472294200\n\n\n\n\nCode\nkidiq %>% \n  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% \n  correlation()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nkid_score\nmom_iq\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nkid_score\nkid_score_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nkid_score_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\nmom_iq\nmom_iq_z\n1.0000000\n0.95\n1.000000\n1.000000\nInf\n432\n0\nPearson correlation\n434\n\n\nkid_score_z\nmom_iq_z\n0.4482758\n0.95\n0.369749\n0.520444\n10.42319\n432\n0\nPearson correlation\n434\n\n\n\n\n\n\n\n\n10.14.2 Prüfen der Linearitätsannahme\nZentrale Annahme: Die AV ist eine lineare Funktion der einzelnen Prädiktoren:\n\\[y= \\alpha + \\beta_1x_1 + \\beta_2 x_2 + \\cdots .\\]\nHingegen ist es weniger, dass die AV (y) normalverteilt ist. Zwar nimmt die Regression häufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu schätzen (Gelman, Hill, und Vehtari 2021).\nIst die Linearitätsannahme erfüllt, so sollte der Residualplot nur zufällige Streuung um \\(y=0\\) herum zeigen, s. Abbildung 10.22.\nEin Residuum \\(e\\) ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tatsächlichem Wert:\n\\(e_i = y_i - \\hat{y}_i\\)\n\n\nCode\nkidiq <-\n  kidiq %>% \n  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte\n         m10.10_resid = resid(m10.10))  # Residuen\n\n\n\n\nCode\nkidiq %>% \n  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +\n  geom_hline(color=\"white\", yintercept = 0, size = 2) +\n  geom_hline(color = \"grey40\", \n             yintercept = c(-1,1), \n             size = 1, \n             linetype = \"dashed\") +\n  geom_point(alpha = .7) +\n  geom_smooth()\n\n\n\n\n\nAbbildung 10.22: Die Verteilung der Fehler scheint keinem starken Trend (in Abhängigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist.\n\n\n\n\nHier erkennt man keine größeren Auffälligkeiten.\n\n\n10.14.3 Modellprüfung mit der PPV\n\n\nCode\npp_check(m10.10)\n\n\n\n\n\nUnser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, \\(y_{rep}\\) verfehlt den Mittelwert von \\(y\\) leider recht häufig.\n\n\n10.14.4 Visualisierung der bereinigten Regressionskoeffizienten\n\n\nCode\nset.seed(42)\ndata(kidiq)\nkidiq3 <- \n  kidiq %>% \n  standardize(append = TRUE) %>% \n  sample_n(size = 300)\n\n#| results: \"hide\"\nm10.10a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)\nm10.10b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(mom_age_resid = resid(m10.10a)) %>% \n  mutate(mom_iq_resid = resid(m10.10b))\n\n\nm10.10c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)\nm10.10d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)\n\n\nkidiq3 <-\n  kidiq3 %>% \n  mutate(m10.10c_resid = resid(m10.10c)) %>% \n  mutate(m10.10d_resid = resid(m10.10d))\n\n\n\n\n\n\n\nCode\n#(m10.10a_plot + m10.10b_plot) / (m10.10c_plot + m10.10d_plot)\nplots(m10.10a_plot, m10.10b_plot, m10.10c_plot, m10.10d_plot, \n      n_rows = 2, tags = \"A\",\n      guides = \"collect\")\n\n\n\n\n\nDie vertikalen Balken zeigen die Residuen.\nObere Reihe: Regression eines Prädiktors auf den anderen Prädiktor. Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, kid-score_z. Unten links (C): Die Residuen von mom_iq_c sind kaum mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_age_z, der nicht mit mom_iq_z zusammenhängt, um kid_score vorher zusagen, findet man keinen (kaum) Zusammenhang. Unten rechts (D): Die Residuen von mom_age_c sind stark mit der AV assoziiert. Das heißt, nutzt man den Teil von mom_iq_z, der nicht mit mom_age_z zusammenhängt, um kid_score vorher zusagen, findet man einen starken Zusammenhang.\nEine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-7.53e-04\n(-0.09, 0.09)\n50.50%\n0.999\n5170.00\nNormal (-2.81e-16 +- 2.50)\n\n\nmom_iq_z\n0.44\n(0.36, 0.53)\n100%\n0.999\n5501.00\nNormal (0.00 +- 2.50)\n\n\nmom_age_z\n0.05\n(-0.03, 0.14)\n87.72%\n0.999\n4884.00\nNormal (0.00 +- 2.50)\n\n\n\n\n\n\n\n10.14.5 Bereinigte Regressionskoeffizienten für mtcars\n\n\nCode\nmtcars2 <-\n  mtcars %>% \n  standardize()\n\nm12a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)\nm12b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)\n\nmtcars2 <-\n  mtcars %>% \n  mutate(m12a_resid = resid(m12a)) %>% \n  mutate(m12b_resid = resid(m12b))\n\n\nm12c <- stan_glm(mpg ~ m12a_resid, data = mtcars2, refresh = 0, chains = 1)\nm12d <- stan_glm(mpg ~ m12b_resid, data = mtcars2, refresh = 0, chains = 1)\n\n\nmtcars2 <-\n  mtcars2 %>% \n  mutate(m12c_resid = resid(m12c)) %>% \n  mutate(m12d_resid = resid(m12d))\n\n\n\n\n\n\n\n\n\n\nÜbrigens liefern stan_glm() und lm oft ähnliche Parameterwerte (bei schwach informativen Prioriwerten):\n\n\nCode\nstan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()\n## (Intercept)          hp         cyl \n## 36.84877039 -0.01934222 -2.26124451\n\nlm(mpg ~ hp + cyl, data = mtcars) %>% coef()\n## (Intercept)          hp         cyl \n##  36.9083305  -0.0191217  -2.2646936\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWenn auch die Parameterwerte eines Frequentistischen und Bayes-Modell numerisch ähnlich sein können, so ist doch die Interpretation grundverschieden. Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.\n\n\n\n\n10.14.6 Post: Bayes in fünf Minuten\nEine Kurzdarstellung des Bayes-Inferenz findet sich in diesem Post und in diesem."
  },
  {
    "objectID": "metrische-AV.html#ausblick-binäre-av",
    "href": "metrische-AV.html#ausblick-binäre-av",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.15 Ausblick: Binäre AV",
    "text": "10.15 Ausblick: Binäre AV\n\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: Hängen Spritverbrauch und Getriebeart? (Datensatz mtcars)\n\nDazu nutzen wir den Datensatz mtcars, wobei wir die Variablen z-standardisieren.\n\n\nCode\ndata(mtcars)\nmtcars2 <-\n  mtcars %>% \n  standardize(append = TRUE)\n\n\nDann berechnen wir mit Hilfe von Stan ein Regressionsmodell: m13: am ~ mpg_z:\n\n\nCode\nm13 <-\n  stan_glm(am ~ mpg_z, \n           data = mtcars2, \n           refresh = 0)\ncoef(m13)\n## (Intercept)       mpg_z \n##   0.4060587   0.2975638\n\n\nAb mpg_z = 0.41, 0.3 sagt das Modell am=1 (manuell) vorher. Ganz ok.\n\n\nCode\nmtcars2 %>% \n  ggplot(aes(x = mpg_z, y = am)) +\n  geom_hline(yintercept = 0.5, color = \"white\", size = 2) +\n  geom_point() +\n  geom_abline(intercept = coef(m13)[1],\n              slope = coef(m13)[2],\n              color = \"blue\") \n\n\n\n\n\n\n\nCode\nneg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))\n\n\nFür kleine Werte von mpg_z (<1.3) sagt unser Modell negative Werte für am voraus. Das macht keinen Sinn: Es gibt keine negative Werte von am, nur 0 und 1. Müssen wir mal bei Gelegenheit besser machen.\nWir waren fleißig …\n\n\n\n\n\nQuelle\nGenug für heute. 👍"
  },
  {
    "objectID": "metrische-AV.html#aufgaben",
    "href": "metrische-AV.html#aufgaben",
    "title": "10  Forschungsfragen mit metrischer AV",
    "section": "10.16 Aufgaben",
    "text": "10.16 Aufgaben\n\nAnova-skalenniveau\nNullhyp-Beispiel\nttest-skalenniveau\nGriech-Buchstaben-Inferenz\nInteraktionseffekt1\nRegression2\nRegression3  \ndiamonds-nullhyp-mws\nstan_glm_parameterzahl\nstan_glm_prioriwerte\nzwert-berechnen\nRegr-Bayes-interpret\nRegr-Bayes-interpret03\nRegr-Bayes-interpret02\nrope-regr\nrope1\nrope2\nrope3\nrope4\n\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja, Sitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, und Daniel M. Croymans. 2021. „Behavioural Nudges Increase COVID-19 Vaccinations“. Nature 597 (7876): 404–9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, und Aki Vehtari. 2019. „R-Squared for Bayesian Regression Models“. The American Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, und Sam Brilleman. 2022. „rstanarm: Bayesian applied regression modeling via Stan.“ https://mc-stan.org/rstanarm/.\n\n\nKruschke, John K. 2018. „Rejecting or Accepting Parameter Values in Bayesian Estimation“. Advances in Methods and Practices in Psychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B. Gubbay, Sarah A. Buchan, Deshayne B. Fell, u. a. 2021. „Effectiveness of mRNA and ChAdOx1 COVID-19 Vaccines Against Symptomatic SARS-CoV-2 Infection and Severe Outcomes with Variants of Concern in Ontario“. https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi, Mohammad Hossein Razizadeh, Diana L. Turner, und Raymond J. Turner. 2021. „Efficacy and Safety of COVID-19 Vaccines: A Systematic Review and Meta-Analysis of Randomized Clinical Trials“. Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball, Allison L. Naleway, Toan C. Ong, Malini B. DeSilva, u. a. 2021. „Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient Care Settings“. New England Journal of Medicine 385 (15): 1355–71. https://doi.org/10.1056/NEJMoa2110362."
  },
  {
    "objectID": "kausal.html",
    "href": "kausal.html",
    "title": "11  Kausalinferenz",
    "section": "",
    "text": "Für dieses Kapitel benötigen Sie folgende R-Pakete:\n\n\nCode\nlibrary(dagitty)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n\n\n\n\n\n\n\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nrklären, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\ndie “Atome” der Kausalität eines DAGs benennen\n“kausale Hintertüren” schließen"
  },
  {
    "objectID": "kausal.html#statistik-was-soll-ich-tun",
    "href": "kausal.html#statistik-was-soll-ich-tun",
    "title": "11  Kausalinferenz",
    "section": "11.2 Statistik, was soll ich tun?",
    "text": "11.2 Statistik, was soll ich tun?\n\n11.2.1 Studie A: Östrogen\nMit Blick auf Tabelle 11.1: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\n\n\n\nTabelle 11.1:  Daten zur Studie A \n  \n  \n    \n      Gruppe\n      Mit Medikament\n      Ohne Medikament\n    \n  \n  \n    Männer\n81/87 überlebt (93%)\n234/270 überlebt (87%)\n    Frauen\n192/263 überlebt (73%)\n55/80 überlebt (69%)\n    Gesamt\n273/350 überlebt (78%)\n289/350 überlebt (83%)\n  \n  \n  \n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualität (Beobachtungsstudie). Bei Männern scheint das Medikament zu helfen; bei Frauen auch. Aber insgesamt (Summe von Frauen und Männern) nicht?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er das Geschlecht kennt Pearl, Glymour, und Jewell (2016)?\n\n\n11.2.2 Kausalmodell zur Studie A\nIn Wahrheit sehe die kausale Struktur so aus: Das Geschlecht (Östrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-). Das Medikament hat einen Einfluss (+) auf Heilung. Betrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (Östrogen) und Medikament vermengt (konfundiert, confounded). Die kausale Struktur, also welche Variable beeinflusst bzw. nicht, ist in Abbildung 11.1 dargestellt.\n\n\n\n\n\nAbbildung 11.1: Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender über drug) auf recovery\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren ist also in diesem Fall der korrekte, richtige Weg.\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen konfundierten Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n\n\n\n\nWichtig\n\n\n\nAchtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige Lösung.\n\n\n\n\n11.2.3 Studie B: Blutdruck\nMit Blick auf Tabelle 11.2: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n\n\n\n\nTabelle 11.2:  Daten zur Wirksamkeit eines Medikaments (Studie B) \n  \n  \n    \n      Gruppe\n      Ohne Medikament\n      Mit Medikament\n    \n  \n  \n    geringer Blutdruck\n81/87 überlebt (93%)\n234/270 überlebt (87%)\n    hoher Blutdruck\n192/263 überlebt (73%)\n55/80 überlebt (69%)\n    Gesamt\n273/350 überlebt (78%)\n289/350 überlebt (83%)\n  \n  \n  \n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, \\(n=700\\), hoher Qualität (Beobachtungsstudie). Bei geringem Blutdruck scheint das Medikament zu schaden. Bei hohem Blutdrck scheint das Medikamenet auch zu schaden. Aber insgesamt (Summe über beide Gruppe) nicht, da scheint es zu nutzen?! Was sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? Pearl, Glymour, und Jewell (2016)\n\n\n11.2.4 Kausalmodell zur Studie B\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck. Gleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung. Verringerter Blutdruck hat einen positiven Einfluss auf die Heilung. Sucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament schädlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\nDas Kausalmodell ist in Abbildung 11.2 dargestellt.\n\n\n\n\n\nAbbildung 11.2: Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer schädlich\n\n\n\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den nützlichen (Reduktion des Blutdrucks).\n\n\n\n\n\n\nWichtig\n\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. Stratifizieren wäre falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar wäre.\n\n\n\n\n11.2.5 Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\nVergleichen Sie die DAGs Abbildung 11.1 und Abbildung 11.2, die die Kausalmodelle der Studien A und B darstellen: Sie sind unterschiedlich.\nKausale Interpretation - und damit Entscheidungen für Handlungen - war nur möglich, da das Kausalmodell bekannt ist. Die Daten alleine reichen nicht. Gut merken.\n\n\n11.2.6 Sorry, Statistik: Du allein schaffst es nicht\nStatistik alleine reicht nicht für Kausalschlüsse. 🧟 Statistik plus Theorie erlaubt Kausalschlüsse. 📚➕📊 🟰 🤩\n\n\n\n\n\n\nWichtig\n\n\n\nFür Entscheidungen (“Was soll ich tun?”) braucht man kausales Wissen. Kausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n\n\n\n\n11.2.7 Studie C: Nierensteine\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. Ärzte tendieren zu Behandlung A bei großen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die Ärzte zu Behandlung B.\nSollte ein Patient, der nicht weiß, ob sein Nierenstein groß oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratiﬁzierten Daten (Teildaten nach Steingröße) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) wählt?\n\n\n11.2.8 Kausalmodell zur Studie C\nDie Größe der Nierensteine hat einen Einfluss auf die Behandlungsmethode. Die Behandlung hat einen Einfluss auf die Heilung. Damit gibt es eine Mediation (“Kette”) von Größe \\(\\rightarrow\\) Behandlung \\(\\rightarrow\\) Heilung. Darüber hinaus gibt es noch einen Einfluss von Größe der Nierensteine auf die Heilung.\nDas Kausalmodell ist in Abbildung 11.3 dargestellt; @Abbildung 11.3 visualisiert alternativ.\nSollte man hier size kontrollieren, wenn man den Kausaleffekt von treatment schätzen möchte? Oder lieber nicht kontrollieren?\n\n\n\n\n\nAbbildung 11.3: DAG zur Nierenstein-Studie\n\n\n\n\n\n\n\n\n\nAbbildung 11.4: DAG zur Nierenstein-Studie in zweiter Darstellungsform\n\n\n\n\nJa: In diesem Fall sollte man size kontrollieren, denn man ist am Effekt des treatments interessiert. Würde man nicht size kontrollieren, bekäme man den “vermengten” Effekt von size und treatment, also keine (belastbare) Aussage über den Effekt der Behandlung.\n\n\n11.2.9 Mehr Beispiele\nNehmen Sie Bezug zu folgenden Aussagen:\n\nStudien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erhöhen, wenn du heiratest.\n\n\nStudien zeigen, dass Leute, die sich beeilen, zu spät zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu spät zu deiner Besprechung."
  },
  {
    "objectID": "kausal.html#konfundierung",
    "href": "kausal.html#konfundierung",
    "title": "11  Kausalinferenz",
    "section": "11.3 Konfundierung",
    "text": "11.3 Konfundierung\n\n11.3.1 Datensatz ‘Hauspreise im Saratoga County’\nDatenquelle; Beschreibung des Datensatzes\n\n\nCode\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.3.2 Immobilienpreise in einer schicken Wohngegend vorhersagen\n\nFinden Sie den Wert meiner Immobilie heraus!  Die muss viel wert sein!”\n\n🧑 Das ist Don, Immobilienmogul, Auftraggeber.\n\nDas finde ich heraus. Ich mach das wissenschaftlich. 👩 🔬\n\nDas ist Angie, Data Scientistin.\n\n\n11.3.3 Modell 1: Preis als Funktion der Anzahl der Zimmer\n\n“Hey Don! Mehr Zimmer, mehr Kohle!” 👩 🔬\n\n\n\n\n\n\n\n\n11.3.4 Posteriori-Verteilung von Modell 1\n\n“Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend.”\n\n👩\n\nZu wenig! 🤬\n\n🧑\nBerechnen wir das Modell:\n\n\nCode\nm1 <- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               data = d)\nhdi(m1)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n43840.61\n77124.87\nfixed\nconditional\n\n\nbedrooms\n0.95\n43079.51\n53288.92\nfixed\nconditional\n\n\n\n\n\n\nMit estimate_preditioncs können wir Vorhersagen berechnen (bzw. schätzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist “schätzen” vielleicht das treffendere Wort):\n\n\nCode\ndons_house <- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n\n\n\n\n\n\nbedrooms\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n2\n157442.5\n92828.53\n-17127.16\n342171.7\n\n\n\n\n\n\n\n\n11.3.5 Don hat eine Idee\n\n“Ich bau eine Mauer! Genial! An die Arbeit, Angie!  🧑\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\nDas ist keine gute Idee, Don.”\n\n👩\nBerechnen wir die Vorhersagen für Dons neues Haus (mit den durch Mauern halbierten Zimmern).\n\n\nCode\ndons_new_house <- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\n\n\n\n\n\n\nbedrooms\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n4\n254045.5\n90376.97\n75213.52\n438559.8\n\n\n\n\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut m1.\n\nVolltreffer! Jetzt verdien ich 100 Tausend mehr! 🤑 Ich bin der Größte! 🧑\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: “4e+05” ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: \\(4 \\cdot 100000 = 4\\cdot10^5 = 400000\\)\n\n\n\n\n11.3.6 R-Funktionen, um Beobachtungen vorhersagen\nestimate_prediction(m1, dons_new_house) erstellt Vorhersageintervalle, berücksichtigt also zwei Quellen von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\nUngewissheit im “Strukturmodell”: Wenn also z.B. in unserem Modell ein wichtiger Prädiktor fehlt, so kann die Vorhersagen nicht präzise sein. Fehler im Strukturmodell schlagen sich in breiten Schätzintervallen (bedingt durch ein großes \\(\\sigma\\)) nieder.\n\nestimate_expectation(m1, dons_new_house) erstellt Konfidenzintervalle. berücksichtigt also nur eine Quelle von Ungewissheit:\n\nUngewissheiten in den Parametern (Modellkoeffizienten, \\(\\beta_0, \\beta_1, ...\\))\n\nDie Schätzbereiche sind in dem Fall deutlich kleiner:\n\n\nCode\nestimate_expectation(m1, dons_new_house)\n\n\n\n\n\n\nbedrooms\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n4\n252750.8\n3180.447\n247013\n259149.6\n\n\n\n\n\n\n\n\n11.3.7 Modell 2: price ~ bedrooms + livingArea\nBerechnen wir das Modell m2: price ~ bedrooms + livingArea.\n\n\nCode\nm2 <- stan_glm(price ~ bedrooms + livingArea, data = d, refresh = 0)\n\nhdi(m2)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n23858.8853\n49287.0975\nfixed\nconditional\n\n\nbedrooms\n0.95\n-19765.5040\n-9083.4058\nfixed\nconditional\n\n\nlivingArea\n0.95\n118.4447\n132.5536\nfixed\nconditional\n\n\n\n\n\n\nWas sind die Vorhersgaen des Modell?\n\n\nCode\nestimate_prediction(m2, data = tibble(bedrooms = 4, livingArea = 1200))\n\n\n\n\n\n\nbedrooms\nlivingArea\nPredicted\nSE\nCI_low\nCI_high\n\n\n\n\n4\n1200\n129757.5\n69715.05\n-12376.63\n259215.2\n\n\n\n\n\n\nAndere, aber ähnliche Frage: Wieviel Haus kostet ein Haus mit sagen wir 4 Zimmer gemittelt über die verschiedenen Größen von livingArea? Stellen Sie sich alle Häuser mit 4 Zimmern vor (also mit verschiedenen Wohnflächen). Wir möchten nur wissen, was so ein Haus “im Mittel” kostet. Wir möchten also die Mittelwerte pro bedroom schätzen, gemittelt für jeden Wert von bedroom über livingArea:\n\n\nCode\nestimate_means(m2, at = \"bedrooms\", length = 7)\n\n\n\n\n\n\nbedrooms\nMean\nCI_low\nCI_high\n\n\n\n\n1\n242519.3\n230510.6\n254479.7\n\n\n2\n228300.7\n221405.8\n235327.4\n\n\n3\n214140.5\n210800.1\n217293.3\n\n\n4\n199960.6\n194346.5\n205417.3\n\n\n5\n185766.2\n175301.2\n195983.9\n\n\n6\n171661.4\n155680.4\n186894.2\n\n\n7\n157538.4\n136179.1\n177991.5\n\n\n\n\n\n\n\n“Die Zimmer zu halbieren, hat den Wert des Hauses verringert, Don!”\n\n👩\n\n“Verringert!? Weniger Geld?! Oh nein!” 🧑\n\n\n\n11.3.8 Die Zimmerzahl ist negativ mit dem Preis korreliert\n… wenn man die Wohnfläche (Quadratmeter) kontrolliert.\n\n“Ne-Ga-Tiv!”\n\n👩\nHauspreis stratifizieren\nQuellcode"
  },
  {
    "objectID": "kausal.html#kontrollieren-von-variablen",
    "href": "kausal.html#kontrollieren-von-variablen",
    "title": "11  Kausalinferenz",
    "section": "11.4 Kontrollieren von Variablen",
    "text": "11.4 Kontrollieren von Variablen\n💡 Durch das Aufnehmen von Prädiktoren in die multiple Regression werden die Prädiktoren kontrolliert (adjustiert, konditioniert):\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang \\(\\beta\\) des einen Prädiktors mit \\(y\\), wenn man den (oder die) anderen Prädiktoren statistisch konstant hält.\nMan nennt die Koeffizienten einer multiplen Regression daher auch parzielle Regressionskoeffizienten. Manchmal spricht man, eher umgangssprachlich, auch vom “Netto-Effekt” eines Prädiktors, oder davon, dass ein Prädiktor “bereinigt” wurde vom (linearen) Einfluss der anderen Prädiktoren auf \\(y\\).\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Prädiktors \\(x_1\\) auf \\(y\\) anzeigen unabhängig vom Effekt der anderen Prädiktoren, \\(x_2,x_3,...\\) auf \\(y\\)\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Prädiktors \\(x_1\\) wird für jede Ausprägung (Gruppe) des Prädiktors \\(x_2\\) berechnet.\n\n11.4.1 Das Hinzufügen von Prädiktoren kann die Gewichte der übrigen Prädiktoren ändern\n\nAber welche und wie viele Prädiktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\n🧑\n\nLeider kann die Statistik keine Antwort darauf geben.\n\n👩\n\nWozu ist sie dann gut?!\n\n🧑\n\n\n\n\n\n\nWichtig\n\n\n\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erklärung der Ursachen heranzuziehen."
  },
  {
    "objectID": "kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "href": "kausal.html#welches-modell-richtig-ist-kann-die-statistik-nicht-sagen",
    "title": "11  Kausalinferenz",
    "section": "11.5 Welches Modell richtig ist, kann die Statistik nicht sagen",
    "text": "11.5 Welches Modell richtig ist, kann die Statistik nicht sagen\n\nOften people want statistical modeling to do things that statical modeling cannot do. For example, we’d like to know wheter an effect is “real” or rather spurios. Unfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem. Usually answers to lage world questions about truth and causation depend upon information not included in the model. For example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model. But if we cannot think of the right variable, we might never notice. Therefore all statical models are vulnerable to and demand critique, regardless of the precision of their estimates and apparaent accuracy of their predictions. Rounds of model criticism and revision embody the real tests of scientific hypotheses. A true hypothesis will pass and fail many statistical “tests” on its way to acceptance.\n\nMcElreath (2020), S. 139\n\n11.5.1 Kausalmodell für Konfundierung, km1\n\n\n\n\n\nWenn dieses Kausalmodell stimmt, findet man eine Scheinkorrelation zwischen price und bedrooms.\nEine Scheinkorrelation ist ein Zusammenhang, der nicht auf eine kausalen Einfluss beruht.\nd_connected heißt, dass die betreffenden Variablen “verbunden” sind durch einen gerichteten (d wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss fließt 🌊. d_separated heißt, dass sie nicht d_connected sind.\n\n\n11.5.2 m2 kontrolliert die Konfundierungsvariable livingArea\nWenn das Kausalmodell stimmt, dann zeigt m2 den kausalen Effekt von livingArea.\n\nWas tun wir jetzt bloß?! Oh jeh!\n\n🧑\n\nWir müssen die Konfundierungsvariable kontrollieren.\n\n👩\n\n\n\n\n\nDurch das Kontrollieren (“adjustieren”), sind bedrooms und price nicht mehr korreliert, nicht mehr d_connected, sondern jetzt d_separeted.\n\n\n11.5.3 Konfundierer kontrollieren\n\n\n\n\nOhne Kontrollieren der Konfundierungsvariablen\n\nRegressionsmodell: y ~ x\n\n\n\n\n\nEs wird (fälschlich) eine Korrelation zwischen x und y angezeigt: Scheinkorrelation.\nM2. it Kontrollieren der Konfundierungsvariablen\nRegressionsmodell: y ~ x + group\n\n\n\n\n\nEs wird korrekt gezeigt, dass es keine Korrelation zwischen x und y gibt, wenn group kontrolliert wird.\nQuellcode\n\n\n11.5.4 m1 und m2 passen nicht zu den Daten, wenn km1 stimmt\n\n\n\n\n\nLaut km1 dürfte es keine Assoziation (Korrelation) zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Es gibt aber noch eine Assoziation zwischen bedrooms und price geben, wenn man livingArea kontrolliert. Daher sind sowohl m1 und m2 nicht mit dem Kausalmodell km1 vereinbar.\n\n\n11.5.5 Kausalmodell 2, km2\nUnser Modell m2 sagt uns, dass beide Prädiktoren jeweils einen eigenen Beitrag zur Erklärung der AV haben.\nDaher könnte das folgende Kausalmodell, km2 besser passen.\nIn diesem Modell gibt es eine Wirkkette: \\(a \\rightarrow b \\rightarrow p\\).\nInsgesamt gibt es zwei Kausaleinflüsse von a auf p: - \\(a \\rightarrow p\\) - \\(a \\rightarrow b \\rightarrow p\\)\nMan nennt die mittlere Variable einer Wirkkette auch einen Mediator und den Pfad von der UV (a) über den Mediator (b) zur AV (p) auch Mediation.\n\n\n\n\n\n\n\n11.5.6 Schoki macht Nobelpreis! (?)\nEine Studie fand eine starke Korrelation, \\(r=0.79\\) zwischen (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli 2012).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nKorrelation ungleich Kausation!\n\n\n\n\n11.5.7 Kausalmodell für die Schoki-Studie\nDer “Schoki-DAG” in Abbildung 11.5 zeigt den DAG für das Schokoloaden-Nobelpreis-Modell.\n\n\n\n\n\nAbbildung 11.5: Macht Schokolade Nobelpreise?\n\n\n\n\n\n\n11.5.8 Dons Kausalmodell, km3\nSo sieht Dons Kausalmodell aus, s. Abbildung 11.6.\n\n\n\n\n\nAbbildung 11.6: Dons Kausalmodell\n\n\n\n\n\nIch glaube aber an mein Kausalmodell. Mein Kausalmodell ist das größte! Alle anderen Kausalmodelle sind ein Disaster!”\n\n🧑\n\n\n“Don, nach deinem Kausalmodell müssten bedrooms und livingArea unkorreliert sein. Sind sie aber nicht.”\n\nRechne doch selber, die Korrelation aus, Don:\n\n\nCode\nd %>% \n  summarise(cor(bedrooms, livingArea))\n\n\n\n\n\n\ncor(bedrooms, livingArea)\n\n\n\n\n0.6561957\n\n\n\n\n\n\n👩\n\n\n11.5.9 Unabhängigkeiten laut km1\nb: bedrooms, p: price, a area (living area), s. Abbildung 11.7.\n\n\n\n\n\nAbbildung 11.7: ?(caption)\n\n\n\n\n\\(b \\perp \\!\\!\\! \\perp p \\, |\\, a\\): bedrooms sind unabhängig von price, wenn man livingArea kontrolliert.\n⛈️ Passt nicht zu den Daten/zum Modell!\n\n\n11.5.10 Unabhängigkeiten laut km2\nb: bedrooms, p: price, a area (living area)\n\n\n\n\n\nkeine Unabhängigkeiten\n❓ Passt zu den Daten/zum Modell\n\n\n11.5.11 Unabhängigkeiten laut km3\nb: bedrooms, p: price, a area (living area)\n\n\n\n\n\n\\(b \\perp \\!\\!\\! \\perp a\\): bedrooms sind unabhängig von livingArea (a)\n⛈️ Passt nicht zu den Daten/zum Modell!"
  },
  {
    "objectID": "kausal.html#dags-directed-acyclic-graphs",
    "href": "kausal.html#dags-directed-acyclic-graphs",
    "title": "11  Kausalinferenz",
    "section": "11.6 DAGs: Directed Acyclic Graphs",
    "text": "11.6 DAGs: Directed Acyclic Graphs\nWas sind DAGs?\n\nDAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.\nEin Graph besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.\nDAGs sind gerichtet; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).\nDAGs sind azyklisch; die Wirkung eines Knoten darf nicht wieder auf ihn zurückführen.\nEin Pfad ist ein Weg durch den DAG, von Knoten zu Knoten über die Kanten, unabhängig von der Pfeilrichtung.\n\n\n11.6.1 DAG von km1\n\n\n\n\n\n\n\n11.6.2 Leider passen potenziell viele DAGs zu einer Datenlage\nb: bedrooms, p: price, a area (living area)\n\n\n\n\n\n\n\n11.6.3 Was ist eigentlich eine Ursache?\nEtwas verursachen kann man auch (ziemlich hochtrabend) als “Kausation” verwenden.\n\n\n\n\n\n\nHinweis\n\n\n\nWeiß man, was die Wirkung \\(W\\) einer Handlung \\(H\\) (Intervention) ist, so hat man \\(H\\) als Ursache von \\(W\\) erkannt.\n\n\nMcElreath (2020)\n\n\n\n\n\n\n\n\n\nQuelle und Erklärung\n\n\n11.6.4 Fazit\nSind zwei Variablen korreliert (abhängig, assoziiert), so kann es dafür zwei Gründe geben:\n\nKausaler Zusammenhang\nNichtkausaler Zusammenhang (“Scheinkorrelation”)\n\nEine mögliche Ursache einer Scheinkorrelation ist Konfundierung.\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Prädiktor in eine Regression aufnimmt.\nIst die Annahme einer Konfundierung korrekt, so löst sich der Scheinzusammenhang nach dem Adjustieren auf.\nLöst sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenhänge nach Adjustieren um, so spricht man einem Simpson Paradox.\nDie Daten alleine können nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist nötig, um DAGs auszuschließen."
  },
  {
    "objectID": "kausal.html#kollision",
    "href": "kausal.html#kollision",
    "title": "11  Kausalinferenz",
    "section": "11.7 Kollision",
    "text": "11.7 Kollision\n\n11.7.1 Kein Zusammenhang von Intelligenz und Schönheit (?)\nGott ist gerecht (?)\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (talent) und Schönheit (looks), wie Abbildung 11.8 illustriert. Für geringe Intelligenzwerte gibt es eine breites Spektrum von Schönheitswerten und für hohe Intelligenzwerte sieht es genauso aus.\n\n\n\n\n\nAbbildung 11.8: Kein Zusammenhang von Intelligenz und Schönheit in den Daten\n\n\n\n\nGott ist gerecht (?)\n\n\n11.7.2 Aber Ihre Dates sind entweder schlau oder schön\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates), entweder schön sind oder schlau - aber seltens beides gleichzeitig (schade), s. Abbildung 11.9.\n\n\n\n\n\nAbbildung 11.9: Ihre Datingpartner sind komischerweise entweder schlau oder schön (aber nicht beides), zumindest in der Tendenz.\n\n\n\n\nWie kann das sein?"
  },
  {
    "objectID": "kausal.html#dag-zur-rettung",
    "href": "kausal.html#dag-zur-rettung",
    "title": "11  Kausalinferenz",
    "section": "11.8 DAG zur Rettung",
    "text": "11.8 DAG zur Rettung\n🦹 🦸\nDer DAG in Abbildung 11.10 bietet eine rettende Erklärung.\n\n\n\n\n\nAbbildung 11.10: Date als gemeinsame Wirkung von Schönheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Schönheit und Intelligenz.\n\n\n\n\nIn ähnlicher Weise, s. Abbildung 11.11.\n\n\n\n\n\nAbbildung 11.11: Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\n\n\n\n\n\n\n\n\n11.8.1 Was ist eine Kollision?\nAls Kollision (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen). Kontrolliert man die Wirkung m, so entsteht eine Scheinkorrelation zwischen den Ursachen x und y. Kontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. Abbildung 11.10, vgl. Rohrer (2018).\n\n\n\n\n\n\nWichtig\n\n\n\nMan kann also zu viele oder falsche Prädiktoren einer Regression hinzufügen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n\n\n\n\n11.8.2 Einfaches Beispiel zur Kollision\nIn der Zeitung Glitzer werden nur folgende Menschen gezeigt:\n\nSchöne Menschen\nReiche Menschen\n\nehen wir davon aus, dass Schönheit und Reichtum unabhängig voneinander sind.\nWenn ich Ihnen sage, dass Don nicht schön ist, aber in der Glitzer häufig auftaucht, was lernen wir dann über seine finanzielle Situation?1\n\n“Ich bin schön, unglaublich schön, und groß, großartig, tolle Gene!!!” 🧑\n\n\n\n11.8.3 Noch ein einfaches Beispiel zur Kollision\n\n“So langsam check ich’s!”\n\nSei Z = X + Y, wobei X und Y unabhängig sind.\nWenn ich Ihnen sage, X = 3, lernen Sie nichts über Y, da die beiden Variablen unabhängig sind Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\nAlso: X und Y sind abhängig – gegeben Z: \\(X \\not\\perp \\!\\!\\! \\perp Y \\,|\\, Z\\).\n\n\n11.8.4 Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\nAbbildung 11.10 zeigt: Durch Kontrollieren entsteht eine Kollision, eine Scheinkorrelation zwischen den Ursacxhen.\nKontrollieren kann z.B. bedeuten:\n\nStratifizieren: Aufteilen von date in zwei Gruppen und dann Analyse des Zusammenhangs von talent und looks in jeder Teilgruppe von date\nKontrollieren mit Regressioin: Durch Aufnahme von date als Prädiktor in eine Regression zusätzlich zu looks mit talent als Prädikotr\n\nOhne Kontrolle von date entsteht keine Scheinkorrelation zwischen Looks und Talent. Der Pfad (“Fluss”) von Looks über date nach Talent ist blockiert.\nKontrolliert man date, so öffnet sich der Pfad Looks -> date -> talent und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr “blockiert”, die Korrelation kann “fließen” - was sie hier nicht soll, denn es handelt sich um Scheinkorrelation.\nDas Kontrollieren von date geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n\n11.8.5 IQ, Fleiss und Eignung fürs Studium\nSagen wir, über die Eignung für ein Studium würden nur (die individuellen Ausprägungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in Abbildung 11.12.\n\n\n\n\n\nAbbildung 11.12: Kollisionsstruktur im Dag zur Studiumseignung\n\n\n\n\nBei positiver eignung wird ein Studium aufgenommen (studium = 1) ansonsten nicht (studium = 0).\nQuelle\neignung (fürs Studium) sei definiert als die Summe von iq und fleiss, plus etwas Glück:\n\n\nCode\nset.seed(42)  # Reproduzierbarkeit\nN <- 1e03  \n\nd_eignung <-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung > 0, 1, 0) \n  )\n\n\nLaut unserem Modell setzt sich Eignung zur Hälfte aus Intelligenz und zur Hälfte aus Fleiss zusammen, plus etwas Glück.\n\n\n11.8.6 Schlagzeile “Schlauheit macht Studentis faul!”\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Fleiß (f) bei Studentis (s).\nErgebnis: Ein negativer Zusammenhang!?\nBerechnen wir das “Eignungsmodell”, aber nur mit Studis (studium == 1):\n\n\nCode\nm_eignung <-\n  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n\n\n\n\n\n\nParameter\nCI\nCI_low\nCI_high\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n0.7004608\n0.8596029\nfixed\nconditional\n\n\nfleiss\n0.95\n-0.5266816\n-0.3634545\nfixed\nconditional\n\n\n\n\n\n\nAbbildung 11.13 zeigt das Modell und die Daten.\n\n\n\n\n\nAbbildung 11.13: Der Zusammenhang von Fleiss und IQ\n\n\n\n\nIQ ist nicht unabhängig von Fleiß in unseren Daten, sondern abhängig.\nNichtwissenschaftliche Berichte, etwa in einigen Medien, greifen gerne Befunde über Zusammenhänge auf und interpretieren die Zusammenhänge - oft vorschnell - als kausal.2\n\n\n11.8.7 Kollisionsverzerrung nur bei Stratifizierung\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. Abbildung 11.14.\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Stratifizierung tritt keine Scheinkorrelation auf. Mit Stratifizierung tritt Scheinkorrelation auf.\n\n\n\n\n\n\n\nAbbildung 11.14: Stratifizierung und Scheinkorrelation\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie nützen.\nNur Kenntnis des DAGs verrät die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n\n\n\n\nHinweis\n\n\n\nNimmt man eine Variable als zweiten Prädiktor auf, so “kontrolliert” man diese Variable. Das Regressiongewicht des ersten Prädiktors wird “bereinigt” um den Einfluss des zweiten Prädiktors; insofern ist der zweite Prädiktor dann “kontrolliert”.\n\n\n\n\n11.8.8 Einfluss von Großeltern und Eltern auf Kinder\nWir wollen hier den (kausalen) Einfluss der Eltern E und Großeltern G auf den Bildungserfolg der Kinder K untersuchen.\nWir nehmen folgende Effekte an:\n\nindirekter Effekt von G auf K: \\(G \\rightarrow E \\rightarrow K\\)\ndirekter Effekt von E auf K: \\(E \\rightarrow K\\)\ndirekter Effekt von G auf K: \\(G \\rightarrow K\\)\n\nWir sind v.a. interessiert an \\(G \\rightarrow K\\), dem direkten kausalen Effekt von Großeltern auf ihre Enkel, s. Abbildung 11.15, Kurz (2021).\n\n\n\n\n\nAbbildung 11.15: ?(caption)\n\n\n\n\nAber was ist, wenn wir vielleicht eine unbekannte Variable übersehen haben? (S. nächster Abschnitt 👻)"
  },
  {
    "objectID": "kausal.html#vertiefung",
    "href": "kausal.html#vertiefung",
    "title": "11  Kausalinferenz",
    "section": "11.9 Vertiefung",
    "text": "11.9 Vertiefung\n🏎️VERTIEFUNG🏎️\n\n11.9.1 Der Gespenster-DAG\n👻\nEs gibt “unheilbare” DAGs, nennen wir sie “Gespenster-DAGs”, in denen es nicht möglich ist, einen (unverzerrten) Kausaleffekt zu bestimmen, s. Abbildung 11.16. Letztlich sagt uns der DAG bzw. unsere Analyse zum DAG: “Deine Theorie ist nicht gut, zurück an den Schreibtisch und denk noch mal gut nach. Oder sammele mehr Daten.”\n\n\n\n\n\nAbbildung 11.16: Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollständig) möglich.\n\n\n\n\n\nU könnte ein ungemessener Einfluss sein, der auf E und K wirkt, etwa Nachbarschaft.\nDie Großeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\nE ist sowohl für G als auch für U eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\nWenn wir E kontrollieren, wird es den Pfad \\(G \\rightarrow K\\) verzerren, auch wenn wir niemals U messen.\n\nDie Sache ist in diesem Fall chancenlos. Wir müssen diesen DAG verloren geben, McElreath (2020), S. 180."
  },
  {
    "objectID": "kausal.html#die-hintertür-schließen",
    "href": "kausal.html#die-hintertür-schließen",
    "title": "11  Kausalinferenz",
    "section": "11.10 Die Hintertür schließen",
    "text": "11.10 Die Hintertür schließen\n\n11.10.1 Zur Erinnerung: Konfundierung\nForschungsfrage: Wie groß ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\na: livingArea, b: bedrooms, p: prize\nUV: b, AV: p\nDas Kausalmodell ist in Abbildung 11.17 dargestellt.\n\n\n\n\n\nAbbildung 11.17: Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfläche beeinflusst\n\n\n\n\nIm Regressionsmodell p ~ b wird der kausale Effekt verzerrt sein durch die Konfundierung mit a. Der Grund für die Konfundierung sind die zwei Pfade zwischen b und p:\n\n\\(b \\rightarrow p\\)\n\\(b \\rightarrow a \\rightarrow p\\)\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen b und p. Aber nur der erste Pfad ist kausal; der zweite ist nichtkausal. Gäbe es nur nur den zweiten Pfad und wir würden b ändern, so würde sich p nicht ändern.\n\n\n11.10.2 Gute Experimente zeigen den echten kausalen Effekt\nAbbildung 11.18 zeigt eine erfreuliche Situation: Die “Hintertür” zu unserer UV (Zimmerzahl) ist geschlossen!\nIst die Hintertür geschlossen - führen also keine Pfeile in unserer UV - so kann eine Konfundierung ausgeschlossen werden.\n\n\n\n\n\nAbbildung 11.18: Unverzerrte Schätzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Prädiktor im Modell enthalten ist. Da die beiden Prädiktoren unkorreliert sind, hat die Aufnahme des einen Prädiktors keinen Einfluss auf das Regressionsgewicht des anderen.\n\n\n\n\nDie “Hintertür” der UV (b) ist jetzt zu! Der einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen b und p ist jetzt komplett kausal.\nEine berühmte Lösung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment. Wenn wir den Häusern zufällig (randomisiert) eine Anzahl von Schlafzimmern (b) zuweisen könnten (unabhängig von ihrer Quadratmeterzahl, a), würde sich der Graph so ändern. Das Experiment entfernt den Einfluss von a auf b. Wenn wir selber die Werte von b einstellen im Rahmen des Experiments, so kann a keine Wirkung auf b haben. Damit wird der zweite Pfad, \\(b \\rightarrow a \\rightarrow p\\) geschlossen (“blockiert”).\n\n\n11.10.3 Hintertür schließen auch ohne Experimente\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch die Hintertür schließen (backdoor criterion).\nWir wollen die Hintertüre schließen, da wir sonst nicht den wahren, kausalen Effekt bestimmen können.\nZum Glück gibt es neben Experimenten noch andere Wege, die Hintertür zu schließen, wie die Konfundierungsvariable a in eine Regression mit aufzunehmen.\nWarum blockt das Kontrollieren von aden Pfad \\(b \\leftarrow a \\rightarrow p\\)? Stellen Sie sich den Pfad als eigenen Modell vor. Sobald Sie a kennen, bringt Ihnen Kenntnis über b kein zusätzliches Wissen über p. Wissen Sie hingegen nichts über a, lernen Sie bei Kenntnis von b auch etwas über p. Konditionieren ist wie “gegeben, dass Sie a schon kennen…”.\n\\(b \\perp \\!\\!\\! \\perp p \\,|\\,a\\)\n\n\n11.10.4 Die vier Atome der Kausalanalyse\nAbbildung 11.19 stellt die vier “Atome” der Kausalinferenz dar. Mehr gibt es nicht! Kennen Sie diese vier Grundbausteine, so können Sie jedes beliebige Kausalsystem (DAG) entschlüsseln.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 11.19: Die vier Atome der Kausalinferenz\n\n\n\n\n\n\n11.10.5 Mediation\nDie Mediation (Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten gleiche Wirkrichtung haben: \\(x \\rightarrow m \\rightarrow y\\). Anders gesagt: Eine Mediation, auch “Kette” oder “Wirkkette” genannt, ist eine Kausalabfolge der Art \\(x \\rightarrow m \\rightarrow y\\), s. Abbildung 11.20. Die Variable in der Mitte \\(m\\) der Kette wird auch Mediator genannt, weil sei die Wirkung von X auf Y “vermittelt” oder übeträgt. Die Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften, wie der Psychologie.\n\n\n\n\n\nAbbildung 11.20: Das Kausalmodell der Mediation.\n\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation “fließt” den Pfad entlang (in beide Richtungen). Kontrollieren blockt (schließt) die Kette (genau wie bei der Gabel)."
  },
  {
    "objectID": "kausal.html#der-nachfahre",
    "href": "kausal.html#der-nachfahre",
    "title": "11  Kausalinferenz",
    "section": "11.11 Der Nachfahre",
    "text": "11.11 Der Nachfahre\nEin Nachfahre (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. fig-dag-nachfahre. Kontrolliert man einen Nachfahren d, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), m. Der Grund ist, dass d Information beinhaltet über m. Hier wird das Kontrollieren von d den Pfad von x nach y teilweise öffnen, da m eine Kollisionsvariable ist.\n\n\n\n\n\nAbbildung 11.21: Ein Nachfahre verhält sich ähnlich wie sein Vorfahre…\n\n\n\n\n\n11.11.1 Kochrezept zur Analyse von DAGs\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:\n\nListen Sie alle Pfade von UV (X) zu AV (Y) auf.\nBeurteilen Sie jeden Pfad, ob er gerade geschlossen oder geöffnet ist.\nBeurteilen Sie für jeden Pfad, ob er ein Hintertürpfad ist (Hintertürpfade haben einen Pfeil, der zur UV führt).\nWenn es geöffnete Hinterpfade gibt, prüfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schließen (falls möglich)."
  },
  {
    "objectID": "kausal.html#schließen-sie-die-hintertür-wenn-möglich-bsp1",
    "href": "kausal.html#schließen-sie-die-hintertür-wenn-möglich-bsp1",
    "title": "11  Kausalinferenz",
    "section": "11.12 Schließen Sie die Hintertür (wenn möglich)!, bsp1",
    "text": "11.12 Schließen Sie die Hintertür (wenn möglich)!, bsp1\nUV: \\(X\\), AV: \\(Y\\), drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\nAbbildung 11.22: Puh, ein schon recht komplizierter DAG\n\n\n\n\nEs gibt zwei Hintertürpfade in Abbildung 11.22:\n\n\\(X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y\\), offen\n\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\), geschlossen\n\nKontrollieren von \\(A\\) oder (auch) \\(C\\) schließt die offene Hintertür.\nMcElreath (2020), Kurz (2021), s.S. 186.\n\n11.12.1 Schließen Sie die Hintertür (wenn möglich)!, bsp2\nS. DAG in Abbildung 11.23: UV: \\(W\\), AV: \\(D\\)\n\n\n\n\n\nAbbildung 11.23: Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\n\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintertüren zu schließen:\n\nentweder \\(A\\) und \\(M\\)\noder \\(S\\)\n\nMehr Infos\nDetails finden sich bei McElreath (2020) oder Kurz (2021), ‚S. 188.\n\n\n11.12.2 Implizierte bedingte Unabhängigkeiten von bsp2\nEin Graph ohne Us ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme. Auch wenn die Daten nicht sagen können, welcher DAG der richtige ist, können wir zumindest lernen, welcher DAG falsch ist. Die vom Modell implizierten bedingten Unabhängigkeiten geben uns Möglichkeiten, zu prüfen, ob wir einen DAG verwerfen (ausschließen) können. Bedingten Unabhängigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabhängig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\nbsp2 impliziert folgende bedingte Unabhängigkeiten:\n\n## A _||_ W | S\n## D _||_ S | A, M, W\n## M _||_ W | S\n\n\n\n11.12.3 Fazit\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren können, hängt von der epistemologischen Zielrichting der Forschungsfrage ab:\n\nBei deskriptiven Forschungsfragen können die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. “Der Unterschied zwischen beiden Gruppen beträgt etwa …”. Allerdings ist eine kausale Interpretation nicht zulässig.\nBei prognostischen Fragestellungen spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, \\(\\hat{y}_i\\), z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht möglich, aber auch nicht von Interesse.\nBei kausalen Forschungsfragen dürfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n\nModellkoeffizienten ändern sich (oft), wenn man Prädiktoren zum Modell hinzufügt oder wegnimmt. Entgegen der verbreiteten Annahme ist es falsch, möglichst viele Prädiktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist. Kenntnis der “kausalen Atome” ist Voraussetzung zur Ableitung von Kausalschlüsse in Beobachtungsstudien.\n\n\n\n\nKurz, A. Solomon. 2021. Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition. https://bookdown.org/content/4857/.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press.\n\n\nMesserli, Franz H. 2012. „Chocolate Consumption, Cognitive Function, and Nobel Laureates“. New England Journal of Medicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPearl, Judea, Madelyn Glymour, und Nicholas P. Jewell. 2016. Causal inference in statistics: a primer. Chichester, West Sussex: Wiley.\n\n\nRohrer, Julia M. 2018. „Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data“. Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629."
  },
  {
    "objectID": "abschluss.html",
    "href": "abschluss.html",
    "title": "12  Abschluss",
    "section": "",
    "text": "Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\nSie können …\n\nerläutern, wie Sie eine typische, sozialwissenschaftliche Forschungsfrage (quantitativ) untersuchen\ntypische “Lieblingsfehler” benennen und Wege aufzeigen, um die Fehler zu umgehen\nzwischen den Grundkonzepten der Frequentististischen Statistik und der Bayes-Statistik übersetzen\ndie Grundideen der Bayes-Statistik in eine Gesamtzusammenhang einordnen\n\n\n\n\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\n\nCode\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)"
  },
  {
    "objectID": "abschluss.html#lieblinglingsfehler",
    "href": "abschluss.html#lieblinglingsfehler",
    "title": "12  Abschluss",
    "section": "12.2 Lieblinglingsfehler",
    "text": "12.2 Lieblinglingsfehler\nLieblingsfehler im Überblick 🤷:\n\nPost-Präd-Verteilung (PPV) und Post-Verteilung verwechseln\nQuantile und Verteilungsfunktion verwechseln\nPrädiktoren nicht zentrieren, wenn es einen Interaktionsterm gibt\nInteraktion falsch interpretieren\nRegressionskoeffizienten kausal interpretieren, wenn es keine kausale Fundierung gibt"
  },
  {
    "objectID": "abschluss.html#post-präd-verteilung-ppv-und-post-verteilung-verwechseln",
    "href": "abschluss.html#post-präd-verteilung-ppv-und-post-verteilung-verwechseln",
    "title": "12  Abschluss",
    "section": "12.3 Post-Präd-Verteilung (PPV) und Post-Verteilung verwechseln 🤷",
    "text": "12.3 Post-Präd-Verteilung (PPV) und Post-Verteilung verwechseln 🤷\nBerechen wir das Standard-mtcars-Modell: mpg ~ hp.\n\n\nCode\nm1 <- stan_glm(mpg ~ hp, data = mtcars, refresh = 0)\n\n\nDie Post-Verteilung zeigt Stichproben zu den Parameterwerten.\n\n\nCode\npost_verteilung <- m1 %>% \n  as_tibble()\nhead(post_verteilung)\n\n\n\n\n\n\n(Intercept)\nhp\nsigma\n\n\n\n\n27.99734\n-0.0625998\n4.004573\n\n\n28.41831\n-0.0648228\n4.248156\n\n\n32.35498\n-0.0766825\n3.539327\n\n\n26.64150\n-0.0527664\n4.268596\n\n\n27.85701\n-0.0622692\n4.176046\n\n\n28.17933\n-0.0638320\n4.115600\n\n\n\n\n\n\nDie Posterior-Prädiktiv-Verteilung (PPV) zeigt die Vorhersagen, also keine Parameterwerte, sondern Beobachtungen.\n\n\n\n\n\n\nname\nvalue\n\n\n\n\nMazda RX4\n25.65092\n\n\nMazda RX4 Wag\n21.33374\n\n\nDatsun 710\n16.10424\n\n\nHornet 4 Drive\n17.52942\n\n\nHornet Sportabout\n11.22213"
  },
  {
    "objectID": "abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "href": "abschluss.html#quantile-und-verteilungsfuntion-verwechseln",
    "title": "12  Abschluss",
    "section": "12.4 Quantile und Verteilungsfuntion verwechseln 🤷",
    "text": "12.4 Quantile und Verteilungsfuntion verwechseln 🤷\n\n12.4.1 Quantil für \\(p\\)\nEin \\(p\\)-Quantil teilt eine Verteilung in zwei Teile, und zwar so, dass mind. \\(p\\) kleiner oder gleich dem \\(p\\)-Quantil sind.\n\n\n\n\n\nDas 50%-Quantil (.5-Quantil) beträgt \\(x=0\\). Mind ein Anteil \\(1-p\\) ist größer oder gleich dem \\(p\\)-Quantil.\n\n\n12.4.2 Verteilungsfunktion \\(F\\)\n\\(F(x)\\) gibt die Wahrscheinlichkeit an der Stelle \\(x\\) an, dass \\(X\\) einen Wert kleiner oder gleich \\(x\\) annimmt.\n\n\n\n\n\n\\(F(0)=1/2\\), die Wahrscheinlichkeit beträgt hier 50%, dass \\(x\\) nicht größer ist als 0."
  },
  {
    "objectID": "abschluss.html#interaktion-falsch-interpretieren",
    "href": "abschluss.html#interaktion-falsch-interpretieren",
    "title": "12  Abschluss",
    "section": "12.5 Interaktion falsch interpretieren 🤷",
    "text": "12.5 Interaktion falsch interpretieren 🤷\nBerechnen wir ein einfaches Interaktionsmodell: mpg ~ hp*vs.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: mpg ~ hp*vs ist synonym zu (aber kürzer als) mpg ~ hp + vs + hp:vs.\n\n\n\n\nCode\nm2 <- stan_glm(mpg ~ hp*vs, data = mtcars)  # mit Interaktionseffekt\n\n\nModellkoeffizienten:\n\n\nCode\nparameters(m2)\n\n\n\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n24.64\n(18.96, 30.09)\n100%\n1.001\n2384.00\nNormal (20.09 +- 15.07)\n\n\nhp\n-0.04\n(-0.07, -0.01)\n99.75%\n1.001\n2367.00\nNormal (0.00 +- 0.22)\n\n\nvs\n13.98\n(4.80, 23.02)\n99.90%\n1.000\n1654.00\nNormal (0.00 +- 29.89)\n\n\nhp:vs\n-0.11\n(-0.19, -0.03)\n99.50%\n1.000\n1781.00\nNormal (0.00 +- 0.31)\n\n\n\n\n\n\n\nCode\nplot(parameters(m2))\n\n\n\n\n\nFalsch 😈 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11.\nRichtig 👼 Der Unterschied im Verbrauch zwischen den beiden Gruppen vs=0 und vs=1 beträgt ca. -0.11 – wenn hp=0.\nDa hp=0 kein realistischer Wert ist, ist das Modell schwer zu interpretieren. Zentrierte Prädiktoren wären hier eine sinnvolle Lösung.\nGelman, Hill, und Vehtari (2021),Kap. 10, McElreath (2020), Kap. 8"
  },
  {
    "objectID": "abschluss.html#kochrezepte",
    "href": "abschluss.html#kochrezepte",
    "title": "12  Abschluss",
    "section": "12.6 Kochrezepte 🍲",
    "text": "12.6 Kochrezepte 🍲\n\n12.6.1 Kochrezept: Forschungsfrage untersuchen\nTheoretische Phase 1. Staunen über ein Phänomen, \\(y\\), Kausalfrage finden 2. Literatur wälzen, um mögliche Ursachen \\(x\\) von \\(y\\) zu lernen 3. Forschungsfrage, Hypothese präzisieren 4. Modell präzisieren (DAG(s), Prioris)\nEmpirische Phase\n\nVersuch planen\nDaten erheben\n\nAnalytische Phase\n\nDaten aufbereiten\nModell berechnen anhand eines oder mehrerer DAGs\nModell prüfen/kritisieren\nForschungsfrage beantworten\n\nYeah! Fertig.\n\n\n12.6.2 Parameter schätzen vs. Hypothesen prüfen\nQuantitative Studien haben oft einen von zwei (formalen) Zielen: Hypothesen testen oder Parameter schätzen. Beispiel Hypothesenprüfung: “Frauen parken im Durchschnitt schneller ein als Männer”. Beispiel Parameterschätzung: “Wie groß ist der mittlere Unterschied in der Ausparkzeit zwischen Frauen und Männern?”\nJe ausgereifter ein Forschungsfeld, desto kühnere Hypothesen lassen sich formulieren: - stark ausgereift: - Die nächste totale Sonnenfinsternis in Deutschland wird am 27.7.2082 um 14.47h stattfinden, Quelle - gering ausgereift: - Die nächste Sonnenfinsternis wird in den nächsten 100 Jahren stattfinden. - Lernen bringt mehr als Nicht-Lernen für den Klausurerfolg. Kühne Hypothesen sind wünschenswert 🦹\n\n\n12.6.3 Formalisierung von Forschungsfragen\nDer Mittelwert in Gruppe A ist höher als in Gruppe B (der Unterschied, \\(d\\), im Mittelwert ist größer als Null):\n\\[\\mu_1 > \\mu_2 \\Leftrightarrow \\mu_1 - \\mu_2 > 0 \\Leftrightarrow \\mu_d > 0\\]"
  },
  {
    "objectID": "abschluss.html#kerngedanken-bayes",
    "href": "abschluss.html#kerngedanken-bayes",
    "title": "12  Abschluss",
    "section": "12.7 Kerngedanken Bayes",
    "text": "12.7 Kerngedanken Bayes\n\n12.7.1 Zentraler Kennwert der Bayes-Statistik: Post-Verteilung\nBerechnen wir wieder ein einfaches1 Modell: mpg ~ hp.\n\n\nCode\nm3 <- stan_glm(mpg ~ hp, data = mtcars)\n\n\nUnd schauen wir uns die Post-Verteilung an, mit eingezeichnetem HDI:\n\n\n\n\n\nEin Zusammenfassen der Posterior-Verteilung (z.B. zu einem 95%-PI) ist möglich und oft sinnvoll. Verschiedene Arten des Zusammenfassens der Post-Verteilung sind möglich, z.B. zu Mittelwert oder SD oder einem einem HD-Intervall. Allerdings übermittelt nur die gesamte Post-Verteilung alle Informationen. Daher empfiehlt es sich (oft), die Post-Verteilung zu visualisieren.\n\n\n12.7.2 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]"
  },
  {
    "objectID": "abschluss.html#beispiele-für-prüfungsaufgaben",
    "href": "abschluss.html#beispiele-für-prüfungsaufgaben",
    "title": "12  Abschluss",
    "section": "12.8 Beispiele für Prüfungsaufgaben",
    "text": "12.8 Beispiele für Prüfungsaufgaben\n\n12.8.1 Geben Sie den korrekten Begriff an!\n🌬🚙🙋️👨⬅️Hans 👧⬅️Anna 👩⬅️Lise\nPuh, wie erstelle ich für alle Studis ein anderes Rätsel2?\n\n\n\n\n\n\nHinweis\n\n\n\nIn einer Open-Book-Prüfung bekommen alle Studentis eine eigene, jeweils andere Prüfung. Teamarbeit bleibt natürlich trotzdem untersagt.\n\n\n\n\n12.8.2 DAG mit doppelter Konfundierung\n\n\n\n\n\n❓Geben Sie die minimale Adjustierungsmenge (minimal adjustment set) an, um den totalen (gesamten) Effekt von E auf D zu bestimmen!\n❗ Entweder ist die Menge {A,Z} zu adjustieren oder die Menge {B,Z}.\n\n\n12.8.3 DAG mit vielen Variablen\n\n\n\n\n\nMinimale Adjustierungsmenge, um den Effekt von E auf D zu identifizieren: {7}, {8}.\n\n\n12.8.4 Ein Kausalmodell der Schizophrenie, van Kampen (2014)\nThe SSQ model of schizophrenic prodromal unfolding revised:\nAn analysis of its causal chains based on the language of directed graphs\nD. van Kampen\nLesen Sie hier den Abstract.\nFolgende Symptome der Schizophrenie wurden gemessen:\nSocial Anxiety (SAN), Active Isolation (AIS), Affective Flattening (AFF), Suspiciousness (SUS), Egocentrism (EGC), Living in a Fantasy World (FTW), Alienation (ALN), Apathy (APA), Hostility (HOS), Cognitive Derailment (CDR), Perceptual Aberrations (PER), and Delusional Thinking (DET)\nKampen (2014)\nUV: SUS, AV: EGC\nBerechnen Sie die minimale Adjustierungsmenge, um den kausalen Effekt der UV auf die AV zu identifizieren!\n\n\n12.8.5 DAG von van Kampen (2014) zu den Symptomen der Schizophrenie\n\n\n\n\n\nMinimales Adjustment-Set für den totalen Kausaleffekt: {AIS, ALN}\n\n\n12.8.6 Modelle berechnen\nStellen Sie sich auf Aufgaben ein, in denen Sie Modellparameter berechnen sollen. Orientieren Sie sich an den Aufgaben und Inhalten des Unterrichts.\nPrüfungsfragen zu Modellen könnten z.B. sein:\n\nGeben Sie den Punktschätzer (Median) für den Prädiktor X im Modell Y an!\nGeben Sie ein 89%-HDI für den Parameter X im Modell Y an!\nGeben Sie R-Quadrat an.\nFormulieren Sie ein Interaktionsmodell!\nWelches Modell ist korrekt, um den kausalen Effekt zu modellieren?\nFormulieren Sie ein Modell mit folgenden Prioris …\nLiegt der Effekt X noch im ROPE ?\nUnterscheidet sich die Breite des CI von der Breite des HDI für den Prädiktor X im Modell Y?\nWas verändert sich an den Parametern, wenn Sie die Prädiktoren zentrieren/z-standardisieren?\n…"
  },
  {
    "objectID": "abschluss.html#viel-erfolg-bei-der-prüfung",
    "href": "abschluss.html#viel-erfolg-bei-der-prüfung",
    "title": "12  Abschluss",
    "section": "12.9 Viel Erfolg bei der Prüfung!",
    "text": "12.9 Viel Erfolg bei der Prüfung!\n🥳🏆\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nKampen, D. van. 2014. „The SSQ Model of Schizophrenic Prodromal Unfolding Revised: An Analysis of Its Causal Chains Based on the Language of Directed Graphs“. European Psychiatry 29 (7): 437–48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: a Bayesian course with examples in R and Stan. 2. Aufl. CRC texts in statistical science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bourier, Günther. 2018. Wahrscheinlichkeitsrechnung Und Schließende\nStatistik: Praxisorientierte Einführung: Mit Aufgaben Und Lösungen.\n9., aktualisierte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer\nGabler. https://doi.org/10.1007/978-3-658-07481-4.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik –\nWahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Routledge. http://dx.doi.org/10.4324/9780203771587.\n\n\nDai, Hengchen, Silvia Saccardo, Maria A. Han, Lily Roh, Naveen Raja,\nSitaram Vangala, Hardikkumar Modi, Shital Pandya, Michael Sloyan, and\nDaniel M. Croymans. 2021. “Behavioural Nudges Increase\nCOVID-19 Vaccinations.” Nature 597 (7876):\n404–9. https://doi.org/10.1038/s41586-021-03843-2.\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019.\n“R-Squared for Bayesian Regression Models.” The\nAmerican Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nGoodrich, Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2022.\n“Rstanarm: Bayesian Applied Regression Modeling via\nStan.” https://mc-stan.org/rstanarm/.\n\n\nKampen, D. van. 2014. “The SSQ Model of Schizophrenic\nProdromal Unfolding Revised: An Analysis of Its Causal Chains Based on\nthe Language of Directed Graphs.” European Psychiatry 29\n(7): 437–48. https://doi.org/10.1016/j.eurpsy.2013.11.001.\n\n\nKruschke, John K. 2018. “Rejecting or Accepting Parameter Values\nin Bayesian Estimation.” Advances in Methods and Practices in\nPsychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel Lüdecke. 2019. “Indices of Effect Existence and\nSignificance in the Bayesian Framework.” Frontiers in\nPsychology 10: 2767. https://doi.org/10.3389/fpsyg.2019.02767.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. 2nd ed. CRC Texts in\nStatistical Science. Boca Raton: Taylor; Francis, CRC\nPress.\n\n\nMesserli, Franz H. 2012. “Chocolate Consumption, Cognitive\nFunction, and Nobel Laureates.” New England Journal of\nMedicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nNasreen, Sharifa, Hannah Chung, Siyi He, Kevin A. Brown, Jonathan B.\nGubbay, Sarah A. Buchan, Deshayne B. Fell, et al. 2021.\n“Effectiveness of mRNA and\nChAdOx1 COVID-19 Vaccines Against Symptomatic\nSARS-CoV-2 Infection and Severe Outcomes with\nVariants of Concern in Ontario.” https://doi.org/10.1101/2021.06.28.21259420.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester, West Sussex: Wiley.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html.\n\n\nPormohammad, Ali, Mohammad Zarei, Saied Ghorbani, Mehdi Mohammadi,\nMohammad Hossein Razizadeh, Diana L. Turner, and Raymond J. Turner.\n2021. “Efficacy and Safety of COVID-19 Vaccines: A\nSystematic Review and Meta-Analysis of Randomized Clinical\nTrials.” Vaccines 9 (5): 467. https://doi.org/10.3390/vaccines9050467.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational Data.”\nAdvances in Methods and Practices in Psychological Science 1\n(1): 27–42. https://doi.org/10.1177/2515245917745629.\n\n\nThompson, Mark G., Edward Stenehjem, Shaun Grannis, Sarah W. Ball,\nAllison L. Naleway, Toan C. Ong, Malini B. DeSilva, et al. 2021.\n“Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient\nCare Settings.” New England Journal of Medicine 385\n(15): 1355–71. https://doi.org/10.1056/NEJMoa2110362."
  }
]