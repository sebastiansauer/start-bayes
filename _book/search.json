[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start:Bayes!",
    "section": "",
    "text": "Bayes:Start!\n\n\n\n🚧WORK IN PROGRESS🚧\n\n\n\nNach diesem Kurs sollten Sie …\n\ngrundlegende Konzepte der Inferenzstatistik mit Bayes verstehen und mit R anwenden können\ngängige einschlägige Forschungsfragen in statistische Modelle übersetzen und mit R auswerten können\nkausale Forschungsfragen in statistische Modelle übersetzen und prüfen können\ndie Güte und Grenze von statistischen Modellen einschätzen können\n\n\n\n\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, möglichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse\n\n\n\n\n\nInstallieren Sie R und seine Freunde.\nInstallieren Sie die folgende R-Pakete:\n\ntidyverse\nrstanarm\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\n\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.\n\n\n\n\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen während des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeiträgen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      Nr\n      Thema\n      Datum\n      Kommentar\n    \n  \n  \n    1\nWas ist Inferenz?\n3. - 7. Okt. 2022\nDie erste Unterrichtsstunde fällt auf den 7. Okt. 2023.\n    2\nWahrscheinlichkeit\n10. - 14. Okt. 22\nNA\n    3\nHallo, Bayes\n17. - 21. Okt. 22\nNA\n    4\nDie Post befragen\n24. - 28. Okt. 22\nNA\n    5\nGauss-Modelle\n31. Okt. - 4. Nov. 22\nNA\n    6\nLineare Modelle\n7. - 11. Nov. 22\nNA\n    NA\nBLOCKWOCKE\n14. - 18. Nov. 22\nKein regulärer Unterricht\n    7\nMetrische AV\n21. - 25. Nov. 22\nNA\n    8\nFallstudien\n28. Nov. - 2. Dez. 22\nNA\n    9\nKausalinferenz 1\n5. Dez. - 9. Dez. 22\nNA\n    10\nKausalinferenz 2\n12. - 16. Dez. 22\nNA\n    11\nBinäre AV\n19. - 23. Dez. 22\nNA\n    NA\nWEIHNACHTSFERIEN\nNA\nKein Unterricht\n    12\nAbschluss\n9. Jan. 23 - 13. Jan. 23\nNA\n  \n  \n  \n\n\n\n\n\n\n\nPro Thema wird Literatur ausgewiesen.\n\n\n\nDieses Dokument wurde erzeut am/um 2022-09-08 00:00:41.\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2022-09-08\n pandoc   2.19.2 @ /usr/local/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.2.0)\n cli           3.3.0      2022-04-25 [1] CRAN (R 4.2.0)\n colorout    * 1.2-2      2022-06-13 [1] local\n colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.29     2021-12-01 [1] CRAN (R 4.2.0)\n dplyr         1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.16       2022-08-09 [1] CRAN (R 4.2.0)\n fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n ggplot2       3.3.6.9000 2022-09-05 [1] Github (tidyverse/ggplot2@a58b48c)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n gt            0.7.0      2022-08-25 [1] CRAN (R 4.2.0)\n gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n htmltools     0.5.3      2022-07-18 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4      2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.0      2022-02-22 [1] CRAN (R 4.2.0)\n knitr         1.40       2022-08-24 [1] CRAN (R 4.2.0)\n lifecycle     1.0.2      2022-09-05 [1] Github (r-lib/lifecycle@f92faf7)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n purrr         0.3.4      2020-04-17 [1] CRAN (R 4.2.0)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n readxl        1.4.1      2022-08-17 [1] CRAN (R 4.2.0)\n rlang         1.0.5      2022-08-31 [1] CRAN (R 4.2.0)\n rmarkdown     2.16       2022-08-24 [1] CRAN (R 4.2.0)\n rstudioapi    0.14       2022-08-22 [1] CRAN (R 4.2.0)\n sass          0.4.2      2022-07-16 [1] CRAN (R 4.2.0)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8      2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.4.1      2022-08-20 [1] CRAN (R 4.2.0)\n tibble        3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n tidyselect    1.1.2      2022-02-21 [1] CRAN (R 4.2.0)\n utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n vctrs         0.4.1      2022-04-13 [1] CRAN (R 4.2.0)\n xfun          0.32       2022-08-10 [1] CRAN (R 4.2.0)\n yaml          2.3.5      2022-02-21 [1] CRAN (R 4.2.0)\n\n [1] /Users/sebastiansaueruser/Rlibs\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "Pruefung.html",
    "href": "Pruefung.html",
    "title": "1  Prüfung",
    "section": "",
    "text": "Die Prüfungsleistung besteht aus einer Open-Book-Prüfung."
  },
  {
    "objectID": "Pruefung.html#grundsätzlichkeit",
    "href": "Pruefung.html#grundsätzlichkeit",
    "title": "1  Prüfung",
    "section": "1.2 Grundsätzlichkeit",
    "text": "1.2 Grundsätzlichkeit\nDie folgenden Hinweise gelten grundsätzlich, d.h. soweit nicht anders in der jeweiligen Prüfung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von Prüfungshinweisen kann zu Punkteabzug oder Nichtbestehen führen."
  },
  {
    "objectID": "Pruefung.html#wiederholungsprüfungen",
    "href": "Pruefung.html#wiederholungsprüfungen",
    "title": "1  Prüfung",
    "section": "1.3 Wiederholungsprüfungen",
    "text": "1.3 Wiederholungsprüfungen\n\nWenn Sie bei einer Prüfung durchgefallen sein sollten, so haben Sie grundsätzlich die Möglichkeit, die Prüfung zu wiederholen.\nDenken Sie daran, sich rechtzeitig für Prüfungsleistungen anzumelden; beachten Sie die Fristen.\nDie Termine für die Wiederholungsprüfungen werden stets zusammen/zeitgleich mit denen der regulären Prüfungen in Primuss bekannt gegeben.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine Wiederholungsprüfung nur für Studentis, die durchgefallen sind. Abweichend davon kann ei Dozenti die Prüfung für alle Studentis anbieten. Die Entscheidung, ob eine Wiederholungsprüfung in diesem Fall angeboten wird, obliegt der Dozentin bzw. dem Dozenten des Moduls.\nRelevanter Stoff und formale Bedingungen (wie Prüfungsform) sind grundsätzlich identisch zur letzten abgehaltenen Prüfung des Moduls (d.h. sofern nicht anders angegeben). Daher sind Wiederholungsprüfungen vom Anspruch vergleichbar wie die reguläre Klausur. Die Prüfungen sollen möglichst gleich vom Anspruch sein, um Fairness zu gewährleisten.\nBeachten Sie immer die Hinweise, die für die Wiederholungsprüfung angegeben sind. Im Einzelfall keine eine Wiederholungsprüfung von der vorherigen Prüfung stärker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen Wiederholungsprüfung veröffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine Wiederholungsprüfung. Stattdessen können Sie ggf. an der regulären Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist möglich, dass der Stoff sich dann substanziell ändert; meist halten sich die Änderungen (im Stoff) aber in Rahmen.\nSprechen Sie die Moduldozentis an für Details zur Prüfung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine Prüfung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben, es kommt auf den Einzelfall an. Grundsätzlich rate ich aber dazu, Prüfungen nicht zu verschieben: Schließlich könnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum Prüfungsrecht sprechen Sie bitte die Studienberatung an."
  },
  {
    "objectID": "Pruefung.html#bearbeitungshinweise",
    "href": "Pruefung.html#bearbeitungshinweise",
    "title": "1  Prüfung",
    "section": "1.4 Bearbeitungshinweise",
    "text": "1.4 Bearbeitungshinweise\n\nVerwenden Sie Standardwerte (defaults) der R-Funktionen.\nRunden Sie ggf. auf eine Dezimalstelle.\nVerwenden Sie Methoden der Bayes-Statistik für inferenzstatistische Analysen.\nGeben Sie keine Prozentzahlen an, sondern Anteile (also nicht “50%”, sondern “0.5” bzw. “0,5”).\nFindet sich in einer Auswahlliste möglicher Antworten nicht die exakte Lösung, wählen Sie die am besten passende.\nTreffen Sie Annahmen, wo nötig.\nDie Prüfung besteht zu einem großen Teil aus Multiple-Choice- (MC-)-Aufgaben mit mehreren Antwortoptionen.\nBei Multiple-Choice-Aufgaben (MC-Aufgaben) ist zumeist genau eine Antwortoption auszuwählen aus vier oder fünf Antwortoptionen.\nIm Zweifel ist eine Aussage auf den Stoff, so wie im Unterricht behandelt, zu beziehen.\nBei Fragen zu R-Syntax spielen Aspekte wie Enter-Taste o.Ä. bei der Beantwortung der Frage keine Rolle; diese Aspekte dürfen zu ignorieren.\nJede Aussage einer MC-Aufgabe ist entweder richtig oder falsch (aber nicht beides oder keines).\nDie MC-Aufgaben sind nur mit Kreuzen zu beantworten; Text wird bei der Korrektur nicht berücksichtigt.\nJede Aussage gilt ceteris paribus (unter sonst gleichen Umständen). Aussagen der Art „A ist B“ (z.B. “Menschen sind sterblich”) sind nur dann als richtig auszuwählen, wenn die Aussage immer richtig ist.\nBei Aufgaben, die eine Zahl als Antwort verlangen, ist nur eine Zahl anzugeben (nicht etwa Buchstaben).\nFalls Sie bei einer Aufgabe mehrere Antworten finden, aber nur nach einer gefragt ist, geben Sie nur eine an.\nFalls mehrere (widersprüchliche) Antworten gegeben wurden, wird im Zweifel die erst genannte gewertet.\nDie Aufgabenstellung in einer Moodle-Prüfung wird erst sichtbar, wenn Sie den Prüfungsbedingungen zugestimmt haben und die Prüfungszeit begonnen hat.\nJe nach Spracheinstellung in Moodle kann es sein, dass Sie als Dezimaltrennzeichen ein Komma oder einen Punkt verwenden müssen. Moodle weist Sie, wenn Sie die Aufgabe verlassen, darauf hin, falls eine Zahl nicht als Zahl erkannt wurde."
  },
  {
    "objectID": "Pruefung.html#teilnahmebedingungen",
    "href": "Pruefung.html#teilnahmebedingungen",
    "title": "1  Prüfung",
    "section": "1.5 Teilnahmebedingungen",
    "text": "1.5 Teilnahmebedingungen\n\nDie Prüfung ist selbständig, also alleine nur durch Sie, ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der Prüfung sind einzuhalten.\nEs dürfen nur die explizit als zulässig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulässigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, Bücher sowie Quellen aus dem Internet.\nDie Übernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wörtliche Übernahme (“copy-paste”) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulässig.\nBei technischen Problemen ist sofort der Prüfer bzw. die Prüferin zu verständigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die Prüfung bzw. Teile daraus (z.B. Prüfungsfragen) zu speichern oder weiterzugeben.\nIm Übrigen gelten die allgemeinen Prüfungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht Prüflingen, kommuniziert werden während der Prüfung. Dies gilt auch für den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den Prüfer, wenn Sie meinen, es liege ein technisches Problem vor.\nDas Nichtbeachten der Regeln kann zu Notenabzug oder Nichtbestehen führen."
  },
  {
    "objectID": "Pruefung.html#organisatorische-hinweise",
    "href": "Pruefung.html#organisatorische-hinweise",
    "title": "1  Prüfung",
    "section": "1.6 Organisatorische Hinweise",
    "text": "1.6 Organisatorische Hinweise\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prüfungsrelevant.\nIm Übrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung für formale oder rechtliche Fragen.\nWährend der Prüfung werden nur Fragen beantwortet, die für die Bearbeitung zwingend nötig sind (etwa bei technischen Problemen).\nEs werden keine Fragen der Art “Ist diese Aufgabe klar formuliert?” beantwortet während der Prüfung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der Prüfung=. Der Prüfer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der Prüfung ist nur möglich, wenn Sie den Teilnahmebedingungen der Prüfung zustimmen.\nDie Aufgabenstellung der Prüfung wird nur während des Prüfungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppenteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte Prüfungsuhrzeit (Beginn, Ende).\nPrüfungszeitraum, Aufgabenstellung und sonstige Materialien können variieren zwischen den Prüflingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusätzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der Prüfung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor erhöht."
  },
  {
    "objectID": "Pruefung.html#open-book-prüfungen",
    "href": "Pruefung.html#open-book-prüfungen",
    "title": "1  Prüfung",
    "section": "1.7 Open-Book-Prüfungen",
    "text": "1.7 Open-Book-Prüfungen\nEinige Prüfungen werden als “Take-home-Prüfung” im “Open-Book-Format” geschrieben. Was bedeutet dies?\n“Take-home-Prüfung”: Sie bearbeiten die Prüfung in Ihrem privaten Umgebung in Moodle oder in Räumlichkeiten der Hochschule. Eine Überwachung per Kamera findet nicht statt.\n“Open-Book-Prüfung”: Sie dürfen Hilfsmittel wie Bücher und Folien während der Prüfung nutzen.\nIhre Prüferin/Ihr Prüfer informiert Sie über das Format Ihrer Prüfung."
  },
  {
    "objectID": "Pruefung.html#zeitrahmen-der-prüfung",
    "href": "Pruefung.html#zeitrahmen-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.8 Zeitrahmen der Prüfung",
    "text": "1.8 Zeitrahmen der Prüfung\nDie Prüfung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die Prüfung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). Verspätete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der Prüfung wird Ihnen von Ihrer Prüferin bzw. Ihrem Prüfer bekannt gegeben."
  },
  {
    "objectID": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prüfung",
    "href": "Pruefung.html#technische-und-organisatorische-anforderungen-einer-open-book-prüfung",
    "title": "1  Prüfung",
    "section": "1.9 Technische und organisatorische Anforderungen einer Open-Book-Prüfung",
    "text": "1.9 Technische und organisatorische Anforderungen einer Open-Book-Prüfung\nUm an einer Open-Book-Prüfung teilzunehmen, benötigen Sie IT-Ausstattung sowie Räumlichkeiten. An IT-Ausstattung benötigen Sie einen Computer mit Internetanschluss; ein Smartphone reicht nicht aus. Nutzen Sie Ihr eigenes Gerät (Computer) für die Prüfung; die Hochschule stellt Ihnen keinen Computer zur Verfügung. Sie benötigen keine Webcam und kein Mikrofon. Ein Tablett oder Smartphone reicht nicht für die Prüfung. An Software benötigen Sie Zugang zu Ihrem Moodle-Konto, was einen aktuellen Internet-Browser voraussetzt. Zu den organisatorischen Anforderungen gehören ein Raum, in dem Sie die Prüfung ungestört bearbeiten können sowie ein Internetanschluss zum Bearbeiten der Klausur in Moodle. Bitte benutzen Sie während der Prüfung nicht den Zurück-Button in Ihrem Browser, wenn Sie zu einer vorherigen Frage zurückgehen wollen. Nutzen Sie die in der Prüfung zur Verfügung gestellten Funktionen/Buttons dafür."
  },
  {
    "objectID": "Pruefung.html#technische-probleme-während-der-prüfung",
    "href": "Pruefung.html#technische-probleme-während-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.10 Technische Probleme während der Prüfung",
    "text": "1.10 Technische Probleme während der Prüfung\nIm Falle eines technischen Problems auf Seiten der Prüfungsinfrastruktur ist sofort der Prüfer zu informieren. Ein Beispiel für so ein Problem wäre etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der Prüfer bzw. die Hochschule keine Gewähr übernimmt für Probleme mit Ihrer eigenen Ausstattung."
  },
  {
    "objectID": "Pruefung.html#prüfungsrecht",
    "href": "Pruefung.html#prüfungsrecht",
    "title": "1  Prüfung",
    "section": "1.11 Prüfungsrecht",
    "text": "1.11 Prüfungsrecht\nFür die Open-Book-Prüfungg gilt die aktuelle Prüfungsordnung; die Open-Book-Prüfung fällt nicht unter die BayFEV."
  },
  {
    "objectID": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "href": "Pruefung.html#bitte-formulieren-sie-beanstandungen-nachvollziehbar",
    "title": "1  Prüfung",
    "section": "1.12 Bitte formulieren Sie Beanstandungen nachvollziehbar",
    "text": "1.12 Bitte formulieren Sie Beanstandungen nachvollziehbar\nFalls Sie einen Fehler in einer Aufgabenstellung finden (die der Prüfer zu bestanden hat): Freuen Sie sich! In diesem Fall wird zu Ihren Gunsten entschieden.\nDamit ich Ihre Beanstandung prüfen kann, ist es nötig, dass ich Ihre Beanstandung nachprüfen kann: Zeigen Sie mir meinen Fehler. Es reicht nicht zu sagen “es hat bei mir nicht funktioniert”. Wenn Sie etwa der Meinung sind, dass es die Variable “year” im Datensatz “penguins” nicht gebe, dann schicken Sie mir den R-Code, der an ansprechender Stelle einen Fehler aufwirft (aber ansonsten lauffähig ist). Ein Screenshot kann in einigen Situationen helfen, wenn aber nur ein Teil der Syntax zu sehen ist, ist er nicht ausreichend: Wenn der Befehl data(penguins) nicht funktioniert, so ist zu prüfen, ob Sie vorab mit library(palmerpenguins) das relevante Paket gestartet haben. Andernfalls kann data(penguins) nicht funktionieren und der Fehler läge damit bei Ihnen.\nHier finden Sie Hinweise für einfache, reproduzierbare Beispiele (ERBies); vgl. Sauer (2019), Kap. 3.8.2 (S. 33).\nDie gleiche Messlatte lege ich an mich an: Ich stelle eine Musterlösung (bei der Einsichtnahme) zur Verfügung, die reproduzierbar die Lösung aufzeigt. Sprich: Wenn der R-Code bei mir durchläuft, so wird er auch bei Ihnen durchlaufen."
  },
  {
    "objectID": "Pruefung.html#datenschutz",
    "href": "Pruefung.html#datenschutz",
    "title": "1  Prüfung",
    "section": "1.13 Datenschutz",
    "text": "1.13 Datenschutz\nPersönliche Daten werden an eine Stellen übermittelt: Moodle (über bzw. in Ihre Konto). Es findet keine Überwachung statt, weder kamaragestützt, akustisch oder softwaregestützt."
  },
  {
    "objectID": "Pruefung.html#plagiatskontrolle",
    "href": "Pruefung.html#plagiatskontrolle",
    "title": "1  Prüfung",
    "section": "1.14 Plagiatskontrolle",
    "text": "1.14 Plagiatskontrolle\nIhre Prüfungsarbeiten können auf Plagiate hin untersucht werden. Dabei kommen auch automatisierte Verfahren zum Einsatz. Ihre Arbeiten werden dabei nicht online gestellt und auch nicht Dritten zugänglich gemacht. Alle Prüfungen finden auf Rechnern statt, zu denen nur die Prüfer/innen Zugang habe. Es werden keine persönlichen Daten (von Ihnen) weitergegeben.\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Überlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getäuscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafür bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit “nicht bestanden” bewertet). Die genauen Konsequenzen legt die Prüfungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire Prüfung heißt: Gleiche Chancen für alle, und gute Leistung soll belohnt werden, Täuschung nicht."
  },
  {
    "objectID": "Pruefung.html#typische-fehler-in-der-prüfung",
    "href": "Pruefung.html#typische-fehler-in-der-prüfung",
    "title": "1  Prüfung",
    "section": "1.15 Typische Fehler in der Prüfung",
    "text": "1.15 Typische Fehler in der Prüfung\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heißt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heißt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter “Environment” angezeigt wird. Außerdem können Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort können Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das Paket gestartet zu haben: Mit data(datensatz) können Sie den Datensatz datensatz nur dann verfügbar machen, wenn das Paket, in dem datensatz “wohnt”, mit library(paketname) gestartet worden ist. So “wohnt” z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Übung (und weitere Erklärung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins."
  },
  {
    "objectID": "Pruefung.html#hinweise-zu-scheinmängeln",
    "href": "Pruefung.html#hinweise-zu-scheinmängeln",
    "title": "1  Prüfung",
    "section": "1.16 Hinweise zu Scheinmängeln",
    "text": "1.16 Hinweise zu Scheinmängeln\nImmer wieder kommt es vor, dass Studierende Beanstandungen zu einer Prüfung vorbringen. Teilweise sind diese gerechtfertigt, teilweise nicht. Im Folgenden sehen Sie eine Auswahl an nicht gerechtfertigten Beanstandungen, also nur scheinbaren Mängeln, keine wirklichen Mängel, in einer Prüfung.\n\n“Das zu wählende Vorgehen war nicht 100% klar” – Wenn Sie der Meinung sind, dass das zu wählende Vorgehen (zum Lösen der Aufgabe) nicht komplett klar ist, treffen Sie Annahmen und weisen Sie darauf hin, dass Sie Annahmen getroffen haben. Zum anderen halten Sie sich an das Vorgehen aus dem Unterricht (bzw. den Unterlagen und der Literatur, die im Unterricht verwendet wurde). Eine andere Situation läge vor, wenn die Aufgabe nicht lösbar ist ohne weitere Angaben lösbar ist(“Ist ein Effekt bei n=100 signifikant?”). Im Falle einer nicht lösbaren Aufgabe liegt fer Fehler beim Prüfer.\n“Ich sollte einen Punkt (ein Komma) als Dezimaltrennzeichen verwenden, aber Moodle hat ein Komma (einen Punkt) verlangt!” – Je nach Spracheinstellung in Moodle kann es sein, dass Moodle nur einen Punkt als Dezimaltrennzeichen bzw. ein Komma als Dezimaltrennzeichen verwendet. Moodle weist Sie aber darauf hin, wenn eine Zahl nicht als Zahl erkannt wird, und zwar wenn Sie zur nächsten Aufgabe geben. Sie können also ohne Probleme den Fehler korrigieren. Darüber hinaus ist bei den Prüfungshinweisen vorab auf diesen Punkt verwiesen."
  },
  {
    "objectID": "Inferenz.html",
    "href": "Inferenz.html",
    "title": "2  Inferenz",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Inferenz.html#lernsteuerung",
    "href": "Inferenz.html#lernsteuerung",
    "title": "2  Inferenz",
    "section": "2.1 Lernsteuerung",
    "text": "2.1 Lernsteuerung\n\n2.1.1 Lernziele\nNach Absolvieren des jeweiligen Kapitel sollen folgende Lernziele erreicht sein.\nSie können …\n\ndie Definition von Inferenzstatistik sowie Beispiele für inferenzstatistische Fragestellungen nennen\nzentrale Begriffe nennen und in Grundzügen erklären\nden Nutzen von Inferenzstatistik nennen\nerläutern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\nauch anhand von Beispielen erklären, was ein statistisches Modell ist\ndie Grundkonzepte der Regression angeben\nUnterschiede zwischen klassischer und Bayes-Inferenz benennen\nVor- und Nachteile der klassischen vs. Bayes-Inferenz diskutieren\nDie grundlegende Herangehensweise zur Berechnung des p-Werts informell erklären können"
  },
  {
    "objectID": "Inferenz.html#wozu-ist-statistik-überhaupt-da",
    "href": "Inferenz.html#wozu-ist-statistik-überhaupt-da",
    "title": "2  Inferenz",
    "section": "2.2 Wozu ist Statistik überhaupt da?",
    "text": "2.2 Wozu ist Statistik überhaupt da?\nJa, diese Frage haben Sie sich auch schon mal gestellt?\nAbb. Figure 2.1 gibt einen Überblick über die Ziele der Statistik.\n\n\n\n\n\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n\n\n\n\n\nFigure 2.1: A taxonomy of statistical goals\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nZiele exsitieren nicht “in echt” in der Welt. Wir denken sie uns aus. Ziele haben also keine ontologische Wirklichkeit, sie sind epistemologische Dinge (existieren nur in unserem Kopf). Das heißt, dass man sich nach Beliebem Ziele ausdenken kann. Allerdings hülfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen überzeugen kann."
  },
  {
    "objectID": "Inferenz.html#was-ist-inferenz",
    "href": "Inferenz.html#was-ist-inferenz",
    "title": "2  Inferenz",
    "section": "2.3 Was ist Inferenz?",
    "text": "2.3 Was ist Inferenz?\n\n2.3.1 Inferenz als Generalisieren\nStatistische Inferenz sieht sich drei “Herausforderungen” gegenüber, laut Gelman, Hill, and Vehtari (2021), Kap. 1.1. Diese betreffen das Schließen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\nVon der Stichprobe aus die Grundgesamtheit (Population)\nVon der Experimental- auf die Kontrollgruppe (Kausalinferenz)\nVon einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs beschäftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n\n\n\nImportant\n\n\n\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schließen, bzw. vom Konrketen auf das Abstrakte."
  },
  {
    "objectID": "Inferenz.html#stichprobe-vs.-population",
    "href": "Inferenz.html#stichprobe-vs.-population",
    "title": "2  Inferenz",
    "section": "2.4 Stichprobe vs. Population",
    "text": "2.4 Stichprobe vs. Population\nNehmen wir an, wir möchten Herausfinden, wie groß der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit A1\nDas Grundproblem der Inferenzstatistik ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\nWir müssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe für die Grundgesamtheit schließen: Wir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. Figure 2.2.\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nFigure 2.2: Population vs. sample (Image credit: Karsten Luebke)\n\n\nHäufig ist das praktische Vorgehen recht simpel: Ah, in unserer Stichprobe sind 42% R-Fans!2. Man schreibt: \\(p = 0.42\\) (p wie proportion). Die Stichprobe sei repräsentativ für die Grundgesamtheit aller Studierender. Messerscharf schließen wir: In der Grundgesamtheit ist der Anteil der R-Fans auch 42%, \\(\\pi=0.42\\).\n\n2.4.1 Deskriptiv- vs. Inferenzstatistik\nStatistik gibt es in zwei Geschmacksrichtigungen könnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. Figure 2.3. Einteilungen in Schubladen existieren nicht auf der Welt, sondern in unserem Kopf: Sie besitzen keine ontologische Realität, sondern eine epistemologische. Sie sind frei, sich andere Einteilungen der Statistik auszudenken. Es hilft allerdings, wenn man andere Menschen vom Wert seiner Idee überzeugen kann.\n\n\n\nFigure 2.3: Deskriptiv- vs. Inferenzstatistik\n\n\nDeskriptivstastistik fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\nInferenzstatistik schließt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\n🏋 Schließen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n2.4.2 Wozu ist die Inferenstatistik gut?\n\n\n\n\n\n\nNote\n\n\n\nInferenz bedeutet Schließen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schlüsse zu ziehen.\n🏋️️ Heute Nacht vor dem Schlafen wiederholen Sie die Definition. Üben Sie jetzt schon mal.\n\n\n2.4.3 Deskriptiv- und Inferenzstatistik gehen Hand in Hand\nFür jede Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle Table 2.1.\n\n\n\n\nTable 2.1: Bezeichnungen für Kennwerte\n\n\nKennwert\nStichprobe\nGrundgesamtheit\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\n\n\n\n\n\nFür Statistiken (Stichprobe) verwendet man lateinische Buchstaben; für Parameter (Population) verwendet man griechische Buchstaben.\n🏋️ Geben Sie die griechischen Buchstaben für typische Statistiken an!\n\n\n2.4.4 Schätzen von Parametern einer Grundgesamtheit\nMeist begnügt man sich beim Analysieren von Daten nicht mit Aussagen für eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit Schätzungen begnügen.\nSchätzwerte werden mit einem “Dach” über dem Kennwert gekennzeichnet, z.B.\n\n\n\n\n\nKennwert\nStichprobe\nGrundgesamtheit\nSchätzwert\n\n\n\n\nMittelwert\n\\(\\bar{X}\\)\n\\(\\mu\\)\n\\(\\hat{\\mu}\\)\n\n\nStreuung\n\\(sd\\)\n\\(\\sigma\\)\n\\(\\hat{\\sigma}\\)\n\n\nAnteil\n\\(p\\)\n\\(\\pi\\)\n\\(\\hat{\\pi}\\)\n\n\nKorrelation\n\\(r\\)\n\\(\\rho\\)\n\\(\\hat{\\rho}\\)\n\n\nRegression\n\\(b\\)\n\\(\\beta\\)\n\\(\\hat{\\beta}\\)\n\n\n\n\n\n\n\n2.4.5 Beispiele für inferenzstatistische Fragestellungen\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\nDazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, \\(\\bar{X}_{V1}\\) und \\(\\bar{X}_{V2}\\).\nDie Mittelwerte unterscheiden sich etwas, \\(\\bar{X}_{V1} > \\bar{X}_{V2}\\)\nSind diese Unterschiede “zufällig” oder “substanziell”? Gilt also \\(\\mu_{V1} > \\mu_{V2}\\) oder gilt \\(\\mu_{V1} \\le \\mu_{V2}\\)?\nWie groß ist die Wahrscheinlichkeit3 \\(Pr(\\mu_{V1} > \\mu_{V2})\\)?\n\n🏋️ Predictive Maintenance ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 dieses Berichts!"
  },
  {
    "objectID": "Inferenz.html#modellieren",
    "href": "Inferenz.html#modellieren",
    "title": "2  Inferenz",
    "section": "2.5 Modellieren",
    "text": "2.5 Modellieren\n\n2.5.1 Modellieren als Grundraster des Erkennens\nIn der Wissenschaft, wie auch oft in der Technik, Wirtschaft oder im Alltag, betrachtet man einen Teil der Welt näher, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\nNun ist die Welt ein weites Feld. Jedes Detail zu berücksichtigen ist nicht möglich. Wir müssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend nötig sind. Aber gleichzeitig die Strukturelemente der wirklichen Welt, die für unsere Fragestellung zentral ist, beibehalten.\nDieses Tun nennt man Modellieren: Man erstellt sich ein Modell.\n\n\n\n\n\n\nImportant\n\n\n\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n\n\nAuf die Statistik bezogen heißt das, dass man einen Datensatz zu zusammenfasst, dass man das Wesentliche erkennt. Was ist das “Wesentliche”? Meist interessiert man sich für die Ursachen eines Phänomens? Etwa: “Wie kommt es bloß, dass ich ohne zu lernen die Klausur so gut bestanden habe?”4 Noch allgemeiner ist vom häufig am Zusammenhang von X und Y interessiert, s. Abb. Figure 2.4, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\nFigure 2.4: Sinnbild eines stastistischen Modells\n\n\n\n\nDas Diagramm hat Sie nicht so vom Hocker? Okay, ein statistisches Modell kann natürlich komplexer sein, z.B. wie in Abb. Figure 2.5 dargestellt.\n\n\n\n\n\nflowchart LR\nX1 --> Y\nX2 --> Y\n\n\n\n\n\nFigure 2.5: Sinnbild eines stastistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\n\n\nEs hört sich zugspitzt an, aber eigentlich ist fast alles Modellieren: Wenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet, macht man sich ein Modell: man vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl, die das forschungsleitende Interesse zusammenfasst.\n\n\n2.5.2 Vertiefung\nLesen Sie die Einführung zum Thema Modellieren bei Poldrack (2022) (Kap. 5.1).\n\n\n\n\n\n\nNote\n\n\n\nNutzen Sie die Übersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch."
  },
  {
    "objectID": "Inferenz.html#regression",
    "href": "Inferenz.html#regression",
    "title": "2  Inferenz",
    "section": "2.6 Regression",
    "text": "2.6 Regression\n\n\n\nOne regression\n\n\n\n2.6.1 Regression zum Modellieren\nDie Regression ist eine Art Schweizer Taschenmessen: Für vieles gut einsetzbar.\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden. Das ist nicht nur einfacher, sondern auch schöner. Wir werden im Folgenden stets die Regression zum Modellieren verwenden.\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n\n\n\n\nNote\n\n\n\nRegression + Inferenz = 💖\n\n\nAlternativ zur Regression könnte man sich in den Wald der statistischen Verfahren begeben, wie hier von der Uni Münster als Ausschnitt (!) aufgeführt.\nAuf dieser Basis kann man meditieren, welches statistischen Verfahren man für eine bestimmte Fragestellung verwenden sollte, s. Abb. Figure 2.6.\n\n\n\nFigure 2.6: Wähle deine Statistik mit Bedacht\n\n\n\n\n2.6.2 Viele statistische Verfahren sind Spezialfälle der Regression\nWie Jonas Kristoffer Lindeløv uns erklärt, sind viele statistische Verfahren, wie der sog. t-Test Spezialfälle der Regression, s. Abb. Figure 2.7.\n\n\n\nFigure 2.7: Common statistical tests as linear models\n\n\n\n\n2.6.3 In voller Pracht\nHier ist die Regressionsgleichung in voller Pracht; Abb. Figure 2.8.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon\\]\nAnhan der Gleichung erkennt man auch, warum man von einem linearen Modell spricht: Y wird als gewichteter Mittelwert mehrerer Summanden berechnet. Dabei wird X nicht mit “fortgeschrittenen” Transformationen wie Quadradieren oder Exponenzieren beglückt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n\n\n\nFigure 2.8: Die Regressionsgerade in voller Pracht"
  },
  {
    "objectID": "Inferenz.html#unsicherheit",
    "href": "Inferenz.html#unsicherheit",
    "title": "2  Inferenz",
    "section": "2.7 Unsicherheit",
    "text": "2.7 Unsicherheit\n\n2.7.1 Inferenz beinhaltet Unsicherheit\nInferenzstatistische Schlüsse sind mit Unsicherheit behaftet: Schließlich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), möchte aber vom Teil auf das Ganze schließen.\n\n\n\n\n\n\nImportant\n\n\n\nNichts Genaues weiß man nicht: Schließt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen über das Ganze betrifft.\n\n\nSchließt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit. Man ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger. Schließlich hat man nicht die ganze Population gesehen bzw. vermessen. Sicher ist man sich hingegen für die Stichprobe (Messfehler einmal ausgeblendet).\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer möglich).\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n\n\n\n\n\nNote\n\n\n\nUnter einem zufälligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres nächsten Würfelwurfs. Zufällig bedeutet nicht (zwangsläufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines Würfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n\n🏋 Welche physikalischen Randbedingungen wirken wohl auf einen Münzwurf ein?\n\n\n2.7.2 Beispiele zur Quantifizierung von Ungewissheit\nAussagen mit Unsicherheit können unterschiedlich präzise formuliert sein.\n\nMorgen regnet’s \\(\\Leftrightarrow\\) Morgen wird es hier mehr als 0 mm Niederschlag geben (\\(p=97\\%\\)).\nMethode \\(A\\) ist besser als Methode \\(B\\) \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert für Methode \\(A\\) höher als für Methode \\(B\\).\nDie Maschine fällt demnächst aus \\(\\Leftrightarrow\\) Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den nächsten 1-3 Tagen ausfallen, laut unserem Modell.\nDie Investition lohnt sich \\(\\Leftrightarrow\\) Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\n🏋 Geben Sie weitere Beispiele an!\n\n\n2.7.3 Zwei Arten von Ungewissheit\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. Figure 2.9.\n\nWie (un)gewiss ist man sich über den Wert des Regressionsgewichts?\nWie (un)gewiss ist man sich über den Wert von Y? Schließlich könnte es ja Einflüsse (X) geben, die man nicht berücksichtigt hat.\n\n\n\n\n\n\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 übersehen? .-> B\n\n\n\n\n\n\nFigure 2.9: Zwei Arten der Ungewissheit beim Modellieren\n\n\n\n\n\n\n2.7.4 Ich weiß, was ich nicht weiß: Ungewissheit angeben\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der Schätzung) wertlos. Angenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% schätzt, lässt aber offen wie sicher (präzise) die Schätzung ist. Wir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Schätzung schließt sogar 41% oder 43% aus.\n::callout-important Eine Inferenz nennt man auch Schätzung. Es sollte immer die Genauigkeit (Ungewissheit) der Schätzung angegeben werden. :::\nIm Rahmen der Regressionsanalyse schlägt sich die Ungewissheit an zwei Stellen nieer:\n\nzur Lage der Regressionsgeraden (\\(\\beta_0\\), \\(\\beta_1\\))\nzu Einflüssen (X), die unser Modell nicht kennt (\\(\\epsilon, \\sigma\\))\n\n\n\n2.7.5 Visualisierung von Ungewissheit\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem Punktschätzer. Punktschäter beinhalten keine Angabe der Schätz(un)gen auigkeit, s. Abb. Figure 2.10.\n\n\n\n\n\nFigure 2.10: Eine Punktschätzung\n\n\n\n\nRot markiert: Die Punktschätzung von mpg für hp=200.\n🏋 Geben Sie ein vergleichbares Beispiel an!\n\n\n\nIn Abb. Figure 2.11 ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur Stärke des Zusammenhangs von X und Y?\n\n\n\n\n\nFigure 2.11: Ungewissheit in den Regressionskoeffizienten\n\n\n\n\nAuch wenn wir uns sicher im Hinblick auf die Regressionsgewichte in Abb. Figure 2.11 bliebe eine Restungewissheit: Unsere Schätzungen wären nicht sicher, nicht fehlerfrei. Das liegt daran, da das Modell nicht alle Einflüsse auf Y berücksichtigt, sondern nur einen, hier als X bezeichnet.\nIn Abb. Figure 2.12 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die “Restungewissheit” dargestellt. In diesem Fall spricht man von einem “Vorhersageintervall”, da man nicht nur von “typischen Fällen” auf der Regressiongeraden spricht, sondern für echte Fälle Vorhersagen (Schätzungen) tätigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n\n\n\nFigure 2.12: Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\n\n\n\n\nWie man sieht, wird die Ungewissheit größer, wenn man beide Arten der Ungewissheit berücksichtigt.\nDas Vorhersage-Intervall berücksichtigt Ungewissheit in \\(\\beta_0, \\beta_1, \\epsilon\\) bei der Vorhersage von \\(\\hat{y_i}\\).\n\n\n2.7.6 Konfidenzintervall\nWir sehen hier, dass ein “Ungewissheitskorridor” angegeben wird. Entsprechend wird nicht ein Punktschätzer, sondern ein Schätzbereich angegeben. Man spricht auch von einem Konfidenzintervall oder Unsicherheitsbereich5\nEin Konfidenzintervall wird häufig mit 90% oder 95% Genauigkeit angegeben.\nIm Kontext der Bayes-Analyse ist das einfach zu interpretieren.\nSagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall für den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.\nDieser Befund läßt sich so interpretieren:\n“Laut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.”\n\n\n\n\n\n\nImportant\n\n\n\nEin Konfidenzintervall gibt einen Schätzbereich plausibler Werte für den gesuchten Wert in der Population (den Parameter) an.\n\n\n🏋 Interpretieren Sie den Ungewissheitskorridor!"
  },
  {
    "objectID": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "href": "Inferenz.html#klassische-vs.-bayes-inferenz",
    "title": "2  Inferenz",
    "section": "2.8 Klassische vs. Bayes-Inferenz",
    "text": "2.8 Klassische vs. Bayes-Inferenz\n\n2.8.1 Klassische Inferenz: Frequentismus\n\nDie Berücksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zurückgewiesen.\nNur die Daten selber fliesen in die Ergebnisse ein\nWahrscheinlichkeit wird über relative Häufigkeiten definiert.\nEs ist nicht möglich, die Wahrscheinlichkeit einer Hypothese anzugeben.\nStattdessen wird angegeben, wie häufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr häufig wiederholt ist.\nEin Großteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n\n\n2.8.2 Bayesianische Inferenz\n\nVorwissen (Priori-Wissen) fließt explizit in die Analyse ein (zusammen mit den Daten).\nWenn das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\nDie Wahl des Vorwissens muss explizit (kritisierbar) sein.\nIn der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen für Hypothesen möglich.\nDie Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (für gängige Computer) komfortabel geworden.\n\n\n\n2.8.3 Vergleich von Wahrscheinlichkeitsaussagen\n\n2.8.3.1 Frequentismus\n\nzentrale Statistik: p-Wert\n“Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zufällig verschieden und auf Basis unseres Modells)?”\nFindet man \\(p<.05\\) (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von “(statistischer) Signifikanz” und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n\n\n2.8.3.2 Bayes-Statistik\n\nzentrale Statistik: Posteriori-Verteilung\n“Wie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Baiss unseres Modells?”\n\n🏋 Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\n\n\n\n2.8.4 Frequentist und Bayesianer\n\n\n\nFrequentist wettet mit Bayesianer\n\n\nQuelle\n\n\n2.8.5 Der p-Wert ist wenig intuitiv\n\n\nfrom Imgflip Meme Generator\n\n\n\n2.8.6 Beispiel zum Nutzen von Apriori-Wissen 1\n\nEin Betrunkener behauptet, er könne hellsehen.\nEr wirft eine Münze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\nDie Wahrscheinlichkeit dieses Ergebnisses ist sehr gering (\\(2^{-10}\\)) unter der Hypothese, dass die Münze fair ist, dass Ergebnis also “zufällig” ist.\nUnser Vorwissen lässt uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zufälligkeit des Ergebnisses wohl nicht verwerfen.\n\n\n\n2.8.7 Beispiel zum Nutzen von Apriori-Wissen 2\n\nEine Studie fand einen “großen Effekt” auf das Einkommen von Babies, eine Stunde pro Woche während zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), \\(n=127\\).\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% höher (als in der Kontrollgruppe) mit einem Konfidenzintervall von [+2%,+98%].\nAllerdings lässt uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln lässt. Wir würden den Effekt lieber in einem konservativeren Intervall schätzen (enger um Null)."
  },
  {
    "objectID": "Inferenz.html#literatur",
    "href": "Inferenz.html#literatur",
    "title": "2  Inferenz",
    "section": "2.9 Literatur",
    "text": "2.9 Literatur\nBei Gelman, Hill, and Vehtari (2021), Kap. 1 findet sich eine Darstellung ähnlich zu der in diesem Kapitel."
  },
  {
    "objectID": "Inferenz.html#aufgaben",
    "href": "Inferenz.html#aufgaben",
    "title": "2  Inferenz",
    "section": "2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nGriech-Buchstaben-Inferenz\nkorr-als-regr\nttest-als-regr\nttest-skalenniveau\nadjustieren2\ninferenz-fuer-alle\nadjustieren1\nungewiss-arten-regr\nvorhersageintervall1\nlm-standardfehler\npunktschaetzer-reicht-nicht\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  },
  {
    "objectID": "Wskt.html",
    "href": "Wskt.html",
    "title": "3  Wahrscheinlichkeit",
    "section": "",
    "text": "Bourier, Günther. 2013. Wahrscheinlichkeitsrechnung Und Schließende Statistik: Praxisorientierte Einführung ; Mit Aufgaben Und Lösungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik – Wahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Verteilungen.html",
    "href": "Verteilungen.html",
    "title": "4  Verteilungen",
    "section": "",
    "text": "Bourier, Günther. 2013. Wahrscheinlichkeitsrechnung Und Schließende Statistik: Praxisorientierte Einführung ; Mit Aufgaben Und Lösungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer Gabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik – Wahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage. Wiesbaden: Springer Gabler."
  },
  {
    "objectID": "Globusversuch.html",
    "href": "Globusversuch.html",
    "title": "5  Globusversuch",
    "section": "",
    "text": "Bayes:Start"
  },
  {
    "objectID": "Globusversuch.html#von-welten-und-golems",
    "href": "Globusversuch.html#von-welten-und-golems",
    "title": "5  Globusversuch",
    "section": "5.1 Von Welten und Golems",
    "text": "5.1 Von Welten und Golems\n\n5.1.1 Kleine Welt, große Welt\nBekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika. Das war aber ein glücklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb Figure 5.1.\n\n\n\nFigure 5.1: Behaims Globus: Kein Amerika\n\n\nDie kleine Welt des Modells entsprach hier nicht der großen Welt, der echten Erdkugel.\nDas ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel für, sagen wir, die Komplexität wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Glück gehört halt auch dazu.\n\nKleine Welt vs. große Welt\n\n\n\n\n\n\nKleine Welt\nGroße Welt\n\n\n\n\nDie Welt, wie sie der Golem sieht\nDie Welt, wie sie in Wirklichkeit ist\n\n\nist das Modell, aber nicht (zwangsläufig) die Wirklichkeit\nentspricht nicht (zwangsläufig) dem Modell\n\n\nVerwenden wir beim Modellieren\nIst das, was wir modellieren\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBehaims Globus ist nicht gleich der Erde. Die kleine Welt ist nicht die große Welt.\n\n\nWas in der kleinen Welt funktioniert, muss nicht in der großen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schlüssen und vermeintlicher Gewissheit.\n🏋 Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!\n\n\n5.1.2 Der Golem von Prag\n\n\n\nDer Golem von Prag\n\n\nQuelle\nDer Golem von Prag, eine vom Menschen geschaffene Kreatur gewaltiger Kraft, die Befehle wörtlich ausführt.\nBei kluger Führung kann ein Golem Nützliches vollbringen.\nBei unüberlegter Verwendung wird er jedoch großen Schaden anrichten.\n\n\n5.1.3 Wissenschaftliche Modelle sind wie Golems\nGolem\n\n\nBesteht aus Lehm\nBelebt durch “Wahrheit”\nMächtig\ndumm\nFührt Befehle wörtlich aus\nMissbrauch leicht möglich\nMärchen\n\nModell\n\n\n\n\nflowchart LR\nX --> Y\n\n\n\n\n\n\n\n\n\nBesteht aus LehmSilikon\nBelebt durch Wahrheit (?)\nManchmal mächtig\nsimpler als die Realität\nFührt Befehle wörtlich aus\nMissbrauch leicht möglich\nNicht einmal falsch\n\n\n\n\n\n\n\nImportant\n\n\n\nWir bauen Golems.\n\n\n\n\n5.1.4 So denkt unser Bayes-Golem\n\n\n\nSo denkt unser Bayes-Golem\n\n\n🏋 Bayes-Inferenz ähnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess ähnelt!"
  },
  {
    "objectID": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "href": "Globusversuch.html#ein-erster-versuch-wir-werfen-den-globus",
    "title": "5  Globusversuch",
    "section": "5.2 Ein erster Versuch: Wir werfen den Globus",
    "text": "5.2 Ein erster Versuch: Wir werfen den Globus\n\n5.2.1 Welcher Anteil der Erdoberfläche ist mit Wasser bedeckt?\nUnsere Hypothese bzw. unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist?\n\n\n\nDer Erdball\n\n\nQuelle CC 4.0 BY-NC\nSie werden einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie 9 Mal.\nSo sah mein Ergebnis aus:\n\\[W \\quad L \\quad W \\quad W \\quad W \\quad L \\quad W \\quad L \\quad W\\]\n🏋️️ Besorgen Sie sich einen Globus (zur Not eine Münze) und stellen Sie den Versuch nach!\n\n\n5.2.2 Wie entstanden die Daten?\nDer physikalische Prozess, der zur Entstehung der Daten führt, nennt man den den datengenierende Prozess.\nIn diesem Fall kann man ihn so beschreiben:\n\nDer wahre Anteil von Wasser, \\(W\\), der Erdoberfläche ist \\(p\\) (und \\(1-p\\) ist der Anteil Land, \\(L\\)).\nEin Wurf des Globusballes hat die Wahrscheinlichkeit \\(p\\), eine \\(W\\)-Beobachtung zu erzeugen.\nDie Würfe des Globusballes sind unabhängig voneinander.\nWir haben kein Vorwissen über \\(p\\); jeder Wert ist uns gleich wahrscheinlich.\n\n🏋 Welche Annahmen würden Sie ändern? Welche könnte man wegnehmen? Welche hinzufügen? Was wären die Konsequenzen?\n\n\n5.2.3 Ein paar Fachbegriffe\n\nFür jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilität der Hypothese angibt: Priori-Verteilung.\nFür jede Hypothese (d.h. jeden Parameterwert \\(p\\)) möchten wir wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Das gibt uns den Likelihood.\nDann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die Posteriori-Verteilung1 bekommen.\n\n\n\n\nUpdating mit Bayes\n\n\n\n\n5.2.4 Die Binomialverteilung\nWir nehmen an, dass die Daten unabhängig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich ändert2.\nDann kann man die Wahrscheinlichkeit (\\(Pr\\)), \\(W\\) mal Wasser und \\(L\\) mal Land zu beobachten, wenn die Wahrscheinlichkeit für Wasser \\(p\\) beträgt, mit der Binomialverteilung berechnen.\nDie Binomialverteilung zeigt die Verteilung der Häufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten Münzwurf (und allen vergleichbaren Zufallsexperimenten): “Münzwurfverteilung”\n\\[Pr(W,L|p) = \\frac{(W+L)!}{W!L!}p^W(1-p)^L\\]\n\n\n5.2.5 Binomialverteilung mit R\nWas ist der Anteil der gültigen Pfade (Wahrscheinlichkeit), um 6 mal \\(W\\) bei \\(N=W+L=9\\) Würfen zu bekommen, wenn wir von \\(p=1/2\\) ausgehen?\n\ndbinom(x = 6, size = 9, prob = 1/2)\n\n[1] 0.1640625\n\n\nWas ist die Wahrscheinlichkeit für \\(W=9\\) bei \\(N=9\\) und \\(p=1/2\\)?\n\ndbinom(x = 9, size = 9, prob = 1/2)\n\n[1] 0.001953125\n\n\n\n\n5.2.6 Beispiele zur Berechnung einer binomial verteilten Wahrscheinlichkeit\nEi Professi stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie groß ist die Wahrscheinlichkeit, durch bloßes Münze werfen genau 15 Fragen richtig zu raten?3.\n\ndbinom(x = 15, size = 20, prob = .5)\n\n[1] 0.01478577\n\n\nWas ist die Wahrscheinlichkeit bei 3 Münzwürfen (genau) 3 Treffer (Kopf) zu erzielen?\n\ndbinom(3, 3, 1/2)\n\n[1] 0.125\n\n\n\n\n5.2.7 Unser Modell ist geboren\nWir fassen das Globusmodell so zusammen:\n\\[W \\sim \\text{Bin}(N,p),\\]\nLies: “W ist binomial verteilt mit den Parametern \\(N\\) und \\(p\\)”. \\(N\\) gibt die Anzahl der Globuswürfe an: \\(N=W+L\\).\nUnser Vorab-Wissen zu \\(p\\) sei, dass uns alle Werte gleich plausibel erscheinen (“uniform”):\n\\[p \\sim \\text{Unif}(0,1).\\]\nLies: “\\(p\\) ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1”.\n\n\n5.2.8 So sehen die Verteilungen aus\nAbb. Figure 5.2 zeigt die Binomialverteilung.\n\n\n\n\n\nFigure 5.2: Ein Beispiel für eine Binomialverteilung\n\n\n\n\n\\(N=9, p = 1/2\\)\nAbb. Figure 5.3 zeigt ein Beispiel für eine Gleichverteilung (uniform distribution).\n\n\n\n\n\nFigure 5.3: Gleichverteilung\n\n\n\n\n\\(Min = 0, Max = 1\\)\n🏋️️ Was fällt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Verändert sich die Wahrscheinlichkeit linear? Was fällt Ihnen bei der Gleichverteilung auf?"
  },
  {
    "objectID": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "href": "Globusversuch.html#zur-erinnerung-bayes-theorem",
    "title": "5  Globusversuch",
    "section": "5.3 Zur Erinnerung: Bayes Theorem",
    "text": "5.3 Zur Erinnerung: Bayes Theorem\n\n5.3.1 Herleitung Bayes’ Theorem 1/2: Gemeinsame Wahrscheinlichkeit\nDie Wahrscheinlichkeit für Regen und kalt ist gleich der Wahrscheinlihckeit von Regen, gegeben kalt mal der Wahrscheinlicht von kalt. Entsprechend gilt: Die Wahrscheinlichkeit von \\(W\\), \\(L\\) und \\(p\\) ist das Produkt von \\(Pr(W,L|p)\\) und der Prior-Wahrscheinlichkeit \\(Pr(p)\\):\n\\[Pr(W,L,p) = Pr(W,L|p) \\cdot Pr(p)\\]\nGenauso gilt: Die Wahrscheinlichkeit von Regen und kalt ist gleich der Wahrscheinlichkeit kalt, wenn’s regnet mal der Wahrscheinlichkeit von Regen:\n\\[Pr(W,L,p) = Pr(p|W,L) \\cdot Pr(W, L)\\]\n\n\n5.3.2 Herleitung Bayes’ Theorem 2/2: Posteriori-Wahrscheinlichkeit\nWir setzen die letzten beiden Gleichungen gleich:\n\\[Pr(W,L|p) \\cdot Pr(p) = Pr(p|W,L) \\cdot (W,L)\\]\nUnd lösen auf nach der Posteriori-Wahrscheinlichkeit, \\(Pr(p|W,L)\\):\n\\[Pr(p|W,L) = \\frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}\\]\n\\(Pr(W,L)\\) nennt man die mittlere Wahrscheinlichkeit der Daten oder Evidenz. Die Evidenz berechnet sich als Mittelwert der Likelihoods über alle Werte von \\(p\\). Die Aufgabe dieser Größe ist nur dafür zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.\n\n\n5.3.3 Bayes’ Theorem als Formel\n\\[Pr(H|D) = \\frac{Pr(D|H) Pr(H)}{Pr(D)}\\]\n\nBestandteile:\n\nPosteriori-Wahrscheinlichkeit: \\(Pr_{Post} := Pr(H|D)\\)\nLikelihood: \\(L := Pr(D|H)\\)\nPriori-Wahrscheinlichkeit: \\(Pr_{Priori} := Pr(H)\\)\nEvidenz: \\(E := Pr(D)\\)\n\nBayes’ Theorem gibt die \\(Pr_{Post}\\) an, wenn man die Gleichung mit der \\(Pr_{Priori}\\) und dem \\(L\\) füttert.\nBayes’ Theorem wird häufig verwendet, um die \\(Pr_{Post}\\) zu quantifizieren.\nDie \\(Pr_{Post}\\) ist proportional zu \\(L \\times Pr_{Priori}\\).\n\n\n\n5.3.4 Posteriori als Produkt von Priori und Likelihood\n\\[\\text{Posteriori} = \\frac{\\text{Likelihood} \\times \\text{Priori}}{\\text{Evidenz}}\\]\n\n\n\nPrior mal Likelihood = Post\n\n\n\n\n5.3.5 Wissen updaten: Wir füttern Daten in das Modell\n\n\n\n\n\n\nUnser Golem lernt\n\n\nUnser Golem (das Modell) lernt. Ob das Modell nützlich ist (präzise Vorhersagen liefert), steht auf einem anderen Blatt."
  },
  {
    "objectID": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "href": "Globusversuch.html#bayes-berechnen-mit-mit-der-gitter-methode",
    "title": "5  Globusversuch",
    "section": "5.4 Bayes berechnen mit mit der Gitter-Methode",
    "text": "5.4 Bayes berechnen mit mit der Gitter-Methode\nDie Methode Gitter-Annäherung nennt man auch Grid Approximation*.\n\n5.4.1 Idee\n\nTeile den Wertebereich des Parameter in ein “Gitter” auf, z.B. \\(0.1, 0.2, ..., 0.9, 1\\) (“Gitterwerte”).\nBestimme den Priori-Wert des Parameters für jeden Gitterwert.\nBerechne den Likelihood für Gitterwert.\nBerechne den unstandardisierten Posteriori-Wert für jeden Gitterwert (Produkt von Priori und Likelihood).\nStandardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.\n\n\n\n5.4.2 Gitterwerte in R berechnen\n\nd <-\n  tibble(\n    # definiere das Gitter: \n    p_Gitter = seq(from = 0, to = 1, length.out = 10),\n    # bestimme den Priori-Wert:       \n    Priori  = 1) %>%  \n    mutate(\n      # berechne Likelihood für jeden Gitterwert:\n      Likelihood = dbinom(6, size = 9, prob = p_Gitter),\n      # berechen unstand. Posteriori-Werte:\n      unstd_Post = Likelihood * Priori,\n      # berechne stand. Posteriori-Werte (summiert zu 1):\n      Post = unstd_Post / sum(unstd_Post))  \n\nSo sehen unsere “Gitterdaten” aus:\n\n# | echo: false\nd %>% \n  knitr::kable(digits = 2)\n\n\n\n\np_Gitter\nPriori\nLikelihood\nunstd_Post\nPost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n🏋️ Was wohl mit Post passiert, wenn wir Priori ändern?\n\n\n5.4.3 Was sagt die Post?\nDie Posteriori-Verteilung (Kurz: “Post-Verteilung”), \\(Pr_{Post}\\), zeigt, wie plausibel wir jeden Wert von \\(p\\) halten.\n\n\n\nJe mehr Gittewerte, desto genauer wird die Verteilung wiedergegeben.\n\n\nMehr Gitterwerte glätten die Annäherung.\nJe größer die Stichprobe (\\(N\\)), desto zuverlässiger wird unsere Berechnung.\n\nDie Post-Verteilung ist sowas wie das Ziel all Ihrer Träume (falls Sie es noch nicht gewusst haben): Aus der Post-Verteilung können Sie ablesen, wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des nächsten Kapitels.\n\n\n\n5.4.4 Zusammenfassung\n\nIn unserem Modell haben wir Annahmen zu \\(Pr_{Priori}\\) und \\(L\\) getroffen.\nAuf dieser Basis hat der Golem sein Wissen geupdated zu \\(Pr_{Post}\\).\nMit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die \\(Pr_{Post}\\) berechnet.\nUnser Modell bildet die kleine Welt ab; ob es in der großen Welt nützlich ist, steht auf einem anderen Blatt.\n\n🏋️ Wenn Sie auf einen Prozentwert für \\(W\\) tippen müssten, welchen würden Sie nehmen, laut dem Modell (und gegeben der Daten)?"
  },
  {
    "objectID": "Post.html",
    "href": "Post.html",
    "title": "6  Die Post befragen",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "href": "Post.html#mit-stichproben-die-post-verteilung-zusammenfassen",
    "title": "6  Die Post befragen",
    "section": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen",
    "text": "6.1 Mit Stichproben die Post-Verteilung zusammenfassen\n\n6.1.1 Zur Erinnerung: Gitterwerte in R berechnen\n\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nVoilà, die Post-Verteilung als Tabelle:\n\n\n\n\n\np_grid\nprior\nlikelihood\nunstand_post\npost\n\n\n\n\n0.00\n1\n0.00\n0.00\n0.00\n\n\n0.11\n1\n0.00\n0.00\n0.00\n\n\n0.22\n1\n0.00\n0.00\n0.01\n\n\n0.33\n1\n0.03\n0.03\n0.04\n\n\n0.44\n1\n0.11\n0.11\n0.12\n\n\n0.56\n1\n0.22\n0.22\n0.24\n\n\n0.67\n1\n0.27\n0.27\n0.30\n\n\n0.78\n1\n0.20\n0.20\n0.23\n\n\n0.89\n1\n0.06\n0.06\n0.06\n\n\n1.00\n1\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n6.1.2 Zur Erinnerung, die Gittermethode\nDie Gittermethode ist ein Weg, die Posteriori-Verteilung zu berechnen. Die Posteriori-Verteilung birgt viele nützliche Informationen.\nModell: \\(W=6\\) Wasser, \\(N=9\\) Würfen und \\(k=10\\) Gitterwerten.\nAbb. Figure 6.1 zeigt die resultierende Post-Verteilung.\n\n\n\n\n\nFigure 6.1: Die Postverteilung für W=6, N=9, k=10\n\n\n\n\n\n\n\n\n\n\n  \n    \n      Tabelle d mit Daten zur Posteriori-Verteilung\n    \n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0\n1\n0\n0\n0\n    1 × 10−1\n1\n1 × 10−4\n1 × 10−4\n1 × 10−4\n    2 × 10−1\n1\n5 × 10−3\n5 × 10−3\n5 × 10−3\n    3 × 10−1\n1\n3 × 10−2\n3 × 10−2\n4 × 10−2\n    4 × 10−1\n1\n1 × 10−1\n1 × 10−1\n1 × 10−1\n    6 × 10−1\n1\n2 × 10−1\n2 × 10−1\n2 × 10−1\n  \n  \n  \n\n\n\n\n\n\n6.1.3 Beispiele für Fragen an die Post-Verteilung\n\nMit welcher Wahrscheinlichkeit liegt der Parameter unter einem bestimmten Wert?\nMit welcher Wahrscheinlichkeit liegt der Parameter zwischen zwei bestimmten Werten?\nMit 5% Wahrscheinlichkeit liegt der Parameterwert nicht unter welchem Wert?\nWelcher Parameterwert hat die höchste Wahrscheinlichkeit?\nWie ungewiss ist das Modell über die Parameterwerte?\n\nSolche Fragen kann man in zwei Gruppen aufteilen:\n\nFragen zu Parametern\nFragen zu Wahrscheinlichkeiten\n\n\n\n6.1.4 Wir arbeiten jetzt mit Häufigkeit, nicht mit Wahrscheinlichkeit\nKomplexere Bayes-Modelle können nicht mehr “einfach mal eben” ausgerechnet werden; die Integrale, auf die man dabei stößt, treiben einem gestandenen Mathematiker die Schweißperlen auf die Stirn.\nGlücklicherweiße gibt es einen Trick, der die Sache nicht nur rechnerisch, sondern auch konzeptionell viel einfacher macht.\nDieser Trick lautet: Wir arbeiten nicht mehr mit Wahrscheinlichkeiten, sondern mit Häufigkeiten.\nPraktischerweise werden wir in Kürze einen R-Golem kennenlernen, der uns das meiste an Arbeit abnimmt. Dieser Golem liefert uns Stichproben aus der Post-Verteilung zurück.\nLernen wir jetz also, wie man mit solchen Stichproben umgeht.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung in Stichprobenform ist viel einfach zu handbaben als das direkte Arbeiten mit Wahrscheinlichkeiten. Daher sind viele R-Funktionen für Bayes auf Stichproben eingestellt.\n\n\nDie Grid-Methode ist bei größeren Datensätzen (oder größeren Modellen) zu rechenintensiv. In der Praxis werden daher andere, schnellere Verfahren verwendet, sog. Monte-Carlo-Markov-Ketten (MCMC). Diese Verfahren sind aber nicht mehr Gegenstand dieses Kurses.\n\n\n6.1.5 Häufigkeiten sind einfacher als Wahrscheinlichkeiten\nWie gesagt, typische R-Werkzeuge (“R-Golems”) liefern uns die Post-Verteilung in Stichprobenform zurück.\nBevor wir uns aber mit diesen R-Werkzeugen beschäftigen, sollten wir uns vertraut machen mit einer Post-Verteilung in Stichprobenform.\nErsstellen wir uns also einen Tabelle mit Stichprobendaten aus der Posteriori-Verteilung (Tabelle d):\n\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\nDie Wahrscheinlichkeit, einen Parameterwert aus Tabelle d zu ziehen, ist proportional zur Posteriori-Wahrscheinlichkeit (post) dieses Werts. Ziehen mit Zurücklegen hält die Wahrscheinlichkeiten während des Ziehens konstant.\n\n\n\n\n\n\n  \n    \n      Stichprobendaten aus der Post-Verteilung\n    \n    \n      Nur die ersten Zeilen abgebildet\n    \n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n      post\n    \n  \n  \n    0.778\n1\n0.204\n2 × 10−1\n0.227\n    0.444\n1\n0.111\n1 × 10−1\n0.123\n    0.667\n1\n0.273\n3 × 10−1\n0.303\n  \n  \n  \n\n\n\n\nWenn Sie jetzt denken: “Warum machen wir das jetzt? Brauchen wir doch gar nicht!” - Dann haben Sie Recht. Künftig werden wir aber, wenn wir mit komplexeren Modellen zu tun haben, nur noch mit Post-Verteilungen auf Stichprobenbasis arbeiten.\nWie sieht diese Tabelle dann als Histogramm1 aus?\nHier erstmal die ersten 100 gesampelten Gitterwerte (p_grid):\n\n\n  [1] 0.78 0.44 0.67 0.56 0.44 0.78 0.89 0.67 0.67 0.33 0.67 0.78 0.67 0.78 0.67\n [16] 0.56 0.67 0.78 0.67 0.33 0.78 0.56 0.67 0.78 0.78 0.78 0.44 0.56 0.89 0.78\n [31] 0.67 0.67 0.67 0.56 0.78 0.67 0.78 0.78 0.44 0.56 0.33 0.67 0.78 0.78 0.78\n [46] 0.78 0.78 0.56 0.67 0.56 0.78 0.67 0.56 0.56 0.78 0.56 0.33 0.67 0.44 0.33\n [61] 0.67 0.78 0.67 0.67 0.44 0.44 0.44 0.67 0.56 0.56 0.78 0.78 0.78 0.78 0.67\n [76] 0.78 0.56 0.78 0.44 0.56 0.67 0.89 0.56 0.56 0.67 0.67 0.33 0.67 0.67 0.67\n [91] 0.67 0.67 0.67 0.67 0.44 0.44 0.56 0.67 0.44 0.78\n\n\nSo sieht die Post-Verteilung auf Basis von Stichproben dann aus, s. Abb. Figure 6.2.\n\n\n\n\n\nFigure 6.2: Stichprobenverteilung auf Basis von Stichproben\n\n\n\n\n\n\n6.1.6 Visualisierung der Stichprobendaten mit \\(k=100\\) Gitterwerten\n\\(k=10\\) Gitterwerte ist ein grobes Raster. Drehen wir mal die Auflösung auf \\(k=100\\) nach oeben.\nDatensatz samples, \\(n=10^3\\), \\(k=100\\) Gitterwerte, basierend auf dem Modell oben.\n\n\n\n\nsamples_k100 <-\n  d_k100 %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = n,  # mit insgesamt n=1000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\n\n\n\n\n\nDie Stichprobendaten nähern sich der “echten” Posteriori-Verteilung an: Die Stichproben-Post-Verteilung hat jetzt “glattere” Ränder.\n\n\n\n\n\n\nNote\n\n\n\nMehr Stichproben und mehr Gitterwerte glätten die Verteilung.\n\n\nJetzt noch mal mit mehr Stichproben: \\(n=10^6\\) Stichproben bei \\(k=100\\) Gitterwerten aus der Posteriori-Verteilung.\n\nd_k100 %>% \n  slice_sample(n = 1e6, weight_by = post, replace = T) %>% \n  ggplot(aes(x = p_grid)) +\n  geom_density(fill = \"black\") +\n  scale_x_continuous(\"Anteil Wasser (p)\", limits = c(0, 1)) +\n  labs(y = \"\")"
  },
  {
    "objectID": "Post.html#die-post-verteilung-befragen",
    "href": "Post.html#die-post-verteilung-befragen",
    "title": "6  Die Post befragen",
    "section": "6.2 Die Post-Verteilung befragen",
    "text": "6.2 Die Post-Verteilung befragen\nSo, jetzt befragen wir die Post-Verteilung.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung ist das zentrale Ergebnis einer Bayes-Analyse. Wir können viele nützliche Fragen an sie stellen.\n\n\nEs gibt zwei Arten von Fragen:\n\nnach Wahrscheinlichkeit (p)\nnach Parameterwerten (Quantilen, q)\n\nDer Unterschied zwischen beiden Arten von Fragen ist in Abb. Figure 6.3 illustriert.\n\n\n\nFigure 6.3: Fragen nach p vs. Fragen nach q\n\n\n\n6.2.1 Fragen zu Wahrscheinlichkeiten\nSagen wir, dass sei unsere Forschungsfrage: Wie groß ist die Wahrscheinlichkeit, dass der Wasseranteil unter 50% liegt?\nWir filtern einfach die passenden Stichproben und und summieren die Wahrscheinlichkeiten dieser Stichproben:\n\n\n\n\n\nWir zählen (count) einfach die Stichproben, die sich für einen Wasseranteil (p_grid) von weniger als 50% aussprechen:\n\nsamples %>%\n  count(p_grid < .5) \n\n# A tibble: 2 × 2\n  `p_grid < 0.5`     n\n  <lgl>          <int>\n1 FALSE           8348\n2 TRUE            1652\n\n\nDa wir insgesamt 10000 (1e4) Stichproben gezogen haben, können wir noch durch diese Zahl teilen, um einen Anteil zu bekommen. Dieser Anteil ist die Antwort auf die Forschungsfrage: Wie Wahrscheinlichkeit (laut Modell) für einen Wasseranteil kleiner als 50%.\nEinfach wie 🍰 essen.\nNoch eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.5 und 0.75?\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75)\n\n# A tibble: 2 × 2\n  `p_grid > 0.5 & p_grid < 0.75`     n\n  <lgl>                          <int>\n1 FALSE                           4530\n2 TRUE                            5470\n\n\n\nsamples %>% \n  count(p_grid > .5 & p_grid < .75) %>% \n  summarise(Anteil = n / 1e4,\n            Prozent = 100 * n / 1e4)  # In Prozent\n\n# A tibble: 2 × 2\n  Anteil Prozent\n   <dbl>   <dbl>\n1  0.453    45.3\n2  0.547    54.7\n\n\nAnteile von count() könnte man, wenn man möchte, auch filter() verwenden:\n\nsamples %>% \n  filter(p_grid > .5 & p_grid < .75) %>% \n  summarise(sum     =       n() / 1e4,\n            anteil = 100 * n() / 1e4)  # In Prozent\n\n# A tibble: 1 × 2\n    sum anteil\n  <dbl>  <dbl>\n1 0.547   54.7\n\n\nNoch ein Beispiel für eine Forschungsfrage: Mit welcher Wahrscheinlichkeit liegt der Parameter zwischen 0.9 und 1?\n\nsamples %>% \n  count(p_grid >= .9 & p_grid <= 1) %>% \n  summarise(prop = 100 * n() / 1e4)  # prop wie \"proportion\", Anteil\n\n# A tibble: 1 × 1\n   prop\n  <dbl>\n1  0.01\n\n\nLaut unserem Modell ist es also sehr unwahrscheinlich, dass der Wasseranteil der Erde mind. 90% beträgt.\n\n\n6.2.2 Fragen nach Parameterwerten\n\n\n\n\n\n\nImportant\n\n\n\nSchätzbereiche von Parameterwerten nennt man auch Konfidenz- oder Vertrauensintervall (synonym: Kompatibilitätsintervall oder Passungsbereich).\n\n\nWelcher Parameterwert wird mit 90% Wahrscheinlichkeit nicht überschritten, laut unserem Modell? (Gesucht sind also die unteren 90% Posteriori-Wahrscheinlichkeit)\n\nsamples %>% \n  summarise(quantil90 = quantile(p_grid, p = .9))\n\n# A tibble: 1 × 1\n  quantil90\n      <dbl>\n1     0.778\n\n\nLaut unserem Modell können wir zu 90% sicher sein, dass der Wasseranteil kleiner ist als ca. 78%.\nEs hilft vielleicht, sich die Post-Verteilung noch einmal vor Augen zu führen:\n\nsamples %>% \n  ggplot(aes(x = p_grid)) +\n  geom_bar()\n\n\n\n\nWas ist das mittlere Intervall, das mit 90% Wahrscheinlichkeit den Parameterwert enthält, laut dem Modell?\nDafür “schneiden” wir links und rechts die 5% der Stichproben mit den extremsten Werten ab und schauen, bei welchem Parameterwert wir landen:\n\nsamples %>% \n  summarise(\n    quant_10 = quantile(p_grid, 0.05),\n    quant_90 = quantile(p_grid, 0.95))\n\n# A tibble: 1 × 2\n  quant_10 quant_90\n     <dbl>    <dbl>\n1    0.444    0.889\n\n\nSolche Fragen lassen sich mit Hilfe von Quantilen beantworten.\n\n\n6.2.3 Zur Erinnerung: Quantile\nBeispiel: Wie groß sind die Studentis (Quelle des Datensatzes)? Das Quantil von z.B. 25% zeigt die Körpergröße der 25% kleinsten Studentis an, analog für 50%, 75%:\n\nspeed_gender_height <- read_csv(\"https://raw.githubusercontent.com/rpruim/OpenIntro/master/data/speed_gender_height.csv\")\n\nheight_summary <- \n  speed_gender_height %>% \n  drop_na(height) %>% \n  summarise(q25 = quantile(height, prob = .25),\n            q50 = quantile(height, prob = .5),\n            q75 = quantile(height, prob = .75))\n\nheight_summary\n\n# A tibble: 1 × 3\n    q25   q50   q75\n  <dbl> <dbl> <dbl>\n1    63    66    69\n\n\nVisualisierung der Quantile:\n\n\n\n\n\n\n\n6.2.4 Den Quantilen unter die Motorhaube geschaut\nDen R-Befehl quantile() kann man sich, wenn man will, einfach nachbauen und entmystifizieren.\nAngenommen, wir wollen wissen, welcher Wasseranteil mit 90% Wahrscheinlichkeit nicht überschritten wird:\n\nSortiere die Stichproben aufsteigend.\nSchneide die oberen 10% ab.\nSchaue, was der größte verbleibende Wert ist.\n\n\nsamples %>% \n  arrange(p_grid) %>%   # sortiere\n  slice_head(n = 9000) %>%  # nur die ersten 90000, also die obersten 1000 abschneiden\n  summarise(p90 = max(p_grid))\n\n# A tibble: 1 × 1\n    p90\n  <dbl>\n1 0.778\n\n\nDas (annähernd) gleiche Ergebnis liefert quantile():\n\nsamples %>% \n  summarise(q90 = quantile(p_grid, .9))\n\n# A tibble: 1 × 1\n    q90\n  <dbl>\n1 0.778\n\n\n\n\n6.2.5 Visualisierung der Intervalle\nIntervalle (Bereiche), die die Wahrscheinlichkeitsmasse hälftig auf die beiden Ränder aufteilen, nennen wir Perzentilintervalle oder Equal-Tails-Intervalle (ETI):"
  },
  {
    "objectID": "Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "href": "Post.html#schiefe-posteriori-verteilungen-sind-möglich",
    "title": "6  Die Post befragen",
    "section": "6.3 Schiefe Posteriori-Verteilungen sind möglich",
    "text": "6.3 Schiefe Posteriori-Verteilungen sind möglich\nGehen wir von 3 Würfen mit 3 Treffern aus; auf welche Wasseranteile (Parameterwerte) werden wir jetzt schließen?\nVermutlich ziemlich hohe.\nErstellen wir uns dazu mal eine Post-Verteilung (3 Treffer, 3 Würfe):\n\nd_33 <- \n  tibble(p_grid = seq(0,1, by =.01),\n         prior = 1) %>% \n  mutate(likelihood = dbinom(3, size = 3, prob = p_grid)) %>% \n  mutate(unstand_post = likelihood * prior) %>% \n  mutate(post_33  = unstand_post / sum(unstand_post)) \n\nsamples_33 <- \n  d_33 %>% \n    slice_sample(n = 1e4, \n                 weight_by = post_33, \n                 replace = T)\n\nSo sehen die ersten paar Zeilen der Post-Verteilung, samples_33, aus.\n\n\n\n\n\n\n  \n  \n    \n      p_grid\n      prior\n      likelihood\n      unstand_post\n    \n  \n  \n    0.68\n1\n0.31\n0.31\n    0.55\n1\n0.17\n0.17\n    0.90\n1\n0.73\n0.73\n    0.96\n1\n0.88\n0.88\n    0.95\n1\n0.86\n0.86\n    0.96\n1\n0.88\n0.88\n  \n  \n  \n\n\n\n\nMit dieser “schiefen” Post-Verteilung können wir gut die Auswirkungen auf das Perzentil- und das Höchste-Dichte-Intervall anschauen.\n\n6.3.1 50%-Perzentil-Intervall\nHier z.B. ein 50%-Perzentilintervall (PI, auch Equal-Tails-Intervall, ETI, genannt):\n\nqi_50_low <- eti(samples_33$p_grid, ci = .5)$CI_low\nqi_50_up <- eti(samples_33$p_grid, ci = .5)$CI_high\np1 <-\n  d_33 %>% \n  ggplot(aes(x = p_grid, y = post_33)) +\n  # check out our sweet `qi()` indexing\n  geom_area(data = . %>% \n              filter(p_grid > qi_50_low &  \n                    p_grid < qi_50_up),\n            fill = \"grey75\") +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 0, to = 1, by = .1))\n\np1\n\n\n\n\nDie Grenzwerte dieses ETI (oder jedes beliebig breiten) kann man sich z.B. so ausgeben lassen:\n\nlibrary(easystats)\n\nsamples_33 %>% \n  select(p_grid) %>% \n  eti(ci = .5)\n\nEqual-Tailed Interval\n\nParameter |      50% ETI\n------------------------\np_grid    | [0.72, 0.94]\n\n\nDer wahrscheinlichste Parameterwert (1) ist nicht im Intervall enthalten. Das ist ein Nachteil der ETI.\n\n\n6.3.2 50%-Intervall höchster Dichte\nIntervalle höchster Dichte (Highest density Intervals) sind definiert als die schmälsten Intervalle, die den gesuchten Parameter enthalten.\n\n\n\n\n\nDer wahrscheinlichste Paramterwert (1) ist im Intervall enthalten, was Sinn macht.\nSo kann man sich die Grenzwerte eines 50%-HDI ausgeben lassen:\n\nsamples %>% \n  select(p_grid) %>% \n  bayestestR::hdi(ci = .5)  # aus dem Paket `bayestestR`\n\nWarning: Identical densities found along different segments of the distribution,\nchoosing rightmost.\n\n\nHighest Density Interval\n\nParameter |      50% HDI\n------------------------\np_grid    | [0.67, 0.78]\n\n\nDas Modell ist sich also zu 50% sicher, dass der gesuchte Parameter (der Wasseranteil der Erdoberfläche) sich in diesem Bereich befindet (auf Basis eines HDI).\n\n\n\n\n\n\nNote\n\n\n\nDas R-Paket {bayestestR} ist Teil des Meta-Pakets {easystats}. Es reicht, wenn Sie easystats laden, damit wird bayestestR automatisch geladen."
  },
  {
    "objectID": "Post.html#intervalle-höchster-dichte-vs.-perzentilintervalle",
    "href": "Post.html#intervalle-höchster-dichte-vs.-perzentilintervalle",
    "title": "6  Die Post befragen",
    "section": "6.4 Intervalle höchster Dichte vs. Perzentilintervalle",
    "text": "6.4 Intervalle höchster Dichte vs. Perzentilintervalle\n\nBei symmetrischer Posteriori-Verteilung sind beide Intervalle ähnlich\nPerzentilintervalle sind verbreiteter\nIntervalle höchster Dichte (Highest Density Interval, HDI) sind bei schiefen Post-Verteilungen zu bevorzugen\nIntervalle höchster Dichte sind die schmalsten Intervalle für eine gegebene Wahrscheinlichkeitsmasse"
  },
  {
    "objectID": "Post.html#punktschätzungen",
    "href": "Post.html#punktschätzungen",
    "title": "6  Die Post befragen",
    "section": "6.5 Punktschätzungen",
    "text": "6.5 Punktschätzungen\nDatendatz samples, 6 Treffer bei 9 Würfen.\n\n6.5.1 Lageparameter\nZ.B. Welchen mittleren Wasseranteil muss man annehmen?\n\nsamples %>% \n  summarise(\n    mean   = mean(p_grid),\n    median = median(p_grid))  \n\n# A tibble: 1 × 2\n   mean median\n  <dbl>  <dbl>\n1 0.636  0.667\n\n\n\n\n6.5.2 Streuungsparameter\nZ.B. “Wie unsicher sind wir in der Schätzung des Wasseranteils?”\n\nsamples %>% \n  summarise(\n    p_sd   = sd(p_grid),\n    p_iqr = IQR(p_grid),\n    p_mad = mad(p_grid))  \n\n# A tibble: 1 × 3\n   p_sd p_iqr p_mad\n  <dbl> <dbl> <dbl>\n1 0.138 0.222 0.165\n\n\nAnstelle der Streuungsparameter ist es aber üblicher, ein HDI oder PI anzugeben.\n\n\n6.5.3 Visualisierungen der Punktschätzer\n\n\n\n\n\nJe symmetrischer die Verteilung, desto näher liegen die Punktschätzer aneinander (und umgekehrt)."
  },
  {
    "objectID": "ppv.html",
    "href": "ppv.html",
    "title": "7  Vorhersage-Verteilung",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "href": "ppv.html#der-zwielichte-dozent-stichproben-vert.-vs.-post-vert.",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.1 Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.",
    "text": "7.1 Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem Glücksspiel heraus: Münzwurf; wenn er gewinnt, müssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? Natürlich nehmen Sie sofort an.\nSie spielen also Münzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal1.\nWütend (und mit leeren Taschen) ziehen Sie von dannen.\nDaten: 9 von 10 Treffern beim Münzwurf. Ist die Münze fair?\n\ntibble(\n  Trefferzahl = rbinom(n = 1e4, size = 10, prob = 1/2)\n) %>% \n  mutate(signifikant = ifelse(Trefferzahl %in% c(9,10), TRUE, FALSE)) %>% \n  ggplot() +\n  aes(x = Trefferzahl, fill = signifikant) +\n  geom_bar() +\n  scale_x_continuous(breaks = 0:10) +\n  theme(legend.position = c(0.1, 0.8)) +\n  geom_vline(xintercept = 9) +\n  labs(title = \"Stichprobenverteilung für p=0.5\")\n\n\n\n\nDie Stichprobenverteilung zeigt, wie Wahrscheinlich der empirischen Daten \\(D\\) (z.B. 9 von 10 Treffer) ist gegeben eines Parameterwerts \\(p\\) (z.B. \\(p=0.5\\)): \\(Pr(D|p)\\).\n\n\n\n\n\n\n\n\nDie Posteriori-Verteilung gibt die Wahrscheinlichkeit jedes Parameterwerts \\(p\\) wider, gegeben der empirischen Daten \\(D\\): \\(Pr(p|D)\\).\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung."
  },
  {
    "objectID": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "href": "ppv.html#mit-stichproben-neue-beobachtungen-simulieren",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.2 Mit Stichproben neue Beobachtungen simulieren",
    "text": "7.2 Mit Stichproben neue Beobachtungen simulieren\n\n7.2.1 Wir simulieren die Wasserzahl bei Globuswürfen\nLikelihood (L): Wahrscheinlichkeit für \\(w=0,1,2\\) bei \\(N=2\\) und \\(p = 0.7\\):\n\nL <- dbinom(0:2, size = 2, prob = 0.7)\nL\n\n[1] 0.09 0.42 0.49\n\n\nWir simulieren \\(n=1\\) neuen Globusversuch mit \\(N=2, p=0.7\\) und zählen die (Wasser-)Treffer:\n\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n\n[1] 0\n\n\nWarum nicht \\(n=10\\) neue Globusversuche simulieren:\n\nrbinom(n = 10, size = 2, prob = 0.7)\n\n [1] 0 2 1 1 1 1 2 1 1 2\n\n\nDiese Versuche geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, \\(p,N\\), erwarten kann.\n\n\n7.2.2 Traue niemals einem Golem (einem Modell)\n\n\n\nNever trust a Golem\n\n\nQuelle: https://imgflip.com/i/5qmhmo\nImmer prüfen und wachsam bleiben:\n\n(Inwieweit) decken sich die simulierten Daten mit den tatsächlichen Beobachtungen?\nWie realistisch sind die Modellannahmen?\nKann man das Modell aus verschiedenen Perspektiven prüfen?"
  },
  {
    "objectID": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "href": "ppv.html#mit-guten-simulationen-kommt-man-den-wahren-werten-nahe",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.3 Mit guten Simulationen kommt man den wahren Werten nahe",
    "text": "7.3 Mit guten Simulationen kommt man den wahren Werten nahe\nWarum nicht \\(n=10^6\\) neue Globusversuche simulieren:\n\ndraws <- \n  tibble(\n    draws = rbinom(1e6, size = 2, prob = .7))\n\ndraws %>% \n  count(draws) %>% \n  mutate(proportion = \n           n / nrow(d))\n\n# A tibble: 3 × 3\n  draws      n proportion\n  <int>  <int>      <dbl>\n1     0  89770      8977 \n2     1 420629     42063.\n3     2 489601     48960.\n\n\nDiese simulierten Häufigkeiten sind sehr ähnlich zu den theoretisch bestimmten Häufigkeiten mit dbinom: Unser Modell liefert plausible Vorhersagen.\n\ndbinom(0:2, size = 2, prob = .7)\n\n[1] 0.09 0.42 0.49"
  },
  {
    "objectID": "ppv.html#stichprobenverteilung",
    "href": "ppv.html#stichprobenverteilung",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.4 Stichprobenverteilung",
    "text": "7.4 Stichprobenverteilung\nWir ziehen viele (\\(n=10^6\\)) Stichproben für den Versuch \\(N=9\\) Globuswürfe mit \\(p=0.7\\).\nWie viele Wasser (W) erhalten wir wohl typischerweise?\n\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = rbinom(n_draws, size = 9, prob = .7))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n\n\nn_draws <- 1e6\ndraws <- tibble(draws = rbinom(n_draws, \n                               size = 9, \n                               prob = .7))\n\n# the histogram\ndraws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", size = 1/10) +\n  scale_x_continuous(\"Anzahl Wasser (W) pro Versuch\",\n                     breaks = seq(from = 0, to = 9, by = 2)) +\n  scale_y_continuous(\"Häufigkeit\",\n                     labels = scales::scientific) +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"Stichprobenverteilung für n=9 und p=.7 (binomial verteilt)\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n\nDie Stichprobenverteilung zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir können jetzt prüfen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n7.4.1 Visualisierung der PPV\n\n\n\n\n\nQuelle: McElreath (2020)"
  },
  {
    "objectID": "ppv.html#so-viele-verteilungen",
    "href": "ppv.html#so-viele-verteilungen",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.5 So viele Verteilungen…",
    "text": "7.5 So viele Verteilungen…\n\nDie Posteriori-Verteilung gibt Aufschluss zur Häufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n\nWie wahrscheinlich ist es, dass “in Wirklichkeit” der Wasseranteil 70% beträgt, also \\(\\pi=.7\\)\nIn der Wissenschaft ist man meist an den Parametern interessiert.\n\nDie PPV gibt Aufschluss zur Häufigkeit von neuen Beobachtungen:\n\nWelche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter Durchführung, zu erwarten.\nFür die Praxis kann das eine interessante Frage sein.\n\nDer Likelihood gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklärt.\n\nWie gut passt die Hypothese \\(\\pi=0.7\\) auf die Datenlage 6 von 9 Treffern beim Globusversuch?\nDer Likelihood kann aus der Stichprobenverteilung herausgelesen werden.\n\n\n\n\n\n\nppv2_plot <- \nd_small %>%\n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", linewidth = 1/10) +\n  scale_x_continuous(\"Wasser\", breaks = seq(from = 0, to = 9, by = 3)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(subtitle = \"Stichprobenverteilungen\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ label, ncol = 9)"
  },
  {
    "objectID": "ppv.html#ppv-berechnen",
    "href": "ppv.html#ppv-berechnen",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.6 PPV berechnen",
    "text": "7.6 PPV berechnen\nFür einen bestimmten Parameterwert sind verschiedene Stichprobenwerte möglich. Das Spektrum dieser Möglichkeiten ist in einer Stichprobenverteilung (gegeben eines bestimmten Parameterwerts) dargestellt.\n\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nppv_plot2 <-\n  ppv %>% \n  ggplot() +\n  aes(x = value) +\n  geom_bar() +\n  scale_x_continuous(\n    breaks = 0:9)\n\n\nppv_plot2\n\n\n\n\n\nDie PPV unseres Modells zeigt uns, dass wir in künftigen Versuchen zumeist 6 Treffer zu erwarten haben.\nAber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar."
  },
  {
    "objectID": "ppv.html#vorhersagen-sind-schwierig",
    "href": "ppv.html#vorhersagen-sind-schwierig",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.7 Vorhersagen sind schwierig",
    "text": "7.7 Vorhersagen sind schwierig\n… gerade wenn sie die Zukunft betreffen, so ein Sprichtwort.\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der häufigste in unseren Stichproben, aber die Vorhersagen haben eine große Streuung, birgt also hohe Ungewissheit.\nDie PPV zeigt also, welche Beobachtungen laut unserem Modell künftig zu erwarten sind.\n\n\n\n\n\nWürde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B \\(p=0.6\\)) vornehmen, hätten die Vorhersagen zu wenig Streuung, würden also die Ungewissheit nicht ausreichend abbilden (Übergewissheit, Overconfidence)."
  },
  {
    "objectID": "ppv.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "href": "ppv.html#zwei-arten-von-ungewissheit-in-vorhersagen-von-modellen",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.8 Zwei Arten von Ungewissheit in Vorhersagen von Modellen",
    "text": "7.8 Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\nUngewissheit innerhalb des Modells: Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiß, dass \\(p=1/4\\) Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nächste Murmel haben wird (Ausnahme: \\(p=1\\) oder \\(p=0\\)).\nUngewissheit in den Modellparametern: Wir sind uns nicht sicher, welchen Wert \\(p\\) (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt.\n\nUm zu realistischen Vorhersagen zu kommen, möchte man beide Arten von Ungewissheit berücksichtigen: Das macht die Posteriori-Prädiktiv-Verteilung (PPV).\nDie PPV zeigt, welche Daten das Modell vorhersagt (prädiktiv) und mit welcher Häufigkeit, basierend auf der Post-Verteilung."
  },
  {
    "objectID": "ppv.html#vergleich-der-verteilungen",
    "href": "ppv.html#vergleich-der-verteilungen",
    "title": "7  Vorhersage-Verteilung",
    "section": "7.9 Vergleich der Verteilungen",
    "text": "7.9 Vergleich der Verteilungen\n\n\n\n\n\n\nLinks - Posterior-Verteilung: Wahrscheinlichkeiten der Parameterwerte\nMitte - Stichprobenverteilung: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\nRechts - Posterior-Prädiktiv-Verteilung: Wahrscheinlichkeiten der Beobachtungen unter Berücksichtigung der Unsicherheit der Posteriori-Verteilung\n\nBild\nQuelle: R. McElreath\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "gauss.html",
    "href": "gauss.html",
    "title": "8  Gauss-Modelle",
    "section": "",
    "text": "Bayes:Start!"
  },
  {
    "objectID": "gauss.html#software",
    "href": "gauss.html#software",
    "title": "8  Gauss-Modelle",
    "section": "8.1 Software",
    "text": "8.1 Software\nFür dieses Thema benötigen Sie einige R-Pakete, die Sie wie folgt installieren können:\n\npakete <- c(\"tidyverse\", \"rstanarm\", \"easystats\")\n\ninstall.packages(pakete)\n\nFür rstanarm wird weitere Software benötigt.\n\n\n\n\n\n\nNote\n\n\n\nSoftware, und das sind R-Pakete, müssen Sie nur einmalig installieren. Aber bei jedem Start von R bzw. RStudio müssen Sie die (benötigten!) Pakete starten.\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6.9000     ✔ purrr   0.3.4     \n✔ tibble  3.1.8          ✔ dplyr   1.0.10    \n✔ tidyr   1.2.0          ✔ stringr 1.4.1     \n✔ readr   2.1.2          ✔ forcats 0.5.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rstanarm)\n\nLoading required package: Rcpp\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nPlease use the `linewidth` argument instead.\n\n\nThis is rstanarm version 2.21.3\n- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!\n- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.\n- For execution on a local, multicore CPU with excess RAM we recommend calling\n  options(mc.cores = parallel::detectCores())\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.5.2\n✔ insight     0.18.2     ✔ datawizard  0.5.1   \n✔ bayestestR  0.12.1.1   ✔ performance 0.9.2   \n✔ parameters  0.18.2     ✔ effectsize  0.7.0.5 \n✔ modelbased  0.8.5      ✔ correlation 0.8.2   \n✔ see         0.7.2      ✔ report      0.5.5"
  },
  {
    "objectID": "gauss.html#wie-groß-sind-die-kung-san",
    "href": "gauss.html#wie-groß-sind-die-kung-san",
    "title": "8  Gauss-Modelle",
    "section": "8.2 Wie groß sind die !Kung San?",
    "text": "8.2 Wie groß sind die !Kung San?\nDieser Abschnitt basiert auf McElreath (2020), Kap. 4.3.\n\n8.2.1 !Kung San\n\n\n\n\n\nQuelle Internet Archive Book Images, No restrictions, via Wikimedia Commons]\n\n\n\n\n\nBy Andrewwik.0 - Own work, CC BY-SA 4.0, Quelle]\n\n\n8.2.2 !Kung Data\nDatenquelle\n\nKung_path <-  \n  \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \n\nd <- read_csv(Kung_path)  \n\nRows: 544 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): height, weight, age, male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(d)\n\n# A tibble: 6 × 4\n  height weight   age  male\n   <dbl>  <dbl> <dbl> <dbl>\n1   152.   47.8    63     1\n2   140.   36.5    63     0\n3   137.   31.9    65     0\n4   157.   53.0    41     1\n5   145.   41.3    51     0\n6   164.   63.0    35     1\n\n\nWir interessieren uns für die Größe der erwachsenen !Kung:\n\nd2 <- d %>% \n  filter(age >= 18)\n\n\\(N=352\\).\n\ndescribe_distribution(d2)\n\n\n\n\n\n\n\n  \n  \n    \n      Variable\n      Mean\n      SD\n      IQR\n      Min\n      Max\n      Skewness\n      Kurtosis\n      n\n      n_Missing\n    \n  \n  \n    height\n154.59709\n7.74\n12.06\n136.53\n179.07\n0.15\n−0.48\n352.00\n0.00\n    weight\n44.99049\n6.46\n9.19\n31.07\n62.99\n0.13\n−0.51\n352.00\n0.00\n    age\n41.13849\n15.97\n23.00\n18.00\n88.00\n0.67\n−0.21\n352.00\n0.00\n    male\n0.46875\n0.50\n1.00\n0.00\n1.00\n0.13\n−2.00\n352.00\n0.00\n  \n  \n  \n\n\n\n\n\n\n8.2.3 Wir gehen apriori von normalverteilter Größe Der !Kung aus\n\n\n\n\n\nOwn alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA 3.0 https://creativecommons.org/licenses/by-sa/3.0, via Wikimedia Commons\n\\[\\mu \\sim \\mathcal{N}(178, 20)\\]\nWarum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen. In einer echten Untersuchung sollte man immer einen inhaltlichen Grund für einen Priori-Wert haben. Oder man wählt “schwach informative” Prioris, wie das {rstanarm} tut: Damit lässt man kaum Vorab-Information in das Modell einfließen, aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern in diesem Fall).\n\n\n\n\n\n8.2.4 Unser Gauss-Modell der !Kung\nWir nehmen an, dass \\(\\mu\\) und \\(h_i\\) normalverteilt sind und \\(\\sigma\\) exponentialverteilt (da notwendig positiv) ist:\nLikelihood:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\)\nPrior für \\(\\mu\\):\n\\(\\mu \\sim \\mathcal{N}(178, 20)\\)\nPrior für \\(\\sigma\\):\n\\(\\sigma \\sim \\mathcal{E}(0, 0.1)\\)\n \n\\(95\\%KI( \\mu):\\)\n\\(178 \\pm 40\\)\nHier sind unsere Priori-Verteilungen visualisiert:"
  },
  {
    "objectID": "gauss.html#priori-gewichtet-mit-likelihood-ergibt-posteriori",
    "href": "gauss.html#priori-gewichtet-mit-likelihood-ergibt-posteriori",
    "title": "8  Gauss-Modelle",
    "section": "8.3 Priori gewichtet mit Likelihood ergibt Posteriori",
    "text": "8.3 Priori gewichtet mit Likelihood ergibt Posteriori\nZu Erinnerung: Die Posteriori-Wahrscheinlichkeit ist das Ergebnis von Priori-Wahrscheinlichkeit und Likelihood.\n\n8.3.1 Likelihood\nDie Körpergrößen der einzelnen Personen \\(h_i\\) sind normalverteilt mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\):\n\\[h_i \\sim \\mathcal{N}(\\color{blue}{\\mu},\\color{green}{\\sigma})\\]\n\n\n8.3.2 Prioris\nMittelwert der Größe ist normalverteilt mit \\(\\mu=178\\) und \\(\\sigma=20\\):\n\\[\\color{blue}{\\mu \\sim \\mathcal{N}(178, 20)}\\]\nDie Streuung \\(\\sigma\\) der Größen ist exponentialverteil mit \\(\\lambda = 0.1\\).\n\\[\\color{green}{\\sigma \\sim \\mathcal{E}(0.1)}\\]"
  },
  {
    "objectID": "gauss.html#zufällige-motivationsseite",
    "href": "gauss.html#zufällige-motivationsseite",
    "title": "8  Gauss-Modelle",
    "section": "8.4 Zufällige Motivationsseite",
    "text": "8.4 Zufällige Motivationsseite"
  },
  {
    "objectID": "gauss.html#posteriori-verteilung-des-größen-modells-m41",
    "href": "gauss.html#posteriori-verteilung-des-größen-modells-m41",
    "title": "8  Gauss-Modelle",
    "section": "8.5 Posteriori-Verteilung des Größen-Modells, m41",
    "text": "8.5 Posteriori-Verteilung des Größen-Modells, m41\n\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)\nm41_post <- as_tibble(m41)\nnames(m41_post) <- c(\"mu\", \"sigma\")\n\nDas Argument refresh = 0 verhindert, dass die Dateils zum Ziehen der Stichproben am Bildschirm ausgegeben werden. Ich finde diese Ausgabe meist nicht informativ, so dass ich sie lieber unterdrücke.\nFür das Modell m41 haben wir keine Prioris spezifiziert. Wir greifen damit auf die Voreinstellung der Prioris von rstanarm zurück. Das ist ok, aber wenn Sie Vorab-Wissen haben, sollten Sie das an rstanarm weitergeben, weil es ja schade wäre, wenn Sie Wissen haben, das von Ihrem Modell nicht genutzt wird.\nPlotten wir mal die Posteriori-Verteilung von m41:\n\nm41_post %>% \n  ggplot() +\n  aes(x = mu, y = sigma) %>% \n  geom_hex() +\n  scale_fill_viridis_c() \n\n\n\n\nDa das Modell zwei Parameter hat, können wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen können die Parameter korreliert sein.\nHier noch eine andere Visualisierung:\n\np_m41_post <- \n  m41_post %>% \n  ggplot() +\n  aes(x = mu, y = sigma) +\n  geom_point(alpha = .1) \n\nggExtra::ggMarginal(p_m41_post, type = \"density\")\n\n\n\n\nNatürlich können wir auch nur einen Parameter plotten:\n\nm41_post %>% \n  ggplot(aes(x = mu)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nWir bekommen eine Wahrscheinlichkeitsverteilung für \\(\\mu\\) und eine für \\(\\sigma\\) (bzw. eine zweidimensionale Verteilung, für die \\(\\mu,\\sigma\\)-Paare).\nTrotz des eher vagen Priors ist die Streuung Posteriori-Werte für \\(\\mu\\) und \\(\\sigma\\) klein: Die große Stichprobe hat die Priori-Werte überstimmt.\nZiehen wir Stichproben aus der Posteriori-Verteilung, so können wir interessante Fragen stellen.\n\n\n8.5.1 Hallo, Posteriori-Verteilung\n… wir hätten da mal ein paar Fragen an Sie. 🕵\n\nMit welcher Wahrscheinlichkeit ist die mittlere !Kung-Person größer als 1,55m?\nWelche mittlere Körpergröße wird mit 95% Wahrscheinlichkeit nicht überschritten, laut dem Modell?\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\nMit welcher Unsicherheit ist die Schätzung der mittleren Körpergröße behaftet?\nWas ist der mediane Schätzwert der mittleren Körpergröße, sozusagen der “Best Guess”?\n\nAntworten folgen etwas weiter unten.\nAbschlißend, eigentlich nur Spielerei, noch eine andere Visualisierung der Post-Verteilung von \\(\\mu\\) und von \\(\\sigma\\):\n\nm41_post %>% \n  pivot_longer(mu:sigma) %>% \n  ggplot(aes(x = value)) + \n  geom_density(fill = \"grey33\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(NULL) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ name, scales = \"free\", \n             labeller = label_parsed,\n             nrow = 2)\n\n\n\n\n\n\n8.5.2 Posteriori-Stichproben mit stan_glm() berechnen\n\nMit stan_glm() können wir komfortabel die Posteriori-Verteilung berechnen.\nDie Gittermethode wird nicht verwendet, aber die Ergebnisse sind - in bestimmten Situationen - ähnlich.\nEs werden aber auch viele Stichproben simuliert (sog. MCMC-Methode).\nGibt man keine Priori-Werte an, so greift die Funktion auf Standardwerte zurück.\n\n\nlibrary(rstanarm)  # Paket muss gestartet sein.\n\n\n# berechnet Post.-Vert.:\nstan_glm(\n  # modelldefinition:\n  AV ~ UV,\n  # Datensatz:\n  data = meine_daten\n)\n\nModelldefinition:\n\\(h_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), Likelihood\n\\(\\mu \\sim \\mathcal{N}(155, 19)\\), Prior Größenmittelwert\n\\(\\sigma \\sim \\mathcal{E}(0.13)\\), Prior Streuung der Größen\n\n\n8.5.3 Ausgabe von stan_glm()\n\nm41 <- stan_glm(height ~ 1, data = d2, refresh = 0)  # aus Paket rstanarm\n\nparameters(m41)  # aus Paket easystats\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\n\nparameters(m41)\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |                    Prior\n-------------------------------------------------------------------------------------------------------\n(Intercept) | 154.60 | [153.79, 155.44] | 100% |        0% | 1.000 | 2182.00 | Normal (154.60 +- 19.36)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation."
  },
  {
    "objectID": "gauss.html#wie-tickt-stan_glm",
    "href": "gauss.html#wie-tickt-stan_glm",
    "title": "8  Gauss-Modelle",
    "section": "8.6 Wie tickt stan_glm()?",
    "text": "8.6 Wie tickt stan_glm()?\n\n\n\n\n\nQuelle\n\nStan ist eine Software zur Berechnung von Bayesmodellen; das Paket rstanarm stellt Stan für uns bereit.\nstan_glm() ist für die Berechnung von Regressionsmodellen ausgelegt.\nWill man nur die Verteilung einer Variablen (wie heights) schätzen, so hat man man … eine Regression ohne Prädiktor.\nEine Regression ohne Prädiktor schreibt man auf Errisch so: y ~ 1. Die 1 steht also für die nicht vorhandene UV; y meint die AV (height).\nMAD_SD ist eine robuste Version der Streuung, mit inhaltlich gleicher Aussage\n(Intercept) (Achsenabschnitt) gibt den Mittelwert an.\n\nDokumentation RstanArm\n\n8.6.1 Stichproben aus der Posteriori-Verteilung ziehen\nHier die ersten paar Zeilen von post_m41:\n\npost_m41 <- as_tibble(m41)\nhead(post_m41)\n\n# A tibble: 6 × 2\n  `(Intercept)` sigma\n          <dbl> <dbl>\n1          154.  7.79\n2          154.  7.98\n3          154.  8.19\n4          155.  7.36\n5          154.  8.05\n6          156.  8.41\n\n\nMit welcher Wahrscheinlichkeit ist \\(\\mu>155\\)?\n\nnames(post_m41) <- \n  c(\"mu\", \"sigma\")  # den Namen \"(Intercept)\" durch \"mu\" ersetzen, ist kürzher\n\npost_m41 %>% \n  count(mu > 155) %>% \n  mutate(prop = n/sum(n))\n\n# A tibble: 2 × 3\n  `mu > 155`     n  prop\n  <lgl>      <int> <dbl>\n1 FALSE       3349 0.837\n2 TRUE         651 0.163\n\n\n\n\n8.6.2 Antworten von der Posteriori-Verteilung\nWelche mittlere Körpergröße wird mit 95% Wahrscheinlichkeit nicht überschritten, laut dem Modell m41?\n\npost_m41 %>% \n  summarise(q95 = quantile(mu, .95))\n\n# A tibble: 1 × 1\n    q95\n  <dbl>\n1  155.\n\n\nIn welchem 90%-PI liegt \\(\\mu\\) vermutlich?\n\npost_m41 %>% \n  summarise(pi_90 = quantile(mu, c(0.05, 0.95)))\n\n# A tibble: 2 × 1\n  pi_90\n  <dbl>\n1  154.\n2  155.\n\n\nMit welcher Unsicherheit ist die Schätzung der mittleren Körpergröße behaftet?\n\nm41 %>% \n  parameters()\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |                    Prior\n-------------------------------------------------------------------------------------------------------\n(Intercept) | 154.60 | [153.79, 155.44] | 100% |        0% | 1.000 | 2182.00 | Normal (154.60 +- 19.36)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nDas Modell ist sich recht sicher: die Ungewissheit der mittleren Körpergröße liegt bei nicht viel mehr als einem Zentimeter (95%-CI).\nWas ist der mediane Schätzwert der mittleren Körpergröße, sozusagen der “Best Guess”?\nparameters(m41) hat uns die Antwort schon gegeben: Ca. 155 cm.\n🏋️ Ähnliche Fragen bleiben als Übung für die Lesis 🤓.\n\n\n8.6.3 Standard-Prioriwerte bei stan_glm()\n\nprior_summary(m41)\n\nPriors for model 'm41' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 155, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 155, scale = 19)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.13)\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\nstan_glm() verwendet (in der Voreinstellung) schwach informative Priori-Werte, die nur wenig Vorabwissen in das Modell geben.\nEs werden dafür die Stichproben-Daten als Priori-Daten verwendet.\nMan sollte diese Standardwerte als Minimalvorschlag sehen. Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden.\nDie Voreinstellung hat keinen tiefen Hintergrund; andere Werte wären auch denkbar.\nIntercept: \\(\\mu\\), der Mittelwert der Verteilung \\(Y\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\bar{Y}, sd(Y)\\cdot 2.5)\\)\nals Streuung von \\(\\mu\\) wird die 2.5-fache Streuung der Stichprobe (für \\(Y\\)) angenommen.\n\nAuxiliary (sigma): \\(\\sigma\\), die Streuung der Verteilung \\(Y\\)\n\n\\(\\sigma \\sim \\mathcal{E}(\\lambda=1/sd(Y))\\)\nals “Streuung”, d.h. \\(\\lambda\\) von \\(h_i\\) wird \\(\\frac{1}{sd(Y)}\\) angenommen.\n\n\n\n\n8.6.4 Visualisierung verschiedener Exponentialverteilungen\nUm ein Gefühl zu bekommen, wieviel Ungewissheit in Exponentialverteilugnen mit verschiedener Streuung liegt, sind hier mal ein paar Varianten dargestellt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEine sinnvolle Strategie ist, einen Prior so zu wählen, dass man nicht übergewiss ist, also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren (also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, unplausible Werte ausschleßen.\n\\(\\lambda \\approx 0.1\\) scheint eine sinnvolle Ungewissheit anzugeben.\n\n\n\n\n\n\nImportant\n\n\n\nBei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. Die beste Entscheidung ist auf transparente Art den Stand der Forschung einfließen zu lassen und eigene Entscheidungen zu begründen. Häufig sind mehrere Entscheidungen möglich. Möchte man lieber vorsichtig sein, weil man wenig über den Gegenstand weiß, dann könnte man z.B. auf die Voreinstellung von rstanarm vertrauen, die “schwachinformativ” ist, also nur wenig Priori-Information ind das Modell einfließen lässt."
  },
  {
    "objectID": "gauss.html#modell-m42-unsere-priori-werte",
    "href": "gauss.html#modell-m42-unsere-priori-werte",
    "title": "8  Gauss-Modelle",
    "section": "8.7 Modell m42: unsere Priori-Werte",
    "text": "8.7 Modell m42: unsere Priori-Werte\nIm Modell m41 haben wir auf die Priori-Werte der Voreinstellung von rstanarm vertraut. Jetzt lassen wir mal unsere eigenen Priori-Werte einfließen, im Modell m42.\n\nd2 <- \n  d2 %>% \n  mutate(height_c = height - mean(height))  # zentrieren\n\n\nm42 <- \n  stan_glm(height ~ 1, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\nparameters(m42)\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |              Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 154.60 | [153.81, 155.40] | 100% |        0% | 1.000 | 2550.00 | Normal (178 +- 20)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nWir haben noch nicht alle Informationen kennengelernt, die hier ausgegeben werden. Im Zweifel: Einfach ignorieren. Wichtige Fähigkeit im Studium 🤓.\n\n\n\n\n8.7.1 Posteriori-Verteilung und Parameter plotten\n\nm42 %>% \n  as_tibble() %>% \n  ggplot(aes(x = `(Intercept)`)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWie man sieht, sind sich die Post-Verteilungen von m41 und m42 ziemlich ähnlich, kommen also zu dem gleichen Schluss, was die mittlere Körpergröße betrifft. Das ist ein Beispiel für eine Situation, wo eine ausreichend große Stichprobe die Wahl der Prioris (sofern nicht extrem) aussticht.\nEin Vergleich mehererer Priori-Werte wäre auch nützlich, um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gewählten Priori-Werte zu überzeugen."
  },
  {
    "objectID": "gauss.html#fazit",
    "href": "gauss.html#fazit",
    "title": "8  Gauss-Modelle",
    "section": "8.8 Fazit",
    "text": "8.8 Fazit\n\nWir haben die Posteriori-Verteilung für ein Gauss-Modell berechnet.\nDabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Prädiktoren, betrachtet.\nDie Zielvariable, Körpergröße (height), haben wir als normalverteilt mit den Parametern \\(\\mu\\) und \\(\\sigma\\) angenommen.\nFür \\(\\mu\\) und \\(\\sigma\\) haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung für \\(\\mu\\) bzw. \\(\\sigma\\) festgelegt ist.\n\n🧡 Bleiben Sie dran!"
  },
  {
    "objectID": "gauss.html#wahl-der-priori-werte",
    "href": "gauss.html#wahl-der-priori-werte",
    "title": "8  Gauss-Modelle",
    "section": "8.9 Wahl der Priori-Werte",
    "text": "8.9 Wahl der Priori-Werte\n🏎️ Dieser Abschnitt ist eine VERTIEFUNG. 🏎\n\n8.9.1 Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?\n\nn <- 1e4\n\nsim <- tibble(sample_mu  = \n      rnorm(n, \n            mean = 178, \n            sd   = 20),\n    sample_sigma = \n      rexp(n, \n            rate = 0.1)) %>% \n  mutate(height  = \n      rnorm(n, \n            mean = sample_mu, \n            sd   = sample_sigma))\n\nheight_sim_sd <- \n  sd(sim$height) %>% round()\nheight_sim_mean <- \n  mean(sim$height) %>% round()\n\n💭 Was denkt der Golem (m41) apriori von der Größe der !Kung?\n🦾 Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voilà:\n\np3 <- \n  sim %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\",\n       caption = \"X-Achse zeigt MW±3SD\",\n       x = \"Größe\") +\n  theme(panel.grid = element_blank()) \n\np3\n\n\n\n\nQuellcode\n\n\n8.9.2 Priori-Werte prüfen mit der Priori-Prädiktiv-Verteilung\n\nDie Priori-Prädiktiv-Verteilung (sim) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: \\(h_i \\sim \\mathcal{N}(\\mu, \\sigma),\\) \\(\\mu \\sim \\mathcal{N}(178, 20),\\) \\(\\sigma \\sim \\mathcal{E}(0.1)\\)\nSo können wir prüfen, ob die Priori-Werte vernünftig sind.\n\nDie Priori-Prädiktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Größenwerten zulassen:\n\np3\n\n\n\n\nAnteil \\(h_i > 200\\):\n\nanteil_großer_kung <- \nsim %>% \n  count( height > 200) %>% \n  mutate(prop = n/sum(n))\nanteil_großer_kung\n\n# A tibble: 2 × 3\n  `height > 200`     n  prop\n  <lgl>          <int> <dbl>\n1 FALSE           8372 0.837\n2 TRUE            1628 0.163\n\n\n🤔 Sehr große Buschleute? 16 Prozent sind größer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsläufig ein schlechter Prior sein.\n\n\n8.9.3 Vorhersagen der Priori-Werte\n\n\n\n\n\n\n\n8.9.4 Extrem vage Priori-Verteilung für die Streuung?\n\\[\\sigma \\sim \\mathcal{E}(\\lambda=0.01)\\]\n\n# simulate\nset.seed(4)\n\nsim2 <-\n  tibble(sample_mu    = rnorm(n, mean = 178, sd = 100),\n         sample_sigma = rexp(n, rate = .01)) %>% \n  mutate(height = rnorm(n, mean = sample_mu, sd = sample_sigma))\n\n# compute the values we'll use to break on our x axis\nbreaks <-\n  c(mean(sim2$height) - 3 * sd(sim2$height), 0, mean(sim2$height), mean(sim2$height) + 3 * sd(sim2$height)) %>% \n    round(digits = 0)\n\n# this is just for aesthetics\ntext <-\n  tibble(height = 272 - 25,\n         y      = .0013,\n         label  = \"größter Mann\",\n         angle  = 90)\n\n# plot\np4 <-\n  sim2 %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"black\") +\n  geom_vline(xintercept = 0, color = \"grey92\") +\n  geom_vline(xintercept = 272, color = \"grey92\", linetype = 3) +\n  geom_text(data = text,\n            aes(y = y, label = label, angle = angle),\n            color = \"grey92\") +\n  scale_x_continuous(breaks = breaks, \n                     limits = c(-400, 700)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"height ~ dnorm(mu, sigma)\\nmu ~ dnorm(178, 100)\\nsigma ~ E(0.01)\",\n       x = \"Größe\",\n       caption = \"X-Achse zeigt MW±3SD\") +\n  theme(panel.grid = element_blank()) \n\np4\n\nWarning: Removed 130 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nDie Streuung der Größen ist weit:\n\nd <- \n  tibble(x = seq(0,75, by =.01),\n         y = dexp(x, rate = .01))\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line()\n\n\n\n\n\n\n\n🤔 Das Modell geht apriori von ein paar Prozent Menschen mit negativer Größe aus. Ein Haufen Riesen 👹 werden auch erwartet.\n🤯 Vage (flache, informationslose, “neutrale”, “objektive”) Priori-Werte machen oft keinen Sinn, weil sie extreme, unplausible Werte zulassen.\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "lineare-modelle.html",
    "href": "lineare-modelle.html",
    "title": "9  Lineare Modelle",
    "section": "",
    "text": "library(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nPlease use the `linewidth` argument instead."
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-der-regression",
    "href": "lineare-modelle.html#post-verteilung-der-regression",
    "title": "9  Lineare Modelle",
    "section": "9.2 Post-Verteilung der Regression",
    "text": "9.2 Post-Verteilung der Regression\n\n9.2.1 Einfache Regression\n\nDie (einfache) Regression prüft, inwieweit zwei Variablen, \\(Y\\) und \\(X\\) linear zusammenhängen.\nJe mehr sie zusammenhängen, desto besser kann man \\(X\\) nutzen, um \\(Y\\) vorherzusagen (und umgekehrt).\nHängen \\(X\\) und \\(Y\\) zusammen, heißt das nicht (unbedingt), dass es einen kausalen Zusammenhang zwische \\(X\\) und \\(Y\\) gibt.\nLinear bedeutet, der Zusammenhang ist additiv und konstant: wenn \\(X\\) um eine Einheit steigt, steigt \\(Y\\) immer um \\(b\\) Einheiten (nicht kausal, sondern deskriptiv gemeint).\n\nDatenquelle, McElreath (2020).\n\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd <- read_csv(Kung_path)  \n\nRows: 544 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): height, weight, age, male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd2 <- \n  d %>% \n  filter(age > 18) \n\nd2 %>% \n  #select(weight, height) %>% \n  #drop_na() %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n9.2.2 Bei jedem Prädiktorwert eine Post-Verteilung für \\(\\mu\\)\nUnser Modell erlaubt uns für jeden beliebigen Wert des Prädiktors eine Post-Verteilung (von \\(mu\\)) zu berechnen.\nHier am Beispiel von m42:\n\n\n\n\n\n\n\n\n<ScaleContinuousPosition>\n Range:  \n Limits:    0 --   70\n\n\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      height ~ weight_c\n observations: 346\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 154.6    0.3 \nweight_c      0.9    0.0 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 5.1    0.2   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\n\n\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nPlease use `linewidth` instead.\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n9.2.3 Statistiken zum !Kung-Datensatz\nDatenquelle\n\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd <- read_csv(Kung_path)  \n\nd2 <- d %>% filter(age > 18)\n\ndescribe_distribution(d2)\n\n\n\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:correlation':\n\n    cor_test\n\n\nThe following object is masked from 'package:modelbased':\n\n    get_emmeans\n\n\nThe following objects are masked from 'package:effectsize':\n\n    cohens_d, eta_squared\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\n\n\n\n  \n  \n    \n      variable\n      n\n      min\n      max\n      median\n      q1\n      q3\n      iqr\n      mad\n      mean\n      sd\n      se\n      ci\n    \n  \n  \n    age\n346.0\n19.0\n88.0\n40.0\n29.0\n51.0\n22.0\n16.3\n41.5\n15.8\n0.8\n1.7\n    height\n346.0\n136.5\n179.1\n154.3\n148.6\n160.7\n12.1\n8.5\n154.6\n7.8\n0.4\n0.8\n    male\n346.0\n0.0\n1.0\n0.0\n0.0\n1.0\n1.0\n0.0\n0.5\n0.5\n0.0\n0.1\n    weight\n346.0\n31.5\n63.0\n45.0\n40.3\n49.4\n9.0\n6.7\n45.0\n6.5\n0.3\n0.7\n    weight_c\n346.0\n−13.5\n17.9\n0.0\n−4.7\n4.3\n9.0\n6.7\n0.0\n6.5\n0.3\n0.7\n  \n  \n  \n\n\n\n\nDas mittlere Körpergewicht (weight) liegt bei ca. 45kg (sd 7 kg).\n\n\n9.2.4 Etwas mehr EDA\nDas Paket DataExplorer hat ein paar nette Hilfen zur explorativen Datenanylse.\nWir brauchen das hier nicht wirklich, aber es ist praktisch:\n\nlibrary(DataExplorer)\n\n\n9.2.4.1 Gibt es fehlende Werte?\n\nd2 %>% plot_missing()\n\n\n\n\n\n\n9.2.4.2 Verteilung der numerischen Variablen\n\nd2 %>% plot_histogram()\n\n\n\n\n\n\n9.2.4.3 Verteilung der kategorialen Variablen\n\nd2 %>% plot_bar()\n\n\n\n\n\n\n9.2.4.4 Korrelationen\n\nd2 %>% plot_correlation()\n\n\n\n\n\n\n9.2.4.5 Bonus\nProbieren Sie mal diese Funktion aus:\n\ncreate_report(d2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.5 Prädiktor zentrieren\n\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Prädiktor “zentrieren”).\nWenn man den Prädiktor (weight) zentriert hat, ist der Achsenabschnitt, \\(\\alpha\\), einfacher zu verstehen.\nIn einem Modell mit zentriertem Prädiktor (weight) gibt der Achsenabschnitt die Größe einer Person mit durchschnittlichem Gewicht an.\nWürde man weight nicht zentrieren, gibt der Achsenabschnitt die Größe einer Person mit weight=0 an, was nicht wirklich sinnvoll zu interpretieren ist.\n\nVgl. Gelman, Hill, and Vehtari (2021), Kap. 10.4, 12.2.\nSo kann man das Zentrieren bewerkstelligen:\n\nd3 <- \n  d2 %>% \n  center(weight)\n\nOder so, von Hand:\n\nd3 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n\n\n\n\n\n\n\n  \n  \n    \n      height\n      weight\n      age\n      male\n      weight_c\n    \n  \n  \n    152\n48\n63\n1\n3\n    140\n36\n63\n0\n−9\n    137\n32\n65\n0\n−13\n  \n  \n  \n\n\n\n\nWie man sieht, bleibt die Form der Verteilung gleich, aber sie ist “zur Seite geschoben”: Der Mittelwert liegt jetzt eben bei 0.\n\nd3 %>% \n  select(weight, weight_c) %>% \n  pivot_longer(everything()) %>% \n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(~ name, scales = \"free\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass d3 die Tabelle mit zentriertem Prädiktor ist, nicht d2."
  },
  {
    "objectID": "lineare-modelle.html#modell-m43-zentrierter-prädiktor",
    "href": "lineare-modelle.html#modell-m43-zentrierter-prädiktor",
    "title": "9  Lineare Modelle",
    "section": "9.3 Modell m43: zentrierter Prädiktor",
    "text": "9.3 Modell m43: zentrierter Prädiktor\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren: Bei einem (erwachsenen) Menschen mit Gewicht 0, was wäre wohl die Körpergröße? Hm, Philosophie steht heute nicht auf der Tagesordnung.\nDa wäre es schön, wenn wir die Daten so umformen könnten, dass der Achsenabschnitt eine sinnvolle Aussage macht. Zum Glück geht das leicht: Wir zentrieren den Prädiktor (Gewicht)!\n\n\n\n\n\n\nImportant\n\n\n\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n\n\n\n9.3.1 Modelldefinition von m43\n\nFür jede Ausprägung des Prädiktors (weight), \\(h_i\\), wird eine Post-Verteilung für die abhängige Variable (height) berechnet.\nDer Mittelwert \\(\\mu\\) für jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel).\nDie Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel).\nWir brauchen Priori-Werte für die Steigung \\(\\beta\\) und den Achsenabschnitt \\(\\alpha\\) der Regressionsgeraden.\nAußerdem brauchen wir einen Priori-Wert, der die Streuung \\(\\sigma\\) der Größe (height) angibt; dieser Wert wird als exonentialverteilt angenommen.\nDer Likelihood gibt an, wie wahrscheinlich ein Wert height ist, gegeben \\(\\mu\\) und \\(\\sigma\\).\n\n\\[\n\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\n\\]\n\n\n9.3.2 Likelihood, m43\n\\[\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n\\]\n\nDer Likelihood von m43 ist ähnlich zu den vorherigen Modellen (m41, m42).\nNur gibt es jetzt ein kleines “Index-i” am \\(\\mu\\) und am \\(h\\) (h wie heights).\nEs gibt jetzt nicht mehr nur einen Mittelwert \\(\\mu\\), sondern für jede Beobachtung (Zeile) einen Mittelwert \\(\\mu_i\\).\nLies etwa so:\n\n\n“Die Wahrscheinlichkeit, eine bestimmte Größe bei Person \\(i\\) zu beobachten, gegeben \\(\\mu\\) und \\(\\sigma\\) ist normalverteilt (mit Mittelwert \\(\\mu\\) und Streuung \\(\\sigma\\))”.\n\n\n\n9.3.3 Regressionsformel, m43\n\\[\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n\\]\n\n\\(\\mu\\) ist jetzt nicht mehr ein Parameter, der (stochastisch) geschätzt werden muss. \\(\\mu\\) wird jetzt (deterministisch) berechnet. Gegeben \\(\\alpha\\) und \\(\\beta\\) ist \\(\\mu\\) ohne Ungewissheit bekannt.\n\\(\\text{weight}_i\\) ist der Prädiktorwert (weight) der \\(i\\)ten Beobachtung, also einer !Kung-Person (Zeile \\(i\\) im Datensatz).\nLies etwa so:\n\n\n“Der Mittelwert \\(\\mu_i\\) der \\(i\\)ten Person berechnet sich als Summe von \\(\\alpha\\) und \\(\\beta\\) mal \\(\\text{weight}_i\\)”.\n\n\n\\(\\mu_i\\) ist eine lineare Funktion von weight.\n\\(\\beta\\) gibt den Unterschied in height zweier Beobachtung an, die sich um eine Einheit in weight unterscheiden (Steigung der Regressionsgeraden).\n\\(\\alpha\\) gibt an, wie groß \\(\\mu\\) ist, wenn weight Null ist (Achsenabschnitt, engl. intercept).\n\n\n\n9.3.4 Priori-Werte des Modells m43\n\\[\n\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\n\\]\n\nParameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n\\(\\alpha\\) wurde in m41 als \\(\\mu\\) bezeichnet, da wir dort eine “Regression ohne Prädiktoren” berechnet haben.\n\\(\\sigma\\) ist uns schon als Parameter bekannt und behält seine Bedeutung aus dem letzten Kapitel.\nDa height nicht zentriert ist, der Mittelwert von \\(\\alpha\\) bei 178 und nicht 0.\n\\(\\beta\\) fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Größe positiv (gleichsinnig) ist."
  },
  {
    "objectID": "lineare-modelle.html#vertiefung-prior-prädiktiv-verteilung",
    "href": "lineare-modelle.html#vertiefung-prior-prädiktiv-verteilung",
    "title": "9  Lineare Modelle",
    "section": "9.4 Vertiefung: Prior-Prädiktiv-Verteilung",
    "text": "9.4 Vertiefung: Prior-Prädiktiv-Verteilung\n🏎️ VERTIEFUNG 🏎️\n\n9.4.1 Moment\n\n🤔 Moment. Dieser Prior, \\(\\beta\\) in m43 erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Größe positiv oder negativ ist? Nein, sind wir nicht.\n\n\n\n9.4.2 Priori-Prädiktiv-Verteilung für m43\n\nWas denkt wir bzw. unser Golem apriori über den Zusammenhang von Größe und Gewicht?\nUm diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also für \\(\\alpha\\), \\(\\beta\\) und \\(\\sigma\\).\n\n.pull-left[\n\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter für Prior-Pred-Verteilung\n             data = d2)\n\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\nm43_prior_pred_draws %>% \n  slice_head(n=5) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      sigma\n    \n  \n  \n    186.1\n−12.2\n5.9\n    169.6\n0.8\n18.7\n    144.6\n8.4\n3.5\n    189.8\n−3.4\n4.3\n    203.3\n−2.9\n2.8\n  \n  \n  \n\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n9.4.3 Prior-Prädiktiv-Simulation für m43 mit stan_glm()\n\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d2)\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n\n\n\n\n\n\n9.4.4 Visualisieren der Prior-Prädiktiv-Verteilung\n\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n🤯 Einige dieser Regressionsgeraden sind unsinnig!\n\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n\n\n\n\nDie durchgezogene horizontale Linie gibt die Größe des größten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.5 Ein positiver Wert für \\(\\beta\\) ist plausibler\n\n9.4.5.1 Oh no\nEine Normalverteilung mit viel Streuung:\n\n\n\n\n\n👎 \\(\\beta=-20\\) wäre mit diesem Prior gut möglich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n9.4.5.2 Oh yes\nWir bräuchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):\n\n\n\n\n\n👍 Vermutlich besser: Ein Großteil der Wahrscheinlichkeitsmasse ist \\(X>0\\). Allerdings gibt’s keine Gewähr, dass unser Prior “richtig” ist.\n\n\n\n9.4.6 Priori-Prädiktiv-Simulation, 2. Versuch\n\nm43a_prior_pred <-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter für Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d2)\n\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  # Spaltennamen kürzen: \n  rename(a = `(Intercept)`) %>%  \n  rename(b = weight_c,\n         s = sigma)\n\n\n\n\n\n\n\n  \n  \n    \n      a\n      b\n      s\n    \n  \n  \n    156.1\n1.5\n30.0\n    187.7\n−0.8\n4.1\n    181.7\n−0.8\n0.1\n    154.0\n4.2\n0.2\n    162.2\n4.6\n0.4\n  \n  \n  \n\n\n\n\nDas Argument prior_PD = TRUE sorgt dafür, dass keine Posteriori-Verteilung, sondern eine Prior-Prädiktiv-Verteilung berechnet wird.\n\n\n9.4.7 Visualisieren der Prior-Prädiktiv-Verteilung, m43a\nUnsere Priori-Werte scheinen einigermaßen vernünftige Vorhersagen zu tätigen. Allerdings erwartet unser Golem einige Riesen.\n\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n\n\n\n\nDie durchgezogene horizontale Linie gibt die Größe des größten Menschens, Robert Pershing Wadlow, an.\n\n\n9.4.8 Moment, kann hier jeder machen, was er will?\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\nThis is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.\n\nMcElreath (2020), p. 96.\n\n\n9.4.9 Hier ist unser Modell, m43a\n\\[\n\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\n\\]\n\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n\n\n\n9.4.10 Eine Zusammenfassung der Posteriori-Verteilung für m43a\n\nm43a %>% \n  parameters()\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |              Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 154.65 | [154.09, 155.21] | 100% |        0% | 0.999 | 4132.00 | Normal (178 +- 20)\nweight_c    |   0.91 | [  0.83,   0.99] | 100% |        0% | 1.000 | 3837.00 |    Normal (5 +- 3)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nUnser Modell m43a schätzt die typische Körpergröße einer !Kung-Person mittleren Gewichts (weight_c = 0) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher. Pro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise; auch hier ist sich das Modell ziemlich sicher, da dass zugehörige 95%-CI keine 20 Zentimenter umfasst."
  },
  {
    "objectID": "lineare-modelle.html#die-post-verteilung-befragen",
    "href": "lineare-modelle.html#die-post-verteilung-befragen",
    "title": "9  Lineare Modelle",
    "section": "9.5 Die Post-Verteilung befragen",
    "text": "9.5 Die Post-Verteilung befragen\n\n9.5.1 m43a\nSagen wir, auf Basis gut geprüfter Evidenz haben wir folgendes Modell festgelegt:\n\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n\nWir nennen es m43a1.\n\n\n9.5.2 Mittelwerte von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung\nDie ersten paar Zeilen:\n\n\n\n\n\n\n  \n  \n    \n      id\n      (Intercept)\n      weight_c\n      sigma\n    \n  \n  \n    1\n154.8\n0.9\n4.9\n    2\n154.7\n0.8\n4.8\n    3\n154.9\n1.0\n5.1\n  \n  \n  \n\n\n\n\n\nparameters(m43a)\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\n\nparameters(m43a) %>% \n  display()\n\n\nFixed effects\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\n% in ROPE\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n154.65\n(154.09, 155.21)\n100%\n0%\n0.999\n4132.00\nNormal (178 +- 20)\n\n\nweight_c\n0.91\n(0.83, 0.99)\n100%\n0%\n1.000\n3837.00\nNormal (5 +- 3)\n\n\n\n\n\n\n\n9.5.3 Visualisieren der “mittleren” Regressiongeraden\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern, hier \\(\\beta_0\\), \\(\\beta_1\\) und \\(\\sigma\\):\n\nm43a %>% \n  as_tibble() %>% \n  head()\n\n# A tibble: 6 × 3\n  `(Intercept)` weight_c sigma\n          <dbl>    <dbl> <dbl>\n1          155.    0.906  4.94\n2          155.    0.830  4.79\n3          155.    0.950  5.14\n4          155.    0.963  5.28\n5          154.    0.865  4.93\n6          154.    0.877  4.81\n\n\nWir können z.B. ein Lagemaß wie den Median hernehmen, um die “mittlere” Regressionsgerade zu betrachten:\n\nd2 %>% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n\n\n\n9.5.4 Zentrale Statistiken zu den Parametern\nIn diesem Modell gibt es drei Parameter: \\(\\mu, \\beta, \\sigma\\).\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen können.\n\n9.5.4.1 Lagemaße zu den Parametern\n\nWas ist die mittlere Größe einer !Kung-Person? (\\(\\beta_0\\))\nWas ist der Schätzwert für den Zusammenhang von Gewicht und Größe? (\\(\\beta_1\\))\nWas ist der Schätzwert für Ungewissheit in der Schätzung der Größe? (\\(\\sigma\\))\nWas ist der wahrscheinlichste Wert für z.B: \\(\\beta_1\\)?\n\n\nm43a %>% \n  parameters()\n\nParameter   | Median |           95% CI |   pd | % in ROPE |  Rhat |     ESS |              Prior\n-------------------------------------------------------------------------------------------------\n(Intercept) | 154.65 | [154.09, 155.21] | 100% |        0% | 0.999 | 4132.00 | Normal (178 +- 20)\nweight_c    |   0.91 | [  0.83,   0.99] | 100% |        0% | 1.000 | 3837.00 |    Normal (5 +- 3)\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression mit as_tibble() in eine Tabelle um, so bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\nm43a_post <- \n  m43a %>% \n  as_tibble()\n\nm43a_post %>% \n  head()\n\n# A tibble: 6 × 3\n  `(Intercept)` weight_c sigma\n          <dbl>    <dbl> <dbl>\n1          155.    0.906  4.94\n2          155.    0.830  4.79\n3          155.    0.950  5.14\n4          155.    0.963  5.28\n5          154.    0.865  4.93\n6          154.    0.877  4.81\n\n\nWie wir gesehen haben, nutzen wir diese Tabeller der Post-Verteilung immer wieder. Speichern wir uns sie also als ein Objekt ab, m43_post.\n\n\n\nTypischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR\n\n\nQuelle\nEine Visualisierung zeigt gut sowohl Lage- als auch Streuungsmaße der Parameter, zumindest grob:\n\nm43a_post %>% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n\n\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen. Zur Erinnerung: Der Modus gibt den häufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\nDer Modus wird hier auch Maximum a Posteriori (MAP) genannt, daher:\n\nm43a_post %>% \n  summarise(map_b1 = map_estimate(weight_c))\n\nHier ist die Verteilung von \\(\\sigma\\) visualisiert:\n\nm43a_post %>% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n\n\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen, gleich mit Intervallgrenzen, z.B. 95%.\n\nm43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n\n\n\n\nErgänzt man bei plot() noch show_intercept = TRUE wird auch der Achsenabschnitt angezeigt.\n\n\n\n9.5.5 Streuungsmaße zu den Parametern\n\nWie unsicher sind wir uns in den Schätzungen der Parameter?\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n\n\n\n\nNote\n\n\n\nAn einigen Stellen wird empfohlen, anstelle eines (gebräuchlichen) 95%-Intervalls auf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilität.\n\n\n\n\n9.5.6 Ungewissheit von \\(\\alpha\\) und \\(\\beta\\) aus der Post-Verteilung visualisiert\nDie ersten 10 Stichproben\n\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n\n\n\n\nDie ersten 100 Stichproben\n\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n\n\n\n\nDie ersten 1e3 Stichproben\n\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n\n\n\n\nDie ersten 1000000 … okay, lassen wir es gut sein2\n\n\n9.5.7 Fragen zu Quantilen des Achsenabschnitts\n\n\n\n\n\n\nNote\n\n\n\nZur Erinnerung: Bei einem zentrierten Prädiktor misst der Achsenabschnitt die mittlere Größe.\n\n\n\nWelche mittlere Größe mit zu 50%, 90% Wskt. nicht überschritten?\nWelche mittlere Größe mit zu 95% Wskt. nicht unterschritten?\nVon wo bis wo reicht der innere 50%-Schätzbereich der mittleren Größe?\n\n\n\n# A tibble: 1 × 3\n   q_50  q_90  q_05\n  <dbl> <dbl> <dbl>\n1  155.  155.  154.\n\n\n# A tibble: 2 × 1\n  pi_50\n  <dbl>\n1  154.\n2  155.\n\n\n\n\n9.5.8 Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts\nWie wahrscheinlich ist es, dass die mittlere Größe bei mind. 155 cm liegt?\n\nm43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  gross     n  prop\n  <lgl> <int> <dbl>\n1 FALSE  3574 0.894\n2 TRUE    426 0.106\n\n\n\n\n\nDie Wahrscheinlichkeit beträgt 0.11.\n\nWie wahrscheinlich ist es, dass die mittlere Größe höchstens 154.5 cm beträgt?\n\n\nm43a_post %>% \n  count(klein = (`(Intercept)` <= 154.5)) %>% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  klein     n  prop\n  <lgl> <int> <dbl>\n1 FALSE  2810 0.702\n2 TRUE   1190 0.298\n\n\n\n\n\nDie Wahrscheinlichkeit beträgt 0.3."
  },
  {
    "objectID": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prädiktorwert",
    "href": "lineare-modelle.html#post-verteilung-bedingt-auf-einen-prädiktorwert",
    "title": "9  Lineare Modelle",
    "section": "9.6 Post-Verteilung bedingt auf einen Prädiktorwert",
    "text": "9.6 Post-Verteilung bedingt auf einen Prädiktorwert\n\n9.6.1 Visualisierung\nWas ist wohl die Wahrscheinlichkeit der Körpergröße bei einem bestimmten Gewicht?\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt. Welche Körpergröße ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns über diesen Mittelwert?\nEtwas formaler ausgedrückt:\n\\(\\mu|\\text{weight}=45\\)\n45 kg entspricht genau dem Mittelwert von weight. Geht man von zentrierten Prädiktorwerten aus, gilt in dem Fall weight_c = 0.\n\nmu_at_45 <-\n  m43a_post %>% \n  mutate(mu_at_45 = `(Intercept)`)\n\n\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n\n\n# | echo: false\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 45\"])) +\n  scale_x_continuous(limits = c(150, 160))\n\n\n\n\nAnalog können wir fragen, wie groß wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns über diesen Mittelwert sind.\n50 kg, das sind 5 über dem Mittelwert, in zentrierten Einheiten ausgedrückt also weight_c = 5.\n\nmu_at_50 <-\n  m43a_post %>% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\n\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n\n\n\nWarning: Removed 45 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n9.6.2 Lagemaße und Streuungen\nWas ist das 90% PI für \\(\\mu|w=50\\) ?\n\nmu_at_50 %>% \n  summarise(pi = quantile(mu_at_50, prob = c(0.05, .95)))\n\n# A tibble: 2 × 1\n     pi\n  <dbl>\n1  159.\n2  160.\n\n\nDie mittlere Größe - gegeben \\(w=50\\) - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten.\nWelche mittlere Größe wird mit 95% Wahrscheinlichkeit nicht überschritten, wenn die Person 45kg wiegt?\n\nmu_at_45 %>% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n\n# A tibble: 1 × 1\n   q_95\n  <dbl>\n1  155."
  },
  {
    "objectID": "lineare-modelle.html#die-ppv-befragen",
    "href": "lineare-modelle.html#die-ppv-befragen",
    "title": "9  Lineare Modelle",
    "section": "9.7 Die PPV befragen",
    "text": "9.7 Die PPV befragen\n🏎️ VERTIEFUNG 🏎️\nDie Posterior-Prädiktiv-Verteilung (PPV) gibt uns die Möglichkeit, nach der Wahrscheinlichkeit tatsächlicher Körpergrößen zu fragen - und nicht nur nach mittleren Körpergrößen anhand der Post-Verteilung.\n\n\n\n\n\n\nImportant\n\n\n\nDie Post-Verteilung macht nur Aussagen zur mittleren Körpergröße, denn das ist was wir modellieren wollten. Möchten wir Aussagen zur Wahrscheinlichkeit tatsächlicher Größen treffen, brauchen wir die PPV.\n\n\n\n9.7.1 Perzentil-Intervalle für verschiedenen Prädiktor-Werte\nWir erstellen uns eine Sequenz an Prädiktorwerten, die uns interessieren:\n\nweight_df <- tibble(weight_c = seq(-20,20, by = 5))\n\nFür diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\nmus <- \n  predictive_interval(\n    m43a, \n    newdata = weight_df) %>% \n  as_tibble() %>% \n  bind_cols(weight_df)\n\nUm die Perzentilintervalle zu erstellen, wird von predictive_interval() für jeden Prädiktorwert eine Posteriori-Verteilung erstellt und das 5%- sowie 95%-Quantil berechnet.\nWir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine Körpergrö0e von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI). Hoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben. Ja, denn die Post-Verteilung hat die Ungewissheit zum Mittelwert ausgedrückt; die PPV gibt die Ungewissheit tatsächlicher beobachtbarer Körpergrößen aus, nicht nur die Ungewissheit zum Mittelwert.\nHier ist ein Auszug aus der PPV-Tabelle:\n\n\n\n\n\n\n  \n  \n    \n      weight_c\n      5%\n      95%\n    \n  \n  \n    −20.0\n127.7\n145.4\n    −15.0\n132.3\n149.7\n    −10.0\n137.2\n154.2\n    −5.0\n141.4\n158.5\n    0.0\n146.1\n163.3\n    5.0\n150.9\n167.6\n  \n  \n  \n\n\n\n\n\n\n9.7.2 Perzentilintervalle für verschiedenen Prädiktorwerte visualisiert\n\nmus <- \n  mus %>% \n  mutate(height = 154.6 + 0.9*weight_c)\n\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = \"blue\") +\n  geom_errorbar(data = mus,\n                aes(ymin = `5%`,\n                    ymax = `95%`),\n                size = .5,\n                width = .5,\n                color = \"firebrick\")\n\n\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\nNoch eine andere Visualisierung; je dicker die Katzenaugen, desto mehr Samples liegen vor an der Stelle, und umso genauer ist die Schätzung.\n\n\n\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher \\(\\mu|\\text{weight_c}_i\\).\n\n\n9.7.3 Die PPV visualisiert\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV für einen bestimmten Prädiktorwert, z.B. bei einer Person mittleren Gewichts.\nWir können auch den Mittelwert über alle bedingten PPV anschauen, sozusagen die “Master-PPV” oder “unbedingte PPV” oder schlicht PPV.\nVergleichen wir die echten Werte für height, \\(h\\), mit den von der PPV simulierten Werten für height, \\(h_{sim}\\).\n\nlibrary(bayesplot)\nh <- d2$height\nh_sim <- \n  posterior_predict(m43a, \n                    draws = 50)\nppc_dens_overlay(\n  h, h_sim)\n\n?posterior_predict zeigt Hilfe für diese Funktion. Die Funktion zeigt die Vorhersagen für die AV laut der Posteriori-Verteilung.\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n9.7.4 PPV plotten, von Hand\nPPV berechnen (lassen):\n\nset.seed(42)\nppv_m43a <- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %>% \n  as_tibble() %>% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n\nUnd plotten:\n\nppv_m43a %>% \n  ggplot(aes(x = height)) +\n  geom_density()\n\n\n\n9.7.5 Fragen an die PPV\n\nWie groß sind die !Kung im Schnitt?\nWelche Größe wird von 90% der Personen nicht überschritten?\nWie groß sind die 10% kleinsten?\n\n\nppv_m43a %>% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n\n# A tibble: 1 × 4\n   q_10 height_mean  q_50  q_90\n  <dbl>       <dbl> <dbl> <dbl>\n1  138.        154.  154.  172.\n\n\nWas ist der 50% Bereich der Körpergröße?\n\nppv_m43a %>% \n  summarise(pi_50 = quantile(height,prob = c(.25, .75)))\n\n# A tibble: 2 × 1\n  pi_50\n  <dbl>\n1  144.\n2  165.\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. 2nd ed. CRC Texts in Statistical Science. Boca Raton: Taylor; Francis, CRC Press."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bourier, Günther. 2013. Wahrscheinlichkeitsrechnung Und Schließende\nStatistik: Praxisorientierte Einführung ; Mit Aufgaben Und\nLösungen. 8., aktualisierte Aufl. Lehrbuch. Wiesbaden: Springer\nGabler. https://doi.org/10.1007/978-3-658-01447-6.\n\n\n———. 2022. Statistik-Übungen: Beschreibende Statistik –\nWahrscheinlichkeitsrechnung – Schließende Statistik. 7. Auflage.\nWiesbaden: Springer Gabler.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge:\nCambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. 2nd ed. CRC Texts in\nStatistical Science. Boca Raton: Taylor; Francis, CRC\nPress.\n\n\nPoldrack, Russell. 2022. Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html."
  }
]