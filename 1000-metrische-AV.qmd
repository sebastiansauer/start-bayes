
# Forschungsfragen mit metrischer AV



## Lernsteuerung


### R-Pakete

In diesem Kapite lwerden folgende R-Pakete ben√∂tigt:

```{r}
#| message: false
#| results: "hide"
#| warning: false
library(rstanarm)
library(tidyverse)
library(easystats)
```



```{r libs-hidden}
#| include: false
library(icons)
library(gt)
library(ggridges)
library(plotly)
library(patchwork)
library(plotly)
library(dagitty)

theme_set(theme_modern())

```


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen... 

- typische, deskriptive Forschungsfragen spezifizieren als Regression
- Forschungsfragen in Regressionsterme √ºbersetzen
- typische Forschungsfragen auswerten



### Begleitvideos



- [Teil 1](https://youtu.be/WQOmGUyMkxU)
- [Teil 2](https://youtu.be/k-CB0VGRENY)




## Wissenschaft als Gerechtigkeitsprojekt

### Meinungen als Grundlage der Konfliktl√∂sung ?


Contra:

- "Ich find Masken doof!"
- "Impfen ist sch√§dlich!"
- "Corona gibt's gar nicht!"


```{r}
#| echo: false
if (knitr:::is_html_output()) {
  icon_style(fontawesome("angry", style = "solid"), scale = 2, fill = "red")
}
```




Pro:

- "Ich find Masken gut!"
- "Impfen ist n√ºtzlich!"
- "Corona ist gef√§hrlich!"


```{r}
#| echo: false
if (knitr:::is_html_output()) {
  icon_style(fontawesome("tired", style = "solid"), scale = 2, fill = "red")
}
```

Meinungen kennen kein richtig und kein falsch: Meinungen sind keine Fakten. Konflikte k√∂nnen auf Basis von Meinungen nur schwer gel√∂st werden.





### Fakten als Grundlage der Konfliktl√∂sung

Wissenschaft produziert Fakten.
Da Fakten universell sind (sein k√∂nnen), ist Wissenschaft potenziell ein Weg zur Konfliktl√∂sung.
Warum helfen Fakten bei Konflikten?


Fakten sind neutral gegen√ºber Personen.
Fakten bieten daher eine Chance zur fairen Einigung.


Wann ist ein Fakt ein Fakt?


 Fakten m√ºssen vor allem nachpr√ºfbar sein (Daten, Analyse und Bericht m√ºssen offen zug√§nglich sein).



### Beispiel Corona: Datenlage spricht zugunsten der Covid19-Impfung




>    The effectiveness of full messenger RNA (mRNA) vaccination (‚â•14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit.

@thompson_effectiveness_2021; vgl. auch @nasreen_effectiveness_2021; @pormohammad_efficacy_2021



Drei Anforderungen an die Qualit√§t von Studien:

1. *handwerklich gut*:  z.B. vergleichbare Gruppen, genaue Messinstrumente
2. *bescheiden*: die Forschungsfrage wird nur dann selbstbewusst beantwortet, wenn es die handwerkliche Qualit√§t der Studie zul√§sst. Gibt es eine Vielzahl weiterer Studien mit abweichenden Ergebnissen, wird dies bei der Beantwortung der Forschungsfrage ber√ºcksichtigt. 
3. *transparent*: Das Vorgehen, die Hintergr√ºnde und Ziele werden offengelegt. Das betrifft auch m√∂glich Befangenheit oder Interessenskonflikte der Autoren und Autorinnen



### Psychologische Intervention zur Erh√∂hung der Impfquote

@dai_behavioural_2021 zeigen den Effekt einer psychologischen Intervention zur Erh√∂hung der Impfquote, s. @fig-dai.


>   Here we present two sequential randomized controlled trials to test the effect of behavioural interventions on the uptake of COVID-19 vaccines. ... We designed text-based reminders that make vaccination salient and easy, and delivered them to participants drawn from a healthcare system one day (first randomized controlled trial) (n = 93,354 participants; clinicaltrials number NCT04800965) and eight days (second randomized controlled trial) (n = 67,092 individuals; clinicaltrials number NCT04801524) after they received a notification of vaccine eligibility. The first reminder boosted appointment and vaccination rates within the healthcare system by 6.07 (84%) and 3.57 (26%) percentage points, respectively; the second reminder increased those outcomes by 1.65 and 1.06 percentage points, respectively. The first reminder had a greater effect when it was designed to make participants feel ownership of the vaccine dose.


```{r out.width="100%"}
#| echo: false
#| fig-cap: "a, b, Proportion of participants in each condition who scheduled an appointment for the first dose of the COVID-19 vaccine at UCLA Health between 15:00 h on the first reminder date and 23:59 h on the fifth day following the first reminder date (a) and the proportion of participants in each condition who obtained the first dose of the COVID-19 vaccine at UCLA Health within four weeks of the first reminder date (b). Error bars represent ¬± 1 s.e.m. The number of participants in each condition (from left to right in each panel) is 18,629, 18,592, 18,757, 18,627 and 18,749."
#| label: fig-dai 
knitr::include_graphics("img/41586_2021_3843_Fig2_HTML.png")
```

[Quelle/Volltext](https://www.nature.com/articles/s41586-021-03843-2)






### Was hei√üt "ist effektiv"?

@nasreen_effectiveness_2021  definieren *effectivity*, $e$, so:



$$e = 1 - C; C= \frac{n_{vacc|pos}}{n_{vacc|neg}}$$


- $C$ nennt man das *Chancenverh√§ltnis* (*odds ratio*), es beschreibt einen Bruchterm: $\frac{x}{y}$.
- $n_{vacc|pos}$: Anzahl der geimpften Personen unter allen Personen mit positiver Corona-Diagnose
- $n_{vacc|neg}$: Anzahl der geimpften Personen unter allen Personen mit negativer Corona-Diagnose


*Beispiel*: Von den 100 Personen mit *positiver* Corona-Diagnose sind 10 geimpft, $n_{vacc|pos}=10$. Von den 100 Personen mit *negativer* Corona-Diagnose sind 90 geimpft, $n_{vacc|neg}=90$

$$C= \frac{10}{90} = \frac{1}{9}; e = 1 - \frac{1}{9} = \frac{8}{9} \approx 0.88$$


In diesem Beispiel liegt die Effektvitit√§t $e$ bei knapp 90%.


## Arten von Forschungsfragen


### Nach dem Erkenntnisziel

*Deskriptiv* (beschreibend)

- Wie stark ist der (lineare) Zusammenhang $r$ von Gr√∂√üe und Gewicht?
- Wie stark ist der (lineare) Zusammenhang $b$ von Lernzeit und Note?
- Bevorzugen unsere Kunden Webshop A oder B?



*Pr√§diktiv* (prognostisch, vorhersagend)

- Wie schwer ist ein deutscher Mann der Gr√∂√üe 1,80m im Schnitt?
- Welche Note kann man erwarten, wenn man nichts f√ºr die Klausur lernt?
- Wieviel wird ein Kunde ausgeben, wenn er sich in dieser Variante des Webshops aufh√§lt?



*Pr√§skriptiv* (erkl√§rend, kausal)

- Ist Gr√∂√üe eine Ursache von Gewicht (bei deutschen M√§nnern)?
- Wenn ich 100 Stunden lerne, welche Note schreibe ich dann?
- Hat die Art des Webshops einen Einfluss auf unseren Umsatz?


:::callout-note
Das Erkenntnisziel wissenschaftlicher Studien ist zumeist erkl√§rend.
Anhand der verwendeten statistischen Methode (z.B. Regressionsanalyse)
kann man nicht feststellen, zu welchem Erkenntnisziel die Studie geh√∂rt.
:::


### Nach dem Skalenniveau




Wir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit *metrischer* AV. Andere Skalenniveaus bei der AV klammern wir aus.

F√ºr die UV(s) sind nominale und metrische Skalenniveaus erlaubt. 
Modelle mit mehreren UV (und mehreren Stufen an UV) sind erlaubt.


### Varianten von Forschungsfragen

Im Folgenden sind beispielhafte, h√§ufig verwendete Arten von Forschungsfragen aufgef√ºhrt.
F√ºr jede Variante ist ein Beispiel, die Modellformel, der DAG, die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.


Dabei wird folgende Nomenklatur verwendet:


- `y`: metrische abh√§ngige Variable
- `g`: Gruppierungsvariable; nominal skalierter unabh√§ngige Variable (querschnittlich)
- `b`: bin√§re Variable
- `x`: metrische unabh√§ngige Variable
- `u`: ungemessene Variable



## Eine bin√§re UV



### Forschungsfrage

*Hintergrund:*

Eine Psychologin, die im √∂ffentlichen Dienst als Schulpsychologin arbeitet, versucht herauszufinden, warum einige Kinder intelligenter sind als andere. Dazu wurden in einer aufw√§ndigen Studie die Intelligenz vieler Kinder gemessen. Zus√§tzliche wurden verschiedene Korrelate der Intelligenz erhoben, in der Hoffnung, "Risikofaktoren" f√ºr geringere Intelligenz zu entdecken.




*Forschungsfrage:* 


>    Unterscheidet sich der mittlere IQ-Wert (`kid_score`) von Kindern in Abh√§ngigkeit davon, ob ihre jeweilige Mutter √ºber einen Schlusabschluss (`mom_hs`, $x=1$) verf√ºgt (bzw. nicht, $x=0$)? (ceteris paribus)^[H√§ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - "gr√∂√üer als/kleiner als" - zu formulieren, anstelle der hier verwendeteten "empirisch √§rmeren" einfachen, ungerichteten Ungleichheit. Sch√∂ner w√§re nat√ºrlich noch pr√§ziser als "Ich erwarte einen gr√∂√üeren Wert", also z.B. "Ich erwarte einen Wert von 42!"].


Formaler ausgedr√ºckt und als Behauptung (Hypothese) formuliert, sieht die Forschungsfrage so aus (@eq-fofra1):


$$\mu_{x=1|\alpha, \beta, \sigma} \ne \mu_{x=0|\alpha, \beta, \sigma}$${#eq-fofra1}


Die Modellformel zur Forschungsfrage lautet: `y ~ b`.


Der DAG zur Modellformel sieht aus in @fig-binuv dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-binuv
#| fig-cap: "DAG f√ºr `y ~ b`"
#| echo: false

mein_modell <- "dag{
b -> y
u -> y
}"

plot(graphLayout(mein_modell))
```




### IQ von Kindern, bin√§rer Pr√§diktor


```{r m10-1, echo = TRUE, results = "hide"}
#| results: "hide"
data("kidiq")  # Paket rstanarm
m10.1 <- stan_glm(
  kid_score ~ mom_hs, 
  seed = 42,
  data = kidiq)
```

Alternativ k√∂nnen Sie die Daten [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/kidiq.csv) herunterladen.

Mit `parameters(m10.1)` bekommt man die Parameter des Modells, s. @tbl-m101.


```{r echo = TRUE}
#| echo: false
#| tbl-cap: "Parameter des Modells m10.1 (sigma ist nicht dargestellt)"
#| label: tbl-m101 
display(parameters(m10.1))
```

In @fig-momkid ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt.


```{r}
#| eval: false
estimate_expectation(m10.1) %>% plot()
```


```{r plot-kidiq}
#| label: fig-momkid
#| echo: false
#| fig-cap: "Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen, haben im Mittel einen h√∂heren Intelligenztestwert, laut dem vorliegenden Modell"
ggplot(kidiq) +
  aes(x = mom_hs, y = kid_score) +
  geom_jitter(width = 0.1, alpha = .5) +
  geom_abline(slope = coef(m10.1)[2],
              intercept = coef(m10.1)[1])  +
  scale_x_continuous(breaks = c(0, 1))
```


### Interpretation von `m10.1`

`m10.1: kid_score = 78 + 12*mom_hs + error`

- Der *Achsensabschnitt* (intercept, $\beta_0$ oder auch mit $\alpha$ bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren M√ºtter √ºber keinen Schulabschluss (`mom_hs = 0`) verf√ºgen:

`kid_score = 78 + 0*12 + error`

- Das *Regressionsgewicht* (slope, $\beta$) ist der Unterschied im IQ-Wert von Kindern mit M√ºtter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit M√ºtter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.

`kid_score = 78 + 1*12 + error = 90 + error`

- Die Gr√∂√üer der Konfidenzintervalle zeigt, wie genau die Sch√§tzung (Vorhersage) ist bzw. wie stark Pr√§diktor (UV) und Kriterium (AV) zusammenh√§ngen.



### `m10.1` als Mittelwertsdifferenz 


- UV: bin√§r (zweistufig nominal/kategorial)
- AV: metrisch (quantitativ)


Hey R-Golem! Nimm den Datensatz `kidiq`, gruppiere nach `mom_hs`
und fasse zusammen anhand des Mittelwerts.
Die resultierende Zahl soll hei√üen `kid_score_avg`. 
An die Arbeit!

```{r kidqi2-sum, echo = TRUE}
kidiq %>% 
  group_by(mom_hs) %>% 
  summarise(kid_score_avg = 
              mean(kid_score))
```


In der frequentistischen Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation mit einem *t-Test*.
Der t-Test ist ein inferenzstatistisches Verfahren, das pr√ºft, ob die Mittelwertsdifferenz (in der Population) $\mu_d$ Null ist: $\mu_d = 0$.^[Genauer gesagt wird gepr√ºft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.]
In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).


Der mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von M√ºttern mit Abschluss. Allerdings gibt es viel Streuung um die Mittelwerte herum.






### Antwort auf die Forschungsfrage, `m10.1`

Betrachten wir die Ergebnisse von `m10.1`.
Hier sind die ersten paar Zeilen.

```{r echo = TRUE}
m10.1_post <-
  m10.1 %>% 
  as_tibble() 

names(m10.1_post) <- c("Achsenabschnitt", "momhs", "sigma")  # sch√∂nere Namen
```




```{r m10.1-post}
#| echo: false
m10.1_post %>% 
 # rename(momhs = mom_hs) %>% 
  slice_sample(n=5) %>% 
  gt() %>% 
  fmt_number(1:3, decimals = 1) %>% 
  tab_header("Stichprobe aus der Post-Verteilung")
```

Berechnen wir ein 95%-PI von Hand:^[komfortabler geht es mit `eti(m10.1)`.]


```{r echo = TRUE}
pi_mom_hs <-
  m10.1_post %>% 
  summarise(pi_95 = quantile(momhs, c(.025, .975)))

pi_mom_hs
```






Mit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen 
Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, 
laut unserem Modell: $95\%PI: [7,16]$.
Die Hypothese, dass es keinen  Unterschied oder einen Unterschied in die andere Richtung geben sollte, 
ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.

Visualisieren wir abschlie√üend die Posteriori-Verteilung, s. @fig-m101hdi.

```{r plot-hdi-m101}
#| label: fig-m101hdi
#| fig-cap: "Das 95% ETI zum (statistischen) Effekt des m√ºtterlichen Schulabschlusses"
plot(eti(m10.1))
```



Zur Einnerung: Korrelation ungleich Kausation.
Von einem "Effekt" zu sprechen,
l√§sst in den meisten K√∂pfen wohl die Assoziation zu einem *kausalen* Effekt
entstehen. 
Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung,
die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein
 einfacher Zusammenhang.
 


### Variante zur Forschungsfrage


Unsere Psychologin k√∂nnte auch folgende Hypothese formulieren:

>    Die Wahrscheinlichkeit f√ºr ein Kind mit guten Testwerten (y) ist h√∂her, wenn die Mutter √ºber einen Schulabschluss verf√ºgt.


Pr√§ziser formuliert:


$$Pr(y > 100|x=1, \alpha, \beta, \sigma) > Pr(y > 100|x=0, \alpha, \beta, \sigma)$$

Der vertikale Balken "|" liest sich als "gegeben, dass". 
Hier wird auf die Wahrscheinlichkeit f√ºr ein Testergebnis $y>100$,
*gegeben, dass* die Mutter √ºber einen Schulabschluss verf√ºgt ($x=1$) 
und gegeben der Modellparameter $\alpha, \beta, \sigma$.



## Eine metrische plus eine nominale UV 




### Forschungsfrage


>    Wie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (`mom_hs`) und  IQ der Mutter (`mom_iq`)  auf den IQ des Kindes (`kid_score`) ?



Die Modellformel zur Forschungsfrage lautet: `y ~ x + b`.


Der DAG zur Modellformel sieht aus in @fig-yxb dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-yxb
#| fig-cap: "DAG f√ºr `y ~ b`"
#| echo: false

mein_modell <- "dag{
b -> y
u -> y
x -> y
}"

plot(graphLayout(mein_modell))
```




Deskriptive Statistiken zum Datensatz sind in Tabelle @tbl-kidiq1 dargestellt.


```{r Thema6-Teil2-1, echo = TRUE, results="hide"}
data("kidiq")  # Paket rstanarm, alternativ √ºber CSV einlesen
describe_distribution(kidiq)
```


```{r Thema6-Teil2-2}
#| tbl-cap: "Variablen und ihre Verteilung im Datenatz kidiq"
#| echo: false
#| label: tbl-kidiq1
describe_distribution(kidiq) %>% 
  display()
```



[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/2021-wise/main/Data/kidiq.csv)




### 1 metrischer Pr√§diktor


Berechnen wir folgendens Modell: `kid_score ~ mom_iq` (`m10.2`), s. Tab. @tbl-m102.


```{r Thema6-Teil2-3, results = "hide"}
#| results: "hide"
m10.2 <-
  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)

m10.2 %>% 
  parameters()
```


```{r}
#| echo: false
#| tbl-cap: "Parameter des Modells m10.2"
#| label: tbl-m102
m10.2 %>% 
  parameters() %>% 
  display()
```


`kid_score = 26 + 0.6 * mom_iq + error`


Visualisieren wir uns noch das Modell m10.2, s. @fig-kidiqmomiq.


```{r Thema6-Teil2-4}
#| label: fig-kidiqmomiq
#| fig-cap: "Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)"
kidiq %>% 
  ggplot(aes(x = mom_iq, y = kid_score)) +
  geom_point(alpha = .7) +
  geom_abline(slope = coef(m10.2)[2],
              intercept = coef(m10.2)[1],
              color = "blue")
```

Alternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, s. @fig-m102-a.

```{r}
#| label: fig-m102-a
#| fig-cap: "Die gesch√§tzten Erwartungswerte von m10.2 visualisiert"
plot(estimate_expectation(m10.2))
```




Die Linie zeigt die vorhergesagten IQ-Werte der Kinder f√ºr verschiedene IQ-Werte der M√ºtter.
Vergleicht man Teilpopulationen von M√ºttern mit mittleren Unterschied von einem IQ-Punkt, 
so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern *im Durchschnitt*, laut dem Modell m10.2.
Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.






### Beide Pr√§diktoren, `m10.3`


Berechnen wir als n√§chstes ein Modell mit beiden Pr√§diktoren: `kid_score ~ mom_hs + mom_iq`, s. @tbl-m103.

    

```{r m10-3, echo = TRUE}
m10.3 <- 
  stan_glm(
    kid_score ~ mom_iq + mom_hs, 
    refresh = 0,
    seed = 42,
    data = kidiq)
```


```{r}
#| tbl-cap: "Parameter des Modells m10.3 (ohne sigma)"
#| label: tbl-m103
#| echo: false

parameters(m10.3) %>% 
  display()
```



Will man nur schnell die Koeffizienten des Modells (d.h. Punktsch√§tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von `parameters(mein_modell)` auch `coef(mein_modell)` schreiben:

```{r}
coef(m10.3)
```


`m10.3: kid_score = 26 + mom_hs + 0.6*mom_iq + error`

M√∂chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:

```{r}
coef(m10.3)[3]
```


Aber nat√ºrlich ist es m√∂glich (und einfacher) anstelle von `coef` den Befehl `parameters` zu verwenden.

Und die Visualisierung des Modells `m10.3`, s. @fig-m103.


```{r Thema6-Teil2-5, fig.asp = 0.62}
#| label: fig-m103
#| fig-cap: "Der Effekt von sowohl m√ºtterlicher Intelligenz als auch m√ºtterlichem Schulabschluss."

kidiq2 <-
  kidiq %>% 
  mutate(mom_hs = as.factor(mom_hs))

m10.3a <- 
  stan_glm(
    kid_score ~ mom_iq + mom_hs, 
    refresh = 0,
    seed = 42,
    data = kidiq2)

plot(estimate_expectation(m10.3a))
```




- *Achsenabschnitt*: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann sch√§tzt das Modell den IQ-Wert des Kindes auf 26.
- *Koeffizient zum m√ºtterlichen Schulabschluss*: Vergleicht man Kinder von M√ºttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.
- *Koeffizient zur m√ºtterlichen IQ*: Vergleicht man Kinder von M√ºttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.





## Interaktion

In `m10.3` hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. 
Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen.
Sind die Regressionsgeraden nicht parallel, so spricht man von einer Interaktion (synonym: Interaktionseffekt, Moderation).

:::callout-important
Liegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.
Liegt keine Interaktion vor, so sind die Geraden parallel.$\square$
:::

Wir berechnen mit m10.4 folgendes Modell: `kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq`, s. @fig-m104 und @tbl-m104.

```{r m10-4, echo = TRUE}
m10.4 <- 
  stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, 
           seed = 42,
           data = kidiq, 
           refresh = 0)
```


```{r}
#| echo: false
#| label: tbl-m104
#| tbl-cap: "Parameter von m10.4"
parameters(m10.4) %>% 
  display()
```



```{r Thema6-Teil2-6, fig.width=8}
#| echo: false
#| label: fig-m104
#| fig-cap: "Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt f√ºr diese Daten kaum zu interpretieren ist."
kidiq %>% 
  mutate(mom_hs = factor(mom_hs)) %>%  
  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +
  geom_point(alpha = .7) +
  geom_abline(slope = coef(m10.4)[3],
              intercept = coef(m10.4)[1],
              size = 1,
              color =  "#56B4E9E6" ) +
  geom_abline(slope = coef(m10.4)[3]+coef(m10.4)[3]*coef(m10.4)[4],
              intercept = coef(m10.4)[1] + coef(m10.4)[2],
              size = 2,
              color = "#009E73E6") +
  scale_color_manual(values = c( "#56B4E9E6" , "#009E73E6")) +
  scale_x_continuous(limits = c(0, 140))
```





Die Modellformel zur Forschungsfrage lautet: `y ~ x + b + x:b`.


Der DAG zur Modellformel sieht aus in @fig-yxbi dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-yxbi
#| fig-cap: "DAG f√ºr `y ~ x + b + x:b`"
#| echo: false

mein_modell <- "dag{
b -> y
u -> y
x -> y
xb -> y 
}"

plot(graphLayout(mein_modell))
```




### Interpretation von `m10.4`

- *Achsenabschnitt:* IQ-Sch√§tzwerte f√ºr Kinder mit M√ºtter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.
- `mom_hs`: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit Mutter ohne bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.
- `mom_iq`: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit M√ºttern, die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.
- *Interaktion*: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied des Koeffizienten f√ºr `mom_iq` zwischen M√ºtter mit bzw. ohne Schulabschluss.

```
mom_hs=0:
kid_score = -11 + 51*0 + 1.1* mom_iq + 0.5*0*mom_iq

          = -11 + 1.1*mom_iq


mom_hs=1: 
kid_score = -11 + 51*1 + 1.1* mom_iq + 0.5*1*mom_iq

          = 40 + 0.6*mom_iq
```

@gelman_regression_2021, Kap. 10.3





### Nach der Interpretation von 20 unzentrierten Koeffizienten


<iframe src="https://giphy.com/embed/Zaej3GIZTzCI8" width="480" height="306" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/muppets-rachel-maddow-kermit-Zaej3GIZTzCI8">via GIPHY</a></p>






## Zentrieren von Pr√§diktoren

Unter *Zentrieren* (to center) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.
Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist.
Mit zentrierten Werten ist eine Regression einfacher zu interpretieren.
Hier zentrieren wir (nur) `mom_iq`.


Man k√∂nnte auch `mom_hs` zentrieren,
aber f√ºr eine einfache Interpretation ist es meist n√ºtzlich,
nur metrische Pr√§diktoren zu zentrieren.

```{r Thema6-Teil2-7, echo = TRUE}
#| results: hide
kidiq <-
  kidiq %>% 
  mutate(mom_iq_c = mom_iq - mean(mom_iq))

m10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, 
                  data = kidiq, 
                  seed = 42,
                  refresh = 0)
coef(m10.5)
```


```{r}
#| echo: false
parameters(m10.5) %>% 
  select(1,2) %>% 
  display()
```





### Interpretation von `m10.5`

- Der *Achsenabschnitt* (`Intercept`) gibt den gesch√§tzten IQ des Kindes an, wenn man eine Mutter *mittlerer* Intelligenz und *ohne* Schulabschluss betrachtet.
- `mom_hs` gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.
- `mom_iq_c` gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.
- `mom_hs:mom_iq_c` gibt den Unterschied in den Koeffizienten f√ºr `mom_iq_c` an zwischen den beiden Grupen von `mom_hs`.


`m10.5` ist in @fig-m105 dargestellt.


```{r plot-m10-5, fig.asp = .4, fig.width=8}
#| echo: false
#| label: fig-m105
#| fig-cap: "m10.5: Interaktionsmodell mit zentriertem Pr√§diktor f√ºr m√ºtterlicher Intelligenz"

kidiq %>% 
  mutate(mom_hs = factor(mom_hs)) %>%  
  ggplot(aes(x = mom_iq_c, y = kid_score, color = mom_hs)) +
  geom_point(alpha = .7) +
  geom_abline(slope = coef(m10.5)[3],
              intercept = coef(m10.5)[1],
              size = 1,
              color = "#56B4E9E6") +
  geom_abline(slope = coef(m10.5)[3]+coef(m10.5)[3]*coef(m10.5)[4],
              intercept = coef(m10.5)[1] + coef(m10.5)[2],
              size = 2,
              color = "#009E73E6") +
  scale_color_manual(values = c("#56B4E9E6", "#009E73E6")) +
  theme(legend.position = "bottom",
        axis.title = element_text(size = 8),
        legend.title = element_text(size = 6)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey40")
```




### Zentrieren √§ndert nichts an den Vorhersagen

Betrachten wir die Vorhersagen von `m10.4`: 

```{r Thema6-Teil2-8, echo = TRUE}
new <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))
pred_new <- posterior_predict(m10.4, newdata = new)
mean(pred_new)
```

Und vergleichen wir mit diesen die Vorhersagen von `m10.5`: 

```{r Thema6-Teil2-9, echo = TRUE}
new <- tibble(mom_hs = 0, mom_iq_c = 0)
pred_new <- posterior_predict(m10.5, newdata = new)
mean(pred_new)
```

Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.


Auch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): $\sigma_{m10.4}= `r round(sigma(m10.4))`$; $\sigma_{m10.5}= `r round(sigma(m10.5))`$.


Das Zentrieren √§ndert auch *nicht* die Regressionskoeffizienten, da die Streuungen der Pr√§diktoren nicht ver√§ndert wurden.





### Perzentilintervalle aus der Posterori-Verteilung

@tbl-m105 zeigt die Punktsch√§tzer der Parameter f√ºr m10.5 sowie ihre Perzentilintervalle^[auch ETI (Equal Tails Interval) genannt].
Nutzen Sie daf√ºr `parameters(m10.5)`, s. @tbl-m105.

```{r}
#| tbl-cap: "Parameter von m10.5 und ETIs"
#| echo: false
#| label: tbl-m105
parameters(m10.5) %>% 
  display()
```



Highest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich  komfortabel ausgeben lassen mit `hdi(m10.5)` oder mit `parameters(m10.5, ci_method = "hdi")`,
s. @tbl-m105-hdi.

```{r Thema6-Teil2-11}
#| tbl-cap: "Parameter von m10.5 und HDIs"
#| label: tbl-m105-hdi
parameters(m10.5, ci_method = "hdi") %>% 
  display()
```

Im Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.



### Beantworten der Forschungsfrage

>   Das Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei M√ºttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]). Hingegen fand sich ein Effekt der m√ºtterlichen Intelligenz; pro Punkt Unterschied in m√ºttlerlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte (95%PI). Au√üerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei M√ºtter mit Schulabschluss war der Zusammenhang zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).

</br>
</br>


```{r}
#| echo: false
if (knitr:::is_html_output()) {
  icon_style(fontawesome("bomb", style = "solid"), scale = 2, fill = "red")
}
```


:::callout-important
Das Modell macht *keine* kausalen Aussagen. Es werden lediglich Unterschiede bzw. Zusammenh√§nge beschrieben.
F√ºr kausale Aussagen ist mehr n√∂tig, als einen statistischen Zusammenhang festzustellen.
:::


















## Eine nominale UV mit mehreren Stufen




### Forschungsfrage

*Hintergrund*:


Nach Ihrem Studium wurden Sie reich als Unternehmensberater:in;
Ihre Kompetenz als Wirtschaftspsychologi war hei√ü begehrt.
Von Statistik wollte niemand etwas wissen...
Doch nach einiger Zeit kamen Sie in eine Sinnkrise.
Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen.
Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot
als Nachwuchswissenschaftler:in.

Ihr Forschungsprojekt f√ºhrte Sie in die Antarktis...
Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.


Ihre Aufgabe bestand nun darin, Pinguine zu untersuchen.
Genauer gesagt ging es um Gr√∂√üenunterschiede zwischen drei Pinguinarten.
Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.




</br>


> Unterscheiden sich die mittleren K√∂rpergewichte der drei Pinguinarten?





Die Modellformel zur Forschungsfrage lautet: `y ~ g`.


Der DAG zur Modellformel sieht aus in @fig-yg dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-yg
#| fig-cap: "DAG f√ºr `y ~ g`"
#| echo: false

mein_modell <- "dag{
g -> y
u -> y
}"

plot(graphLayout(mein_modell))
```


### Alle Mittelwerte sind gleich, exakt gleich (?)

- Formal: $\mu_1 = \mu_2 = \ldots = \mu_k$ mit $k$ verschiedenen Gruppen von Pinguinarten.

- Hypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als *Nullhypothesen* bezeichnen.

- Moment. Dass sich *alle* Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:

> *Wie sehr* unterscheiden sich mittlere K√∂rpergewichte in Abh√§ngigkeit von der Pinguinart?

Alternativ k√∂nnen wir  die Hypothese pr√ºfen, ob die Mittelwerte "praktisch" gleich sind, also sich "kaum" unterscheiden. Der Grenzwert f√ºr "praktisch gleich" bzw. "kaum unterschiedlich" ist subjektiv. Dazu in @sec-rope mehr.



### Erster Blick in den Datensatz `penguins`

![Palmer Penguins](https://repository-images.githubusercontent.com/269674245/19ff8480-ab54-11ea-8932-1de30d253dad)

[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv), [Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/palmerpenguins/penguins.html)

Hier ist die Quelle der Daten:


```{r import-penguins}
penguins_url <- "https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv"

#| results: "hide"
#| message: false
penguins <- 
  read_csv(penguins_url)
```

Hier ist die Verteilung des Gewichts jeder Spezies im Datensatz, @tbl-penguins.

```{r}
#| results: hide
penguins %>% 
  select(body_mass_g, species) %>% 
  group_by(species) %>% 
  describe_distribution(range = FALSE, iqr = FALSE)
```

```{r}
#| echo: false
#| tbl-cap: "Die Verteilung des K√∂rpergewichts pro Spezies der Pinguine"
#| label: tbl-penguins
penguins %>% 
  select(body_mass_g, species) %>% 
  group_by(species) %>% 
  describe_distribution(range = FALSE, iqr = FALSE)
```




Was f√§llt Ihnen auf?



### Visualisierung (EDA)


Hier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, 
s. @fig-penguines1? 




```{r}
#| echo: false
#| label: fig-penguines1
#| fig-cap: "Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violine"
library(ggpubr)
ggviolin(penguins,
          x = "species",
         fill = "species",  # F√ºllfarbe nach `species`
          y = "body_mass_g") +
  scale_fill_okabeito()  #  Farbpalette nach Okabe & Ito
```

<!-- @fig-penguines2 zeigt die Gewichtsverteilung pro Spezies als "Bergr√ºcken" (`geom_ridges`). -->

<!-- ```{r fig.asp = .3, fig.width=7} -->
<!-- #| echo: false -->
<!-- #| label: fig-penguines2 -->
<!-- #| fig-cap: "Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Ridges" -->
<!-- ggplot(penguins) + -->
<!--   aes(x = body_mass_g, y = species) + -->
<!--   geom_density_ridges() -->
<!-- ``` -->

<!-- @fig-penguines3 zeigt die Gewichtsverteilung pro Spezies als "halbe Violinen" (`geom_ridges`),  -->
<!-- sozusagen Dichtediagramme um 90 Grad gedreht. -->

<!-- ```{r} -->
<!-- #| label: fig-penguines3 -->
<!-- #| fig-cap: "Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violindot" -->
<!-- penguins %>%  -->
<!--   ggplot(aes(x = species, y = body_mass_g, fill = species)) + -->
<!--   geom_violindot(fill_dots = "black") -->
<!-- ``` -->






### Mittlere Gewichtsunterschiede in der Population

Berechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. `m10.6` und @tbl-m106-params.



```{r m106, echo = TRUE}
#| results: hide
options(mc.cores = parallel::detectCores())  # Turbo einschalten

m10.6 <- stan_glm(body_mass_g ~ species, 
                  data = penguins, 
                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
                  seed = 42  # zur Reproduzierbarkeit
                  )


m10.6 %>% 
  parameters()
```

```{r}
#| echo: false
#| tbl-cap: "Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen"
#| label: tbl-m106-params
m10.6 %>% 
  parameters() %>% 
  display()
```




### Interpretation von `m10.6`

Die UV hat drei verschiedene Stufen (Werte, Auspr√§gungen; hier: Spezies), aber es werden in @tbl-m106-params nur zwei Stufen angezeigt (also eine weniger) zus√§tzlich zum Achsenabsdhnitt.
Die fehlende Stufe (`Adelie`, nicht ausgegeben) ist die *Vergleichs- oder Referenzkategorie* (baseline) und ist im Achsenabschnitt ausgedr√ºckt (Intercept).
Die Koeffizienten f√ºr `species` geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder.
Pinguine der Spezies `Adelie` haben laut Modell ein mittleres Gewicht von ca. 3700g.
Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies `Adelie`, etc.


Der Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in @fig-m106-params verdeutlicht.

```{r plot-hdi-m106}
#| fig-cap: "Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)"
#| label: fig-m106-params

plot(hdi(m10.6)) + scale_fill_okabeito()
```


Das [Farbschema nach Okabe und Ito](https://jfly.uni-koeln.de/color/) ist gut geeignet, um nominal skalierte Farben zu kodieren (d. [Details hier](https://data-se.netlify.app/2023/06/30/farbpaletten/)).


### Glauben wir jetzt an Gruppeneffekte?

Glauben wir jetzt, auf Basis der Modellparameter,
an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?

Es scheinen sich nicht alle Gruppen voneinander zu unterscheiden. 
So ist der Mittelwert der Gruppe `Gentoo` deutlich h√∂her als der der beiden anderen Gruppen. 
Umgekehrt sind sich die Pinguinarten `Adelie` und `Chinstrap` in ihren Mittelwerten ziemlich √§hnlich.

Wie in @fig-m106-params ersichtlich,
√ºberlappt sich der Sch√§tzbereich f√ºr den Parameter von Gentoo *nicht* mit der Null;
hingegen √ºberlappt sich der Sch√§tzbereich des Parameters f√ºr Chinstrap deutlich mit der Nullinie.



Auf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass *alle* Mittelwerte   *exakt* identisch sind.

Ehrlicherweise h√§tte sowieso (fast) niemand geglaubt, dass die *exakte Nullhypothese* $\mu_1 = \mu_2 = \ldots = \mu_k$ bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.
Aber: Viele Forschis pr√ºfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese.
Das Verfahren der Frequentistischen Statistik, um die Nullhypothese $\mu_1 = \mu_2 = \ldots = \mu_k$ zu testen, nennt man *Varianzanalyse* (analysis of variance, kurz *ANOVA*).
In der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art)  inferenzstatistisch zu beurteilen.








## Priori-Werte

Unser Modell `m10.6` hat schwach informierte (weakly informative) Priors.
F√ºr Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:

- Achsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen
- mit Mittelwert entsprechend den Stichprobendaten 
- und einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht
- f√ºr Sigma wird eine Exponentialverteilung mit Rate $\lambda=1$ angenommen, skaliert mit der Streuung der AV.

Mehr Infos kann man sich so ausgeben lassen: `prior_summary(modell)`:


```{r}
prior_summary(m10.6)
```

Wo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Prioris anpassen wollen, z.B.:

```{r echo = TRUE}
m10.6b <- stan_glm(
  body_mass_g ~ species, 
  data = penguins, 
  refresh = 0,
  seed = 42,
  prior = normal(location = c(0, 0),  # betas, Mittelwert
                 scale = c(500, 500)),  # betas, Streuung
  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung
  prior_aux = exponential(0.001)
)
coef(m10.6b)
```


Anstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher.
Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz `autoscale = TRUE` an.



```{r echo = TRUE}
m10.6c <- stan_glm(
  body_mass_g ~ species, 
  data = penguins, 
  refresh = 0,
  seed = 42,
  prior = normal(location = c(0, 0),  # betas, Mittelwert
                 scale = c(2.5, 2.5),  # betas, Streuung
                 autoscale = TRUE),  # in z-Einheiten
  prior_intercept = normal(4200, 2.5,   # Achsenabschnitt, Mittelwert und Streuung
                           autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE)
)
coef(m10.6c)
```





Den Parameter f√ºr die Streuung des Modells, $\sigma$, kann man sich mit `sigma(modell)` ausgeben lassen:

```{r}
sigma(m10.6b)
```



Implizit bekommt man die Informationen zu $\sigma$ mitgeteilt durch die Gr√∂√üe der Konfidenzintervalle.

√úbrigens macht es meistens keinen Sinn, extrem weite Prioris zu definieren^[s. Details [hier](https://mc-stan.org/rstanarm/articles/priors.html#how-to-specify-flat-priors-and-why-you-typically-shouldnt).].



### Wechsel der Referenzkategorie

- `species` ist eine nominale Variable, da passt in R der Typ `factor` (Faktor) am besten. Aktuell ist der Typ noch `character` (Text):

```{r echo = TRUE}
penguins <- penguins %>% 
  mutate(species = factor(species))
```


Im Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern. 

```{r echo = TRUE}
levels(penguins$species)
```

Setzen wir `Gentoo` als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:

```{r echo = TRUE}
library(forcats)
penguins <- penguins %>% 
  mutate(species = factor(species),
    species = fct_relevel(species, "Gentoo"))
```

Beachten Sie, dass dazu das Paket `forcats` verf√ºgbar sein muss.

Jetzt haben wir die Referenzkategorie ge√§ndert:


```{r}
levels(penguins$species)
```









Der Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell, s. @tbl-m106a.

```{r echo = TRUE}
#| results: hide
m10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)
hdi(m10.6a)
```


```{r}
#| echo: false
#| tbl-cap: "m10.6a mit ge√§nderter Referenzkategorie; die Effekte der UVs bleiben gleich."
#| label: tbl-m106a
m10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)
hdi(m10.6a) |> display()
```












## Modellg√ºte mit R-Quadrat bestimmen

### Modellg√ºte mit $R^2$ bestimmen



$R^2$ gibt den Anteil der Gesamtvarianz (der AV) an, den das Modell erkl√§rt.
- H√∂here Wert von $R^2$ bedeuten, dass das Modell die Daten besser erkl√§rt.
$R^2$ wird normalerweise auf Basis eines Punktsch√§tzers definiert.
Solch eine Definition l√§sst aber viel Information - √ºber die Ungewissheit der Sch√§tzung - au√üen vor.
Daher ist es w√ºnschenswert, diese Information in $R^2$ einflie√üen zu lassen: *Bayes-R-Quadrat*.





<!-- R^2_{Bayes} = \frac{\text{erkl√§rte Varianz}}{\text{erk√§rte Varianz + Residualvarianz}} = \frac{var_{fit}}{var_{fit}+var_{res}} -->

<!-- - $var_{fit}$ ist die Varianz der vorhergesagten Sch√§tzwerte $\hat{y}_i$. -->



```{r echo = TRUE}
r2(m10.6)
```


M√∂chte man es ausf√ºhrlicher, und im Komfort einer Bayes-Analyse schwelgen,
so kann man sich die Posteriori-Verteilung von $R2$ ausgeben lassen, s. @fig-m106-r2.

```{r}
#| fig.cap: "Die Verteilung von R-Quadrat im Modell m10.6"
#| label: fig-m106-r2
m10.6_r2 <-
m10.6 %>% 
  r2_posterior() %>% 
  as_tibble()

hdi(m10.6_r2) %>% 
  plot()
```




### Definition vom "klassischen" $R^2$




Wie genau sind die Vorhersagen des Modells? $\sigma$ (Vorhersagefehler) quantifiziert die Streuung der Residuen $r_i = y_i - X_i\hat{\beta}$, mit $\hat{y}_i = X_i\hat{\beta}$. 
Anders gesagt: $\hat{y} = \beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots = X\hat{\beta}$.
Anders gesagt gibt $\sigma$ die "typische" Abweichung einer Beobachtung vom vorhergesagten Wert an.
Es ist n√ºtzlich, $\sigma$ in Bezug zu setzen zur Streuung der AV, $sd_y=s_y$:
$R^2 = 1- (\hat{\sigma}^2/s^2_y)$.
$R2$ gibt damit den Anteil der vom Modell erkl√§rten Varianz, $V$, an.
Berechnet man das Modell mit der Methode der kleinsten Quadrate (nicht mit Bayes), dann ist der obige Ausdruck √§quivalent zu:
$R^2=V_{i=1}^n \hat{y}_i/s_y^2$
Die beiden obigen Ausdr√ºcke nehmen $\hat{y}_i$ als fix (sicher) an und vernachl√§ssigen Ungewissheit; sie sind √ºbergewiss aus Bayes-Sicht.




### Bayes' $R^2$

Besser ist es (aus Bayes-Sicht), die Ungewissheit der Vorhersagen bei der Berechnung der Modellg√ºte miteinzubeziehen:
$\text{Bayes }R^2 = \frac{\text{erk√§rte Varianz}}{\text{Erkl√§rte Varianz + Residualvarianz}}= \frac{V_{mod}}{V_{mod} + V_{res}}$.

$V_{mod}$ ist die Varianz in der PPV mit $s = 1, \ldots, S$ simulierten Stichproben, $V(\hat{y}_i)$ und $V_{res}$ ist die Residualvarianz im Modell.
F√ºr jede Stichprobe $s$ berechnet man die vorhergesagten Werte, $\hat{y}_i^s$, die Residualvarianz $\sigma^2_s$ und den Anteil der erkl√§rten Varianz:
$\text{Bayes }R^2_s = \frac{V(\hat{y}_i^s)}{V(\hat{y}_i^s+\sigma_s^2)}$, vgl. 
@gelman_r_squared_2019, @gelman_regression_2021, Kap. 11.7.





## Nullhypothesen sind praktisch immer falsch  {#sec-rope}



Nullhypothesen sind fast immer falsch, s. @fig-nullmeme.


```{r meme-null}
#| echo: false
#| label: fig-nullmeme
#| fig-cap: "Du testest Nullhypothesen?"
knitr::include_graphics("img/5v5531.jpg")
```

[Quelle: Imgflip Meme Generator](https://imgflip.com/i/5v5531)







>   We do not generally use null hypothesis significance testing in our own work. In the fields in which we work, we do not generally think null hyptheses can be true: in social science and public health, just about every treatment one might consider will have *some* effect, and no comparison or regression coefficient of interest will be exactly zero. We do not find it particularly helpful to formulate and test null hypothess that we knowe ahead of time cannot be true.


@gelman_regression_2021






### Alternativen zu Nullhypothesen


Nullhypothesen, $H_0$, sind z.B.: $\rho=0$, $\rho_1 = rho_2$, $\mu_1 = \mu_2$, $\mu=0$, $\beta_1=0$.
Nullhypothesen zu testen, ist sehr verbreitet.
Ein Grund ist, dass in der Frequentistischen Statistik keine andere Art von Hypothesentest m√∂glich ist^[Mittlerweile gibt es Ans√§tze f√ºr einem Verfahren √§hnlich dem ROPE-Ansatz, der weiter unten vorgestellt wird.]

Ein anderer Grund ist vermutlich, ... wir haben es schon immer so gemacht.

Alternativen zum Testen von Nullhypothesen sind: 

- Posteriori-Intervalle (PI oder HDI) berichten
- Rope-Konzept [@kruschke_rejecting_2018]
- Wahrscheinlichkeit von inhaltlich bedeutsamen Hypothesen quantifizieren.
- Wahrscheinlichkeit quantifizieren, dass der Effekt ein positives bzw. ein negatives Vorzeichen hat.






### "Praktisch" kein Unterschied: Das Rope-Konzept



Sagen wir, wenn sich zwei Preismittelwerte um h√∂chstens $d=100$‚Ç¨ unterscheiden, gilt dieser Unterschied f√ºr uns als "praktisch gleich", "praktisch kein Unterschied" bzw. vernachl√§ssigbar.
Nimmt man (praktisch) keinen Unterschied/Zusammenhang/Effekt an, spricht man von einer *Nullhypothese*: $H_0$.
Die Wahl von $d$ ist *subjektiv* in dem Sinne als sie von inhaltlichen √úberlegungen geleitet sein sollte.
Diesen Bereich bezeichnen wir den *Indifferenzbereich* (√Ñquivalenzzone, Bereich eines vernachl√§ssigbaren Unterschieds oder *Region of practical equivalence*, Rope). 
Jetzt pr√ºfen wir, ob ein "Gro√üteil" der Posteriori-Stichproben im Rope liegt.
Unter "Gro√üteil" wird h√§ufig das *95%-HDI* verstanden (das ist auch der Standard der R-Funktion `rope()`, die wir hier nutzen).



*Entscheidungsregel* nach @kruschke_rejecting_2018:

- Gro√üteil liegt *innerhalb* von Rope  ‚û°Ô∏è *Annahme* der Nullhypothese "praktisch kein Effekt", $H_0$
- Gro√üteil liegt *au√üerhalb* von Rope  ‚û°Ô∏è *Ablehnung* der Nullhypothese "praktisch kein Effekt", $H_0$
- Ansonsten  ‚û°Ô∏è  keine Entscheidung 






### HDI-Rope-Entscheidungsregel visualisiert

```{r out.width="100%"}
#| echo: false
#| fig-align: "center"
#| fig-cap: "Die Entscheidungsregeln zum ROPE illustiert."
#| label: fig-kruschke-rope
knitr::include_graphics("img/Kruschke-2018-Fig1.png")
```

@fig-kruschke-rope illustriert die Entscheidungsregel zum ROPE 
f√ºr mehrere Situatioenen [@kruschke_rejecting_2018, Abbildung 1, S. 272]:

- Liegt das HDI komplett au√üerhalb des ROPE, verwirft man die Nullhypothese.
- Liegt das HDI komplett innerhalb des ROPE, akzeptiert man die Nullhypothese.
- Ansonsten ist keine Entscheidung m√∂glich; die Datenlage ist unklar.



### Rope berechnen

Den Rope berechnet man mit `rope(model)`.


```{r}
rope(m10.6)
```

Die Faktorstufe `Chinstrap` von `species` hat doch einen betr√§chtlichen Teil ihrer Wahrscheinlichkeitsmasse der Posteriori-Verteilung im ROPE. 

Wir k√∂nnen daher f√ºr diese Gruppe  das ROPE *nicht* verwerfen.

Aber: `Gentoo` liegt zu 0% im Rope. F√ºr Gentoo k√∂nnen wir das Rope verwerfen.

Das h√∂rt sich abstrakt an? Dann lassen Sie uns das lieber visualisieren.

:::callout-note
Die angegebenen Prozentwerte beziehen sich nicht auf die 100% der Post-Verteilung, sondern (in der Voreinstellung) auf das 95%-ETI, s. `help(rope)`.
:::


### Visualisierung unserer Rope-Werte, m10.6

- Ein Gro√üteil der Posteriori-Masse von `m10.6` liegt  *nicht* innerhalb des Rope. 
- Aber k√∂nnen wir umgekehrt sagen, dass ein Gro√üteil au√üerhalb liegt? Das erkennt man optisch ganz gut.

```{r fig.asp = .5}
plot(rope(m10.6)) + scale_fill_okabeito()
```


Das ROPE druchkreuzt die "Berge" der Posteriori-Verteilung f√ºr Chinstrap deutlich.
Aber: Das 95%-HDI liegt nicht komplett innerhalb des Rope.
Wir k√∂nnen das Rope f√ºr Chinstrap *nicht verwerfen*, aber auch *nicht best√§tigen*.

Gentoo hingegen wird vom vom Rope nicht durchkreuzt, 
es ist weit entfernt vom "blauen Fluss" des Rope: Gentoo liegt au√üerhalb des Rope. 
Es gibt einen "substanziellen" Unterschied, gr√∂√üer als das ROPE. 
Wir verwerfen die "Praktisch-Null-Hypothese" in diesem Fall.




### Finetuning des Rope

Wir k√∂nnen festlegen, was wir unter "praktischer √Ñquivalenz" verstehen,
also die Grenzen des Ropes ver√§ndern.
Sagen wir, 100 Gramm sind unsere Grenze f√ºr einen vernachl√§ssigbaren Effekt, s. @fig-rope-range.


```{r echo = TRUE, results="hide"}
#| label: fig-rope-range
#| fig-cap: ROPE mit selber eingestellter Grenze von ¬±100 (Gramm)
rope(m10.6, range = c(-100, 100))
plot(rope(m10.6, range = c(-100, 100))) + scale_fill_okabeito()
```






Im Standard werden 95%-HDI berichtet, das kann man so √§ndern, wenn man m√∂chte:

```{r echo=TRUE, eval = FALSE}
rope(m10.6, range = c(-100,100), ci = .89, ci_method = "ETI")
```

`ETI` (equal tails interval) steht f√ºr ein PI.
Jetzt wird berichtet, welcher Teil eines 89%-CI sich im Rope befindet.






### Beantwortung der Forschungsfrage


F√ºr die Spezeis *Gentoo* wurde ein substanzieller Gewichtsunterschied zur Referenzgruppe, Adelie, vom Modell entdeckt. F√ºr *Chinstrap* hingegen  ist keine klare inferenzstatistische Aussage hinsichtlich eines Indifferenzbereichs m√∂glich: Es ist plauibel, laut dem Modell, dass es einen praktisch bedeutsamen Unterschied gibt, aber es ist auch plausibel, dass es keinen praktisch bedeutsamen Unterschied gibt.












## Mehrere metrische UV




### Forschungsfrage

>   Stehen sowohl der IQ der Mutter als auch, unabh√§ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?


- Das ist wieder eine *deskriptive* Forschungsfrage. *Keine* Kausalwirkung (etwa "IQ der Mutter ist die Ursache zum IQ des Kindes") wird impliziert. 
- Es geht rein darum, Zusammenh√§nge in den Daten - bzw. in der Population - aufzuzeigen.
- Viele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. F√ºr solche Fragen ist eine deskriptive Untersuchung nicht geeignet, sondern eine Kausalanalyse ist n√∂tig.


[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/data/main/Data/kidiq.csv) als CSV-Datei oder alternativ:

```{r echo = TRUE}
library(rstanarm)
data("kidiq")
```



### Was hei√üt, X h√§ngt mit Y zusammen?


- Der Begriff "Zusammenhang" ist nicht exakt.
- H√§ufig wird er (f√ºr metrische Variablen) verstanden als
    - lineare Korrelation $\rho$ bzw. $r$ 
    - lineare Regression $\beta$, bzw. $b$ 


- Der Regressionskoeffizient 
    - misst die *Steigung* der Regressionsgerade
    - zeigt, wie gro√ü der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden
    - wird manchmal mit dem "Effekt von X auf Y" √ºbersetzt. Vorsicht: "Effekt" klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begr√ºndung f√ºr einen Kausalzusammenhang. 
    
- Der Korrelationskoeffizient
    - misst eine Art der St√§rke des linearen Zusammenhangs
    - zeigt, wie klein die Vorhersagefehler der zugeh√∂rigen Regrssion im Schnitt sind.
    - [Korrelation ist nicht (automatisch) Kausation.](https://xkcd.com/552/)
    




### Korrelationen zur Forschungsfrage


```{r echo = TRUE, eval = FALSE}
kidiq %>% 
  correlation()
```

```{r}
#| echo: false
kidiq %>% 
  correlation() %>% 
  display()
```


@tbl-kidiq-corr zeigt die Korrelationsmatrix als Korrelationsmatrix:

```{r}
#| eval: false
kidiq %>% 
  correlation() %>% 
  summary()
```

```{r}
#| echo: false
#| label: tbl-kidiq-corr
#| tbl-cap: "Die Korrelationen zwischen den Variablen der Tabelle kidiq"
kidiq %>% 
  correlation() %>% 
  summary() |> 
  display()
```


N√ºtzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, @fig-kidiq-heatmap.

```{r echo = TRUE}
#| label: fig-kidiq-heatmap
#| fig-cap: "Visualisierung der Korrelationsmatrix als Heatmap"
kidiq %>% 
  correlation() %>% 
  summary() %>% 
  plot()
```




### Univariate Regressionen

Wir berechnen jeweils eine univariate Regression, pro Pr√§diktor,
also eine f√ºr `mom_iq` und eine f√ºr `mom_age`.

```{r echo = TRUE}
m10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)
m10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)
```

Hier die Ergebnisse f√ºr `mom_iq`:

```{r echo = TRUE}
coef(m10.7)
```

Hier die Ergebnisse f√ºr `mom_age`:


```{r echo = TRUE}
coef(m10.8)
```




### Visualisierung der univariaten Regressionen

In @fig-regr-one-pred ist die univariate Regression mit jeweils einem der beiden Pr√§diktoren dargestellt.


`m10.7`: Die Steigung betr√§gt `r round(coef(m10.7)[2], 1)`.
`m10.8`: Die Steigung betr√§gt `r round(coef(m10.8)[2], 1)`.




```{r p1-p2}
#| fig-cap: Zwei univariate Regressionen
#| label: fig-regr-one-pred
#| echo: false
p1 <- 
  kidiq %>% 
  ggplot(aes(x = mom_iq, y = kid_score)) +
  geom_point() +
  geom_abline(intercept = coef(m10.7)[1],
              slope = coef(m10.7)[2],
              color = "blue") 

p2 <- 
kidiq %>% 
  ggplot(aes(x = mom_age, y = kid_score)) +
  geom_point() +
  geom_abline(intercept = coef(m10.8)[1],
              slope = coef(m10.8)[2],
              color = "blue")

plots(p1, p2,
      title = c("m10.7: Die univariate Regression mit dem Alter der Mutter als Pr√§diktor",
        "m10.8: Die univariate Regression mit dem IQ der Mutter als Pr√§diktor"))
```


Univariate Regressionen




### Multiples Modell (beide Pr√§diktoren), m10.9


`m10.9` stellt das multiple Regressionsmodell dar;
*multipel* bedeutet in diesem Fall, dass mehr als ein Pr√§diktor im Modell aufgenommen ist.


```{r m109, echo = TRUE}
#| message: false
m10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, 
                  data = kidiq, 
                  refresh = 0)
coef(m10.9)
```


:::callout-important
Die Regressionsgewichte unterscheiden sich zu den von den jeweiligen univariaten Regressionen.
:::


- Bei einer multiplen Regression ist ein Regressionsgewicht jeweils "bereinigt" vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.
- Das bedeutet, man betrachtet den den Zusammenhang eines Pr√§diktors mit der AV, wobei man gleichzeitig den anderen Pr√§diktor konstant h√§lt.

```{r echo = TRUE}
coef(m10.9)
```




### 3D-Visualisierung eines Modells mit zwei Pr√§diktoren 1

In @fig-m109-plotly ist das Modell `m10.9` in 3D dargestellt via [Plotly](https://plotly.com/r/).

```{r m109-plotly, out.width = "100%", fig.align="center"}
#| echo: false
#| label: fig-m109-plotly
#| fig-cap: "3D-Visualisierung von m10.9 (zwei Pr√§diktoren)"
lm1_coef <- coef(m10.9)
x1_seq <- seq(min(kidiq$mom_iq), max(kidiq$mom_iq), length.out = 25)
x2_seq <- seq(min(kidiq$mom_age), max(kidiq$mom_age), length.out = 25)

z <- t(outer(x1_seq, x2_seq, 
              function(x,y) lm1_coef[1]+lm1_coef[2]*x+lm1_coef[3]*y))

if (knitr:::is_html_output()) {
plot_ly(width = 800, height = 500,
  x=~x1_seq, y=~x2_seq, z=~z,type="surface") %>%
  add_trace(data=kidiq, 
            x=~mom_iq, y=~mom_age, z=~kid_score, 
            mode="markers", 
            type="scatter3d",
            marker = list(color="#00998a", 
                          opacity=0.7, 
                          size = 1,
                          symbol=105)) %>% 
  layout(scene = list(
    aspectmode = "manual", 
    aspectratio = list(x=1, y=1, z=1),
    xaxis = list(title = "mom_iq"),
    yaxis = list(title = "mom_age"),
    zaxis = list(title = "kid_score")))
}

if (knitr:::is_latex_output()) {
  knitr::include_graphics("img/m109-plotly.jpg")
}
```





### Visualisierung mit Farbe statt 3. Dimension

3D-Visualisierungen haben Vorteile, aber auch Nachteile;
@fig-m109-color zeigt eine alternative Visualisierung,
in der die 3. Dimension durch eine Farbschattierung ersetzt ist.


```{r fig-m109-color, fig.asp = .5}
#| echo: false
#| label: fig-m109-color
#| fig-cap: "Modell m10.9; die Farbverl√§ufe zeigen der Wert der abh√§ngigen Variablen"
kidiq <-
  kidiq %>%
  mutate(pred_m10.9 = predict(m10.9))

grid1 <- expand_grid(mom_iq = x1_seq, mom_age =  x2_seq) %>% 
  mutate(pred_m10.9 = predict(m10.9, newdata = data.frame(mom_iq,
                                                              mom_age)))

ggplot(aes(x = mom_iq, y = mom_age), data = grid1) +
  geom_raster(aes(fill = pred_m10.9)) +
 # geom_point(aes(color = kid_score_pred)) +
  scale_fill_viridis_c() +
  scale_color_viridis_c() +
  geom_point(data = kidiq,  alpha = .3, size = .7)
```


Auf der Achse von mom_iq erkennt man deutlich (anhand der Farb√§nderung) die Ver√§nderung f√ºr die AV (kid_score). Auf der Achse f√ºr `mom_age` sieht man, dass sich die AV kaum √§ndert, wenn sich `mom_age` √§ndert.




### Visualisierung in 10 Dimensionen

@fig-ten-dims visualisiert den Zusammenhang von 10 Variablen untereinander.

```{r plot-ten-dims, out.width="50%"}
#| fig-align: "center"
#| echo: false
#| label: fig-ten-dims
#| fig-cap: "So sieht der Zusammenhang im 10-dimensionalen Raum aus"
ggplot(data.frame(x=NA, y=NA)) +
  theme(panel.background = element_rect(fill = 'lightblue'))
```

Leider macht mein Hirn hier nicht mit. Unsere Schw√§chen, eine gro√üe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.

Daher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.







### Relevanz der Pr√§diktoren


Woher wei√ü man,
welcher Pr√§diktor am st√§rksten mit der AV zusammenh√§ngt?
Man k√∂nnte auch sagen: Welcher Pr√§diktor (welche UV) am "wichtigsten" ist
oder den "st√§rksten Einfluss" auf die AV aus√ºbt?
Bei solchen kausal konnotierten Ausdr√ºcken muss man vorsichtig sein:
Die Regressionsanalyse als solche ist keine Kausalanalyse.
Die Regressionsanalyse - wie jede statistische Methoden - kann
f√ºr sich *nur Muster in den Daten*, also Zusammenh√§nge bzw. Unterschiede,
entdecken, s. @fig-how-would-i-know.


![Made at imgflip.com](img/5sps62.jpg){#fig-how-would-i-know width=50%}








Welcher Pr√§diktor ist nun "wichtiger" oder "st√§rker" in Bezug auf den Zusammenhang mit der AV, `mom_iq` oder `mom_age` (Modell `m10.9`)?

- `mom_iq` hat den gr√∂√üeren Koeffizienten.
- `mom_age` hat weniger Streuung.


Um die Relevanz der Pr√§diktoren vergleichen zu k√∂nnen, m√ºsste man vielleicht die Ver√§nderung von `kid_score` betrachten, wenn man von kleinsten zum gr√∂√üten Pr√§diktorwert geht.
Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden).
Sinnvoller ist es daher, die Ver√§nderung in der AV zu betrachten, wenn man den Pr√§diktor von "unterdurchschnittlich" auf "√ºberdurchschnittlich" √§ndert.
Das kann man mit *z-Standardisierung* erreichen.







### z-Standardisierung




*z-Standardisierung* bedeutet, eine Variable so zu transformieren, dass sie √ºber einen Mittelwert von 0 und eine SD von 1 verf√ºgt:

$$z = \frac{x - \bar{x}}{sd(x)}$$

```{r kidiq2, echo = TRUE}
data("kidiq")
kidiq2 <- 
  kidiq %>% 
  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>% 
  select(mom_iq, mom_iq_z) %>% 
  head()
```


Der Nutzen von Standardisieren (dieser Art) ist die bessere Vergleichbarkeit von Variablen, die (zuvor) verschiedene Mittelwerte und Streuungen hatten^[am n√ºtzlichsten ist diese Standardisierung bei normal verteilten Variablen.].
Die Standardisierung ist √§hnlich zur Vergabe von Prozentr√§ngen: "Dieser Messwert geh√∂rt zu den Top-3-Prozent".
Diese Aussage ist bedeutsam f√ºr Variablen mit verschiedenem Mittelwert und Streuung.
So werden vergleichende Aussagen f√ºr verschiedene Verteilungen m√∂glich.






### Statistiken zu den z-transformierten Variablen

@tbl-kidiq1 zeigt die Verteilung der (metrischen) Variablen im Datensatz `kidiq`.

Metrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:

- der Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Auspr√§gung bezieht)
- Interaktionen sind einfacher zu interpretieren (aus dem gleichen Grund)
- Prioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)
- die Effekte verschiedener Pr√§diktoren sind einfacher in ihrer Gr√∂√üe zu vergleichen, da dann mit gleicher Skalierung/Streuung
- kleine und √§hnlich gro√üe Wertebereich erleichtern dem Golem die Rechenarbeit


Man kann die z-Transformation ("Skalierung") mit `standardize` (aus `easystats`) durchf√ºhren, s. @tbl-kidiq-z.


```{r kidiq-stand}
kidiq_z <- 
  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte
```



```{r kidiq-stand-print}
#| label: tbl-kidiq-z
#| tbl-cap: "z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)"
#| echo: false
standardize(kidiq, append = TRUE) |> 
  head() |> 
  display()
```


Der Schalter `append = TRUE` sorgt daf√ºr, dass die urspr√ºnglichen Variablen beim z-Standardisieren nicht √ºberschrieben werden, sondern angeh√§ngt werden (mit einem Suffix `_z`).


Man kann auch nur einzelne Variablen mit `standardize` standardisieren, indem man das Argument `select` nutzt.

```{r}
#| eval: false
kidiq %>% 
  standardize(select = c("mom_iq", "mom_age", "kid_score"))
```



Man kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. @tbl-scale-manual.
Dazu verwendet man den Befehl `scale()`.

```{r}
#| eval: false
kidiq %>% 
  mutate(mom_iq_z2 = scale(mom_iq),
         mom_age_z2 = scale(mom_age),
         kid_score_z2 = scale(kid_score))
```


```{r echo = TRUE}
#| echo: false
#| label: tbl-scale-manual
#| tbl-cap: Z-Standardisierung ohne Extrapaket"
data(kidiq)
kidiq %>% 
  mutate(mom_iq_z2 = scale(mom_iq),
         mom_age_z2 = scale(mom_age),
         kid_score_z2 = scale(kid_score)) %>% 
  head()
```




## Modell `m10.10`

Im Modell `m10.10` sind die Pr√§diktoren z-standardisiesrt.
Das Standardisieren der AV, `kid_score` ist *nicht* n√∂tig, um den Effekt der Pr√§diktoren (UV) auf die AV zu untersuchen.
Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage dar√ºber,
um wie viele *SD-*Einheiten sich die AV ver√§ndert, wenn sich ein Pr√§diktor um eine *SD-*Einheit ver√§ndert.

```{r m10-10, echo = TRUE}
m10.10 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, 
                   data = kidiq_z, 
                   refresh = 0)
coef(m10.10)
```


- Der *Achsenabschnitt* gibt den Mittelwert der AV (`kid_score`) an, da `kid_score_z = 0` identisch ist zum Mittelwert von  `kid_score`.
- Der Koeffizient f√ºr `mom_iq_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) √§ndert, wenn sich `mom_iq` um eine SD-Einheit √§ndert. 
- Der Koeffizient f√ºr `mom_age_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) √§ndert, wenn sich `mom_age` um eine SD-Einheit √§ndert.



Jetzt sind die Pr√§diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar: 

- Man sieht, dass die Intelligenz der Mutter *deutlich wichtiger* ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).




### 95%-PI


Mit `parameters` k√∂nnen wir uns ein PI f√ºr `m10.10` ausgeben lassen, s. @fig-m1010hdi;
 im Standard wird ein 95%-ETI berichtet^[Zumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen k√∂nnen sich √§ndern. Am besten in der Dokumentation nachlesen: `?parameters`.].


```{r m10-10-params-noeval, echo = TRUE}
#| eval: false
parameters(m10.10) 
```

```{r m1010-params}
#| echo: false
parameters(m10.10) %>% display()
```



```{r 1010-params-plot}
#| label: fig-m1010hdi
#| fig-cap: "Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI f√ºr m10.10"
plot(eti(m10.10)) + scale_fill_okabeito()
```




### Was ist ein kleiner, was ein gro√üer Effekt?

@cohen_statistical_1988 definiert Effektst√§rken in Bezug auf Mittelwertsvergleiche anhand von $d=(\mu_1 - \mu_o) / \sigma$.
F√ºr kleine, mittlere und gro√üe Werte gab er folgende Richtwerte:

- klein: $d \approx 0.2$
- mittel: $d \approx 0.5$
- gro√ü: $d \approx 0.8$

Auf dieser Basis schl√§gt @kruschke_rejecting_2018 einen Rope von $\pm0.1$ vor.
F√§llt ein Intervall (mit vorab definierter Sicherheit, z.B. 95%) komplett in das Rope, so gilt der Effekt als "praktisch null".
Richtlinien f√ºr Effektst√§rken sind nur Notl√∂sungen, die durch  Sachverstand ersetzt werden sollen, wo immer m√∂glich.
Man kann Effektst√§rken ineinander √ºberf√ºhren, s. [hier](https://www.escal.site/), z.B. von Korrelation (*r*) zu Cohens *d* oder $R^2$.




### Vernachl√§ssigbarer Regressionseffekt

@kruschke_rejecting_2018 schl√§gt vor, einen Regressionskoeffizienten unter folgenden Umst√§nden als "praktisch Null" zu bezeichnen:



Wenn eine Ver√§nderung √ºber "praktisch den ganzen Wertebereich" von $x$ nur einen vernachl√§ssigbaren Effekt auf $y$ hat.
Ein vernachl√§ssigbarer Effekt ist dabei $\hat{y}= \pm 0.1 sd_y$.
Der "praktisch ganze Wertebereich" von $x$ sei $\bar{x} \pm 2 sd_x$.
Resultiert der Vergleich von $\bar{x} -2 sd$ mit $\bar{x}+2sd$ nur eine Ver√§nderung in $\hat{y}$ von $\bar{y} - 0.1sd_y$ auf $\bar{y} + 0.1 sd_y$, so ist der Regressionskoeffizient praktisch Null, der Effekt also vernachl√§ssigbar.
Das impliziert Rope-Grenzen von $\beta_x = \pm 0.05$ f√ºr z-standardisierte Variablen.








### Modellg√ºte

```{r m10-10-r2}
r2(m10.10)
```


Ist dieser Wert von $R2$ "gut"?
Diese Frage ist √§hnlich zur Frage "Ist das viel Geld?"; 
man kann die Frage nur im Kontext beantworten.

Eine einfache L√∂sung ist immer, Modelle zu vergleichen.
Dann kann man angeben, welches Modell die Daten am besten erkl√§rt,
z.B. auf Basis von $R^2$.

Zu beachten ist, dass das Modell theoretisch fundiert sein sollte.
Vergleicht man viele Modelle aufs Geratewohl, so muss man von zuf√§llig hohen Werten der Modellg√ºte im Einzelfall ausgehen.


Wenn Sie aber unbedingt eine "objektive" Antwort auf die Frage "wie viel ist viel?" haben wollen,
ziehen wir Herrn Cohen zu Rate:


```{r}
interpret_r2(0.2)  # aus `easystats`
```

Danke, Herr Cohen!


### Priori-Verteilung f√ºr `m10.10` und Modelldefinition

Stan hat f√ºr uns folgende Prioris ausgesucht:


```{r m10-10-prior}
prior_summary(m10.10)  # aus rstanarm
```


Wie gesagt, Stan nimmt daf√ºr einfach die empirischen Mittelwerte und Streuungen her^[Nicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Sch√§tzer der echten Parameter sein m√ºssten, wenn die Stichprobe, die wir ihm angeschleppt h√§tten, tats√§chlich gut ist...].

Stans Ausgabe kann man in Mathe-Sprech so darstellen, s. @eq-m1010.


$$
\begin{aligned}
\text{kidscore}  &\sim \mathcal{N}(0,2.5)\\
\mu_i &= \alpha + \beta_1\text{momiq}_i + \beta_2\text{momage}_i \\
\alpha &\sim \mathcal{N}(0,2.5)\\
\beta_1 &\sim \mathcal{N}(0,2.5)\\
\beta_2 &\sim \mathcal{N}(0,2.5)\\
\sigma &\sim \mathcal{E}(1)
\end{aligned}
$${#eq-m1010}

Man beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird:
Bei *mittlerer* Intelligenz und *mittlerem* Alter der Mutter wird *mittlere* Intelligenz des Kindes erwartet in `m10.10`. 
Dadurch, dass nicht nur UV, sondern auch AV zentriert (und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.

Schreibt man einen Bericht, so bietet es sich an, die Modelldefinition *zumindest* im Anhang aufzuf√ºhren.


### Beantwortung der Forschungsfrage



>   Das Modell spricht sich klar f√ºr einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erk√§rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm [@goodrich_rstanarm_2020] zur√ºck (s. Anhang f√ºr Details).



:::callout-important
Hier wird von einem "statistischen Effekt" gesprochen, um klar zu machen, dass es sich lediglich um assoziative Zusammenh√§nge, und nicht um kausale Zusammenh√§nge, handelt.
Kausale Zusammenh√§nge d√ºrfen wir nur verk√ºnden, 
wenn wir sie a) explizit untersuchen, b) sich in der Literatur Belege daf√ºr finden oder c) wir ein  Experiment fachgerecht durchgef√ºhrt haben.
:::






## Vertiefung


üèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è








### Verwandtheit von Korrelation und Regression


 Sind X und Y *z-standardisiert*, so sind Korrelation und Regression identisch.


$$b = r \frac{sd_x}{sd_y}$$

Berechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen 
und betrachten die Punktsch√§tzer f√ºr die Regressionskoeffizienten:

```{r m10-11, echo = TRUE}
m10.11 <- 
  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)
coef(m10.11)
```

Vergleichen Sie diese Werte mit der Korrelation, s. @tbl-m10.11-corr.^[Ignorieren Sie die Zeile mit dem Befehl `display()`. Dieser Befehl dient nur dazu, die Ausgabe zu versch√∂nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.]

```{r}
#| label: tbl-m10.11-corr
#| fig-cap: "Korrelationen der z-transformierten Variablen im Datensatz kidiq"

kidiq_z %>% 
  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% 
  correlation() |> 
  display()
```






### Pr√ºfen der Linearit√§tsannahme


Zentrale Annahme: Die AV ist eine *lineare* Funktion der einzelnen Pr√§diktoren: 

$$y= \alpha + \beta_1x_1 + \beta_2 x_2 + \cdots .$$ 

Hingegen ist es weniger, dass die AV (y) normalverteilt ist.
Zwar nimmt die Regression h√§ufig normalverteilte Residuen an, aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu sch√§tzen [@gelman_regression_2021].





Ist die Linearit√§tsannahme erf√ºllt, so sollte der Residualplot nur *zuf√§llige* Streuung um $y=0$ herum zeigen, s. @fig-kidiqresiduum.


Ein Residuum $e$ ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tats√§chlichem Wert:


$e_i = y_i - \hat{y}_i$

```{r kidiq-def}
kidiq <-
  kidiq %>% 
  mutate(m10.10_pred = predict(m10.10),  # vorhergesagten Werte
         m10.10_resid = resid(m10.10))  # Residuen
```



```{r fig.asp = .5}
#| label: fig-kidiqresiduum
#| fig-cap: "Die Verteilung der Fehler scheint keinem starken Trend (in Abh√§ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist."
kidiq %>% 
  ggplot(aes(x = m10.10_pred, y = m10.10_resid)) +
  geom_hline(color="white", yintercept = 0, size = 2) +
  geom_hline(color = "grey40", 
             yintercept = c(-1,1), 
             size = 1, 
             linetype = "dashed") +
  geom_point(alpha = .7) +
  geom_smooth()
```

Hier erkennt man keine gr√∂√üeren Auff√§lligkeiten.







### Modellpr√ºfung mit der PPV


```{r m10-10-pp-check, echo = TRUE, fig.asp = .5}
pp_check(m10.10)
```

Unser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, $y_{rep}$ verfehlt den Mittelwert von $y$ leider recht h√§ufig.





### Visualisierung der bereinigten Regressionskoeffizienten


```{r kidiq3}
#| echo: false
set.seed(42)
data(kidiq)
kidiq3 <- 
  kidiq %>% 
  standardize(append = TRUE) %>% 
  sample_n(size = 300)

#| results: "hide"
m10.10a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)
m10.10b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)

kidiq3 <-
  kidiq3 %>% 
  mutate(mom_age_resid = resid(m10.10a)) %>% 
  mutate(mom_iq_resid = resid(m10.10b))


m10.10c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)
m10.10d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)


kidiq3 <-
  kidiq3 %>% 
  mutate(m10.10c_resid = resid(m10.10c)) %>% 
  mutate(m10.10d_resid = resid(m10.10d))
```


```{r comp-resid-lm-plot-kidiq3}
#| echo: false
m10.10a_plot <-
  kidiq3 %>% 
  ggplot() +
  aes(x = mom_iq_z, y = mom_age_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.10a)[2],
              intercept = coef(m10.10a)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m10.10a),
                   x = mom_iq_z,
                   xend = mom_iq_z,
                   yend = mom_age_z),
               color = "skyblue3",
               alpha = .1) +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))


m10.10b_plot <-
  kidiq3 %>% 
  ggplot() +
  aes(y = mom_iq_z, x = mom_age_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.10b)[2],
              intercept = coef(m10.10b)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m10.10b),
                   x = mom_age_z,
                   xend = mom_age_z,
                   yend = mom_iq_z),
               color = "skyblue3",
               alpha = .1)  +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))


m10.10c_plot <-
  kidiq3 %>%
  ggplot() +
  aes(x = mom_age_resid, y = kid_score_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.10c)[2],
              intercept = coef(m10.10c)[1],
              color = "blue")   +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))



m10.10d_plot <-
  kidiq3 %>% 
  ggplot() +
  aes(x = mom_iq_resid, y = kid_score_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.10d)[2],
              intercept = coef(m10.10d)[1],
              color = "blue")  +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))

```


```{r resid-lm-plot, fig.asp = .619}
#| echo: false
#| fig-cap: "Bereinigte Regressionskoeffizienten"
#| label: fig-bereinigt
plots(m10.10a_plot, m10.10b_plot, m10.10c_plot, m10.10d_plot, 
      n_rows = 2, tags = "A",
      caption = "Die vertikalen Balken zeigen die Residuen.",
      guides = "collect")
```














@fig-bereinigt zeigt in der oberen Reihe die Regression eines Pr√§diktors auf den anderen Pr√§diktor.
Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, `kid-score_z`. 
Unten links (C): Die Residuen von `mom_iq_c` sind kaum mit der AV assoziiert. Das hei√üt, nutzt man den Teil von `mom_age_z`, der nicht mit `mom_iq_z` zusammenh√§ngt, um `kid_score` vorher zusagen, findet man keinen (*kaum*) Zusammenhang.
Unten rechts (D): Die Residuen von `mom_age_c` sind *stark* mit der AV assoziiert. Das hei√üt, nutzt man den Teil von `mom_iq_z`, der nicht mit `mom_age_z` zusammenh√§ngt, um `kid_score` vorher zusagen, findet man einen starken Zusammenhang.



Eine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).










### Bayesianisch gleich Frequentistisch?





```{r mtcars2}
#| results: "hide"
#| echo: false

mtcars2 <-
  mtcars %>% 
  standardize()

m12a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)
m12b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)

mtcars2 <-
  mtcars %>% 
  mutate(m12a_resid = resid(m12a)) %>% 
  mutate(m12b_resid = resid(m12b))


m12c <- stan_glm(mpg ~ m12a_resid, data = mtcars2, refresh = 0, chains = 1)
m12d <- stan_glm(mpg ~ m12b_resid, data = mtcars2, refresh = 0, chains = 1)


mtcars2 <-
  mtcars2 %>% 
  mutate(m12c_resid = resid(m12c)) %>% 
  mutate(m12d_resid = resid(m12d))
```


```{r comp-resid-lm-plot}
#| echo: false
m12a_plot <-
  mtcars2 %>% 
  ggplot() +
  aes(x = wt, y = disp) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m12a)[2],
              intercept = coef(m12a)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m12a),
                   x = wt,
                   xend = wt,
                   yend = disp),
               color = "skyblue3")



m12b_plot <- 
mtcars2 %>% 
  ggplot() +
  aes(y = wt, x = disp) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m12b)[2],
              intercept = coef(m12b)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m12b),
                   x = disp,
                   xend = disp,
                   yend = wt),
               color = "skyblue3")

m12c_plot <-
  mtcars2 %>%
  ggplot() +
  aes(x = m12a_resid, y = mpg) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m12c)[2],
              intercept = coef(m12c)[1],
              color = "blue")  +
  scale_x_continuous(limits = c(-1,1))



m12d_plot <-
  mtcars2 %>% 
  ggplot() +
  aes(x = m12b_resid, y = mpg) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m12d)[2],
              intercept = coef(m12d)[1],
              color = "blue")   +
  scale_x_continuous(limits = c(-1,1))

```


```{r resid-lm-plot-mtcars}
#| echo: false
#| fig-cap: "Pr√ºfung der Voraussetzungen des Modells"
#| label: fig-resid-lm-plot
#| eval: false
plots(m12a_plot, m12b_plot, m12c_plot, m12d_plot, n_rows = 2, tags = "A",
      guides = "collect")
```


√úbrigens liefern `stan_glm()` und `lm` oft √§hnliche Ergebnisse (bei schwach informativen Prioriwerten):

```{r stan-vs-lm}
stan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()

lm(mpg ~ hp + cyl, data = mtcars) %>% coef()
```


:::callout-important
Wenn auch die  Ergebnisse eines Frequentistischen und Bayes-Modell numerisch √§hnlich sein k√∂nnen, so ist doch die Interpretation grundverschieden. 
Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.
:::





### Post: Bayes in f√ºnf Minuten


Eine Kurzdarstellung des Bayes-Inferenz findet sich [in diesem Post](https://data-se.netlify.app/2022/01/27/bayes-in-f%C3%BCnf-minuten/) und in [diesem](https://data-se.netlify.app/2022/01/28/bayes-in-f%C3%BCnf-minuten-f%C3%BCr-fortgeschrittene/).





## Ausblick: Bin√§re AV


>    *Forschungsfrage:* Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart? (Datensatz `mtcars`)


Dazu nutzen wir den Datensatz `mtcars`, wobei wir die Variablen z-standardisieren.

```{r echo = TRUE}
data(mtcars)
mtcars2 <-
  mtcars %>% 
  standardize(append = TRUE)
```


Dann berechnen wir mit Hilfe von Stan ein Regressionsmodell: `m13: am ~ mpg_z`:

```{r m13, echo = TRUE, results = "show"}
m13 <-
  stan_glm(am ~ mpg_z, 
           data = mtcars2, 
           refresh = 0)
coef(m13)
```

Ab  `mpg_z = `r round(coef(m13),2)`` sagt das Modell `am=1` (manuell) vorher. Ganz ok.




```{r}
mtcars2 %>% 
  ggplot(aes(x = mpg_z, y = am)) +
  geom_hline(yintercept = 0.5, color = "white", size = 2) +
  geom_point() +
  geom_abline(intercept = coef(m13)[1],
              slope = coef(m13)[2],
              color = "blue") 
```


```{r neg-am-predict}
neg_am <- predict(m13, newdata = tibble(mpg_z = -1.3))
```


F√ºr kleine Werte von `mpg_z` (<1.3) sagt unser Modell *negative* Werte f√ºr `am` voraus. Das macht keinen Sinn: Es gibt keine negative Werte von `am`, nur 0 und 1.
M√ºssen wir mal bei Gelegenheit besser machen.







Wir waren flei√üig ... 

```{r}
#| echo: false
if (knitr:::is_html_output()) {
  knitr::include_graphics("https://media.giphy.com/media/XIqCQx02E1U9W/giphy.gif")
}
```

[Quelle](https://giphy.com/gifs/XIqCQx02E1U9W)


Genug f√ºr heute. üëç 





## Fazit



:::callout-important
Kontinuierliches Lernen ist der Schl√ºssel zum Erfolg.
:::



## Aufgaben


1. [Anova-skalenniveau](https://datenwerk.netlify.app/posts/anova-skalenniveau/anova-skalenniveau.html)
2. [Nullhyp-Beispiel](https://datenwerk.netlify.app/posts/nullhyp-beispiel/nullhyp-beispiel)
1. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau.html)
2. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz)
3. [Interaktionseffekt1](https://datenwerk.netlify.app/posts/interaktionseffekt1/interaktionseffekt1)
1. [Regression2](https://datenwerk.netlify.app/posts/regression2/regression2)
2. [Regression3](https://datenwerk.netlify.app/posts/regression3/regression3)
<!-- 3. [Regression6](https://datenwerk.netlify.app/posts/regression6/regression6) -->
<!-- 1. [posterior_interval](https://datenwerk.netlify.app/posts/posterior_interval/posterior_interval.html) -->
2. [diamonds-nullhyp-mws](https://datenwerk.netlify.app/posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html)
3. [stan_glm_parameterzahl](https://datenwerk.netlify.app/posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html)
1. [stan_glm_prioriwerte](https://datenwerk.netlify.app/posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html)
2. [zwert-berechnen](https://datenwerk.netlify.app/posts/zwert-berechnen/zwert-berechnen.html)
3. [Regr-Bayes-interpret](https://datenwerk.netlify.app/posts/regr-bayes-interpret/regr-bayes-interpret)
3. [Regr-Bayes-interpret03](https://datenwerk.netlify.app/posts/regr-bayes-interpret03/regr-bayes-interpret03)
3. [Regr-Bayes-interpret02](https://datenwerk.netlify.app/posts/regr-bayes-interpret03/regr-bayes-interpret02)
2. [rope-regr](https://datenwerk.netlify.app/posts/rope-regr/rope-regr.html)
3. [rope1](https://datenwerk.netlify.app/posts/rope1/rope1.html)
3. [rope2](https://datenwerk.netlify.app/posts/rope2/rope2.html)
3. [rope3](https://datenwerk.netlify.app/posts/rope3/rope3.html)
3. [rope4](https://datenwerk.netlify.app/posts/rope4/rope4.html)









## ---



![](img/outro-10.jpg){width=100%}


