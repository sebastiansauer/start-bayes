
# Fallbeispiele



## Lernsteuerung


### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.




### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen... 

- typische, deskriptive Forschungsfragen spezifizieren als Regression
- Forschungsfragen in Regressionsterme √ºbersetzen
- typische Forschungsfragen auswerten


### Begleitliteratur

Der Stoff dieses Kapitels orientiert sich an @mcelreath2020, Kap. 4.4 sowie @gelman2021, Kap. 7 und 10.



### Vorbereitung im Eigenstudium

Frischen Sie Ihr Wissen in den Grundlagen der einfachen und multiplen Regression (inkl. Interaktionseffekte) auf. Dazu sind z.B. folgende Literaturstellen geeignet.

- [Statistik1, Kap. "Geradenmodelle 1"](https://statistik1.netlify.app/080-regression1)
- [Statistik1, Kap. "Geradenmodelle 2"](https://statistik1.netlify.app/090-regression2)




### R-Pakete

In diesem Kapitel werden die √ºblichen R-Pakete ben√∂tigt.

```{r}
#| message: false
#| results: "hide"
#| warning: false
library(rstanarm)   # Bayes-Modelle
library(tidyverse)
library(easystats)
```



```{r libs-hidden}
#| include: false
#library(icons)
library(gt)
library(ggridges)
library(plotly)
library(patchwork)
library(plotly)
library(dagitty)

theme_set(theme_modern())

```



### Ben√∂tigte Daten


Wir ben√∂tigen in diesem Kapitel folgende Datens√§tze: `kidiq`, `penguins`.

#### `kidiq`

Den Datensatz `kidiq` importieren Sie am einfachsten aus dem R-Paket `rstanarm`, das Sie schon installiert haben.

```{r}
data("kidiq", package = "rstanarm")
```

Alternativ k√∂nnen Sie die Daten [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/kidiq.csv) herunterladen.

{{< downloadthis data/kidiq.csv dname="kidiq" >}}


#### `penguins`

Sie k√∂nnen den Datensatz `penguins` entweder via dem Pfad importieren oder via dem zugeh√∂rigen R-Paket. Beide M√∂glichkeit sind okay.


```{r import-penguins}
#| results: "hide"
#| message: false
#| eval: false
penguins_url <- "https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv"

penguins <- read.csv(penguins_url)
```

{{< downloadthis data/penguins.csv dname="penguins" >}}



```{r}
data("penguins", package = "palmerpenguins")
```




### Einstieg


:::{#exm-skalenniveaus}
### Was waren noch mal die Skalenniveaus?
Um Forschungsfragen zu klassifizieren, m√ºssen Sie wissen, was die Skalenniveaus der beteiligten AV und der UV(s) sind.^[Hier ist eine kurze Erkl√§rung dazu: https://statistik1.netlify.app/010-rahmen#sec-arten-variablen]
$\square$
:::

:::{#exm-interaktion}
### Was war noch einmal die Interaktion?
Erk√§ren Sie die Grundkonzepte der Interaktion (hier synonym: Moderation) im Rahmen einer Regressionsanalyse!^[Hier finden Sie eine kurze Erkl√§rung zur Interaktion: https://statistik1.netlify.app/090-regression2#interaktion] $\square$
:::


### √úberblick

Wenn Sie die Skalenniveaus wissen, k√∂nnen Sie die Forschungsfrage korrekt auswerten, also das korrekte (Regressions-)Modell spezifizieren.
Wir werden hier viele der typischen Forschungsfragen (aus psychologischen und √§hnlichen Fragestellungen) mit Hilfe von Regressionsmodellen beantworten. Das hat den Vorteil,
dass sie nicht viele verschiedene Auswertungsmethoden (t-Test, Varianzanalyse, ...) lernen m√ºssen.
Au√üerdem ist die Regressionsanalyse (f√ºr viele Situationen) die beste Heransgehensweise, da sie viele M√∂glichkeiten f√ºr Erweiterungen bietet.
Entsperchend ist das Thema dieses Kapitels g√§ngige Forschungsfragen mit Hilfe der Regressionsanalyse zu untersuchen.
Wenn Sie die Grundkonzepte der Regression schon kennen,
wird Ihnen vieles sehr bekannt vorkommen.
Nat√ºrlich w√ºrzen wir das Ganze mit einer ordentlichen Portion Post-Verteilungen aus der Bayes-K√ºche.
Allerdings kommt auch dabei nichts Wesentliches mehr hinzu, abgesehen von einer paar Erweiterungen.




## Taxonomie von Forschungsfragen







Wir konzentrieren uns im Folgenden auf Forschungsfragen auf Basis von Regressionsmodellen mit *metrischer* AV. Andere Skalenniveaus bei der AV klammern wir aus.
Im Folgenden sind f√ºr die UV(s)  nominale sowie metrische Skalenniveaus erlaubt. 
Modelle mit mehreren UV (und mehreren Stufen an UV) sind ebenfalls erlaubt.



Wir untersuchen in diesem Kapitel h√§ufig verwendete Arten von Forschungsfragen mittels Regressionsanalysen.
F√ºr jede Variante ist zumeist ein Beispiel, die Modellformel, der Kausalgraph^[auch DAG genannt, s. @sec-kausal], die Forschungsfrage sowie die Grundlagen der Auswertung dargestellt.


Dabei wird folgende Nomenklatur verwendet, um die Skalenniveaus der beteiligten Variablen einer Forschungsfrage zu benennen:


- `y`: metrische abh√§ngige Variable
- `g`: Gruppierungsvariable; nominal skalierter unabh√§ngige Variable (querschnittlich)
- `b`: bin√§re Variable
- `x`: metrische unabh√§ngige Variable
- `u`: ungemessene Variable



## `y ~ b`





### Forschungsfrage

*Hintergrund:*

Eine Psychologin, die im √∂ffentlichen Dienst als Schulpsychologin arbeitet, 
versucht herauszufinden, warum einige Kinder intelligenter sind als andere. 
Dazu wurden in einer aufw√§ndigen Studie die Intelligenz vieler Kinder gemessen. 
Zus√§tzliche wurden verschiedene Korrelate der Intelligenz erhoben, 
in der Hoffnung, "Risikofaktoren" f√ºr geringere Intelligenz zu entdecken.




*Forschungsfrage:* 


>    Ist der mittlere IQ-Wert (`kid_score`) von Kindern, deren jeweilige Mutter √ºber einen Schlusabschluss (`mom_hs`, $x=1$) verf√ºgt h√∂her, als bei Kinderen, deren jeweilige Mutter nicht √ºber einen Schulabschluss verf√ºgt ($x=0$)? (ceteris paribus)^[H√§ufig erlaubt uns unser Vorwissen eine gerichtete Hypothese - "gr√∂√üer als/kleiner als" - zu formulieren, anstelle der   "empirisch √§rmeren" einfachen, ungerichteten Ungleichheit].


Die Modellformel zur Forschungsfrage lautet: `y ~  b` bzw. `kid_iq ~ mom_hs`.

Formaler ausgedr√ºckt und als Behauptung (Hypothese) formuliert, 
sieht die Forschungsfrage so aus (@thm-fofra1).

:::{#thm-fofra1}

### Hypothese f√ºr ungleiche Mittelwerte

$$H_A: \mu_{x=0|M} \ne \mu_{x=1|M}\quad \square$$
:::

In Worten: "Der mittlere IQ-Wert f√ºr Kinder, 
deren M√ºtter √ºber einen Schulabschluss verf√ºgen ist h√∂her als in der Gruppe von Kindern, deren M√ºtter √ºber keinen Schulabschluss verf√ºgen". 
Zu beachten ist, dass sich eine Population immer auf Parameterwerte bezieht, 
also auf die Population, nicht auf die Statistiken der Stichprobe.

Die zugeh√∂rige Nullhypothese lautet:


$$H_0: \mu_{x=1|M} = \mu_{x=0|M}\quad \square$$


### Modell

Die Regressionsformel zur Forschungsfrage lautet: `y ~ b` bzw. `kid_iq ~ mom_hs`.


Der Kausalgraph zur Modellformel sieht aus in @fig-binuv dargestellt.
Y hat, laut unserem Modell, zwei Ursachen:

1. mom_hs (b)
2. u, das steht f√ºr "unbekannt"^[unknown, sozusagen der unbekannte Gott, also f√ºr alle sonstigen Einfl√ºsse; man kann das "u" ohne Schaden weglassen, da wir es sowieso nicht modellieren. Hier ist es nur aufgef√ºhrt, um zu verdeutlichen, dass wir nicht so verwegen sind, zu behaupten, es g√§be keine anderen Einfl√ºsse als `mom_hs` auf die IQ des Kindes.]


```{r out.width = "100%", fig.asp = .5}
#| label: fig-binuv
#| fig-cap: "DAG f√ºr `kid_iq ~ mom_hs`"
#| echo: false

mein_modell <- "dag{
mom_hs -> kid_score
u -> kid_score
}"

plot(graphLayout(mein_modell))
```





```{r m10-1, echo = TRUE, results = "hide"}
#| results: "hide"
data("kidiq")  # Paket rstanarm
m10.1 <- stan_glm(
  kid_score ~ mom_hs, 
  seed = 42,
  data = kidiq)
```




Der Einfachheit halber √ºbernehmen wir die Prioriwerte von Stan, s. @lst-m101.

```{r}
#| lst-cap: "Standard-Prioriwerte f√ºr m10.1, von Stan vergeben"
#| lst-label: lst-m101
prior_summary(m10.1)
```


Die komplette Modellspezifikation ist in @eq-m101 aufgef√ºhrt.




$$\begin{align*}
\text{kid score}_i &\sim \operatorname{Normal}(\mu_i, \sigma) && \text{Likelihood} \\
\mu_i &= \beta_0 + \beta_1 \cdot \text{mom hs}_i && \text{Lineares Modell} \\
\beta_0 &\sim \operatorname{Normal}(87, 51) && \text{Prior Achsenabschnitt} \\
\beta_1 &\sim \operatorname{Normal}(0, 124) && \text{Prior Regressionsgewicht} \\
\sigma &\sim \operatorname{Exp}(0.049) && \text{Prior Vorhersageg√ºte}
\end{align*}$${#eq-m101} 



Mit `parameters(m10.1)` bekommt man die Parameter des Modells, s. @tbl-m101.


```{r echo = TRUE}
#| echo: false
#| tbl-cap: "Parameter des Modells m10.1 (sigma ist nicht dargestellt, da meistens nicht von hohem Interesse)"
#| label: tbl-m101 
display(parameters(m10.1))
```



### Interpretation der Koeffizienten

`m10.1: kid_score = 78 + 12*mom_hs + error`

Der *Achsensabschnitt* (intercept, $\beta_0$ oder auch mit $\alpha$ bezeichnet) ist der mittlere (bzw. vorhergesagte) IQ-Wert von Kindern, deren M√ºtter √ºber keinen Schulabschluss (`mom_hs = 0`) verf√ºgen:

`kid_score = 78 + 0*12 + error`

Das *Regressionsgewicht* (slope, $\beta_1$, $\beta$) ist der Unterschied im IQ-Wert von Kindern mit M√ºtter mit Schlulabschluss (im Vergleich zum IQ-Wert von Kindern mit M√ºtter ohne Schlusabschluss). Dieser Unterschied entspricht der Steigung der Regressionsgeraden.

`kid_score = 78 + 1*12 + error = 90 + error`

Der Wert von `error` zeigt, wie genau die Sch√§tzung (Vorhersage) ist bzw. wie stark Pr√§diktor (UV) und Kriterium (AV) zusammenh√§ngen.


`error` entspricht dem Vorhersagefehler, also dem Unterschied vom tats√§chlichen IQ-Wert des Kindes ($y$) zum vom Modell vorhergesagten Wert ($\hat{y}$).


### `y ~ g` als Mittelwertsdifferenz 

Ein lineares Modell der Art `y ~ g` kann man als Berechnung des Unterschieds im Mittelwert von `y` zwischen beiden Gruppen (g0 vs. g1) verstehen.



>    üë®‚Äçüè´ Hey R-Golem! Nimm den Datensatz `kidiq`, gruppiere nach `mom_hs` und fasse zusammen anhand des Mittelwerts. Die resultierende Zahl soll hei√üen `kid_score_avg`.  An die Arbeit!

>    ü§ñ Loving it!


:::{.panel-tabset}

### R-Code

```{r kidqi2-sum}
#| eval: false
kidiq %>% 
  group_by(mom_hs) %>% 
  summarise(kid_score_avg = 
              mean(kid_score))
```

### Ausgabe

```{r kidqi2-sum-output}
#| echo: false
kidiq %>% 
  group_by(mom_hs) %>% 
  summarise(kid_score_avg = 
              mean(kid_score)) |> 
  display()
```

Der mittlere (average, avg) IQ-Wert unterscheidet sich um ca. 12 Punkte (89.4-77.6), zugunsten der Kinder von M√ºttern mit Abschluss. 
:::



In @fig-momkid ist der Unterschied im IQ der Kinder als Funktion des Schlussabschlusses der Mutter dargestellt, auf Basis des Datensatzes `kidiq`.


```{r}
#| eval: false
estimate_relation(m10.1) %>% plot()
```


```{r plot-kidiq}
#| label: fig-momkid
#| echo: false
#| fig-cap: "Kinder, deren M√ºtter √ºber einen Schulabschluss verf√ºgen, haben im Mittel einen h√∂heren Intelligenztestwert, laut dem vorliegenden Modell. Die Regressionsgerade ist als durchgezogene Linie dargestellt. Die Mittelwerte pro Gruppe als Punkte und als gestrichelte, horizontale Linie."
ggplot(kidiq) +
  aes(x = mom_hs, y = kid_score) +
  geom_jitter(width = 0.1, alpha = .5) +
  geom_abline(slope = coef(m10.1)[2],
              intercept = coef(m10.1)[1],
              color = okabeito_colors()[2], size = 2) +
  scale_x_continuous(breaks = c(0, 1)) +
  stat_summary(geom = "point", fun = mean, color = okabeito_colors()[1], size = 9, alpha = .7) +
  geom_hline(yintercept = mean(kidiq$kid_score[kidiq$mom_hs == 0]), 
             linetype = "dashed", color = "grey40") +
  geom_hline(yintercept = mean(kidiq$kid_score[kidiq$mom_hs == 1]), 
             linetype = "dashed", color = "grey40")

```




### Rope

Pr√ºfen wir mit `rope(m10.1)`, ob der Effekt der UV (Unterschied zwischen den Gruppen) "praktisch Null" ist; dazu nutzen wir das ROPE-Verfahren.

```{r}
#| eval: false
rope(m10.1)
```


```{r}
#| echo: false
rope(m10.1) |> plot()
```


Das Ergebnis zeigt uns, dass es 0% √úberlappung vom Rope und dem 95%-HDI (der Posterior-Verteilung) gibt.

Fazit: Wir verwerfen die Praktisch-Null-Hypothese. Adios!
@fig-rope-m101 visualisiert die Erstreckung der Posteriori-Verteilung (und des 95%-HDI) sowie des Rope.


```{r}
#| label: fig-rope-m101
#| layout-ncol: 2
#| echo: false
#| fig-cap: "Rope und HDI √ºberlappen nicht. Wir verwerfen die Praktisch-Null-Hypothese."
#| fig-subcap: 
#|   - "Diagramm mit rope(m10.1) %>% plot()"
#|   - "Diagramm mit parameters(m10.1) %>% plot()"
rope(m10.1) %>% plot()
parameters(m10.1) %>% 
  plot() +
  geom_rect(aes(xmin = 0-2, xmax = 0+2, ymin = -Inf, ymax = Inf), 
              fill = "blue", alpha = 0.2, color = NA)
```




### t-Test

In der *frequentistischen* Statistik (die mehrheitlich unterricht wird) untersucht man diese Datensituation - Mittelwertsdifferenz zwischen zwei Gruppen - mit einem *t-Test*.

Der *t*-Test ist ein inferenzstatistisches Verfahren, das pr√ºft, ob die Mittelwertsdifferenz (in der Population) $\mu_d$ Null ist: $\mu_d = 0$.^[Genauer gesagt wird gepr√ºft, wie wahrscheinlich es auf Basis des Modell ist, noch extremere Ergebnisse zu beachten unter der Annahme, dass die (exakte) Nullhypothese wahr ist. Es ist etwas kompliziert.]
In der Bayes-Statistik betrachtet man dazu stattdessen die Posteriori-Verteilung (z.B. mit 95%PI).

Alternativ zum t-Test kann man - unabh√§ngig, ob man Frequentistisch oder Bayesianisch unterwegs ist - mit einer Regression vom Typ `y ~ b` das in etwa gleiche Ergebnis erreichen.^[Genauer gesagt, erlaubt der t-Test in der Form des Welche-Tests auch Abweichungen von der Varianzhomogenit√§t der gestesten Gruppen. Die Regression geht hingegen von Varianzhomogenit√§t (Homoskedastizit√§t) aus. Allerdings ist diese Annahme nicht von besonderer Bedeutung, wenn es um die Regressionskoeffizienten geht.]







### Antwort auf die Forschungsfrage

Betrachten wir die Ergebnisse von `m10.1`.

:::{.panel-tabset}

### R-Code


```{r m101post-code}
m10.1_post <-
  m10.1 %>% 
  as_tibble() 

names(m10.1_post) <- c("Achsenabschnitt", "momhs", "sigma")  # sch√∂nere Namen
```

### Ausgabe

Hier sind die ersten paar Zeilen, s. @tbl-m101post.


```{r m101post-output}
#| echo: false
#| label: tbl-m101post
#| tbl-cap: "m10.1, Postverteilung, ersten paar Zeilen"
m10.1_post %>% 
 # rename(momhs = mom_hs) %>% 
  slice_sample(n=5) %>% 
  gt() %>% 
  fmt_number(1:3, decimals = 1) %>% 
  tab_header("Stichprobe aus der Post-Verteilung")
```

:::




Berechnen wir zur √úbung ein 95%-PI von Hand; komfortabler geht es mit `eti(m10.1)`, s. @tbl-m101.


```{r echo = TRUE}
pi_mom_hs <-
  m10.1_post %>% 
  summarise(pi_95 = quantile(momhs, c(.025, .975)))

pi_mom_hs
```






Mit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen 
Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 7 bis 14 IQ-Punkten, 
laut unserem Modell: $95\%PI: [7,16]$.
Die Hypothese, dass es keinen  Unterschied oder einen Unterschied in die andere Richtung geben sollte, 
ist vor diesem Hintergrund als unwahrscheinlich abzulehnen.

Visualisieren wir abschlie√üend die Posteriori-Verteilung, s. @fig-m101hdi.

```{r plot-hdi-m101}
#| label: fig-m101hdi
#| fig-cap: "Das 95% ETI zum (statistischen) Effekt des m√ºtterlichen Schulabschlusses"
plot(eti(m10.1))
```



Zur Einnerung: Korrelation ungleich Kausation.
Von einem "Effekt" zu sprechen,
l√§sst in den meisten K√∂pfen wohl die Assoziation zu einem *kausalen* Effekt
entstehen. 
Ein Kausaleffekt ist eine starke (und sehr interessante und wichtige) Behauptung,
die mehr Fundierung bedarf als eine einfache Korrelation bzw. ein
 einfacher Zusammenhang. F√ºr eine Kausalaussage braucht man ein Argument, etwa einen Verweis auf bestehende Studien oder eine Theorie.
 


<!-- ### Variante zur Forschungsfrage -->


<!-- Unsere Psychologin k√∂nnte auch folgende Hypothese formulieren: -->

<!-- >    Die Wahrscheinlichkeit f√ºr ein Kind mit IQ-Testwerten (y) von √ºber 100 Punkten ist h√∂her, wenn die Mutter √ºber einen Schulabschluss verf√ºgt. -->


<!-- Pr√§ziser formuliert: -->


<!-- $$Pr(y > 100|x=1, \alpha, \beta, \sigma) > Pr(y > 100|x=0, \alpha, \beta, \sigma)$$ -->

<!-- Der vertikale Balken "|" liest sich als "gegeben, dass".  -->
<!-- Hier wird auf die Wahrscheinlichkeit f√ºr ein Testergebnis $y>100$, -->
<!-- *gegeben, dass* die Mutter √ºber einen Schulabschluss verf√ºgt ($x=1$)  -->
<!-- und gegeben der Modellparameter $\alpha, \beta, \sigma$. -->



### Vertiefung: Toleranzbereich {#sec-toleranz}

üèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è


Berechnet man ein Regressionsmodell mit `stan_glm` (ü§ñüòÅ), dann zieht man dabei Zufallszahlen üé≤.
Der Hintergrund ist, dass Stan eine Stichproben-Post-Verteilung erstellt, und das Ziehen der Stichproben erfolgt zuf√§llig.
Das erkl√§rt, warum Ihre Ergebnisse einer Regressionsanalyse mittels `stan_glm` von denen in diesem Buch abweichen k√∂nnen.

Um zu pr√ºfen, ob Ihre Ergebnisse "√§hnlich genug" oder "innerhalb eines Toleranzbereichs" sind, kann man die Funktion `is_in_tolerance()` aus dem R-Paket `prada` nutzen.

:::{.callout-note}
### Gr√∂√üe des Toleranzbereichs

Die Gr√∂√üe des *relativen Toleranzbereichs* ist in `is_in_toleranzce()` auf 5% festgelegt.
Das hei√üt, ein Unterschied von 5% zwischen einem Referenzwert (dem "wahren" Wert) und Ihrem Wert ist *okay*, also im Toleranzbereich.
Au√üerdem gibt es noch einen *absoluten Toleranzbereich*, der auf *5% der SD der AV* festgelegt ist (bei Regressionsmodellen).
Der *gr√∂√üere* der beiden Werte gilt. $\square$
:::

Wenn Sie diese Funktion nutzen wollen, m√ºssen Sie zun√§chst das Paket installieren (von Github, nicht vom Standard-R-App-Store CRAN) und dann wie gewohnt starten.

```{r}
#| eval: false
library(remotes)  # dieses Paket k√∂nnen Sie mit `install.packages("remotes") installieren
install_github("sebastiansauer/prada")
library(prada)
```



```{r}
#| include: false
library(prada)
```


Dann testen Sie, ob Ihr Modellparameter, z.B. $\beta_1$ innerhalb eines Toleranzbereichs liegt.

Sagen wir der "richtige" oder "wahre" Wert (oder schlicht der Wert einer Musterl√∂sung) f√ºr $\beta_0$ ist `77`. Unser Wert sei `77.56`.
Liegt dieser Wert noch innerhalb eines Toleranzbereichs?

```{r}
is_in_tolerance(asis = 77.56,  # Ihr Wert
                tobe = 77,   # Referenzwert
                tol_rel = .05,   # relative Toleranz
                tol_abs = .05 * sd(kidiq$kid_score)  # absolute Toleranz
                )
```

Ja, unser Wert ist *innerhalb* des Toleranzbereichs. ‚úÖ 

## `y ~ x + b`




### Forschungsfrage


>    Wie stark ist der statistische Effekt von jeweils Schulabschluss der Mutter (`mom_hs`) und  IQ der Mutter (`mom_iq`)  auf den IQ des Kindes (`kid_score`) ?



Die Modellformel zur Forschungsfrage lautet: `y ~ x + b` bzw. `kid_score ~ mom_iq + mom_hs`.

Die Hypothesen lauten:

1. Der Schulabschluss der Mutter hat einen positiven Effekt auf den IQ des Kindes:  $\beta_{momhs} > 0$.
2. Der IQ der Mutter hat einen positiven Effekt auf den IQ des Kindes:  $\beta_{momiq} > 0$.

Der Kausalgraph^[DAG, s. @sec-kausal] zur Modellformel sieht aus in @fig-yxb dargestellt.
Laut unserem Modell ist `y` also eine Funktion zweier (kausaler) Einfl√ºsse, `b` und `u`, wobei `u` f√ºr "unbekannt" steht, also f√ºr alle sonstigen Einfl√ºsse.^[Dabei nehmen wir an, dass `x` und `u` nicht voneinander abh√§ngen, was man daran erkennt, dass es keine Pfeile zwischen den beiden Variablen gibt.]


```{r out.width = "100%", fig.asp = .5}
#| label: fig-yxb
#| fig-cap: "DAG f√ºr `y ~ b`"
#| echo: false

mein_modell <- "dag{
mom_hs -> kid_score
u -> kid_score
mom_iq -> kid_score
}"

plot(graphLayout(mein_modell))
```





Deskriptive Statistiken zum Datensatz sind in Tabelle @tbl-kidiq1 dargestellt.


```{r Thema6-Teil2-1, echo = TRUE, results="hide"}
data("kidiq")  # Paket rstanarm, alternativ √ºber CSV einlesen
describe_distribution(kidiq)
```


```{r Thema6-Teil2-2}
#| tbl-cap: "Variablen und ihre Verteilung im Datenatz kidiq"
#| echo: false
#| label: tbl-kidiq1
describe_distribution(kidiq) %>% 
  display()
```








### 1 metrischer Pr√§diktor


Berechnen wir folgendes Modell: `kid_score ~ mom_iq` (`m10.2`), s. Tab. @tbl-m102.


```{r Thema6-Teil2-3, results = "hide"}
#| results: "hide"
m10.2 <-
  stan_glm(kid_score ~ mom_iq, data = kidiq, seed = 42)

m10.2 %>% 
  parameters()
```


```{r}
#| echo: false
#| tbl-cap: "Parameter des Modells m10.2"
#| label: tbl-m102
m10.2 %>% 
  parameters() %>% 
  display()
```


`kid_score = 26 + 0.6 * mom_iq + error`




:::{.panel-tabset}


### mit `ggplot2`

Visualisieren wir uns noch das Modell m10.2, s. @fig-kidiqmomiq.

```{r Thema6-Teil2-4}
#| label: fig-kidiqmomiq
#| fig-cap: "Die Intelligenz eines Kindes als Funktion der Intelligenz der Mutter (m10.2)"
kidiq %>% 
  ggplot(aes(x = mom_iq, y = kid_score)) +
  geom_point(alpha = .7) +
  geom_abline(slope = coef(m10.2)[2],
              intercept = coef(m10.2)[1],
              color = "blue")
```

### Mit `easystats`

Alternativ kann man sich - einfacher - das Modell (m10.2) so visualisieren, mit Hilfe des R-Pakets `easystats`, s. @fig-m102-a.

```{r}
#| label: fig-m102-a
#| fig-cap: "Die gesch√§tzten Erwartungswerte von m10.2 visualisiert"
plot(estimate_relation(m10.2))
```

:::


Die Linie zeigt die vorhergesagten IQ-Werte der Kinder f√ºr verschiedene IQ-Werte der M√ºtter.
Vergleicht man Teilpopulationen von M√ºttern mit mittleren Unterschied von einem IQ-Punkt, 
so findet man 0.6 IQ-Punkte Unterschied bei ihren Kindern *im Durchschnitt*, laut dem Modell m10.2.
Der Achsenabschnitt hilft uns nicht weiter, da es keine Menschen mit einem IQ von 0 gibt.






### Beide Pr√§diktoren, `m10.3`


Berechnen wir als n√§chstes ein Modell mit beiden Pr√§diktoren: `kid_score ~ mom_hs + mom_iq`, s. @tbl-m103.

    

```{r m10-3, echo = TRUE}
m10.3 <- 
  stan_glm(
    kid_score ~ mom_iq + mom_hs, 
    refresh = 0,
    seed = 42,
    data = kidiq)
```


```{r}
#| tbl-cap: "Parameter des Modells m10.3 (ohne sigma; ETI-Intervalle)"
#| label: tbl-m103
#| echo: false

parameters(m10.3) %>% 
  display()
```



Will man nur schnell die Koeffizienten des Modells (d.h. Punktsch√§tzer der Modellparametern, in diesem Fall den Median) wissen, so kann man anstelle von `parameters(mein_modell)` auch `coef(mein_modell)` schreiben:

```{r}
coef(m10.3)
```


`m10.3: kid_score = 26 + 0.6*mom_iq + 6*mom_hs + error`

M√∂chte man nur z.B. den 3. Wert aus diesem Vektor, so kann man schreiben:

```{r}
coef(m10.3)[3]
```


Aber nat√ºrlich ist es m√∂glich (und einfacher) anstelle von `coef` den Befehl `parameters` zu verwenden.

Und die Visualisierung des Modells `m10.3`, s. @fig-m103.


```{r Thema6-Teil2-5, fig.asp = 0.62}
#| label: fig-m103
#| fig-cap: "Der Effekt von sowohl m√ºtterlicher Intelligenz als auch m√ºtterlichem Schulabschluss."

kidiq2 <-
  kidiq %>% 
  mutate(mom_hs = as.factor(mom_hs))

m10.3a <- 
  stan_glm(
    kid_score ~ mom_iq + mom_hs, 
    refresh = 0,
    seed = 42,
    data = kidiq2)

pred <- estimate_relation(m10.3a)
plot(pred)


```




- *Achsenabschnitt*: Hat das Kind eine Mutter mit einem IQ von 0 und ohne Schulabschluss, dann sch√§tzt das Modell den IQ-Wert des Kindes auf 26.
- *Koeffizient zum m√ºtterlichen Schulabschluss*: Vergleicht man Kinder von M√ºttern gleicher Intelligenz, aber mit Unterschied im Schulabschluss, so sagt das Modell einen Unterschied von 6 Punkten im IQ voraus.
- *Koeffizient zur m√ºtterlichen IQ*: Vergleicht man Kinder von M√ºttern mit gleichem Wert im Schulabschluss, aber mit 1 IQ-Punkt Unterschied, so sagt das Modell einen Unterschied von 0.6 IQ-Punkten bei den Kindern voraus.


### Antwort auf die Forschungsfrage



Mit 95% Wahrscheinlichkeit liegt der Unterschied im mittleren IQ-Wert zwischen Kindern von M√ºttern mit bzw. ohne Schulabschluss im Bereich von 1.6 bis 10.1 IQ-Punkten, laut unserem Modell. Der Effekt des m√ºtterlichen IQs wird auf 0.5 bis 0.7 gesch√§tzt (95%-ETI). Da f√ºr beide UV die Null nicht im Intervall plausibler Werte liegt, kann ein Null-Effekt (die exakte Nullhypothese) abgelehnt werden.




## `y ~ x + b + x:b`

### Forschungsfrage und Modelldefinition


>   Gibt es einen Interaktionseffekt zwischen m√ºtterlichem Schulabschluss und m√ºtterlichem IQ (auf den IQ-Wert des Kindes)?

Au√üerdem ist man vermutlich auch an den Effekten der beiden UV auf die AV interessiert; diese Fragen haben wir im letzten Abschnitt untersucht (und greifen sie daher nicht noch mal ausf√ºhrlich auf).




Die Modellformel zur Forschungsfrage lautet: `y ~ x + b + x:b`.
Der Einfachheit halber √ºbernehmen wir wieder die Prioris wie vom R-Paket `rstanarm` bereitgestellt.


Der DAG zur Modellformel sieht aus in @fig-yxbi dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-yxbi
#| fig-cap: "DAG f√ºr `y ~ x + b + x:b`"
#| echo: false

mein_modell <- "dag{
u -> kid_score
mom_iq -> kid_score
mom_hs -> kid_score
momiqmom_hs -> kid_score
}"

plot(graphLayout(mein_modell))
```




### Interaktion zur Modellformel hinzuf√ºgen

In `m10.3` hat das Modell die Regressionsgeraden gezwungen, parallel zu sein. 
Betrachtet man das Streudiagramm, so sieht man, das nicht-parallele Geraden besser passen.
Sind die Regressionsgeraden nicht parallel, so spricht man von einer *Interaktion* (synonym: Interaktionseffekt, Moderation).

:::callout-important
Liegt eine Interaktion vor, so unterscheidet sich die Steigung der Geraden in den Gruppen.
Liegt keine Interaktion vor, so sind die Geraden parallel.$\square$
:::

Wir berechnen mit m10.4 das Modell mit folgender Modellformel: `kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq`, s. @lst-m104, @fig-m104 und @tbl-m104.

```{r m10-4, echo = TRUE}
#| lst-cap: "Die Modelldefition von m10.4 mit stanglm"
#| lst-label: lst-m104
m10.4 <- 
  stan_glm(kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq, 
           seed = 42,
           data = kidiq, 
           refresh = 0)
```

In der Regressionsformel sieht man, dass ein zus√§tzlicher Parametern, eben der Interaktionseffekt, in das Modell aufgenommen wurde.


```{r}
#| echo: false
#| label: tbl-m104
#| tbl-cap: "Parameter von m10.4"
parameters(m10.4) %>% 
  display()
```

Mit `estimate_relation(m10.4) |> plot()` kann man  sich das Modell visualisieren, s. @fig-m104.


```{r Thema6-Teil2-6, fig.width=8}
#| echo: false
#| label: fig-m104
#| fig-cap: "Wie m10.3, aber mit Interaktionseffekt. Es ist gut zu erkennen, dass der Achsenabschnitt f√ºr diese Daten kaum zu interpretieren ist."
kidiq %>% 
  mutate(mom_hs = factor(mom_hs)) %>%  
  ggplot(aes(x = mom_iq, y = kid_score, color = mom_hs)) +
  geom_point2(alpha = .7) +
  geom_abline(slope = coef(m10.4)[2],
              intercept = coef(m10.4)[1],
              linewidth = 1,
              color =  okabeito_colors()[1] ) +
  geom_abline(slope = coef(m10.4)[2]+coef(m10.4)[4],
              intercept = coef(m10.4)[1] + coef(m10.4)[3],
              linewidth = 2,
              color = okabeito_colors()[2]) +
  scale_color_okabeito() +
  scale_x_continuous(limits = c(0, 140)) +
  theme(legend.position = c(0.9, 0.2)) +
  theme_minimal()
```






### Interpretation von `m10.4`

*Achsenabschnitt:* IQ-Sch√§tzwerte f√ºr Kinder mit M√ºtter ohne Abschluss und mit einem IQ von 0. Kaum zu interpretieren.
- `mom_hs`: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit Mutter ohne 
bzw. mit Schulabschluss und jeweils mit einem IQ von 0. Puh.
`mom_iq`: Unterschied der IQ-Sch√§tzwerte zwischen Kindern mit M√ºttern, 
die sich um einen IQ-Punkt unterscheiden aber jeweils ohne Schulabschluss.
*Interaktion*: Der Unterschied in den Steigungen der Regressiongeraden, also der Unterschied 
des Koeffizienten f√ºr `mom_iq` zwischen M√ºtter mit bzw. ohne Schulabschluss.

F√ºr beide Gruppen, `mom_hs=0` und `mom_hs=1` gilt folgende Regressionsformel, s. @eq-lm4.


$$\text{kid score} = \beta_0 + \beta_1 \cdot \text{mom hs} + \beta_2 \cdot \text{mom iq} + \beta_3 \cdot \text{mom hs} \cdot \text{mom iq}$$ {#eq-lm4}

$\beta_3$ gibt die St√§rke des Interaktionseffekts an.

Auf Errisch schreibt mit @eq-lm4 so (s. @lst-m104): 

`kid_score ~ mom_iq + mom_hs + mom_hs:mom_iq`.

Der Doppelpunkt zwischen `mom_hs` und `mom_iq` steht f√ºr den Interaktionseffekt der beiden Variablen.

Tr√§gt man die Werte der Koeffizienten ($\beta_0, \beta_1, \beta_2, \beta_3$) ein, 
so erh√§lt man @eq-lm4-with-values.

$$\text{kid score} = `r round(coef(m10.4)[1], 1)` + `r round(coef(m10.4)[3], 1)` \cdot \text{mom hs} + `r round(coef(m10.4)[2], 1)`  \cdot \text{mom iq} + `r round(coef(m10.4)[4], 1)` \cdot \text{mom hs} \cdot \text{mom iq}$$ {#eq-lm4-with-values}



Teilen wir die Regressionsformel einmal auf die beiden Gruppen (`mom_hs=0` bzw. `mom_hs=1`) auf:


`mom_hs=0`:

```
kid_score = `r round(coef(m10.4)[1], 1)` + `r round(coef(m10.4)[3], 1)`*0 + `r  round(coef(m10.4)[2], 1)`*mom_iq  - `r round(coef(m10.4)[4], 1)`*0*mom_iq
          = -10 + 1.1*mom_iq
```

`mom_hs=1`: 



```
kid_score = `r round(coef(m10.4)[1], 1)` + `r round(coef(m10.4)[3], 1)`*mom_hs + `r  round(coef(m10.4)[2], 1)`*mom_iq  - `r round(coef(m10.4)[4], 1)`*mom_hs*mom_iq
          = -10 + 1.1*mom_iq
```









::: {.content-visible when-format="html"}


Nach der Interpretation von 20 unzentrierten Koeffizienten ...


<iframe src="https://giphy.com/embed/Zaej3GIZTzCI8" width="480" height="306" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/muppets-rachel-maddow-kermit-Zaej3GIZTzCI8">via GIPHY</a></p>

Wir m√ºssen dringend die unzentrierten Pr√§diktoren loswerden ...

:::



### Antwort auf die Forschungsfrage


Wie in @tbl-m104 ersichtlich, kann f√ºr alle drei Effekte (m√ºtterliche IQ, m√ºtterlicher Schulabschluss und Interaktion von m√ºtterlichem IQ mit m√ºtterlichem Schulabschluss) ein Nulleffekt ausgeschlossen werden.
Ob die Effekte st√§rker als "praktisch Null" sind, kann mittels des ROPE-Verfahren untersucht werden.


## `y ~ x_c + b + x_c:b`

### Zentrieren von Pr√§diktoren

Unter *Zentrieren* (to *c*enter) versteht man das Bilden der Differenz eines Messwerts zu seinem Mittelwert.^[Vgl. [Abschnitt "UV zentrieren"](https://statistik1.netlify.app/090-regression2.html#uv-zentrieren) im Kursbuch [Statistik1](https://statistik1.netlify.app/).]
Zentrierte Werte geben also an, wie weit ein Messwert vom mittleren (typischen) Messwert entfernt ist.
Mit zentrierten Werten ist eine Regression einfacher zu interpretieren.
Hier zentrieren wir (nur) `mom_iq`; 
die zentrierte Variable kennzeichnen wir durch den Suffix `_c`, also `mom_iq_c`.


Man k√∂nnte auch `mom_hs` zentrieren,
aber f√ºr eine einfache Interpretation ist es meist n√ºtzlich,
nur metrische Pr√§diktoren zu zentrieren.

```{r Thema6-Teil2-7, echo = TRUE}
#| results: hide
kidiq <-
  kidiq %>% 
  mutate(mom_iq_c = mom_iq - mean(mom_iq))

m10.5 <- stan_glm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c, 
                  data = kidiq, 
                  seed = 42,
                  refresh = 0)

coef(m10.5)  # nur die Punktsch√§tzer f√ºr die Koeffizienten ausgeben
```

@tbl-m105-point zeigt die Punktsch√§tzer der Koeffizienten von m10.5.

```{r}
#| echo: false
#| label: tbl-m105-point
#| tbl-cap: "Punktsch√§tzer von m10.5 (zentrierte UV)"
parameters(m10.5) %>% 
  select(1,2) %>% 
  display()
```




### Interpretation von `m10.5`

- Der *Achsenabschnitt* (`Intercept`) gibt den gesch√§tzten IQ des Kindes an, wenn man eine Mutter *mittlerer* Intelligenz und *ohne* Schulabschluss betrachtet.
- `mom_hs` gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter mittlerer Intelligenz aber mit bzw. ohne Schlusabschluss vergleicht.
- `mom_iq_c` gibt den Unterschied im gesch√§tzten IQ des Kindes an, wenn man M√ºtter ohne Schlusabschluss aber mit einem IQ-Punkt Unterschied vergleicht.
- `mom_hs:mom_iq_c` gibt den Unterschied in den Koeffizienten f√ºr `mom_iq_c` an zwischen den beiden Grupen von `mom_hs`.




Mit `estimate_relation(m10.5) |> plot()` kann man  sich das Modell visualisieren, s. @fig-m105.


```{r Thema6-Teil2-6, fig.width=8}
#| echo: false
#| label: fig-m105
#| fig-cap: "m10.5: Mit zentrierten Pr√§diktoren gibt der Achsenabschnitt den Y-Wert f√ºr eine Beobachtung mit mittleren X-Wert an; daher ist der Achsenabschnitt besser zu interpretieren als ohne Zentrierung."
kidiq %>% 
  mutate(mom_hs = factor(mom_hs)) %>%  
  ggplot(aes(x = mom_iq_c, y = kid_score, color = mom_hs)) +
  geom_point2(alpha = .7) +
  geom_abline(slope = coef(m10.5)[2],
              intercept = coef(m10.5)[1],
              linewidth = 1,
              color =  okabeito_colors()[1] ) +
  geom_abline(slope = coef(m10.5)[2]+coef(m10.5)[4],
              intercept = coef(m10.5)[1] + coef(m10.5)[3],
              linewidth = 2,
              color = okabeito_colors()[2]) +
  scale_color_okabeito() +
  theme(legend.position = c(0.9, 0.2))  +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey40") +
  theme_minimal()
```


### Zentrieren √§ndert nichts an den Vorhersagen

Betrachten wir die Vorhersagen von `m10.4`.

```{r Thema6-Teil2-8, echo = TRUE}
new <- tibble(mom_hs = 0, mom_iq = mean(kidiq$mom_iq))
pred_new <- predict(m10.4, newdata = new)
mean(pred_new)
```

Und vergleichen wir mit diesen die Vorhersagen von `m10.5`: Wir sehen, die Vorhersagen sind (bis auf Rundungsfehler) identisch.


```{r Thema6-Teil2-9, echo = TRUE}
new <- tibble(mom_hs = 0, mom_iq_c = 0)
pred_new <- predict(m10.5, newdata = new)
mean(pred_new)
```




Auch die Streuungen der vorhergesagten Werte unterscheiden sich nicht (wirklich): $\sigma_{m10.4}= `r round(sigma(m10.4))`$; $\sigma_{m10.5}= `r round(sigma(m10.5))`$.


Das Zentrieren √§ndert auch *nicht* die zentrierten Regressionskoeffizienten, da die Streuungen dieser Variable nicht ver√§ndert wurden.





### Perzentilintervalle aus der Posterori-Verteilung

@tbl-m105 zeigt die Punktsch√§tzer der Parameter f√ºr m10.5 sowie ihre Perzentilintervalle^[auch ETI (Equal Tails Interval) genannt].
Nutzen Sie daf√ºr `parameters(m10.5)`, s. @tbl-m105.

```{r}
#| tbl-cap: "Parameter von m10.5 und ETIs"
#| echo: false
#| label: tbl-m105
parameters(m10.5) %>% 
  display()
```



Highest Density (Posterior) Intervalle (HDI oder HDPI) kann man sich  komfortabel ausgeben lassen mit `hdi(m10.5)` oder mit `parameters(m10.5, ci_method = "hdi")`,
s. @tbl-m105-hdi.

```{r Thema6-Teil2-11}
#| tbl-cap: "Parameter von m10.5 und HDIs"
#| label: tbl-m105-hdi
parameters(m10.5, ci_method = "hdi") %>% 
  display()
```

Im Falle symmetrischer Posteriori-Verteilungen (wie hier) kommen beide Arten von Intervallen zu gleichen Ergebnissen.



### Beantworten der Forschungsfrage

>   Das Model zeigt keine Belege, dass sich die mittlere Intelligenz von Kindern bei M√ºttern mit bzw. ohne Schlusabluss unterscheidet (95%PI: [-2.0, 7.8]); die Befundlage ist unklar. Hingegen fand sich ein Effekt der m√ºtterlichen Intelligenz; pro Punkt Unterschied in m√ºtterlichem IQ fand sich ein Unterschied von 0.7 bis 1.3 IQ-Punkte beim Kind (95%PI). Au√üerdem fand sich ein Beleg, dass der Zusammenhang des IQ zwischen Mutter und Kind durch den Schulabschluss moderiert wird: Bei M√ºtter mit Schulabschluss war der Regressionskoeffizient zwischen Mutter-IQ und Kind-IQ geringer (95%PI: [-0.80, -0.17]).

</br>
</br>



:::callout-important
Das Modell hat mittels @fig-yg mutig Kausalaussagen postuliert. Das ist zwar sch√∂n, bedarf aber einer Begr√ºndung mit R√ºckgriff auf die Literatur (was hier nicht getan wurde).
:::


















## `y ~ g` {#sec-yg}


Hier untersuchen wir ein Modell mit einer nominalen UV mit mehreren Stufen.




### Forschungsfrage



Nach Ihrem Studium wurden Sie reich als Unternehmensberaterin;
Ihre Kompetenz als Wirtschaftspsychologi war hei√ü begehrt.
Von Statistik wollte niemand etwas wissen...
Doch nach einiger Zeit kamen Sie in eine Sinnkrise.
Sie warfen Ihre Job hin und beschlossen, in die Wissenschaft zu gehen.
Kurz entschlossen bewarben Sie sich auf das erste Stellenangebot
als Nachwuchswissenschaftler:in.

Ihr Forschungsprojekt f√ºhrte Sie in die Antarktis...
Nun, das war zumindest ein Gegenentwurf zu Ihrem bisherigen Jet-Set-Leben.


Ihre Aufgabe bestand nun darin, Pinguine zu untersuchen.
Genauer gesagt ging es um Gr√∂√üenunterschiede zwischen drei Pinguinarten.
Ja, stimmt, an so ein Forschungsprojekt hatten Sie vorher nie auch nur nur im Traum gedacht.




</br>


> Unterscheiden sich die mittleren K√∂rpergewichte der drei Pinguinarten?





Die allgemeine Modellformel zur Forschungsfrage lautet: `y ~ g`. 


Der DAG zur Modellformel sieht aus in @fig-yg dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-yg
#| fig-cap: "DAG f√ºr `y ~ g`"
#| echo: false

mein_modell <- "dag{
g -> y
u -> y
}"

plot(graphLayout(mein_modell))
```


### Alle Mittelwerte sind gleich, exakt gleich (?)

- Formal: $\mu_1 = \mu_2 = \ldots = \mu_k$ mit $k$ verschiedenen Gruppen von Pinguinarten.

- Hypothesen, die keinen (Null) Unterschied zwischen Gruppen oder keinen Zusammenhang zwischen Variablen postulieren, kann man als *Nullhypothesen* bezeichnen.

- Moment. Dass sich *alle* Mittelwerte um 0,00000000 unterscheiden, ist wohl nicht zu vermuten. Wer glaubt sowas? ü§î Daher ist die bessere Forschungsfrage:

> *Wie sehr* unterscheiden sich mittlere K√∂rpergewichte in Abh√§ngigkeit von der Pinguinart?

Alternativ k√∂nnen wir  die Hypothese pr√ºfen, ob die Mittelwerte "praktisch" gleich sind, also sich "kaum" unterscheiden. Der Grenzwert f√ºr "praktisch gleich" bzw. "kaum unterschiedlich" ist subjektiv. Dazu in @sec-rope mehr.



### Erster Blick in den Datensatz `penguins`

![Palmer Penguins](img/penguins-logo.png){width="25%"}

[Datenquelle](https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv), [Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/palmerpenguins/penguins.html)

Hier ist die Verteilung des Gewichts jeder Spezies im Datensatz, @tbl-penguins.

```{r}
#| results: hide
penguins %>% 
  select(body_mass_g, species) %>% 
  group_by(species) %>% 
  describe_distribution(range = FALSE, iqr = FALSE)
```

```{r}
#| echo: false
#| tbl-cap: "Die Verteilung des K√∂rpergewichts pro Spezies der Pinguine"
#| label: tbl-penguins
penguins %>% 
  select(body_mass_g, species) %>% 
  group_by(species) %>% 
  describe_distribution(range = FALSE, iqr = FALSE)
```




Was f√§llt Ihnen auf?



### Visualisierung (EDA)


Hier kommen die Pinguine! Wie schwer sind die Tiere in unserer Stichprobe, 
s. @fig-penguines1? 




```{r}
#| echo: false
#| label: fig-penguines1
#| fig-cap: "Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violine"
library(ggpubr)
ggviolin(penguins,
          x = "species",
         fill = "species",  # F√ºllfarbe nach `species`
          y = "body_mass_g") +
  scale_fill_okabeito()  #  Farbpalette nach Okabe & Ito
```

<!-- @fig-penguines2 zeigt die Gewichtsverteilung pro Spezies als "Bergr√ºcken" (`geom_ridges`). -->

<!-- ```{r fig.asp = .3, fig.width=7} -->
<!-- #| echo: false -->
<!-- #| label: fig-penguines2 -->
<!-- #| fig-cap: "Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Ridges" -->
<!-- ggplot(penguins) + -->
<!--   aes(x = body_mass_g, y = species) + -->
<!--   geom_density_ridges() -->
<!-- ``` -->

<!-- @fig-penguines3 zeigt die Gewichtsverteilung pro Spezies als "halbe Violinen" (`geom_ridges`),  -->
<!-- sozusagen Dichtediagramme um 90 Grad gedreht. -->

<!-- ```{r} -->
<!-- #| label: fig-penguines3 -->
<!-- #| fig-cap: "Verteilung des K√∂rpergewichts dreier Arten von Pinguinen - Geom Violindot" -->
<!-- penguins %>%  -->
<!--   ggplot(aes(x = species, y = body_mass_g, fill = species)) + -->
<!--   geom_violindot(fill_dots = "black") -->
<!-- ``` -->






### Gewicht pro Spezies, `m10.6`

Berechnen wir das mittlere Gewicht pro Spezies (Gruppe) der Pinguine, s. `m10.6` und @tbl-m106-params.

Die Modellformel  f√ºr `m10.6` lautet also `body_mass_g ~ species`.


```{r m106, echo = TRUE}
#| results: hide
options(mc.cores = parallel::detectCores())  # Turbo einschalten

m10.6 <- stan_glm(body_mass_g ~ species, 
                  data = penguins, 
                  refresh = 0,  # unterdr√ºckt Ausgabe der Posteriori-Stichproben
                  seed = 42  # zur Reproduzierbarkeit
                  )

m10.6 %>% parameters()
```

```{r}
#| echo: false
#| tbl-cap: "Parameter des Modells m10.6; neben dem Achsenabschnitt sind die Effekte der Gruppe Adelie und Chinstrap ausgewiesen"
#| label: tbl-m106-params
m10.6 %>% 
  parameters() %>% 
  display()
```




### Interpretation von `m10.6`

Die UV hat drei verschiedene Stufen (Werte, Auspr√§gungen; hier: Spezies), aber es werden in @tbl-m106-params nur zwei Stufen angezeigt (also eine weniger) zus√§tzlich zum Achsenabsdhnitt.
Die fehlende Stufe (`Adelie`, nicht ausgegeben) ist die *Vergleichs- oder Referenzkategorie* (baseline) und ist im Achsenabschnitt ausgedr√ºckt (Intercept).
Die Koeffizienten f√ºr `species` geben jeweils den (vorhergesagten) Unterschied zur Vergleichskategorie wieder.
Pinguine der Spezies `Adelie` haben laut Modell ein mittleres Gewicht von ca. 3700g.
Pinguine der Spezies Gentoo sind laut Modell im Mittel gut 1000g schwerer als Pinguine der Spezies `Adelie`, etc.


Der Unterschied im mittleren Gewicht von den Gruppen Chinstrap und Gentoo zur Referenzgruppe (Adelie) ist in @fig-m106-params verdeutlicht.

```{r plot-hdi-m106}
#| fig-cap: "Effekt der UV: Unterschiede zur Referenzgruppe (95%-HDI)"
#| label: fig-m106-params

plot(hdi(m10.6)) + scale_fill_okabeito()
```


Das [Farbschema nach Okabe und Ito](https://jfly.uni-koeln.de/color/) ist gut geeignet, um nominal skalierte Farben zu kodieren (s. [Details hier](https://data-se.netlify.app/2023/06/30/farbpaletten/)).


### Glauben wir jetzt an Gruppeneffekte?

Glauben wir jetzt, auf Basis der Modellparameter,
an Unterschiede (hinsichtlich der AV) zwischen den Gruppen (UV)?

Es scheinen sich nicht alle Gruppen voneinander zu unterscheiden. 
So ist der Mittelwert der Gruppe `Gentoo` deutlich h√∂her als der der beiden anderen Gruppen. 
Umgekehrt sind sich die Pinguinarten `Adelie` und `Chinstrap` in ihren Mittelwerten ziemlich √§hnlich.

Wie in @fig-m106-params ersichtlich,
√ºberlappt sich der Sch√§tzbereich f√ºr den Parameter von Gentoo *nicht* mit der Null;
hingegen √ºberlappt sich der Sch√§tzbereich des Parameters f√ºr Chinstrap deutlich mit der Nullinie.



Auf Basis unseres Modells verwerfen wir die also (mit hoher Sicherheit) die Hypothese, dass *alle* Mittelwerte   *exakt* identisch sind.

Ehrlicherweise h√§tte sowieso (fast) niemand geglaubt, dass die *exakte Nullhypothese* $\mu_1 = \mu_2 = \ldots = \mu_k$ bis in die letzte Dezimale gilt. Anders gesagt: Die Wahrscheinlichkeit eines bestimmten Wertes einer stetigen Zufallsvariable ist praktisch Null.
Aber: Viele Forschis pr√ºfen gerne die Nullhypothese, daher diskutieren wir den Begriff der (exakten) Nullhypothese.
Das Verfahren der Frequentistischen Statistik, um die Nullhypothese $\mu_1 = \mu_2 = \ldots = \mu_k$ zu testen, nennt man *Varianzanalyse* (analysis of variance, kurz *ANOVA*).
In der Bayes-Statistik nutzt man - wie immer - prim√§r die Post-Verteilung, um Fragen der Inferenz (z.B. Gruppenunterschiede dieser Art)  inferenzstatistisch zu beurteilen.








### Priori-Werte √§ndern

Unser Modell `m10.6` hat schwach informierte (weakly informative) Priors.
F√ºr Achsenabschnitt und die Regressionskoeffizienten trifft unser Golem Stan folgende Annahmen in der Voreinstellung:

- Achsenabschnitt und Regressionsgewichte werden als normalverteilt angenommen
- mit Mittelwert entsprechend den Stichprobendaten 
- und einer Streuung des Mittelwerts, die der 2.5-fachen der Streuung in der Stichprobe entspricht
- f√ºr Sigma wird eine Exponentialverteilung mit Rate $\lambda=1$ angenommen, skaliert mit der Streuung der AV.

Mehr Infos kann man sich mit `prior_summary(modell)` ausgeben lassen.


```{r}
prior_summary(m10.6)
```




Wo man man √ºber mehr inhaltliches Wissen verf√ºgt, so wird man die Prioris anpassen wollen.
So k√∂nnte man z.B. auf Basis von Fachwissen √ºber das Gewicht von Pinguinen postulieren,
dass Adelie-Pinguine im Mittel 3000 g wiegen. Und dass die anderen zwei Pinguin-Arten im Mittel sich nicht unterscheiden vom Mittelwert der Adelie-Pinguine.

```{r echo = TRUE}
m10.6b <- stan_glm(
  body_mass_g ~ species, 
  data = penguins, 
  refresh = 0,
  seed = 42,
  prior = normal(location = c(0, 0),  # betas, Mittelwert
                 scale = c(500, 500)),  # betas, Streuung
  prior_intercept = normal(3000, 500),  # Achsenabschnitt, Mittelwert und Streuung
  prior_aux = exponential(0.001)
)
coef(m10.6b)
```


Anstelle von Rohwerten (hier Angabe von Gramm Gewicht) kann man die Streuung auch in z-Werten eingeben, das macht es etwas einfacher.
Dazu gibt man bei dem oder den entsprechenden Parametern den Zusatz `autoscale = TRUE` an.



```{r echo = TRUE}
m10.6c <- stan_glm(
  body_mass_g ~ species, 
  data = penguins, 
  refresh = 0,
  seed = 42,
  prior = normal(location = c(0, 0),  # betas, Mittelwert
                 scale = c(2.5, 2.5),  # betas, Streuung
                 autoscale = TRUE),  # in z-Einheiten
  prior_intercept = normal(3000, 2.5,   # Achsenabschnitt, Mittelwert und Streuung
                           autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE)
)
coef(m10.6c)
```





Den Parameter f√ºr die Streuung des Modells, $\sigma$, kann man sich mit `sigma(modell)` ausgeben lassen.

```{r}
sigma(m10.6b)
```



Implizit bekommt man die Informationen zu $\sigma$ mitgeteilt durch die Gr√∂√üe der Konfidenzintervalle.

√úbrigens macht es meistens keinen Sinn, *extrem* weite Prioris zu definieren.^[s. Details [hier](https://mc-stan.org/rstanarm/articles/priors.html#how-to-specify-flat-priors-and-why-you-typically-shouldnt).]



### Vertiefung: Wechsel der Referenzkategorie

`species` ist eine nominale Variable, da passt in R der Typ `factor` (Faktor) am besten. Aktuell ist der Typ noch `character` (Text):

```{r echo = TRUE}
penguins <- penguins %>% 
  mutate(species = factor(species))
```


Im Standard sortiert R die Faktorstufen alphabetisch, aber man kann die Reihenfolge √§ndern. 

```{r echo = TRUE}
levels(penguins$species)
```

Setzen wir `Gentoo` als Referenzkategorie und lassen die restliche Reihenfolge, wie sie ist:

```{r echo = TRUE}
library(forcats)
penguins <- penguins %>% 
  mutate(species = factor(species),
    species = fct_relevel(species, "Gentoo"))
```

Beachten Sie, dass dazu das Paket `forcats` verf√ºgbar sein muss.

Jetzt haben wir die Referenzkategorie ge√§ndert:


```{r}
levels(penguins$species)
```









Der Wechsel der Referenzkategorie √§ndert nichts Wesentliches am Modell, s. @tbl-m106a.

```{r echo = TRUE}
#| results: hide
m10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)
hdi(m10.6a)
```


```{r}
#| echo: false
#| tbl-cap: "m10.6a mit ge√§nderter Referenzkategorie; die Effekte der UVs bleiben gleich."
#| label: tbl-m106a
m10.6a <- stan_glm(body_mass_g ~ species, data = penguins, refresh = 0)
hdi(m10.6a) |> display()
```













## `y ~ x1 + x2`


Hier untersuchen wir Forschungsfragen mit zwei metrischen UV (und einer metrischen AV).


### Forschungsfrage

>   Stehen sowohl der IQ der Mutter als auch, unabh√§ngig davon, das Alter der Mutter im Zusammenhang mit dem IQ des Kindes?


- Das ist eine *deskriptive* Forschungsfrage. *Keine* Kausalwirkung (etwa "IQ der Mutter ist die Ursache zum IQ des Kindes") wird impliziert. 
- Es geht in dieser Forschungsfrage rein darum, Zusammenh√§nge in den Daten - bzw. in der Population - aufzuzeigen.
- Viele Forschungsfagen gehen allerdings weiter und haben explizit Kausalwirkungen im Fokus. F√ºr solche Fragen ist ein Kausalmodell n√∂tig: Fachlich fundierte Annahmen √ºber Kausalzusammenh√§nge zwischen UV und AV.




### Was hei√üt, X h√§ngt mit Y zusammen?


- Der Begriff "Zusammenhang" ist nicht exakt.
- H√§ufig wird er (f√ºr metrische Variablen) verstanden als
    - lineare Korrelation $\rho$ bzw. $r$ 
    - lineare Regression $\beta$, bzw. $b$ 


- Der Regressionskoeffizient 
    - misst die *Steigung* der Regressionsgerade
    - zeigt, wie gro√ü der vorhergesagte Unterschied in Y, wenn man zwei Personen (Beobachtungseinheiten) vergleicht, die sich um eine Einheit in X unterscheiden
    - wird manchmal mit dem "Effekt von X auf Y" √ºbersetzt. Vorsicht: "Effekt" klingt nach Kausalzusammenhang. Eine Regression ist keine hinreichende Begr√ºndung f√ºr einen Kausalzusammenhang. 
    
- Der Korrelationskoeffizient
    - misst eine Art der St√§rke des linearen Zusammenhangs
    - zeigt, wie klein die Vorhersagefehler der zugeh√∂rigen Regression im Schnitt sind.
    - [Korrelation ist nicht (automatisch) Kausation.](https://xkcd.com/552/)
    



Es ist hilfreich, sich die Korrelationen zwischen den (metrischen) Variablen zu betrachten,
bevor man ein (Regressions-)Modell aufstellt, s. @tbl-cor-kidiq.


```{r echo = TRUE, eval = FALSE}
kidiq %>% 
  correlation()
```

```{r}
#| echo: false
#| label: tbl-cor-kidiq
#| tbl-cap: "Korrelation der Variablen im Datensatz kidiq (inkl. frequentistischer Statistiken wie t- und p-Werten, die wir hier ignorieren)"
kidiq %>% 
  correlation() %>% 
  display()
```


@tbl-kidiq-corr zeigt die Korrelationsmatrix als Korrelationsmatrix.

```{r}
#| eval: false
kidiq %>% 
  correlation() %>% 
  summary()
```

```{r}
#| echo: false
#| label: tbl-kidiq-corr
#| tbl-cap: "Die Korrelationen zwischen den Variablen der Tabelle kidiq. Die Sterne geben einen Bereich des p-Werts an (wir ignorieren die Sterne hier)."
kidiq %>% 
  correlation() %>% 
  summary() |> 
  display()
```


N√ºtzlich ist auch die Visualisierung der Korrelationstabelle als Heatmap, @fig-kidiq-heatmap.

```{r echo = TRUE}
#| label: fig-kidiq-heatmap
#| fig-cap: "Visualisierung der Korrelationsmatrix als Heatmap"
kidiq %>% 
  correlation() %>% 
  summary() %>% 
  plot()
```




### Univariate Regressionen

Wir berechnen jeweils eine univariate Regression, pro Pr√§diktor,
also eine f√ºr `mom_iq` und eine f√ºr `mom_age`.

```{r echo = TRUE}
m10.7 <- stan_glm(kid_score ~ mom_iq, data = kidiq, refresh = 0)
m10.8 <- stan_glm(kid_score ~ mom_age, data = kidiq, refresh = 0)
```

@tbl-m107 zeigt die Ergebnisse f√ºr `mom_iq`.

```{r}
#| echo: false
#| tbl-cap: "Parameter f√ºr m10.7"
#| label: tbl-m107
parameters(m10.7) |> 
  print_md()
```

@tbl-m108 zeigt die Ergebnisse f√ºr `mom_age`.


```{r}
#| echo: false
#| tbl-cap: "Parameter f√ºr m10.8"
#| label: tbl-m108
parameters(m10.8) |> 
  print_md()
```




### Visualisierung der univariaten Regressionen

In @fig-regr-one-pred ist die univariate Regression mit jeweils einem der beiden Pr√§diktoren dargestellt.


`m10.7`: Die Steigung betr√§gt `r round(coef(m10.7)[2], 1)`.
`m10.8`: Die Steigung betr√§gt `r round(coef(m10.8)[2], 1)`.




```{r p1-p2}
#| fig-cap: Zwei univariate Regressionen
#| label: fig-regr-one-pred
#| echo: false
p1 <- 
  kidiq %>% 
  ggplot(aes(x = mom_iq, y = kid_score)) +
  geom_point() +
  geom_abline(intercept = coef(m10.7)[1],
              slope = coef(m10.7)[2],
              color = "blue") 

p2 <- 
kidiq %>% 
  ggplot(aes(x = mom_age, y = kid_score)) +
  geom_point() +
  geom_abline(intercept = coef(m10.8)[1],
              slope = coef(m10.8)[2],
              color = "blue")

plots(p1, p2,
      title = c("m10.7: Die univariate Regression mit dem Alter der Mutter als Pr√§diktor",
        "m10.8: Die univariate Regression mit dem IQ der Mutter als Pr√§diktor"))
```


Univariate Regressionen




### Multiples Modell (beide Pr√§diktoren), m10.9


`m10.9` stellt das multiple Regressionsmodell dar;
*multipel* bedeutet in diesem Fall, dass mehr als ein Pr√§diktor im Modell aufgenommen ist, s @tbl-m109.


```{r m109, echo = TRUE}
#| message: false
#| results: hide
m10.9 <- stan_glm(kid_score ~ mom_iq + mom_age, 
                  data = kidiq, 
                  refresh = 0)
parameters(m10.9)
```



```{r}
#| echo: false
#| tbl-cap: "Parameter f√ºr m10.9"
#| label: tbl-m109
parameters(m10.9) |> 
  print_md()
```



:::callout-important
Die Regressionsgewichte unterscheiden sich (potenziell) zu den von den jeweiligen univariaten Regressionen.
:::


Bei einer multiplen Regression ist ein Regressionsgewicht jeweils "bereinigt" vom Zusammenhang mit dem (oder den) anderen Regressionsgewicht.
Das bedeutet anschaulich, man betrachtet den den Zusammenhang einee UV mit der AV, wobei man gleichzeitig den anderen Pr√§diktor konstant h√§lt.




::: {.content-visible when-format="html"}



In @fig-m109-plotly ist das Modell `m10.9` in 3D dargestellt via [Plotly](https://plotly.com/r/).

```{r m109-plotly, out.width = "100%", fig.align="center"}
#| echo: false
#| label: fig-m109-plotly
#| fig-cap: "3D-Visualisierung von m10.9 (zwei Pr√§diktoren)"
lm1_coef <- coef(m10.9)
x1_seq <- seq(min(kidiq$mom_iq), max(kidiq$mom_iq), length.out = 25)
x2_seq <- seq(min(kidiq$mom_age), max(kidiq$mom_age), length.out = 25)

z <- t(outer(x1_seq, x2_seq, 
              function(x,y) lm1_coef[1]+lm1_coef[2]*x+lm1_coef[3]*y))

if (knitr:::is_html_output()) {
plot_ly(width = 800, height = 500,
  x=~x1_seq, y=~x2_seq, z=~z,type="surface") %>%
  add_trace(data=kidiq, 
            x=~mom_iq, y=~mom_age, z=~kid_score, 
            mode="markers", 
            type="scatter3d",
            marker = list(color="#00998a", 
                          opacity=0.7, 
                          size = 1,
                          symbol=105)) %>% 
  layout(scene = list(
    aspectmode = "manual", 
    aspectratio = list(x=1, y=1, z=1),
    xaxis = list(title = "mom_iq"),
    yaxis = list(title = "mom_age"),
    zaxis = list(title = "kid_score")))
}

if (knitr:::is_latex_output()) {
  knitr::include_graphics("img/m109-plotly.jpg")
}
```


:::



@fig-m109-color zeigt eine Visualisierung von m10.9,
in der die 3. Dimension durch eine Farbschattierung ersetzt ist.


```{r fig-m109-color, fig.asp = .5}
#| echo: false
#| label: fig-m109-color
#| fig-cap: "Modell m10.9; die Farbverl√§ufe zeigen der Wert der abh√§ngigen Variablen"
kidiq <-
  kidiq %>%
  mutate(pred_m10.9 = predict(m10.9))

grid1 <- expand_grid(mom_iq = x1_seq, mom_age =  x2_seq) %>% 
  mutate(pred_m10.9 = predict(m10.9, newdata = data.frame(mom_iq,
                                                              mom_age)))

ggplot(aes(x = mom_iq, y = mom_age), data = grid1) +
  geom_raster(aes(fill = pred_m10.9)) +
 # geom_point(aes(color = kid_score_pred)) +
  scale_fill_viridis_c() +
  scale_color_viridis_c() +
  geom_point(data = kidiq,  alpha = .3, size = .7)
```


Auf der Achse von mom_iq erkennt man deutlich (anhand der Farb√§nderung) die Ver√§nderung f√ºr die AV (kid_score). Auf der Achse f√ºr `mom_age` sieht man, dass sich die AV kaum √§ndert, wenn sich `mom_age` √§ndert.




### Visualisierung in 10 Dimensionen

@fig-ten-dims visualisiert den Zusammenhang von 10 Variablen untereinander.

```{r plot-ten-dims, out.width="50%"}
#| fig-align: "center"
#| echo: false
#| label: fig-ten-dims
#| fig-cap: "So sieht der Zusammenhang im 10-dimensionalen Raum aus"
ggplot(data.frame(x=NA, y=NA)) +
  theme(panel.background = element_rect(fill = 'lightblue'))
```

Leider macht mein Hirn hier nicht mit. Unsere Schw√§chen, eine gro√üe Zahl an Dimensionen zu visualisieren, ist der Grund, warum wir mathematische Modelle brauchen.

Daher kann man ein Modell verstehen als eine Zusammenfassung eines (ggf. hochdimensionalen) Variablenraums.





## `y ~ x1_z + x2_z`

In diesem Abschnitt untersuchen wir ein Modell mit zwei z-standardisierten, metrischen Pr√§diktoren (und einer metrischen, *nicht*-standardisierten AV).


### Relevanz der Pr√§diktoren


Woher wei√ü man,
welche UV am st√§rksten mit der AV zusammenh√§ngt?
Man k√∂nnte auch sagen: Welcher Pr√§diktor (welche UV) am "wichtigsten" ist
oder den "st√§rksten Einfluss" auf die AV aus√ºbt?
Bei solchen kausal konnotierten Ausdr√ºcken muss man vorsichtig sein:
Die Regressionsanalyse als solche ist keine Kausalanalyse.
Die Regressionsanalyse - wie jede statistische Methoden - kann
f√ºr sich *nur Muster in den Daten*, also Zusammenh√§nge bzw. Unterschiede,
entdecken, s. @fig-how-would-i-know.
M√∂chte man die Relevanz von Pr√§diktoren vergleichen,
so ist ein Kausalmodell empfehlenswert.


![Made at imgflip.com](img/5sps62.jpg){#fig-how-would-i-know width=50%}








Welcher Pr√§diktor ist nun "wichtiger" oder "st√§rker" in Bezug auf den Zusammenhang mit der AV, `mom_iq` oder `mom_age` (Modell `m10.9`)?
Die Antwort h√§ngt auch von der Streuung bzw. Skalierung der Variablen ab.
`mom_iq` hat den gr√∂√üeren Koeffizienten und viel Streuung; `mom_age` hat weniger Streuung.


Um die Relevanz der Pr√§diktoren vergleichen zu k√∂nnen, m√ºsste man vielleicht die Ver√§nderung von `kid_score` betrachten, wenn man von kleinsten zum gr√∂√üten Pr√§diktorwert geht.
Allerdings sind Extremwerte meist instabil (da sie von einer einzigen Beobachtung bestimmt werden).
Sinnvoller ist es daher, die Ver√§nderung in der AV zu betrachten, wenn man den Pr√§diktor von "unterdurchschnittlich" auf "√ºberdurchschnittlich" √§ndert.
Das kann man mit *z-Standardisierung* erreichen, s. @sec-standardnormalverteilung.







<!-- ### z-Standardisierung -->



<!-- *z-Standardisierung* bedeutet, eine Variable so zu transformieren, dass sie √ºber einen Mittelwert von 0 und eine SD von 1 verf√ºgt: -->

<!-- $$z = \frac{x - \bar{x}}{sd(x)}$$ -->

```{r kidiq2, echo = TRUE}
kidiq2 <- 
  kidiq %>% 
  mutate(mom_iq_z = ((mom_iq - mean(mom_iq)) / sd(mom_iq)))  %>%  # z-Transformation
  select(mom_iq, mom_iq_z) 

kidiq2 %>% 
  head()
```


Der Nutzen von Standardisieren (dieser Art) ist die *bessere Vergleichbarkeit* der Effekte von UV, die (zuvor) verschiedene Mittelwerte und Streuungen hatten^[am n√ºtzlichsten ist diese Standardisierung bei normal verteilten Variablen.].
Die Standardisierung ist √§hnlich zur Vergabe von Prozentr√§ngen: "Dieser Messwert geh√∂rt zu den Top-3-Prozent".
Diese Aussage ist bedeutsam f√ºr Variablen mit verschiedenem Mittelwert und Streuung.
So werden vergleichende Aussagen f√ºr verschiedene Verteilungen m√∂glich.






### Statistiken zu den z-transformierten Variablen

@tbl-kidiq1 zeigt die Verteilung der (metrischen) Variablen im Datensatz `kidiq`.

Metrische Variablen in z-Werte zu transformieren, hat verschiedenen Vorteile:

- der Achsenabschnitt ist einfacher zu interpretieren (da er sich dann auf ein Objekt mit mittlerer Auspr√§gung bezieht)
- Interaktionen sind einfacher zu interpretieren (aus dem gleichen Grund)
- Prioriwerte sind einfacher zu definieren (wieder aus dem gleichen Grund)
- die Effekte verschiedener Pr√§diktoren sind einfacher in ihrer Gr√∂√üe zu vergleichen, da dann mit gleicher Skalierung/Streuung
- kleine und √§hnlich gro√üe Wertebereich erleichtern dem Golem die Rechenarbeit


Man kann die z-Transformation ("Skalierung") mit `standardize` (aus `easystats`) durchf√ºhren, s. @tbl-kidiq-z.


```{r kidiq-stand}
kidiq_z <- 
  standardize(kidiq, append = TRUE)  # z-transformiert alle numerischen Werte
```



```{r kidiq-stand-print}
#| label: tbl-kidiq-z
#| tbl-cap: "z-transformierte Variablen im Datensatz kidiq (erste paar Zeilen)"
#| echo: false
standardize(kidiq, append = TRUE) |> 
  head() |> 
  display()
```


Der Schalter `append = TRUE` sorgt daf√ºr, dass die urspr√ºnglichen Variablen beim z-Standardisieren nicht √ºberschrieben werden, sondern angeh√§ngt werden (mit einem Suffix `_z`).


Man kann auch nur einzelne Variablen mit `standardize` standardisieren, indem man das Argument `select` nutzt.

```{r}
#| eval: false
kidiq %>% 
  standardize(select = c("mom_iq", "mom_age", "kid_score"))
```



Man kann das Standardisieren auch von Hand machen, ohne ein Extra-Paket, s. @tbl-scale-manual.
Dazu verwendet man den Befehl `scale()`.

```{r}
#| eval: false
kidiq %>% 
  mutate(mom_iq_z2 = scale(mom_iq),
         mom_age_z2 = scale(mom_age),
         kid_score_z2 = scale(kid_score))
```


```{r echo = TRUE}
#| echo: false
#| label: tbl-scale-manual
#| tbl-cap: Z-Standardisierung ohne Extrapaket"
kidiq %>% 
  mutate(mom_iq_z2 = scale(mom_iq),
         mom_age_z2 = scale(mom_age),
         kid_score_z2 = scale(kid_score)) %>% 
  head()
```



### Modell

Berechnen wir das Modell `m10.10`: `y ~ x1_z + x2_z`.

```{r}
#| results: hide
m10.10 <- stan_glm(kid_score ~ mom_iq_z + mom_age_z, 
                   data = kidiq_z, 
                   refresh = 0)
parameters(m10.10)
```

```{r}
#| echo: false
#| tbl-cap: "Parameter von m10.12"
#| label: tbl-m1010

parameters(m10.10) |> print_md()
```




## `y_z ~ x1_z + x2_z`


In diese Abschnitt berechnen wir ein Modell (Modell `m10.12`), in dem sowohl die Pr√§diktoren z-transformiert sind (standardisiert) *als auch* die *AV*.
Das z-Standardisieren der AV, `kid_score` ist zwar *nicht* n√∂tig, um den Effekt der Pr√§diktoren (UV) auf die AV zu untersuchen.
Standardisiert man aber die AV, so liefern die Regressionskoeffizienten (Betas) Aussage dar√ºber,
um wie viele *SD-*Einheiten sich die AV ver√§ndert, wenn sich ein Pr√§diktor um eine *SD-*Einheit ver√§ndert.
Das kann auch eine interessante(re) Aussage sein.

### Modell `y_z ~ x1_z + x2_z`

Berechnen wir das Modell `m10.12`: `y_z ~ x1_z + x2_z`.

```{r m10-11, echo = TRUE}
m10.12 <- stan_glm(kid_score_z ~ mom_iq_z + mom_age_z, 
                   data = kidiq_z, 
                   refresh = 0)
coef(m10.12)
```


- Der *Achsenabschnitt* gibt den Mittelwert der AV (`kid_score`) an, da `kid_score_z = 0` identisch ist zum Mittelwert von  `kid_score`.
- Der Koeffizient f√ºr `mom_iq_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) √§ndert, wenn sich `mom_iq` um eine SD-Einheit √§ndert. 
- Der Koeffizient f√ºr `mom_age_z` gibt an, um wie viele SD-Einheiten sich `kid_score` (die AV) √§ndert, wenn sich `mom_age` um eine SD-Einheit √§ndert.



Jetzt sind die Pr√§diktoren in ihrer Relevanz (Zusammenhang mit der AV) vergleichbar.
Man sieht, dass die Intelligenz der Mutter *deutlich wichtiger* ist das Alter der Mutter (im Hinblick auf die Vorhersage bzw. den Zusammenhang mit mit der AV).




### 95%-PI


Mit `parameters` k√∂nnen wir uns ein PI f√ºr `m10.12` ausgeben lassen, s. @fig-m1011hdi;
 im Standard wird ein 95%-ETI berichtet^[Zumindest zur Zeit als ich diese Zeilen schreibe. Achtung: Voreinstellungen k√∂nnen sich √§ndern. Am besten in der Dokumentation nachlesen: `?parameters`.].


```{r m10-11-params-noeval, echo = TRUE}
#| eval: false
parameters(m10.12) 
```

```{r m10-11-params}
#| echo: false
parameters(m10.12) %>% display()
```



```{r m10-11-params-plot}
#| label: fig-m1011hdi
#| fig-cap: "Im Standard wird ein 95%-Intervall gezeigt bzw. berechnet; hier das ETI f√ºr m10.12"
plot(eti(m10.12)) + scale_fill_okabeito()
```



### Modellg√ºte

```{r m10-11-r2}
r2(m10.12)
```


Ist dieser Wert von $R2$ "gut"?
Diese Frage ist √§hnlich zur Frage "Ist das viel Geld?"; 
man kann die Frage nur im Kontext beantworten.

Eine einfache L√∂sung ist immer, Modelle zu vergleichen.
Dann kann man angeben, welches Modell die Daten am besten erkl√§rt,
z.B. auf Basis von $R^2$.

Zu beachten ist, dass das Modell theoretisch fundiert sein sollte.
Vergleicht man viele Modelle aufs Geratewohl, so muss man von zuf√§llig hohen Werten der Modellg√ºte im Einzelfall ausgehen.


Wenn Sie aber unbedingt eine "objektive" Antwort auf die Frage "wie viel ist viel?" haben wollen,
ziehen wir Herrn Cohen zu Rate, der eine Antwort auf die Frage "Wieviel ist viel?" gegeben hat [@cohen1992]:


```{r}
interpret_r2(0.2)  # aus `easystats`
```

Danke, Herr Cohen!


### Priori-Verteilung f√ºr `m10.12` und Modelldefinition

Die Prioris f√ºr `m10.12` kann man sich mit `prior_summary(m10.12)` ausgeben lassen.
Danke, Stan!


```{r m10-11-prior}
prior_summary(m10.12)  # aus rstanarm
```


>   ü§ñ  Nix zu danken!

Wie gesagt, Stan nimmt daf√ºr einfach die empirischen Mittelwerte und Streuungen her.^[Nicht unbedingt die feine bayesianische Art, denn die Prioris sollten ja eigentlich apriori, also vor Kenntnis der Daten, bestimmt werden. Auf der anderen Seite behauptet Stan, von uns zur Rede gestellt, dass die empirischen Mittelwerte ja doch gute Sch√§tzer der echten Parameter sein m√ºssten, wenn die Stichprobe, die wir ihm angeschleppt h√§tten, tats√§chlich gut ist...]

Stans Ausgabe kann man in Mathe-Sprech so darstellen, s. @eq-m1012.


$$
\begin{aligned}
\text{kidscore}^z_i  &\sim \mathcal{N}(\mu_i,\sigma)\\
\mu_i &= \beta_0 + \beta_1\text{momiq}_i^z + \beta_2\text{momage}_i^z \\
\beta_0 &\sim \mathcal{N}(0,2.5)\\
\beta_1 &\sim \mathcal{N}(0,2.5)\\
\beta_2 &\sim \mathcal{N}(0,2.5)\\
\sigma &\sim \mathcal{E}(1)
\end{aligned}
$${#eq-m1012}

Man beachte, dass der Achsenabschnitt zur Intelligenz der Kinder auf Null festgelegt wird:
Bei *mittlerer* Intelligenz und *mittlerem* Alter der Mutter wird *mittlere* Intelligenz des Kindes erwartet in `m10.12`. 
Dadurch, dass nicht nur UV, sondern auch AV z-standardisiert (d.h. zentriert und in der Streuung auf 1 standardisiert) sind, ist der Mittelwert der AV Null.

Schreibt man einen Bericht, so bietet es sich an, die Modelldefinition zumindest im Anhang aufzuf√ºhren.


:::{#exm-anz-mod-m1011}
### Anzahl der Modellparameter
Wie viele Modellparameter hat `m10.12`?^[4: $\beta_0, \beta_1, \beta_2, \sigma$]
:::

### Antwort auf die Forschungsfrage



>   Das Modell spricht sich klar f√ºr einen statistischen, linearen Effekt von Intelligenz der Mutter auf die Intelligenz des Kindes aus, wenn das Alter der Mutter statistisch kontrolliert wird (95%PI: [0.38, 0.51]). 
Pro Einheit Standardabweichung in der UV (Intelligenz der Mutter) √§ndert sich die AV um ca. 0.44 Standardabweichungseinheiten.
Hingegen zeigt das Modell, dass das Alter der Mutter statistisch eher keine Rolle spielt (95%PI: [-0.02, 0.12]). Alle Variablen wurden z-transformiert. Insgesamt erk√§rt das Modell im Median einen Anteil von ca. 0.2 an der Varianz der Kinderintelligenz. Das Modell griff auf die Standard-Priori-Werte aus dem R-Paket rstanarm [@goodrich2020] zur√ºck (s. Anhang f√ºr Details).



:::callout-important
Hier wird von einem "statistischen Effekt" gesprochen, um klar zu machen, 
dass es sich lediglich um assoziative Zusammenh√§nge, 
und nicht um kausale Zusammenh√§nge, handelt.
Kausale Zusammenh√§nge d√ºrfen wir nur verk√ºnden, 
wenn wir sie a) explizit untersuchen und b) sich in der Literatur Belege daf√ºr finden oder c) wir ein Experiment fachgerecht durchgef√ºhrt haben.
:::






## Vertiefung


üèéÔ∏èVERTIEFUNG, nicht pr√ºfungsrelevantüèéÔ∏è








### Verwandtheit von Korrelation und Regression


Sind X und Y *z-standardisiert*, so sind Korrelation und Regression identisch, s. @thm-br.

::: {#thm-br}

### Regression als Korrelation

$$b = r \frac{sd_x}{sd_y}\quad \square$$
:::

Berechnen wir dazu ein einfaches Modell mit z-standardisierten Variablen 
und betrachten die Punktsch√§tzer f√ºr die Regressionskoeffizienten, s. m10.12.

```{r m10-12, echo = TRUE}
m10.12 <- 
  stan_glm(kid_score_z ~ mom_iq_z , data = kidiq_z, refresh = 0)
coef(m10.12)
```

Vergleichen Sie diese Werte mit der Korrelation, s. @tbl-m10.12-corr.^[Ignorieren Sie die Zeile mit dem Befehl `display()`. Dieser Befehl dient nur dazu, die Ausgabe zu versch√∂nern in Markdown-Dokumenten, wie im Quelltext dieses Kapitels.]

```{r}
#| label: tbl-m10.12-corr
#| fig-cap: "Korrelationen der z-transformierten Variablen im Datensatz kidiq"

kidiq_z %>% 
  select(kid_score, mom_iq, kid_score_z, mom_iq_z) %>% 
  correlation() |> 
  display()
```






### Pr√ºfen der Linearit√§tsannahme


Zentrale Annahme eines linearen Modells: Die AV ist eine *lineare* Funktion der einzelnen Pr√§diktoren, $y= \beta_0 + \beta_1x_1 + \beta_2 x_2 + \cdots $, vgl. @thm-lm.

Hingegen ist es weniger wichtig, dass die AV (y) normalverteilt ist.
Zwar nimmt die Regression h√§ufig normalverteilte Residuen an^[was auf normal verteilte AV hinauslaufen kann aber nicht muss], aber diese Annahme ist nicht wichtig, wenn es nur darum geht, die Regressionskoeffizienten zu sch√§tzen [@gelman2021].





Ist die Linearit√§tsannahme erf√ºllt, so sollte der Residualplot nur *zuf√§llige* Streuung um $y=0$ herum zeigen, s. @fig-kidiqresiduum.


Ein Residuum $e$ ist der Vorhersagefehler, also die Differenz zwischen vorhergesagtem und tats√§chlichem Wert: $e_i = y_i - \hat{y}_i$

```{r kidiq-def}
kidiq <-
  kidiq %>% 
  mutate(m10.12_pred = predict(m10.12),  # vorhergesagten Werte
         m10.12_resid = resid(m10.12))  # Residuen
```



```{r fig.asp = .5}
#| label: fig-kidiqresiduum
#| fig-cap: "Die Verteilung der Fehler scheint keinem starken Trend (in Abh√§ngigkeit zum vorhergesagten Wert) zu folgen, was ein gutes Zeichen ist."
kidiq %>% 
  ggplot(aes(x = m10.12_pred, y = m10.12_resid)) +
  geom_hline(color="white", yintercept = 0, size = 2) +
  geom_hline(color = "grey40", 
             yintercept = c(-1,1), 
             size = 1, 
             linetype = "dashed") +
  geom_point(alpha = .7) +
  geom_smooth()
```

Hier erkennt man keine gr√∂√üeren Auff√§lligkeiten.







### Modellpr√ºfung mit der PPV


```{r m10-11-pp-check, echo = TRUE, fig.asp = .5}
pp_check(m10.12)
```

Unser Modell - bzw. die Stichproben unserer Posteriori-Verteilung, $y_{rep}$ verfehlt den Mittelwert von $y$ leider recht h√§ufig.





### Visualisierung der bereinigten Regressionskoeffizienten


```{r kidiq3}
#| echo: false
#| results: "hide"


kidiq3 <- 
  kidiq %>% 
  standardize(append = TRUE) %>% 
  sample_n(size = 300)


m10.12a <- stan_glm(mom_age_z ~ mom_iq_z, data = kidiq3, refresh = 0, chains = 1)
m10.12b <- stan_glm(mom_iq_z ~ mom_age_z, data = kidiq3, refresh = 0, chains = 1)

kidiq3 <-
  kidiq3 %>% 
  mutate(mom_age_resid = resid(m10.12a)) %>% 
  mutate(mom_iq_resid = resid(m10.12b))


m10.12c <- stan_glm(kid_score_z ~ mom_age_resid, data = kidiq3, refresh = 0, chains = 1)
m10.12d <- stan_glm(kid_score_z ~ mom_iq_resid, data = kidiq3, refresh = 0, chains = 1)


kidiq3 <-
  kidiq3 %>% 
  mutate(m10.12c_resid = resid(m10.12c)) %>% 
  mutate(m10.12d_resid = resid(m10.12d))
```


```{r comp-resid-lm-plot-kidiq3}
#| echo: false
m10.12a_plot <-
  kidiq3 %>% 
  ggplot() +
  aes(x = mom_iq_z, y = mom_age_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.12a)[2],
              intercept = coef(m10.12a)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m10.12a),
                   x = mom_iq_z,
                   xend = mom_iq_z,
                   yend = mom_age_z),
               color = "skyblue3",
               alpha = .1) +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))


m10.12b_plot <-
  kidiq3 %>% 
  ggplot() +
  aes(y = mom_iq_z, x = mom_age_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.12b)[2],
              intercept = coef(m10.12b)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m10.12b),
                   x = mom_age_z,
                   xend = mom_age_z,
                   yend = mom_iq_z),
               color = "skyblue3",
               alpha = .1)  +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))


m10.12c_plot <-
  kidiq3 %>%
  ggplot() +
  aes(x = mom_age_resid, y = kid_score_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.12c)[2],
              intercept = coef(m10.12c)[1],
              color = "blue")   +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))



m10.12d_plot <-
  kidiq3 %>% 
  ggplot() +
  aes(x = mom_iq_resid, y = kid_score_z) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m10.12d)[2],
              intercept = coef(m10.12d)[1],
              color = "blue")  +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(-2, 2))

```


```{r resid-lm-plot, fig.asp = .619}
#| echo: false
#| fig-cap: "Bereinigte Regressionskoeffizienten"
#| label: fig-bereinigt
plots(m10.12a_plot, m10.12b_plot, m10.12c_plot, m10.12d_plot, 
      n_rows = 2, tags = "A",
      caption = "Die vertikalen Balken zeigen die Residuen.",
      guides = "collect")
```














@fig-bereinigt zeigt in der oberen Reihe die Regression eines Pr√§diktors auf den anderen Pr√§diktor.
Untere Reihe: Regression der Residuen der oberen Reihe auf die AV, `kid-score_z`. 
Unten links (C): Die Residuen von `mom_iq_c` sind kaum mit der AV assoziiert. Das hei√üt, nutzt man den Teil von `mom_age_z`, der nicht mit `mom_iq_z` zusammenh√§ngt, um `kid_score` vorher zusagen, findet man keinen (*kaum*) Zusammenhang.
Unten rechts (D): Die Residuen von `mom_age_c` sind *stark* mit der AV assoziiert. Das hei√üt, nutzt man den Teil von `mom_iq_z`, der nicht mit `mom_age_z` zusammenh√§ngt, um `kid_score` vorher zusagen, findet man einen starken Zusammenhang.



Eine multiple Regression liefert die gleichen Regressionskoeffizienten wie die Modelle aus Teildiagrammen (C) und (D).






### Bayesianisch gleich Frequentistisch?





```{r mtcars2}
#| results: "hide"
#| echo: false

mtcars2 <-
  mtcars %>% 
  standardize()

m13a <- stan_glm(disp ~ wt, data = mtcars2, refresh = 0, chains = 1)
m13b <- stan_glm(wt ~ disp, data = mtcars2, refresh = 0, chains = 1)

mtcars2 <-
  mtcars %>% 
  mutate(m13a_resid = resid(m13a)) %>% 
  mutate(m13b_resid = resid(m13b))


m13c <- stan_glm(mpg ~ m13a_resid, data = mtcars2, refresh = 0, chains = 1)
m13d <- stan_glm(mpg ~ m13b_resid, data = mtcars2, refresh = 0, chains = 1)


mtcars2 <-
  mtcars2 %>% 
  mutate(m13c_resid = resid(m13c)) %>% 
  mutate(m13d_resid = resid(m13d))
```


```{r comp-resid-lm-plot}
#| echo: false
m13a_plot <-
  mtcars2 %>% 
  ggplot() +
  aes(x = wt, y = disp) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m13a)[2],
              intercept = coef(m13a)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m13a),
                   x = wt,
                   xend = wt,
                   yend = disp),
               color = "skyblue3")



m13b_plot <- 
mtcars2 %>% 
  ggplot() +
  aes(y = wt, x = disp) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m13b)[2],
              intercept = coef(m13b)[1],
              color = "blue") +
  geom_segment(aes(y = predict(m13b),
                   x = disp,
                   xend = disp,
                   yend = wt),
               color = "skyblue3")

m13c_plot <-
  mtcars2 %>%
  ggplot() +
  aes(x = m13a_resid, y = mpg) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m13c)[2],
              intercept = coef(m13c)[1],
              color = "blue")  +
  scale_x_continuous(limits = c(-1,1))



m13d_plot <-
  mtcars2 %>% 
  ggplot() +
  aes(x = m13b_resid, y = mpg) +
  geom_point(alpha = .5) +
  geom_abline(slope = coef(m13d)[2],
              intercept = coef(m13d)[1],
              color = "blue")   +
  scale_x_continuous(limits = c(-1,1))

```


```{r resid-lm-plot-mtcars}
#| echo: false
#| fig-cap: "Pr√ºfung der Voraussetzungen des Modells"
#| label: fig-resid-lm-plot
#| eval: false
plots(m13a_plot, m13b_plot, m13c_plot, m13d_plot, n_rows = 2, tags = "A",
      guides = "collect")
```


√úbrigens liefern `stan_glm()` und `lm` oft √§hnliche Ergebnisse (bei schwach informativen Prioriwerten):

```{r stan-vs-lm}
stan_glm(mpg ~ hp + cyl, data = mtcars, refresh = 0) %>% coef()

lm(mpg ~ hp + cyl, data = mtcars) %>% coef()
```


:::callout-important
Wenn auch die  Ergebnisse eines Frequentistischen und Bayes-Modell numerisch √§hnlich sein k√∂nnen, so ist doch die Interpretation grundverschieden. 
Bayesmodelle erlauben Wahrscheinlichkeitsaussagen zu den Parametern, Frequentistische Modelle nicht.
:::







## Fazit


### Austieg: Bayes in f√ºnf Minuten


Eine Kurzdarstellung des Bayes-Inferenz findet sich [in diesem Post](https://data-se.netlify.app/2022/01/27/bayes-in-f%C3%BCnf-minuten/) und in [diesem](https://data-se.netlify.app/2022/01/28/bayes-in-f%C3%BCnf-minuten-f%C3%BCr-fortgeschrittene/).


üì∫ [Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: mtcars](https://www.youtube.com/watch?v=Yoo8IcmwRWg)

üì∫ [Musterl√∂sung und Aufgabe im Detail besprochen - Bayes-Modell: CovidIstress](https://www.youtube.com/watch?v=5A5bDNeB6sA)



### Ausblick: Bin√§re AV


>    *Forschungsfrage:* Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart? (Datensatz `mtcars`)


Dazu nutzen wir den Datensatz `mtcars`, wobei wir die Variablen z-standardisieren.

```{r echo = TRUE}
data(mtcars)
mtcars2 <-
  mtcars %>% 
  standardize(append = TRUE)
```


Dann berechnen wir mit Hilfe von Stan ein Regressionsmodell: `m14: am ~ mpg_z`:

```{r m13, echo = TRUE, results = "show"}
m14 <-
  stan_glm(am ~ mpg_z, 
           data = mtcars2, 
           refresh = 0)
coef(m14)
```

Ab  `mpg_z = `r round(coef(m14),2)`` sagt das Modell `am=1` (manuell) vorher. Ganz ok.




```{r}
mtcars2 %>% 
  ggplot(aes(x = mpg_z, y = am)) +
  geom_hline(yintercept = 0.5, color = "white", size = 2) +
  geom_point() +
  geom_abline(intercept = coef(m14)[1],
              slope = coef(m14)[2],
              color = "blue") 
```


```{r neg-am-predict}
neg_am <- predict(m14, newdata = tibble(mpg_z = -1.3))
```


F√ºr kleine Werte von `mpg_z` (<1.3) sagt unser Modell *negative* Werte f√ºr `am` voraus. Das macht keinen Sinn: Es gibt keine negative Werte von `am`, nur 0 und 1.
M√ºssen wir mal bei Gelegenheit besser machen.






::: {.content-visible when-format="html"}

### Genug f√ºr heute



Wir waren flei√üig ... 

```{r}
#| echo: false
if (knitr:::is_html_output()) {
  knitr::include_graphics("https://media.giphy.com/media/XIqCQx02E1U9W/giphy.gif")
}
```

[Quelle](https://giphy.com/gifs/XIqCQx02E1U9W)


:::





:::callout-important
Kontinuierliches Lernen ist der Schl√ºssel zum Erfolg.
:::


Genug f√ºr heute. üëç 


### Weiterf√ºhrende Literatur

Weiter Hinweise zu den Themen dieses Kapitels dazu finden sich bei @gelman2021, Kap. 10, insbesondere 10.3.

@gelman2021 bieten einen Zugang mittleren Anspruchs zur Regressionsmodellierung. Das Buch ist von einem weltweit f√ºhrenden Statistiker geschrieben und vermittelt tiefe Einblicke bei gleichzeitig √ºberschaubarem mathematischen Aufwand. 

F√ºr das vorliegende Kapitel sind insbesondere daraus die Kapitel 6,7, und 10 relevant.



## Aufgaben


### Papier-und-Bleistift-Aufgaben



1. [anz-params](https://datenwerk.netlify.app/posts/anz-params/)
1. [fofrage-regrformel2](https://datenwerk.netlify.app/posts/fofrage-regrformel2/)
2. [modelldef-regrformel](https://datenwerk.netlify.app/posts/modelldef-regrformel/)
4. [finde-prior/](https://datenwerk.netlify.app/posts/finde-prior/)
2. [Nullhyp-Beispiel](https://datenwerk.netlify.app/posts/nullhyp-beispiel/nullhyp-beispiel)
2. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz)
3. [Interaktionseffekt1](https://datenwerk.netlify.app/posts/interaktionseffekt1/interaktionseffekt1)
1. [Regression2](https://datenwerk.netlify.app/posts/regression2/regression2)
2. [Regression3](https://datenwerk.netlify.app/posts/regression3/regression3)
<!-- 3. [Regression6](https://datenwerk.netlify.app/posts/regression6/regression6) -->
<!-- 1. [posterior_interval](https://datenwerk.netlify.app/posts/posterior_interval/posterior_interval.html) -->
2. [diamonds-nullhyp-mws](https://datenwerk.netlify.app/posts/diamonds-nullhyp-mws/diamonds-nullhyp-mws.html)
2. [zwert-berechnen](https://datenwerk.netlify.app/posts/zwert-berechnen/zwert-berechnen.html)
3. [stan_glm_parameterzahl](https://datenwerk.netlify.app/posts/stan_glm_parameterzahl/stan_glm_parameterzahl.html)
4. [kausale-verben](https://datenwerk.netlify.app/posts/kausale-verben/kausale-verben)


### Aufgaben, f√ºr die man einen Computer ben√∂tigt


1. [Regr-Bayes-interpret](https://datenwerk.netlify.app/posts/regr-bayes-interpret/regr-bayes-interpret)
2. [Regr-Bayes-interpret03](https://datenwerk.netlify.app/posts/regr-bayes-interpret03/regr-bayes-interpret03)
3. [Regr-Bayes-interpret02](https://datenwerk.netlify.app/posts/regr-bayes-interpret03/regr-bayes-interpret02)
3. [rope4](https://datenwerk.netlify.app/posts/rope4/rope4.html)



### Vertiefung

1. [Anova-skalenniveau](https://datenwerk.netlify.app/posts/anova-skalenniveau/anova-skalenniveau.html)
2. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau.html)
1. [stan_glm_prioriwerte](https://datenwerk.netlify.app/posts/stan_glm_prioriwerte/stan_glm_prioriwerte.html)




## ---



![](img/outro-10.jpg){width=100%}


