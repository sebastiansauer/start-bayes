# Bayes-Versuch






![Bayes:Start!](img/Golem_hex.png){width=10%}




## Lernsteuerung

### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.




### √úberblick

In diesem Kapitel √ºbersetzen wir eine Problemstellung (Forschungsfrage) in ein (mathematisches) Modell, das uns dann mit Hilfe der Bayes-Formel Antworten auf die Problemstellung gibt.


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...


- Unterschiede zwischen Modellen und der Realit√§t erl√§utern
- die Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (f√ºr binomial verteilte Zufallsvariablen)
- die weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren
- das Bayes-Modell anhand bekannter Formeln herleiten
- Post-Wahrscheinlichkeiten anhand der Bayesbox berechnen


### Begleitliteratur


Der Stoff dieses Kapitels deckt einen Teil aus @mcelreath2020, Kap. 2, ab. @mcelreath2020 stellt das Globusmodell mit mehr Erl√§uterung und etwas mehr theoretischem Hintergrund vor, als es in diesem Kapitel der Fall ist.




### Vorbereitung im Eigenstudium

- [Statistik 1, Kap. "Daten Einlesen"](https://statistik1.netlify.app/020-r)


### Begleitvideos

- üì∫ [Globusversuch](https://www.youtube.com/watch?v=fGlt9Ld4xzk&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=6)


### Ben√∂tigte R-Pakete


```{r}
library(tidyverse)
library(ggpubr)  # komfortable Visualisierung
```


```{r}
#| include: false
library(patchwork)
library(easystats)
library(ggraph)
library(tidygraph)

source("funs/binomial_plot.R")
source("funs/plot_binom_likelihood.R")
```


```{r}
#| include: false
theme_set(theme_modern())
```

```{r}
#| include: false
source("_common.R") 
```



## Von Welten und Golems

### Kleine Welt, gro√üe Welt

Bekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika^[wenn auch nicht als Erster]. Das war aber ein gl√ºcklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb @fig-behaim.

![Behaims Globus: Kein Amerika](img/Behaim.jpg){#fig-behaim}

[Quelle: Ernst Ravenstein, Wikimedia, Public Domain](https://commons.wikimedia.org/wiki/File:RavensteinBehaim.jpg)

Die *kleine Welt des Modells* entsprach hier nicht *der gro√üen Welt, der echten Erdkugel*.

Das ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel f√ºr, sagen wir, die Komplexit√§t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Gl√ºck geh√∂rt halt auch dazu.


::: callout-note
Behaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die gro√üe Welt, ist nicht die Erde.
:::

Was in der kleinen Welt funktioniert, muss nicht in der gro√üen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schl√ºssen und vermeintlicher Gewissheit.


:::{exr-modellno}
üèã Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht! $\square$
:::







### Der Golem von Prag

![Der Golem von Prag](img/170px-Golem_and_Loew.jpg){#fig-golem-prag width="33%"}

[Bildquelle: Mikol√°≈° Ale≈°, Wikimedia, Gemeinfrei](https://de.wikipedia.org/wiki/Golem)

[Der Golem von Prag](http://www.prague.net/golem), die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle w√∂rtlich ausf√ºhrt, s. @fig-golem-prag.
Die Geschichte besagt, dass ein Rabbi mit Zauberkr√§ften den Golem aus Lehm erschuf, um die j√ºdische Bev√∂lkerung der Stadt zu sch√§tzen.
Bei kluger F√ºhrung kann ein Golem N√ºtzliches vollbringen.
Bei un√ºberlegter Verwendung wird er jedoch gro√üen Schaden anrichten.

### Wissenschaftliche Modelle sind wie Golems



!["Yeah, ich bin ein Golem!" - Bildquelle: Klara Schaumann](img/Golem_hex.png){width=25%}

:::: {.columns}

::: {.column width="50%"}
**Golem**

Eigenschaften des *Golems*:

-   Besteht aus Lehm
-   Belebt durch "Wahrheit"
-   M√§chtig
-   dumm
-   F√ºhrt Befehle w√∂rtlich aus
-   Missbrauch leicht m√∂glich
-   M√§rchen
:::

::: {.column width="50%"}
**Modell**

Eigenschaften eines *Modells*:


-   Besteht aus ~~Lehm~~Silikon
-   Belebt durch Wahrheit (?)
-   Manchmal m√§chtig
-   simpler als die Realit√§t
-   F√ºhrt Befehle w√∂rtlich aus
-   Missbrauch leicht m√∂glich
-   Nicht einmal falsch
:::

::::





::: callout-note
Wir bauen Golems.
:::

@fig-xy stellt ein Sinnbild von Modellen dar.


Vergleichen wir die kleine Welt unserer Modellen (@tbl-klein-gross), wie z.B. Behaims Globus, mit der Gro√üen Welt, die Kolumbus und wir befahren.




| Kleine Welt                                                | Gro√üe Welt                                 |
|-----------------------------------------|-------------------------------|
| Die Welt, wie sie der Golem sieht                          | Die Welt, wie sie in Wirklichkeit ist      |
| ist das Modell, aber nicht (zwangsl√§ufig) die Wirklichkeit | entspricht nicht (zwangsl√§ufig) dem Modell |
| Verwenden wir beim Modellieren                             | Ist das, was wir modellieren               |

: Kleine Welt vs. gro√üe Welt {#tbl-klein-gross}






<!-- ![So denkt unser Bayes-Golem](img/bayesupdate2.png){#fig-bayes1} -->



:::{#exm-bayes-lernen}
### Die Bayes-Formel und Lernen
üèã Bayes-Inferenz √§hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess √§hnelt! $\square$
:::


:::{#exm-regr-grosse-welt}
### Ein Regressionsmodell stammt aus der kleinen Welt

Ein wissenschaftliches Modell, etwa auf Basis eines Regressionsmodell ist Teil der *kleinen* Welt.
Man muss sich bei der Interpretation eines Regressionsmodell vor Augen halten: "Die Ergebnisse des Modell sind nur richtig unter der Annahme, dass sich der Zusammenhang X und Y durch eine Gerade beschreiben lasssen und unter der Annahme, dass meine Daten repr√§sentativ sind." $\square$
:::






## Ein erster Versuch: Wir werfen den Globus





### Das Bayes-Update 


:::{#exm-fofra1}
### Wasseranteil auf der Erdoberfl√§che
Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (@fig-erde)? Um m√∂glichst wenig schreiben zu m√ºssen, schreiben wir f√ºr "angenommener Wasseranteil auf der Erdoberfl√§che" kurz $p$ oder $\pi$ (p wie proportion, Anteil). $\square$
:::

![Die Erde. Sch√∂n! Und mit viel Wasser, ca. 70% der Erdoberfl√§che sind mit Wasser bedeckt. 
[Quelle](https://pngimg.com/image/25340), Lizenz: CC 4.0 BY-NC](img/earth.png){#fig-erde width="10%" fig-align="center"}


Analog k√∂nnen wir uns vorstellen, 11 Wissenschaftler haben jeweils eine andere Hypothese zum Wasseranteil, $\pi$, der Erde. 
Die erste Person hat die Hypothese $\pi_1 = 0$, die zweite Person geht von $\pi_2 = 0.1$ aus ... die 11. Person von $\pi_{11} = 1$.
Um die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. 
Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.^[Warum gerade 9 Mal? Tja, dann hat das Handy geklingelt... Auch in wissenschaftlichen Versuchen ist (leider?) nicht immer alles genau geregelt.]
So sah *mein*^[*Ihr* Ergebnis kann anders aussehen, schlie√ülich ist es ja Zufall.] Ergebnis aus:

$$W \quad L \quad W \quad W \quad W \quad L \quad W \quad L \quad W$$


Also $W=6$ (Wasser, d.h. "Treffer") und $L=3$ (Land, "Niete") ($n=9$ Versuche).

:::{#exr-globe1}
### Spin the Globe
üèãÔ∏èÔ∏è Besorgen Sie sich einen Globus (zur Not eine M√ºnze) und stellen Sie den Versuch nach!$\square$
:::




Der Bayes-Golem denkt eigentlich ganz vern√ºnftig:
Zuerst ("Apriori") hat er ein Vorwissen zum Wasseranteil, die dazugeh√∂rige Wahrscheinlichkeitsverteilung nennt man *Apriori-Verteilung* (s. @def-priori).
In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel.
Als n√§chstes beschaut sich der Golem die Daten und √ºberlegt,
wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 50% betr√§gt.
Die zugeh√∂rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die^[oder den?] *Likelihood*^[zu Deutsch etwa: "Mutma√ülichkeit"], s. @def-L.
Als letztes bildet sich der Golem eine abschlie√üende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man *Aposteriori-Verteilung*, s. @def-post1.
Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten, die durch die Likelihood repr√§sentiert werden.
Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert: Das Bayes-Update, s. @fig-bayes-update.


<!-- ![Updating mit Bayes](img/bayesupdate.png){#fig-bayes-update} -->


```{mermaid}
%%| fig-cap: Updating mit Bayes
%%| label: fig-bayes-update
graph LR
A[Apriori-Vert.]-->B[Likelihood]-->C[Post-Vert.]-->A
```






:::{#def-priori}
### Apriori-Verteilung
F√ºr jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilit√§t der Hypothese angibt: *Apriori-Verteilung* (synonym: Apriori-Verteilung).$\square$
:::

:::{#def-L}
### Likelihood
F√ºr jede Hypothese (d.h. jeden *Parameterwert* $\pi$) m√∂chten wir wissen, 
wie wahrscheinlich die Daten sind (unter der Annahme, 
dass die Hypothese richtig ist).
Anders gesagt: Die *Likelihood* sagt uns, 
wie gut die Daten zu einer bestimmten Hypothese passen.$\square$
:::

:::{#def-post1}
### Aposteriori-Verteilung
Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die *Aposteriori-Verteilung*^[ Anstatt von *Apriori* liest man auch *Prior* oder *Priori*; anstatt *Aposteriori* auch *Posterior*] bekommen. $\square$
:::






:::{#exr-l1}
### Wie gut passen die Daten zur Hypothese, dass die Erde komplett trocken ist?

Wir haben in unseren Versuch $W=6$ und $L=3$ erzielt. 
Diese Daten passen *√ºberhaupt nicht* zur Hypothese, dass die Erdoberfl√§che komplett trocken ist.
Die *Likelihood*, $L$ f√ºr $\pi=0$ ist also Null.
Analog ist die Likelihood f√ºr $\pi=1$ auch Null. $\square$
:::



### Berechnung der Likelihood im Globusversuch



Wie wahrscheinlich ist es, ein bestimmtes Ergebnis, 
z.B. $W=6$ Treffer (bei 9 W√ºrfen), zu erhalten, 
wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 90%) annimmt?
Diese Wahrscheinlichkeit nennt man die *Likelihood*, $L = Pr(W = 6, n = 9| \pi=.9)$.


Wenn wir eine Binomialverteilung f√ºr die Globusw√ºrfe annehmen, 
dann gehen wir davon aus,  dass die Daten unabh√§ngig voneinander entstehen 
und sich der Parameterwert nicht zwischenzeitlich √§ndert.
^[Die sog. "iid-Annahme", *i*ndependently and *i*dentically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen. 
Jeder Wurf ist unabh√§ngig von allen anderen: 
Das Ergebnis eines Wurfes hat keinen (stochastischen) Einfluss auf ein Ergebnis anderer W√ºrfe.
Die Wahrscheinlichkeitsverteilung ist bei jedem Wurf identisch.]
Der Wasseranteil der Erde bleibt w√§hrend des Versuchs gleich (durchaus plausibel).



Berechnen wir also die Likelihood f√ºr verschiedene Hypothesen (Wasseranteile, $\pi$), 
f√ºr $\pi = 0, 0.1, 0.2, \ldots, 1$,
s. @lst-lik1.
Wir halten also die Daten fest (6 Treffer bei 9 W√ºrfen) und 
berechnen die Wahrscheinlichkeit dieser Daten f√ºr verschiedene Hypothesen (Wasseranteile, $\pi$).



```{r lik1}
#| lst-cap: "Likelihood-Funktion f√ºr x=6 Treffer, bei n=9 W√ºrfen, f√ºr eine binomialverteilte Zufallsvariable: Wir halten die Daten fest und variieren den Parameterwert (Wasseranteil, $\pi$)."
#| lst-label: lst-lik1
#| results: hold 
dbinom(x = 6, size = 9, prob = .1)
dbinom(x = 6, size = 9, prob = .2)
dbinom(x = 6, size = 9, prob = .3)
dbinom(x = 6, size = 9, prob = .4)
dbinom(x = 6, size = 9, prob = .5)
dbinom(x = 6, size = 9, prob = .6)
dbinom(x = 6, size = 9, prob = .7)
dbinom(x = 6, size = 9, prob = .8)
dbinom(x = 6, size = 9, prob = .9)
```




@fig-lik1 visualisiert die 
Likelihood-Funktion f√ºr unser Beispiel (6 Wasser bei 9 W√ºrfen) f√ºr verschiedene Hypothesen (Wasseranteile, $\pi$).
Man sieht, dass die Likelihood um $\pi = 0.7$ herum am h√∂chsten ist.


```{r}
#| fig-cap: "Die Likelihood-Funktion f√ºr x=6 Treffer, bei n=9 W√ºrfen, f√ºr eine binomialverteilte Zufallsvariable (mit 11 Parameterwerten: 0, 0.1, 0.2, ..., 1): Die Parameterwerte um 0.7 herum sind am plausibelsten."
#| label: fig-lik1
#| echo: false
plot_binom_likelihood(x = 6, n = 9) 
```



Oder von Hand gerechnet f√ºr $\pi = 1/2$, s. @eq-dbinom1:

$$\begin{aligned}
Pr(\pi = 1/2| x = 6, n = 9) &=\\ 
\tbinom{9}{6} \cdot (1/2)^6 \cdot (1/2)^3 &=\\
\frac{9!}{6!3!} \cdot (1/2)^9 &= \\
84 \cdot 1/512 = 21/128 &= 0.16
\end{aligned}
$${#eq-dbinom1}



Mit Hilfe von R als Taschenrechner gerechnet:

```{r}
anz_pfade <- choose(9, 6)
wskt_pro_pfad <- (1/2)^6 * (1/2)^3
gesamt_wskt <- anz_pfade * wskt_pro_pfad
gesamt_wskt
```






F√ºr so viele W√ºrfe ($n=9$) w√ºrde ein Baumdiagramm un√ºbersichtlich werden, s. @fig-binom2.
Visualisierungen wie Baumdiagramme sind eine praktische Hilfe zum Verst√§ndnis,
kommen aber bei gr√∂√üeren Daten schnell an ihre Grenze.


```{r}
#| echo: false
#| label: fig-binom2
#| fig-cap: Wir werfen den Globus (oder eine M√ºnze) 9 Mal, es resultieren 512 Endknoten. Nicht gerade √ºbersichtlich.
my_tree <- tidygraph::create_tree(1023, 2, mode = "out")

my_tree %>%
  mutate(lab = 1:1023) %>% 
  ggraph(circular = TRUE) +
  geom_edge_link() +
  geom_node_label(mapping = aes(label = lab), size = 1) +
  coord_flip() +
  scale_y_reverse() +
  theme_void()
```


Jetzt folgen einige Beispiele.



:::{#exm-globus697-dbinom}
### Likelihood f√ºr $W = 6, n = 9, \pi=.7$
Was ist die Likelihood von $W=6$ bei $n=9$ gegeben $\pi=.7$ bei unserem Globusversuch?

```{r QM2-Thema2-kleineModelle-21, echo = TRUE}
dbinom(x = 6, size = 9, prob = .7)
```

Oder, synonym, wenn man einen Taschenrechner (oder R als Taschenrechner) benutzt:

```{r}
choose(9, 6) * (.7)^6 * (.3)^3
```


Noch "h√§ndischer" gerechnet:

```{r}
factorial(9)/(factorial(6)*factorial(3)) * (.7)^6 * (.3)^3
```

Die Daten passen gut zur Hypothese $\pi=.7$. $\square$
:::


Zur Erinnerung: Die Funktion `dbinom` gibt uns die Wahrscheinlichkeit von `x` Treffern, 
bei `size` Versuchen zur√ºck, 
wobei eine Binomialverteilung angenommen wird mit der Trefferwahrscheinlichkeit `prob`.

::: {#exm-globus2}


### Likelihood f√ºr $W = 6, n = 9, \pi=1/3$
Was ist die Likelihood von $W=6$ bei $n=9$ gegeben $\pi=1/3$ bei unserem Globusversuch?

```{r QM2-Thema2-kleineModelle-22a, echo = TRUE}
dbinom(x = 6, size = 9, prob = 1/3)
```

Offenbar ist $\pi=1/3$ eine schlechte Hypothese, um die Daten zu erkl√§ren:
Die Daten passen nicht gut zu ihr. $\square$

:::


:::{#exm-globus697}

### Likelihood f√ºr $\pi=0$

Was ist die Likelihood von $W=6$ bei $n=9$ gegeben $\pi=0$ bei unserem Globusversuch?


```{r QM2-Thema2-kleineModelle-22, echo = TRUE}
dbinom(x = 6, size = 9, prob = 0)
```


$\pi=0$ ist offenbar eine sehr schlechte Hypothese, um die Daten zu erkl√§ren:
Die Daten sind unm√∂glich unter dieser Hypothese. $\square$

:::


Es gibt Taschenrechner(-Apps), die die Binomialverteilung oder den Binomialkoeffizienten berechnen k√∂nnen.^[<https://www.geogebra.org/scientific?lang=de>]



:::{#exr-globus}
### Peer Instruction: Welcher Parameterwert ist am plausibelsten?

Wir f√ºhren wieder den Globusversuch durch (oder werfen eine M√ºnze) und erhalten folgendes Ergebnis: 7 Mal Wasser und 2 Mal Land (also $W=7$ und $L=2$).

Welcher Wasseranteil, $\pi$ ist am plausibelsten?

A) 0 Wasser (0%)
B) 1/9 Wasser (ca. 11%)
C) 3/9 Wasser (ca. 33%)
D) 7/9 Wasser (ca. 78%)
E) 9 Wasser (100%) $\square$
:::



### Unser Modell ist geboren

Ein Modell (in der Bayes-Statistik) besteht aus mind. drei Komponenten:

1. Die *Likelihood* (die Wahrscheinlichkeit der Daten unter Annahme der Hypothese), s. @eq-globus1
2. Die *Apriori-Verteilung(en)* (die Wahrscheinlichkeit der Hypothese vor den Daten), a. @eq-prior-unif-globus
3. Die *Aposteriori-Verteilung* (die Wahrscheinlichkeit der Hypothese nach den Daten), s. @fig-post1




### Apriori-Verteilung

Unser Vorab- bzw. *Apriori*-Wissen zu $\pi$ sei, dass uns alle Werte gleich ("uniform") plausibel erscheinen, s. @eq-prior-unif-globus.

$$\pi \sim \text{Unif}(0,1).
$${#eq-prior-unif-globus}

Lies: "$\pi$ ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1".

Man k√∂nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (apriori) indifferent;
jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich, 
s. @fig-unif01.









```{r QM2-Thema2-kleineModelle-26}
#| echo: false
#| fig-cap: "Gleichverteilung mit Parametern min=0 und max=1"
#| label: fig-unif01
#| eval: true
#| out-width: 50%

source("funs/uniform_plot.R")

uniform_plot(0, 1)
```




### Aposteriori-Verteilung

:::{#def-post-ver}
### Aposteriori-Verteilung
die Aposteriori-Verteilung (kurz: "Post-Verteilung") quantifiziert unser Wissen zu den Parameterwerten *nach* Kenntnis der Daten und aufbauend auf unserem Vorwissen (Apriori-Wissen).
Die Aposteriori-Verteilung ist das Ergebnis des Bayes-Updates; man bezeichnet sie kurz mit $Pr(H|D)$. 
Lies: "Die Wahrscheinlichkeit der Hypothese H gegeben der Daten D." $\square$
:::

Dabei nimmt man stillschweigend an, dass die Daten anhand eines gewissen Modells generiert wurden,
z.B. der Binomialverteilung; so dass die Likelihood $Pr(D|H)$ berechnet werden kann.
@fig-post1 zeigt die Post-Verteilung f√ºr unser Globusbeispiel (6 Wasser bei 9 W√ºrfen).





## Bayes' Theorem

### Wozu wird Bayes in der Praxis genutzt?




In der Praxis nutzt man Bayes h√§ufig,
wenn man Daten $D$ gesammelt hat,
und wissen m√∂chte,
wie wahrscheinlich eine Hypothese $H$ ist,
im Lichte dieser gesammelten Daten, s. @thm-bayes1.
Anders gesagt: 
Die Likelihood ist relativ einfach zu bestimmen, 
$Pr(D|H)$, aber nicht so interessant.
Die Aposteriori-Wahrscheinlichkeit, $Pr(H|D)$,
ist schwerer zu bestimmen, aber interessanter.
Man k√∂nnte also sinnbildlich sagen,
das Bayes-Theorem ist eine "Maschine", die die Apriori-Wahrscheinlichkeit zusammen mit 
der Likelihood zur Aposteriori-Wahrscheinlichkeit "umbaut".



<!-- $$D \quad \underrightarrow{Bayes} \quad H$$ -->


::: {#thm-bayes1}

### Bayes' Theorem
$$
Pr(H|D) = \frac{ Pr(H) \cdot Pr(D|H) }{Pr(D)} = \frac{\text{Apriori} \cdot \text{Likelihood}} {\text{Evidenz}}\quad \square
$$

:::



Bayes' Theorem (@thm-bayes1) fragt nach $Pr(H|D)$:

>    Was ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten kennen (und ein Modell?)

Und antwortet so (@thm-bayes1):

>    Diese Wahrscheinlichkeit entspricht der Apriori-Wahrscheinlichkeit der Hypothese mal der Plausibilit√§t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgr√ºnden dividiert man noch die totale Wahrscheinlichkeit der Daten √ºber alle Hypothesen (durch die sog. Evidenz).


F√ºr unser Globusbeispiel:


>    Wie wahrscheinlich ist denn jetzt ein bestimmter Wasseranteil auf der Erde, $\pi$, (gegeben den Daten, $W=6$ und $L=3$) und wenn wir jede Hypothese apriori f√ºr gleich wahrscheinlich halten?  Also, wie wahrscheinlich ist z.B. ein Wasseranteil von 70% oder von 50%?






### Die Evidenz zur Standardisierung 

Die Aufgabe der Evidenz ist nur daf√ºr zu sorgen, dass der Wert von $Pr(H|D)$ insgesamt nur Werte zwischen 0 und 1 annehmen kann, 
also eine brave, normale Wahrscheinlichkeit ist. 
W√ºrde man in  @thm-bayes1 nicht durch die Evidenz teilen, 
so w√§re die Aposteriori-Wahrscheinlichkeit nicht normiert, 
d.h. sie k√∂nnte Werte >1 annehmen, was ja nicht sein darf.



:::{#def-evidenz}
### Evidenz
$Pr(D)$ nennt man die *Evidenz*. 
Die Evidenz berechnet sich als Summe der Likelihoods f√ºr alle Parameterwerte $H_i$, 
d.h. als die totale Wahrscheinlichkeit von $D$, s. @thm-evidenz, vgl. @def-totwskt. $\square$
:::

::: {#thm-evidenz} 
### Evidenz
$$\begin{aligned}
Pr(D) = \sum_{i=1}^n Pr(D|H_i) \cdot Pr(H_i)
\end{aligned}\quad \square
$$
:::

Die verschiedenen Parameterwerte kann man auch als die verschiedenen Hypothesen $H_i$ auffassen.
Falls es nur zwei Hypothesen bzw. Parameterwerte gibt, vereinfacht sich @thm-evidenz zu @thm-evidenz2.


::: {#thm-evidenz2} 
### Evidenz bei zwei Hypothesen
$$\begin{aligned}
Pr(D) = Pr(D|H_1) \cdot Pr(H_1) + Pr(D|H_2) \cdot Pr(H_2)
\end{aligned}\quad \square
$$
:::





Schauen wir uns die Bestandteile von Bayes' Theorem (@thm-bayes1) noch etwas n√§her an:

-   (standardisierte) Aposteriori-Wahrscheinlichkeit: $Pr_{Post} := Pr(H|D)$
-   Likelihood: $L := Pr(D|H)$
-   Apriori-Wahrscheinlichkeit: $Pr_{Apriori} := Pr(H)$
-   Evidenz: $E := Pr(D)$
-   unstandardisierte Aposteriori-Wahrscheinlichkeit: $Pr_{\text{unPost}} = Pr_{\text{Apriori}} \cdot L$


Bayes' Theorem gibt die $Pr_{Post}$ an, wenn man die Gleichung
mit der $Pr_{Apriori}$ und dem $L$ f√ºttert.
Bayes' Theorem wird verwendet, um die $Pr_{Post}$ zu quantifizieren.
Die $Pr_{Post}$ ist proportional zu $Pr_{unPost} = L \times Pr_{Apriori}$.





Abb. @fig-post3 visualisiert, dass die Post-Verteilung eine Gewichtung von Apriori und Likelihood ist (das gilt sowohl f√ºr die unstandardisierte als auch f√ºr die standardisierte Post-Verteilung).
Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.



![Prior mal Likelihood = Post](img/img241.png){#fig-post3}


Standardisiert man die unstandardisierte Post-Verteilung,
so erh√§lt man die standardisierte Post-Verteilung.
Das Standardisieren dient nur dazu, einen Wert zwischen 0 und 1 zu erhalten. 
Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren.
Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung @thm-post.







### Wissen updaten: Wir f√ºttern Daten in das Modell

Golems k√∂nnen lernen?! @fig-lernen-golem zeigt die Post-Verteilung, nach $n=1, 2, ...,n=9$ 
Datenpunkten, d.h. W√ºrfen mit dem Globusball.
Man sieht: Am Anfang, apriori, also bevor die Daten kennen, 
vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich f√ºr den Golem (das Modell).
Je nach Ergebnis des Wurfes ver√§ndert sich die Wahrscheinlichkeit der Parameterwerte,
kurz gesagt, die Post-Verteilung ver√§ndert sich in Abh√§ngigkeit von den Daten.


![Unser Golem lernt](img/img221.png){#fig-lernen-golem}


Insofern kann man sagen: Unser Golem (das Modell) lernt. 
Ob das Modell n√ºtzlich ist (pr√§zise Vorhersagen liefert), 
steht auf einem anderen Blatt.



## Die Post berechnen mit mit der Bayesbox

Wir erstellen uns eine kleine Tabelle, die man "Bayesbox" nennen k√∂nnte.^[Auch Gitter-Methode oder Grid-Methode genannt.]
Unser Ziel ist es, die Posteriori-Wahrscheinlichkeit f√ºr verschiedene Parameterwerte zu berechnen,
also die Wahrscheinlichkeit, dass ein bestimmter Wasseranteil $\pi$ vorliegt,
gegeben die Daten (6 Wasser bei 9 W√ºrfen).
Dazu gehen wir so vor:

### Die Idee der Bayesbox

1. Teile den Wertebereich des Parameters in ein "Gitter" auf, z.B. $0.1, 0.2, ..., 0.9, 1$.
2. W√§hle die Apriori-Wahrscheinlichkeit f√ºr jeden Parameterwert, z.B. 1/11 bei einer diskreten Gleichverteilung von 0 bis 1.
3. Berechne die Likelihood f√ºr jeden Parameterwert.
4. Berechne den unstandardisierten Aposteriori-Wert f√ºr jeden Parameterwert (Produkt von Apriori und Likelihood).
5. Standardisiere den Aposteriori-Wert durch Teilen anhand der Summe aller unstandardisierten Aposteriori-Wahrscheinlichkeiten.


F√ºr jeden Parameterwert berechnen wir eine (Post-)Wahrscheinlichkeit.^[Ein Parameterwert ist eine m√∂gliche Auspr√§gung des Parameters.]
H√§ufig entspricht eine Hypothese einem Parameterwert, 
etwa wenn man sagt: "Ich glaube, die M√ºnze ist fair", was auf einen Parameterwert von 50% herausl√§uft.
Dazu geben wir an, f√ºr wie wahrscheinlich wie apriori^[synonym: priori] 
-- also bevor wir irgendwelche Daten erheben -- jeden einzelnen Parameterwert halten.
Wir machen es uns hier einfach und halten jeden Parameterwert f√ºr gleich wahrscheinlich. 

Tats√§chlich ist der konkrete Wert hier egal, 
solange wir allen Parameterwerten denselben Wert geben,
wird sich die standardisierte Aposteriori-Wahrscheinlichkeit nicht √§ndern.

Entscheidend ist das Verh√§ltnis der Apriori-Werte zueinander: 
Geben wir einem Parameterwerten den Wert 2, aber einem anderen den Wert 1, 
so halten wir Ersteren f√ºr (apriori) doppelt so plausibel wie Letztere.
Die Post-Wahrscheinlichkeit f√ºr den Ersteren wird dann auch doppelt so gro√ü sein wie die f√ºr Letztere (alles andere konstant gehalten).

Die "End-Wahrscheinlichkeit", die unstandardisierte Post-Wahrscheinlichkeit, 
die "hinten rauskommt" ist das Produkt von Apriori-Wert und Likelihood.
Anschaulich gesprochen: Die Apriori-Werte werden mit den Likelihoodwerten gewichtet^[synonym: Die Likelihoodwerte werden mit den Apriori-Werten gewichtet.].
Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen m√∂chten, 
teilen wir jeden Aposteriori-Wert durch die Summe aller Aposteriori-Werte. 
Dadurch ist gerantiert, dass sich die Aposteriori-Werte zu eins aufaddieren. 
Damit haben wir dann die Anspr√ºche an eine Wahrscheinlichkeitsverteilung erf√ºllt (vgl. @sec-kolmogorov).


### Bayesbox in R berechnen

Legen wir uns ein Gitter mit Parameterwerten ($\pi$) an, um deren Aposteriori-Wahrscheinlichkeit zu berechnen.
Konkret gesprochen: Wir listen jeden f√ºr uns interessanten Wasseranteil ($\pi$) auf,
also $\pi=0, 0.1, 0.2, ..., 1$.
Diese Parameterwerte sind die Hypothesen, die wir testen wollen,
s. @lst-wasseranteile.


```{r p-gitter}
#| lst-label: lst-wasseranteile
#| lst-cap: "Parameterwerte (Gitter) f√ºr Wasseranteile: 0, 0.1, 0.2, ..., 1"
wasseranteile <- seq(from = 0, to = 1, by = 0.1)  # Parameterwerte
wasseranteile
```


Dann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 W√ºrfen) gegeben jeweils eines Wasseranteils.

```{r lik-69}
Likelihood <- dbinom(6, size = 9, prob = wasseranteile)
Likelihood
```

Schlie√ülich packen wir das alles in eine Tabelle, die "Bayesbox", s. @tbl-globus und @lst-gitter1.

```{r gitter1, echo = TRUE}
#| lst-cap: "Wir basteln uns eine Bayesbox"
#| lst-label: lst-gitter1
bayesbox_globusversuch <-
  tibble(
    # definiere die Hypothesen (die Parameterwerte, p): 
    p = wasseranteile,
    # Lege den Apriori-Wert f√ºr alle Parameterwerte auf 1/11 fest:
    Apriori  = 1/11) |> 
    mutate(
      # berechne Likelihood f√ºr jeden Wasseranteil (Parameterwert):
      Likelihood = Likelihood,
      # berechne unstand. Aposteriori-Werte:
      unstd_Post = Likelihood * Apriori,
      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:
      Evidenz = sum(unstd_Post),
      # berechne stand. Aposteriori-Werte (summiert zu 1):
      Post = unstd_Post / Evidenz)  
```

Die Bayesbox (@tbl-globus) zeigt, wie sich die Post-Verteilung berechnet.

```{r QM2-Thema2-kleineModelle-29}
#| label: tbl-globus
#| tbl-cap: "Die Bayesbox f√ºr den Globusversuch, k=6 Treffer, n=9 Versuche, Apriori-Wahrscheinlichkeit Pr(H)=9%, und Wasseranteile p von 0 bis 1"
#| echo: false
bayesbox_globusversuch %>% 
  mutate(id = 1:11) %>% 
  relocate(id, .before = 1) %>% 
  knitr::kable(digits = 3)
```


F√ºr jede Hypothese (Spalte `id`) berechnen wir die *unstandardisierte*
Aposteriori-Wahrscheinlichkeit als Produkt von Apriori und Likelihood.

Um zur *standardisierten* Aposteriori-Wahrscheinlichkeit zu gelangten,
teilen wir in jeder Zeile der Bayesbox (also f√ºr jede Hypothese) 
die unstandardisierte Post-Wahrscheinlichkeit durch die Summe 
der unstandardisierten Post-Wahrscheinlichkeiten.
Dabei haben wir die Apriori-Wahrscheinlichkeit f√ºr alle Parameterwerte als gleich angenommen, da wir keinerlei Vorwissen hatten, $Pr(H_i) = 1/11$.
Die Evidenz berechnet sich als Summe der unstandardisierten Post-Wahrscheinlichkeiten, $Pr(D) = 0.09$.

Wenn die Apriori-Wahrscheinlichkeit f√ºr alle Hypothesen gleich ist,
dann ist die standardisierte Aposteriori-Wahrscheinlichkeit identisch mit der Likelihood.
Denn die Post-Wahrscheinlichkeit ist die um die Priori-Wahrscheinlichkeit gewichtete Likelihood.
Sind die Apriori-Wahrscheinlichkeiten alle gleich,
so ist die Gewichtung der Likelihood f√ºr alle Hypothesen gleich.


:::{#exm-globus697-post}
### Post-Wahrscheinlichkeit im Globusversuch f√ºr p=.7
In @exm-globus697-dbinom haben wir die Wahrscheinlichkeit f√ºr 6 Treffer bei 9 W√ºrfen gegeben einer Trefferwahrscheinlichkeit von $\pi = .7$ berechnet.
Damit haben wir die Likelihood $L = Pr(D|H) =.27$ berechnet.


Auf dieser Basis k√∂nnen wir die Aposteriori-Wahrscheinlichkeit $Pr_{Post}$ berechnen, zun√§chst die unstandardisierte.
Dazu haben wir die Apriori-Wahrscheinlichkeit mit der Likelihood multipliziert, s. @eq-postunstand697:

$$\text{Post}_{\text{unstand}} = Pr(H) \cdot Pr(D|H) = 1/11 \cdot 0.2668 = 0.024$${#eq-postunstand697}

Jetzt standardisieren wir die unstandardisierte Post-Wahrscheinlichkeit,
indem wir durch die Evidenz dividieren, s. @eq-poststand697.

$$\text{Post} = \frac{\text{Post}_{\text{unstand}}}{\text{Evidenz}} = \frac{0.024}{0.09} = 0.267$${#eq-poststand697}



Fazit: Nach dem Versuch, d.h. nachdem wir die Daten in Betracht gezogen haben,
hat sich unsere Meinung √ºber den Wasseranteil von $\pi=.7$ aktualisiert von 0.09 auf 0.27 -- 
das ist eine Verdreifachung. 
Wir sind uns drei Mal so sicher wie vor dem Versuch, dass der Wasseranteil bei 70% liegt. $\square$
:::






:::{#exr-priori-change}
üèãÔ∏è Was wohl mit *Post* passiert, wenn wir *Apriori* √§ndern?$\square$
:::

@fig-post1 zeigt eine Visualisierung der Post-Verteilung mit Hilfe der Funktion `ggline(x, y)` aus dem Paket `ggpubr`.
Wie man sieht, ist die Post-Wahrscheinlichkeit am h√∂chsten bei $\pi=0.7$.
Wobei der Bereich von 0.6 bis 0.8 auch recht wahrscheinlich ist.


```{r}
#| echo: false
#| label: fig-post1
#| out-width: 70%
#| fig-cap: "Die Post-Verteilung visualisiert. Die Post-Wahrscheinlichkeit ist am h√∂chsten bei p=0.7"
library(ggpubr)

ggline(bayesbox_globusversuch,
       x = "p",
       y = "Post")
```





### Was sagt die Post?

Die Aposteriori-Verteilung (Kurz: "Post-Verteilung", oder "Post"), $Pr_{Post}$, sagt, 
wie plausibel wir jeden Wert von $p$ halten, 
jetzt, nachdem wir die Daten des Versuchs kennen.
Die Post-Wahrscheinlichkeit updatet unser Apriori-Wissen mit dem Wissen, 
das wir durch die Daten erhalten haben.



@fig-gitter zeigt die Post-Wahrscheinlichkeit f√ºr 5, 10 und 20 Parameterwerte. 
Das mittlere Teilbild mit 10 Parameterwerten entspricht unserer Tabelle oben.
Man sieht: Je mehr Parameterwerte, desto "glatter" wird die Verteilung.




```{r}
#| echo: false
#| label: fig-gitter
#| out-width: 100%
#| fig-cap: "Die Post-Verteilung zunehmend mehr Parameterwerte in der Bayesbox. Je mehr Parameterwerte, desto 'glatter' wird die Verteilung."
source("R-Code/img242.R")

print(plot242)
```







Die Post-Verteilung ist sowas wie das Ziel all Ihrer Tr√§ume (falls Sie es noch nicht gewusst haben):
Aus der Post-Verteilung k√∂nnen Sie ablesen,
wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. 
Und noch einiges mehr, aber das ist Thema des n√§chsten Kapitels. $\square$



:::{#exr-bayesidee}
### Peer Instruction: Schl√ºsse ziehen mit dem Bayes-Modell

Auf einer Party: Unterhalten sich f√ºnf Studis √ºber das Bayesmodell. Einer hat Unrecht, die anderen Recht. Aber wer?

A) Wenn eine Hypothese $A$ apriori doppelt so wahrscheinlich ist wie die anderen und die Likelihoods f√ºr alle Hypothesen gleich ist, dann ist $A$ aposteriori auch doppelt so wahrscheinlich wie die anderen Hypothesen.

B) Sind alle Hypothesen apriori gleich wahrscheinlich, dann hat die Hypothese mit dem h√∂chsten Likelihood aposteriori auch die h√∂chste Post-Wahrscheinlichkeit.

C) Hat eine Hypothese apriori die Wahrscheinlichkeit Null, so hat sie automatisch aposteriori auch die Wahrscheinlichkeit Null, unabh√§ngig von ihrer Likelihood.

D) Die unstandardisierte Aposteriori-Wahrscheinlichkeit ist gleich der standardisierten mal einen Faktor $k$.

E) Hat eine Hypothese die h√∂chste Likelihood, so hat sie automatisch auch die h√∂chste Wahrscheinlichkeit aposteriori. $\square$
:::


## Abschluss

### Zusammenfassung


üì∫ [√úbung zum Globusversuch](https://www.youtube.com/watch?v=YJEZiQvCBgs&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=7)

-   In unserem Modell haben wir Annahmen zu $Pr_{Apriori}$ und $L$ getroffen.
-   Auf dieser Basis hat der Golem sein Wissen geupdated zu $Pr_{Post}$.
-   Mit der Bayesbox haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die $Pr_{Post}$ berechnet.
-   Unser Modell bildet die kleine Welt ab; ob es in der gro√üen Welt n√ºtzlich ist, steht auf einem anderen Blatt.

:::{#exr-tipp-p}
üèãÔ∏è Wenn Sie auf einen Prozentwert f√ºr $W$ tippen m√ºssten, welchen w√ºrden Sie nehmen, 
laut dem Modell (und gegeben der Daten)? $\square$
:::


### Der Globusversuch als Modell f√ºr zweiwertige Zufallsversuche

Der Globusversuch ist kein prototypisches Beispiel f√ºr Statistik in der Praxis, zumindest nicht auf dem ersten Blick. 
Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist.
Bei n√§herer Betrachtung ist der Globusversuch prototypisch f√ºr ganz viele Fragestellungen:

- Von einem neuen Produkt von von $n$ Exemplaren $k$ verkauft. Auf welchen Wert $p$ kann die Akzeptanzrate dieses Produkts gesch√§tzt werden?
- Ein Chat-Bot hat von $n$ Fragen $k$ richtig beantwortet. Wie hoch kann die Verst√§ndnisrate $p$ dieses Programms gesch√§tzt werden?
- Eine neue Krebstherapie hat von $n$ "austherapierten" Patientis $k$ geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie gesch√§tzt werden?



Kurz: Der Globusversuch ist ein Muster f√ºr zweiwertige Zufallsversuche. Und solche sind h√§ufig im Leben, im Business und in der Wissenschaft.





## Vertiefung


### Bayes-Video von 3b1b

Das ["Bayes-Paradox-Video" von 3b1b](https://youtu.be/lG4VkPoG3ko) pr√§sentiert eine gut verst√§ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, 
aber √§hnlichen Darstellung wie in diesem Kapitel.



### Bayes als Baum

Bayes' Theorem kann man sich als als Baumdiagramm vor Augen f√ºhren,
@fig-tot-wskt2.

Gesucht sei $Pr(M_1|A)$,
also: die Wahrscheinlichkeit,
dass das Teil von Maschine 1 produziert wurde, gegeben, dass es Ausschuss ist.
Gegeben sind die Wahrscheinlichkeiten, dass Machine $i$ das Teil produziert hat, $Pr(M_i)$. Au√üerdem sind die Wahrscheinlichkeiten, dass das Teil Ausschuss ist, $Pr(A|M_i)$, bekannt.

Das Diagramm l√∂st die Aufgabe f√ºr uns;
es zeigt damit die Anwendung von Bayes' Theorem auf.

Um $Pr(M_1|A)$ zu erhalten,
setzt man die Wahrscheinlichkeit
des  *g√ºnstigen* Asts ins Verh√§ltnis zur Wahrscheinlichkeit 
*aller relevanten* √Ñste, $Pr(A)$.

:::{#exm-bayes1}
### Maschine produziert Ausschuss

Die drei Maschinen $M_1, M_2, M_3$ produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. 
Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. @fig-tot-wskt2.

*Aufgabe*: Wie gro√ü ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde? Berechnen Sie diese Wahrscheinlichkeit.$\square$
:::



Der g√ºnstige (gesuchte) Ast, $Pr(M1 \cap A)$, ist hier fett gedruckt, s. @fig-tot-wskt2. 
In @fig-tot-wskt2 zeigen die runden K√§stchen am Ende der Pfade die Wahrscheinlichkeiten des jeweiligen Pfades an.





```{mermaid}
%%| fig-cap: G√ºnstige Pfade
%%| label: fig-tot-wskt2
flowchart LR
  A[Start] ==>|0.60|B[M1]
  A --->|0.10|C[M2]
  A --->|0.30|D[M3]
  B ==>|0.05|E[A]
  B -->|0.95|F[Nicht-A]
  C --->|0.02|G[A]
  C --->|0.98|H[Nicht-A]
  D --->|0.04|I[A]
  D --->|0.96|J[Nicht-A]
  E --- K((0.030))
  F --- L((0.570))
  G --- M((0.002))
  H --- N((0.098))
  I --- O((0.012))
  J --- P((0.288))
```



$$Pr(M1|A) = \frac{Pr(M1 \cap A)}{Pr(A)} = \frac{0.6 \cdot 0.05}{0.03 + 0.002 + 0.012} = \frac{0.03}{0.044} \approx 0.68$$


$Pr(M1|A)$ betr√§gt also ca. 68%.

Zur Erinnerung: $Pr(A)$ ist die totale Wahrscheinlichkeit
(dass ein produziertes Teil Ausschuss ist).



### Bayes als bedingte Wahrscheinlichkeit

Bayes' Theorem wird verwendet,
um die *Wahrscheinlichkeit* einer *Hypothese*,
*gegeben einer bestimmten Datenlage* und basierend auf einer *Apriori-Wahrscheinlichkeit dieser Hypothese* zu berechnen.
Man berechnet also $Pr(H|D)$.
Bayes' Theorem ist nichts anderes als eine normale bedingte Wahrscheinlichkeit.




$Pr(H| D)$ kann man  umformen (vgl. @thm-pr-cond und @def-gem-wskt-abh),
dann erh√§lt man Bayes' Theorem, s. @thm-bayes3.

:::{#thm-bayes3}

### Bayes' Theorem als bedinte Wahrscheinlichkeit

$$\begin{aligned}
Pr(H|D) &=\frac{\overbrace{ Pr(H\cap D)}^\text{umformen}}{Pr(D)} \\  &= \frac{\overbrace{Pr(H)}^\text{Apriori-Wahrscheinlichkeit} \cdot \overbrace{Pr(D|H)}^\text{Likelihood}}{\underbrace{Pr(D)}_\text{Evidenz}}
\end{aligned}\quad \square$$
:::



### Weitere Herleitung der Bayes-Formel

Man kann sich Bayes' Theorem  auch wie folgt herleiten:

$Pr(D\cap H) = Pr(D \cap H) = Pr(D) \cdot Pr(H|D) = Pr(H) \cdot Pr(D|H)$

Dann l√∂sen wir nach P$(H|D)$ auf, s. @thm-bayes3.

::: {#thm-bayes3}

### Bayes' Theorem 3

$$Pr(H|D) = \frac{\overbrace{Pr(H)}^\text{Apriori-Wahrscheinlichkeit} \cdot \overbrace{Pr(D|H)}^\text{Likelihood}}{\underbrace{Pr(D)}_\text{Evidenz}}\quad \square$$
:::




### Zusammengesetzte Hypothesen

Das ist vielleicht ein bisschen fancy,
aber man kann Bayes' Theorem auch nutzen, um die Wahrscheinlichkeit einer *zusammengesetzten Hypothese* zu berechnen: $H = H_1 \cap H_2$. 
Ein Beispiel w√§re: "Was ist die Wahrscheinlichkeit, dass es Regen ($R$) *und* Blitzeis ($B$) gibt, wenn es kalt ($K$) ist?".

Das sieht dann so aus wie in @thm-bayes4 gezeigt.


::: {#thm-bayes4}

### Bayes' Theorem f√ºr zusammengesetzte Hypothesen

$$
\begin{aligned}
Pr(R \cap B |K) &= \frac{ Pr(R \cap B) \cdot Pr(K|R \cap B) }{Pr(D)} \\
&= \frac{ Pr(R ) \cdot Pr(B) \cdot Pr(K|R \cap B) }{Pr(D)}
\end{aligned}
\quad \square$$
:::


Hier haben wir $Pr(R \cap B)$  aufgel√∂st in $Pr(R) \cdot Pr(B)$,
das ist nur zul√§ssig, wenn $R$ und $B$ unabh√§ngig sind.






## Aufgaben

:::{.callout-tip}
Einige der folgenden Aufgaben sind in englischer Sprache.
Wenn Ihnen eine andere Sprache (z.B. Deutsch) lieber ist, nutzen
Sie einfach die √úbersetzungsfunktion Ihres Browsers. Das sind meist nur zwei Klicks. $\square$
:::

### Papier-und-Bleistift-Aufgaben

1. [Verteilungen-Quiz-01](https://datenwerk.netlify.app/posts/verteilungen-quiz-01/verteilungen-quiz-01)
2. [globus1](https://datenwerk.netlify.app/posts/globus1/index.html)
2. [globus2](https://datenwerk.netlify.app/posts/globus2/index.html)
3. [globus3](https://datenwerk.netlify.app/posts/globus3/index.html)
4. [globus-bin](https://datenwerk.netlify.app/posts/globus-bin/index.html)
4. [globus-bin2](https://datenwerk.netlify.app/posts/globus-bin2/index.html)
3. [Krebs1](https://datenwerk.netlify.app/posts/krebs1/krebs1)
2. [kekse01](https://datenwerk.netlify.app/posts/kekse01/kekse01)
2. [kekse03](https://datenwerk.netlify.app/posts/kekse03/kekse03)
2. [bayes2](https://datenwerk.netlify.app/posts/bayes2/bayes2)
3. [Bayes-Theorem1](https://datenwerk.netlify.app/posts/bayes-theorem1/bayes-theorem1) 
5. [bayes-ziel1](https://datenwerk.netlify.app/posts/bayes-ziel1/bayes-ziel1)
6. [totale-wskt1](https://datenwerk.netlify.app/posts/totale-wskt1/totale-wskt1.html)
7. [wskt-quiz13](https://datenwerk.netlify.app/posts/wskt-quiz13/wskt-quiz13)
8. [wskt-quiz12](https://datenwerk.netlify.app/posts/wskt-quiz12/wskt-quiz12)
8. [wskt-quiz15](https://datenwerk.netlify.app/posts/wskt-quiz15/wskt-quiz15)


### Aufgaben, f√ºr die man einen Computer braucht

<!-- 2. [Rethink2E4](https://datenwerk.netlify.app/posts/Rethink2e4/Rethink2e4) -->
2. [Rethink2m1](https://datenwerk.netlify.app/posts/Rethink2m1/Rethink2m1.html)
2. [Rethink2m2](https://datenwerk.netlify.app/posts/Rethink2m2/Rethink2m2)
2. [Rethink2m3](https://datenwerk.netlify.app/posts/Rethink2m3/Rethink2m3)
<!-- 2. [Rethink2m4](https://datenwerk.netlify.app/posts/Rethink2m4/Rethink2m4) -->
<!-- 2. [Rethink2m5](https://datenwerk.netlify.app/posts/Rethink2m5/Rethink2m5) -->
<!-- 2. [Rethink2m6](https://datenwerk.netlify.app/posts/Rethink2m6/Rethink2m6) -->
<!-- 2. [Rethink2m7](https://datenwerk.netlify.app/posts/Rethink2m7/Rethink2m7) -->
2. [kekse02](https://datenwerk.netlify.app/posts/kekse02/kekse02.html)
2. [euro-bayes](https://datenwerk.netlify.app/posts/euro-bayes/euro-bayes.html)
3. [bath42](https://datenwerk.netlify.app/posts/bath42/bath42)
4. [Kaefer2](https://datenwerk.netlify.app/posts/kaefer2/kaefer2)
5. [rethink3m1](https://datenwerk.netlify.app/posts/ReThink3m1/ReThink3m1.html)
1. [Lose-Nieten-Binomial-Grid](https://datenwerk.netlify.app/posts/lose-nieten-binomial-grid/lose-nieten-binomial-grid)







## ---



![](img/outro-05.jpg){width=100%}


