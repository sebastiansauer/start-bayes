# Bayes-Globus 





![Bayes:Start](img/Golem_hex.png){width=5%}




## Lernsteuerung

### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.




### √úberblick

In diesem Kapitel √ºbersetzen wir eine Problemstellung (Forschungsfrage) in ein (mathematisches) Modell, das uns dann mit Hilfe der Bayes-Formel Antworten auf die Problemstellung gibt.


### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ...


- Unterschiede zwischen Modellen und der Realit√§t erl√§utern
- die Binomialverteilung heranziehen, um geeignete (einfache) Modelle zu erstellen (f√ºr binomial verteilte Zufallsvariablen)
- die weite Einsetzbarkeit anhand mehrerer Beispiele exemplifizieren
- das Bayes-Modell anhand bekannter Formeln herleiten
- Post-Wahrscheinlichkeiten anhand der Gittermethode berechnen


### Begleitliteratur


Der Stoff dieses Kapitels deckt einen Teil aus @mcelreath2020, Kap. 2, ab. @mcelreath2020 stellt das Globusmodell mit mehr Erl√§uterung und etwas mehr theoretischem Hintergrund vor, als es in diesem Kapitel der Fall ist.




### Vorbereitung im Eigenstudium

- [Statistik 1, Kap. "Daten Einlesen"](https://statistik1.netlify.app/020-r)


### Ben√∂tigte R-Pakete


```{r}
library(tidyverse)
library(ggpubr)  # komfortable Visualisierung
```


```{r}
#| include: false
library(patchwork)
library(easystats)
library(ggraph)
library(tidygraph)

source("funs/binomial_plot.R")
```


```{r}
#| include: false
theme_set(theme_modern())
```





## Von Welten und Golems

### Kleine Welt, gro√üe Welt

Bekanntlich segelte Kolumbus 1492 los, und entdeckte Amerika^[wenn auch nicht als Erster]. Das war aber ein gl√ºcklicher Zufall, denn auf seinem Globus existierte Amerika gar nicht. Vielleicht sah sein Globus so aus wie der von Behaim, s. Abb @fig-behaim.

![Behaims Globus: Kein Amerika](img/Behaim.jpg){#fig-behaim}

[Quelle: Ernst Ravenstein, Wikimedia, Public Domain](https://commons.wikimedia.org/wiki/File:RavensteinBehaim.jpg)

Die *kleine Welt des Modells* entsprach hier nicht *der gro√üen Welt, der echten Erdkugel*.

Das ist ein Beispiel, das zeigt, wie Modellieren schiefgehen kann. Es ist aber auch ein Beispiel f√ºr, sagen wir, die Komplexit√§t wissenschaftlicher (und sonstiger) Erkenntnis. Einfach gesagt: Gl√ºck geh√∂rt halt auch dazu.


::: callout-note
Behaims Globus ist nicht gleich der Erde. Die kleine Welt von Behaims Globus ist nicht die gro√üe Welt, ist nicht die Erde.
:::

Was in der kleinen Welt funktioniert, muss nicht in der gro√üen Welt funktionieren. Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schl√ºssen und vermeintlicher Gewissheit.


:::{exr-modellno}
üèã Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht! $\square$
:::







### Der Golem von Prag

![Der Golem von Prag](img/170px-Golem_and_Loew.jpg){#fig-golem-prag width="33%"}

[Quelle](https://de.wikipedia.org/wiki/Golem)

[Der Golem von Prag](http://www.prague.net/golem), die Legende einer vom Menschen geschaffene Kreatur mit gewaltiger Kraft, die Befehle w√∂rtlich ausf√ºhrt, s. @fig-golem-prag.
Die Geschichte besagt, dass ein Rabbi mit Zauberkr√§ften den Golem aus Lehm erschuf, um die j√ºdische Bev√∂lkerung der Stadt zu sch√§tzen.
Bei kluger F√ºhrung kann ein Golem N√ºtzliches vollbringen.
Bei un√ºberlegter Verwendung wird er jedoch gro√üen Schaden anrichten.

### Wissenschaftliche Modelle sind wie Golems



!["Yeah, ich bin ein Golem!" - Bildquelle: Klara Schaumann](img/Golem_hex.png){width=25%}

:::: {.columns}

::: {.column width="50%"}
**Golem**

Eigenschaften des *Golems*:

-   Besteht aus Lehm
-   Belebt durch "Wahrheit"
-   M√§chtig
-   dumm
-   F√ºhrt Befehle w√∂rtlich aus
-   Missbrauch leicht m√∂glich
-   M√§rchen
:::

::: {.column width="50%"}
**Modell**

Eigenschaften eines *Modells*:


-   Besteht aus ~~Lehm~~Silikon
-   Belebt durch Wahrheit (?)
-   Manchmal m√§chtig
-   simpler als die Realit√§t
-   F√ºhrt Befehle w√∂rtlich aus
-   Missbrauch leicht m√∂glich
-   Nicht einmal falsch
:::

::::





::: callout-note
Wir bauen Golems.
:::

@fig-xy stellt ein Sinnbild von Modellen dar.


Vergleichen wir die kleine Welt unserer Modellen (@tbl-klein-gross), wie z.B. Behaims Globus, mit der Gro√üen Welt, die Kolumbus und wir befahren.




| Kleine Welt                                                | Gro√üe Welt                                 |
|-----------------------------------------|-------------------------------|
| Die Welt, wie sie der Golem sieht                          | Die Welt, wie sie in Wirklichkeit ist      |
| ist das Modell, aber nicht (zwangsl√§ufig) die Wirklichkeit | entspricht nicht (zwangsl√§ufig) dem Modell |
| Verwenden wir beim Modellieren                             | Ist das, was wir modellieren               |

: Kleine Welt vs. gro√üe Welt {#tbl-klein-gross}






<!-- ![So denkt unser Bayes-Golem](img/bayesupdate2.png){#fig-bayes1} -->



::: exm-bayes-lernen
### Die Bayes-Formel und Lernen
üèã Bayes-Inferenz √§hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess √§hnelt!$\square$
:::

## Ein erster Versuch: Wir werfen den Globus





### Welcher Anteil der Erdoberfl√§che ist mit Wasser bedeckt?


:::{#exm-fofra1}
### Wasseranteil auf der Erdoberfl√§che
Unsere Forschungsfrage lautet, mit welchem Anteil die Erde wohl mit Wasser bedeckt ist (@fig-erde)? Um m√∂glichst wenig schreiben zu m√ºssen, schreiben wir f√ºr "angenommener Wasseranteil auf der Erdoberfl√§che" kurz $p$ (wie proportion, Anteil). $\square$
:::

![Die Erde. Sch√∂n! Und mit viel Wasser, ca. 70% der Erdoberfl√§che sind mit Wasser bedeckt.](img/earth.png){#fig-erde width="10%" fig-align="center"}

[Quelle](https://pngimg.com/image/25340) CC 4.0 BY-NC

Analog k√∂nnen wir uns vorstellen, 11 Wissenschaftlis haben jeweils eine andere Hypothese zum Wasseranteil, $\pi$, der Erde. Die erste Person hat die Hypothese $\pi_1 = 0$, die zweite Person geht von $\pi_2 = 0.1$ aus ... die 11. Person von $\pi_{11} = 1$.
 
Um die Forschungsfage zu beantworten, werfen Sie einen Globus-Ball in die Luft und fangen in wieder auf. 
Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie, bis Sie den Globusball insgesamt 9 Mal geworfen haben.^[Warum gerade 9 Mal? Tja, dann hat das Handy geklingelt... Auch in wissenschaftlichen Versuchen ist (leider?) nicht immer alles genau geregelt.]

So sah *mein*^[*Ihr* Ergebnis kann anders aussehen, schlie√ülich ist es ja Zufall.] Ergebnis aus:

$$W \quad L \quad W \quad W \quad W \quad L \quad W \quad L \quad W$$


Also $W=6$ und $L=3$.

:::{#exr-globe1}
üèãÔ∏èÔ∏è Besorgen Sie sich einen Globus (zur Not eine M√ºnze) und stellen Sie den Versuch nach!$\square$
:::

### Wie entstanden die Daten?

Der physikalische Prozess, der zur Entstehung der Daten f√ºhrt, nennt man den  *datengenierenden Prozess*.

In diesem Fall kann man ihn so beschreiben:

1.  Der wahre Anteil von Wasser, $W$, der Erdoberfl√§che ist $\pi$ (und $1-\pi$ ist der Anteil Land, $L$).
2.  Ein Wurf des Globusballs hat die Wahrscheinlichkeit $\pi$, eine $W$-Beobachtung zu erzeugen.
3.  Die W√ºrfe des Globusballs sind unabh√§ngig voneinander.
4.  Wir haben kein Vorwissen √ºber $\pi$; jeder Wert ist uns gleich wahrscheinlich.


:::{#exr-annahmen1}
üèã Welche Annahmen w√ºrden Sie √§ndern? 
Welche k√∂nnte man wegnehmen? Welche hinzuf√ºgen? 
Was w√§ren die Konsequenzen?$\square$
:::






### Ein paar Fachbegriffe


:::{#def-priori}
### Priori-Verteilung
F√ºr jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilit√§t der Hypothese angibt: *Priori-Verteilung*.$\square$
:::

:::{#def-L}
### Likelihood
F√ºr jede Hypothese (d.h. jeden *Parameterwert* $\pi$) m√∂chten wir wissen, wie wahrscheinlich die Daten sind (unter der Annahme, dass die Hypothese richtig ist). Kurz: Wir suchen die *Likelihood*. 
Anders gesagt: Die Likelihood sagt uns, wie gut die Daten zu einer bestimmten Hypothese passen.$\square$
:::

:::{#def-post1}
### Posteriori-Verteilung
Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die *Posteriori-Verteilung*^[ Anstatt von *Priori* liest man auch *Prior*; anstatt *Posteriori* auch *Posterior*] bekommen.$\square$
:::


### Bayes-Updates


Der Golem denkt eigentlich ganz vern√ºnftig:
Zuerst hat er ein Vorwissen zum Wasseranteil, die dazugeh√∂rige Wahrscheinlichkeitsverteilung nennt man *Priori-Verteilung*.
In unserem Beispiel ist das Vorwissen recht bescheiden: Jeder Wasseranteil ist ihm gleich plausibel.
Als n√§chstes beschaut sich der Golem die Daten und √ºberlegt,
wie wahrscheinlich die Daten sind, wenn man von einer bestimmten Hypothese ausgeht, z.B. dass der Wasseranteil 10% betr√§gt.
Die zugeh√∂rige Wahrscheinlichkeit der Daten unter Annahme einer Hypothese nennt man die^[oder den?] *Likelihood.*
Als letztes bildet sich der Golem eine abschlie√üende Meinung zur Wahrscheinlichkeit jeder Hypothese. Diese Wahrscheinlichkeitsverteilung nennt man *Posteriori-Verteilung*.
Sie berechnet als Gewichtung des Vorwissen mit den neuen Daten.
Anders gesagt: Das Vorwissen wird anhand der Erkenntnisse (der Daten) aktualisiert oder "geupdatet", s. @fig-bayes-update.


<!-- ![Updating mit Bayes](img/bayesupdate.png){#fig-bayes-update} -->


```{mermaid}
%%| fig-cap: Updating mit Bayes
%%| label: fig-bayes-update
graph LR
A[Priori-Vert.]-->B[Likelihood]-->C[Post-Vert.]-->A
```



:::{#exr-l1}
### Wie gut passen die Daten zur Hypothese, dass die Erde komplett trocken ist?

Wir haben in unseren Versuch $W=6$ und $L=3$ erzielt. Diese Daten passen *√ºberhaupt nicht* zur Hypothese, dass die Erdoberfl√§che komplett trocken ist.
Die *Likelihood*, $L$ f√ºr $\pi=0$ ist also Null.
Analog ist die Likelihood f√ºr $\pi=1$ auch Null.$\square$
:::



### Wie wahrscheinlich ist ein Wasseranteil von 90%?

Wie wahrscheinlich ist es, einen bestimmten Wasseranteil, z.B. 6 Treffer (bei 9 W√ºrfen) zu erhalten, wenn man eine bestimmte Hypothese (einen bestimmten Wasseranteil, z.B. 90%) annimmt?
Diese Wahrscheinlichkeit nennt man die *Likelihood*, $L$ oder  $L$.

<!-- Geht man von einer Binomialverteilng aus, ist die Likelihood einfach zu berechnen. -->

Wenn wir eine Binomialverteilung annehmen, 
dann gehen wir davon aus,  dass die Daten unabh√§ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich √§ndert
^[Die sog. "iid-Annahme", *i*ndependently and *i*dentically distributed: Jeder Wurf der Globusballes ist eine Realisation der gleichen Zufallsvariablen. 
Jeder Wurf ist unabh√§ngig von allen anderen: 
Das Ergebnis eines Wurfes hat keinen (stochastischen) Einfluss auf ein Ergebnis anderer W√ºrfe.
Die Wahrscheinlichkeitsverteilung ist bei jedem Wurf identisch.].
Der Wasseranteil der Erde bleibt w√§hrend des Versuchs gleich (durchaus plausibel).

Lassen Sie uns im Folgenden die Wahrscheinlichkeit ($Pr$), $W$ mal Wasser und $L$ mal Land zu beobachten, wenn die Wahrscheinlichkeit f√ºr Wasser $\pi$ betr√§gt, so bezeichnen: $(Pr(W,L | \pi))$.
Diese Wahrscheinlichkeit, $(Pr(W,L | \pi))$, kann man mit der *Binomialverteilung* berechnen.

M√∂chte man die Wahrscheinlichkeit ansprechen f√ºr das Ereignis "5 mal Wasser und 2 mal Land, 
wenn wir von einem Wasseranteil von 70% ausgehen", so w√ºrden wir kurz schreiben: $Pr(W=5, L=2 | \pi=.7)$.
Oder noch k√ºrzer:  $Pr(W=5 | \pi=.7)$, 
denn bei 7 W√ºrfen, von denen 5 $W$ gezeigt haben, ist die Anzahl von $L$ festgelegt. 

Die Binomialverteilung zeigt die Verteilung der H√§ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten M√ºnzwurf (und allen vergleichbaren Zufallsexperimenten): "M√ºnzwurfverteilung", s. Kap. @sec-bin-distrib.


### Binomialverteilung mit R


Praktischerweise ist die Binomialverteilung in R eingebaut, wie wir gleich sehen werden.

Was ist der Anteil der g√ºltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), 

um 2 mal $W$ bei $N=W+L=3$ W√ºrfen zu bekommen, wenn wir von $\pi=1/2$ ausgehen?
^[Allgemeiner spricht man auch von 2 Treffern bei 3 W√ºrfen 
(d.h. 1 "Nicht-Treffer", den wir als "Niete" bezeichnen). 
Treffer werden oft mit `1`  und Nieten mit `0` bezeichnet], 
s. @lst-dbinom1, @fig-binom1a und @eq-dbinom1.


```{r QM2-Thema2-kleineModelle-21a, echo = TRUE}
#| lst-cap: "Binomialvertielung mit R f√ºr x=2, n=3, p=1/2"
#| lst-label: lst-dbinom1
dbinom(x = 2, size = 3, prob = 1/2)
```


$$\begin{aligned}
Pr(W=2 | \pi=1/2, n=3) &=\\ 
\tbinom{3}{2} \cdot (1/2)^2 \cdot (1/2)^1 &=\\
\frac{3!}{2!1!} \cdot (1/2)^3 &= \\
3 \cdot 1/8 = 3/8 &= 0.375
\end{aligned}$${#eq-dbinom1}

Wenn man sich den entsprechenden Baum anschauen w√ºre: 
Von den 8 Endkonten bzw. Pfaden sind 3 g√ºnstig. 
Demnach ist die Wahrscheinlichkeit des gesuchten Ereignis (2 Treffer bei 3 W√ºrfen, binomialverteilt) gleich 3 von 8 (alle Pfade sind gleich wahrscheinlich);
3/8 sind 0.375.






```{mermaid}
%%| echo: false
%%| label: fig-binom1a
%%| fig-cap: Wir werfen den Globus (oder eine M√ºnze) 3 Mal
flowchart TD
  A[A - Start] -. 1/2 .-> B[B - 0]
  A -. 1/2 .-> C[C - 1]
  B -. 1/2 .-> D[D - 0]
  B -. 1/2 .-> E[E - 1]
  C -. 1/2 .-> F[F - 0]
  C -. 1/2 .-> G[G - 1]
  D -. 1/2 .-> H[H - 0]
  D -. 1/2 .-> J[I - 1]
  E -. 1/2 .-> K[K - 0]
  E -. 1/2 .-> L[L - 1]
  F -. 1/2 .-> M[M - 0]
  F -. 1/2 .-> N[N - 1]
  G -. 1/2 .-> O[O - 0]
  G -. 1/2 .-> P[P - 1]
```


Abb. @fig-binom1a stellt einen einfachen Baum f√ºr 3 Globusw√ºrfe mit je zwei m√∂glichen Ereignissen (W vs. L) dar.
In der ersten (obersten) Zeile (Knoten A; "Start") ist Ausgangspunkt dargestellt: Der Globus ruht wurfbereit in unserer Hand.
Jetzt Achtung: Sie werfen den Globusball hoch.
Die Pfeile zeigen zu den (zwei) m√∂gliche Ergebnissen.
Die zweite Zeile (Knoten B und C) stellt die beiden Ergebnisse des Wurfes dar. 
Die Ergebnisse sind hier mit `0` und `1` bezeichnet (das eine eine einfache und weiteinsetzbare Notation).
Die dritte Zeile (Knoten D bis G) stellt die Ergebnisse des des zweiten Wurfes dar.
Die vierte Zeile (Knoten H bis P)  stellt die Ergebnisse des des dritten Wurfes dar.


F√ºr mehr W√ºrfe w√ºrde das Diagramm irgendwann un√ºbersichtlich werden.



Was ist der Anteil der g√ºltigen Pfade in einem Baumdiagramm (Wahrscheinlichkeit), 
um 6 mal $W$ bei $N=W+L=9$ W√ºrfen zu bekommen, wenn wir von $p=1/2$ ausgehen?

```{r QM2-Thema2-kleineModelle-21, echo = TRUE}
dbinom(x = 6, size = 9, prob = 1/2)
```

Oder, synonym, wenn man einen Taschenrechner (oder R als Taschenrechner) benutzt:

```{r}
choose(9, 6) * (1/2)^6 * (1/2)^3
```




@fig-bin-klein zeigt die Binomialverteilung $X \sim Bin(9, 1/2)$:
Die jeweilige Wahrscheinlichkeit f√ºr $k=0,1,\ldots, 9$ Treffer bei $n=9$ Versuchen mit
Trefferwahrscheinlichkeit $p=1/2$.


```{r QM2-Thema2-kleineModelle-25}
#| echo: false
#| label: fig-bin-klein
#| fig-cap: "Ein Beispiel f√ºr eine Binomialverteilung mit Parametern N=9 und p=1/2."

binomial_plot(n = 9, p = 1/2)
```



Abb @fig-binom2 ist ein vergeblicher Versuch, so einen gro√üen Baum ($n=9$) darzustellen.

:::callout-note
Visualisierungen wie Baumdiagramme sind eine praktische Hilfe zum Verst√§ndnis,
kommen aber bei gr√∂√üeren Daten schnell an ihre Grenze.
:::


```{r}
#| echo: false
#| label: fig-binom2
#| fig-cap: Wir werfen den Globus (oder eine M√ºnze) 9 Mal, es resultieren 512 Endknoten. Nicht gerade √ºbersichtlich.
my_tree <- tidygraph::create_tree(1023, 2, mode = "out")

my_tree %>%
  mutate(lab = 1:1023) %>% 
  ggraph(circular = TRUE) +
  geom_edge_link() +
  geom_node_label(mapping = aes(label = lab), size = 1) +
  coord_fliPr() +
  scale_y_reverse() +
  theme_void()

```


Jetzt folgen einige Beispiele.


::: {#exm-globus2}

## Globus mit 9 Treffern bei 9 W√ºrfen

Was ist die Wahrscheinlichkeit f√ºr $W=9$ bei $N=9$ und $p=1/2$?

```{r QM2-Thema2-kleineModelle-22, echo = TRUE}
dbinom(x = 9, size = 9, prob = 1/2)
```

Das ist 1 g√ºnstiger Pfad von 512 Pfaden.

:::



`dbinom` gibt uns die Wahrscheinlichkeit von `x` Treffern, bei `size` Versuchen zur√ºck, 
wobei eine Binomialverteilung angenommen wird mit Trefferwahrscheinlichkeit `prob`.



### Unser Modell ist geboren

Wir fassen das Globusmodell so zusammen, s. @eq-globus1.

$$W \sim \text{Bin}(N,\pi)$${#eq-globus1}

Lies: "W ist *bin*omial verteilt mit den Parametern $N$ und $\pi$". $N$ gibt die Anzahl der Globusw√ºrfe an: $n=W+L$.

Unser Vorab-Wissen zu $p$ sei, dass uns alle Werte gleich ("uniform") plausibel erscheinen:

$$\pi \sim \text{Unif}(0,1).$$

Lies: "$\pi$ ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1".

Man k√∂nnte auch sagen: Wir haben praktisch kein Vorwissen, wir sind erstmal (aprior) indifferent,
jeder Parameterwert erscheint uns erstmal gleich wahrscheinlich.









```{r QM2-Thema2-kleineModelle-26}
#| echo: false
#| fig-cap: "Gleichverteilung mit Parametern min=0 und max=1"
#| label: fig-unif
#| eval: false

source("funs/uniform_plot.R")

uniform_plot(0, 1)
```




## Bayes' Theorem

### Wozu wird Bayes in der Praxis genutzt?




In der Praxis nutzt man Bayes h√§ufig, wenn man Daten zu einer Wirkung $W$ hat,
und auf die Ursache $U$ zur√ºckschlie√üen m√∂chte, sinngem√§√ü:

$$W \quad \underrightarrow{Bayes} \quad U$$

Dann kann man @eq-bayes1 so schreiben, s. @eq-bayes2:

$$Pr(U|W) = \frac{ Pr(U) \cdot Pr(W|U) }{Pr(W)}$${#eq-bayes2}

Eine √§hnliche Situation, die in der Praxis h√§ufig ist,
dass man Daten $D$ hat und auf die Wahrscheinlichkeit einer Hypothese $H$ schlie√üen m√∂chte, s. @eq-bayes3.

$$D \quad \underrightarrow{Bayes} \quad H$$


$$rPr(H|D) = \frac{ Pr(H) \cdot Pr(D|H) }{Pr(D)}$${#eq-bayes3}

@eq-bayes3 fragt nach $Pr(H|D)$:

>    Was ist die Wahrscheinlichkeit der Hypothese H, jetzt wo wir die Daten haben (und ein Modell?)

Und antwortet so (@eq-bayes3):

>    Diese Wahrscheinlichkeit entspricht der Grundrate (Apriori-Wahrscheinlichkeit) der Hypothese mal der Plausibilit√§t (Likelihood) der Daten unter Annahme (gegeben) der Hypothese. Aus Standardisierungsgr√ºnden dividiert man noch die totale Wahrscheinlichkeit der Daten √ºber alle Hypothesen.



### Bayes als Baum

Gesucht sei $Pr(A_1|B)$.

F√ºr Bayes' Formel^[synonym: Satz von Bayes] setzt man die Wahrscheinlichkeit des  *g√ºnstigen* Ast zur Wahrscheinlichkeit aller relevanten √Ñste, $Pr(B)$.

:::{#exm-bayes1}
### Maschine produziert Ausschuss

Die drei Maschinen $M_1, M_2, M_3$ produzieren den gleichen Artikel. Ihr jeweiliger Anteil, an der Produktion liegt bei 60%, 10% bzw. 30%. 
Die jeweilige Ausschussquote liegt bei 5, 2, bzw. 4%, s. @fig-tot-wskt2.
*Aufgabe*: Wie gro√ü ist die Wahrscheinlichkeit, dass ein defektes Teil von Maschine 1 produziert wurde?$\square$
:::



Der g√ºnstige (gesuchte) Ast ist hier schwarz gedruckt, die √ºbrigen √Ñste gestrichelt, s. @fig-tot-wskt2. $A_i$ zeigt das Ereignis, dass der Artikel von Maschine $i$ produziert wurde. $B$ ist das Ereignis "Artikel ist Ausschuss".

```{mermaid}
%%| fig-cap: G√ºnstige Pfade
%%| label: fig-tot-wskt2
flowchart LR
  A[Start] -->|0.6|B[A1]
  A -.->|0.1|C[A2]
  A -.->|0.3|D[A3]
  B --->|0.05|E[B]
  B -.->|0.95|F[Nicht-B]
  C -.->|0.02|G[B]
  C -.->|0.98|H[Nicht-B]
  D -.->|0.04|I[B]
  D -.->|0.96|J[Nicht-B]
```


$$Pr(A|B) = \frac{Pr(A1 \cap B)}{Pr(B)} = \frac{0.6 \cdot 0.05}{0.03 + 0.002 + 0.012} = \frac{0.03}{0.044} \approx 0.68$$


$Pr(A|B)$ betr√§gt also ca. 68%.

Zur Erinnerung: $Pr(B)$ ist die totale Wahrscheinlichkeit.




### Bayes als bedingte Wahrscheinlichkeit

Bayes' Theorem wird h√§ufig verwendet,
um die Wahrscheinlichkeit einer Hypothese,
gegeben einer bestimmten Datenlage, zu berechnen,
also $Pr(H|D)$.
Dabei ist Bayes' Theorem nichts anderes als eine normale bedingte Wahrscheinlichkeit.



$Pr(H|D) = \frac{\overbrace{ Pr(H\cap D)}^\text{umformen}}{Pr(D)}$

$Pr(H| D)$ kann man  umformen, 
dann erh√§lt man Bayes' Theorem, s. @eq-bayes1:

$$Pr(H|D) =\frac{Pr(D\cap H)}{Pr(D)} = \frac{Pr(D|H) \cdot Pr(H)}{Pr(D)}$$ {#eq-bayes1}

Man kann sich Bayes' Theorem  auch wie folgt herleiten:



$Pr(D\cap H) = Pr(D \cap H) = Pr(D) \cdot Pr(H|D) = Pr(H) \cdot Pr(D|H)$

Dann l√∂sen wir nach P$(H|D)$ auf, s. @eq-bayes2.


$$Pr(H|D) = \frac{Pr(H) \cdot Pr(D|H)}{Pr(D)}$${#eq-bayes2}



### Vertiefung: Zusammengesetzte Hypothesen

Das ist vielleicht ein bisschen fancy,
aber man kann Bayes' Theorem auch nutzen, um die Wahrscheinlichkeit einer *zusammengesetzten Hypothese* zu berechnen: $H = H_1 \cap H_2$. 
Ein Beispiel w√§re: "Was ist die Wahrscheinlichkeit, dass es Regen ($R$) *und* Blitzeis ($B$) gibt, wenn es kalt ($K$) ist?".

Das sieht dann so aus, @eq-bayes4:

$$
\begin{aligned}
Pr(R \cap B |K) &= \frac{ Pr(R \cap B) \cdot Pr(K|R \cap B) }{Pr(D)} \\
&= \frac{ Pr(R ) \cdot Pr(B) \cdot Pr(K|R \cap B) }{Pr(D)}
\end{aligned}
$${#eq-bayes4}


Hier haben wir $Pr(R \cap B)$  aufgel√∂st in $Pr(R) \cdot Pr(B)$,
das ist nur zul√§ssig, wenn $R$ und $B$ unabh√§ngig sind.




## Das Globus-Modell als Bayes' Theorem


üì∫ [Globusversuch](https://www.youtube.com/watch?v=fGlt9Ld4xzk&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=6)

### Von gemeinsamer zur bedingen Wahrscheinlichkeit

Erinnerung wir uns (@exm-kalt-regen): Die Wahrscheinlichkeit f√ºr *Regen* und *kalt* ist gleich der Wahrscheinlichkeit von *Regen*, *gegeben kalt* mal der Wahrscheinlichkeit von *kalt*; das ist die Kettenregel (@def-kettenregel).

Entsprechend gilt: 

Die gemeinsame Wahrscheinlichkeit f√ºr die beiden Ereignisse $W$ (z.B. 6 Mal Wasser zu erhalten bei 9 Versuchen) und $A$ (z.B. dass der Wasseranteil der Erdoberfl√§che 70% betr√§gt) l√§sst sich ebenso mit der Kettenregel der Wahrscheinlichkeitsrechnung bestimmen:


<!-- Die Wahrscheinlichkeit von einer bestimmten Zahl an $W$ mit einer bestimmten Wasser-Wahrscheinlichkeit $p$ ist das Produkt von $Pr(W|p)$ und der Wahrscheinlichkeit $Pr(p)$: -->

$$Pr(W,A) = Pr(W|A) \cdot Pr(A)$$

Laut der Kettenregel ist "Drehen" erlaubt:

$$Pr(A,W) = Pr(A|W) \cdot Pr(W)$$



Wir setzen die letzten beiden Gleichungen gleich:

$$Pr(W|p) \cdot Pr(A) = Pr(A|W) \cdot (W)$$

Und dann l√∂sen wir auf nach der Posteriori-Wahrscheinlichkeit^[k√ºrzen wir mit Post-Wahrscheinlichkeit or $Pr(Post)$ ab], $Pr(A|W)$,
voil√†! 
Wir haben Bayes' Theorem genutzt, um die gesuchte Gr√∂√üe, $Pr(A|W)$, zu bestimmen, s. @eq-globusbayes.

$$Pr(A|W) = \frac{Pr(W|A) \times Pr(A)}{Pr(W)}$${#eq-globusbayes}

$Pr(W)$ nennt die *Evidenz*. 
Die Evidenz berechnet sich als Mittelwert der Likelihoods √ºber alle Werte von $W$, vgl. @def-totwskt:

$Pr(W) = Pr(W|A) \times Pr(A) + Pr(\neg W| \neg A) \times Pr(\neg A)$


Die Aufgabe der Evidenz ist nur daf√ºr zu sorgen, dass der Bruch insgesamt nur Werte zwischen 0 und 1 annehmen kann.

### Bayes' Theorem als Formel

Gesucht ist die Wahrscheinlichkeit einer Hypothese gegeben einer bestimmten Datenlage, $Pr(H|D)$:

$$Pr(H|D) = \frac{Pr(D|H) Pr(H)}{Pr(D)} = \frac{\text{Likelihood}  \cdot \text{Priori}}{\text{Evidenz}}$$

Schauen wir uns die Bestandteile von Bayes' Theorem noch etwas n√§her an:

-   Posteriori-Wahrscheinlichkeit: $Pr_{Post} := Pr(H|D)$

-   Likelihood: $L := Pr(D|H)$

-   Priori-Wahrscheinlichkeit: $Pr_{Priori} := Pr(H)$

-   Evidenz: $E := Pr(D)$


Bayes' Theorem gibt die $Pr_{Post}$ an, wenn man die Gleichung mit der $Pr_{Priori}$ und dem $L$ f√ºttert.

Bayes' Theorem wird verwendet, um die $Pr_{Post}$ zu quantifizieren.

Die $Pr_{Post}$ ist proportional zu $L \times Pr_{Priori}$.

### Posteriori als Produkt von Priori und Likelihood

Die unstandardisierte Post-Wahrscheinlichkeit $Pr_{\text{unPost}}$ ist einfach das Produkt von Likelihood und Priori, s. @eq-unpost.

$$Pr_{\text{unPost}} = L \times \text{Priori}$${#eq-unpost}

Das Standardisieren dient wie gesagt nur dazu, einen Wert zwischen 0 und 1 zu erhalten. 
Dies erreichen wir, indem wir durch die Summe aller Post-Wahrscheinlichkeiten dividieren.
Die Summe der Post-Wahrscheinlichkeiten bezeichnet man (auch) als Evidenz, vgl. Gleichung @eq-post.


$$\text{Posteriori} = \frac{\text{Likelihood} \times \text{Priori}}{\text{Evidenz}}$${#eq-post}



Abb. @fig-post3 visualisiert, dass die Post-Verteilung eine Gewichtung von Priori und Likelihood ist.
Mathematisch gesprochen beruht diese Gewichtung auf einer einfachen Multiplikationen der beiden genannten Terme.



![Prior mal Likelihood = Post](img/img241.png){#fig-post3}







### Wissen updaten: Wir f√ºttern Daten in das Modell

Golems k√∂nnen lernen?! @fig-lernen-golem zeigt die Post-Verteilung, nach $n=1, 2, ...,n=9$ Datenpunkten, d.h. W√ºrfen mit dem Globusball.
Man sieht: Am Anfang, apriori, also bevor die Daten haben, vor dem ersten Wurf also, ist jeder Parameterwert gleich wahrscheinlich f√ºr den Golem (das Modell).
Je nach Ergebnis des Wurfes ver√§ndert sich die Wahrscheinlichkeit der Parameterwerte,
kurz gesagt, die Post-Verteilung ver√§ndert sich in Abh√§ngigkeit von den Daten.


![Unser Golem lernt](img/img221.png){#fig-lernen-golem}


Insofern kann man sagen: Unser Golem (das Modell) lernt. Ob das Modell n√ºtzlich ist (pr√§zise Vorhersagen liefert), steht auf einem anderen Blatt.



## Bayes berechnen mit mit dem Bayes-Gitter

Wir erstellen uns eine kleine Tabelle, die man "Bayes-Gitter" nennen k√∂nnte.
Dazu gehen wir so vor:

### Idee

1.  Teile den Wertebereich des Parameter in ein "Gitter" auf, z.B. $0.1, 0.2, ..., 0.9, 1$.
2.  W√§hle den Priori-Wert des Parameters f√ºr jeden Gitterwert, z.B. 1/10 bei einer Gleichverteilung von 0 bis 1.
3.  Berechne den Likelihood f√ºr jeden Parameterwert.
4.  Berechne den unstandardisierten Posteriori-Wert f√ºr jeden Parameterwert (Produkt von Priori und Likelihood).
5.  Standardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.


F√ºr jeden Parameterwert berechnen wir eine (Post-)Wahrscheinlichkeit.^[Ein Parameterwert ist eine m√∂gliche Auspr√§gung des Parameters.]
H√§ufig entspricht eine Hypothese einem Parameterwert, 
etwa wenn man sagt: "Ich glaube, die M√ºnze ist fair", was auf einem Parameterwert von 50% herausl√§uft.
Dazu geben wir an, f√ºr wie wahrscheinlich wie apriori^[synonym: priori] - also bevor wir irgendwelche Daten erheben - jeden einzelnen Gitterwert halten.
Wir machen es uns hier einfach und halten jeden Gitterwert f√ºr gleich wahrscheinlich. 
Tats√§chlich ist der konkrete Wert hier egal, entscheidend ist das Verh√§ltnis der Apriori-Werte zueinander: 
Geben wir einigen Gitterwerten den Wert 2, aber anderen den Wert 1, 
so halten wir Erstere f√ºr (apriori) doppelt so plausibel wie Letztere.
Der Likelihood wird in diesem Fall mit der Binomialverteilung berechnet. Der Likelihood gibt an, 
wie wahrscheinlich ein Gitterwert ist gegeben einem bestimmten apriori gew√§hlten Parameterwert.
Die "End-Wahrscheinlichkeit", die unstandardisierte Post-Wahrscheinlichkeit, die "hinten rauskommt" ist das Produkt von Priori-Wert und Likelihood.
Anschaulich gesprochen: Die Priori-Werte werden mit den Likelihoodwerten gewichtet^[synonym: Die Likelihoodwerte werden mit den Apriori-Werten gewichtet.].
Da wir letztlich eine Wahrscheinlichkeitverteilung bekommen m√∂chten, teilen wir jeden Posteriori-Wert durch die Summe aller Posteriori-Werte. 
Dadurch ist gerantiert, dass sich die Posteriori-Werte zu eins aufaddieren. 
Damit haben wir dann die Anspr√ºche an eine Wahrscheinlichkeitsverteilung erf√ºllt (vgl. @sec-kolmogorov).


### Bayes-Gitter in R berechnen

Legen wir uns eine Tabelle mit Gitterwerten an, um deren Posteriori-Wahrscheinlichkeit zu berechnen.

Ein paar Vorarbeiten. 
Zuerst w√§hlen wir unsere Parameterwerte; sagen wir 0, 0.1, 0.2, ... , 1:

```{r}
p_Gitter <- seq(from = 0, to = 1, by = 0.1)
p_Gitter
```


Dann berechnen wir schon mal die Wahrscheinlichkeit der Daten (6 W bei 9 W√ºrfen) gegeben jeweils eines Gitterwerts:

```{r}
Likelihood <- dbinom(6, size = 9, prob = p_Gitter)
Likelihood
```

Dann packen wir das alles in eine Tabelle, s. @tbl-globus.

```{r QM2-Thema2-kleineModelle-28, echo = TRUE}
d <-
  tibble(
    # definiere die Hypothesen (das "Gitter"): 
    p_Gitter = p_Gitter,
    # bestimme den Priori-Wert:       
    Priori  = .1) %>%  
    mutate(
      # berechne Likelihood f√ºr jeden Gitterwert:
      Likelihood = Likelihood,
      # berechne unstand. Posteriori-Werte:
      unstd_Post = Likelihood * Priori,
      # berechne Evidenz, d.i. die Summe aller unstand. Post-Werte:
      Evidenz = sum(unstd_Post),
      # berechne stand. Posteriori-Werte (summiert zu 1):
      Post = unstd_Post / Evidenz)  
```

Das "Bayes-Gitter" (@tbl-globus) zeigt, wie sich die Post-Verteilung berechnet.

```{r QM2-Thema2-kleineModelle-29}
#| label: tbl-globus
#| tbl-cap: "Die Bayes-Box f√ºr den Globusversuch"
#| echo: false
d %>% 
  mutate(id = 1:11) %>% 
  relocate(id, .before = 1) %>% 
  knitr::kable(digits = 2)
```


F√ºr jede Hypothese (Spalte `id`) berechnen wir die unstandardisierte Posteriori-Wahrscheinlichkeit als Produkt von Priori und Likelihood:

$\text{Post}_{\text{unstand}} = \text{Priori} \cdot \text{Likelihood}$

Um zur standardisierten Posteriori-Wahrscheinlichkeit zu gelangten,
teilen wir in jeder Zeile der Gitterbox (also f√ºr jede Hypothese) die unstandardisierte Post-Wahrscheinlichkeit durch die Summe der unstandardisierten Post-Wahrscheinlichkeiten.


:::callout-note
Wenn der Priori-Wert f√ºr jeden Gitterwert gleich ist, dann ist der Likelihood gleich der unstandardisierten Post-Wahrscheinlichkeit.$\square$
:::


:::{exr-priori-change}
üèãÔ∏è Was wohl mit *Post* passiert, wenn wir *Priori* √§ndern?$\square$
:::

@fig-post1 zeigt eine Visualisierung der Post-Verteilung mit Hilfe der Funktion `ggline()` aus dem Paket `ggpubr`.

:::: {.columns}

::: {.column width="50%"}

```{r}
#| eval: false
library(ggpubr)

ggline(d,
       x = "p_Gitter",
       y = "Post")
```
:::

::: {.column width="50%"}

```{r}
#| echo: false
#| label: p-post1
#| fig-cap: Die Post-Verteilung visualisiert
library(ggpubr)

ggline(d,
       x = "p_Gitter",
       y = "Post")
```
:::

::::




### Was sagt die Post?

Die Posteriori-Verteilung (Kurz: "Post-Verteilung"), $Pr_{Post}$, zeigt, wie plausibel wir jeden Wert von $p$ halten, jetzt, nachdem wir die Daten des Versuchs kennen.


@fig-gitter zeigt die Post-Wahrscheinlichkeit f√ºr 5, 10 und 20 Parameterwerte. Das mittlere Teilbild (10 Gitterwerte) entspricht unserer Tabelle oben.


![Je mehr Parameterwerte, desto genauer wird die Verteilung wiedergegeben.](img/img242.png){#fig-gitter}


:::callout-note
Unter sonst gleichen Umst√§nden gilt:

- Mehr Gitterwerte gl√§tten die Ann√§herung.
- Je gr√∂√üer die Stichprobe ($N$), desto zuverl√§ssiger wird unsere Berechnung.
:::

::: callout-important
Die Post-Verteilung ist sowas wie das Ziel all Ihrer Tr√§ume (falls Sie es noch nicht gewusst haben):
Aus der Post-Verteilung k√∂nnen Sie ablesen,
wie wahrscheinlich Ihre Hypothese (Ihr Lieblings-Parameterwert) ist. Und noch einiges mehr, aber das ist Thema des n√§chsten Kapitels.
:::




## Abschluss

### Zusammenfassung


üì∫ [√úbung zum Globusversucht](https://www.youtube.com/watch?v=YJEZiQvCBgs&list=PLRR4REmBgpIGgz2Oe2Z9FcoLYBDnaWatN&index=7)

-   In unserem Modell haben wir Annahmen zu $Pr_{Priori}$ und $L$ getroffen.

-   Auf dieser Basis hat der Golem sein Wissen geupdated zu $Pr_{Post}$.

-   Mit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die $Pr_{Post}$ berechnet.

-   Unser Modell bildet die kleine Welt ab; ob es in der gro√üen Welt n√ºtzlich ist, steht auf einem anderen Blatt.

üèãÔ∏è Wenn Sie auf einen Prozentwert f√ºr $W$ tippen m√ºssten, welchen w√ºrden Sie nehmen, laut dem Modell (und gegeben der Daten)?


### Der Globusversuch als Modell f√ºr zweiwertige Zufallsversuche

Der Globusversuch ist kein prototypisches Beispiel f√ºr Statistik in der Praxis, zumindest nicht auf dem ersten Blick. 
Er hat aber aber den Vorteil, dass es ein einfaches, gut greifbares Beispiel ist, und damit zum Lernen gut geeignet ist.
Bei n√§herer Betrachtung ist der Globusversuch prototypisch f√ºr ganz viele Fragestellungen:

- Von einem neuen Produkt von von $n$ Exemplaren $k$ verkauft. Auf welchen Wert $p$ kann die Akzeptanzrate dieses Produkts gesch√§tzt werden?
- Ein Chat-Bot hat von $n$ Fragen $k$ richtig beantwortet. Wie hoch kann die Verst√§ndnisrate $p$ dieses Programms gesch√§tzt werden?
- Eine neue Krebstherapie hat von $n$ "austherapierten" Patientis $k$ geheilt. Auf wie hoch kann die Erfolgsrate dieser Therapie gesch√§tzt werden?



Kurz: Der Globusversuch ist ein Muster f√ºr zweiwertige Zufallsversuche. Und solche sind h√§ufig im Leben, im Business und in der Wissenschaft.



### Halbzeit-Quiz

Testen Sie Ihr Wissen mit [diesem Halbzeit-Quiz](https://datenwerk.netlify.app/#category=quiz1-qm2-ws23). Viel Erfolg! üçÄüçÄüçÄ



## Vertiefung


Das ["Bayes-Paradox-Video" von 3b1b](https://youtu.be/lG4VkPoG3ko) pr√§sentiert eine gut verst√§ndliche Darstellung des Bayes-Theorem aus einer zwar nicht gleichen, 
aber √§hnlichen Darstellung wie in diesem Kapitel.








## Aufgaben

Alle Aufgaben mit dem Tag [rethink-chap2](https://datenwerk.netlify.app/#category=rethink-chap2).

1. [Lose-Nieten-Binomial-Grid](https://datenwerk.netlify.app/posts/lose-nieten-binomial-grid/lose-nieten-binomial-grid)
2. [Rethink2E4](https://datenwerk.netlify.app/posts/Rethink2e4/Rethink2e4)
2. [Rethink2m1](https://datenwerk.netlify.app/posts/Rethink2m1/Rethink2m1)
2. [Rethink2m2](https://datenwerk.netlify.app/posts/Rethink2m2/Rethink2m2)
2. [Rethink2m3](https://datenwerk.netlify.app/posts/Rethink2m3/Rethink2m3)
2. [Rethink2m4](https://datenwerk.netlify.app/posts/Rethink2m4/Rethink2m4)
2. [Rethink2m5](https://datenwerk.netlify.app/posts/Rethink2m5/Rethink2m5)
2. [Rethink2m6](https://datenwerk.netlify.app/posts/Rethink2m6/Rethink2m6)
2. [Rethink2m7](https://datenwerk.netlify.app/posts/Rethink2m7/Rethink2m7)
2. [kekse01](https://datenwerk.netlify.app/posts/kekse01/kekse01.html)
2. [kekse02](https://datenwerk.netlify.app/posts/kekse02/kekse02.html)
2. [euro-bayes](https://datenwerk.netlify.app/posts/euro-bayes/euro-bayes.html)
2. [bayes2](https://datenwerk.netlify.app/posts/bayes2/bayes2)
i3. [Krebs1](https://datenwerk.netlify.app/posts/krebs1/krebs1)
3. [Bayes-Theorem1](https://datenwerk.netlify.app/posts/bayes-theorem1/bayes-theorem1) 









## ---



![](img/outro-05.jpg){width=100%}


