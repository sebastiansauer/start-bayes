{"title":"Kausalinferenz","markdown":{"headingText":"Kausalinferenz","containsRefs":false,"markdown":"\n\n## Lernsteuerung\n\n\n### R-Pakete\n\n\nF√ºr dieses Kapitel ben√∂tigen Sie folgende R-Pakete:\n\n```{r libs}\n#| warning: false\nlibrary(dagitty)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(easystats)\n```\n\n\n\n```{r libs-hidden}\n#| echo: false\nlibrary(gt)\n#library(DT)\nlibrary(ggdag)\n\ntheme_set(theme_modern())\n```\n\n\n### Lernziele\n\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ... \n\n- erkl√§ren, wann eine Kausalaussage gegeben eines DAGs berechtigt ist\n- die ‚ÄúAtome‚Äù der Kausalit√§t eines DAGs benennen\n- ‚Äúkausale Hintert√ºren‚Äù schlie√üen\n\n\n\n\n## Statistik, was soll ich tun?\n\n\n### Studie A: √ñstrogen\n\n#### Medikament einnehmen?\n\nMit Blick auf @tbl-studie-a: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n</br>\n\n```{r tbl-studie-a}\n#| echo: false\n#| label: tbl-studie-a\n#| tbl-cap: \"Daten zur Studie A\"\n\nstudie_a <-\n  tibble::tribble(\n     ~ Gruppe,      ~`Mit Medikament`,         ~`Ohne Medikament`,\n\"M√§nner\",    \"81/87 √ºberlebt (93%)\", \"234/270 √ºberlebt (87%)\",\n\"Frauen\",  \"192/263 √ºberlebt (73%)\",   \"55/80 √ºberlebt (69%)\",\n\"Gesamt\",  \"273/350 √ºberlebt (78%)\", \"289/350 √ºberlebt (83%)\"\n  ) \n\nstudie_a %>% \n  gt()\n```\n\n</br>\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualit√§t (Beobachtungsstudie).\nBei M√§nnern scheint das Medikament zu helfen; bei Frauen auch.\nAber *insgesamt* (Summe von Frauen und M√§nnern) *nicht*?!\nWas sollen wir den Arzt raten? Soll er das Medikament verschreiben? \nVielleicht nur dann, wenn er das Geschlecht kennt [@pearl_causal_2016]?\n\n\n\n\n\n#### Kausalmodell zur Studie A\n\n\n\nIn Wahrheit sehe die kausale Struktur so aus:\nDas Geschlecht (√ñstrogen) hat einen Einfluss (+) auf Einnahme des Medikaments und auf Heilung (-).\nDas Medikament hat einen Einfluss (+) auf Heilung.\nBetrachtet man die Gesamt-Daten zur Heilung, so ist der Effekt von Geschlecht (√ñstrogen) und Medikament *vermengt* (konfundiert, confounded).\nDie kausale Struktur, also welche Variable beeinflusst bzw. nicht,\nist in @fig-dag-studie-a dargestellt.\n\n\n\n```{r dag-studie-a}\n#| echo: false\n#| label: fig-dag-studie-a\n#| fig-cap: \"Zwei direkte Effekte (gender, drug) und ein indirekter Effekt (gender √ºber drug) auf recovery\"\n#| out-width: \"50%\"\ndag_studie_a <-\n  dagitty(\"dag{\n          gender -> drug\n          drug -> recovery\n          gender -> recovery\n          }\n      \")\n\ncoordinates(dag_studie_a) <-\n  list(x = c(gender = 0, drug = 0, recovery  = 1),\n       y = c(gender = 0, drug = 1, recovery = 0.5))\n\n\nplot(dag_studie_a)\n```\n\n\nBetrachtung der Gesamtdaten zeigt in diesem Fall einen *konfundierten* Effekt: Geschlecht konfundiert den Zusammenhang von Medikament und Heilung.\n\n\n:::callout-important\nBetrachtung der Teildaten (d.h. stratifiziert pro Gruppe) zeigt in diesem Fall den wahren, kausalen Effekt. \nStratifizieren ist also in diesem Fall der korrekte, richtige Weg.\nAchtung: Das Stratifizieren ist nicht immer und nicht automatisch die richtige L√∂sung.\nStratifizieren bedeutet,\nden Gesamtdatensatz in Gruppen oder \"Schichten\" (\"Strata\")\n:::\n\n\n\n\n### Studie B: Blutdruck\n\n\n#### Medikament einnehmen?\n\nMit Blick auf @tbl-studie-b: Was raten Sie dem Arzt? Medikament einnehmen, ja oder nein?\n\n\n```{r dag-studie-b-table}\n#| echo: false\n#| message: false\n#| label: tbl-studie-b\n#| tbl-cap: \"Daten zur Wirksamkeit eines Medikaments (Studie B)\"\nstudie_b <- \n  tibble::tribble(\n~ Gruppe,          ~`Ohne Medikament`,          ~`Mit Medikament`,\n\"geringer Blutdruck\",    \"81/87 √ºberlebt (93%)\", \"234/270 √ºberlebt (87%)\",\n\"hoher Blutdruck\",  \"192/263 √ºberlebt (73%)\",   \"55/80 √ºberlebt (69%)\",\n\"Gesamt\",  \"273/350 √ºberlebt (78%)\", \"289/350 √ºberlebt (83%)\"\n  )\n\nstudie_b %>% \n  gt()\n```\n\n\n\n\n\n\nDie Daten stammen aus einer (fiktiven) klinischen Studie, $n=700$, hoher Qualit√§t (Beobachtungsstudie).\nBei geringem Blutdruck scheint das Medikament zu schaden.\nBei hohem Blutdrck scheint das Medikamenet auch zu schaden.\nAber *insgesamt* (Summe √ºber beide Gruppe) *nicht*, da scheint es zu nutzen?!\nWas sollen wir den Arzt raten? Soll er das Medikament verschreiben? Vielleicht nur dann, wenn er den Blutdruck nicht kennt? @pearl_causal_2016\n\n\n#### Kausalmodell zur Studie B\n\n\n\n\n\nDas Medikament hat einen (absenkenden) Einfluss auf den Blutdruck.\nGleichzeitig hat das Medikament einen (toxischen) Effekt auf die Heilung.\nVerringerter Blutdruck hat einen positiven Einfluss auf die Heilung.\nSucht man innerhalb der Leute mit gesenktem Blutdruck nach Effekten, findet man nur den toxischen Effekt: Gegeben diesen Blutdruck ist das Medikament sch√§dlich aufgrund des toxischen Effekts. Der positive Effekt der Blutdruck-Senkung ist auf diese Art nicht zu sehen.\n\nDas Kausalmodell ist in @fig-dag-studie-b dargestellt.\n\n\n\n```{r dag-studie-b}\n#| echo: false\n#| label: fig-dag-studie-b\n#| fig-cap: \"Drug hat keinen direkten, aber zwei indirekte Effekt auf recovery, einer davon ist heilsam, einer sch√§dlich\"\n#| out-width: \"50%\"\ndag_studie_b <-\n  dagitty(\"dag{\n          drug -> pressure\n          drug -> toxic\n          pressure -> recovery\n          toxic -> recovery\n          }\n      \")\n\nplot(dag_studie_b)\n```\n\nBetrachtung der Teildaten zeigt nur den toxischen Effekt des Medikaments, nicht den n√ºtzlichen (Reduktion des Blutdrucks).\n\n\n\n\n:::callout-important\nBetrachtung der Gesamtdaten zeigt in diesem Fall den wahren, kausalen Effekt. \nStratifizieren w√§re falsch, da dann nur der toxische Effekt, aber nicht der heilsame Effekt sichtbar w√§re.\n:::\n\n\n\n\n\n\n### Studie A und B: Gleiche Daten, unterschiedliches Kausalmodell\n\n\nVergleichen Sie die DAGs @fig-dag-studie-a und @fig-dag-studie-b,\ndie die *Kausalmodelle* der Studien A und B darstellen:\nSie sind *unterschiedlich*.\nAber: Die *Daten* sind *identisch*.\n\n\n\nKausale Interpretation - und damit Entscheidungen f√ºr Handlungen - war nur m√∂glich, da das Kausalmodell bekannt ist. \nDie Daten alleine reichen nicht.\nGut merken.\n\n\n\n\n\n### Sorry, Statistik: Du allein schaffst es nicht\n\n\n\n\nStatistik alleine reicht nicht f√ºr Kausalschl√ºsse. üßü\nStatistik plus Theorie erlaubt Kausalschl√ºsse. üìö‚ûïüìä  üü∞  ü§©\n\n\n\n:::callout-important\nF√ºr Entscheidungen (\"Was soll ich tun?\") braucht man kausales Wissen.\nKausales Wissen basiert auf einer Theorie (Kausalmodell) plus Daten.\n:::\n\n\n### Vertiefung^[Dieser Abschnitt ist pr√ºfungsrelevant, birgt aber nichts Neues.]\n\n\n\n\n#### Studie C: Nierensteine\n\n\n\nNehmen wir an, es gibt zwei Behandlungsvarianten bei Nierensteinen, Behandlung A und B. √Ñrzte tendieren zu Behandlung A bei gro√üen Steinen (die einen schwereren Verlauf haben); bei kleineren Steinen tendieren die √Ñrzte zu Behandlung B. \n\n\nSollte ein Patient, der nicht wei√ü, ob sein Nierenstein gro√ü oder klein ist, die Wirksamkeit in der Gesamtpopulation (Gesamtdaten) oder in den stratifizierten Daten (Teildaten nach Steingr√∂√üe) betrachten, um zu entscheiden, welche Behandlungsvariante er (oder sie) w√§hlt?\n\n\n\n\n\n\n\n\n\n\nDie Gr√∂√üe der Nierensteine hat einen Einfluss auf die Behandlungsmethode.\nDie Behandlung hat einen Einfluss auf die Heilung.\nDamit gibt es eine Mediation (\"Kette\") von Gr√∂√üe $\\rightarrow$ Behandlung $\\rightarrow$ Heilung.\nDar√ºber hinaus gibt es noch einen Einfluss von Gr√∂√üe der Nierensteine auf die Heilung.\n\nDas Kausalmodell ist in @fig-dag-studie-c dargestellt; @fig-dag-studie-c2 visualisiert alternativ.\n\nSollte man hier `size` kontrollieren,\nwenn man den Kausaleffekt von `treatment` sch√§tzen m√∂chte? \nOder lieber nicht kontrollieren?\n\n\n\n\n```{r dag-studie-c}\n#| echo: false\n#| fig-cap: \"DAG zur Nierenstein-Studie\"\n#| out-width: \"50%\"\n#| label: fig-dag-studie-c\ndag_studie_c <-\n  dagitty(\"dag{\n         size -> recovery\n         size -> treatment\n         treatment -> recovery\n          }\n      \")\n\ncoordinates(dag_studie_c) <-\n  list(x = c(size = 0, treatment = 0, recovery  = 1),\n       y = c(size = 0, treatment = 1, recovery = 0.5))\nplot(dag_studie_c)\n\n\n```\n\n\n```{r dag-c2}\n#| echo: false\n#| fig-cap: \"DAG zur Nierenstein-Studie in zweiter Darstellungsform\"\n#| out-width: \"50%\"\n#| label: fig-dag-studie-c2\ncoordinates(dag_studie_c) <-\n  list(x = c(size = 0.5, treatment = 0, recovery  = 1),\n       y = c(size = 0, treatment = 1, recovery = 1))\nplot(dag_studie_c)\n```\n\nJa: In diesem Fall sollte man `size` kontrollieren,\ndenn man ist am Effekt des `treatments` interessiert.\nW√ºrde man nicht `size` kontrollieren,\nbek√§me man den \"vermengten\" Effekt von `size ` und `treatment`,\nalso keine (belastbare) Aussage √ºber den Effekt der Behandlung.\n\n\n\n\n#### Mehr Beispiele\n\nNehmen Sie Bezug zu folgenden Aussagen:\n\n\n>   Studien zeigen, dass Einkommen und Heiraten (bzw. verheiratete sein) hoch korrelieren. Daher wird sich dein Einkommen erh√∂hen, wenn du heiratest.\n\n\n\n\n\n>   Studien zeigen, dass Leute, die sich beeilen, zu sp√§t zu ihrer Besprechung kommen. Daher lieber nicht beeilen, oder du kommst zu sp√§t zu deiner Besprechung.\n\n\n\n\n\n\n\n### Zwischenfazit\n\nBei *Beobachtungsstudien* ist aus den Daten alleine nicht herauszulesen,\nob eine Intervention wirksam ist,\nob es also einen kausalen Effekt von der Intervention (angenommen Ursache) auf eine AV (Wirkung) gibt.\nDamit ist auch nicht zu erkennen, welche Entscheidung zu treffen ist.\nNur Kenntnis des Kausalmodells zus√§tzlich zu den Daten erlaubt,\neine Entscheidung sinnvoll zu treffen.\n\nBei *experimentellen Daten* ist die Kenntnis des Kausalmodells nicht n√∂tig (wenn das Experiment handwerklich gut gestaltet ist):\nDas Randomisieren der Versuchspersonen zu Gruppen und das Kontrollieren der Versuchsbedingungen sorgen daf√ºr,\ndass es keine Konfundierung gibt.\n\n\n\n\n\n## Konfundierung\n\n\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\n\n\n\n\n### Datensatz 'Hauspreise im Saratoga County'\n\n\nWir nutzen den Datensatz [Saratoga County](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv); s. @tbl-saratoga.\nHier gibt es eine \n[Beschreibung des Datensatzes](https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SaratogaHouses.html).\n\n\n```{r data-saratoga, echo = TRUE}\nd_path <- \"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv\"\n```\n\n\n\n```{r read-data, echo = FALSE}\n#| message: false\nd <- data_read(d_path)  # aus easystats\n```\n\n```{r}\n#| echo: false\n#| label: tbl-saratoga\n#| tbl-cap: \"Saratoga-County-Datensatz\"\nd %>% \n  select(price, livingArea, bedrooms,waterfront) %>% \n  slice_head(n = 5)\n```\n\n\n\n\n### Immobilienpreise in einer schicken Wohngegend vorhersagen\n\n\n\n>   Finden Sie den Wert meiner Immobilie heraus! </br>\nDie muss viel wert sein!\"\n\nüßë Das ist Don, Immobilienmogul, Auftraggeber.\n\n\n\n>   Das finde ich heraus. Ich mach das wissenschaftlich.\n\nüë© üî¨ Das ist Angie, Data Scientistin.\n\n\n\n### Modell 1: Preis als Funktion der Anzahl der Zimmer\n\n\n\n>   \"Hey Don! Mehr Zimmer, mehr Kohle!\"\nüë© üî¨\n\n\nModell 1 (`m1`) modelliert den Hauspreis als Funktion der Zimmerzahl, s. @fig-m1.\n\n\n\n```{r d-plot-don1}\n#| echo: false\n#| message: false\n#| label: fig-m1\n#| fig-cap: \"Modell m1\"\nd %>% \n  ggplot() +\n  aes(x = bedrooms, y = price) +\n  geom_jitter(alpha = .3) +\n  geom_smooth(method = \"lm\")\n```\n\n\n\n\n\n\n>   \"Jedes Zimmer mehr ist knapp 50 Tausend wert. Dein Haus hat einen Wert von etwa 150 Tausend Dollar, Don.\"\n\nüë©\n\n>   Zu wenig! ü§¨\n\nüßë\n\n\nBerechnen wir das Modell `m1`; der Punktsch√§tzer des Parameters `bedroom` steht in @tbl-m1-hdi.\n\n\n```{r m1, echo = TRUE}\n#| label: tbl-m1-hdi\n#| tbl-cap: \"Parameter f√ºr m1\"\nm1 <- stan_glm(price ~ bedrooms,\n               refresh = 0,\n               seed = 42,\n               data = d)\n\npoint_estimate(m1)\n```\n\n\n`point_estimates(modell)` gibt die Punktsch√§tzer der Parameter eines Modells zur√ºck,\naber nicht die Sch√§tzbereiche. M√∂chten Sie beides, k√∂nnen Sie die Funktion `parameters(modell)` nutzen.^[In aller Regel macht es mehr Sinn, die Sch√§tzbereiche der Punktsch√§tzer auch zu betrachten. Nur die Punktsch√§tzer zu betrachten vernachl√§ssigt wesentliche Information.]\n\nMit `estimate_predictions` k√∂nnen wir Vorhersagen berechnen (bzw. sch√§tzen; die Vorhersagen sind ja mit Ungewissheit verbunden, daher ist \"sch√§tzen\" vielleicht das treffendere Wort).\n@tbl-m1-pred zeigt den laut `m1` vorhergesagten Hauspreis f√ºr ein Haus mit 2 Zimmern.\n\n\n```{r echo = TRUE}\n#| tbl-cap: \"Vorhersage des Hauspreises f√ºr ein Haus mit 2 Zimmern\"\n#| label: tbl-m1-pred\ndons_house <- tibble(bedrooms = 2)\nestimate_prediction(m1, data = dons_house)\n```\n\n\n\n\n### Don hat eine Idee \n\n\n\n>   \"Ich bau eine Mauer! Genial! An die Arbeit, Angie! </br>\nüßë\n\nDon hofft, durch Verdopplung der Zimmerzahl den doppelten Verkaufspreis zu erzielen. Ob das klappt?\n\n>   Das ist keine gute Idee, Don.\"\n\nüë©\n\nBerechnen wir die Vorhersagen f√ºr Dons neues Haus (mit den durch Mauern halbierten Zimmern), s. @tbl-m1-pred2a.\n\n\n```{r}\n#| tbl-cap: \"Vorhergesagter Hauspreis laut m1 f√ºr ein Haus mit 4 Zimmern\"\n#| label: tbl-m1-pred2a\ndons_new_house <- tibble(bedrooms = 4)\nestimate_prediction(m1, dons_new_house)\n```\n\n\nMit 4 statt 2 Schlafzimmer steigt der Wert auf 250k, laut `m1`, @fig-m1.\n\n\n>   Volltreffer! Jetzt verdien ich 100 Tausend mehr! ü§ë Ich bin der Gr√∂√üte!\nüßë\n\n\n\n\n:::callout-note\nZur Erinnerung: \"4e+05\" ist die Kurzform der wissenschaftlichen Schreibweise und bedeutet: $4 \\cdot 100000 = 4\\cdot10^5 = 400000$\n:::\n\n\n### R-Funktionen, um Beobachtungen vorhersagen \n\n\n\n`estimate_prediction(m1, dons_new_house)` erstellt *Vorhersageintervalle*, ber√ºcksichtigt also *zwei Quellen* von Ungewissheit:\n\n- Ungewissheiten in den Parametern (Modellkoeffizienten, $\\beta_0, \\beta_1, ...$)\n- Ungewissheit im \"Strukturmodell\": Wenn also z.B. in unserem Modell ein wichtiger Pr√§diktor fehlt, so kann die Vorhersagen nicht pr√§zise sein. Fehler im Strukturmodell schlagen sich in breiten Sch√§tzintervallen (bedingt durch ein gro√ües $\\sigma$) nieder.\n\n\n\n`estimate_expectation(m1, dons_new_house)` erstellt *Konfidenzintervalle*.  ber√ºcksichtigt also nur *eine Quelle* von Ungewissheit:\n\n- Ungewissheiten in den Parametern (Modellkoeffizienten, $\\beta_0, \\beta_1, ...$)\n\n\nDie Sch√§tzbereiche sind in dem Fall deutlich kleiner:\n\n\n```{r plot-m1-dons-new-house}\nestimate_expectation(m1, dons_new_house)\n```\n\n\n\n\n### Modell 2\n\n\nBerechnen wir das Modell  `m2: price ~ bedrooms + livingArea`, s. @tbl-m2.\n\n```{r, echo = TRUE}\n#| tbl-cap: \"Parameter von m2\"\n#| label: tbl-m2\nm2 <- stan_glm(price ~ bedrooms + livingArea, \n               data = d, \n               seed = 42,\n               refresh = 0)\n\npoint_estimate(m2, centrality = \"median\")\n```\n\nWas sind die Vorhersagen des Modell? \n@tbl-m2-pred gibt Aufschluss f√ºr den laut `m2` vorhersagten Kaufpreis eines Hauses\nmit 4 Zimmern und 1200 Quadratfu√ü Wohnfl√§che; @tbl-m2-pred2 gibt die Sch√§tzung (laut `m2`) f√ºr den Preis eines Hauses mit 2 Zimmern (und der gleichen Wohnfl√§che).\n\n\n```{r m2-pred, echo = TRUE}\n#| tbl-cap: \"Vorhersage von m2 f√ºr ein Haus mit 4 Zimmern und 1200 Einheiten Wohnfl√§che\"\n#| label: tbl-m2-pred\nestimate_prediction(m2, data = tibble(bedrooms = 4, livingArea = 1200))\n```\n\n\n```{r m2-pred2, echo = FALSE}\n#| tbl-cap: \"Vorhersage von m2 f√ºr ein Haus mit 2 Zimmern und 1200 Einheiten Wohnfl√§che\"\n#| label: tbl-m2-pred2\nestimate_prediction(m2, data = tibble(bedrooms = 2, livingArea = 1200))\n```\n\n\n\n\nAndere, aber √§hnliche Frage: Wieviel kostet ein Haus mit sagen wir 4 Zimmer *gemittelt* √ºber die verschiedenen Gr√∂√üen von `livingArea`? Stellen Sie sich alle H√§user mit 4 Zimmern vor (also mit verschiedenen Wohnfl√§chen). Wir m√∂chten nur wissen, was so ein Haus \"im Mittel\" kostet.\nWir m√∂chten also die Mittelwerte pro `bedroom` sch√§tzen, gemittelt f√ºr jeden Wert von `bedroom` √ºber `livingArea`.\nDie Ergebnisse stehen in @tbl-m2-preds und sind in @fig-m2-preds visualisiert.\n\n```{r m2-pred-means}\n#| label: tbl-m2-preds\n#| tbl-cap: \"Vorhersagen des Preises von H√§usern mit verschiedener Zimmerzahl gemittelt √ºber die verschiedenen Werte der Wohnfl√§che; basierend auf m2.\"\nestimate_means(m2, at = \"bedrooms\", length = 7)\n```\n\n\n```{r}\n#| echo: false\n#| label: fig-m2-preds\n#| fig-asp: 0.3\n#| fig-cap: \"Hauspreis als Funktion der Zimmerzahl, laut m2\"\nestimate_means(m2, at = \"bedrooms\", length = 7) %>% \n  ggplot() +\n  aes(x = bedrooms, y = Mean) +\n  geom_line() +\n  geom_point(alpha = .7) \n```\n\n\n\n\n>   \"Die Zimmer zu halbieren,\nhat den Wert des Hauses *verringert*,\nDon!\"\n\nüë©\n\n\n>   \"Verringert!? Weniger Geld?! Oh nein!\"\n\nüßë\n\n\n\n\n\n### Die Zimmerzahl ist negativ mit dem Preis korreliert \n\n... wenn man die Wohnfl√§che (Quadratmeter) kontrolliert, s. @fig-m2-negativ.\n\n\n\n>   **\"Ne-Ga-Tiv!\"**\n\nüë©\n\n\n![Hauspreis stratifizieren](img/hauspreis1.png){#fig-m2-negativ fig-asp=.5}\n\n[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Hauspreis-stratifizieren.Rmd)\n\n\n## Kontrollieren von Variablen\n\n\nüí° Durch das Aufnehmen von Pr√§diktoren in die multiple Regression werden die Pr√§diktoren *kontrolliert* (adjustiert, konditioniert):\n\nDie Koeffizienten einer multiplen Regression zeigen den Zusammenhang $\\beta$ des einen Pr√§diktors mit $y$, wenn man den (oder die) anderen Pr√§diktoren statistisch *konstant h√§lt*. \n\nMan nennt die Koeffizienten einer multiplen Regression daher auch *parzielle Regressionskoeffizienten*. Manchmal spricht man, eher umgangssprachlich, auch vom \"Netto-Effekt\" eines Pr√§diktors, oder davon, dass ein Pr√§diktor \"bereinigt\" wurde vom (linearen) Einfluss der anderen Pr√§diktoren auf $y$.\n\nDamit kann man die Regressionskoeffizienten so interpretieren, dass Sie den Effekt des Pr√§diktors $x_1$ auf $y$ anzeigen *unabh√§ngig* vom Effekt der anderen Pr√§diktoren, $x_2,x_3,...$ auf $y$.\n\nMan kann sich dieses Konstanthalten vorstellen als eine Aufteilung in Gruppen: Der Effekt eines Pr√§diktors $x_1$ wird f√ºr jede Auspr√§gung (Gruppe) des Pr√§diktors $x_2$ berechnet.\n\n\n\n\n### Das Hinzuf√ºgen von Pr√§diktoren kann die Gewichte der √ºbrigen Pr√§diktoren √§ndern\n\n\n\n\n\n\n>   Aber welche und wie viele Pr√§diktoren soll ich denn jetzt in mein Modell aufnehmen?! Und welches Modell ist jetzt richtig?!\n\nüßë\n\n>   Leider kann die Statistik keine Antwort darauf geben.\n\nüë©\n\n\n>   Wozu ist sie dann gut?!\n\nüßë\n\n\n:::callout-important\nIn Beobachtungsstudien hilft nur ein (korrektes) Kausalmodell. Ohne Kausalmodell ist es nutzlos, die Regressionskoeffizienten (oder eine andere Statistik) zur Erkl√§rung der Ursachen heranzuziehen:\nDie Regressionskoeffizienten k√∂nnen sich wild √§ndern, wenn man Pr√§diktoren hinzuf√ºgt oder wegl√§sst. \nEs k√∂nnen sich sogar die Vorzeichen der Regressionsgewichte √§ndern;\nin dem Fall spricht man von einem Simpson-Paradox.\n:::\n\n\n\n\n## Welches Modell richtig ist, kann die Statistik nicht sagen\n\n>   Often people want statistical modeling to do things that statical modeling cannot do.\nFor example, we'd like to know wheter an effect is \"real\" or rather spurios.\nUnfortunately, modeling merely quantifies uncertainty in the precise way that the model understands the problem.\nUsually answers to lage world questions about truth and causation depend upon information not included in the model.\nFor example, any observed correlation between an outcome and predictor could be eliminated or reversed once another predictor is added to the model.\nBut if we cannot think of the right variable,\nwe might never notice.\nTherefore all statical models are vulnerable to and demand critique,\nregardless of the precision of their estimates\nand apparaent accuracy of their predictions.\nRounds of model criticism and revision embody the real tests of scientific hypotheses.\nA true hypothesis will pass and fail many statistical \"tests\" on its way to acceptance.\n\n\n@mcelreath_statistical_2020, S. 139\n\n\n\n### Kausalmodell f√ºr Konfundierung, `km1`\n\nDas Kausalmodell `km1` ist in @fig-km1 dargestellt; vgl.  @fig-m2-negativ.\n\n\n```{r km1, fig.asp = .33, fig.width=9}\n#| echo: false\n#| warning: false\n#| label: fig-km1\n#| fig-cap: \"Kausalmodell km1 - Eine Erkl√§rung (von mehreren) f√ºr m1 bzw. die Daten, die m1 zugrunde liegen\"\nkm1 <- confounder_triangle(x = \"bedrooms\",\n                          y = \"price\",\n                          z = \"living area\") %>% \n  ggdag_dconnected(text = FALSE, use_labels = \"label\") +\n  theme_dag()\n\nprint(km1)\n```\n\nWenn dieses Kausalmodell stimmt, findet man eine *Scheinkorrelation* zwischen `price` und `bedrooms`.\n\nEine Scheinkorrelation ist ein Zusammenhang, der *nicht* auf eine kausalen Einfluss beruht.\n\n`d_connected` hei√üt, dass die betreffenden Variablen \"verbunden\" sind durch einen gerichteten (`d` wie directed) Pfad, durch den die Assoziation (Korrelation) wie durch einen Fluss flie√üt üåä. `d_separated` hei√üt, dass sie nicht `d_connected` sind.\n\n\n### `m2` kontrolliert die Konfundierungsvariable `livingArea`\n\nWenn das Kausalmodell stimmt, dann zeigt `m2` den kausalen Effekt von `livingArea`.\n\n>   Was tun wir jetzt blo√ü?! Oh jeh!\n\nüßë\n\n\n>   Wir m√ºssen die Konfundierungsvariable kontrollieren.\n\nüë©\n\n\n@fig-km1-controlled zeigt, dass `bedrooms` und `price` *unkorreliert* werden (`d_separated`), wenn man `living area` kontrolliert.\n\n```{r confounder-triangle, fig.asp = 0.45, fig.width=9, dpi=300}\n#| echo: false\n#| warning: false\n#| label: fig-km1-controlled\n#| fig-cap: \"Durch Kontrolle von living area wird die Assoziation von price und bedrooms aufgehoben.\"\nconfounder_triangle(x = \"bedrooms\",\n                          y = \"price\",\n                          z = \"living area\") %>% \n ggdag_dconnected(text = FALSE, use_labels = \"label\", \n                  controlling_for = \"z\") +\n  theme_dag()\n```\n\nDurch das Kontrollieren (\"adjustieren\"), sind `bedrooms` und `price` nicht mehr korreliert, nicht mehr `d_connected`, sondern jetzt `d_separeted`.\n\n\n### Konfundierer kontrollieren\n\nGehen wir in diesem Abschnitt davon aus, dass `km1` richtig ist.\n\n\n```{r}\n#| echo: false\nsource(\"https://raw.githubusercontent.com/sebastiansauer/QM2-Folien/41bc43754169f64abd6ad98f8d52b5c0e23eda80/R-Code/controlling-confounder.R\")\n```\n\n\n\n*Ohne* Kontrollieren der Konfundierungsvariablen: Regressionsmodell `y ~ x`, @fig-p-konf1, links:\nEs wird (f√§lschlich) eine Korrelation zwischen `x` und `y`  angezeigt: Scheinkorrelation.\n*Mit* Kontrollieren der Konfundierungsvariablen: Regressionsmodell `y ~ x + group`, @fig-p-konf1, rechts.\n\n```{r}\n#| echo: false\n#| fig-cap: \"Konfundierung von y und x!\"\n#| layout-ncol: 2\n#| fig-subcap: \n#|   - \"Ohne Kontrolle der Konfundierungsvariablen: Konfundierung tritt auf.\"\n#|   - \"Mit Kontrolle der Konfundierungsvariablen: Konfundierung tritt nicht auf.\"\n#| label: fig-p-konf1\np_konf1\np_konf2\n```\n\n\n\n\n\n@fig-p-konf1, rechts, zeigt korrekt, dass es keine Korrelation zwischen `x` und `y` gibt, wenn `group` kontrolliert wird.\nAu√üerdem sieht man im rechten Teildiagramm, dass es ein Kontrollieren der Variable `group` durch Aufnahme als Pr√§diktor in die Regressionsgleichung einem Stratifizieren entspricht (getrennte Berechnung der Regressionsgerade pro Gruppe).\n\n\n\n\n\n\n[Quellcode](https://github.com/sebastiansauer/QM2-Folien/blob/main/Themen/children/Konfundierer-kontrollieren.Rmd)\n\n\n\n\n\n\n### `m1` und `m2` passen nicht zu den Daten, wenn `km1` stimmt\n\n\n\n\n\n\nLaut `km1` d√ºrfte es keine Assoziation (Korrelation) zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert, wie in @fig-km1 dargestellt.\nEs gibt aber noch eine Assoziation zwischen `bedrooms` und `price` geben, wenn man `livingArea` kontrolliert.\n Daher sind sowohl `m1` und `m2` nicht mit dem Kausalmodell `km1` vereinbar.\n\n\n\n\n\n### Kausalmodell 2, `km2` \n\nUnser Modell `m2` sagt uns, \ndass beide Pr√§diktoren jeweils einen eigenen Beitrag zur Erkl√§rung der AV haben.\n\n\n\nDaher k√∂nnte das folgende Kausalmodell, `km2` besser passen.\n\nIn diesem Modell gibt es eine *Wirkkette*: $a \\rightarrow b \\rightarrow p$.\n\nInsgesamt gibt es zwei Kausaleinfl√ºsse von `a` auf `p`:\n    - $a \\rightarrow p$\n    - $a \\rightarrow b \\rightarrow p$\n\nMan nennt die mittlere Variable einer Wirkkette auch einen *Mediator* und den Pfad von der UV (`a`) √ºber den Mediator (`b`) zur AV (`p`) auch *Mediation*, s. @fig-m1-mediation.\n\n\n\n```{r km2}\n#| echo: false\n#| fig-cap: \"Der Effekt von livingArea wird √ºber den Mediator bedrooms auf price vermittelt.\"\n#| label: fig-m1-mediation\nkm2 <- \n  dagify(\n  b ~ a,\n  p ~ a,\n  p ~ b,\n  labels = c(b = \"bedrooms\",\n             p = \"price\",\n             a = \"livingArea\")) %>% \n    ggdag(use_labels = \"label\") +\n  theme_dag()\n\nprint(km2)\n```\n\n\n\n\n\n\n### Dons Kausalmodell, `km3`\n\nSo sieht Dons Kausalmodell aus, s. @fig-km3.\n\n\n```{r km3, fig.width=9}\n#| echo: false\n#| out-width: \"50%\"\n#| label: fig-km3\n#| fig-cap: \"Dons Kausalmodell\"\nkm3 <- collider_triangle(x = \"bedrooms\",\n                          y = \"livingArea\",\n                          m = \"price\") %>% \n  ggdag_dconnected(text = FALSE, use_labels = \"label\") +\n  theme_dag()\n\nprint(km3)\n```\n\n\n\n>   Ich glaube aber an mein Kausalmodell. Mein Kausalmodell ist das gr√∂√üte! Alle anderen Kausalmodelle sind ein Disaster!\"\n\nüßë\n\n</br>\n\n>   \"Don, nach deinem Kausalmodell m√ºssten `bedrooms` und `livingArea` unkorreliert sein. Sind sie aber nicht.\"\n\n\nRechne doch selber die Korrelation aus, Don:\n\n\n>   √Ñh, wie ging das nochmal?\n\nüßë\n\n\nSo k√∂nntest du das rechnen, Don: `correlation(d, select = c(\"bedrooms\", \"livingArea\"))`. \nOder z.B. so:\n\n```{r}\ndons_r <- d %>% \n  summarise(cor(bedrooms, livingArea))\n```\n\nDie Korrelation liegt also bei `r  round(cor(d$bedrooms, d$livingArea), 2)`\n\n\n>   Bitte, gerne hab ich dir geholfen, Don.\n\nüë©\n\n\n\n\n\n\n### Unabh√§ngigkeiten laut der Kausalmodelle\n\n\n`km1`: `b`: bedrooms, `p`: price, `a` area (living area), s. @fig-km1.\n\n\n\nDas Kausalmodell `km1` behauptet: $b \\indep p \\, |\\, a$: `bedrooms` sind unabh√§ngig von `price`, wenn man `livingArea` kontrolliert.\n\n*Kontrollieren* einer Variable $Z$ erreicht man auf einfache Art,\nindem man sie in zus√§tzlich zur vermuteten Ursache $X$ in die Regressionsgleichung mit aufnimmt, also `y ~ x + z`. \n\n\nAber diese behauptete Unabh√§ngigkeit findet sich *nicht* in den Daten wieder, s. @tbl-m2. Also: ‚õàÔ∏è Passt nicht zu den Daten!\n\n\n\n\n\n\n`km2` `b`: bedrooms, `p`: price, `a` area (living area), s. @fig-m1-mediation.\n\n\n\nDas Kausalmodell `km2` postuliert *keine* Unabh√§ngigkeiten:\nLaut `km2`sind alle Variablen des Modells miteinander assoziiert (korreliert).\n\n:::callout-note\nEin Modell, in dem alle Variablen miteinander korreliert sind,\nnennt man auch *satuiert* oder saturiertes Modell.\nSo ein Modell ist empirisch *schwach*.\nDenn: Behauptet ein Modell, \ndass die Korrelation zwischen zwei Variablen irgendeinen Wert zwischen -1 und +1 betr√§gt (nur nicht exakt Null), so ist das eine sehr schwache Aussage (und kaum zu falsifizieren). \nSo ein Modell ist wissenschaftlich wenig wert. \nDas ist so √§hnlich wie ein Modell, das voraussagt,\ndass es morgen irgendeine Temperatur hat zwischen -30 und +30 Grad (nur nicht exakt Null). Trifft diese Temperaturvorhersage ein,\nso werden wir nicht gerade beeindruckt sein. ü•±\n:::\n\nFazit: `km2` passt zu den Daten, aber wir sind nicht gerade beeindruckt vom Modell.\n\n\n\n\n\n\n`km3`: `b`: bedrooms, `p`: price, `a` area (living area), s. @fig-km3.\n\n\n\n\n\n$b \\indep a$: `bedrooms` sind unabh√§ngig von `livingArea` (`a`)\n\n\n‚õàÔ∏è `km3` passt nicht zu den Daten/zum Modell!\n\n\n\n\n\n## DAGs: Directed Acyclic Graphs\n\n\nWas sind DAGs? Wir haben in diesem Kapitel schon viele Beispiele gesehen, z.B.  @fig-km3.\n\n- DAGs sind eine bestimmte Art von Graphen zur Analyse von Kausalstrukturen.\n\n- Ein *Graph* besteht aus Knoten (Variablen) und Kanten (Linien), die die Knoten verbinden.\n\n- DAGs sind *gerichtet*; die Pfeile zeigen immer in eine Richtung (und zwar von Ursache zu Wirkung).\n\n- DAGs sind *azyklisch*; die Wirkung eines Knoten darf nicht wieder auf ihn zur√ºckf√ºhren. \n\n- Ein *Pfad* ist ein Weg durch den DAG, von Knoten zu Knoten √ºber die Kanten, unabh√§ngig von der Pfeilrichtung.\n\n\n\nDer DAG von `km1` ist in @fig-km1 zu sehen.\n\n\n### Leider passen potenziell viele DAGs zu einer Datenlage\n\n`b`: bedrooms, `p`: price, `a` area (living area)\n\n\nJa, der Job der Wissenschaft ist kein Zuckerschlecken.\nAber wenn es einfach w√§re, die Kausalstruktur der Ph√§nomene zu entdecken,\nw√§ren sie l√§ngst erkannt, und alle Probleme der Menschheit gel√∂st.\n\nIn @fig-kms sind m√∂gliche Kausalmodelle f√ºr Dons Studie dargestellt.\n\n\n```{r dag-km1, fig.width=9}\n#| echo: false\n#| label: fig-kms\n#| fig-cap: \"Kausalmodelle, die potenziell geeignet sind f√ºr Dons Fragestellung\"\ndag_km1 <-\n  dagitty(\"dag{\n         a -> b\n         a -> p\n         }\n         \")\n\n\ncoordinates(dag_km1) <- list(\n  x = list(a = 0, b = 1, p = 1),\n  y = list(a = 0.5, b= 1, p = 0 )\n)\n\nggdag_equivalent_dags(dag_km1) +\n  theme_dag()\n```\n\n\nAlle diese DAgs in @fig-km1 haben die *gleichen* Implikationen hinsichtlich der (Un-)Abh√§ngigkeiten zwischen der Variablen.\nWir k√∂nnen also leider empirisch nicht bestimmen,\nwelcher der DAGs der richtige ist.\nUm den richtigen DAG zu identifizieren, br√§uchten wir z.B. einen reichhaltigeren DAG,\nalso mit mehr Variablen.\n\n\n\n\n### Was ist eigentlich eine Ursache?\n\nEtwas verursachen kann man auch (hochtrabend) als \"Kausation\" bezeichnen.\n\n:::callout-note\nWei√ü man, was die Wirkung $W$ einer Handlung $H$ (Intervention) ist,  so hat man $H$ als Ursache von $W$ erkannt.\n:::\n  \n@mcelreath_statistical_2020\n\n\nViele Menschen denken - f√§lschlich - dass Korrelation Kausation bedeuten muss, s. @fig-xkcd-causation.\n\n\n```{r}\n#| echo: false\n#| fig-align: \"center\"\n#| out-width: \"50%\"\n#| label: fig-xkcd-causation\n#| fig-cap: \"xkcd zum Thema Kausation\"\nknitr::include_graphics(\"img/correlation.png\")\n```\n\n\n[Quelle](https://xkcd.com/552/) und [Erkl√§rung](https://www.explainxkcd.com/wiki/index.php/552:_Correlation)\n\n\n\n\n\n### Zwischenfazit\n\nSind zwei Variablen korreliert (abh√§ngig, assoziiert), so kann es daf√ºr zwei Gr√ºnde geben:\n\n- Kausaler Zusammenhang\n- Nichtkausaler Zusammenhang (\"Scheinkorrelation\")\n    \nEine m√∂gliche Ursache einer Scheinkorrelation ist Konfundierung.\n\nKonfundierung kann man entdecken, indem man die angenommene Konfundierungsvariable kontrolliert (adjustiert), z.B. indem man ihn als Pr√§diktor in eine Regression aufnimmt.\n\nIst die Annahme einer Konfundierung korrekt, so l√∂st sich der Scheinzusammenhang nach dem Adjustieren auf.\n\nL√∂st sich der Scheinzusammenhang nicht auf, sondern drehen sich die Vorzeichen der Zusammenh√§nge nach Adjustieren um, so spricht man einem *Simpson-Paradox*.\n\nDie Daten alleine k√∂nnen nie sagen, welches Kausalmodell der Fall ist in einer Beobachtungsstudie. Fachwissen (inhaltliches wissenschaftliches Wissen) ist n√∂tig, um DAGs auszuschlie√üen.\n\n\n\n\n\n\n### Schoki macht Nobelpreis! (?)\n\nüèéÔ∏è Vertiefung üèéÔ∏è\n\n\n\nEine Studie fand eine starke Korrelation, $r=0.79$ zwischen (H√∂he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes [@messerli_chocolate_2012], s. @fig-schoki.\n\n\n```{r schoki-plot, out.width=\"50%\"}\n#| echo: false\n#| warning: false\n#| fig-align: \"center\"\n#| label: fig-schoki\n#| fig-cap: \"Je mehr Schoki, desto mehr Nobelpreise\"\nknitr::include_graphics(\"img/correlation_550.png\")\n```\n\n\n\n:::callout-important\nKorrelation ungleich Kausation! Korrelation *kann* bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt.\nLiegt Korrelation ohne Kausation vor, so spricht man von einer *Scheinkorrelation*.\nUm Scheinkorrelation von echter Assoziation (auf Basis von Kausation) abzugrenzen,\nmuss man die Kausalmodelle √ºberpr√ºfen,\nso wie wir das hier tun.\n:::\n\n\n\n\n\n\n\n\n\n\n\nDer \"Schoki-DAG\" in @fig-schoki-dag zeigt den DAG f√ºr das Schokoloaden-Nobelpreis-Modell.\n\n```{r schok-dag, fig.width=7}\n#| echo: false\n#| label: fig-schoki-dag\n#| fig-cap: \"Macht Schokolade Nobelpreise?\"\nconfounder_triangle(x = \"Schoki\",\n                          y = \"Nobelpreise\",\n                          z = \"Entwicklungsstand\") %>% \n  ggdag_dconnected(text = FALSE, use_labels = \"label\") +\n  theme_dag()\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Kollision\n\n\n\n\n\n\n\n\n\n### Kein Zusammenhang von Intelligenz und Sch√∂nheit (?)\n\nGott ist gerecht (?)\n\nZumindest findet sich in folgenden Daten kein Zusammenhang von Intelligenz (`talent`) und Sch√∂nheit (`looks`),\nwie @fig-iq-schoen illustriert.\nF√ºr geringe Intelligenzwerte gibt es eine breites Spektrum von Sch√∂nheitswerten\nund f√ºr hohe Intelligenzwerte sieht es genauso aus.\n\n```{r p-coll1}\n#| echo: false\n#| out-width: \"50%\"\n#| label: fig-iq-schoen\n#| fig-cap: \"Kein Zusammenhang von Intelligenz und Sch√∂nheit in den Daten\"\n\nmyf <- function(x) -x+0.75\n\nmyf2 <- function(x) -x + 1.25\n\nn <- 1e3\n\nd2 <- tibble(\n  x = runif(n),\n  y = runif(n),\n  status = case_when(\n    y > myf(x) & y < myf2(x) ~ TRUE,\n    TRUE ~ FALSE\n  )\n)\n\n\np_coll1 <-\n  d2 %>% \n  ggplot() +\n  aes(x  = x,\n      y = y) +\n  geom_point() +\n # scale_color_manual(values = c(\"grey80\", \"black\")) +\n  theme_bw() +\n  labs(x = \"Looks\",\n       y = \"Talent\") +\n    theme(legend.position = \"bottom\",\n          axis.text = element_blank())\n\np_coll1\n```\n\n[Gott ist gerecht (?)](https://twitter.com/TheTweetOfGod/status/1462594155176026123)\n\n\n\n\n### Aber Ihre Dates sind entweder schlau oder sch√∂n\n\nSeltsamerweise beobachten Sie, dass die Menschen, die Sie daten (Ihre Dates),\nentweder sch√∂n sind oder schlau - aber seltens beides gleichzeitig (schade),\ns. @fig-dates-beauty.\n\n\n```{r p-coll2}\n#| echo: false\n#| label: fig-dates-beauty\n#| fig-cap: Ihre Datingpartner sind komischerweise entweder schlau oder sch√∂n (aber nicht beides), zumindest in der Tendenz.\n#| out-width: \"50%\"\np_coll2 <- \n  d2 %>% \n  ggplot() +\n  aes(x  = x,\n      y = y,\n      color = status) +\n  geom_point() +\n  scale_color_manual(values = c(\"grey80\", \"black\")) +\n  theme_bw() +\n  labs(x = \"Looks\",\n       y = \"Talent\") +\n    theme(legend.position = \"bottom\",\n          axis.text = element_blank())\n\np_coll2\n```\n\nWie kann das sein?\n\n\n\n\n## DAG zur Rettung \n\nü¶π ü¶∏\n\nDer DAG in @fig-coll1-dag bietet eine rettende Erkl√§rung.\n\n\n\n\n```{r plot-coll-dag1}\n#| echo: false\n#| fig-cap: \"Date als gemeinsame Wirkung von Sch√∂nheit und Intelligenz. Stratifiziert man die gemeinsame Wirkung (dates), so kommt es zu einer Scheinkorrelation zwischen Sch√∂nheit und Intelligenz.\"\n#| out-width: \"50%\"\n#| label: fig-coll1-dag\n\ncoll1_dag <-\n  dagify(date ~ Looks + Talent)\n\np_coll_dag1 <- \ncoll1_dag %>% \n  ggdag() +\n  theme_dag()\n\np_coll_dag1\n```\n\n\nEine √§hnliche Visualisierung des gleichen Sachverhalts zeigt @fig-coll2-dag.\n\n```{r p-coll-dag22, fig.width=9}\n#| echo: false\n#| label: fig-coll2-dag\n#| fig-cap: \"Durch Kontrolle der gemeinsamen Wirkung entsteht eine Scheinkorrelation zwischen den Ursachen\"\np_coll_dag2 <-\n  collider_triangle(x = \"Looks\",\n                  y = \"Talent\",\n                  m = \"date\") %>% \n  ggdag_dseparated(controlling_for = \"m\",\n                   text = TRUE,\n                   use_labels = \"label\") +\n  theme_dag()\n\np_coll_dag2\n```\n\n\n\n\n```{r eval = FALSE}\n#| echo: false\n#| eval: false\nggdag_adjust(coll1_dag, var = \"date\") +\n  theme_dag()\n```\n\n\n\n### Was ist eine Kollision?\n\n\n\nAls *Kollision* (Kollisionsverzerrung, Auswahlverzerrung, engl. collider) bezeichnet man einen DAG, bei dem eine Wirkung zwei Ursachen hat (eine gemeinsame Wirkung zweier Ursachen).\nKontrolliert man  die *Wirkung* `m`, so entsteht eine Scheinkorrelation zwischen den Ursachen `x` und `y`.\nKontrolliert man die Wirkung nicht, so entsteht keine Scheinkorrelation zwischen den Ursachen, s. @fig-coll1-dag, vgl. @rohrer_thinking_2018.\n\n\n::: callout-important\nMan kann also zu viele oder falsche Pr√§diktoren einer Regression hinzuf√ºgen, so dass die Koeffizienten nicht die kausalen Effekte zeigen, sondern durch Scheinkorrelation verzerrte Werte.\n:::\n\n\n### Einfaches Beispiel zur Kollision\n\n\n\nIn der Zeitung *Glitzer* werden nur folgende Menschen gezeigt:\n\n- Sch√∂ne Menschen\n- Reiche Menschen\n    \nehen wir davon aus, dass Sch√∂nheit und Reichtum unabh√§ngig voneinander sind.\n\nWenn ich Ihnen sage, dass Don nicht sch√∂n ist, aber in der Glitzer h√§ufig auftaucht, was lernen wir dann √ºber seine finanzielle Situation?^[Don muss reich sein.]\n\n\n\n\n>   \"Ich bin sch√∂n, unglaublich sch√∂n, und gro√ü, gro√üartig, tolle Gene!!!\" üßë\n\n\n\n\n\n### Noch ein einfaches Beispiel zur Kollision\n\n>   \"So langsam check ich's!\"\n\n\n\nSei Z = X + Y, wobei X und Y unabh√§ngig sind.\n\nWenn ich Ihnen sage, X = 3, lernen Sie nichts √ºber Y, da die beiden Variablen unabh√§ngig sind\n Aber: Wenn ich Ihnen zuerst sage, Z = 10, und dann sage, X = 3, wissen Sie sofort, was Y ist (Y = 7).\n\nAlso: X und Y sind abh√§ngig ‚Äì gegeben Z: $X \\not\\indep Y \\,|\\, Z$.\n\n\n### Durch Kontrollieren entsteht eine Verzerrung bei der Kollision\n\n\n@fig-coll1-dag zeigt: Durch Kontrollieren entsteht eine Kollision,\neine Scheinkorrelation zwischen den Ursachen.\n\n*Kontrollieren* kann z.B. bedeuten:\n\n- *Stratifizieren*: Aufteilen von `date` in zwei Gruppen und dann Analyse des Zusammenhangs von `talent` und `looks` in jeder Teilgruppe von `date`\n- *Kontrollieren mit Regressioin*: Durch Aufnahme von `date` als Pr√§diktor in eine Regression zus√§tzlich zu `looks` mit `talent` als Pr√§dikotr\n\n\n*Ohne* Kontrolle von `date` entsteht *keine* Scheinkorrelation zwischen `Looks` und `Talent`. Der Pfad (\"Fluss\") von `Looks` √ºber `date` nach `Talent` ist blockiert.\n\nKontrolliert man `date`, so *√∂ffnet* sich der Pfad `Looks -> date -> talent` und die Scheinkorrelation entsteht: Der Pfad ist nicht mehr \"blockiert\", die\nKorrelation kann \"flie√üen\" - was sie hier nicht soll,\ndenn es handelt sich um Scheinkorrelation.\n\nDas Kontrollieren von `date` geht zumeist durch Bilden einer Auswahl einer Teilgruppe von sich.\n\n\n\n\n### IQ, Fleiss und Eignung f√ºrs Studium\n\n\nSagen wir, √ºber die *Eignung* f√ºr ein Studium w√ºrden nur (die individuellen Auspr√§gungen) von Intelligenz (IQ) und Fleiss entscheiden, s. den DAG in @fig-coll3-dag.\n\n```{r coll32-dag}\n#| echo: false\n#| label: fig-coll3-dag\n#| fig-cap: Kollisionsstruktur im Dag zur Studiumseignung\ncoll2_dag <- ggdag::dagify(s ~ d + iq,\n                      outcome = \"s\",\n                      labels = c(\"s\" = \"Studium\",\n                                 \"iq\" = \"Intelligenz\",\n                                 \"d\" = \"Fleiss\"))\n\np_coll_dag2 <- ggdag(coll2_dag, use_labels = \"label\")  + theme_dag_blank()\np_coll_dag2\n\n# coll2_dag <-\n#   dagify(eignung ~ fleiss + iq)\n# \n# p_coll_dag2 <- \n# coll2_dag %>% \n#   ggdag() +\n#   theme_dag()\n# \n# p_coll_dag2\n```\n\nBei positiver `eignung` wird ein Studium aufgenommen (`studium = 1`) ansonsten nicht (`studium = 0)`. \n\n\n[Quelle](https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/)\n\n\n\n`eignung` (f√ºrs Studium) sei definiert als die Summe von `iq` und `fleiss`, plus etwas Gl√ºck:\n\n```{r d-eignung, echo = TRUE}\nset.seed(42)  # Reproduzierbarkeit\nN <- 1e03  \n\nd_eignung <-\ntibble(\n  iq = rnorm(N),  # normalverteilt mit MW=0, sd=1\n  fleiss = rnorm(N),\n  glueck = rnorm(N, mean = 0, sd = .1),\n  eignung = 1/2 * iq + 1/2 * fleiss + glueck,\n  # nur wer geeignet ist, studiert (in unserem Modell):\n  studium = ifelse(eignung > 0, 1, 0) \n  )\n```\n\nLaut unserem Modell setzt sich Eignung zur H√§lfte aus Intelligenz und zur H√§lfte aus Fleiss zusammen, plus etwas Gl√ºck.\n\n\n\n### Schlagzeile \"Schlauheit macht Studentis faul!\"\n\nEine Studie untersucht den Zusammenhang von Intelligenz (iq) und Flei√ü (f) bei Studentis (s).\n\nErgebnis: Ein *negativer* Zusammenhang!?\n\n\n\nBerechnen wir das \"Eignungsmodell\", aber nur mit Studis (`studium == 1)`, s. @tbl-m-eignung.\n\n```{r}\n#| tbl-cap: \"Zum Zusammenhang von Fleiss und Talent\"\n#| label: fig-m-eignung\nm_eignung <-\n  stan_glm(iq ~ fleiss, data = d_eignung %>%  filter(studium == 1), refresh = 0)\n\nhdi(m_eignung)\n```\n\n\n@fig-eignung zeigt das Modell und die Daten.\n\n```{r}\n#| echo: false\n#| label: fig-eignung\n#| fig-cap: \"Der Zusammenhang von Fleiss und IQ\"\n#| fig-asp: 0.5\nd_eignung %>% \n  filter(studium == 1) %>% \n  ggplot(aes(x = fleiss, y = iq)) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Nativer Zusammenhang von Fleiss und IQ bei Studentis\",\n       subtitle = \"Macht Fleiss bl√∂d?\")\n```\n\n\nIQ ist *nicht* unabh√§ngig von Flei√ü in unseren Daten, sondern abh√§ngig.\n\nNichtwissenschaftliche Berichte, etwa in einigen Medien,\ngreifen gerne Befunde √ºber Zusammenh√§nge auf und interpretieren die Zusammenh√§nge\n- oft vorschnell - als kausal.^[Ehrlicherweise muss man zugeben, dass auch wissenschaftliche Berichte Daten √ºber Zusammenh√§nge gerne kausal interpretieren, oft vorschnell.]\n\n\n\n\n\n### Kollisionsverzerrung nur bei Stratifizierung\n\nNur durch das Stratifizieren (Aufteilen in Subgruppen, Kontrollieren, Adjustieren) tritt die Scheinkorrelation auf, s. @fig-eignung-strat.\n\n\n:::callout-note\n*Ohne* Stratifizierung tritt *keine* Scheinkorrelation auf.\n*Mit* Stratifizierung tritt Scheinkorrelation auf.\n:::\n\n\n\n```{r}\n#| echo: false\n#| fig-cap: \"Stratifizierung und Scheinkorrelation\"\n#| label: fig-eignung-strat\np1 <- d_eignung %>% \n ggplot(aes(x = fleiss, y = iq)) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\")\n\np2 <- \nd_eignung %>% \n  mutate(studium = factor(studium)) %>% \n  ggplot(aes(x = fleiss, y = iq, color = studium)) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\")\n\n\nplots(p1, p2,\n      title = c(\"Kein Stratifizierung, keine Scheinkorrelation\",\n               \"Mit Stratifizierung gibt es Scheinkorrelation\"))\n```\n\n\n\n\nWildes Kontrollieren einer Variablen - Aufnehmen in die Regression - kann genausog ut schaden wie n√ºtzen.\n\n*Nur* Kenntnis des DAGs verr√§t die richtige Entscheidung: ob man eine Variable kontrolliert oder nicht.\n\n\n:::callout-note\nNimmt man eine Variable als zweiten Pr√§diktor auf,\nso \"kontrolliert\" man diese Variable. Das Regressiongewicht des ersten Pr√§diktors wird \"bereinigt\" um den Einfluss des zweiten Pr√§diktors; insofern ist der zweite Pr√§diktor dann \"kontrolliert\".\n:::\n\n\n\n\n### Einfluss von Gro√üeltern und Eltern auf Kinder\n\n\n\n\n\nWir wollen hier den (kausalen) Einfluss der Eltern `E` und Gro√üeltern `G` auf den *Bildungserfolg* der Kinder `K` untersuchen.\n\nWir nehmen folgende Effekte an:\n\n- indirekter Effekt von `G` auf `K`: $G \\rightarrow E \\rightarrow K$\n- direkter Effekt von `E` auf `K`: $E \\rightarrow K$\n- direkter Effekt von `G` auf `K`: $G \\rightarrow K$\n\n\nWir sind v.a. interessiert an $G \\rightarrow K$, dem *direkten kausalen* Effekt von Gro√üeltern auf ihre Enkel, s. @fig-dag-grannies, @kurz_statistical_2021.\n\n\n\n\n\n```{r}\n#| echo: false\n#| label: fig-dag-grannies\n#| fig-cap: \"Der kausale Effekt von Gro0eltern auf Enkel. Ein verlorener Fall, zumindest was den DAG betrifft\"\ndag_coords <-\n  tibble(name = c(\"G\", \"E\", \"K\"),\n         x    = c(1, 2, 2),\n         y    = c(2, 2, 1))\n\ndagify(E ~ G,\n       K ~ E + G,\n       coords = dag_coords) %>%\n  ggdag() +\n  theme_dag()\n```\n\n\nAber was ist, wenn wir vielleicht eine *u*nbekannte Variable √ºbersehen haben? (S. n√§chster Abschnitt). üëª\n\n\n\n\n\n\n## Vertiefung\n\nüèéÔ∏èVERTIEFUNG - nicht pr√ºfungsrelevantüèéÔ∏è\n\n\n### Der Gespenster-DAG\n\nüëª\n\nEs gibt \"unheilbare\" DAGs, nennen wir sie \"Gespenster-DAGs\",\nin denen es nicht m√∂glich ist, einen (unverzerrten) Kausaleffekt zu bestimmen,\ns. @fig-dag-ghost.\nLetztlich sagt uns der DAG bzw. unsere Analyse zum DAG:\n\"Deine Theorie ist nicht gut, zur√ºck an den Schreibtisch und denk noch mal gut nach. \nOder sammele mehr Daten.\"\n\n\n\n```{r}\n#| echo: false\n#| label: fig-dag-ghost\n#| fig-cap: \"Der Gespenster-DAG: Eine Identifikation der Kausaleffekt ist nicht (vollst√§ndig) m√∂glich.\"\n#| out-width: \"50%\"\n\n# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding\ngg_fancy_dag <- function(d, x = 1, y = 1, circle = \"U\") {\n  \n  d %>% \n    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n    geom_dag_point(aes(color = name == circle),\n                   alpha = 1/2, size = 6.5, show.legend = F) +\n    geom_point(x = x, y = y, \n               size = 6.5, shape = 1, stroke = 1, color = \"orange\") +\n    geom_dag_text(color = \"black\") +\n    geom_dag_edges() + \n    scale_color_manual(values = c(\"steelblue\", \"orange\")) +\n    theme_dag()\n}\n\ncoll4_dag <-\n  dagitty(\"dag\n          {\n          G -> E\n          E -> K\n          G -> K\n          U -> E\n          U -> K\n          }\n          \")\n\ndag_coords <-\n  tibble(name = c(\"G\", \"E\", \"K\", \"U\"),\n         x    = c(1, 2, 2, 2.5),\n         y    = c(2, 2, 1, 1.5))\n\ndagify(E ~ G + U,\n       K ~ E + G + U,\n       coords = dag_coords) %>% \n  gg_fancy_dag(x = 2.5, y = 1.5, circle = \"U\")\n```\n\n\n\n- `U` k√∂nnte ein ungemessener Einfluss sein, der auf `E` und `K` wirkt, etwa *Nachbarschaft*.\n\n- Die Gro√üeltern wohnen woanders (in Spanien), daher wirkt die Nachbarschaft der Eltern und Kinder nicht auf sie.\n\n- `E` ist sowohl f√ºr `G` als auch f√ºr `U` eine Wirkung, also eine Kollisionsvariable auf diesem Pfad.\n\n- Wenn wir `E` kontrollieren, wird es den Pfad $G \\rightarrow K$ verzerren, auch wenn wir niemals `U` messen.\n\n\nDie Sache ist in diesem Fall chancenlos. Wir m√ºssen diesen DAG verloren geben, @mcelreath_statistical_2020, S. 180.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Die Hintert√ºr schlie√üen\n\n\n\n### Zur Erinnerung: Konfundierung\n\n\n\n\n\n*Forschungsfrage*: Wie gro√ü ist der (kausale) Einfluss der Schlafzimmerzahl auf den Verkaufspreis des Hauses?\n\n`a:` livingArea, `b`: bedrooms, `p`: prize\n\nUV: `b`, AV: `p`\n\n\nDas Kausalmodell ist in @fig-dag-don1 dargestellt.\n\n```{r}\n#| echo: false\n#| label: fig-dag-don1\n#| fig-cap: \"Der Preis wird sowohl von der Zimmerzahl als auch der Wohnfl√§che beeinflusst\"\n#| out-width: \"50%\"\n\n\n# source: https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#confronting-confounding\n\n\ngg_simple_dag <- function(d) {\n  \n  d %>% \n    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n    geom_dag_point(color = \"steelblue\", alpha = 1/2, size = 6.5) +\n    geom_dag_text(color = \"black\") +\n    geom_dag_edges() + \n    theme_dag()\n}\n\ndag_coords <-\n  tibble(name = c(\"a\", \"b\", \"p\"),\n         x    = c(0, -1, 1),\n         y    = c(1, 0, 0))\n\ndagify(p ~ a + b,\n       b ~ a,\n       coords = dag_coords) %>%\n  gg_simple_dag()\n```\n\n\n\n Im Regressionsmodell `p ~ b` wird der kausale Effekt verzerrt sein durch die Konfundierung mit `a`.\n Der Grund f√ºr die Konfundierung sind die zwei Pfade zwischen `b` und `p`:\n \n1. $b \\rightarrow p$\n2. $b \\rightarrow a \\rightarrow p$\n\nBeide Pfade erzeugen (statistische) Assoziation zwischen `b` und `p`.\nAber nur der erste Pfad ist kausal; der zweite ist nichtkausal.\nG√§be es nur nur den zweiten Pfad und wir w√ºrden `b` √§ndern, so w√ºrde sich `p` nicht √§ndern.\n\n\n\n### Gute Experimente zeigen den echten kausalen Effekt\n\n@fig-dag-tuer-zu zeigt eine erfreuliche Situation:\nDie \"Hintert√ºr\" zu unserer UV (Zimmerzahl) ist geschlossen!\n\nIst die Hintert√ºr geschlossen - f√ºhren also keine Pfeile in unserer UV -\nso kann eine Konfundierung ausgeschlossen werden.\n\n```{r}\n#| echo: false\n#| label: fig-dag-tuer-zu\n#| fig-cap: \"Unverzerrte Sch√§tzung des kausalen Effekts unserer UV (Zimmerzahl). Das Regressionsgewicht ist hier der unverzerrte Kausaleffekt. Es spielt keine Rolle, ob der andere Pr√§diktor im Modell enthalten ist. Da die beiden Pr√§diktoren unkorreliert sind, hat die Aufnahme des einen Pr√§diktors keinen Einfluss auf das Regressionsgewicht des anderen.\"\n#| out-width: \"50%\"\ndag_coords <-\n  tibble(name = c(\"a\", \"b\", \"p\"),\n         x    = c(0, -1, 1),\n         y    = c(1, 0, 0))\n\ndagify(p ~ a + b,\n       coords = dag_coords) %>%\n  gg_simple_dag()\n```\n\nDie \"Hintert√ºr\" der UV (`b`) ist jetzt zu!\nDer einzig verbleibende, erste Pfad ist der kausale Pfad und die Assoziation zwischen `b` und `p` ist jetzt komplett kausal.\n\n\nEine ber√ºhmte L√∂sung, den kausalen Pfad zu isolieren, ist ein (randomsiertes, kontrolliertes) Experiment.\nWenn wir den H√§usern zuf√§llig (randomisiert) eine Anzahl von Schlafzimmern (`b`) zuweisen k√∂nnten (unabh√§ngig von ihrer Quadratmeterzahl, `a`), w√ºrde sich der Graph so √§ndern.\nDas Experiment *entfernt* den Einfluss von `a` auf `b`.\nWenn wir selber die Werte von `b` einstellen im Rahmen des Experiments, so kann `a` keine Wirkung auf `b` haben.\nDamit wird der zweite Pfad, $b \\rightarrow a \\rightarrow p$ geschlossen (\"blockiert\").\n\n\n\n\n### Hintert√ºr schlie√üen auch ohne Experimente\n\nKonfundierende Pfade zu blockieren zwischen der UV und der AV nennt man auch *die Hintert√ºr schlie√üen* (backdoor criterion).\n\nWir wollen die Hintert√ºre schlie√üen, da wir sonst nicht den wahren, kausalen Effekt bestimmen k√∂nnen.\n\nZum Gl√ºck gibt es neben Experimenten noch andere Wege, die Hintert√ºr zu schlie√üen, wie die Konfundierungsvariable `a` in eine Regression mit aufzunehmen.\n\nWarum blockt das Kontrollieren von `a`den Pfad $b \\leftarrow a \\rightarrow p$?\nStellen Sie sich den Pfad als eigenen Modell vor.\nSobald Sie `a` kennen, bringt Ihnen Kenntnis √ºber `b` kein zus√§tzliches Wissen √ºber `p`.\nWissen Sie hingegen nichts √ºber `a`, lernen Sie bei Kenntnis von `b` auch etwas √ºber `p`.\nKonditionieren ist wie \"gegeben, dass Sie `a` schon kennen...\".\n\n$b \\indep p \\,|\\,a$\n\n\n\n### Die vier Atome der Kausalanalyse\n\n\n@fig-four-atoms stellt die vier \"Atome\" der Kausalinferenz dar.\nMehr gibt es nicht!\nKennen Sie diese vier Grundbausteine,\nso k√∂nnen Sie jedes beliebige Kausalsystem (DAG) entschl√ºsseln.\n\n\n\n\n```{r}\n#| echo: false\np_conf <- confounder_triangle(x = NULL, y = NULL, z = NULL, x_y_associated = FALSE) %>% \n  gg_simple_dag() +\n  labs(title = \"Die Konfundierung\")\n```\n\n```{r}\n#| echo: false\np_med <- \n  mediation_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% \n  gg_simple_dag() +\n  labs(title = \"Die Mediation\")\n```\n\n\n```{r}\n#| echo: false\np_coll <- collider_triangle(x = NULL, y = NULL, m = NULL, x_y_associated = FALSE) %>% \n  gg_simple_dag() +\n  labs(title = \"Die Kollision\")\n```\n\n\n\n```{r}\n#| echo: false\ndag_desc <- \n  dagitty('\n          dag{\n          \n          m [pos=\"1.000,0.000\"]\n          x [exposure,pos=\"0.000,1.000\"]\n          y [outcome,pos=\"2.000,1.000\"]\n          d [pos=\"1,1\"]\n\n          x -> m\n          y -> m\n          m -> d\n          }')\n\np_desc <-\n  dag_desc %>%\n  gg_simple_dag() +\n  labs(title =\"Der Nachfahre\")\n```\n\n\n\n\n\n```{r}\n#| echo: false\n#| label: fig-four-atoms\n#| fig-cap: Die vier Atome der Kausalinferenz\n#| fig-width: 9\nplots(p_conf, p_med, p_coll, p_desc, n_rows = 2)\n```\n\n\n\n\n\n### Mediation\n\nDie *Mediation* (Wirkkette, Rohr, Kette, chain) beschreibt Pfade, in der die Kanten gleiche Wirkrichtung haben: $x \\rightarrow m \\rightarrow y$. \nAnders gesagt: Eine Mediation, auch \"Kette\" oder \"Wirkkette\" genannt, ist eine Kausalabfolge der Art $x \\rightarrow m \\rightarrow y$, s. @fig-med1.\nDie Variable in der Mitte $m$ der Kette wird auch *Mediator* genannt,\nweil sei die Wirkung von X auf Y \"vermittelt\" oder √ºbetr√§gt.\nDie Erforschung von Mediation spielt eine recht wichtige Rolle in einigen Wissenschaften,\nwie der Psychologie.\n\n```{r}\n#| echo: false\n#| label: fig-med1\n#| fig-cap: Das Kausalmodell der Mediation.\np_med\n```\n\n\n\n\nOhne Kontrollieren ist der Pfad offen: Die Assoziation \"flie√üt\" den Pfad entlang (in beide Richtungen).\nKontrollieren blockt (schlie√üt) die Kette (genau wie bei der Gabel).\n\n\n## Der Nachfahre\n\n\n\nEin *Nachfahre* (descendent) ist eine Variable die von einer anderen Variable beeinflusst wird, s. fig-dag-nachfahre.\nKontrolliert man einen Nachfahren `d`, so kontrolliert man damit zum Teil den Vorfahren (die Ursache), `m`.\nDer Grund ist, dass `d` Information beinhaltet √ºber `m`.\nHier wird das Kontrollieren von `d` den Pfad von `x` nach `y` teilweise √∂ffnen, da `m` eine Kollisionsvariable ist.\n\n\n\n```{r}\n#| echo: false\n#| label: fig-dag-nachfahre\n#| fig-cap: \"Ein Nachfahre verh√§lt sich √§hnlich wie sein Vorfahre...\"\n#| out-width: \"50%\"\np_desc\n```\n\n\n\n### Kochrezept zur Analyse von DAGs\n\nWie kompliziert ein DAG auch aussehen mag, er ist immer aus diesen vier Atomen aufgebaut.\n\nHier ist ein Rezept, das garantiert, dass Sie welche Variablen Sie kontrollieren sollten und welche nicht:\n\n1. Listen Sie alle Pfade von UV (`X`) zu AV (`Y`) auf.\n2. Beurteilen Sie jeden Pfad, ob er gerade geschlossen oder ge√∂ffnet ist.\n3. Beurteilen Sie f√ºr jeden Pfad, ob er ein Hintert√ºrpfad ist (Hintert√ºrpfade haben einen Pfeil, der zur UV f√ºhrt).\n4. Wenn es ge√∂ffnete Hinterpfade gibt, pr√ºfen Sie, welche Variablen mann kontrollieren muss, um den Pfad zu schlie√üen (falls m√∂glich).\n\n\n\n\n## Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, `bsp1`\n\nUV: $X$, AV: $Y$, drei Covariaten (A, B, C) und ein ungemessene Variable, U\n\n\n\n\n\n```{r gg-fancey-dag, out.width=\"50%\"}\n#| echo: false\n#| label: fig-dag-fancy\n#| fig-cap: \"Puh, ein schon recht komplizierter DAG\"\ndag_coords <-\n  tibble(name = c(\"A\", \"B\", \"C\", \"U\", \"X\", \"Y\"),\n         x    = c(2, 2, 3, 1, 1, 3),\n         y    = c(4, 2, 3, 3, 1, 1))\n\ndagify(B ~ C + U,\n       C ~ A,\n       U ~ A,\n       X ~ U,\n       Y ~ C + X,\n       coords = dag_coords) %>%\n  gg_fancy_dag(x = 1, y = 3, circle = \"U\")\n```\n\n\n\nEs gibt zwei Hintert√ºrpfade in @fig-dag-fancy:\n\n1. $X \\leftarrow U \\leftarrow A \\rightarrow C \\rightarrow Y$, offen\n2. $X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y$, geschlossen\n\nKontrollieren von $A$ oder (auch) $C$ schlie√üt die offene Hintert√ºr.\n\n\n\n@mcelreath_statistical_2020, @kurz_statistical_2021, s.S. 186.\n\n\n\n\n\n### Schlie√üen Sie die Hintert√ºr (wenn m√∂glich)!, `bsp2`\n\nS. DAG in @fig-dag-bsp2: UV: $W$, AV: $D$\n\n```{r bsp2}\n#| echo: false\n#| label: fig-dag-bsp2\n#| fig-asp: 0.5\n#| fig-cap: \"Welche Variablen muss man kontrollieren, um den Effekt von W auf D zu bestimmen?\"\ndag_coords <-\n  tibble(name = c(\"A\", \"D\", \"M\", \"S\", \"W\"),\n         x    = c(1, 3, 2, 1, 3),\n         y    = c(1, 1, 2, 3, 3))\n\ndagify(A ~ S,\n       D ~ A + M + W,\n       M ~ A + S,\n       W ~ S,\n       coords = dag_coords) %>%\n  gg_simple_dag()\n```\n\n\n\nKontrollieren Sie diese Variablen, um die offenen Hintert√ºren zu schlie√üen:\n\n- entweder $A$ und $M$\n- oder $S$\n\n[Mehr Infos](https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html#backdoor-waffles.)\n\n\n\nDetails finden sich bei @mcelreath_statistical_2020 oder @kurz_statistical_2021, ‚ÄöS. 188.\n\n\n\n### Implizierte bedingte Unabh√§ngigkeiten von `bsp2`\n\nEin Graph ohne `U`s ist eine starke - oft zu starke (unrealistisch optimistische) - Annahme.\nAuch wenn die Daten nicht sagen k√∂nnen, welcher DAG der richtige ist, k√∂nnen wir zumindest lernen, welcher DAG falsch ist.\nDie vom Modell implizierten bedingten Unabh√§ngigkeiten geben uns M√∂glichkeiten, zu pr√ºfen, ob wir einen DAG verwerfen (ausschlie√üen) k√∂nnen.\nBedingten Unabh√§ngigkeit zwischen zwei Variablen sind Variablen, die nicht assoziiert (also stochastisch unabh√§ngig) sind, wenn wir eine bestimmte Menge an Drittvariablen kontrollieren.\n\n`bsp2` impliziert folgende bedingte Unabh√§ngigkeiten:\n\n```{r bsp2-cond-independence}\n#| echo: false\ndag_6.2 <- \n  dagitty(\n    \"dag {\n    A -> D\n    A -> M -> D\n    A <- S -> M\n    S -> W -> D\n    }\"\n  )\n\nimpliedConditionalIndependencies(dag_6.2)\n```\n\n\n\n## Fazit\n\nWie (und sogar ob) Sie statistische Ergebnisse (z.B. eines Regressionsmodells) interpretieren k√∂nnen, h√§ngt von der *epistemologischen Zielrichtung* der Forschungsfrage ab:\n\n- Bei *deskriptiven* Forschungsfragen k√∂nnen die Ergebnisse (z.B. Regressionskoeffizienten) direkt interpretiert werden. Z.B. \"Der Unterschied zwischen beiden Gruppen betr√§gt etwa ...\". Allerdings ist eine kausale Interpretation nicht zul√§ssig.\n- Bei *prognostischen* Fragestellungen (Vorhersagen) spielen die Modellkoeffizienten keine Rolle, stattdessen geht es um vorhergesagten Werte, $\\hat{y}_i$, z.B. auf Basis der PPV. Kausalaussagen sind zwar nicht m√∂glich, aber auch nicht von Interesse.\n- Bei *kausalen* Forschungsfragen d√ºrfen die Modellkoeffizienten nur auf Basis eines Kausalmodells (DAG) oder eines (gut gemachten) Experiments interpretiert werden.\n    \nModellkoeffizienten √§ndern sich (oft), wenn man Pr√§diktoren zum Modell hinzuf√ºgt oder wegnimmt.\nEntgegen der verbreiteten Annahme ist es falsch, m√∂glichst viele Pr√§diktoren in das Modell aufzunehmen, wenn das Ziel eine Kausalaussage ist.\nKenntnis der \"kausalen Atome\" ist Voraussetzung zur Ableitung von Kausalschl√ºsse in Beobachtungsstudien.\n\n\n\n## Aufgaben\n\n\n- [Sammlung \"kausal\"](https://datenwerk.netlify.app/#category=causal)\n\n\n\n\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":true,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"kausal.html"},"language":{},"metadata":{"lang":"de","fig-responsive":true,"quarto-version":"1.2.269","bibliography":["references.bib"],"editor":"source","knitr":{"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":true,"keep-source":false,"keep-hidden":false,"prefer-html":true,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"number-sections":true,"output-file":"kausal.pdf"},"language":{},"metadata":{"block-headings":true,"lang":"de","bibliography":["references.bib"],"editor":"source","knitr":{"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"colorlinks":true,"papersize":"a4"},"extensions":{"book":{}}}}}