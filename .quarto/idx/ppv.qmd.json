{"title":"Vorhersage-Verteilung","markdown":{"headingText":"Vorhersage-Verteilung","containsRefs":false,"markdown":"\n\n\n\n![Bayes:Start!](img/Golem_hex.png){width=5%}\n\n```{r}\n#| include: false\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(easystats)\n```\n\n\n\n\n```{r QM2-Thema2-kleineModelle-28}\n#| echo: false\nn <- 10\nn_success <- 6\nn_trials  <- 9\n\nd <-\n  tibble(p_grid = seq(from = 0, to = 1, length.out = n),\n         prior  = 1) %>% \n  mutate(likelihood = dbinom(n_success, \n                             size = n_trials, \n                             prob = p_grid)) %>% \n  mutate(unstand_post = (likelihood * prior),\n         post = unstand_post / sum(unstand_post))\n\nsamples <-\n  d %>%  # nimmt die Tabelle mit Posteriori-Daten,\n  slice_sample(  # Ziehe daraus eine Stichprobe,\n    n = 1e4,  # mit insgesamt n=10000 Elementen,\n    weight_by = post,  # Gewichte nach Spalte mit Post-Wskt.,\n    replace = T)  # Ziehe mit Zurücklegen\n\n```\n\n\n\n\n## Der zwielichte Dozent: Stichproben-Vert. vs. Post-Vert.\n\nIn einer dunklen Gasse fordert Sie ein Statistik-Dozent zu einem Glücksspiel heraus: Münzwurf; wenn er gewinnt, müssen Sie 10 Euro zahlen. Gewinnen Sie, bekommen Sie 11 Euro. Klingt nach einer guten Partie, nicht war? Natürlich nehmen Sie sofort an. \n\nSie spielen also Münzwurf; der Dozent setzt auf Zahl. Sie spielen 10 Runden. Leider gewinnt der Dozent 9 von 10 Mal^[was er mit lautem Gelächter quittiert].\n\nWütend (und mit leeren Taschen) ziehen Sie von dannen.\n\n\nDaten: 9 von 10 Treffern beim Münzwurf. Ist die Münze fair?\n\n\n```{r QM2-Thema3-Post-befragen-21}\ntibble(\n  Trefferzahl = rbinom(n = 1e4, size = 10, prob = 1/2)\n) %>% \n  mutate(signifikant = ifelse(Trefferzahl %in% c(9,10), TRUE, FALSE)) %>% \n  ggplot() +\n  aes(x = Trefferzahl, fill = signifikant) +\n  geom_bar() +\n  scale_x_continuous(breaks = 0:10) +\n  theme(legend.position = c(0.1, 0.8)) +\n  geom_vline(xintercept = 9) +\n  labs(title = \"Stichprobenverteilung für p=0.5\")\n```\n\nDie *Stichprobenverteilung* zeigt, wie Wahrscheinlich der empirischen Daten $D$ (z.B. 9 von 10 Treffer) ist *gegeben* eines Parameterwerts $p$ (z.B. $p=0.5$): $Pr(D|p)$.\n\n\n\n\n```{r zwielicht-daten}\n#| echo: false\nd_zwielicht <-\n  tibble(\n    p_grid = seq( from=0 , to=1 , length.out=100),\n    prior = 1,  # Priori-Gewichte\n    likelihood = dbinom(8, size = 10, prob=p_grid) ,\n    unstandardisierte_posterior = likelihood * prior ,\n    posterior = unstandardisierte_posterior / sum(unstandardisierte_posterior))\n\n# Stichproben ziehen aus der Posteriori-Verteilung:\nsamples_zwielicht <- \n  tibble(\n    gewinnchance_muenze = sample(\n      d_zwielicht$p_grid , \n      prob=d_zwielicht$posterior, \n      size=1e4, \n      replace=TRUE)) %>% \n  mutate(\n    id = row_number())\n```\n\n```{r QM2-Thema3-Post-befragen-22}\n#| echo: false\nsamples_zwielicht %>% \n  ggplot() +\n  aes(x = gewinnchance_muenze) +\n  geom_histogram(fill = \"grey60\", bins = 30) +\n  geom_vline(xintercept = 0.9) +\n  #geom_label(x = 0.8, y= 0, label = \"Emp. Ergebnis\") +\n  labs(title = \"Posteriori-Verteilung\",\n       subtitle = \"Vertikale Linie: Emp. Ergebnis (9/10 Treffer)\",\n       x = \"Gewinnchance der Münze (50%: faire Münze)\")\n```\n\nDie *Posteriori-Verteilung* gibt die Wahrscheinlichkeit jedes Parameterwerts $p$ wider, gegeben der empirischen Daten $D$: $Pr(p|D)$. \n\n\nDie meisten Forschungsfragen lassen sich mit der Post-Verteilung beantworten, nicht mit der Stichprobenverteilung.\n\n\n\n## Mit Stichproben neue Beobachtungen simulieren\n\n\n### Wir simulieren die Wasserzahl bei Globuswürfen\n\nLikelihood (L): Wahrscheinlichkeit für $w=0,1,2$ bei $N=2$ und $p = 0.7$:\n\n```{r QM2-Thema3-Post-befragen-23}\nL <- dbinom(0:2, size = 2, prob = 0.7)\nL\n```\n\n\nWir simulieren $n=1$ neuen Globusversuch mit $N=2, p=0.7$ und zählen die (Wasser-)Treffer:\n\n```{r QM2-Thema3-Post-befragen-25}\nset.seed(42)  # Zufallszahlen festlegen\nrbinom(n = 1, size = 2, prob = .7)  # 0 Treffer (Wasser)\n```\n\nWarum nicht $n=10$ neue Globusversuche simulieren:\n\n```{r QM2-Thema3-Post-befragen-27, echo = TRUE}\nrbinom(n = 10, size = 2, prob = 0.7)\n```\n\n\nDiese Versuche geben Aufschluss, welche Daten (wie oft Wasser) man bei einem bestimmten Modell, $p,N$, erwarten kann. \n\n\n\n\n### Traue niemals einem Golem (einem Modell)\n\n\n\n\n\n![Never trust a Golem](https://i.imgflip.com/5qmhmo.jpg){width=25%}\n\n\nQuelle: https://imgflip.com/i/5qmhmo\n\n\n\nImmer prüfen und wachsam bleiben:\n\n- (Inwieweit) decken sich die simulierten Daten mit den tatsächlichen Beobachtungen?\n- Wie realistisch sind die Modellannahmen?\n- Kann man das Modell aus verschiedenen Perspektiven prüfen?\n\n\n\n## Mit guten Simulationen kommt man den wahren Werten nahe\n\n\nWarum nicht $n=10^6$ neue Globusversuche simulieren:\n\n```{r QM2-Thema3-Post-befragen-28, echo = TRUE}\ndraws <- \n  tibble(\n    draws = rbinom(1e6, size = 2, prob = .7))\n\ndraws %>% \n  count(draws) %>% \n  mutate(proportion = \n           n / nrow(d))\n```\n\nDiese simulierten Häufigkeiten sind sehr ähnlich zu den theoretisch bestimmten Häufigkeiten mit `dbinom`: Unser Modell liefert plausible Vorhersagen.\n\n```{r QM2-Thema3-Post-befragen-29, echo = TRUE}\ndbinom(0:2, size = 2, prob = .7)\n```\n\n\n## Stichprobenverteilung\n\nWir ziehen viele ($n=10^6$) Stichproben für den Versuch $N=9$ Globuswürfe mit $p=0.7$. \n\nWie viele Wasser (W) erhalten wir wohl typischerweise?\n\n\n```{r QM2-Thema3-Post-befragen-30, echo = TRUE, results = \"hide\", eval = FALSE}\nn_draws <- 1e6\n\ndraws <- \n  tibble(draws = rbinom(n_draws, size = 9, prob = .7))\n\nplot1 <- \n  draws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram() \n```\n\n\n\n```{r QM2-Thema3-Post-befragen-31}\nn_draws <- 1e6\ndraws <- tibble(draws = rbinom(n_draws, \n                               size = 9, \n                               prob = .7))\n\n# the histogram\ndraws %>% \n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", size = 1/10) +\n  scale_x_continuous(\"Anzahl Wasser (W) pro Versuch\",\n                     breaks = seq(from = 0, to = 9, by = 2)) +\n  scale_y_continuous(\"Häufigkeit\",\n                     labels = scales::scientific) +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"Stichprobenverteilung für n=9 und p=.7 (binomial verteilt)\")\n```\n\nDie *Stichprobenverteilung* zeigt, welche Stichprobendaten laut unserem Modell (einem bestimmten Parameterwert) zu erwarten sind. Wir können jetzt prüfen, ob die echten Daten zu den Vorhersagen des Modells passen.\n\n\n\n### Visualisierung der PPV\n\n```{r QM2-Thema3-Post-befragen-36}\n#| echo: false\nknitr::include_graphics(\"https://github.com/sebastiansauer/QM2-Folien/raw/main/img/ppv.png\")\n```\n\nQuelle: @mcelreath_statistical_2020\n\n\n\n## So viele Verteilungen... \n\n\n\n\n- Die *Posteriori-Verteilung* gibt Aufschluss zur Häufigkeit (Wahrscheinlichkeit) von Parameterwerten:\n    - Wie wahrscheinlich ist es, dass \"in Wirklichkeit\" der Wasseranteil 70% beträgt, also $\\pi=.7$\n    - In der Wissenschaft ist man meist an den Parametern interessiert.\n    \n- Die *PPV* gibt Aufschluss zur Häufigkeit von neuen Beobachtungen:\n    - Welche Beobachtungen (wie viele Wasser/Treffer) sind in Zukunft, bei erneuter Durchführung, zu erwarten.\n    - Für die Praxis kann das eine interessante Frage sein.\n    \n- Der *Likelihood* gibt Aufschluss, wie gut eine bestimmte Hypothese die Datenlage erklärt.\n    - Wie gut passt die Hypothese $\\pi=0.7$ auf die Datenlage 6 von 9 Treffern beim Globusversuch?\n    - Der Likelihood kann aus der Stichprobenverteilung herausgelesen werden. \n\n```{r QM2-Thema3-Post-befragen-33}\n#| echo: false\nn_draws <- 1e5\n\nsimulate_binom <- function(probability) {\n  set.seed(3)\n  rbinom(n_draws, size = 9, prob = probability) \n}\n\nd_small <-\n  tibble(probability = seq(from = .1, to = .9, by = .1)) %>% \n  mutate(draws = purrr::map(probability, simulate_binom)) %>% \n  unnest(draws) %>% \n  mutate(label = str_c(\"p = \", probability))\n```\n\n```{r PP2}\nppv2_plot <- \nd_small %>%\n  ggplot(aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"grey92\", linewidth = 1/10) +\n  scale_x_continuous(\"Wasser\", breaks = seq(from = 0, to = 9, by = 3)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(subtitle = \"Stichprobenverteilungen\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ label, ncol = 9) \n```\n\n\n## PPV berechnen\n\nFür einen bestimmten Parameterwert sind verschiedene Stichprobenwerte möglich.\nDas Spektrum dieser Möglichkeiten ist in einer Stichprobenverteilung (gegeben eines bestimmten Parameterwerts) dargestellt.\n\n\n\n```{r pp-plot1, echo = TRUE, eval = TRUE}\nppv <- \n  rbinom(1e4, \n         size = 9, \n         prob = samples$p_grid) %>% \n  as_tibble()\n\nppv_plot2 <-\n  ppv %>% \n  ggplot() +\n  aes(x = value) +\n  geom_bar() +\n  scale_x_continuous(\n    breaks = 0:9)\n```\n\n\n\n```{r QM2-Thema3-Teil2-2, fig.width = 4, fig.asp = 1}\nppv_plot2\n```\n\n\n\n\n\n\n\n- Die PPV unseres Modells zeigt uns, dass wir in künftigen Versuchen zumeist 6 Treffer zu erwarten haben. \n- Aber ein relativer breiter Bereich an Treffern ist ebenfalls gut laut unserer PPV erwartbar.\n\n\n## Vorhersagen sind schwierig\n\n\n... gerade wenn sie die Zukunft betreffen, so ein Sprichtwort.\n\nDas zeigt uns die PPV: Der PPV unseres Modells gelingt es zwar, der theoretisch wahrscheinlichste Parameterwert ist auch der häufigste in unseren Stichproben, aber die Vorhersagen haben eine große Streuung, birgt also hohe Ungewissheit.\n\nDie PPV zeigt also, welche Beobachtungen laut unserem Modell künftig zu erwarten sind.\n\n```{r QM2-Thema3-Post-befragen-37}\n#| echo: false\nppv_plot2\n```\n\nWürde man die Vorhersagen nur anhand eines bestimmten Parameterwertes (z.B $p=0.6$) vornehmen, hätten die Vorhersagen zu wenig Streuung, würden also die Ungewissheit nicht ausreichend abbilden (Übergewissheit, Overconfidence).\n\n\n\n\n\n\n## Zwei Arten von Ungewissheit in Vorhersagen von Modellen\n\n\n1. *Ungewissheit innerhalb des Modells*: Auch wenn der (oder die) Modellparameter eines Modells mit Sicherheit bekannt sind, so bleibt Unsicherheit, welche Beobachtung eintreten wird: Auch wenn man sicher weiß, dass $p=1/4$ Murmeln blau sind, so kann man nicht sicher sagen, welche Farbe die nächste Murmel haben wird (Ausnahme: $p=1$ oder $p=0$).\n\n2. *Ungewissheit in den Modellparametern*: Wir sind uns nicht sicher, welchen Wert $p$ (bzw. die Modellparameter) haben. Diese Unsicherheit ist in der Post-Verteilung dargestellt. \n\nUm zu realistischen Vorhersagen zu kommen, möchte man beide Arten von Ungewissheit berücksichtigen: Das macht die *Posteriori-Prädiktiv-Verteilung (PPV)*.\n\n\n\nDie PPV zeigt, welche Daten das Modell vorhersagt (prädiktiv) und mit welcher Häufigkeit, basierend auf der Post-Verteilung.\n\n\n\n## Vergleich der Verteilungen\n\n\n\n\n```{r QM2-Thema3-Post-befragen-38}\n#| echo: false\nimg_file <- paste0(\"https://github.com/sebastiansauer/QM2-Folien/raw/main/img/post-pred-ppv-anim.gif\")\nknitr::include_graphics(img_file)\n```\n\n\n- Links - *Posterior-Verteilung*: Wahrscheinlichkeiten der Parameterwerte\n- Mitte - *Stichprobenverteilung*: Wahrscheinlichkeiten der Beobachtungen gegeben eines bestimmten Parameterwertes\n- Rechts - *Posterior-Prädiktiv-Verteilung*: Wahrscheinlichkeiten der Beobachtungen unter Berücksichtigung der Unsicherheit der Posteriori-Verteilung\n\n[Bild](https://sebastiansauer.github.io/QM2-Folien/Themen/QM2-Thema3-Post-befragen.html#1)\n\n[Quelle: R. McElreath](https://twitter.com/rlmcelreath/status/1448978045247893505)\n\n\n\n\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":true,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"ppv.html"},"language":{},"metadata":{"lang":"de","fig-responsive":true,"quarto-version":"1.1.168","bibliography":["references.bib"],"knitr":{"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}}}