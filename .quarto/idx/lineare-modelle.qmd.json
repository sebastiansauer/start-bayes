{"title":"Lineare Modelle","markdown":{"headingText":"Lineare Modelle","containsRefs":false,"markdown":"\n\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\n\n```{r}\n#| message: false\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n```\n\n\n```{r libs-hidden}\n#| include: false\nlibrary(\"latex2exp\")\nlibrary(\"patchwork\")\nlibrary(\"gt\")\n\ntheme_set(theme_modern())\n```\n\n\n\n## Post-Verteilung der Regression\n\n\n### Einfache Regression\n\n\n\nDie (einfache) Regression prüft, inwieweit zwei Variablen, $Y$ und $X$ linear zusammenhängen.\nJe mehr sie zusammenhängen, desto besser kann man $X$ nutzen, um $Y$ vorherzusagen (und umgekehrt).\nHängen $X$ und $Y$ zusammen, heißt das nicht (unbedingt), dass es einen *kausalen* Zusammenhang zwischen $X$ und $Y$ gibt.\nLinear bedeutet, der Zusammenhang ist additiv und konstant: wenn $X$ um eine Einheit steigt, steigt $Y$ immer um $b$ Einheiten (nicht kausal, sondern deskriptiv gemeint).\n\n[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv), @mcelreath_statistical_2020.\n\nLaden wir die Daten und visualisieren wir uns den Zusammenhang.\n\n\n```{r Post-Regression-2}\n#| fig-asp: 0.5\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd <- read_csv(Kung_path)  \n\nd2 <- \n  d %>% \n  filter(age > 18) \n\nd2 %>% \n  #select(weight, height) %>% \n  #drop_na() %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n```\n\n\n\n\n\n### Bei jedem Prädiktorwert eine Post-Verteilung für $\\mu$\n\n\nUnser Modell erlaubt uns für jeden beliebigen Wert des Prädiktors eine Post-Verteilung (von $mu$) zu berechnen.\n\nHier am Beispiel von `m42`: \n\n```{r m42-read-from-disk, echo = FALSE}\n#| echo: false\n#| output: \"hide\"\nm42 <- read_rds(paste0(here::here(),\"/objects/m42.rds\"))\n\nm42_post <- as_tibble(m42)\nnames(m42_post) <- c(\"mu\", \"sigma\")\n```\n\n\n\n\n```{r Post-Regression-10}\n#| echo: false\nplot_post_42 <- \n  m42_post %>% \n  ggplot() +\n  aes(x = mu) +\n  geom_density(fill = \"grey60\") +\n  labs(x = expression(mu),\n       title = TeX(\"Posteriori-Verteilung für $\\\\mu$, m42\")) +\n  scale_y_continuous(breaks = NULL)\n```\n\n\n```{r Post-Regression-11}\n#| echo: false\nlm1 <- lm(height ~ weight, data = d2)\n\nd_pred <-\n  tibble(weight = c(40, 45, 50, 55),\n         height = predict(lm1, newdata = data.frame(weight)))\n\nplot_condition <- \n  d2 %>% \n  #select(weight, height) %>% \n  #drop_na() %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\") +\n  geom_point(data = d_pred, color = \"red\", size = 5, alpha = .5) +\n  scale_x_continuous(limits = c(0, 70))\n```\n\n```{r m3}\n#| echo: false\n#| results: \"hide\"\n\nd2 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n\nm43 <- \n  stan_glm(height ~ weight_c, \n           prior = normal(0, 10),\n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\n\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE, \n           prior_PD = TRUE,\n           data = d2)\n\nstan_glm(height ~ weight_c, \n           prior = normal(0, 10),\n           prior_intercept = normal(0, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\n\nm43a_prior_pred <-\n    stan_glm(height ~ weight_c, \n           prior_intercept = normal(0, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE, \n           prior_PD = TRUE,\n           data = d2)\n```\n\n\n\n\n\n\n```{r eval = FALSE}\n#| eval: false\n#| echo: false\nprint(m43)\nsummary(m43_prior_pred)\nwrite_rds(m43, \"objects/m43.rds\")\nwrite_rds(m43a, \"objects/m43a.rds\")\n```\n\n\n\n\n```{r m43-plot}\n#| echo: false\nnd <- tibble(\n  weight_c = c(-5, 0, +5, 10)\n)\n\nppv_m43 <- \n  posterior_predict(m43, , newdata = nd) %>% \n  as_tibble() %>% \n  pivot_longer(everything(), \n               names_to = \"weight_condition\",\n               values_to = \"h\")\n\n\n\nppv_m43_summary <-\n  ppv_m43 %>% \n  group_by(weight_condition) %>% \n  summarise(m = mean(h),\n            s = sd(h))\n\n\npost_at_plot <-\n  ppv_m43 %>% \n  ggplot() +\n  aes(x = h) +\n  geom_density(fill = \"grey60\") +\n  facet_wrap(~ weight_condition, nrow = 1, scales = \"free\") +\n  scale_y_continuous(breaks = NULL) +\n  labs(title = \"Post-Verteilungen an verschiedenen Werten von X\",\n       caption = \"MW±2sd\",\n       x = \"Größe\",\n       y = \"Post-Wskt\") +\n  geom_point(data = ppv_m43_summary,\n             aes(x = m,\n                 y = 0),\n             size = 2, color = \"blue\", alpha = .5) +\n  geom_segment(data = ppv_m43_summary,\n               aes(x = m-2*s,\n                   xend = m+2*s),\n               y = 0,\n               yend = 0,\n               color = \"blue\",\n               alpha = .5,\n               size = 2) \n```\n\n\n\n```{r Post-Regression-12, out.width=\"100%\", fig.width=7}\n#| echo: false\np1 <- (plot_condition) / post_at_plot\np1\n```\n\n\n\n\n\n### Statistiken zum !Kung-Datensatz\n\n[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv)\n\n\nHier sind die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n```{r Post-Regression-3}\n#| echo: true\n#| eval: false\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd <- read_csv(Kung_path)  \n\nd2 <- d %>% filter(age > 18)\n\ndescribe_distribution(d2)\n```\n\n\n\n```{r Post-Regression-4, echo = FALSE, eval = TRUE}\n#| echo: false\nlibrary(rstatix)\n\nget_summary_stats(d2) %>% \n  gt() %>% \n  fmt_number(columns = 2:13, decimals = 1)\n```\n\n\nDas mittlere Körpergewicht (`weight`) liegt bei ca. 45kg (sd 7 kg).\n\n\n### Etwas mehr EDA\n\n\n\n\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket `DataExplorer` hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\n```{r}\n#| message: false\nlibrary(DataExplorer)\n```\n\n#### Gibt es fehlende Werte?\n\nNein, s. Abb. @fig-na.\n\n```{r}\n#| fig-cap: Fehlende Werte - fehlen.\n#| label: fig-na\nd2 %>% plot_missing()\n```\n\n#### Verteilung der numerischen Variablen\n\n```{r}\nd2 %>% plot_histogram()\n```\n\n\n\n#### Verteilung der kategorialen Variablen\n\n\n```{r}\nd2 %>% plot_bar()\n```\n\n\n\n#### Korrelationen\n\n\n```{r}\nd2 %>% plot_correlation()\n```\n\n\n#### Bonus\n\nProbieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: `create_report(d2)`.\n\n\n\n\n\n\n<!-- ### Selbsgetrickte Visualisierung von `weight` und `height` -->\n\n\n<!-- ```{r Post-Regression-6} -->\n<!-- d2 %>%  -->\n<!--   select(weight, height) %>%  -->\n<!--   pivot_longer(everything()) %>%  -->\n<!--   ggplot(aes(x = value)) + -->\n<!--   geom_histogram() + -->\n<!--   facet_wrap(~ name, scales = \"free\") + -->\n<!--   geom_vline(data = d2_summary, -->\n<!--              aes(xintercept = avg)) + -->\n<!--   geom_segment(data = d2_summary, -->\n<!--               aes(x = avg-stdev, -->\n<!--                   xend = avg+stdev), -->\n<!--               y = 0, -->\n<!--               yend = 0, -->\n<!--               alpha = .7, -->\n<!--               color = \"blue\", -->\n<!--               size = 2) + -->\n<!--   labs(caption = \"Vertikale Linie: Mittelwert\\nhorizontale Linie: Standardabweichung\") -->\n<!-- ``` -->\n\n\n\n\n\n### Prädiktor zentrieren \n\n\n\n\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Prädiktor \"zentrieren\").\nWenn man den Prädiktor (`weight`) zentriert hat, ist der Achsenabschnitt, $\\alpha$, einfacher zu verstehen.\nIn einem Modell mit zentriertem Prädiktor (`weight`) gibt der Achsenabschnitt die Größe einer Person mit durchschnittlichem Gewicht an. \nWürde man `weight` nicht zentrieren, gibt der Achsenabschnitt die Größe einer Person mit `weight=0` an, was nicht wirklich sinnvoll zu interpretieren ist.\n\n\n\nVgl. @gelman_regression_2021, Kap. 10.4,  12.2.\n\n\n\n\nSo kann man das Zentrieren bewerkstelligen:\n\n\n```{r}\nd3 <- \n  d2 %>% \n  center(weight)\n```\n\nOder so, von Hand:\n\n```{r Post-Regression-7, echo = TRUE}\nd3 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n```\n\n\n```{r Post-Regression-8}\n#| echo: false\nd3 %>% \n  slice_head(n=3) %>% \n  gt() %>% \n  fmt_number(columns = everything(), decimals = 0)\n```\n\n\nWie man sieht, ist die Verteilung \"zur Seite geschoben\": Der Mittelwert liegt jetzt eben bei 0.\n\n\n\n```{r Post-Regression-9, fig.asp=0.4}\n#| echo: false\nd3 %>% \n  select(weight, weight_c) %>% \n  pivot_longer(everything()) %>% \n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(~ name, scales = \"free\")\n```\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass `d3` die Tabelle mit zentriertem Prädiktor ist, nicht `d2`.\n\n\n## Modell m43: zentrierter Prädiktor\n\n\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren:\nBei einem (erwachsenen) Menschen mit *Gewicht 0*, was wäre wohl die Körpergröße?\nHm, Philosophie steht heute nicht auf der Tagesordnung.\n\nDa wäre es schön, wenn wir die Daten so umformen könnten, dass der Achsenabschnitt eine sinnvolle Aussage macht.\nZum Glück geht das leicht: Wir zentrieren den Prädiktor (Gewicht)!\n\n\n:::callout-important\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n:::\n\n\n\n\n\n### Modelldefinition von `m43`\n\n- Für jede Ausprägung des Prädiktors (`weight`), $h_i$, wird eine Post-Verteilung für die abhängige Variable (`height`) berechnet.\n- Der Mittelwert $\\mu$ für jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel).\n- Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel).\n- Wir brauchen Priori-Werte für die Steigung $\\beta$ und den Achsenabschnitt $\\alpha$ der Regressionsgeraden.\n- Außerdem brauchen wir einen Priori-Wert, der die Streuung $\\sigma$ der Größe (`height`) angibt; dieser Wert wird als exonentialverteilt angenommen.\n- Der Likelihood gibt an, wie wahrscheinlich ein Wert `height` ist, gegeben $\\mu$ und $\\sigma$.\n\n\n$$\n\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\n$$\n\n\n\n\n### Likelihood, `m43`\n\n\n\n$$\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n$$\n\n\n\n\n- Der Likelihood von `m43` ist ähnlich zu den vorherigen Modellen (`m41, m42`).\n- Nur gibt es jetzt ein kleines \"Index-i\" am $\\mu$ und am $h$ (h wie `heights`).\n- Es gibt jetzt nicht mehr nur einen Mittelwert $\\mu$, sondern für jede Beobachtung (Zeile) einen Mittelwert $\\mu_i$.\n- Lies  etwa so:\n\n>    \"Die Wahrscheinlichkeit, eine bestimmte Größe bei Person $i$ zu beobachten, gegeben $\\mu$ und $\\sigma$ ist normalverteilt (mit Mittelwert $\\mu$ und Streuung $\\sigma$)\".\n\n\n\n\n\n### Regressionsformel, `m43`\n\n\n$$\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n$$\n\n\n- $\\mu$ ist jetzt nicht mehr ein Parameter, der (stochastisch) geschätzt werden muss. $\\mu$ wird jetzt (deterministisch) *berechnet*. Gegeben $\\alpha$ und $\\beta$ ist $\\mu$ ohne Ungewissheit bekannt.\n- $\\text{weight}_i$ ist der Prädiktorwert (`weight`) der $i$ten Beobachtung, also einer !Kung-Person (Zeile $i$ im Datensatz).\n- Lies  etwa so:\n\n>    \"Der Mittelwert $\\mu_i$ der $i$ten Person berechnet sich als Summe von $\\alpha$ und $\\beta$ mal  $\\text{weight}_i$\".\n\n\n- $\\mu_i$ ist eine lineare Funktion von `weight`.\n- $\\beta$ gibt den Unterschied in `height` zweier Beobachtung an, die sich um eine Einheit in `weight` unterscheiden (Steigung der Regressionsgeraden).\n- $\\alpha$ gibt an, wie groß $\\mu$ ist, wenn `weight` Null ist (Achsenabschnitt, engl. intercept).\n\n\n\n### Priori-Werte des Modells `m43`\n\n\n\n$$\n\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\n$$\n\n- Parameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n- $\\alpha$ wurde in `m41` als $\\mu$ bezeichnet, da wir dort eine \"Regression ohne Prädiktoren\" berechnet haben.\n- $\\sigma$ ist uns schon als Parameter bekannt und behält seine Bedeutung aus dem letzten Kapitel.\n- Da `height` nicht zentriert ist, der Mittelwert von $\\alpha$ bei 178 und nicht 0.\n- $\\beta$ fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Größe positiv (gleichsinnig) ist.\n\n\n## Vertiefung: Prior-Prädiktiv-Verteilung\n\n🏎️ VERTIEFUNG 🏎️\n\n### Moment\n\n   - 🤔 Moment. Dieser Prior, $\\beta$ in `m43` erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\n   - Sind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Größe positiv oder negativ ist? [Nein, sind wir nicht.](https://media.giphy.com/media/daPCSjwus6UR2JxRX1/giphy.gif) \n    \n\n\n### Priori-Prädiktiv-Verteilung für `m43`\n\n\n\n- Was denkt [wir](https://media.giphy.com/media/Aausss8uUBIe3bZ3d2/giphy.gif) bzw. unser Golem *apriori* über den Zusammenhang von Größe und Gewicht?\n- Um diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also für $\\alpha$, $\\beta$ und $\\sigma$.\n\n\n\n```{r m43-prior-pred}\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter für Prior-Pred-Verteilung\n             data = d2)\n\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n```\n\n\n\n```{r}\nm43_prior_pred_draws %>% \n  slice_head(n=5) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n```\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n\n### Prior-Prädiktiv-Simulation für `m43` mit `stan_glm()` \n\n\n\n\n```{r echo = TRUE, eval = FALSE}\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d2)\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n```\n\n\n\n```{r echo = FALSE, eval = FALSE}\nm43a_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(0, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter machts\n             data = d2)\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n```\n\n\n\n\n\n\n\n\n\n### Visualisieren der Prior-Prädiktiv-Verteilung\n\n\n\n```{r prior-pv1, echo = TRUE, eval = FALSE, fig.asp = .5}\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n```\n\n\n\n🤯 Einige dieser Regressionsgeraden sind unsinnig!\n\n\n```{r ref.label = \"prior-pv1\", eval = TRUE, fig.asp = .3}\n\n```\n\n\nDie durchgezogene horizontale Linie gibt die Größe des [größten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.\n\n\n\n\n\n### Ein positiver Wert für $\\beta$ ist plausibler\n\n\n#### Oh no\n\nEine Normalverteilung mit viel Streuung:\n\n```{r Post-Regression-16, fig.asp = .5}\n#| echo: false\nd <-\n  tibble(\n    x = seq(-30,30,.1),\n    y = dnorm(x, mean = 0, sd = 10)\n  )\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line() +\n  scale_y_continuous(breaks = NULL) +\n  labs(title = \"mu=0, s=10\")\n```\n\n👎 $\\beta=-20$ wäre mit diesem Prior gut möglich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n\n\n#### Oh yes\n\nWir bräuchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):\n\n```{r Post-Regression-17, fig.asp=.5}\n#| echo: false\nd <-\n  tibble(\n    x = seq(-30,30,.1),\n    y = dnorm(x, mean = 3, sd = 2)\n  )\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line() +\n  scale_y_continuous(breaks = NULL) +\n  labs(title = \"mu=5, sd = 3\")\n```\n\n👍 Vermutlich besser: Ein Großteil der Wahrscheinlichkeitsmasse ist $X>0$. Allerdings gibt's keine Gewähr, dass unser Prior \"richtig\" ist.\n\n\n\n\n### Priori-Prädiktiv-Simulation, 2. Versuch\n\n\n\n\n\n```{r echo = TRUE}\nm43a_prior_pred <-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter für Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d2)\n\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  # Spaltennamen kürzen: \n  rename(a = `(Intercept)`) %>%  \n  rename(b = weight_c,\n         s = sigma)\n```\n\n\n\n\n\n```{r}\n#| echo: false\nm43a_prior_pred_draws %>% \n  slice_head(n=5) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n```\n\n\n\nDas Argument `prior_PD = TRUE` sorgt dafür, dass keine Posteriori-Verteilung, sondern eine Prior-Prädiktiv-Verteilung berechnet wird.\n\n\n\n\n### Visualisieren der Prior-Prädiktiv-Verteilung, `m43a`\n\n\nUnsere Priori-Werte scheinen einigermaßen vernünftige Vorhersagen zu tätigen. Allerdings erwartet unser Golem einige Riesen.\n\n\n```{r, eval = TRUE, fig.asp=.5}\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n```\n\n\nDie durchgezogene horizontale Linie gibt die Größe des [größten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.\n\n\n\n\n\n\n\n\n### Moment, kann hier jeder machen, was er will?\n\n\n\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\n\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\n\n>    This is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.  \n\n@mcelreath_statistical_2020, p. 96.\n\n\n\n\n\n### Hier ist unser Modell, `m43a`\n\n\n\n\n$$\n\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\n$$\n\n\n\n```{r Post-Regression-25, echo = TRUE}\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n```\n\n\n\n\n\n### Eine Zusammenfassung der Posteriori-Verteilung für `m43a`\n\n\n```{r}\nm43a %>% \n  parameters()\n```\n\n\nUnser Modell `m43a` schätzt die typische Körpergröße einer !Kung-Person *mittleren Gewichts* (`weight_c = 0`) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher.\nPro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise;\nauch hier ist sich das Modell ziemlich sicher, da dass zugehörige 95%-CI keine 20 Zentimenter umfasst.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Die Post-Verteilung befragen\n\n\n### m43a\n\n\nSagen wir, auf Basis gut geprüfter Evidenz haben wir folgendes Modell festgelegt: `height ~ weight_c`.\n\nPrioris:\n\n$$\n\\beta_1 \\sim N(5,3) \\\\\n\\beta_0 \\sim N(178, 20) \\\\\n\\sigma \\sim E(0.1)\n$$\n\n\n\n```{r m43a, echo = TRUE}\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n```\n\n\nWir nennen es `m43a`^[Wer ist hier für die Namensgebung zuständig?].\n\n\n### Mittelwerte von $\\alpha$ und $\\beta$ aus der Post-Verteilung\n\n\n\nDie ersten paar Zeilen:\n\n```{r Post-Regression-befragen-3}\n#| echo: false\nm43a %>%  \n  as_tibble() %>% \n  mutate(id = 1:nrow(.), .before = 1) %>% \n  head(n=3) %>% \n  gt() %>% \n  fmt_number(columns = 2:4, decimals = 1)\n```\n\n\n\n```{r Post-Regression-befragen-4, echo = TRUE}\n#| echo: true\n#| results: hide\n#| message: false\nparameters(m43a)\n```\n\n\n```{r Post-Regression-befragen-5}\n#| echo: false\nparameters(m43a) %>% \n  display()\n```\n\n\n\nDie Kennzahl  `pd` (propability of direction) gibt die Wahrscheinlichkeit an,\ndass der Effekt positiv (also größer als Null) oder negativ ist (jenachdem ob der Median des Effekts positiv oder negativ ist).\n`pd` gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt.\nDamit ist er so etwas (grob!) Ähnliches wie der p-Wert in der Frequentistischen Statistik [@makowski_indices_2019].\n\n\nAm besten das Diagramm dazu anschauen:\n\n\n```{r}\nplot(p_direction(m43a))\n```\n\n\n\n`Rhat` und `ESS` sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein.\n`Rhat` sollte nicht (viel) größer als 1 oder 1,01 sein. `ESS` (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\n\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter beschäftigen in diesem Kurs.\n\n\n### Visualisieren der \"mittleren\" Regressiongeraden\n\n\n\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern,\nhier $\\beta_0$, $\\beta_1$ und $\\sigma$:\n\n\n\n```{r}\nm43a %>% \n  as_tibble() %>% \n  head()\n```\n\nWir können z.B. ein Lagemaß wie den Median hernehmen, um die \"mittlere\" Regressionsgerade zu betrachten:\n\n\n```{r Post-Regression-befragen-6, echo = TRUE, eval = FALSE}\n#| echo: true\n#| eval: true\nd2 %>% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n```\n\n\n\n\n\n\n### Zentrale Statistiken zu den Parametern\n\nIn diesem Modell gibt es drei Parameter: $\\mu, \\beta, \\sigma$.\n\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen können.\n\n\n#### Lagemaße zu den Parametern\n\n- Was ist die mittlere Größe einer !Kung-Person? ($\\beta_0$)\n- Was ist der Schätzwert für den Zusammenhang von Gewicht und Größe? ($\\beta_1$)\n- Was ist der Schätzwert für Ungewissheit in der Schätzung der Größe? ($\\sigma$)\n- Was ist der wahrscheinlichste Wert für z.B: $\\beta_1$?\n\n```{r Post-Regression-befragen-7, echo = TRUE}\nm43a %>% \n  parameters()\n```\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression mit `as_tibble()` in eine Tabelle um,\nso bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\n```{r}\nm43a_post <- \n  m43a %>% \n  as_tibble()\n\nm43a_post %>% \n  head()\n```\n\n\nWie wir gesehen haben, nutzen wir diese Tabeller der Post-Verteilung immer wieder.\nSpeichern wir uns sie also als ein Objekt ab, `m43_post`.\n\n\n\n![Typischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR](https://easystats.github.io/bayestestR/reference/figures/bayesianMaster.jpg)\n\n[Quelle](https://easystats.github.io/bayestestR/articles/bayestestR.html)\n\n\nEine Visualisierung zeigt gut sowohl Lage- als auch Streuungsmaße der Parameter, zumindest grob:\n\n\n\n```{r}\nm43a_post %>% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n```\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen.\nZur Erinnerung: Der Modus gibt den häufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\n\nDer Modus wird hier auch *Maximum a Posteriori* (MAP) genannt, daher:\n\n\n```{r map-estimate-m43a}\n#| eval: false\nm43a_post %>% \n  summarise(map_b1 = map_estimate(weight_c))\n```\n\n\n\n\n\nHier ist die Verteilung von $\\sigma$ visualisiert:\n\n\n```{r}\nm43a_post %>% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n```\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen,\ngleich mit Intervallgrenzen, z.B. 95%.\n\n```{r}\nm43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n```\n\nErgänzt man bei `plot()` noch `show_intercept = TRUE` wird auch der Achsenabschnitt angezeigt.\n\n\n\n\n### Streuungsmaße zu den Parametern\n\n\n- Wie unsicher sind wir uns in den Schätzungen der Parameter?\n\n\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n:::callout-note\nAn einigen Stellen wird empfohlen, anstelle eines (gebräuchlichen) 95%-Intervalls \nauf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilität.\n:::\n\n\n### Ungewissheit von $\\alpha$ und $\\beta$ aus der Post-Verteilung visualisiert\n\n\n\nDie ersten 10 Stichproben\n```{r Post-Regression-befragen-10, echo = TRUE}\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n```\n\n\nDie ersten 100 Stichproben\n```{r Post-Regression-befragen-11-ersten-1000, echo = TRUE}\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n```\n\n\nDie ersten `1e3` Stichproben\n```{r Post-Regression-befragen-11-die-ersten-1000, echo = TRUE}\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n```\n\n\nDie ersten 1000000 ... okay, lassen wir es gut sein^[Im Standard beschert uns `stan_glm()` 4000 Stichproben.].\n\n\n### Fragen zu Quantilen des Achsenabschnitts \n\n:::callout-note\nZur Erinnerung: Bei einem zentrierten Prädiktor misst der Achsenabschnitt die mittlere Größe.\n:::\n\n- Welche mittlere Größe mit zu 50%, 90% Wskt. nicht überschritten?\n- Welche mittlere Größe mit zu 95% Wskt. nicht unterschritten?\n- Von wo bis wo reicht der innere 50%-Schätzbereich der mittleren Größe?\n\n\n\nQuantile:\n\n```{r quantile-post}\nm43a_post %>% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .05))\n```\n\n50%-PI:\n\n```{r}\nm43a_post %>% \n  summarise(pi_50 = quantile(`(Intercept)`, prob = c(.25, .75)))\n```\n\n\n\n### Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts \n\n\n\nWie wahrscheinlich ist es, dass die mittlere Größe bei mind. 155 cm liegt?\n\n\n```{r echo = TRUE}\nm43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n))\n```\n\n```{r}\n#| echo: false\nwskt_gross <- \n  m43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n)) %>% \n  pull(prop) %>% \n  `[`(2) %>% \n  round(2)\n```\n\nDie Wahrscheinlichkeit beträgt `r wskt_gross`.\n\n\n- Wie wahrscheinlich ist es, dass die mittlere Größe höchstens 154.5 cm beträgt?\n\n\n```{r echo = TRUE}\nm43a_post %>% \n  count(klein = (`(Intercept)` <= 154.5)) %>% \n  mutate(prop = n / sum(n))\n```\n\n```{r}\n#| echo: false\nwskt_klein <- \n  m43a_post %>% \n  count(klein = `(Intercept)` <= 154.5) %>% \n  mutate(prop = n / sum(n)) %>% \n  pull(prop) %>% \n  `[`(2) %>% \n  round(2)\n```\n\n\nDie Wahrscheinlichkeit beträgt `r wskt_klein`.\n\n\n\n\n\n\n<!-- ### Ungewissheit von Achsenabschnitt und Steigung  -->\n\n<!-- ... als Histogramme visualisiert -->\n\n<!--  -->\n\n<!-- ### Achsenabschnitt -->\n\n<!-- ```{r Post-Regression-befragen-13, echo = TRUE, eval = TRUE} -->\n<!-- post_m43a %>%  -->\n<!--   ggplot(aes(x = a)) + -->\n<!--   geom_density() -->\n<!-- ``` -->\n\n<!-- ] -->\n\n<!-- .pull-right[ -->\n\n<!-- ### Regressionsgewicht (Steigung) -->\n\n<!-- ```{r Post-Regression-befragen-14, echo = TRUE} -->\n<!-- post_m43a %>%  -->\n<!--   ggplot(aes(x = b)) + -->\n<!--   geom_density() -->\n<!-- ``` -->\n\n<!-- ] -->\n\n\n## Post-Verteilung bedingt auf einen Prädiktorwert\n\n\n### Visualisierung\n\n\nWas ist wohl die Wahrscheinlichkeit der Körpergröße bei einem bestimmten Gewicht?\n\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt.\nWelche Körpergröße ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns über diesen Mittelwert?\n\nEtwas formaler ausgedrückt:\n\n$\\mu|\\text{weight}=45$\n\n\n45 kg entspricht genau dem Mittelwert von `weight`. Geht man von zentrierten Prädiktorwerten aus, gilt in dem Fall `weight_c = 0`.\n\n\n```{r mu-at-45, echo = TRUE}\nmu_at_45 <-\n  m43a_post %>% \n  mutate(mu_at_45 = `(Intercept)`)\n```\n\n\n```{r Post-Regression-befragen-15, echo = TRUE, eval = FALSE}\n#| eval: false\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n```\n\n\n\n```{r Post-Regression-befragen-17}\n# | echo: false\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 45\"])) +\n  scale_x_continuous(limits = c(150, 160))\n```\n\n\nAnalog können wir fragen,\nwie groß wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns über diesen Mittelwert sind.\n\n\n50 kg, das sind 5 über dem Mittelwert, in zentrierten Einheiten ausgedrückt also `weight_c = 5`.\n\n\n\n```{r mu-at-50, echo = TRUE}\nmu_at_50 <-\n  m43a_post %>% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n```\n\n\n\n```{r Post-Regression-befragen-16, echo = TRUE, eval = FALSE}\n#| eval: false\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n```\n\n\n\n\n\n```{r Post-Regression-befragen-18}\n#| echo: false\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 50\"])) +\n  scale_x_continuous(limits = c(150, 160))\n```\n\n\n\n\n### Lagemaße und Streuungen\n\n\n\n\nWas ist das 90% PI für $\\mu|w=50$ ?\n\n```{r Post-Regression-befragen-19, echo = TRUE}\nmu_at_50 %>% \n  summarise(pi = quantile(mu_at_50, prob = c(0.05, .95)))\n```\n\nDie mittlere Größe - gegeben $w=50$ - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten.\n\n\n\nWelche mittlere Größe wird mit 95% Wahrscheinlichkeit nicht überschritten, wenn die Person 45kg wiegt?\n\n```{r Post-Regression-befragen-20, echo = TRUE}\nmu_at_45 %>% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n```\n\n\n\n\n## Die PPV befragen\n\n\n🏎️ VERTIEFUNG 🏎️\n\n\n\n\n\n\n\n\nDie Posterior-Prädiktiv-Verteilung (PPV) gibt uns die Möglichkeit,\nnach der Wahrscheinlichkeit *tatsächlicher* Körpergrößen zu fragen - \nund nicht nur nach *mittleren* Körpergrößen anhand der Post-Verteilung.\n\n\n:::callout-important\nDie Post-Verteilung macht nur Aussagen zur mittleren Körpergröße,\ndenn das ist was wir modellieren wollten.\nMöchten wir Aussagen zur Wahrscheinlichkeit tatsächlicher Größen treffen,\nbrauchen wir die PPV.\n:::\n\n\n### Perzentil-Intervalle für verschiedenen Prädiktor-Werte\n\n\nWir erstellen uns eine Sequenz an Prädiktorwerten, die uns interessieren:\n\n```{r echo = TRUE}\nweight_df <- tibble(weight_c = seq(-20,20, by = 5))\n```\n\n\nFür diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\n```{r Post-Regression-befragen-21, echo = TRUE}\nmus <- \n  predictive_interval(\n    m43a, \n    newdata = weight_df) %>% \n  as_tibble() %>% \n  bind_cols(weight_df)\n```\n\nUm die Perzentilintervalle zu erstellen, wird von `predictive_interval()` für jeden Prädiktorwert eine Posteriori-Verteilung erstellt und das 5%- sowie 95%-Quantil berechnet. \n\nWir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine Körpergrö0e von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI).\nHoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben.\nJa, denn die Post-Verteilung hat die Ungewissheit zum *Mittelwert* ausgedrückt;\ndie PPV gibt die Ungewissheit *tatsächlicher* beobachtbarer Körpergrößen aus,\nnicht nur die Ungewissheit zum Mittelwert.\n\n\n\nHier ist ein Auszug aus der PPV-Tabelle:\n\n\n\n\n```{r Post-Regression-befragen-23}\n#| echo: false\nmus %>% \n  head() %>% \n  relocate(weight_c, .before = 1) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n```\n\n\n\n\n\n\n### Perzentilintervalle für verschiedenen Prädiktorwerte visualisiert\n\n\n\n```{r}\nmus <- \n  mus %>% \n  mutate(height = 154.6 + 0.9*weight_c)\n\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = \"blue\") +\n  geom_errorbar(data = mus,\n                aes(ymin = `5%`,\n                    ymax = `95%`),\n                size = .5,\n                width = .5,\n                color = \"firebrick\")\n```\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\n\nNoch eine andere Visualisierung; je dicker die Katzenaugen, desto mehr Samples liegen vor an der Stelle,\nund umso genauer ist die Schätzung.\n\n\n```{r}\n#| echo: false\nppv_m43_weight_df <-\n  posterior_predict(m43a,\n                    newdata = weight_df) %>% \n  as_tibble() %>% \n  pivot_longer(everything(),\n               names_to = \"weight_condition\",\n               values_to = \"height\")\n\nweight_df <-\n  weight_df %>% \n  mutate(weight_condition = as.character(c(1:9)))\n\nppv_m43_weight_df <- \n  ppv_m43_weight_df %>% \n  full_join(weight_df, by = \"weight_condition\")\n\nd2 %>% \n  ggplot() +\n  geom_violin(data = ppv_m43_weight_df,\n              aes(x = weight_c, y = height, group = weight_c),\n                fill = \"grey80\",\n              width = 1) +\n    geom_point(aes(x = weight_c, y = height)) +\n  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = \"blue\")\n```\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher $\\mu | w_i}$.\n\n\n\n### Die PPV visualisiert\n\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV für einen bestimmten Prädiktorwert, z.B. bei einer Person mittleren Gewichts.\n\nWir können auch den Mittelwert über alle bedingten PPV anschauen, sozusagen die \"Master-PPV\" oder \"unbedingte PPV\" oder schlicht PPV.\n\n\nVergleichen wir die echten Werte für `height`, $h$, mit den von der PPV simulierten Werten für `height`, $h_{sim}$.\n\n```{r ppv-plot1, eval = FALSE, echo = TRUE}\nlibrary(bayesplot)\nh <- d2$height\nh_sim <- \n  posterior_predict(m43a, \n                    draws = 50)\nppc_dens_overlay(\n  h, h_sim)\n```\n\n`?posterior_predict` zeigt Hilfe für diese Funktion. \nDie Funktion zeigt die Vorhersagen für die AV laut der Posteriori-Verteilung.\n\n\n\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, ansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n\n\n\n### PPV plotten, von Hand\n\n\nPPV berechnen (lassen):\n\n```{r Post-Regression-befragen-27, echo = TRUE}\nset.seed(42)\nppv_m43a <- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %>% \n  as_tibble() %>% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n```\n\nUnd plotten:\n\n```{r ppv-regr, echo = TRUE, eval = FALSE, fig.asp = .4}\nppv_m43a %>% \n  ggplot(aes(x = height)) +\n  geom_density()\n```\n\n\n\n\n\n\n\n### Fragen an die PPV\n\n- Wie groß sind die !Kung im Schnitt?\n- Welche Größe wird von 90% der Personen nicht überschritten?\n- Wie groß sind die 10% kleinsten?\n\n```{r Post-Regression-befragen-29, echo = TRUE }\nppv_m43a %>% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n```\n\n\nWas ist der 50% Bereich der Körpergröße?\n\n```{r Post-Regression-befragen-30, echo = TRUE}\nppv_m43a %>% \n  summarise(pi_50 = quantile(height,prob = c(.25, .75)))\n```\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"lineare-modelle.html"},"language":{},"metadata":{"lang":"de","fig-responsive":true,"quarto-version":"1.1.168","bibliography":["references.bib"],"editor":"source","knitr":{"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}}}