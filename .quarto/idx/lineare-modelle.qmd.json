{"title":"Lineare Modelle","markdown":{"headingText":"Lineare Modelle","containsRefs":false,"markdown":"\n\n## Lernsteuerung\n\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ...\n\n\n\n- die Post-Verteilung f√ºr einfache lineare Modelle in R berechnen\n- zentrale Informationen zu Modellparametern - wie Lage- oder Streuungsma√üe und auch Sch√§tzintervalle - aus der Post-Verteilung herauslesen\n- k√ºnftige, laut Modell zu erwartende Beobachtungen mit der PPV simulieren\n\n### Ben√∂tigte R-Pakete\n\nIn diesem Kapitel ben√∂tigen Sie folgende R-Pakete.\n\n\n```{r}\n#| message: false\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\n```\n\n\n```{r libs-hidden}\n#| include: false\nlibrary(\"latex2exp\")\nlibrary(\"patchwork\")\nlibrary(\"gt\")\n\ntheme_set(theme_modern())\n```\n\n\nDa wir in diesem Kapitel immer mal wieder eine Funktion aus dem R-Paket `{easystats}` verwenden: [Hier](https://easystats.github.io/easystats/articles/list_of_functions.html) finden Sie eine √úbersicht aller Funktionen des Pakets.^[Da es viele Funktionen sind, bietet es sich an mit *Strg-F* auf der Webseite nach Ihrem Lieblingsbefehl zu suchen.]\n\n\n### Begleitvideso\n\n- [Pr√§diktoren zentrieren](https://youtu.be/3Z1dXPO_MSE)\n\n\n## Post-Verteilung der Regression\n\n\n### Einfache Regression\n\n\n\nDie (einfache) Regression pr√ºft, inwieweit zwei Variablen, $Y$ und $X$ linear zusammenh√§ngen.\nJe mehr sie zusammenh√§ngen, desto besser kann man $X$ nutzen, um $Y$ vorherzusagen (und umgekehrt).\nH√§ngen $X$ und $Y$ zusammen, hei√üt das nicht (unbedingt), dass es einen *kausalen* Zusammenhang zwischen $X$ und $Y$ gibt.\n*Linear* ist ein Zusammenhang, wenn der Zuwachs in $Y$ relativ zu $X$ konstant ist: wenn $X$ um eine Einheit steigt, steigt $Y$ immer um $b$ Einheiten (nicht kausal, sondern deskriptiv gemeint).\n\n[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv), @mcelreath_statistical_2020.\n\nLaden wir die !Kung-Daten und visualisieren wir uns den Zusammenhang zwischen Gewicht (X) und Gr√∂√üe (Y), @fig-kung-zshg.\n\n\n```{r Post-Regression-2}\n#| fig-asp: 0.5\n#| message: false\n#| label: fig-kung-zshg\n#| fig-cap: Der Zusammenhang von Gr√∂√üe und Gewicht im !Kung-Datensatz\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"\n\nd <- read_csv(Kung_path)  \n\nd2 <- \n  d %>% \n  filter(age > 18) \n\nd2 %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\")\n```\n\n\n\n\n\n### Bei jedem Pr√§diktorwert eine Post-Verteilung f√ºr $\\mu$\n\n\nKomfort pur: Unser Modell erlaubt uns f√ºr jeden beliebigen Wert des Pr√§diktors eine Post-Verteilung (von $\\mu$) zu berechnen.\n\nHier am Beispiel von `m42`, s. @fig-post42.\n\n```{r m42-read-from-disk, echo = FALSE}\n#| echo: false\n#| output: \"hide\"\nm42 <- read_rds(paste0(here::here(),\"/objects/m42.rds\"))\n\nm42_post <- as_tibble(m42)\nnames(m42_post) <- c(\"mu\", \"sigma\")\n```\n\n\n\n\n```{r Post-Regression-10}\n#| echo: false\n\nplot_post_42 <- \n  m42_post %>% \n  ggplot() +\n  aes(x = mu) +\n  geom_density(fill = \"grey60\") +\n  labs(x = expression(mu),\n       title = TeX(\"Posteriori-Verteilung f√ºr $\\\\mu$, m42\")) +\n  scale_y_continuous(breaks = NULL)\n```\n\n\n```{r Plot-condition}\n#| echo: false\nlm1 <- lm(height ~ weight, data = d2)\n\nd_pred <-\n  tibble(weight = c(40, 45, 50, 55),\n         height = predict(lm1, newdata = data.frame(weight)))\n\n\n\nplot_condition <- \n  d2 %>% \n  #select(weight, height) %>% \n  #drop_na() %>% \n  ggplot(\n       aes(x = weight, y = height)) +\n  geom_point(alpha = .7) +\n  geom_smooth(method = \"lm\") +\n  geom_point(aes(color = as.factor(weight)), data = d_pred, size = 5, alpha = .5) +\n  labs(color = \"Gewicht\",\n       x = \"Gewicht (weight)\",\n       y = \"Gr√∂√üe (height)\")\n\n```\n\n```{r m3}\n#| echo: false\n#| results: \"hide\"\n#| cache: true\n\nd2 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n\nm43 <- \n  stan_glm(height ~ weight_c, \n           prior = normal(0, 10),\n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\n\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n           prior_intercept = normal(178, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE, \n           prior_PD = TRUE,\n           data = d2)\n\nstan_glm(height ~ weight_c, \n           prior = normal(0, 10),\n           prior_intercept = normal(0, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken\n           data = d2)\n\nm43a_prior_pred <-\n    stan_glm(height ~ weight_c, \n           prior_intercept = normal(0, 20),  # mu\n           prior_aux = exponential(0.1),  # sigma\n           refresh = FALSE, \n           prior_PD = TRUE,\n           data = d2)\n```\n\n\n\n\n\n\n```{r objects-m43-m43a-to-disk, eval = FALSE}\n#| eval: false\n#| echo: false\nprint(m43)\nsummary(m43_prior_pred)\nwrite_rds(m43, \"objects/m43.rds\")\nwrite_rds(m43a, \"objects/m43a.rds\")\n```\n\n\n\n\n```{r m43-plot}\n#| echo: false\n\nnd <- tibble(\n  weight_c = c(-5, 0, +5, 10)\n)\n\nppv_m43 <- \n  posterior_predict(m43, , newdata = nd) %>% \n  as_tibble() %>% \n  pivot_longer(everything(), \n               names_to = \"weight_condition\",\n               values_to = \"h\") %>% \n  mutate(weight =\n           case_when(weight_condition == 1 ~ 40,\n                     weight_condition == 2 ~ 45,\n                     weight_condition == 3 ~ 50,\n                     weight_condition == 4 ~ 55\n                     )) %>% \n  mutate(weight = as.factor(weight))\n\n\n\nppv_m43_summary <-\n  ppv_m43 %>% \n  group_by(weight) %>% \n  summarise(m = mean(h),\n            s = sd(h))\n\n\npost_at_plot <-\n  ppv_m43 %>% \n  ggplot() +\n  aes(x = h) +\n  geom_density(aes(fill = weight)) +\n  facet_wrap(~ weight, nrow = 1, scales = \"free\") +\n  scale_y_continuous(breaks = NULL) +\n  labs(\n       caption = \"Horizontale Balken zeigen MW¬±2sd\",\n       x = \"Gr√∂√üe\",\n       y = \"Post-Wskt\") +\n  geom_point(data = ppv_m43_summary,\n             aes(x = m,\n                 y = 0),\n             size = 2, color = \"blue\", alpha = .5) +\n  geom_segment(data = ppv_m43_summary,\n               aes(x = m-2*s,\n                   xend = m+2*s),\n               y = 0,\n               yend = 0,\n               color = \"blue\",\n               alpha = .5,\n               size = 2) +\n  scale_x_continuous(breaks = c(140, 160))\n```\n\n\n\n```{r Post-Regression-12, out.width=\"100%\", fig.width=7}\n#| echo: false\n#| label: fig-post42\n#| fig-cap: \"F√ºr jeden beliebigen Pr√§diktorwert kann man eine Post-Verteilung bekommen. A: Regressionsmodell mit einigen ausgew√§hlten Gewichtswerten. B: F√ºr jeden beliebigen Gewichtswert bekommt man eine Post-Verteilung\"\n\n\nplots(plot_condition, post_at_plot, n_rows = 2, tags = \"A\")\n```\n\n\n\n\n\n### Statistiken zum !Kung-Datensatz\n\n[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv)\n\n\nHier sind die zentralen deskriptiven Statistiken zum !Kung-Datensatz.\n\n```{r Post-Regression-3}\n#| echo: true\n#| eval: false\nKung_path <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv\"  \nd <- read_csv(Kung_path)  \n\nd2 <- d %>% filter(age > 18)\n\ndescribe_distribution(d2)\n```\n\n\n\n```{r Post-Regression-4, echo = FALSE, eval = TRUE}\n#| echo: false\ndescribe_distribution(d2)\n```\n\n\nDas mittlere K√∂rpergewicht (`weight`) liegt bei ca. 45kg (sd 7 kg).\n\n\n### Etwas mehr EDA\n\n\n\n\nWir brauchen die EDA hier nicht wirklich, aber es ist praktisch. Das Paket `DataExplorer` hat ein paar nette Hilfen zur explorativen Datenanalyse.\n\n\n```{r}\n#| message: false\nlibrary(DataExplorer)\n```\n\n#### Gibt es fehlende Werte?\n\nNein, s. Abb. @fig-na.\n\n```{r}\n#| fig-cap: Fehlende Werte - fehlen.\n#| label: fig-na\nd2 %>% plot_missing()\n```\n\n\n\n#### Verteilung der numerischen Variablen\n\nBetrachten wir die Verteilung der *numerischen* Variablen des Datensatzes, s. @fig-d2-hists.\n\n\n```{r}\n#| label: fig-d2-hists\n#| fig-cap: \"Verteilung (als Histogramme dargestellt) der numerischen Variablen des Datensatzes\"\nd2 %>% plot_histogram()\n```\n\n\n\n#### Verteilung der kategorialen Variablen\n\n\nBetrachten wir die Verteilung der *kategorialen* Variablen des Datensatzes, s. @fig-d2-bars.\n\n\n```{r}\n#| label: fig-d2-bars\n#| fig-cap: \"Verteilung (als Balkendiagramme dargestellt) der kategorialen Variablen des Datensatzes\"\nd2 %>% plot_bar()\n```\n\n\n\n#### Korrelationen\n\nDie Korrelationen der (numerischen) Variablen sind in @fig-num-korrs dargestellt.\n\n```{r}\n#| label: fig-num-korrs\n#| fig-cap: \"Korrelationsmatrix\"\nd2 %>% plot_correlation()\n```\n\n\n#### Bonus\n\nProbieren Sie mal die folgende Funktion aus, die Ihnen einen Bericht zur EDA erstellt: `create_report(d2)`.\n\n\n\n\n\n\n<!-- ### Selbsgetrickte Visualisierung von `weight` und `height` -->\n\n\n<!-- ```{r Post-Regression-6} -->\n<!-- d2 %>%  -->\n<!--   select(weight, height) %>%  -->\n<!--   pivot_longer(everything()) %>%  -->\n<!--   ggplot(aes(x = value)) + -->\n<!--   geom_histogram() + -->\n<!--   facet_wrap(~ name, scales = \"free\") + -->\n<!--   geom_vline(data = d2_summary, -->\n<!--              aes(xintercept = avg)) + -->\n<!--   geom_segment(data = d2_summary, -->\n<!--               aes(x = avg-stdev, -->\n<!--                   xend = avg+stdev), -->\n<!--               y = 0, -->\n<!--               yend = 0, -->\n<!--               alpha = .7, -->\n<!--               color = \"blue\", -->\n<!--               size = 2) + -->\n<!--   labs(caption = \"Vertikale Linie: Mittelwert\\nhorizontale Linie: Standardabweichung\") -->\n<!-- ``` -->\n\n\n\n\n\n### Pr√§diktor zentrieren \n\n\n\n\nZieht man von jedem Gewichtswert den Mittelwert ab, so bekommt man die Abweichung des Gewichts vom Mittelwert (Pr√§diktor \"zentrieren\").\nWenn man den Pr√§diktor (`weight`) zentriert hat, ist der Achsenabschnitt, $\\alpha$, einfacher zu verstehen.\nIn einem Modell mit zentriertem Pr√§diktor (`weight`) gibt der Achsenabschnitt die Gr√∂√üe einer Person mit durchschnittlichem Gewicht an. \nW√ºrde man `weight` nicht zentrieren, gibt der Achsenabschnitt die Gr√∂√üe einer Person mit `weight=0` an, was nicht wirklich sinnvoll zu interpretieren ist.\n\n\n\nVgl. @gelman_regression_2021, Kap. 10.4,  12.2.\n\n\n\n\nSo kann man das Zentrieren bewerkstelligen:\n\n\n```{r}\nd3 <- \n  d2 %>% \n  center(weight)\n```\n\nOder so, von Hand:\n\n```{r Post-Regression-7, echo = TRUE}\nd3 <-\n  d2 %>% \n  mutate(weight_c = weight - mean(weight))\n```\n\n\n```{r Post-Regression-8}\n#| echo: false\nd3 %>% \n  slice_head(n=3) %>% \n  gt() %>% \n  fmt_number(columns = everything(), decimals = 0)\n```\n\n\nWie man sieht, ist die Verteilung \"zur Seite geschoben\": Der Mittelwert liegt jetzt eben bei 0.\n\n\n\n```{r Post-Regression-9, fig.asp=0.4}\n#| echo: false\nd3 %>% \n  select(weight, weight_c) %>% \n  pivot_longer(everything()) %>% \n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(~ name, scales = \"free\")\n```\n\n\n\nDas schwierigste ist dabei, nicht zu vergessen, dass `d3` die Tabelle mit zentriertem Pr√§diktor ist, nicht `d2`.\n\n\n## Modell m43: zentrierter Pr√§diktor\n\n\nEinige Regressionskoeffizienten, wie der Achsenabschnitt (Intercept) sind schwer zu interpretieren:\nBei einem (erwachsenen) Menschen mit *Gewicht 0*, was w√§re wohl die K√∂rpergr√∂√üe?\nHm, Philosophie steht heute nicht auf der Tagesordnung.\n\nDa w√§re es sch√∂n, wenn wir die Daten so umformen k√∂nnten, dass der Achsenabschnitt eine sinnvolle Aussage macht.\nZum Gl√ºck geht das leicht: Wir zentrieren den Pr√§diktor (Gewicht)!\n\n\n:::callout-important\nDurch Zentrieren kann man die Ergebnisse einer Regression einfacher interpretieren.\n:::\n\n\n\n\n\n### Modelldefinition von `m43`\n\nF√ºr jede Auspr√§gung des Pr√§diktors (`weight_centered`), $wc_i$, wird eine Post-Verteilung f√ºr die abh√§ngige Variable (`height`, $h_i$) berechnet.\nDer Mittelwert $\\mu$ f√ºr jede Post-Verteilung ergibt sich aus dem linearen Modell (unserer Regressionsformel).\n Die Post-Verteilung berechnet sich auf Basis der Priori-Werte und des Likelihood (Bayes-Formel).\n Wir brauchen Priori-Werte f√ºr die Steigung $\\beta$ und den Achsenabschnitt $\\alpha$ der Regressionsgeraden.\n Au√üerdem brauchen wir einen Priori-Wert, der die Streuung $\\sigma$ der Gr√∂√üe (`height`) angibt; dieser Wert wird als exonentialverteilt angenommen.\n Der Likelihood gibt an, wie wahrscheinlich ein Wert `height` ist, gegeben $\\mu$ und $\\sigma$.\n\n\n\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}} \\\\\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weightcentered}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori}}\n\\end{align*}\n\n\n\n:::callout-note\nDer Achsenabschnit (engl. *intercept*) eines Regressionsmodell wird in der Literatur oft mit $\\beta_0$ bezeichnet,\naber manchmal auch mit $\\alpha$.\nUnd manchmal mit noch anderen Buchstaben, das Alphabet ist weit. ü§∑\n:::\n\n\n\n\n\n\n### Likelihood, `m43`\n\n\n\n$$\n\\begin{aligned}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{Likelihood}}\n\\end{aligned}\n$$\n\n\n\n\n Der Likelihood von `m43` ist √§hnlich zu den vorherigen Modellen (`m41, m42`).\n Nur gibt es jetzt ein kleines \"Index-i\" am $\\mu$ und am $h$ (h wie `heights`).\n Es gibt jetzt nicht mehr nur einen Mittelwert $\\mu$, sondern f√ºr jede Beobachtung (Zeile) einen Mittelwert $\\mu_i$.\n Lies  etwa so:\n\n>    \"Die Wahrscheinlichkeit, eine bestimmte Gr√∂√üe bei Person $i$ zu beobachten, gegeben $\\mu$ und $\\sigma$ ist normalverteilt (mit Mittelwert $\\mu$ und Streuung $\\sigma$)\".\n\n\n\n\n\n### Regressionsformel, `m43`\n\n\n$$\n\\begin{aligned}\n\\color{green}{\\mu_i} & \\color{green}= \\color{green}{\\alpha + \\beta\\cdot \\text{weight}_i}  && \\color{green}{\\text{Lineares Modell} } \\\\\n\\end{aligned}\n$$\n\n\n $\\mu$ ist jetzt nicht mehr ein Parameter, der (stochastisch) gesch√§tzt werden muss. $\\mu$ wird jetzt (deterministisch) *berechnet*. Gegeben $\\alpha$ und $\\beta$ ist $\\mu$ ohne Ungewissheit bekannt.\n $\\text{weight}_i$ ist der Pr√§diktorwert (`weight`) der $i$ten Beobachtung, also einer !Kung-Person (Zeile $i$ im Datensatz).\nLies  etwa so:\n\n>    \"Der Mittelwert $\\mu_i$ der $i$ten Person berechnet sich als Summe von $\\alpha$ und $\\beta$ mal  $\\text{weight}_i$\".\n\n\n $\\mu_i$ ist eine lineare Funktion von `weight`.\n $\\beta$ gibt den Unterschied in `height` zweier Beobachtung an, die sich um eine Einheit in `weight` unterscheiden (Steigung der Regressionsgeraden).\n $\\alpha$ gibt an, wie gro√ü $\\mu$ ist, wenn `weight` Null ist (Achsenabschnitt, engl. intercept).\n\n\n\n### Priori-Werte des Modells `m43`\n\n\n\n\\begin{align*}\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{Priori Achsenabschnitt}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)}  && \\color{blue}{\\text{Priori Regressionsgewicht}}\\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Exp}(0.1)}  && \\color{blue}{\\text{Priori Sigma}}\n\\end{align*}\n\n- Parameter sind hypothetische Kreaturen: Man kann sie nicht beobachten, sie existieren nicht wirklich. Ihre Verteilungen nennt man Priori-Verteilungen.\n- $\\alpha$ wurde in `m41` als $\\mu$ bezeichnet, da wir dort eine \"Regression ohne Pr√§diktoren\" berechnet haben.\n- $\\sigma$ ist uns schon als Parameter bekannt und beh√§lt seine Bedeutung aus dem letzten Kapitel.\n- Da `height` nicht zentriert ist, der Mittelwert von $\\alpha$ bei 178 und nicht 0.\n- $\\beta$ fasst unser Vorwissen, ob und wie sehr der Zusammenhang zwischen Gewicht und Gr√∂√üe positiv (gleichsinnig) ist.\n\n\n## Vertiefung: Prior-Pr√§diktiv-Verteilung\n\nüèéÔ∏è VERTIEFUNG, nicht pr√ºfungsrelevant üèéÔ∏è\n\n### Moment\n\n ü§î Moment. Dieser Prior, $\\beta$ in `m43` erachtet positive und negative Zusammenhang als gleich wahrscheinlich?!\n\nSind wir wirklich indifferent, ob der Zusammenhang von Gewicht und Gr√∂√üe positiv oder negativ ist? [Nein, sind wir nicht.](https://media.giphy.com/media/daPCSjwus6UR2JxRX1/giphy.gif) \n    \n\n\n### Priori-Pr√§diktiv-Verteilung f√ºr `m43`\n\n\n\nWas denkt [wir](https://media.giphy.com/media/Aausss8uUBIe3bZ3d2/giphy.gif) bzw. unser Golem *apriori* √ºber den Zusammenhang von Gr√∂√üe und Gewicht?\nUm diese Frage zu beantworten ziehen wir Stichproben aus den Priori-Verteilungen des Modells, also f√ºr $\\alpha$, $\\beta$ und $\\sigma$.\n\n\n\n```{r m43-prior-pred}\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),\n             prior_intercept = normal(178, 20),  # mu\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # Schalter f√ºr Prior-Pred-Verteilung\n             data = d2)\n\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n```\n\n\n\n```{r}\n#| echo: false\nm43_prior_pred_draws %>% \n  slice_head(n=5) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n```\n\n\n\nJede Zeile definiert eine Regressionsgerade.\n\n\n\n### Prior-Pr√§diktiv-Simulation f√ºr `m43` mit `stan_glm()` \n\n\n\n\n```{r echo = TRUE, eval = FALSE}\nm43_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(178, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter macht's\n             data = d2)\n\nm43_prior_pred_draws <- \n  m43_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n```\n\n\n\n```{r echo = FALSE, eval = FALSE}\nm43a_prior_pred <-\n    stan_glm(height ~ weight_c, \n             prior = normal(0, 10),  # beta\n             prior_intercept = normal(0, 20),  # alpha\n             prior_aux = exponential(0.1),  # sigma\n             refresh = FALSE, \n             prior_PD = TRUE,  # DIESER Schalter machts\n             data = d2)\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  rename(a = `(Intercept)`,\n         b = weight_c) %>% \n  slice_sample(n = 50)\n```\n\n\n\n\n\n\n\n\n\n### Visualisieren der Prior-Pr√§diktiv-Verteilung\n\n\n\n```{r prior-pv1, echo = TRUE, eval = FALSE, fig.asp = .5}\nd2 %>% ggplot() +\n  geom_point(aes(x = weight_c, y = height)) + \n  geom_abline(data = m43_prior_pred_draws,\naes(intercept = a, slope = b), color = \"skyblue\", size = 0.2) +\n  scale_y_continuous(limits = c(0, 500)) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n```\n\n\n\nü§Ø Einige dieser Regressionsgeraden sind unsinnig!\n\n\n```{r ref.label = \"prior-pv1\", eval = TRUE, fig.asp = .3}\n\n```\n\n\nDie durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.\n\n\n\n\n\n### Ein positiver Wert f√ºr $\\beta$ ist plausibler\n\n\n#### Oh no\n\nEine Normalverteilung mit viel Streuung:\n\n```{r Post-Regression-16, fig.asp = .5}\n#| echo: false\nd <-\n  tibble(\n    x = seq(-30,30,.1),\n    y = dnorm(x, mean = 0, sd = 10)\n  )\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line() +\n  scale_y_continuous(breaks = NULL) +\n  labs(title = \"mu=0, s=10\")\n```\n\nüëé $\\beta=-20$ w√§re mit diesem Prior gut m√∂glich: Pro kg Gewicht sind Menschen im Schnitt 20cm kleiner, laut dem Modell. Quatsch.\n\n\n\n\n#### Oh yes\n\nWir br√§uchten eher so eine Verteilung, mit mehr Masse auf der positiven Seite (x>0):\n\n```{r Post-Regression-17, fig.asp=.5}\n#| echo: false\nd <-\n  tibble(\n    x = seq(-30,30,.1),\n    y = dnorm(x, mean = 3, sd = 2)\n  )\n\nd %>% \n  ggplot(aes(x,y)) +\n  geom_line() +\n  scale_y_continuous(breaks = NULL) +\n  labs(title = \"mu=5, sd = 3\")\n```\n\nüëç Vermutlich besser: Ein Gro√üteil der Wahrscheinlichkeitsmasse ist $X>0$. Allerdings gibt's keine Gew√§hr, dass unser Prior \"richtig\" ist.\n\n\n\n\n### Priori-Pr√§diktiv-Simulation, 2. Versuch\n\n\n\n\n\n```{r echo = TRUE}\nm43a_prior_pred <-\n    stan_glm(\n      height ~ weight_c, \n      prior = normal(2, 2),  # Regressionsgewicht\n      prior_intercept = normal(178, 20),  # mu\n      prior_aux = exponential(0.1),  # sigma\n      refresh = FALSE, \n      # Schalter f√ºr Prior-Pred-Verteilung:\n      prior_PD = TRUE, \n      data = d2)\n\n\nm43a_prior_pred_draws <- \n  m43a_prior_pred %>% \n  as_tibble() %>% \n  # Spaltennamen k√ºrzen: \n  rename(a = `(Intercept)`) %>%  \n  rename(b = weight_c,\n         s = sigma)\n```\n\n\n\n\n\n```{r}\n#| echo: false\nm43a_prior_pred_draws %>% \n  slice_head(n=5) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n```\n\n\n\nDas Argument `prior_PD = TRUE` sorgt daf√ºr, dass keine Posteriori-Verteilung, sondern eine Prior-Pr√§diktiv-Verteilung berechnet wird.\n\n\n\n\n### Visualisieren der Prior-Pr√§diktiv-Verteilung, `m43a`\n\n\nUnsere Priori-Werte scheinen einigerma√üen vern√ºnftige Vorhersagen zu t√§tigen. Allerdings erwartet unser Golem einige Riesen.\n\n\n```{r, eval = TRUE, fig.asp=.5}\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(data = {m43a_prior_pred_draws %>% slice_head(n=50)},\n              aes(slope = b,\n                  intercept = a),\n              color = \"skyblue\",\n              size = .2,\n              alpha = .7) +\n  geom_hline(yintercept = 272, size = .5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\")+\n  scale_y_continuous(limits = c(0, 500)) \n```\n\n\nDie durchgezogene horizontale Linie gibt die Gr√∂√üe des [gr√∂√üten Menschens, Robert Pershing Wadlow](https://en.wikipedia.org/wiki/Robert_Wadlow), an.\n\n\n\n\n\n\n\n\n### Moment, kann hier jeder machen, was er will?\n\n\n\nEs doch den einen, richtigen, objektiven Priori-Wert geben?!\n\nKann denn jeder hier machen, was er will?! Wo kommen wir da hin?!\n\n\n>    This is a mistake. There is no more a uniquely correct prior than there is a uniquely correct likelihood. Statistical models are machines for inference. Many machines will work, but some work better than others. Priors can be wrong, but only in the same sense that a kind of hammer can be wrong for building a table.  \n\n@mcelreath_statistical_2020, p. 96.\n\n\n\n\n\n### Hier ist unser Modell, `m43a`\n\n\n\n\n\\begin{align}\n\\text{height}_i &\\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta \\cdot  \\text{weight}_i\\\\\n\\alpha &\\sim \\operatorname{Normal}(178, 20)\\\\\n\\beta &\\sim \\operatorname{Normal}(5,3)\\\\\n\\sigma &\\sim \\operatorname{Exp}(0.1)\n\\end{align}\n\n\n\n```{r Post-Regression-25, echo = TRUE}\n# Zufallszahlen festlegen:\nset.seed(42)  \n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    data = d2)\n```\n\n\n\n\n\n### Eine Zusammenfassung der Posteriori-Verteilung f√ºr `m43a`\n\n\n```{r}\n#| eval: false\nm43a %>% \n  parameters()\n```\n\n\n\n```{r}\n#| echo: false\nm43a %>% \n  parameters() %>% \n  display()\n```\n\n\n\nUnser Modell `m43a` sch√§tzt die typische K√∂rpergr√∂√üe einer !Kung-Person *mittleren Gewichts* (`weight_c = 0`) auf knapp 155 cm, und ist sich dieses Werts ziemlich sicher.\nPro Kilogramm kommt (laut unserem Modell) ein knapper Zentimeter hinzu, typischerweise;\nauch hier ist sich das Modell ziemlich sicher, da dass zugeh√∂rige 95%-CI keine 20 Zentimenter umfasst.\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Die Post-Verteilung befragen\n\n\n### m43a\n\n\nSagen wir, auf Basis gut gepr√ºfter Evidenz haben wir folgendes Modell festgelegt: `height ~ weight_c`, s. @eq-m43a.\n\nPrioris:\n\n$$\\beta_1 \\sim N(5,3); \\\\\n\\beta_0 \\sim N(178, 20); \\\\\n\\sigma \\sim E(0.1)$${#eq-m43a}\n\n\nWir nennen das Modell `m43a`^[Wer ist hier f√ºr die Namensgebung zust√§ndig? Besoffen oder was?], s. @lst-m43a.\n\n\n\n\n```{#lst-m43a .r lst-cap=\"Modelldefinition von m43a in R\"}\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest f√ºr Reproduzierbarkeit\n    data = d3)\n```\n\n\n\n\n```{r m43a, echo = FALSE}\n# Posteriori-Vert. berechnen:\nm43a <-\n  stan_glm(\n    height ~ weight_c,  # Regressionsformel\n    prior = normal(5, 3),  # Regressionsgewicht (beta 1)\n    prior_intercept = normal(178, 20),  # mu\n    prior_aux = exponential(0.1),  # sigma\n    refresh = 0,  # zeig mir keine Details\n    seed = 42,  # lege die Zufallszahlen fest f√ºr Reproduzierbarkeit\n    data = d3)\n```\n\n\n:::callout-note\nMit `seed` kann man die Zufallszahlen fixieren,\nso dass jedes Mal die gleichen Werte resultieren.\nSo ist die Nachpr√ºfbarkeit der Ergebnisse (\"Reproduzierbarkeit\") sichergestellt^[oder zumindest *besser* sichergestellt].\nWelche Wert f√ºr `seed` man verwendet, ist egal,\nsolange alle den gleichen verwenden.\nDer Autor verwendet z.B. oft den Wert 42.\nZur Erinnerung: Der Golem zieht Zufallszahlen,\ndamit erstellt er Stichproben, die die Postverteilung sch√§tzen.\n:::\n\n\n\n\n### Mittelwerte von $\\alpha$ und $\\beta$ aus der Post-Verteilung\n\n\n\nDie ersten paar Zeilen:\n\n```{r Post-Regression-befragen-3}\n#| echo: false\nm43a %>%  \n  as_tibble() %>% \n  mutate(id = 1:nrow(.), .before = 1) %>% \n  head(n=3) %>% \n  gt() %>% \n  fmt_number(columns = 2:4, decimals = 1)\n```\n\nHier sind die Zusammenfassungen der Stichproben aus der Post-Verteilung, komfortabel zu erhalten mit dem Befehle `parameters`:\n\n```{r Post-Regression-befragen-4, echo = TRUE}\n#| echo: true\n#| results: hide\n#| message: false\nparameters(m43a)\n```\n\n\n```{r Post-Regression-befragen-5}\n#| echo: false\nparameters(m43a) %>% \n  display()\n```\n\n\n\nDie Kennzahl  `pd` (propability of direction) gibt die Wahrscheinlichkeit an,\ndass der Effekt positiv (also gr√∂√üer als Null) oder negativ ist (jenachdem ob der Median des Effekts positiv oder negativ ist).\n`pd` gibt aber nicht an, wie stark der Effekt ist, nur ob er klar auf einer Seite der Null liegt.\nDamit ist er so etwas (grob!) √Ñhnliches wie der p-Wert in der Frequentistischen Statistik [@makowski_indices_2019].\n\n\nAm besten das Diagramm dazu anschauen, s @fig-pd1.\n\n\n```{r}\n#| fig-cap: Diagramm zur Probability of Direction, Modell m43a\n#| label: fig-pd1\nplot(p_direction(m43a))\n```\n\n\n\n`Rhat` und `ESS` sind Kennzahlen, die untersuchen, ob mit der Stichprobenziehung im Bayes-Modell alles gut funktioniert hat. Bei einfachen Modellen (die wir hier berechnen) sollte da in der Regel alles in Ordnung sein.\n`Rhat` sollte nicht (viel) gr√∂√üer als 1 oder 1,01 sein. `ESS` (effective sample size) gibt die Anzahl der effektiv nutzbaren Stichproben an (im Standard werden 4000 berechnet). Die Zahl sollte nicht deutlich geringer sein.\n\nWir werden uns aber mit diesen beiden Kennwerten nicht weiter besch√§ftigen in diesem Kurs.\n\n\n### Visualisieren der \"mittleren\" Regressiongeraden\n\n\n\nZur Erinnerung: Die Bayes-Analyse liefert uns viele Stichproben zu den gesuchten Parametern,\nhier $\\beta_0$, $\\beta_1$ und $\\sigma$.\n√úberzeugen wir uns mit einem Blick in die Post-Verteilung von `m43a`:\n\n\n\n```{r}\nm43a %>% \n  as_tibble() %>% \n  head()\n```\n\nWir k√∂nnen z.B. ein Lagema√ü wie den Median hernehmen, um die \"mittlere\" Regressionsgerade zu betrachten:\n\n\n```{r Post-Regression-befragen-6, echo = TRUE, eval = FALSE}\n#| echo: true\n#| eval: true\nd2 %>% \n  ggplot() +\n  aes(x = weight_c, y = height) +\n  geom_point() +\n  geom_abline(\n    slope = 0.9,  # Median beta 1\n    intercept = 154,  # Median beta 0\n    color = \"blue\")\n```\n\nEinfacher ist die Syntax vielleicht, wenn man die Funktion `estimate_expectation` benutzt, s. @fig-expect-m43a.\nMit \"expectation\" sind hier die erwarteten Werte, also die Regressionsgerade, gemeint.\n\n```{r}\n#| fig-cap: Erwartete Werte des Modell m43a, sprich, die Regressionsgerade\n#| label: fig-expect-m43a\nm43_expect <- estimate_expectation(m43a)\nplot(m43_expect)\n```\n\n\n\n\n### Zentrale Statistiken zu den Parametern\n\nIn diesem Modell gibt es drei Parameter: $\\alpha, \\beta, \\sigma$.\n\nHier folgen einige Beispiele an Fragen, die wir an unser Modell bzw. die Post-Verteilung stellen k√∂nnen.\n\n\n#### Lagema√üe zu den Parametern\n\n- Was ist die mittlere Gr√∂√üe einer !Kung-Person? ($\\beta_0$)\n- Was ist der Sch√§tzwert f√ºr den Zusammenhang von Gewicht und Gr√∂√üe? ($\\beta_1$)\n- Was ist der Sch√§tzwert f√ºr Ungewissheit in der Sch√§tzung der Gr√∂√üe? ($\\sigma$)\n- Was ist der wahrscheinlichste Wert f√ºr z.B: $\\beta_1$?\n\n\nEine n√ºtzliche Zusammenfassung der Post-Verteilung bekommt man mit `parameters(modell)`:\n\n```{r Post-Regression-befragen-7, echo = TRUE}\n#| eval: false\nm43a %>% \n  parameters()\n```\n\n\n```{r Post-Regression-befragen-7a}\n#| echo: false\nm43a %>% \n  parameters() %>% \n  display()\n```\n\n\nWandelt man das Ausgabe-Objekt der Bayes-Regression, d.h. `m43a`, mit `as_tibble()` in eine Tabelle um,\nso bekommt man eine Tabelle mit den Stichproben der Post-Verteilung:\n\n\n```{r}\nm43a_post <- \n  m43a %>% \n  as_tibble()\n\nm43a_post %>% \n  head()\n```\n\n\nWie wir gesehen haben, nutzen wir diese Tabelle der Post-Verteilung immer wieder.\nSpeichern wir uns sie also als ein Objekt ab, `m43_post`.\n\n\nJetzt haben wir wieder eine sch√∂ne Tabelle mit Stichproben aus der Post-Verteilung,\ndie wir wie gewohnt befragen k√∂nnen.\n\n\n\nEine Visualisierung zeigt gut sowohl Lage- als auch Streuungsma√üe der Parameter, zumindest grob.,\n\n\n\n\n\nOder man erstellt selber ein Diagramm mit `ggplot`.\n\n\n\n\n```{r}\nm43a_post %>% \n  ggplot(aes(x = weight_c)) +\n  geom_density(fill = \"orange\")\n```\n\n\nDas Diagramm zeigt, dass Mittelwert, Median und Modus eng zusammenliegen.\nZur Erinnerung: Der Modus gibt den h√§ufigsten, d.h. hier also den wahrscheinlichsten, Wert an.\n\nDer Modus wird hier auch *Maximum a Posteriori* (MAP) genannt, daher:\n\n\n```{r map-estimate-m43a}\n#| eval: false\nm43a_post %>% \n  summarise(map_b1 = map_estimate(weight_c))\n```\n\n\n\n\n\nHier ist die Verteilung von $\\sigma$ visualisiert, s. @fig-m43a-post.\n\n\n```{r}\n#| label: fig-m43a-post\n#| fig-cap: \"Die Post-Verteilung f√ºr den Parameter sigma, m43a\"\n\nm43a_post %>% \n  ggplot(aes(x = sigma)) +\n  geom_density(fill = \"orange\")\n```\n\n\nAlternativ kann man sich die Verteilung eines Parameters auch so ausgeben lassen,\ngleich mit Intervallgrenzen, z.B. 95%, s.@fig-m43a-plot.\n\n```{r}\n#| label: fig-m43a-plot\n#| fig-cap: \"Die Parameter Gewicht (zentriert) und sigma des Modells m43a\"\nm43a_hdi <- hdi(m43a_post)  # analog mit eti(m43a)\n\nplot(m43a_hdi)\n```\n\nErg√§nzt man bei `plot()` noch `show_intercept = TRUE` wird auch der Achsenabschnitt angezeigt.\n\n\n\n\n\n### Streuungsma√üe zu den Parametern\n\n\n- Wie unsicher sind wir uns in den Sch√§tzungen der Parameter?\n\n\n\nDiese Frage wird durch die Ungewissheitsintervalle in der Ausgabe beantwortet.\n\n\n:::callout-note\nAn einigen Stellen wird empfohlen, anstelle eines (gebr√§uchlichen) 95%-Intervalls \nauf ein 90%- oder 89%-Intervall auszuweichen, aufgrund der besseren numerischen Stabilit√§t.\n:::\n\n\n### Ungewissheit von $\\alpha$ und $\\beta$ aus der Post-Verteilung visualisiert\n\n\n\nDie ersten 10 Stichproben:\n\n```{r Post-Regression-befragen-10, echo = TRUE}\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 10),\n    aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .3)\n```\n\n\nDie ersten 100 Stichproben:\n\n```{r Post-Regression-befragen-11-ersten-1000, echo = TRUE}\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 100),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .1)\n```\n\n\nDie ersten `1e3` Stichproben:\n\n```{r Post-Regression-befragen-11-die-ersten-1000, echo = TRUE}\nd2 %>% \n  ggplot(aes(x = weight_c, \n             y = height)) +\n  geom_point() +\n  geom_abline(\n    data = m43a_post %>% \n      slice_head(n = 1e3),\n     aes(slope = weight_c,\n        intercept = `(Intercept)`),\n    alpha = .01)\n```\n\n\n\n\nDie ersten 1000000 ... okay, lassen wir es gut sein^[Im Standard beschert uns `stan_glm()` 4000 Stichproben.].\n\n\n\nEinfacher ist die Visualisierung mit `estimate_expectation`:\n\n```{r}\nestimate_expectation(m43a) %>% plot()\n```\n\n\n### Fragen zu Quantilen des Achsenabschnitts \n\n:::callout-note\nZur Erinnerung: Bei einem zentrierten Pr√§diktor misst der Achsenabschnitt die mittlere Gr√∂√üe.\n:::\n\n- Welche mittlere Gr√∂√üe wird mit zu 50%, 90% bzw. 95% Wahrscheinlichkeit nicht √ºberschritten?\n- Welche mittlere Gr√∂√üe mit zu 95% Wskt. nicht unterschritten?\n- Von wo bis wo reicht der innere 50%-Sch√§tzbereich der mittleren Gr√∂√üe?\n\n\n\nQuantile:\n\n\n```{r quantile-post}\nm43a_post %>% \n  summarise(\n    q_50 = quantile(`(Intercept)`, prob = .5),\n    q_90 = quantile(`(Intercept)`, prob = .9),\n    q_05 = quantile(`(Intercept)`, prob = .95))\n```\n\n50%-PI:\n\n```{r}\nm43a %>% \n  eti(ci = .5)\n```\n\n\n\n### Fragen zu Wahrscheinlichkeitsmassen des Achsenabschnitts \n\n\n\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe bei mind. 155 cm liegt?\n\n\n```{r echo = TRUE}\nm43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n))\n```\n\n```{r}\n#| echo: false\nwskt_gross <- \n  m43a_post %>% \n  count(gross = `(Intercept)` >= 155) %>% \n  mutate(prop = n / sum(n)) %>% \n  pull(prop) %>% \n  `[`(2) %>% \n  round(2)\n```\n\nDie Wahrscheinlichkeit betr√§gt `r wskt_gross`.\n\n\nWie wahrscheinlich ist es, dass die mittlere Gr√∂√üe h√∂chstens 154.5 cm betr√§gt?\n\n\n```{r echo = TRUE}\nm43a_post %>% \n  count(klein = (`(Intercept)` <= 154.5)) %>% \n  mutate(prop = n / sum(n))\n```\n\n```{r wsktklein}\n#| echo: false\nwskt_klein <- \n  m43a_post %>% \n  count(klein = `(Intercept)` <= 154.5) %>% \n  mutate(prop = n / sum(n)) %>% \n  pull(prop) %>% \n  `[`(2) %>% \n  round(2)\n```\n\n\nDie Wahrscheinlichkeit betr√§gt `r wskt_klein`.\n\n\n\n\n\n\n<!-- ### Ungewissheit von Achsenabschnitt und Steigung  -->\n\n<!-- ... als Histogramme visualisiert -->\n\n<!--  -->\n\n<!-- ### Achsenabschnitt -->\n\n<!-- ```{r Post-Regression-befragen-13, echo = TRUE, eval = TRUE} -->\n<!-- post_m43a %>%  -->\n<!--   ggplot(aes(x = a)) + -->\n<!--   geom_density() -->\n<!-- ``` -->\n\n<!-- ] -->\n\n<!-- .pull-right[ -->\n\n<!-- ### Regressionsgewicht (Steigung) -->\n\n<!-- ```{r Post-Regression-befragen-14, echo = TRUE} -->\n<!-- post_m43a %>%  -->\n<!--   ggplot(aes(x = b)) + -->\n<!--   geom_density() -->\n<!-- ``` -->\n‚Äö\n<!-- ] -->\n\n\n\n### Typischer Bayes-Nutzer in Aktion\n\n![Typischer Bayes-Nutzer, der ein Ungewissheitsintervall berechnet. Bildquelle: Easystats, bayestestR](img/bayesianMaster.jpg){width=\"50%\" fig-align=\"center\"}\n\n[Quelle](https://easystats.github.io/bayestestR/articles/bayestestR.html)\n\n\n\n\n\n## Post-Verteilung bedingt auf einen Pr√§diktorwert\n\n\n### Visualisierung\n\n\nWas ist wohl die Wahrscheinlichkeit der K√∂rpergr√∂√üe bei einem bestimmten Gewicht?\n\nAngenommen wir wissen, dass das Gewicht bei, sagen wir 45 kg liegt.\nWelche K√∂rpergr√∂√üe ist (im Schnitt) zu erwarten? Wie unsicher sind wir uns √ºber diesen Mittelwert?\n\nEtwas formaler ausgedr√ºckt:\n\n$\\mu|\\text{weight}=45$\n\n\n45 kg entspricht genau dem Mittelwert von `weight`. Geht man von zentrierten Pr√§diktorwerten aus, gilt in dem Fall `weight_c = 0`.\nErstellen wir uns dazu eine Tabelle:\n\n\n```{r mu-at-45-def, echo = TRUE}\nmu_at_45 <-\n  m43a_post %>% \n  mutate(mu_at_45 = `(Intercept)`)\n```\n\nUnd plotten diese, s. @fig-mu-at-45.\n\n```{r Post-Regression-befragen-15, echo = TRUE, eval = FALSE}\n#| eval: false\n\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density()\n```\n\n\n\n```{r Post-Regression-befragen-17}\n#| echo: false\n#| label: fig-mu-at-45\n#| fig-cap: \"Post-Verteilung der Gr√∂√üe (laut unserem Modell) bei einem Gewicht von 45kg\"\nmu_at_45 %>% \n  ggplot(aes(x = mu_at_45)) +\n  geom_density() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 45\"])) +\n  scale_x_continuous(limits = c(150, 160))\n```\n\n\nAnalog k√∂nnen wir fragen,\nwie gro√ü wohl eine Person mit 50 kg im Mittelwert sein wird und wie (un)gewiss wir uns √ºber diesen Mittelwert sind.\n\n\n50 kg, das sind 5 √ºber dem Mittelwert, in zentrierten Einheiten ausgedr√ºckt also `weight_c = 5`. Auch dazu erstellen wir uns eine Tabelle.\n\n\n\n```{r mu-at-50, echo = TRUE}\nmu_at_50 <-\n  mu_at_45 %>% \n  mutate(mu_at_50 = `(Intercept)` + 5 * weight_c)\n\nhead(mu_at_50)\n```\n\nDie Verteilung der mittleren Gr√∂√üe bei einem Gewicht von 50kg ist weiter \"rechts\" (Richtung h√∂here Gr√∂√üe) zentriert, s. @fig-mu-at-50.\n\n\n```{r Post-Regression-befragen-16, echo = TRUE, eval = FALSE}\n#| eval: false\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density()\n```\n\n\n\n\n\n```{r Post-Regression-befragen-18}\n#| echo: false\n#| label: fig-mu-at-50\n#| fig-cap: Post-Verteilung der mittleren Gr√∂√üe (laut unserem Modell) bedingt auf ein Gewicht von 50 kg\nmu_at_50 %>% \n  ggplot(aes(x = mu_at_50)) +\n  geom_density() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 50\"])) +\n  scale_x_continuous(limits = c(150, 160))\n```\n\n\n\n\n### Lagema√üe und Streuungen\n\nBefragen wir die bedingte Post-Verteilung. Eine erste Frage zielt nach den typischen deskriptiven Statistiken, also nach Lage und Streuung der Verteilung der K√∂rpergr√∂√üe.\n\n\n\n\nWas ist das 90% PI f√ºr $\\mu|w=50$ ?\n\n```{r Post-Regression-befragen-19, echo = TRUE}\nmu_at_50 %>% \n  eti(mu_at_50, ci = .9)\n```\n\nDie mittlere Gr√∂√üe - gegeben $w=50$ - liegt mit 90% Wahrscheinlichkeit zwischen den beiden Werten (ca.) 159cm und 160cm.\n\n\n\nWelche mittlere Gr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, wenn die Person 45kg wiegt?\n\n```{r Post-Regression-befragen-20, echo = TRUE}\nmu_at_45 %>% \n  summarise(q_95 = quantile(mu_at_45, prob = .95))\n```\n\n\n\n\n## Die PPV befragen\n\n\n\n\n\n\n\n\nDie Posterior-Pr√§diktiv-Verteilung (PPV) gibt uns die M√∂glichkeit,\nnach der Wahrscheinlichkeit *tats√§chlicher* K√∂rpergr√∂√üen zu fragen - \nund nicht nur nach *mittleren* K√∂rpergr√∂√üen anhand der Post-Verteilung.\n\n\n:::callout-important\nDie Post-Verteilung macht nur Aussagen zur mittleren K√∂rpergr√∂√üe,\ndenn das ist was wir modellieren wollten.\nM√∂chten wir Aussagen zur Wahrscheinlichkeit tats√§chlicher Gr√∂√üen treffen,\nbrauchen wir die PPV.\n:::\n\n\n### Perzentil-Intervalle f√ºr verschiedenen Pr√§diktor-Werte\n\n\nWir erstellen uns eine Sequenz an Pr√§diktorwerten, die uns interessieren, `weight_df`:\n\n```{r echo = TRUE}\nweight_df <- tibble(weight_c = seq(-20,20, by = 5))\n```\n\n\nF√ºr diese Werte lassen wir uns dann die Perzentil-Intervalle (PI) ausgeben:\n\n```{r Post-Regression-befragen-21, echo = TRUE}\nmus <- \n  predictive_interval(\n    m43a, \n    seed = 42,\n    newdata = weight_df) %>% \n  as_tibble() %>% \n  bind_cols(weight_df)\n\nhead(mus)\n```\n\nUm die Perzentilintervalle zu erstellen, wird von `predictive_interval()` f√ºr jeden Pr√§diktorwert eine PPV erstellt und (in der Voreinstellung) das 5%- sowie 95%-Quantil daf√ºr berechnet. \nSie k√∂nnen die Voreinstellung √§ndern mittels des Arguments `prob`;\num ein 89%-PI zu berechnen, w√ºrde man z.B. schreiben `prob = .89`.\n\nUm Reproduzierbarkeit sicherzustellen,\nhaben wir mit `seed = 42` die Zufallszahlen fixiert.\n\nWir sehen etwa, dass wir bei einer Person mittleren Gewichts, eine K√∂rpergr√∂√üe von ca. 146 cm bis 163 cm zu erwarten haben (95%-KI).\nHoppla! Das ist ja viel ungenauer, als die Angaben der Post-Verteilung oben.\nJa, denn die Post-Verteilung hat die Ungewissheit zum *Mittelwert* ausgedr√ºckt;\ndie PPV gibt die Ungewissheit *tats√§chlicher* beobachtbarer K√∂rpergr√∂√üen aus,\nnicht nur die Ungewissheit zum Mittelwert.\n\n\nBerechnen wir die PPV f√ºr `m43a`:\n\n```{r ppv-m43a}\nppv_m43a <- posterior_predict(\n  m43a,\n  newdata = weight_df,\n  draws = 100) %>% \n  as_tibble() %>% \n  pivot_longer(\n    cols = everything(),\n    names_to = \"weight_condition\",\n    values_to = \"height\")\n```\n\n\n\nHier ist ein Auszug aus der PPV-Tabelle:\n\n\n\n\n```{r Post-Regression-befragen-23}\n#| echo: false\nmus %>% \n  head() %>% \n  relocate(weight_c, .before = 1) %>% \n  gt() %>% \n  fmt_number(everything(), decimals = 1)\n```\n\n\n\n\n\n\n### Perzentilintervalle f√ºr verschiedenen Pr√§diktorwerte visualisiert\n\n@fig-m43a-nochmal visualisiert die Ungewissheit von Vorhersagen laut der PPV.\nDie Ungewissheit in @fig-m43a-nochmal ist die Antwort auf die Frage: \"Wie sicher sind wir uns,\nzur Gr√∂√üe einer !Kung-Person, gegeben dass die z.B. 10 kg mehr als der Durchschnitt wiegt?\"\nEine Vorhersage bezeichnet man auch als \"bedingte Verteilung\", da man den Wert einer Verteilung voraussagt,\n*gegeben* einer Bedingung, z.B. `weight_c = 10`.  \n\n\n```{r mus-d2}\n#| echo: false\n#| label: fig-m43a-nochmal \n#| fig-cap: \"Visualisierung der Ungewissheit der Vorhersagen laut PPV: Die Vorhersage von Beobachtungen beinhaltet mehr Ungewissheit als die Vorhersage von zu erwartenden Werten, daher sind die Ungewissheitsintervalle der PPV gr√∂√üer als die der Post-Verteilung.\"\nmus <- \n  mus %>% \n  mutate(height = 154.6 + 0.9*weight_c)\n\nd2 %>% \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point() +\n  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = \"blue\") +\n  geom_errorbar(data = mus,\n                aes(ymin = `5%`,\n                    ymax = `95%`),\n                size = .5,\n                width = .5,\n                color = \"firebrick\")\n```\n\n\nDie vertikalen Balken geben die 95%-KI wieder, die wir jeweils zu erwarten haben.\n\nNoch eine andere Visualisierung, s. @fig-katzenaugen; \nje dicker die \"Katzenaugen\", desto mehr Stichproben (samples) liegen vor an der Stelle,\nund umso genauer ist die Sch√§tzung.\n\n\n```{r ppv-m43-weight}\n#| echo: false\n#| label: fig-katzenaugen\n#| fig-cap: Die PPV f√ºr bestimmte Gewichtswerte w, visualisiert mit Katzenaugen-Diagrammen\nppv_m43_weight_df <-\n  posterior_predict(m43a,\n                    newdata = weight_df) %>% \n  as_tibble() %>% \n  pivot_longer(everything(),\n               names_to = \"weight_condition\",\n               values_to = \"height\")\n\nweight_df <-\n  weight_df %>% \n  mutate(weight_condition = as.character(c(1:9)))\n\nppv_m43_weight_df <- \n  ppv_m43_weight_df %>% \n  full_join(weight_df, by = \"weight_condition\")\n\nd2 %>% \n  ggplot() +\n  geom_violin(data = ppv_m43_weight_df,\n              aes(x = weight_c, y = height, group = weight_c),\n                fill = \"grey80\",\n              width = 1) +\n    geom_point(aes(x = weight_c, y = height)) +\n  geom_abline(slope = coef(m43a)[2], intercept = coef(m43a)[1], color = \"blue\")\n```\n\n\nAlso: Je dicker die Violine, desto wahrscheinlicher $\\mu | w_i$.\n\n\n\n### Die PPV visualisiert\n\nGerade eben haben wir bedingte PPVen angeschaut: Also eine PPV f√ºr einen bestimmten Pr√§diktorwert, z.B. bei einer Person mittleren Gewichts.\nWir k√∂nnen auch den Mittelwert √ºber alle bedingten PPV anschauen, sozusagen die \"Master-PPV\" oder \"unbedingte PPV\" oder schlicht PPV.\nVergleichen wir die echten Werte f√ºr `height`, $y$, mit den von der PPV simulierten Werten f√ºr `height`, $y_{rep}$, s. @fig-ppv-check.\n\n```{r ppv-plot1}\n#| label: fig-ppv-check\n#| fig-cap: Vergleich der Vorhersagen f√ºr y (leichte, blaue Linien) mit der beobachteten Verteilung von y\ncheck_predictions(m43a) \n```\n\n`?check_predictions` zeigt Hilfe f√ºr diese Funktion. \nDie Funktion zeigt die Vorhersagen f√ºr die AV laut der Posteriori-Verteilung.\n\n\n\nDie zwei Gipfel hat unser Modell nicht mitgekriegt, \nansonsten decken sich die Vorhersagen der PPV gut mit den echten Daten.\n\n\n\n\n\n\n\n\n### Fragen an die PPV\n\n- Wie gro√ü sind die !Kung im Schnitt?\n- Welche Gr√∂√üe wird von 90% der Personen nicht √ºberschritten?\n- Wie gro√ü sind die 10% kleinsten?\n\n```{r Post-Regression-befragen-29, echo = TRUE }\nppv_m43a %>% \n  summarise(\n    q_10 = quantile(height, prob = .1),\n    height_mean = mean(height),\n    q_50 = quantile(height, prob = .5),\n    q_90 = quantile(height, prob = .9)\n  )\n```\n\n\nWas ist der 50% Bereich der K√∂rpergr√∂√üe?\n\n```{r Post-Regression-befragen-30, echo = TRUE}\nppv_m43a %>% \n  eti(ci = .5)\n```\n\n\n## Aufgaben\n\n\n\n- [Bayes-Ziel1](https://datenwerk.netlify.app/posts/bayes-ziel1/bayes-ziel1)\n- [Bayesmod-bestimmen01](https://datenwerk.netlify.app/posts/bayesmod-bestimmen01/bayesmod-bestimmen01)\n- [Likelihood2](https://datenwerk.netlify.app/posts/likelihood2/likelihood2)\n- [Post-befragen1](https://datenwerk.netlify.app/posts/post-befragen1/post-befragen1)\n- [Postvert-Regr-01](https://datenwerk.netlify.app/posts/postvert-regr-01/postvert-regr-01)\n- [regression1a](https://datenwerk.netlify.app/posts/regression1a/regression1a.html)\n- [Regression2](https://datenwerk.netlify.app/posts/regression2/regression2)\n- [Bed-Post-Wskt1](https://datenwerk.netlify.app/posts/bed-post-wskt1/bed-post-wskt1)\n- [Priorwahl1](https://datenwerk.netlify.app/posts/priorwahl1/priorwahl1)\n- [Bayesmod-bestimmen02\n](https://datenwerk.netlify.app/posts/bayesmod-bestimmen02/bayesmod-bestimmen02)\n- [Aussagen-einfache-Regr](https://datenwerk.netlify.app/posts/aussagen-einfache-regr/aussagen-einfache-regr)\n- [Likelihood-identifizieren](https://datenwerk.netlify.app/posts/likelihood-identifizieren/likelihood-identifizieren)\n- [Priorwahl2](https://datenwerk.netlify.app/posts/priorwahl2/priorwahl2)\n- [penguins-stan-01](https://datenwerk.netlify.app/posts/penguins-stan-01/penguins-stan-01.html)\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":true,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"lineare-modelle.html"},"language":{},"metadata":{"lang":"de","fig-responsive":true,"quarto-version":"1.2.269","bibliography":["references.bib"],"editor":"source","knitr":{"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":true,"keep-source":false,"keep-hidden":false,"prefer-html":true,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"number-sections":true,"output-file":"lineare-modelle.pdf"},"language":{},"metadata":{"block-headings":true,"lang":"de","bibliography":["references.bib"],"editor":"source","knitr":{"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"colorlinks":true,"papersize":"a4"},"extensions":{"book":{}}}}}