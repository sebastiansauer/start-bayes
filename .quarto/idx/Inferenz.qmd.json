{"title":"Inferenz","markdown":{"headingText":"Inferenz","containsRefs":false,"markdown":"\n```{r}\n#| echo: false\n#| message: false\nlibrary(tidyverse)\nlibrary(easystats)\ntheme_set(theme_minimal())\n```\n\n\n\n![Bayes:Start!](img/Golem_hex.png){width=10%}\n\n\n\n\n\n\n\n\n## Lernsteuerung\n\n### Lernziele\n\nNach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.\n\nSie k√∂nnen ...\n\n\n\n- die Definition von Inferenzstatistik sowie Beispiele f√ºr inferenzstatistische Fragestellungen nennen\n- zentrale Begriffe nennen und in Grundz√ºgen erkl√§ren\n- den Nutzen von Inferenzstatistik nennen\n- erl√§utern, in welchem Zusammenhang Ungewissheit zur Inferenzstatistik steht\n- auch anhand von Beispielen erkl√§ren, was ein statistisches Modell ist\n- die Grundkonzepte der Regression angeben\n- Unterschiede zwischen klassischer und Bayes-Inferenz benennen\n- Vor- und Nachteile der klassischen vs. Bayes-Inferenz diskutieren\n- Die grundlegende Herangehensweise zur Berechnung des p-Werts informell erkl√§ren k√∂nnen\n\n\n### Begleitvideos\n\n- [Video zur Inferenz, Teil 1](https://youtu.be/gcwWwBy0kPI)\n- [Video zur Inferenz, Teil 2](https://https://youtu.be/QNMVi6IqQ90)\n\n\n## Wozu ist Statistik √ºberhaupt da?\n\nJa, diese Frage haben Sie sich auch schon mal gestellt? \n\nAbb. @fig-goals gibt einen √úberblick √ºber die Ziele der Statistik.\n\n```{mermaid}\n%%| label: fig-goals\n%%| fig-cap: A taxonomy of statistical goals\nflowchart LR\n  A{Goals} --> B(describe)\n  A --> C(predict)\n  A --> D(explain)\n  B --> E(distribution)\n  B --> F(assocation)\n  B --> G(extrapolation)\n  C --> H(point estimate)\n  C --> I(interval)\n  D --> J(causal inference)\n  D --> K(population)\n  D --> L(latent construct)\n\n```\n\n::: callout-note\nZiele existieren nicht \"in echt\" in der Welt. \nWir denken sie uns aus.\nZiele haben also keine ontologische Wirklichkeit,\nsie sind epistemologische Dinge (existieren nur in unserem Kopf).\nDas hei√üt, dass man sich nach Beliebem Ziele ausdenken kann.\nAllerdings h√ºlfe es, wenn man andere Menschen vom Nutzen der eigenen Ideen √ºberzeugen kann.\n:::\n\n\n\n\n\n## Was ist Inferenz?\n\n```{r}\n#| include: false\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(easystats)\n```\n\n\n\n\n### Inferenz als Generalisieren\n\nStatistische Inferenz sieht sich drei \"Herausforderungen\" gegen√ºber, laut  @gelman_regression_2021, Kap. 1.1. \nDiese betreffen das Schlie√üen (oder Generalisieren) vom Einzelfall auf das Allgemeine:\n\n1. Von der Stichprobe aus die Grundgesamtheit (Population)\n2. Von der Experimental- auf die Kontrollgruppe (Kausalinferenz)\n3. Von einem Messwert auf das zugrundeliegende Konstrukt\n\nIn diesem Kurs besch√§ftigen wir uns mit den ersten beiden Herausforderungen.\n\n\n\n::: callout-important\nStatistische Inferenz hat zum Ziel, vom Teil aufs Ganze zu schlie√üen, bzw. vom Konrketen auf das Abstrakte.\n:::\n\n## Stichprobe vs. Population\n\n\nNehmen wir an, wir m√∂chten herausfinden, wie gro√ü der Anteil der R-Fans an der Population der Studierenden ist. Den Anteil der F-Fans bezeichnen wir der Einfachheit halber hier mit `A`^[~~Meistens~~ Manchmal darf man bei der Statistik nicht nach einem tieferen Sinn suchen. Ist Statistik eine Art moderne Kunst?].\n\nDas *Grundproblem der Inferenzstatistik* ist, dass wir an Aussagen zur Grundgesamtheit interessiert sind, aber nur eine Stichprobe, also einen Ausschnitt oder eine Teilmenge der Grundgesamtheit vorliegen haben.\n\nWir m√ºssen also den Anteil der R-Fans auf Basis des Anteils in der Stichprobe f√ºr die Grundgesamtheit schlie√üen:\nWir verallgemeinern oder generalisieren von der Stichprobe auf die Grundgesamtheit, s. Abb. @fig-pop-sample.\n\n\n::: {#fig-pop-sample layout-ncol=\"2\"}\n![Population](img/pvoll.png){#fig-pop}\n\n![Sample](img/psti.png){#fig-sample}\n\nPopulation vs. sample (Image credit: Karsten Luebke)\n:::\n\n\n\nH√§ufig ist das praktische Vorgehen recht simpel: \nAh, in unserer Stichprobe sind 42% R-Fans!^[Mancheiner h√§tte mit mehr gerechnet]. Man schreibt: $p = 0.42$ (`p` wie `proportion`). Die Stichprobe sei repr√§sentativ f√ºr die Grundgesamtheit aller Studierender. \nMesserscharf schlie√üen wir:\nIn der Grundgesamtheit ist der Anteil der R-Fans auch 42%, $\\pi=0.42$.\n\n\n\n### Deskriptiv- vs. Inferenzstatistik\n\nStatistik gibt es in zwei Geschmacksrichtungen, k√∂nnte man sagen: Deskriptiv- und Inferenzstatistik, s. Abb. @fig-inf1.\nEinteilungen in Schubladen existieren nicht auf der Welt,\nsondern in unserem Kopf:\nSie besitzen keine ontologische Realit√§t, sondern eine epistemologische.\nSie sind frei, sich andere Einteilungen der Statistik auszudenken.\nEs hilft allerdings, wenn man andere Menschen vom Wert seiner Idee √ºberzeugen kann.\n\n![Deskriptiv- vs. Inferenzstatistik](img/desk_vs_inf-crop.png){#fig-inf1 width=70% fig-align=\"center\"}\n\n\n*Deskriptivstastistik* fasst Stichprobenmerkmale zu Kennzahlen (Statistiken) zusammen.\n\n*Inferenzstatistik* schlie√üt von Statistiken auf Parameter (Kennzahlen von Grundgesamtheiten).\n\nüèã Schlie√üen Sie die Augen und zeichnen Sie obiges Diagramm!\n\n\n\n### Wozu ist die Inferenstatistik gut?\n\n::: {#def-inferenz}\n\n## Inferent\nInferenz bedeutet Schlie√üen; auf Basis von vorliegenden Wissen wird neues Wissen generiert.\n\nInferenzstatistik ist ein Verfahren, das mathematische Modelle (oft aus der Stochastik) verwendet, um ausgehend von einer bestimmten Datenlage, die eine Stichprobe einer Grundgesamtheit darstellt, allgemeine Schl√ºsse zu ziehen.\n\n:::\n\n\n\n\n\nüèãÔ∏èÔ∏è Heute Nacht vor dem Schlafen wiederholen Sie die Definition. √úben Sie jetzt schon mal.\n\n\n### Deskriptiv- und Inferenzstatistik gehen Hand in Hand\n\nF√ºr jede beliebige Statistik (Kennzahl von Stichprobendaten) kann man die Methoden der Inferenzstatistik verwenden, s. Tabelle @tbl-kennwerte.\n\n```{r}\n#| echo: false\n#| label: tbl-kennwerte\n#| tbl-cap: Bezeichnungen f√ºr Kennwerte\n#| message: false\nx <- tribble(\n    ~Kennwert, ~Stichprobe, ~Grundgesamtheit,\n  \"Mittelwert\", \"$\\\\bar{X}$\", \"$\\\\mu$\",\n  \"Streuung\", \"$sd$\", \"$\\\\sigma$\",\n  \"Anteil\", \"$p$\", \"$\\\\pi$\",\n  \"Korrelation\", \"$r$\", \"$\\\\rho$\" ,\n  \"Regression\", \"$b$\", \"$\\\\beta$\"\n\n)\n\nkable(x, escape = FALSE, booktabs = TRUE, format = \"simple\") \n```\n\nF√ºr Statistiken (Daten einer Stichprobe) verwendet man *lateinische* Buchstaben; \nf√ºr Parameter (Population) verwendet man *griechische* Buchstaben.\n\nüèãÔ∏è Geben Sie die griechischen Buchstaben f√ºr typische Statistiken an!\n\n\n\n### Sch√§tzen von Parametern einer Grundgesamtheit\n\nMeist begn√ºgt man sich  beim Analysieren von Daten nicht mit Aussagen f√ºr eine Stichprobe, sondern will auf eine Grundgesamtheit verallgemeinern.\n\nLeider sind die Parameter einer Grundgesamtheit zumeist unbekannt, daher muss man sich mit *Sch√§tzungen* begn√ºgen.\n\nSch√§tzwerte werden mit einem \"Dach\" √ºber dem Kennwert gekennzeichnet, z.B.\n\n```{r}\n#| echo: false\nx <- tribble(\n    ~Kennwert, ~Stichprobe, ~Grundgesamtheit, ~Sch√§tzwert,\n  \"Mittelwert\", \"$\\\\bar{X}$\", \"$\\\\mu$\", \"$\\\\hat{\\\\mu}$\",\n  \"Streuung\", \"$sd$\", \"$\\\\sigma$\", \"$\\\\hat{\\\\sigma}$\",\n  \"Anteil\", \"$p$\", \"$\\\\pi$\", \"$\\\\hat{\\\\pi}$\",\n  \"Korrelation\", \"$r$\", \"$\\\\rho$\", \"$\\\\hat{\\\\rho}$\" ,\n  \"Regression\", \"$b$\", \"$\\\\beta$\", \"$\\\\hat{\\\\beta}$\"\n\n)\n\nkable(x, escape = FALSE, booktabs = TRUE, format = \"simple\") \n```\n\n### Beispiele f√ºr inferenzstatistische Fragestellungen\n\nSie testen zwei Varianten Ihres Webshops (V1 und V2), die sich im Farbschema unterscheiden und ansonsten identisch sind: Hat das Farbschema einen Einfluss auf den Umsatz?\n\n-   Dazu vergleichen Sie den mittleren Umsatz pro Tag von V1 vs. V2, $\\bar{X}_{V1}$ und $\\bar{X}_{V2}$.\n\n-   Die Mittelwerte unterscheiden sich etwas, $\\bar{X}_{V1} > \\bar{X}_{V2}$\n\n-   Sind diese Unterschiede \"zuf√§llig\" oder \"substanziell\"? Gilt also $\\mu_{V1} > \\mu_{V2}$ oder gilt $\\mu_{V1} \\le \\mu_{V2}$?\n\n-   Wie gro√ü ist die Wahrscheinlichkeit[^inferenz-1] $Pr(\\mu_{V1} > \\mu_{V2})$?\n\n[^inferenz-1]: oft mit *Pr* oder *p* abgek√ºrzt, f√ºr *probability*\n\nüèãÔ∏è *Predictive Maintenance* ist ein Anwendungsfeld inferenzstatistischer Modellierung. Lesen Sie dazu S. 3 [dieses Berichts](https://www.rolandberger.com/publications/publication_pdf/roland_berger_vdma_predictive_maintenance_d_1.pdf)!\n\n\n## Modellieren\n\n### Modellieren als Grundraster des Erkennens\n\nIn der Wissenschaft - wie auch oft in der Technik, Wirtschaft oder im Alltag - betrachtet man einen Teil der Welt n√§her, meist mit dem Ziel, eine Entscheidung zu treffen, was man tun wird oder mit dem Ziel, etwas zu lernen.\n\nNun ist die Welt ein weites Feld. \nJedes Detail zu ber√ºcksichtigen ist nicht m√∂glich.\nWir m√ºssen die Sache vereinfachen: Alle Informationen ausblenden, die nicht zwingend n√∂tig sind.\nAber gleichzeitig die Strukturelemente der wirklichen Welt, die f√ºr unsere Fragestellung zentral ist, beibehalten.\n\nDieses Tun nennt man *Modellieren*: Man erstellt sich ein Modell.\n\n::: callout-important\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.\n:::\n\n\nAuf die Statistik bezogen hei√üt das,\ndass man einen Datensatz zu zusammenfasst,\ndass man das Wesentliche erkennt.\nWas ist das \"Wesentliche\"? Meist interessiert man sich f√ºr die Ursachen eines Ph√§nomens? Etwa: \"Wie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?\"^[Das ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.]\nNoch allgemeiner ist vom h√§ufig am Zusammenhang von `X ` und `Y` interessiert, s. @fig-xy, linker Teil, die ein Sinnbild eines statistischen Modells widergibt.\n\n\n\n\n\n:::{#fig-xy fig-align=\"center\"}\n\n\n```{mermaid}\nflowchart LR\nX --> Y\n\n\nX1 --> Y2\nX2 --> Y2\n```\n\noben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (Ursachen)\n\n\n:::\n\n\n\nDas Diagramm hat Sie nicht so vom Hocker?\nOkay, ein statistisches Modell kann nat√ºrlich komplexer sein, z.B. wie in Abb. @fig-xy, rechter Teil, dargestellt.\n\n\n\n\nEs h√∂rt sich zugspitzt an, aber eigentlich ist fast alles Modellieren:\nWenn man den Anteil der R-Fans in einer Gruppe Studierender ausrechnet,\nmacht man sich ein Modell:\nman vereinfacht diesen Ausschnitt der Wirklichkeit anhand einer statistischen Kennzahl,\ndie das forschungsleitende Interesse zusammenfasst.\n\n### Vertiefung\n\nLesen Sie die Einf√ºhrung zum Thema Modellieren bei @poldrack_statistical_2022 (Kap. 5.1).\n\n\n:::callout-note\nNutzen Sie die √úbersetzungsfunktion Ihres Browsers, wenn Sie einen englischen Text lieber auf Deutsch lesen wollen. Oder einen deutschen lieber auf Englisch.\n:::\n\n\n## Regression\n\nEinflussreiche Leute schw√∂ren auf die Regressionsanalyse (@fig-gandalf).\n\n![One regression](img/einring.jpg){width=\"50%\" #fig-gandalf fig-align=\"center\"}\n\n\n\n### Regression zum Modellieren\n\nDie Regression ist eine Art Schweizer Taschenmessen: F√ºr vieles gut einsetzbar.\n\nAnstelle von vielen verschiedenen Verfahren des statistischen Modellierens kann man (fast) immer die Regression verwenden.\nDas ist nicht nur einfacher, sondern auch sch√∂ner. \nWir werden im Folgenden stets die Regression zum Modellieren verwenden.\n\n\nDann wenden wir die Methoden der Inferenz auf die Kennzahlen der Regression an.\n\n\n:::callout-note\nRegression + Inferenz = üíñ\n:::\n\n\n\nAlternativ zur Regression k√∂nnte man sich in den Wald der statistischen Verfahren begeben, [wie hier von der Uni M√ºnster als Ausschnitt (!) aufgef√ºhrt](https://web.archive.org/web/20091029162244/http://www.wiwi.uni-muenster.de/ioeb/en/organisation/pfaff/stat_overview_table.html).\n\nAuf dieser Basis kann man meditieren,\nwelches statistischen Verfahren man f√ºr eine bestimmte Fragestellung verwenden sollte, s. Abb.  @fig-choose-test.\n\n![W√§hle deine Statistik mit Bedacht](img/choose-test.png){#fig-choose-test}\n\n### Viele statistische Verfahren sind Spezialf√§lle der Regression\n\nWie Jonas Kristoffer Lindel√∏v uns erkl√§rt, sind viele statistische Verfahren, wie der sog. t-Test Spezialf√§lle der Regression, s. Abb. @fig-lindeloev.\n\n\n![Common statistical tests as linear models](img/linear_tests_cheat_sheet.png){#fig-lindeloev}\n\n\n\n### In voller Pracht\n\n\nHier ist die Regressionsgleichung in voller Pracht; Abb. @fig-regr-rules.\n\n\n$$y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + \\epsilon$$\n\n\nAnhan der Gleichung erkennt man auch, warum man von einem *linearen Modell* spricht: \nY wird als gewichteter Mittelwert mehrerer Summanden berechnet.\nDabei wird X nicht mit \"fortgeschrittenen\" Transformationen wie Quadradieren oder Exponenzieren begl√ºckt, sondern nur mit den Regressiongewichten multipliziert.\n\n\n```{r}\n#| message: false\n#| echo: false\n#| label: fig-regr-rules\n#| fig-cap: Die Regressionsgerade in voller Pracht\ndata(mtcars)\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal()\n\n```\n\n\n\n## Unsicherheit\n\n### Inferenz beinhaltet Unsicherheit\n\nInferenzstatistische Schl√ºsse sind mit Unsicherheit behaftet: Schlie√ülich kennt man nur einen Teil (die Stichprobe) eines Ganzen (die Population), m√∂chte aber vom Teil auf das Ganze schlie√üen.\n\n\n\n:::callout-important\nNichts Genaues wei√ü man nicht: Schlie√üt man von einem Teil auf das Ganze, so geschieht das unter Unsicherheit. Man spricht von Ungewissheit, da man die Unsicherheit das Wissen √ºber das Ganze betrifft.\n:::\n\n\nSchlie√üt man etwa, dass in einer Grundgesamtheit der Anteil der R-Fans bei 42% liegt, so geschieht das unter Unsicherheit.\nMan ist sich nicht sicher, dass es wirklich 42% in der Population sind - und nicht etwa etwas mehr oder etwas weniger.\nSchlie√ülich hat man *nicht* die ganze Population gesehen bzw. vermessen. \n*Sicher* ist man sich hingegen f√ºr die Stichprobe (Messfehler einmal ausgeblendet).\n\n\nZur Bemessung der Unsicherheit (Ungewissheit) bedient man sich der Wahrscheinlichkeitsrechnung (wo immer m√∂glich).\n\nDie Wahrscheinlichkeitstheorie bzw. -rechnung wird auch als die Mathematik des Zufalls bezeichnet.\n\n::: {#def-zufall}\n\n## Zuf√§lliges Ereignis\n\nUnter einem zuf√§lligen Ereignis (random) verstehen wir ein Ereignis, das nicht (komplett) vorherzusehen ist, wie etwa die Augenzahl Ihres n√§chsten W√ºrfelwurfs. Zuf√§llig bedeutet nicht (zwangsl√§ufig), dass das Ereignisse keine Ursachen besitzt. So gehorchen die Bewegungen eines W√ºrfels den Gesetzen der Physik, nur sind uns diese oder die genauen Randbedingungen nicht (ausreichend) bekannt.\n\n:::\n\nüèã Welche physikalischen Randbedingungen wirken wohl auf einen M√ºnzwurf ein?\n\n### Beispiele zur Quantifizierung von Ungewissheit\n\nAussagen mit Unsicherheit k√∂nnen unterschiedlich pr√§zise formuliert sein.\n\n-   Morgen regnet's $\\Leftrightarrow$ Morgen wird es hier mehr als 0 mm Niederschlag geben ($p=97\\%$).\n\n-   Methode $A$ ist besser als Methode $B$ $\\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 57% ist der Mittelwert f√ºr Methode $A$ h√∂her als f√ºr Methode $B$.\n\n-   Die Maschine f√§llt demn√§chst aus $\\Leftrightarrow$ Mit einer Wahrscheinlichkeit von 97% wird die Maschine in den n√§chsten 1-3 Tagen ausfallen, laut unserem Modell.\n\n-   Die Investition lohnt sich $\\Leftrightarrow$ Die Investition hat einen Erwartungswert von 42 Euro; mit 90% Wahrscheinlichkeit wird der Gewinn zwischen -10000 und 100 Euro.\n\nüèã Geben Sie weitere Beispiele an!\n\n\n\n\n### Zwei Arten von Ungewissheit\n\nIm Modellieren im Allgemeinen und in Regressionsmodellen im Besonderen lassen sich (mindestens) zwei Arten von Ungewissheiten angeben, s. auch Abb. @fig-zwei-arten.\n\n\n1. Wie (un)gewiss ist man sich √ºber den Wert des Regressionsgewichts?\n\n2. Wie (un)gewiss ist man sich √ºber den Wert von Y? Schlie√ülich k√∂nnte es ja Einfl√ºsse (X) geben, die man nicht ber√ºcksichtigt hat.\n\n\n```{mermaid}\n%%| label: fig-zwei-arten\n%%| fig-cap: Zwei Arten der Ungewissheit beim Modellieren\nflowchart LR\nX1 -->|Wie stark ist der Einfluss?|B\nX2 -. Haben wir vielleicht X2 √ºbersehen? .-> B\n\n```\n\n\n\n\n### Ich wei√ü, was ich nicht wei√ü: Ungewissheit angeben\n\n\nStreng genommen ist eine Inferenz aus Angabe der Ungewissheit (Genuaigkeit der Sch√§tzung) wertlos.\nAngenommen, jemand sagt, dass sie den Anteil der R-Fans (in der Population) auf 42% sch√§tzt, l√§sst aber offen wie *sicher* (pr√§zise) die Sch√§tzung ist.\nWir wissen also nicht, ob z.B. 2% oder 82% noch erwartbar sind. Oder ob man im Gegenteil mit hoher Sicherheit sagen kann, die Sch√§tzung schlie√üt sogar 41% oder 43% aus.\n\n:::callout-important\nEine Inferenz nennt man auch Sch√§tzung. \nEs sollte immer die Genauigkeit (Ungewissheit) der Sch√§tzung angegeben werden.\n:::\n\n\n\nIm Rahmen der Regressionsanalyse schl√§gt sich die Ungewissheit an zwei Stellen nieder:\n\n1.  zur Lage der Regressionsgeraden ($\\beta_0$, $\\beta_1$)\n2.  zu Einfl√ºssen (X), die unser Modell nicht kennt ($\\epsilon, \\sigma$)\n\n\n\n### Visualisierung von Ungewissheit\n\n\n::: {#def-punktschaetzer}\n\n## Punktsch√§tzer\n\nGibt man nur einen Punktwert an, wie 42%, als Ergebnis einer Inferenz, spricht man von einem *Punktsch√§tzer*.\n\n\nPunktsch√§tzer beinhalten *keine Angabe* der Sch√§tz(un)genauigkeit, s. Abb. @fig-punktschaetzer2, links. Rot markiert: Die Punktsch√§tzung von `mpg` f√ºr `hp=200`.\n\n:::\n\n\n![Eine Punktsch√§tzung und ihre Ungewissheit](img/fig-punktschaetzer.png){#ig-punktschaetzer2}\n\n\n```{r fig-punktschaetzer}\n#| echo: false\n#| fig-cap: \"\"\n#| label: fig-punktschaetzer2\n#| message: false\n#| eval: true\n\nlm1_glm <- lm(mpg ~ hp, data = mtcars)\n\nmtcars <-\n  mtcars %>%\n  mutate(pred = 30 - hp*0.07)\n\n\npred_interval <-\n  tibble(\n    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),\n    mpg = predict(lm1_glm, newdata = data.frame(hp)),\n    lwr = mpg - 2*3,\n    upr = mpg + 2*3\n  )\n\nplot1 <-\n  ggplot(mtcars,\n       aes(x = hp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  annotate(\"point\", x = 200,\n           y = predict(lm1_glm, newdata = data.frame(hp = 200)),\n           color = \"red\",\n           alpha = .5,\n           size = 5)\n\n\nlm1_glm <- lm(mpg ~ hp, data = mtcars)\n\nmtcars <- \n  mtcars %>% \n  mutate(pred = 30 - hp*0.07)\n\n\npred_interval <-\n  tibble(\n    hp = seq(min(mtcars$hp), max(mtcars$hp), by = 1),\n    mpg = predict(lm1_glm, newdata = data.frame(hp)),\n    lwr = mpg - 2*3,\n    upr = mpg + 2*3\n  )\n\n\nplot2 <-\n  ggplot(mtcars,\n       aes(x = hp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  annotate(\"point\", x = 200,\n           y = predict(lm1_glm, newdata = data.frame(hp = 200)),\n           color = \"red\",\n           alpha = .5,\n           size = 5)\n\n\n# plots(plot1, plot2, n_rows = 1,\n#       title = c(\"Eine Punktsch√§tzung mittels einer Regressionsanalyse \\nohne (links) bzw. mit Ungewissheitsintervall (rechts, in grau)\"))\n\n```\n\n\n\n\n\n\n\n\n\nIn Abb. @fig-punktschaetzer2, rechts, ist die Ungewissheit in den Regressionskoeffizienten visualisiert: Wie sicher sind wir uns zur St√§rke des Zusammenhangs von X und Y, vgl. @def-punktschaetzer.\n\n\n\nAuch wenn wir uns *sicher* im Hinblick auf die Regressionsgewichte in Abb. @fig-ungewiss2 *bliebe eine Restungewissheit*:\nUnsere Sch√§tzungen w√§ren auch dann nicht sicher, nicht fehlerfrei.\nDas liegt daran, da das Modell nicht alle Einfl√ºsse auf Y ber√ºcksichtigt, sondern nur einen, hier als X bezeichnet.\n\nIn Abb. @fig-ungewiss2 ist nicht nur die Ungewissheit durch die Regressionsgewichte, sondern auch die \"Restungewissheit\" dargestellt. In diesem Fall spricht man von einem \"Vorhersageintervall\", da man nicht nur von \"typischen F√§llen\" auf der Regressiongeraden spricht, sondern f√ºr echte F√§lle Vorhersagen (Sch√§tzungen) t√§tigt, wo auch die zweite Art von Ungewissheit relevant ist.\n\n\n![Das Vorhersageintevall zeigt eine Punktsch√§tzung und ihre Ungewissheit](img/fig-predintervall.png)\n\n\n```{r p-zweifach}\n#| echo: false\n#| fig-cap: \"Zweifache Ungewissheit in den Regressionskoeffizienten - Vorhersageintervall\"\n#| label: fig-ungewiss2\n#| message: false\n\npred_interval2 <-\n  predict(lm1_glm,\n          newdata = data.frame(hp = pred_interval$hp),\n          interval = \"prediction\") %>%\n  as_tibble() %>%\n  rename(mpg = fit) %>% \n  mutate(hp = pred_interval$hp)\n\n\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point()+\n  geom_ribbon(data = pred_interval2,\n              aes(ymin = lwr, ymax = upr,\n                  y = mpg,\n                  x = hp),\n              fill = \"blue\",\n              alpha = .1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  annotate(\"point\", x = 200,\n           y = predict(lm1_glm, newdata = data.frame(hp = 200)),\n           color = \"red\",\n           alpha = .5,\n           size = 5)\n```\n\n\n\n\nWie man sieht, wird die Ungewissheit *gr√∂√üer*, wenn man beide Arten der Ungewissheit ber√ºcksichtigt. Das Vorhersage-Intervall ber√ºcksichtigt Ungewissheit in $\\beta_0, \\beta_1, \\epsilon$ bei der Vorhersage von $\\hat{y_i}$.\n\n\nüèã Geben Sie ein vergleichbares Beispiel an!\n\n### Konfidenzintervall\n\n\nWir sehen hier, dass ein \"Ungewissheitskorridor\" angegeben wird. \nEntsprechend wird nicht ein *Punktsch√§tzer*, sondern ein *Sch√§tzbereich* angegeben.\nMan spricht auch von einem *Konfidenzintervall* oder *Unsicherheitsbereich*^[Tats√§chlich gibt es mehrere Synonyme oder √§hnliche Begriffe f√ºr Konfidenzintervall. Wir kommen sp√§ter darauf detaillierter zu sprechen.]\n\n::: {#def-konfintervall}\n\n## Konfidenzintervall\n\nEin Konfidenzintervall (confidence intervall, CI) ist ein Oberbegriff f√ºr Sch√§tzbereiche. Die Grenzen eines Konfindenzintervall markieren einen Bereich plausibler Werte f√ºr einen Parameter. \n\n:::\n\n\nEin Konfidenzintervall wird h√§ufig mit 90% oder 95% Genauigkeit angegeben.  Im Kontext der Bayes-Analyse ist das einfach zu interpretieren. \nSagen wir, wir finden, dass in einem Modell ein 95%-Konfidenzintervall f√ºr den Anteil der R-Fans angegeben wird, dass sich von 40 bis 44 Prozent erstreckt.\nDieser Befund l√§sst sich so interpretieren: \"Laut Modell liegt der gesuchte Anteil mit einer Wahrscheinlichkeit von 95% im Bereich von 44 bis 44 Prozentpunkten.\"\n\n\n\n\n\nüèã Interpretieren Sie den Ungewissheitskorridor!\n\n## Klassische vs. Bayes-Inferenz\n\n### Klassische Inferenz: Frequentismus\n\n-   Die Ber√ºcksichtigung von Vorwissen zum Sachgegenstand wird vom Frequentismus als subjektiv zur√ºckgewiesen.\n-   Nur die Daten selber fliesen in die Ergebnisse ein\n-   Wahrscheinlichkeit wird √ºber relative H√§ufigkeiten definiert.\n-   Es ist nicht m√∂glich, die Wahrscheinlichkeit einer Hypothese anzugeben.\n-   Stattdessen wird angegeben, wie h√§ufig eine vergleichbare Datenlage zu erwarten ist, wenn die Hypothese gilt und der Versuch sehr h√§ufig wiederholt ist.\n-   Ein Gro√üteil der Forschung (in den Sozialwissenschaften) verwendet diesen Ansatz.\n\n### Bayesianische Inferenz\n\n-   Vorwissen (Priori-Wissen) flie√üt explizit in die Analyse ein (zusammen mit den Daten).\n-   *Wenn* das Vorwissen gut ist, wird die Vorhersage genauer, ansonsten ungenauer.\n-   Die Wahl des Vorwissens muss explizit (kritisierbar) sein.\n-   In der Bayes-Inferenz sind Wahrscheinlichkeitsaussagen f√ºr Hypothesen m√∂glich.\n-   Die Bayes-Inferenz erfordert mitunter viel Rechenzeit und ist daher erst in den letzten Jahren (f√ºr g√§ngige Computer) komfortabel geworden.\n\n### Vergleich von Wahrscheinlichkeitsaussagen\n\n#### Frequentismus\n\nDie zentrale Statistik hei√üt der *p-Wert*\n\nDer p-Wert ist so definiert: \"Wie wahrscheinlich ist der Wert der Teststatistik (oder noch extremere Werte), vorausgesetzt die Nullhypothese gilt und man wiederholt den Versuch unendlich oft (mit gleichen Bedingungen, aber zuf√§llig verschieden und auf Basis unseres Modells)?\"\n\nFindet man $p<.05$ (oder einen anderen Prozentwert, aber meistens wird 5% hergenommen), so spricht man von \"(statistischer) Signifikanz\" und nimmt dies als Beleg, dass man einen Effekt gefunden hat, die Hypothese eines Nulleffekts (z.B. kein Zusammenhang von X und Y) also verwerfen kann.\n\n#### Bayes-Statistik\n\nDie zentrale Statistik ist die *Posteriori-Verteilung*.\n\nDie Posteriori-Verteilung beantwortet uns die Frage: \"Wie wahrscheinlich ist die Forschungshypothese, jetzt, nachdem wir die Daten kennen, auf Basis unseres Modells?\"\n\nüèã Recherchieren Sie eine Definition des p-Werts und lesen Sie sie genau.\n\n\n[In diesem Post](https://data-se.netlify.app/2022/01/27/warum-bayes/) wird f√ºr Bayes geworben und (vielleicht einseitig) Stellung pro Bayes bezogen.\n\n\n\n### Frequentist und Bayesianer\n\n\nIm Cartoon 1132 [von xkcd](https://xkcd.com/) wird sich √ºber das Nicht-Ber√ºcksichtigen von Vorab-Informationen (Prior-Verteilung) lustig gemacht, s. @fig-xkcd-bayes.\n\n![Frequentist wettet mit Bayesianer](img/frequentists_vs_bayesians_2x.png){#fig-xkcd-bayes width=50%}\n\n[Quelle](https://xkcd.com/1132/)\n\n### Der p-Wert ist wenig intuitiv\n\n<a href=\"https://imgflip.com/i/6m29tz\"><img src=\"https://i.imgflip.com/6m29tz.jpg\" title=\"made at imgflip.com\" width=\"250\"/></a>\n\n<div>\n\n<a href=\"https://imgflip.com/memegenerator\">from Imgflip Meme Generator</a>\n\n</div>\n\n### Beispiel zum Nutzen von Apriori-Wissen 1\n\nEin Betrunkener behauptet, er k√∂nne hellsehen.\nEr wirft eine M√ºnze 10 Mal und sagt jedes Mal korrekt vorher, welche Seite oben landen wird.\n\n Die Wahrscheinlichkeit dieses Ergebnisses ist sehr gering ($2^{-10}$) unter der Hypothese, dass die M√ºnze fair ist, dass Ergebnis also \"zuf√§llig\" ist.\n\nUnser Vorwissen l√§sst uns allerdings trotzdem an der Hellsichtigkeit des Betrunkenen zweifeln, so dass die meisten von uns die Hypothese von der Zuf√§lligkeit des Ergebnisses wohl nicht verwerfen.\n\n### Beispiel zum Nutzen von Apriori-Wissen 2\n\nEine Studie (vgl. @gelman_regression_2021) fand einen \"gro√üen Effekt\" auf das Einkommen von Babies, eine Stunde pro Woche w√§hrend zwei Jahren an einem psychosozialen Entwicklungsprogramm teilnahmen (im Vergleich zu einer Kontrollgruppe), $n=127$.\n\nNach 20 Jahren war das mittlere Einkommen der Experimentalgruppe um 42% h√∂her (als in der Kontrollgruppe) mit einem Konfidenzintervall von \\[+2%,+98%\\].\n\nAllerdings l√§sst uns unser Vorwissen vermuten, dass so ein Treatment das Einkommen nach 20 Jahren kaum verdoppeln l√§sst. Wir w√ºrden den Effekt lieber in einem konservativeren Intervall sch√§tzen (enger um Null).\n\n\n\n## Literatur\n\nBei @gelman_regression_2021, Kap. 1 findet sich eine Darstellung √§hnlich zu der in diesem Kapitel.\n\n\n\n\n\n## Fazit\n\n\n\n:::callout-important\n[Kontinuierliches Lernen](https://imgflip.com/i/77wn7m) ist der Schl√ºssel zum Erfolg.\n:::\n\n\n\n\n## Aufgaben\n\n\n1. [Griech-Buchstaben-Inferenz](https://datenwerk.netlify.app/posts/griech-buchstaben-inferenz/griech-buchstaben-inferenz/)\n2. [korr-als-regr](https://datenwerk.netlify.app/posts/korr-als-regr/korr-als-regr/)\n3. [ttest-als-regr](https://datenwerk.netlify.app/posts/ttest-als-regr/ttest-als-regr/)\n4. [ttest-skalenniveau](https://datenwerk.netlify.app/posts/ttest-skalenniveau/ttest-skalenniveau/)\n5. [adjustieren2](https://datenwerk.netlify.app/posts/adjustieren2/adjustieren2/)\n6. [inferenz-fuer-alle](https://datenwerk.netlify.app/posts/inferenz-fuer-alle/inferenz-fuer-alle)\n7. [adjustieren1](https://datenwerk.netlify.app/posts/adjustieren1/adjustieren1.html)\n8. [ungewiss-arten-regr](https://datenwerk.netlify.app/posts/ungewiss-arten-regr/ungewiss-arten-regr.html)\n9. [vorhersageintervall1](https://datenwerk.netlify.app/posts/vorhersageintervall1/vorhersageintervall1.html)\n10. [lm-standardfehler](https://datenwerk.netlify.app/posts/lm-standardfehler/lm-standardfehler)\n11. [punktschaetzer-reicht-nicht](https://datenwerk.netlify.app/posts/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht.html)\n\n\n\n\n\n## ---\n\n\n\n![](img/outro-02.jpg){width=100%}\n\n\n\n\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":true,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"Inferenz.html"},"language":{"toc-title-document":"Inhaltsverzeichnis","toc-title-website":"Auf dieser Seite","related-formats-title":"Andere Formate","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Quelle","section-title-abstract":"Zusammenfassung","section-title-appendices":"Anhang","section-title-footnotes":"Fu√ünoten","section-title-references":"Literatur","section-title-reuse":"Wiederverwendung","section-title-copyright":"Urheberrechte","section-title-citation":"Zitat","appendix-attribution-cite-as":"Bitte zitieren Sie diese Arbeit als:","appendix-attribution-bibtex":"Mit BibTeX zitieren:","title-block-author-single":"Autor:in","title-block-author-plural":"Autor:innen","title-block-affiliation-single":"Zugeh√∂rigkeit","title-block-affiliation-plural":"Zugeh√∂rigkeiten","title-block-published":"Ver√∂ffentlichungsdatum","title-block-modified":"Ge√§ndert","callout-tip-title":"Tipp","callout-note-title":"Hinweis","callout-warning-title":"Warnung","callout-important-title":"Wichtig","callout-caution-title":"Vorsicht","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Gesamten Code zeigen","code-tools-hide-all-code":"Gesamten Code verbergen","code-tools-view-source":"Quellcode anzeigen","code-tools-source-code":"Quellcode","code-line":"Zeile","code-lines":"Zeilen","copy-button-tooltip":"In die Zwischenablage kopieren","copy-button-tooltip-success":"Kopiert","repo-action-links-edit":"Seite editieren","repo-action-links-source":"Quellcode anzeigen","repo-action-links-issue":"Problem melden","back-to-top":"Zur√ºck nach oben","search-no-results-text":"Keine Treffer","search-matching-documents-text":"Treffer","search-copy-link-title":"Link in die Suche kopieren","search-hide-matches-text":"Zus√§tzliche Treffer verbergen","search-more-match-text":"weitere Treffer in diesem Dokument","search-more-matches-text":"weitere Treffer in diesem Dokument","search-clear-button-title":"Zur√ºcksetzen","search-detached-cancel-button-title":"Abbrechen","search-submit-button-title":"Abschicken","search":"Suchen","toggle-sidebar":"Seitenleiste umschalten","toggle-dark-mode":"Dunkelmodus umschalten","toggle-reader-mode":"Lesemodus umschalten","toggle-navigation":"Navigation umschalten","crossref-fig-title":"Abbildung","crossref-tbl-title":"Tabelle","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Korollar","crossref-prp-title":"Aussage","crossref-cnj-title":"Annahme","crossref-def-title":"Definition","crossref-exm-title":"Beispiel","crossref-exr-title":"√úbungsaufgabe","crossref-ch-prefix":"Kapitel","crossref-apx-prefix":"Anhang","crossref-sec-prefix":"Kapitel","crossref-eq-prefix":"Gleichung","crossref-lof-title":"Abbildungsverzeichnis","crossref-lot-title":"Tabellenverzeichnis","crossref-lol-title":"Listingverzeichnis","environment-proof-title":"Beweis","environment-remark-title":"Anmerkung","environment-solution-title":"L√∂sung","listing-page-order-by":"Sortieren nach","listing-page-order-by-default":"Voreinstellung","listing-page-order-by-date-asc":"Datum (aufsteigend)","listing-page-order-by-date-desc":"Neueste","listing-page-order-by-number-desc":"Absteigend","listing-page-order-by-number-asc":"Aufsteigend","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beschreibung","listing-page-field-author":"Autor:in","listing-page-field-filename":"Dateiname","listing-page-field-filemodified":"Ge√§ndert","listing-page-field-subtitle":"Untertitel","listing-page-field-readingtime":"Lesezeit","listing-page-field-categories":"Kategorien","listing-page-minutes-compact":"{0} min","listing-page-category-all":"alle","listing-page-no-matches":"Keine Treffer"},"metadata":{"lang":"de","fig-responsive":true,"quarto-version":"1.3.247","bibliography":["references.bib"],"editor":"source","knitr":{"opts_knit":{"verbose":true,"fig-align":"center"},"opts_chunk":{"collapse":true,"R.options":{"knitr.graphics.auto_pdf":true}}},"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}}}