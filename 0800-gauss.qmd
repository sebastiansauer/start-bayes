# Gauss-Modelle

![Bayes:Start!](img/Golem_hex.png){width="10%"}

## Lernsteuerung

### Position im Modulverlauf

@fig-modulverlauf gibt einen √úberblick zum aktuellen Standort im Modulverlauf.

### Lernziele

Nach Absolvieren des jeweiligen Kapitels sollen folgende Lernziele erreicht sein.

Sie k√∂nnen ‚Ä¶

- ein Gau√ümodell spezifizieren und in R berechnen
- an Beispielen verdeutlichen, wie sich eine vage bzw. eine informationsreiche Priori-Verteilung auf die Posteriori-Verteilung auswirkt

### Begleitendes Lehrmaterial

Der Stoff dieses Kapitels orientiert sich an @mcelreath2020, Kap. 4.1 bis 4.3.
Im YouTube-Kanal des Autors finden sich passende Videos wie üì∫ [Teil 1](https://youtu.be/cYHArln1DkM) und üì∫ [Teil 2](https://youtu.be/qIuu-4qRT_0).


### Vorbereitung im Eigenstudium

-   [Statistik1, Kap. "Modellg√ºte"](https://statistik1.netlify.app/060-modellguete)
-   [Statistik1, Kap. "Punktmodelle 2"](https://statistik1.netlify.app/070-zusammenhaenge)
-   [Statistik1, Abschnitt "Normalverteilung"](https://statistik1.netlify.app/040-verbildlichen#normalverteilung)

### Ben√∂tigte R-Pakete

F√ºr `rstanarm` wird ggf. [weitere Software](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started) ben√∂tigt.

::: callout-note
Software, und das sind R-Pakete, m√ºssen Sie nur einmalig installieren. 
Aber bei jedem Start von R bzw. RStudio m√ºssen Sie die (ben√∂tigten!) Pakete starten.

:::

```{r load-libs-hidden}
#| include: false
library(gt)
library(patchwork)
library(figpatch)
library(ggExtra)
library(tidyverse)
library(easystats)
#library(plotly)

theme_set(theme_modern())
```

```{r load-libs-non-hidden}
#| message: false
library(tidyverse)  # Datenjudo
library(rstanarm)  # Bayes-Modelle berechnen
library(easystats)  # Statistik-Komfort
library(DataExplorer)  # Daten verbildlichen
library(ggpubr)  # Daten verbildlichen
library(hexbin)  # stat_bin_hex ggplot2
```

::: callout-important
Ab diesem Kapitel ben√∂tigen Sie das R-Paket `rstanarm`. $\square$
:::

### Ben√∂tigte Daten

Wir ben√∂tigen den Datensatz *!Kung*. Quelle der Daten ist @mcelreath2020 mit Bezug auf Howell.

```{r Post-Regression-3}
Kung_path <-  
  "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/Howell1a.csv"  

kung <- read.csv(Kung_path) 

head(kung, n = 5)
```

[Datenquelle](https://raw.githubusercontent.com/sebastiansauer/2021-wise/main/Data/Howell1a.csv)

{{< downloadthis data/Howell1a.csv dname="Howell1a" label = "Download CSV">}}
{{< downloadthis data/Howell1a.xlsx dname="Howell1a" label = "Download XLSX">}}

### Einstieg

::: {#exm-gauss}
### Was war noch mal eine Normalverteilung?

In diesem Kapitel ben√∂tigen Sie ein gutes Verst√§ndnis der Normalverteilung (die auch als Gauss-Verteilung bezeichnet wird). 
Fassen Sie daher die wesentlichen Aspekte der Normalverteilung (soweit im Unterricht behandelt) zusammen! $\square$
:::

::: {#exm-post-gauss}
### Was war noch mal eine Posteriori-Verteilung?

In diesem Kapitel befragen wir die Post-Verteilung f√ºr ein normalverteilte Zufallsvariable, n√§mlich die K√∂rpergr√∂√üe der !Kung San.
Was war noch mal eine Post-Verteilung und wozu ist sie gut? $\square$
:::



### Stan stellt sich vor


![Hallo, Leute! Ich bin Stan! Ich mache hier die Schwerarbeit.](img/Golem_hex.png){width="30%"}


## Wie gro√ü sind die !Kung San?

Dieser Abschnitt basiert auf @mcelreath2020, Kap. 4.3.

### !Kung San

In diesem Abschnitt untersuchen wir eine Forschungsfrage in Zusammenhang mit dem Volk der !Kung.

> The «ÉKung are one of the San peoples who live mostly on the western edge of the Kalahari desert, Ovamboland (northern Namibia and southern Angola), and Botswana.The names «ÉKung («ÉXun) and Ju are variant words for 'people', preferred by different «ÉKung groups. This band level society used traditional methods of hunting and gathering for subsistence up until the 1970s. Today, the great majority of «ÉKung people live in the villages of Bantu pastoralists and European ranchers.

[Quelle](https://en.wikipedia.org/wiki/%C7%83Kung_people)

Wir interessieren uns f√ºr die Gr√∂√üe der erwachsenen !Kung, 
also filtern wir die Daten entsprechend und speichern die neue Tabelle als `kung_erwachsen`.

```{r Kung-5}
kung_erwachsen <- kung %>% 
  filter(age >= 18)

nrow(kung_erwachsen)
```

$N=`r nrow(kung_erwachsen)`$.

Lassen wir uns einige typische deskriptive Statistiken zum Datensatz ausgeben. `{easystats`} macht das tats√§chlich recht easy, s. @tbl-kung.

```{r Kung-7, echo = TRUE, eval = FALSE}
#| eval: false
describe_distribution(kung_erwachsen)
```

```{r Kung-7a, eval = TRUE}
#| echo: false
#| label: tbl-kung
#| tbl-cap: Statistiken der metrischen Variablen im Kung-Datensatz

describe_distribution(kung_erwachsen) %>% 
  gt() %>% 
  fmt_number(columns = c(3:last_col()-1)) %>% 
  fmt_integer(columns = last_col())
```

Die Verteilungen lassen sich mit `plot_density` (aus `{DataExplorer}`), s. @fig-kung-dens.

```{r}
#| label: fig-kung-dens
#| fig-cap: Verteilungen der Variablen im Kung-Datensatz. Gr√∂√üe und Gewicht sind recht symmetrisch bzw. normalverteilt; Alter ist rechtsschief.

plot_density(kung_erwachsen)
```

### Wir gehen apriori von normalverteilter Gr√∂√üe Der !Kung aus

*Forschungsfrage:* Wie gro√ü sind die erwachsenen !Kung im *Durchschnitt*?

Wir interessieren uns also f√ºr den Mittelwert der K√∂rpergr√∂√üe einer erwachsenen !Kung-Person, $\mu$.
Der Einfachheit halber gehen wir davon aus, dass Frauen und M√§nner im Schnitt gleich gro√ü sind.

![Mensch, [Wikimedia Commons](https://creativecommons.org/licenses/by-sa/3.0)[^0800-gauss-2]](img/human.png){width="5%"}

[^0800-gauss-2]: Bildquelle: Own alterations andFile:SVG_Human_With_All_Organs.svg by Madhero88, CC BY-SA, 3.0





```{r p1-p2}
#| echo: false
p_nv_kung_prior <-
  tibble(x = seq(from = 100, to = 250, by = .1)) %>% 
  ggplot(aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +
  geom_line(color = blue) +
  scale_x_continuous(breaks = seq(from = 100, to = 250, by = 75)) +
  labs(title = "mu ~ dnorm(178, 20)",
       y = "",
       x = "Mittelwert der K√∂rpergr√∂√üe, mu") +
  scale_y_continuous(breaks = NULL)

p_exp_kung_prior <-
  tibble(x = seq(0, 50, by = .01)) %>%
  ggplot(aes(x = x, y = dexp(x, rate = .1))) +
  geom_line(color = green) +
  scale_x_continuous() +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "sigma ~ dexp(0.1)",
       x = "Streuung der K√∂rpergr√∂√üen, sigma")
```

## Unser Gauss-Modell der !Kung

### Normalverteilung als Grundlage des Modells

Hier gehen wir von einer Normalverteilung (synonym: "Gauss-Verteilung") des Populationsmittelwert, $\mu$,
sowie der tats√§chlichen K√∂rpergr√∂√üen der einzelnen Personen, $h_i$ (*h* wie *height*) aus.

Zur Erinnerung: Die (unstandardisierte) Post-Verteilung ist das Produkt von Apriori und Likelihood, 
s. @fig-priori-x-lik-is-post.
Im Folgenden gehen wir diese Bestimmungsst√ºcke der Reihe nach durch, in gewohnter Manier.

![Apriori mal Likelihood ist gleich der unstandardisierten Post-Verteilung](img/apriori_x_lik_is_post.png){#fig-priori-x-lik-is-post}


Nur dass wir dieses Mal die Bayesbox nicht von Hand berechnen, 
sondern Stan die Arbeit √ºberlassen.
Stan liefert uns brav eine Stichproben-Post-Verteilung zur√ºck.

ü§ñ Ich berechne dir die Stichproben-Postverteilung, ganz ohne Bayesbox!

üßë‚Äçüè´ Toll, dann hab ich ja nix zu tun!


### Apriori-Verteilungen

Wir haben zwei Apriori-Gr√∂√üen (Parameter):

1. Den *Mittelwert* der K√∂rpergr√∂√üen in der Population, $\mu$. Dieser Parameter beantwortet die Frage: "Wie gro√ü sind die erwachsenen !Kung im Durchschnitt?"
2. Die *Streuung* der tats√§chlichen K√∂rpergr√∂√üen um den Mittelwert der Population herum, $\sigma$. Dieser Parameter beantwortet die Frage: "Wie unterschiedlich gro√ü sind die erwachsenen !Kung?"




Apriori-Verteilung f√ºr $\mu$: Der Mittelwert der K√∂rpergr√∂√üe, $\mu$, sei *normalverteilt* mit $\mu=178$ und $\sigma=20$:

$$\color{blue}{\mu \sim \mathcal{N}(178, 20)} \qquad{\text{Prior}}$$


Apriori-Verteilung f√ºr $\sigma$: die Streuung f√ºr den  $\sigma$ der Gr√∂√üen sei *exponentialverteil*  (da notwendig positiv) mit $\lambda = 1/8$.

$$\color{green}{\sigma \sim \mathcal{E}(1/8)} \qquad{\text{Prior}}$$
Warum gerade $\lambda=1/8$?
Das ist einfach ein grobes Absch√§tzen mit Blick auf @fig-exps:
Bei $\lambda=1/8$ liegt der Median bei ca. 5 cm.
Eine Streuung von ca. 5 cm um den Mittelwert herum erscheint nicht ganz falsch.
Dann kann man folgern: $95\%KI( \mu): 178 \pm 40$.
In Worten: 95% der erwachsenen !Kung sind zwischen 138 cm und 218 cm gro√ü - laut unserem Modell (unserer Apriori-Verteilung).
Das ist ein ausreichend gro√üer Bereich,
um √úberraschungen zuzulassen, aber eng genug, um biologisch unm√∂gliche Werte auszuschlie√üen.

In @fig-kung-model sind unsere Priori-Verteilungen visualisiert.

```{r Kung-10}
#| echo: false
#| label: fig-kung-model
#| fig-cap: Prioris unseres (ersten) Kung-Modells (`m_kung`)
#| fig-asp: 0.4
#| fig-subcap: 
#|   - Priori der mittleren K√∂rpergr√∂√üe
#|   - Priori der Sch√§tzungenauigkeit

p_nv_kung_prior
p_exp_kung_prior
```

::: callout-note
Dieses Modell hat zwei Parameter, $\mu$ und $\sigma$. $\square$
:::




Warum 178 cm? Kein besonderer Grund. Hier wollen wir den Effekt verschiedener Priori-Werte untersuchen.[^0800-gauss-5] 
In einer echten Untersuchung sollte man einen inhaltlichen Grund f√ºr einen Priori-Wert haben. 
*Oder* man w√§hlt "schwach informative" Prioris, wie das `{rstanarm}` im Standard tut: 
Damit l√§sst man kaum Vorab-Information in das Modell einflie√üen, 
aber man verhindert extreme Prioris, die meistens unsinnig sind (so wie eine SD von 100 Metern bei der K√∂rpergr√∂√üe).

[^0800-gauss-5]: Der Autor des zugrundeliegenden Lehrbuchs, Richard McElreath, gibt 178cm als seine K√∂rpergr√∂√üe an.

::: callout-note
Wir haben zwar vorab nicht viel Wissen, aber auch nicht gar keines: 
Eine Gleichverteilung der K√∂rpergr√∂√üen kommt nicht in Frage und ein vages Wissen zum Mittelwert haben wir auch. 
Dar√ºber hinaus ist eine Normalverteilung f√ºr K√∂rpergr√∂√üe biologisch nicht unplausibel und spiegelt sich in den Daten wider, s. @fig-kung-dens.
:::




### Likelihood

F√ºr viele Auspr√§gungen von $\mu$ und $\sigma$ m√ºssen wir (bzw. Stan) die jeweilige Likelihood berechnen.
Z.B. ist zu fragen, wie gro√ü die Wahrscheinlichkeit ist, 
dass wir einen !Kung finden mit K√∂rpergr√∂√üe 190 bis 191 cm ($h_i = [190,191]$),
gegeben der Hypothesen (Parameterwerte), 
dass der Populationsmittelwert $\mu=170$ cm und der Streuung der K√∂rpergr√∂√üen $\sigma = 10$ cm betr√§gt.
Nehmen wir an, dass die K√∂rpergr√∂√üen, $h_i$ normalverteilt sind,
dann k√∂nnen wir die Likelihood anhand der Quantile der Normalverteilung berechnen.
Etwa so:

$$L = Pr(h_i = [190;191]\quad |\mu=180, \sigma=10)$$

Aber da wir das Rechnen an Stan geben,
begn√ºgen wir uns mit einer Kurz-Schreibweise

$$\textcolor{orange}{h_i} \sim \mathcal{\textcolor{orange}{N}}(\textcolor{blue}{\mu}, \textcolor{green}{\sigma})
\qquad
\textcolor{black}{\textcolor{orange}{Likelihood}}$$

Lies: "Die K√∂rpergr√∂√üe ist normalverteilt mit Mittelwert $\mu$ und Streuung $\sigma$."
Stan wei√ü dann, was er zu tun hat.
F√ºr die Post-Verteilung muss Stan f√ºr alle plausiblen Kombinationen von $\mu$ und $\sigma$ die Likelihoods berechnen, s. @fig-mod-kung1.






```{r}
#| eval: false
#| echo: false
source("R-Code/Kruschke-plot3.R")
```


![Die Verteilung der der K√∂rpergr√∂√üen, $h_i$ setzt sich aus zwei Verteilungen zusammen: Dem Mittelwert $\mu$ und der exponentialverteilten Streuung $\sigma$ ](img/kruschke_plot3.png){#fig-mod-kung1 width=75%}




Jetzt haben wir unser Modell (`m_kung`) definiert!

Weil es so sch√∂n ist, schreiben/zeichnen wir es hier noch einmal auf, @eq-mod-kung1.

$$
\begin{aligned}
\mu &\sim \mathcal{N}(M=178, S=20) & \text{Prior} \\
\sigma &\sim \mathcal{E}(1/8) & \text{Prior} \\
h_i &\sim \mathcal{N}(\mu, \sigma) & \text{Likelihood}  \\
\end{aligned}
$$ {#eq-mod-kung1}


### Post-Verteilung berechnen mit Stan

Zur Berechnung von `m_kung` nutzen wir jetzt dieses Mal aber *nicht* die Bayesbox, 
sondern lassen Stan (in R) die Arbeit verrichten.





Okay, Stan, du Golem unseres Vertrauens! An die Arbeit! Berechne uns das Kung-Modell! 


```{r}
#| results: hide
# library(rstanarm)  # nicht vergessen, das Paket zu starten
m_kung <- 
  stan_glm(height ~ 1, # <1>
  prior_intercept = normal(178, 20), # <2>
  prior_aux = exponential(1/8),  # <3>
  refresh = 0,  # <4>
  data = kung_erwachsen)  

m_kung_post <- as_tibble(m_kung)    # <5>
names(m_kung_post) <- c("mu", "sigma")  # <6>  
```
1.  Stan berechnet die Post-Verteilung f√ºr die K√∂rpergr√∂√üen, $h_i$, hier `height` genannt
2.  Apriori f√ºr $\mu$
3.  Apriori f√ºr $\sigma$
4.  Stan soll nicht so gesch√§tzig sein und alle seine Stichproben am Bildschirm zeigen, sondern nur das Wichtigste zur√ºckmelden.
5.  Modellergebnis in Tabelle umwandeln
6.  Sch√∂nere Namen f√ºr die Spalten geben

Mit `stan_glm` rufen wir Stan zur Arbeit.
`stan_glm`[^0800-gauss-8] ist eine Funktion,
mit der man Regressionsmodelle berechnen kann. 
Nun haben wir in diesem Fall kein "richtiges" Regressionsmodell. Man k√∂nnte sagen, wir haben eine AV (K√∂rpergr√∂√üe), aber keine UV (keine Pr√§diktoren). 
Gl√ºcklicherweise k√∂nnen wir auch solche "armen" Regressionsmodelle formulieren: 
`av ~ 1` bzw. in unserem Beispiel `height ~ 1` bedeutet, 
dass man nur die Verteilung der AV berechnen m√∂chte, 
aber keine Pr√§diktoren hat (das soll die `1` symbolisieren). 

[^0800-gauss-8]: aus dem R-Paket `rstanarm`, das zuvor installiert und gestartet sein muss, bevor Sie den Befehl nutzen k√∂nnen.


Betrachten wir die Post-Verteilungen von $\mu$ und von $\sigma$, fig-kung3.

```{r Kung-22}
#| echo: false
#| label: fig-kung3
#| fig-cap: Die beiden Randverteilungen der Post-Verteilungen, d.h. die Verteilungen f√ºr mu und f√ºr sigma
#| fig-asp: 0.5

m_kung_post %>% 
  pivot_longer(mu:sigma) %>% 
  ggplot(aes(x = value)) + 
  geom_density(fill = "grey33") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(NULL) +
  theme(
    panel.grid = element_blank(),
    strip.text = element_text(size = 16)  # increase facet header font size
  ) +
  facet_wrap(~ name, scales = "free", 
             labeller = label_parsed,
             ncol = 2)
```





Plotten wir mal die *gemeinsame* Post-Verteilung von `m_kung`, s. @fig-m_kung_neue_prioris-post-joint,
also die Kombinationen, die "P√§rchen" der Werte von Mittelwert und Streuung.

::: panel-tabset

### Fliesendiagramm

Gemeinsame Post-Verteilung von Mittelwert, $\mu$ und Streuung, $\sigma$

```{r post-m_kung-plot}
#| echo: true
#| label: fig-m_kung_neue_prioris-post-joint
#| fig-cap: "Die gemeinsame Post-Verteilung von Mittelwert und Streuung von m_kung_neue_prioris"

m_kung_post %>% 
  ggplot() +
  aes(x = mu, y = sigma) %>% 
  geom_hex() +
  scale_fill_viridis_c() 
```

### Streudiagramm


```{r Kung-5-bis}
#| echo: false
#| fig-cap: "Die Postverteilung in unterschiedlicher Darstellung"
#| label: fig-m_kung_neue_prioris-post-anders1


p_m_kung_post <- 
  m_kung_post %>% 
  ggplot() +
  aes(x = mu, y = sigma) +
  geom_point(alpha = .1) 

p10 <- ggExtra::ggMarginal(p_m_kung_post, type = "density")

p20 <- 
  m_kung_post %>% 
  ggplot(aes(x = mu)) + 
  geom_histogram()

p10
```

### Histogramm

Und hier kommt die Post-Verteilung nur des Mittelwerts.

Nat√ºrlich k√∂nnen wir auch nur von einem einzelnen Parameter (z.B. Mittelwert) die Verteilung untersuchen, s. @fig-m_kung_neue_prioris-post-anders2.

```{r}
#| echo: false
#| fig-cap: Die Post-Verteilung von mu in m_kung_neue_prioris; ein Balkendiagramm bietet sich an.
#| label: fig-m_kung_neue_prioris-post-anders2
p20
```

:::

Da das Modell *zwei* Parameter hat, k√∂nnen wir auch beide gleichzeitig plotten. Wie man sieht, sind die beiden Parameter unkorreliert. In anderen Modellen k√∂nnen die Parameter korreliert sein.
@fig-m_kung_neue_prioris-post-joint erlaubt uns, f√ºr *jede Kombination von Mittelwert und Streuung* zu fragen, wie wahrscheinlich diese bestimmte Kombination ist.


Fassen wir die Ergebnisse dieses Modells zusammen:

-   Wir bekommen eine Wahrscheinlichkeitsverteilung f√ºr $\mu$ und eine f√ºr $\sigma$ (bzw. eine zweidimensionale Verteilung, f√ºr die $\mu,\sigma$-Paare).

-   Trotz des eher vagen Priors ist die Streuung Posteriori-Werte f√ºr $\mu$ und $\sigma$ klein: Die gro√üe Stichprobe hat die Priori-Werte √ºberstimmt.

-   Ziehen wir Stichproben aus der Posteriori-Verteilung, so k√∂nnen wir interessante Fragen stellen.

## Hallo, Posteriori-Verteilung

... wir h√§tten da mal ein paar Fragen an Sie. üïµ

1.  Mit welcher Wahrscheinlichkeit ist die *mittlere* !Kung-Person gr√∂√üer als 1,55m?
2.  Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell?
3.  In welchem 90%-PI liegt $\mu$ vermutlich?
4.  Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?
5.  Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der "Best Guess"?

Antworten folgen etwas weiter unten.


### Posteriori-Stichproben von `stan_glm()` berechnen lassen

Mit `stan_glm()` k√∂nnen wir komfortabel die Posteriori-Verteilung berechnen. 
Die Gittermethode wird nicht verwendet, aber die Ergebnisse sind - f√ºr unsere F√§lle - √§hnlich. 
Es werden aber auch viele Stichproben simuliert (sog. MCMC-Methode). 

Grob gesagt berechnen wir die Post-Verteilung mit `stan_glm` so: `stan_glm(AV ~ UV, data = meine_daten)`.


Wir k√∂nnen, wie wir es oben getan haben, uns die Stichproben der Post-Verteilung ausgeben lassen, 
und diese z.B. plotten.

Wir k√∂nnen es aber auch komfortabler haben ... Mit dem Befehl `parameters` kann man sich die gesch√§tzten Parameterwerte einfach ausgeben lassen (s. @fig-m_kung_neue_prioris-post-joint).

```{r Kung-24, echo = TRUE, results="hide"}
parameters(m_kung)  # aus Paket `easystats`
```

```{r Kung-6}
#| echo: false
parameters(m_kung) %>% display()

ci_low <- parameters(m_kung)$CI_low |> round(2)
ci_high <- parameters(m_kung)$CI_high |> round(2)
y_pointestimate <- round(as.numeric(parameters(m_kung)$Median), 0)
```

Das Wesentliche: Unser Golem sch√§tzt den Gr√∂√üenmittelwert der Kung auf ca. `r y_pointestimate`cm bzw. 
auf einen Bereich von etwa `r ci_low` bis `r ci_high` sch√§tzt. 
Informativ ist vielleicht noch, dass wir den `Prior` erfahren, der im Modell verwendet wurde. Dazu sp√§ter mehr.

::: callout-note
In dieser Ausgabe sind ein paar Angaben, die wir nicht verstehen, wie `pd`, `Rhat` und `ESS`. 
Kein Problem: Einfach ignorieren ü§ì Wer N√§heres wissen will, 
findet [hier](https://easystats.github.io/easystats/) einen Anfang. 
Au√üerdem sei an @mcelreath2020 und @gelman2021 verwiesen. $\square$
:::

## Wie tickt `stan_glm()`?


::::: columns
::: {.column width="20%"}
![Stan](img/stanlogo.png){width="50%"} 

[Quelle](https://mc-stan.org/)

![Hallo Leute!](img/Golem_hex.png){width="50%"}
:::

::: {.column width="80%"}
Hier ein paar Kerninfos zu `stan_glm`:

-   *Stan* ist eine Software zur Berechnung von Bayesmodellen; das Paket `rstanarm` stellt Stan f√ºr uns bereit.
-   `stan_glm()` ist f√ºr die Berechnung von Regressionsmodellen ausgelegt.
-   Will man nur die Verteilung einer einzelnen Variablen (wie `heights`) sch√§tzen, so hat man man ... eine Regression ohne Pr√§diktor.
-   Eine Regression ohne Pr√§diktor schreibt man auf Errisch so: `y ~ 1`. Die `1` steht also f√ºr die nicht vorhandene UV; `y` meint die AV (`height`).
-   `(Intercept)` (Achsenabschnitt) gibt den Mittelwert an.
:::
:::::

Mehr findet sich in der [Dokumentation von RstanArm](https://mc-stan.org/rstanarm/).

### Sch√§tzwerte zu den Modellparameter

Die Parameter eines Modells sind die Gr√∂√üen, f√ºr die wir eine Priori-Verteilung annehmen. 
Au√üerdem w√§hlen wir die Normalverteilung als Likelihood-Verteilung, 
so dass wir die Likelihood berechnen k√∂nnen. 
Auf dieser Basis sch√§tzen wir dann die Post-Verteilung. 
Ich sage *sch√§tzen*, um hervorzuheben, dass wir die wahren Werte nicht kennen, 
sondern nur eine Vermutung haben, unsere Ungewissheit vorab also (wie immer) in der Priori-Verteilung festnageln 
und unsere Ungewissheit nach Kenntnis der Daten in der Posteriori-Verteilung quantifizieren. 
Wie gerade gesehen, lassen sich die Modellparameter (bzw. genauer gesagt deren Sch√§tzungen) 
einfach mit `parameters(modellname)` auslesen.

### Stichproben aus der Posteriori-Verteilung ziehen

Wie wir es vom Globusversuch gewohnt sind, k√∂nnen wir aber auch Stichproben aus der Post-Verteilung ziehen.

Hier die ersten paar Zeilen von `m_kung_post`:

```{r Kung-26}
head(m_kung_post)
```

In einer Regression ohne Pr√§diktoren entspricht der Achsenabschnitt dem Mittelwert der AV, daher gibt uns die Spalte `(Intercept)` Aufschluss √ºber unsere Sch√§tzwerte zu $\mu$ (der K√∂rpergr√∂√üe).

:::: {#exr-kung1}
## Mit welcher Wahrscheinlichkeit ist $\mu>155$?

::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r Kung-28a, echo = TRUE}

names(m_kung_post) <- 
  c("mu", "sigma")  # den Namen "(Intercept)" durch "mu" ersetzen, ist pr√§gnanter

m_kung_post %>% 
  count(mu > 155) %>% 
  mutate(prop = n/sum(n))
```

Die Wahrscheinlichkeit ist nicht hoch, aber nicht auszuschlie√üen, dass die Kung im Schnitt gr√∂√üer als 155 cm sind. Wahrscheinlicher ist jedoch, dass sie kleiner als 155 cm sind. $\square$
:::
::::

:::: {#exr-kung2}
## Mit welcher Wahrscheinlichkeit ist $\mu>165$?

::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r Kung-28, echo = TRUE}
names(m_kung_post) <- 
  c("mu", "sigma")  # den Namen "(Intercept)" durch "mu" ersetzen, ist pr√§gnanter

m_kung_post %>% 
  count(mu > 165) %>% 
  mutate(prop = n/sum(n))
```

Oh, diese Hypothese k√∂nnen wir mit an Sicherheit grenzender Wahrscheinlichkeit ausschlie√üen. Aber Achtung: Das war eine Kleine-Welt-Aussage! Die Wahrscheinlichkeit, die Hypothese $\mu > 165$ auszuschlie√üen ist *nur* dann hoch, wenn das Modell gilt! Wenn also der Golem keinen Mist gebaut hat. Und sind wir mal ehrlich, der Golem tut, was sein:e Herr:in und Meister:in ihm befiehlt. Letztlich liegt es an uns, den Golem auf Spur zu kriegen.
:::
::::

:::: {#exm-kung3}
## Welche mittlere K√∂rpergr√∂√üe wird mit 95% Wahrscheinlichkeit nicht √ºberschritten, laut dem Modell `m_kung`?

::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r Kung-29, echo = TRUE}
m_kung_post %>% 
  summarise(q95 = quantile(mu, .95))
```
:::
::::

:::: {#exr-kung4}
## In welchem 90%-PI liegt $\mu$ vermutlich?

::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r Kung-30, echo = TRUE}
m_kung_post %>% 
  eti()
```

Ein ETI ist synonym zu PI.
:::
::::

:::: {#exr-kung5}
## Mit welcher Unsicherheit ist die Sch√§tzung der mittleren K√∂rpergr√∂√üe behaftet?

::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

```{r eval = FALSE}
m_kung %>% 
  parameters()
```

```{r}
#| echo: false
m_kung %>% 
  parameters() |> 
  display()
```

Seeing is believing, s. @fig-m_kung-params-intercept.

```{r}
#| fig-cap: "Parameter von m_kung, nur einer: der Intercept"
#| label: fig-m_kung-params-intercept
m_kung %>% 
  parameters() %>% 
  plot(show_intercept = TRUE)
```

Das Modell ist sich recht sicher: die Ungewissheit der mittleren K√∂rpergr√∂√üe liegt bei nicht viel mehr als einem Zentimeter (95%-CI).
:::
::::

:::: {#exr-kung6}
## Was ist der mediane Sch√§tzwert der mittleren K√∂rpergr√∂√üe, sozusagen der "Best Guess"?

::: {.callout-tip appearance="minimal" collapse="true"}
### L√∂sung

`parameters(m_kung)` hat uns die Antwort schon gegeben: Ca. 155 cm.
:::
::::

üèãÔ∏è √Ñhnliche Fragen bleiben als √úbung f√ºr die Lesis. ü§ì

### Standard-Prioriwerte bei `stan_glm()`

Man kann `stan_glm()` auch ohne Priori-Werte aufrufen.
In dem Fall bestimmt Stan die Priori-Werte selber.
Welche das sind, kann man sich so anzeigen lassen:

```{r Kung-8-bis, echo = TRUE}
prior_summary(m_kung)
```
Aber welche Priori-Werte verwendet Stan?
Ganz einfach: Stan zieht die Stichproben-Daten als Prioris heran.
Strenggenommen ist das nicht "pures Bayes", weil die Priori-Werte ja *vorab*, 
also vor Kenntnis der Daten bestimmt werden sollen. 


Man sollte diese Standardwerte als (komfortablen) Minimalvorschlag sehen. 
Kennt man sich im Sachgebiet aus, kann man meist bessere Prioris finden. 
Die Voreinstellung ist nicht zwingend; andere Werte w√§ren auch denkbar.

::: callout-note
### Standardwerte von `stan_glm`

-   `Intercept`: $\mu$, der Mittelwert der Verteilung $Y$
    -   $\mu \sim \mathcal{N}(\bar{Y}, sd(Y)\cdot 2.5)$
    -   als Streuung von $\mu$ wird die 2.5-fache Streuung der Stichprobe (f√ºr $Y$) angenommen.
-   `Auxiliary (sigma)`: $\sigma$, die Streuung der Verteilung $Y$
    -   $\sigma \sim \mathcal{E}(\lambda=1/sd(Y))$
    -   als "Streuung", d.h. $\lambda$ von $h_i$ wird $\frac{1}{sd(Y)}$ angenommen. $\square$
:::

Eine sinnvolle Strategie ist, einen Prior so zu w√§hlen, dass man nicht √ºbergewiss ist, 
also nicht zu sicher Dinge behauptet, die dann vielleicht doch passieren 
(also die Ungewissheit zu gering spezifiziert), andererseits sollte man extreme, 
unplausible Werte ausschlie√üen.

::: callout-important
Bei der Wahl der Prioris gibt es nicht die eine, richtige Wahl. 
Die beste Entscheidung ist auf transparente Art den Stand der Forschung einflie√üen zu lassen und eigene Entscheidungen zu begr√ºnden. 
H√§ufig sind mehrere Entscheidungen m√∂glich. M√∂chte man lieber vorsichtig sein,
weil man wenig √ºber den Gegenstand wei√ü, dann k√∂nnte man z.B. auf die Voreinstellung von `rstanarm` vertrauen,
die "schwachinformativ" ist, also nur wenig Priori-Information in das Modell einflie√üen l√§sst.
:::

### Wenn es schnell gehen muss

`stan_glm()` ist deutlich langsamer als z.B. der befreundete Golem `lm()`.
Der Grund f√ºr Stans Langsamkeit ist, dass er viele Stichproben zieht, also viel zu z√§hlen hat.
Au√üerdem wiederholt er das Stichprobenziehen (im Standard) 4 Mal, damit sein Meister pr√ºfen kann, ob er (Stan) die Arbeit auch immer richtig gemacht hat.
Die Idee dabei ist, wenn alle vier Durchf√ºhrungen (auch "Ketten" engl., chains) genannt,
zum etwa gleichen Ergebnis kommen, dann wird schon alles mit rechten Dingen zugegangen sein.
Weichen die Ergebnisse der 4 Ketten voneinander ab, so ist Stan ein Fehler unterlaufen, oder, irgendetwas ist "dumm gelaufen".
An dieser Stelle schauen wir uns die Ketten nicht n√§her an, aber es sei notiert, dass man die Anzahl der Ketten mit dem Argument `chains` steuern kann.
M√∂chte man, dass Stan sich beeilt, so kann man `chains = 1` setzen, das spart Zeit, s. `m_kung_1kette`. 

```{r m41a, echo = TRUE, results="hide"}
m_kung_1kette <- stan_glm(height ~ 1, 
                 data = kung_erwachsen, 
                 chains = 1,  # nur 1 Kette, anstelle von 4 im Default, spart Zeit
                 refresh = 0) 

parameters(m_kung_1kette)  
```

## Modell `m_kung_neue_prioris`: Standard-Priori-Werte



Im Modell `m_kung` haben wir unsere eigenen Priori-Werte einflie√üen lassen.
Jetzt vertrauen wir die Wahl der Prioris Stand an.
Betrachten Sie dazu unser zweites Kung-Modell, `m_kung_neue_prioris`.


```{r}
#| eval: false
m_kung_neue_prioris <- 
  stan_glm(height ~ 1,
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           data = kung_erwachsen)
parameters(m_kung_neue_prioris)
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-m_kung_neue_prioris-params
#| tbl-cap: "Parameter von m_kung_neue_prioris mit Standard-rioriwerten"
m_kung_neue_prioris <- 
  stan_glm(height ~ 1, 
           refresh = FALSE,  # bitte nicht so viel Ausgabe drucken
           seed = 42,  # Zufallszahlen fixieren
           data = kung_erwachsen)
parameters(m_kung_neue_prioris) |> display()
```

Wir haben noch nicht alle Informationen kennengelernt, die in @tbl-m_kung_neue_prioris-params ausgegeben werden. 
Im Zweifel: Einfach ignorieren. Wichtige F√§higkeit im Studium. ü§ì

::: callout-important
Vergleichen Sie die Parameterwerte von `m_kung` und `m_kung_neue_prioris`! 
Was f√§llt Ihnen auf? Nichts? Gut! 
Tats√§chlich liefern beide Modelle sehr √§hnliche Parameterwerte. Die Prioriwerte waren nicht so wichtig, 
weil wir genug Daten haben. Hat man einigerma√üen viele Daten, 
so fallen Prioriwerte nicht mehr ins Gewicht, zumindest wenn sie moderat gew√§hlt waren.
:::

```{r Kung-16-bis, eval = FALSE}
#| echo: false
#write_rds(m_kung_neue_prioris, "objects/m_kung_neue_prioris.rds")
```

### Posteriori-Verteilung und Parameter plotten

Leider liefert der Stan-Golem leider keinen braven Tibble (Tabelle) zur√ºck.

> üë®‚Äçüè´ Mensch, Stan, streng dich mal ein bisschen an!

> ü§ñ Mach's halt selber, wenn du es besser kannst!

Daher m√ºssen wir die Ausgabe des Stan-Golemns erst in eine sch√∂ne Tabelle umwandeln:

```{r}
m_kung_neue_prioris_tibble <-
  as_tibble(m_kung_neue_prioris)

head(m_kung_neue_prioris_tibble)
```

Au√üerdem ist der Name der ersten Spalte eigentlich unzul√§ssig, 
da Spaltennamen in R nicht mit Sonderzeichen anfangen d√ºrfen (sondern mit Buchstaben). 
Daher m√ºssen wir den Namen mit "Samthandschuhen" anpacken. 
Auf Errisch sind das die Backticks, die wir um den Namen rumwickeln m√ºssen, s. die folgende Syntax.

::: panel-tabset
### Mit `{ggpubr}`

```{r}
m_kung_neue_prioris_tibble |> 
  gghistogram(x = "`(Intercept)`")  # Aus dem Paket "ggpubr"
```

### Mit `{ggplot}`

```{r}
m_kung_neue_prioris_tibble |> 
  ggplot(aes(x = `(Intercept)`)) +  # Aus dem Paket `ggplot2`
  geom_histogram()
```
:::

Als Ausblick: Ein Vergleich mehrerer Priori-Werte w√§re auch n√ºtzlich, 
um ein skeptisches Publikum von der Wahl (bzw. der Indifferenz) der gew√§hlten Priori-Werte zu √ºberzeugen.

### Welche K√∂rpergr√∂√üen erwartet unser Modell

Bisher haben wir untersucht, wie die Verteilung der *mittleren* K√∂rpergr√∂√üen, $\mu$, 
laut unserem Modell aussehen k√∂nnte; wir haben uns also mit der Post-Verteilung von $\mu$ besch√§ftigt. 
Wir k√∂nnten aber auch an der Frage der Verteilung der *tats√§chlichen* K√∂rpergr√∂√üen, $h_i$, laut Modell, interessiert sein: 
Wie gro√ü sind sie denn, die !Kung, laut unserem Modell?


Wie wir wissen, liefert unser Stan-Golem eine *Stichproben-Postverteilung*.
Wenn wir das Ergebnisobjekt unserer Analyse, `m_kung` in eine Tabelle (Tibble) umwandeln und (die ersten paar Zeilen) betrachen,
sehen wir diese Stichproben:

```{r}
m_kung |> as_tibble() |> head()
```

Laut unserem Modell sind die K√∂rpergr√∂√üen, $h_i$, normalverteilt mit $\mu$ und $\sigma$.
$\mu$ wird von Stan, der in Begriffen der Regressionsanalyse denkt, schn√∂de als `(Intercept)` bezeichnet.
Wir k√∂nnten jetzt also f√ºr jede Zeile eine Normalverteilung berechnen.
Und daraus zuf√§llig eine Zahl ziehen. Damit h√§tten wir dann unsere Verteilung von K√∂rpergr√∂√üen laut Modell.
Diese Verteilung nennt man auch *Posterior-Pr√§diktiv-Verteilung*.
Pr√§diktiv daher, weil sie die Werte der K√∂rpergr√∂√üen "vorhersagt".

Wir k√∂nnen uns diese Verteilung auch komfortabel von R ausgeben lassen, s. @fig-ppcheck.

```{r}
#| layout-ncol: 2
#| label: fig-ppcheck
#| fig-cap: "Die Posterior-Pr√§diktiv-Verteilung: Die Verteilung der tats√§chlichen K√∂rpergr√∂√üen auf Basis der Post-Verteilung. Unser Modell stellt die tats√§chliche Verteilung ganz gut nach."
#| fig-subcap:
#|   - "Die dunkle, dicke Dichtekurve zeigt die tats√§chliche Verteilung der K√∂rpergr√∂√üen im Datensatz. Die hellen, leichten Dichtekurven zeigen die Verteilungen laut der Post-Verteilung unseres Modells."
#|   - "Der wahre Wert einer Test-Statistik (T), hier der Mittelwert der K√∂rpergr√∂√üen, wird mit der Verteilung der K√∂rpergr√∂√üen in Bezug gesetzt."
pp_check(m_kung)
pp_check(m_kung, "stat")
```

## Fazit

<!-- TODO: Die neuen Infosder Gauss-Modelle auf die formel von Bayes Theorem zur√ºck√ºhren. -->

### Zusammenfassung

Wir haben die Posteriori-Verteilung f√ºr ein Gauss-Modell berechnet. Dabei hatten wir ein einfaches Modell mit metrischer Zielvariablen, ohne Pr√§diktoren, betrachtet. Die Zielvariable, K√∂rpergr√∂√üe (`height`), haben wir als normalverteilt mit den Parametern $\mu$ und $\sigma$ angenommen. F√ºr $\mu$ und $\sigma$ haben wir jeweils keinen einzelnen (fixen) Wert angenommen, sondern eine Wahrscheinlichkeitsverteilung, der mit der Priori-Verteilung f√ºr $\mu$ bzw. $\sigma$ festgelegt ist.

### Botschaft von einem Statistiker

![üß° Bleiben Sie dran!](img/chicken_standard_deviation.jpg)

::: callout-important
Kontinuierliches Lernen ist der Schl√ºssel zum Erfolg.
:::

## Vertiefung: Wahl der Priori-Werte

üèéÔ∏è Dieser Abschnitt ist eine VERTIEFUNG und nicht pr√ºfungsrelevant. üèé

### Welche Beobachtungen sind auf Basis unseres Modells zu erwarten?

```{r prior-pred, echo = TRUE}
n <- 1e4

sim <- tibble(sample_mu  = 
      rnorm(n, 
            mean = 178, 
            sd   = 20),
    sample_sigma = 
      rexp(n, 
            rate = 0.1)) %>% 
  mutate(height  = 
      rnorm(n, 
            mean = sample_mu, 
            sd   = sample_sigma))

height_sim_sd <- 
  sd(sim$height) %>% round()
height_sim_mean <- 
  mean(sim$height) %>% round()

```

üí≠ Was denkt der Golem (`m_kung`) *apriori* von der Gr√∂√üe der !Kung?

ü¶æ Ziehen wir mal ein paar Stichproben auf Basis des Modells. Voil√†:

```{r Kung-12}
p3 <- 
  sim %>% 
  ggplot(aes(x = height)) +
  geom_density(fill = "grey33") +
  scale_x_continuous(breaks = c(0, 178-3*height_sim_sd, 178, 178+3*height_sim_sd)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "height ~ dnorm(mu, sigma)",
       caption = "X-Achse zeigt MW¬±3SD",
       x = "Gr√∂√üe") +
  theme(panel.grid = element_blank()) 

p3
```

[Quellcode](https://bookdown.org/content/4857/geocentric-models.html#a-gaussian-model-of-height)

### Priori-Werte pr√ºfen mit der Priori-Pr√§diktiv-Verteilung

-   Die Priori-Pr√§diktiv-Verteilung (`sim`) simuliert Beobachtungen (nur) auf Basis der Priori-Annahmen: $h_i \sim \mathcal{N}(\mu, \sigma),$ $\mu \sim \mathcal{N}(178, 20),$ $\sigma \sim \mathcal{E}(0.1)$
-   So k√∂nnen wir pr√ºfen, ob die Priori-Werte vern√ºnftig sind.

Die Priori-Pr√§diktiv-Verteilung zeigt, dass unsere Priori-Werte ziemlich vage sind, also einen zu breiten Bereich an Gr√∂√üenwerten zulassen:

```{r Kung-13}
p3
```

Anteil $h_i > 200$:

```{r Kung-14, echo = TRUE}
anteil_gro√üer_kung <- 
sim %>% 
  count( height > 200) %>% 
  mutate(prop = n/sum(n))
anteil_gro√üer_kung
```

ü§î Sehr gro√üe Buschleute? `r round(anteil_gro√üer_kung$prop[2], 2)*100` Prozent sind gr√∂√üer als 2 Meter. Das ist diskutabel, muss aber nicht zwangsl√§ufig ein schlechter Prior sein.

### Vorhersagen der Priori-Werte

```{r Kung-15}
#| echo: false
sw_path <- paste0(here::here(),"/img/south_west_black_24dp2.png")
se_path <- paste0(here::here(),"/img/south_east_black_24dp2.png")


sw <- fig(sw_path)
se <- fig(se_path)



(p_nv_kung_prior + p_exp_kung_prior) / (se + sw) / (plot_spacer() + p3 + plot_spacer()) 

```

### Extrem vage Priori-Verteilung f√ºr die Streuung?

$$\sigma \sim \mathcal{E}(\lambda=0.01)$$

```{r Kung-16}
#| echo: false
set.seed(4)


# simulate
sim2 <-
  tibble(sample_mu    = rnorm(n, mean = 178, sd = 100),
         sample_sigma = rexp(n, rate = .01)) %>% 
  mutate(height = rnorm(n, mean = sample_mu, sd = sample_sigma))

# compute the values we'll use to break on our x axis
breaks <-
  c(mean(sim2$height) - 3 * sd(sim2$height), 0, mean(sim2$height), mean(sim2$height) + 3 * sd(sim2$height)) %>% 
    round(digits = 0)

# this is just for aesthetics
text <-
  tibble(height = 272 - 25,
         y      = .0013,
         label  = "gr√∂√üter Mann",
         angle  = 90)

# plot
p4 <-
  sim2 %>% 
  ggplot(aes(x = height)) +
  geom_density(fill = "grey20") +
  geom_vline(xintercept = 0, color = "white") +
  geom_vline(xintercept = 272, color = "white", linetype = 3) +
  geom_text(data = text,
            aes(y = y, label = label, angle = angle),
            color = "grey92") +
  scale_x_continuous(breaks = breaks, 
                     limits = c(-400, 700)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "height ~ dnorm(mu, sigma)\nmu ~ dnorm(178, 100)\nsigma ~ E(0.01)",
       x = "Gr√∂√üe",
       caption = "X-Achse zeigt MW¬±3SD") +
  theme(panel.grid = element_blank()) 

p4
```

Die Streuung der Gr√∂√üen ist weit:

```{r Kung-3}
d <- 
  tibble(x = seq(0,75, by =.01),
         y = dexp(x, rate = .01))

d %>% 
  ggplot(aes(x,y)) +
  geom_line()
```

```{r Kung-17, echo = FALSE, eval = FALSE}
sim2 %>% 
  count(height < 0) %>% 
  mutate(prop = n()/n)
```

ü§î Das Modell geht apriori von ein paar Prozent Menschen mit *negativer* Gr√∂√üe aus. 
Ein Haufen Riesen üëπ werden bei den !Kung auch erwartet.

ü§Ø Vage (flache, informationslose, "neutrale", "objektive") Priori-Werte machen oft keinen Sinn, 
weil sie extreme, unplausible Werte zulassen.

## Aufgaben

### Papier-und-Bleistift-Aufgaben

<!-- 3. [ReThink4e3](https://datenwerk.netlify.app/posts/ReThink4e3/ReThink4e3.html) -->

1.  [exp-tab](https://datenwerk.netlify.app/posts/exp-tab/)
2.  [exp-tab2](https://datenwerk.netlify.app/posts/exp-tab2/)
3.  [norms-sd](https://datenwerk.netlify.app/posts/norms-sd/)
4.  [small-wide-normal](https://datenwerk.netlify.app/posts/small-wide-normal/)
5.  [exp1](https://datenwerk.netlify.app/posts/exp1/)
6.  [distros](https://datenwerk.netlify.app/posts/distros/)
7.  [mtcars-post_paper](https://datenwerk.netlify.app/posts/mtcars-post_paper/)
8.  [groesse03](https://datenwerk.netlify.app/posts/groesse03/)
9.  [pupil-size2](https://datenwerk.netlify.app/posts/pupil-size2/)
10. [groesse04](https://datenwerk.netlify.app/posts/groesse04/)
11. [ReThink4e2](https://datenwerk.netlify.app/posts/ReThink4e2/ReThink4e2.html)
12. [Priorwahl1](https://datenwerk.netlify.app/posts/Priorwahl1/Priorwahl1.html)

### Aufgaben, f√ºr die man einen Computer ben√∂tigt

1.  [stan_glm01](https://datenwerk.netlify.app/posts/stan_glm01/stan_glm01.html)
2.  [ReThink4e1](https://datenwerk.netlify.app/posts/rethink4e1/rethink4e1)
3.  [ReThink4e3](https://datenwerk.netlify.app/posts/rethink4e3/rethink4e3)
4.  [Kung-height](https://datenwerk.netlify.app/posts/kung-height/kung-height)
5.  [Pupil-size](https://datenwerk.netlify.app/posts/pupil-size/pupil-size)
6.  [IQ-Studentis](https://datenwerk.netlify.app/posts/iq-studentis/iq-studentis)
7.  [Priori-Streuung](https://datenwerk.netlify.app/posts/priori-streuung/priori-streuung)

## ---

![](img/outro-08.jpg){width="100%"}
